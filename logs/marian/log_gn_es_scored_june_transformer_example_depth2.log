[2023-07-01 07:38:44] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 07:38:44] [marian] Running on node20.datos.cluster.uy as process 38181 with command line:
[2023-07-01 07:38:44] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 1 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 07:38:44] [config] after: 0e
[2023-07-01 07:38:44] [config] after-batches: 0
[2023-07-01 07:38:44] [config] after-epochs: 1
[2023-07-01 07:38:44] [config] all-caps-every: 0
[2023-07-01 07:38:44] [config] allow-unk: false
[2023-07-01 07:38:44] [config] authors: false
[2023-07-01 07:38:44] [config] beam-size: 12
[2023-07-01 07:38:44] [config] bert-class-symbol: "[CLS]"
[2023-07-01 07:38:44] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 07:38:44] [config] bert-masking-fraction: 0.15
[2023-07-01 07:38:44] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 07:38:44] [config] bert-train-type-embeddings: true
[2023-07-01 07:38:44] [config] bert-type-vocab-size: 2
[2023-07-01 07:38:44] [config] build-info: ""
[2023-07-01 07:38:44] [config] check-gradient-nan: false
[2023-07-01 07:38:44] [config] check-nan: false
[2023-07-01 07:38:44] [config] cite: false
[2023-07-01 07:38:44] [config] clip-norm: 5
[2023-07-01 07:38:44] [config] cost-scaling:
[2023-07-01 07:38:44] [config]   []
[2023-07-01 07:38:44] [config] cost-type: ce-sum
[2023-07-01 07:38:44] [config] cpu-threads: 0
[2023-07-01 07:38:44] [config] data-threads: 8
[2023-07-01 07:38:44] [config] data-weighting: ""
[2023-07-01 07:38:44] [config] data-weighting-type: sentence
[2023-07-01 07:38:44] [config] dec-cell: gru
[2023-07-01 07:38:44] [config] dec-cell-base-depth: 2
[2023-07-01 07:38:44] [config] dec-cell-high-depth: 1
[2023-07-01 07:38:44] [config] dec-depth: 2
[2023-07-01 07:38:44] [config] devices:
[2023-07-01 07:38:44] [config]   - 0
[2023-07-01 07:38:44] [config] dim-emb: 512
[2023-07-01 07:38:44] [config] dim-rnn: 1024
[2023-07-01 07:38:44] [config] dim-vocabs:
[2023-07-01 07:38:44] [config]   - 0
[2023-07-01 07:38:44] [config]   - 0
[2023-07-01 07:38:44] [config] disp-first: 0
[2023-07-01 07:38:44] [config] disp-freq: 1000u
[2023-07-01 07:38:44] [config] disp-label-counts: true
[2023-07-01 07:38:44] [config] dropout-rnn: 0
[2023-07-01 07:38:44] [config] dropout-src: 0
[2023-07-01 07:38:44] [config] dropout-trg: 0
[2023-07-01 07:38:44] [config] dump-config: ""
[2023-07-01 07:38:44] [config] dynamic-gradient-scaling:
[2023-07-01 07:38:44] [config]   []
[2023-07-01 07:38:44] [config] early-stopping: 10
[2023-07-01 07:38:44] [config] early-stopping-on: first
[2023-07-01 07:38:44] [config] embedding-fix-src: false
[2023-07-01 07:38:44] [config] embedding-fix-trg: false
[2023-07-01 07:38:44] [config] embedding-normalization: false
[2023-07-01 07:38:44] [config] embedding-vectors:
[2023-07-01 07:38:44] [config]   []
[2023-07-01 07:38:44] [config] enc-cell: gru
[2023-07-01 07:38:44] [config] enc-cell-depth: 1
[2023-07-01 07:38:44] [config] enc-depth: 2
[2023-07-01 07:38:44] [config] enc-type: bidirectional
[2023-07-01 07:38:44] [config] english-title-case-every: 0
[2023-07-01 07:38:44] [config] exponential-smoothing: 0.0001
[2023-07-01 07:38:44] [config] factor-weight: 1
[2023-07-01 07:38:44] [config] factors-combine: sum
[2023-07-01 07:38:44] [config] factors-dim-emb: 0
[2023-07-01 07:38:44] [config] gradient-checkpointing: false
[2023-07-01 07:38:44] [config] gradient-norm-average-window: 100
[2023-07-01 07:38:44] [config] guided-alignment: none
[2023-07-01 07:38:44] [config] guided-alignment-cost: mse
[2023-07-01 07:38:44] [config] guided-alignment-weight: 0.1
[2023-07-01 07:38:44] [config] ignore-model-config: false
[2023-07-01 07:38:44] [config] input-types:
[2023-07-01 07:38:44] [config]   []
[2023-07-01 07:38:44] [config] interpolate-env-vars: false
[2023-07-01 07:38:44] [config] keep-best: false
[2023-07-01 07:38:44] [config] label-smoothing: 0.1
[2023-07-01 07:38:44] [config] layer-normalization: false
[2023-07-01 07:38:44] [config] learn-rate: 0.0003
[2023-07-01 07:38:44] [config] lemma-dependency: ""
[2023-07-01 07:38:44] [config] lemma-dim-emb: 0
[2023-07-01 07:38:44] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 07:38:44] [config] log-level: info
[2023-07-01 07:38:44] [config] log-time-zone: ""
[2023-07-01 07:38:44] [config] logical-epoch:
[2023-07-01 07:38:44] [config]   - 1e
[2023-07-01 07:38:44] [config]   - 0
[2023-07-01 07:38:44] [config] lr-decay: 0
[2023-07-01 07:38:44] [config] lr-decay-freq: 50000
[2023-07-01 07:38:44] [config] lr-decay-inv-sqrt:
[2023-07-01 07:38:44] [config]   - 16000
[2023-07-01 07:38:44] [config] lr-decay-repeat-warmup: false
[2023-07-01 07:38:44] [config] lr-decay-reset-optimizer: false
[2023-07-01 07:38:44] [config] lr-decay-start:
[2023-07-01 07:38:44] [config]   - 10
[2023-07-01 07:38:44] [config]   - 1
[2023-07-01 07:38:44] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 07:38:44] [config] lr-report: true
[2023-07-01 07:38:44] [config] lr-warmup: 16000
[2023-07-01 07:38:44] [config] lr-warmup-at-reload: false
[2023-07-01 07:38:44] [config] lr-warmup-cycle: false
[2023-07-01 07:38:44] [config] lr-warmup-start-rate: 0
[2023-07-01 07:38:44] [config] max-length: 100
[2023-07-01 07:38:44] [config] max-length-crop: false
[2023-07-01 07:38:44] [config] max-length-factor: 3
[2023-07-01 07:38:44] [config] maxi-batch: 100
[2023-07-01 07:38:44] [config] maxi-batch-sort: trg
[2023-07-01 07:38:44] [config] mini-batch: 1000
[2023-07-01 07:38:44] [config] mini-batch-fit: true
[2023-07-01 07:38:44] [config] mini-batch-fit-step: 10
[2023-07-01 07:38:44] [config] mini-batch-round-up: true
[2023-07-01 07:38:44] [config] mini-batch-track-lr: false
[2023-07-01 07:38:44] [config] mini-batch-warmup: 0
[2023-07-01 07:38:44] [config] mini-batch-words: 0
[2023-07-01 07:38:44] [config] mini-batch-words-ref: 0
[2023-07-01 07:38:44] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 07:38:44] [config] multi-loss-type: sum
[2023-07-01 07:38:44] [config] n-best: false
[2023-07-01 07:38:44] [config] no-nccl: false
[2023-07-01 07:38:44] [config] no-reload: false
[2023-07-01 07:38:44] [config] no-restore-corpus: false
[2023-07-01 07:38:44] [config] normalize: 1
[2023-07-01 07:38:44] [config] normalize-gradient: false
[2023-07-01 07:38:44] [config] num-devices: 0
[2023-07-01 07:38:44] [config] optimizer: adam
[2023-07-01 07:38:44] [config] optimizer-delay: 1
[2023-07-01 07:38:44] [config] optimizer-params:
[2023-07-01 07:38:44] [config]   - 0.9
[2023-07-01 07:38:44] [config]   - 0.98
[2023-07-01 07:38:44] [config]   - 1e-09
[2023-07-01 07:38:44] [config] output-omit-bias: false
[2023-07-01 07:38:44] [config] overwrite: true
[2023-07-01 07:38:44] [config] precision:
[2023-07-01 07:38:44] [config]   - float32
[2023-07-01 07:38:44] [config]   - float32
[2023-07-01 07:38:44] [config] pretrained-model: ""
[2023-07-01 07:38:44] [config] quantize-biases: false
[2023-07-01 07:38:44] [config] quantize-bits: 0
[2023-07-01 07:38:44] [config] quantize-log-based: false
[2023-07-01 07:38:44] [config] quantize-optimization-steps: 0
[2023-07-01 07:38:44] [config] quiet: false
[2023-07-01 07:38:44] [config] quiet-translation: true
[2023-07-01 07:38:44] [config] relative-paths: false
[2023-07-01 07:38:44] [config] right-left: false
[2023-07-01 07:38:44] [config] save-freq: 10000u
[2023-07-01 07:38:44] [config] seed: 1234
[2023-07-01 07:38:44] [config] sentencepiece-alphas:
[2023-07-01 07:38:44] [config]   []
[2023-07-01 07:38:44] [config] sentencepiece-max-lines: 2000000
[2023-07-01 07:38:44] [config] sentencepiece-options: ""
[2023-07-01 07:38:44] [config] sharding: global
[2023-07-01 07:38:44] [config] shuffle: data
[2023-07-01 07:38:44] [config] shuffle-in-ram: false
[2023-07-01 07:38:44] [config] sigterm: save-and-exit
[2023-07-01 07:38:44] [config] skip: false
[2023-07-01 07:38:44] [config] sqlite: ""
[2023-07-01 07:38:44] [config] sqlite-drop: false
[2023-07-01 07:38:44] [config] sync-freq: 200u
[2023-07-01 07:38:44] [config] sync-sgd: true
[2023-07-01 07:38:44] [config] tempdir: /tmp
[2023-07-01 07:38:44] [config] tied-embeddings: false
[2023-07-01 07:38:44] [config] tied-embeddings-all: true
[2023-07-01 07:38:44] [config] tied-embeddings-src: false
[2023-07-01 07:38:44] [config] train-embedder-rank:
[2023-07-01 07:38:44] [config]   []
[2023-07-01 07:38:44] [config] train-sets:
[2023-07-01 07:38:44] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 07:38:44] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 07:38:44] [config] transformer-aan-activation: swish
[2023-07-01 07:38:44] [config] transformer-aan-depth: 2
[2023-07-01 07:38:44] [config] transformer-aan-nogate: false
[2023-07-01 07:38:44] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 07:38:44] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 07:38:44] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 07:38:44] [config] transformer-depth-scaling: false
[2023-07-01 07:38:44] [config] transformer-dim-aan: 2048
[2023-07-01 07:38:44] [config] transformer-dim-ffn: 2048
[2023-07-01 07:38:44] [config] transformer-dropout: 0.1
[2023-07-01 07:38:44] [config] transformer-dropout-attention: 0
[2023-07-01 07:38:44] [config] transformer-dropout-ffn: 0
[2023-07-01 07:38:44] [config] transformer-ffn-activation: swish
[2023-07-01 07:38:44] [config] transformer-ffn-depth: 2
[2023-07-01 07:38:44] [config] transformer-guided-alignment-layer: last
[2023-07-01 07:38:44] [config] transformer-heads: 8
[2023-07-01 07:38:44] [config] transformer-no-projection: false
[2023-07-01 07:38:44] [config] transformer-pool: false
[2023-07-01 07:38:44] [config] transformer-postprocess: dan
[2023-07-01 07:38:44] [config] transformer-postprocess-emb: d
[2023-07-01 07:38:44] [config] transformer-postprocess-top: ""
[2023-07-01 07:38:44] [config] transformer-preprocess: ""
[2023-07-01 07:38:44] [config] transformer-tied-layers:
[2023-07-01 07:38:44] [config]   []
[2023-07-01 07:38:44] [config] transformer-train-position-embeddings: false
[2023-07-01 07:38:44] [config] tsv: false
[2023-07-01 07:38:44] [config] tsv-fields: 0
[2023-07-01 07:38:44] [config] type: transformer
[2023-07-01 07:38:44] [config] ulr: false
[2023-07-01 07:38:44] [config] ulr-dim-emb: 0
[2023-07-01 07:38:44] [config] ulr-dropout: 0
[2023-07-01 07:38:44] [config] ulr-keys-vectors: ""
[2023-07-01 07:38:44] [config] ulr-query-vectors: ""
[2023-07-01 07:38:44] [config] ulr-softmax-temperature: 1
[2023-07-01 07:38:44] [config] ulr-trainable-transformation: false
[2023-07-01 07:38:44] [config] unlikelihood-loss: false
[2023-07-01 07:38:44] [config] valid-freq: 50000000
[2023-07-01 07:38:44] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 07:38:44] [config] valid-max-length: 1000
[2023-07-01 07:38:44] [config] valid-metrics:
[2023-07-01 07:38:44] [config]   - cross-entropy
[2023-07-01 07:38:44] [config]   - translation
[2023-07-01 07:38:44] [config] valid-mini-batch: 64
[2023-07-01 07:38:44] [config] valid-reset-stalled: false
[2023-07-01 07:38:44] [config] valid-script-args:
[2023-07-01 07:38:44] [config]   []
[2023-07-01 07:38:44] [config] valid-script-path: ""
[2023-07-01 07:38:44] [config] valid-sets:
[2023-07-01 07:38:44] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 07:38:44] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 07:38:44] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 07:38:44] [config] vocabs:
[2023-07-01 07:38:44] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 07:38:44] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 07:38:44] [config] word-penalty: 0
[2023-07-01 07:38:44] [config] word-scores: false
[2023-07-01 07:38:44] [config] workspace: 2048
[2023-07-01 07:38:44] [config] Model is being created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 07:38:44] Using synchronous SGD
[2023-07-01 07:38:45] Synced seed 1234
[2023-07-01 07:38:45] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 07:38:45] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 07:38:45] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 07:38:45] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 07:38:45] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 07:38:45] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 07:38:47] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 07:38:47] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 07:38:47] [comm] Using global sharding
[2023-07-01 07:38:47] [comm] NCCLCommunicators constructed successfully
[2023-07-01 07:38:47] [training] Using 1 GPUs
[2023-07-01 07:38:47] [logits] Applying loss function for 1 factor(s)
[2023-07-01 07:38:47] [memory] Reserving 88 MB, device gpu0
[2023-07-01 07:38:50] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 07:38:50] [memory] Reserving 88 MB, device gpu0
[2023-07-01 07:38:58] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 07:38:58] [valid] No post-processing script given for validating translator
[2023-07-01 07:38:58] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 07:38:58] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 07:38:58] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 07:38:58] [comm] Using global sharding
[2023-07-01 07:38:58] [comm] NCCLCommunicators constructed successfully
[2023-07-01 07:38:58] [training] Using 1 GPUs
[2023-07-01 07:38:58] Training started
[2023-07-01 07:38:58] [data] Shuffling data
[2023-07-01 07:38:58] [data] Done reading 20,192 sentences
[2023-07-01 07:38:58] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 07:38:58] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-07-01 07:38:58] [memory] Reserving 88 MB, device gpu0
[2023-07-01 07:38:58] [memory] Reserving 88 MB, device gpu0
[2023-07-01 07:38:58] Parameter type float32, optimization type float32, casting types false
[2023-07-01 07:38:58] Allocating memory for general optimizer shards
[2023-07-01 07:38:58] [memory] Reserving 88 MB, device gpu0
[2023-07-01 07:38:58] Allocating memory for Adam-specific shards
[2023-07-01 07:38:58] [memory] Reserving 176 MB, device gpu0
[2023-07-01 07:39:19] Seen 20,073 samples
[2023-07-01 07:39:19] Starting data epoch 2 in logical epoch 2
[2023-07-01 07:39:19] Training finished
[2023-07-01 07:39:22] [valid] Ep. 2 : Up. 189 : cross-entropy : 249.233 : new best
[2023-07-01 07:44:49] [valid] Ep. 2 : Up. 189 : translation : 0 : new best
[2023-07-01 07:44:49] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 07:44:50] Saving Adam parameters
[2023-07-01 07:44:51] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 07:44:59] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 07:44:59] [marian] Running on node20.datos.cluster.uy as process 38561 with command line:
[2023-07-01 07:44:59] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 2 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 07:44:59] [config] after: 0e
[2023-07-01 07:44:59] [config] after-batches: 0
[2023-07-01 07:44:59] [config] after-epochs: 2
[2023-07-01 07:44:59] [config] all-caps-every: 0
[2023-07-01 07:44:59] [config] allow-unk: false
[2023-07-01 07:44:59] [config] authors: false
[2023-07-01 07:44:59] [config] beam-size: 12
[2023-07-01 07:44:59] [config] bert-class-symbol: "[CLS]"
[2023-07-01 07:44:59] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 07:44:59] [config] bert-masking-fraction: 0.15
[2023-07-01 07:44:59] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 07:44:59] [config] bert-train-type-embeddings: true
[2023-07-01 07:44:59] [config] bert-type-vocab-size: 2
[2023-07-01 07:44:59] [config] build-info: ""
[2023-07-01 07:44:59] [config] check-gradient-nan: false
[2023-07-01 07:44:59] [config] check-nan: false
[2023-07-01 07:44:59] [config] cite: false
[2023-07-01 07:44:59] [config] clip-norm: 5
[2023-07-01 07:44:59] [config] cost-scaling:
[2023-07-01 07:44:59] [config]   []
[2023-07-01 07:44:59] [config] cost-type: ce-sum
[2023-07-01 07:44:59] [config] cpu-threads: 0
[2023-07-01 07:44:59] [config] data-threads: 8
[2023-07-01 07:44:59] [config] data-weighting: ""
[2023-07-01 07:44:59] [config] data-weighting-type: sentence
[2023-07-01 07:44:59] [config] dec-cell: gru
[2023-07-01 07:44:59] [config] dec-cell-base-depth: 2
[2023-07-01 07:44:59] [config] dec-cell-high-depth: 1
[2023-07-01 07:44:59] [config] dec-depth: 2
[2023-07-01 07:44:59] [config] devices:
[2023-07-01 07:44:59] [config]   - 0
[2023-07-01 07:44:59] [config] dim-emb: 512
[2023-07-01 07:44:59] [config] dim-rnn: 1024
[2023-07-01 07:44:59] [config] dim-vocabs:
[2023-07-01 07:44:59] [config]   - 16384
[2023-07-01 07:44:59] [config]   - 16384
[2023-07-01 07:44:59] [config] disp-first: 0
[2023-07-01 07:44:59] [config] disp-freq: 1000u
[2023-07-01 07:44:59] [config] disp-label-counts: true
[2023-07-01 07:44:59] [config] dropout-rnn: 0
[2023-07-01 07:44:59] [config] dropout-src: 0
[2023-07-01 07:44:59] [config] dropout-trg: 0
[2023-07-01 07:44:59] [config] dump-config: ""
[2023-07-01 07:44:59] [config] dynamic-gradient-scaling:
[2023-07-01 07:44:59] [config]   []
[2023-07-01 07:44:59] [config] early-stopping: 10
[2023-07-01 07:44:59] [config] early-stopping-on: first
[2023-07-01 07:44:59] [config] embedding-fix-src: false
[2023-07-01 07:44:59] [config] embedding-fix-trg: false
[2023-07-01 07:44:59] [config] embedding-normalization: false
[2023-07-01 07:44:59] [config] embedding-vectors:
[2023-07-01 07:44:59] [config]   []
[2023-07-01 07:44:59] [config] enc-cell: gru
[2023-07-01 07:44:59] [config] enc-cell-depth: 1
[2023-07-01 07:44:59] [config] enc-depth: 2
[2023-07-01 07:44:59] [config] enc-type: bidirectional
[2023-07-01 07:44:59] [config] english-title-case-every: 0
[2023-07-01 07:44:59] [config] exponential-smoothing: 0.0001
[2023-07-01 07:44:59] [config] factor-weight: 1
[2023-07-01 07:44:59] [config] factors-combine: sum
[2023-07-01 07:44:59] [config] factors-dim-emb: 0
[2023-07-01 07:44:59] [config] gradient-checkpointing: false
[2023-07-01 07:44:59] [config] gradient-norm-average-window: 100
[2023-07-01 07:44:59] [config] guided-alignment: none
[2023-07-01 07:44:59] [config] guided-alignment-cost: mse
[2023-07-01 07:44:59] [config] guided-alignment-weight: 0.1
[2023-07-01 07:44:59] [config] ignore-model-config: false
[2023-07-01 07:44:59] [config] input-types:
[2023-07-01 07:44:59] [config]   []
[2023-07-01 07:44:59] [config] interpolate-env-vars: false
[2023-07-01 07:44:59] [config] keep-best: false
[2023-07-01 07:44:59] [config] label-smoothing: 0.1
[2023-07-01 07:44:59] [config] layer-normalization: false
[2023-07-01 07:44:59] [config] learn-rate: 0.0003
[2023-07-01 07:44:59] [config] lemma-dependency: ""
[2023-07-01 07:44:59] [config] lemma-dim-emb: 0
[2023-07-01 07:44:59] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 07:44:59] [config] log-level: info
[2023-07-01 07:44:59] [config] log-time-zone: ""
[2023-07-01 07:44:59] [config] logical-epoch:
[2023-07-01 07:44:59] [config]   - 1e
[2023-07-01 07:44:59] [config]   - 0
[2023-07-01 07:44:59] [config] lr-decay: 0
[2023-07-01 07:44:59] [config] lr-decay-freq: 50000
[2023-07-01 07:44:59] [config] lr-decay-inv-sqrt:
[2023-07-01 07:44:59] [config]   - 16000
[2023-07-01 07:44:59] [config] lr-decay-repeat-warmup: false
[2023-07-01 07:44:59] [config] lr-decay-reset-optimizer: false
[2023-07-01 07:44:59] [config] lr-decay-start:
[2023-07-01 07:44:59] [config]   - 10
[2023-07-01 07:44:59] [config]   - 1
[2023-07-01 07:44:59] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 07:44:59] [config] lr-report: true
[2023-07-01 07:44:59] [config] lr-warmup: 16000
[2023-07-01 07:44:59] [config] lr-warmup-at-reload: false
[2023-07-01 07:44:59] [config] lr-warmup-cycle: false
[2023-07-01 07:44:59] [config] lr-warmup-start-rate: 0
[2023-07-01 07:44:59] [config] max-length: 100
[2023-07-01 07:44:59] [config] max-length-crop: false
[2023-07-01 07:44:59] [config] max-length-factor: 3
[2023-07-01 07:44:59] [config] maxi-batch: 100
[2023-07-01 07:44:59] [config] maxi-batch-sort: trg
[2023-07-01 07:44:59] [config] mini-batch: 1000
[2023-07-01 07:44:59] [config] mini-batch-fit: true
[2023-07-01 07:44:59] [config] mini-batch-fit-step: 10
[2023-07-01 07:44:59] [config] mini-batch-round-up: true
[2023-07-01 07:44:59] [config] mini-batch-track-lr: false
[2023-07-01 07:44:59] [config] mini-batch-warmup: 0
[2023-07-01 07:44:59] [config] mini-batch-words: 0
[2023-07-01 07:44:59] [config] mini-batch-words-ref: 0
[2023-07-01 07:44:59] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 07:44:59] [config] multi-loss-type: sum
[2023-07-01 07:44:59] [config] n-best: false
[2023-07-01 07:44:59] [config] no-nccl: false
[2023-07-01 07:44:59] [config] no-reload: false
[2023-07-01 07:44:59] [config] no-restore-corpus: false
[2023-07-01 07:44:59] [config] normalize: 1
[2023-07-01 07:44:59] [config] normalize-gradient: false
[2023-07-01 07:44:59] [config] num-devices: 0
[2023-07-01 07:44:59] [config] optimizer: adam
[2023-07-01 07:44:59] [config] optimizer-delay: 1
[2023-07-01 07:44:59] [config] optimizer-params:
[2023-07-01 07:44:59] [config]   - 0.9
[2023-07-01 07:44:59] [config]   - 0.98
[2023-07-01 07:44:59] [config]   - 1e-09
[2023-07-01 07:44:59] [config] output-omit-bias: false
[2023-07-01 07:44:59] [config] overwrite: true
[2023-07-01 07:44:59] [config] precision:
[2023-07-01 07:44:59] [config]   - float32
[2023-07-01 07:44:59] [config]   - float32
[2023-07-01 07:44:59] [config] pretrained-model: ""
[2023-07-01 07:44:59] [config] quantize-biases: false
[2023-07-01 07:44:59] [config] quantize-bits: 0
[2023-07-01 07:44:59] [config] quantize-log-based: false
[2023-07-01 07:44:59] [config] quantize-optimization-steps: 0
[2023-07-01 07:44:59] [config] quiet: false
[2023-07-01 07:44:59] [config] quiet-translation: true
[2023-07-01 07:44:59] [config] relative-paths: false
[2023-07-01 07:44:59] [config] right-left: false
[2023-07-01 07:44:59] [config] save-freq: 10000u
[2023-07-01 07:44:59] [config] seed: 1234
[2023-07-01 07:44:59] [config] sentencepiece-alphas:
[2023-07-01 07:44:59] [config]   []
[2023-07-01 07:44:59] [config] sentencepiece-max-lines: 2000000
[2023-07-01 07:44:59] [config] sentencepiece-options: ""
[2023-07-01 07:44:59] [config] sharding: global
[2023-07-01 07:44:59] [config] shuffle: data
[2023-07-01 07:44:59] [config] shuffle-in-ram: false
[2023-07-01 07:44:59] [config] sigterm: save-and-exit
[2023-07-01 07:44:59] [config] skip: false
[2023-07-01 07:44:59] [config] sqlite: ""
[2023-07-01 07:44:59] [config] sqlite-drop: false
[2023-07-01 07:44:59] [config] sync-freq: 200u
[2023-07-01 07:44:59] [config] sync-sgd: true
[2023-07-01 07:44:59] [config] tempdir: /tmp
[2023-07-01 07:44:59] [config] tied-embeddings: false
[2023-07-01 07:44:59] [config] tied-embeddings-all: true
[2023-07-01 07:44:59] [config] tied-embeddings-src: false
[2023-07-01 07:44:59] [config] train-embedder-rank:
[2023-07-01 07:44:59] [config]   []
[2023-07-01 07:44:59] [config] train-sets:
[2023-07-01 07:44:59] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 07:44:59] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 07:44:59] [config] transformer-aan-activation: swish
[2023-07-01 07:44:59] [config] transformer-aan-depth: 2
[2023-07-01 07:44:59] [config] transformer-aan-nogate: false
[2023-07-01 07:44:59] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 07:44:59] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 07:44:59] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 07:44:59] [config] transformer-depth-scaling: false
[2023-07-01 07:44:59] [config] transformer-dim-aan: 2048
[2023-07-01 07:44:59] [config] transformer-dim-ffn: 2048
[2023-07-01 07:44:59] [config] transformer-dropout: 0.1
[2023-07-01 07:44:59] [config] transformer-dropout-attention: 0
[2023-07-01 07:44:59] [config] transformer-dropout-ffn: 0
[2023-07-01 07:44:59] [config] transformer-ffn-activation: swish
[2023-07-01 07:44:59] [config] transformer-ffn-depth: 2
[2023-07-01 07:44:59] [config] transformer-guided-alignment-layer: last
[2023-07-01 07:44:59] [config] transformer-heads: 8
[2023-07-01 07:44:59] [config] transformer-no-projection: false
[2023-07-01 07:44:59] [config] transformer-pool: false
[2023-07-01 07:44:59] [config] transformer-postprocess: dan
[2023-07-01 07:44:59] [config] transformer-postprocess-emb: d
[2023-07-01 07:44:59] [config] transformer-postprocess-top: ""
[2023-07-01 07:44:59] [config] transformer-preprocess: ""
[2023-07-01 07:44:59] [config] transformer-tied-layers:
[2023-07-01 07:44:59] [config]   []
[2023-07-01 07:44:59] [config] transformer-train-position-embeddings: false
[2023-07-01 07:44:59] [config] tsv: false
[2023-07-01 07:44:59] [config] tsv-fields: 0
[2023-07-01 07:44:59] [config] type: transformer
[2023-07-01 07:44:59] [config] ulr: false
[2023-07-01 07:44:59] [config] ulr-dim-emb: 0
[2023-07-01 07:44:59] [config] ulr-dropout: 0
[2023-07-01 07:44:59] [config] ulr-keys-vectors: ""
[2023-07-01 07:44:59] [config] ulr-query-vectors: ""
[2023-07-01 07:44:59] [config] ulr-softmax-temperature: 1
[2023-07-01 07:44:59] [config] ulr-trainable-transformation: false
[2023-07-01 07:44:59] [config] unlikelihood-loss: false
[2023-07-01 07:44:59] [config] valid-freq: 50000000
[2023-07-01 07:44:59] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 07:44:59] [config] valid-max-length: 1000
[2023-07-01 07:44:59] [config] valid-metrics:
[2023-07-01 07:44:59] [config]   - cross-entropy
[2023-07-01 07:44:59] [config]   - translation
[2023-07-01 07:44:59] [config] valid-mini-batch: 64
[2023-07-01 07:44:59] [config] valid-reset-stalled: false
[2023-07-01 07:44:59] [config] valid-script-args:
[2023-07-01 07:44:59] [config]   []
[2023-07-01 07:44:59] [config] valid-script-path: ""
[2023-07-01 07:44:59] [config] valid-sets:
[2023-07-01 07:44:59] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 07:44:59] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 07:44:59] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 07:44:59] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 07:44:59] [config] vocabs:
[2023-07-01 07:44:59] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 07:44:59] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 07:44:59] [config] word-penalty: 0
[2023-07-01 07:44:59] [config] word-scores: false
[2023-07-01 07:44:59] [config] workspace: 2048
[2023-07-01 07:44:59] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 07:44:59] Using synchronous SGD
[2023-07-01 07:44:59] Synced seed 1234
[2023-07-01 07:44:59] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 07:44:59] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 07:44:59] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 07:44:59] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 07:44:59] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 07:44:59] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 07:45:00] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 07:45:00] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 07:45:00] [comm] Using global sharding
[2023-07-01 07:45:00] [comm] NCCLCommunicators constructed successfully
[2023-07-01 07:45:00] [training] Using 1 GPUs
[2023-07-01 07:45:00] [logits] Applying loss function for 1 factor(s)
[2023-07-01 07:45:00] [memory] Reserving 88 MB, device gpu0
[2023-07-01 07:45:00] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 07:45:00] [memory] Reserving 88 MB, device gpu0
[2023-07-01 07:45:08] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 07:45:08] [valid] No post-processing script given for validating translator
[2023-07-01 07:45:08] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 07:45:08] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 07:45:08] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 07:45:08] [comm] Using global sharding
[2023-07-01 07:45:08] [comm] NCCLCommunicators constructed successfully
[2023-07-01 07:45:08] [training] Using 1 GPUs
[2023-07-01 07:45:08] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 07:45:09] Allocating memory for general optimizer shards
[2023-07-01 07:45:09] [memory] Reserving 88 MB, device gpu0
[2023-07-01 07:45:09] Loading Adam parameters
[2023-07-01 07:45:09] [memory] Reserving 176 MB, device gpu0
[2023-07-01 07:45:09] [memory] Reserving 88 MB, device gpu0
[2023-07-01 07:45:09] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 07:45:09] [data] Restoring the corpus state to epoch 2, batch 189
[2023-07-01 07:45:09] [data] Shuffling data
[2023-07-01 07:45:09] [data] Done reading 20,192 sentences
[2023-07-01 07:45:09] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 07:45:09] Training started
[2023-07-01 07:45:09] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-07-01 07:45:09] [memory] Reserving 88 MB, device gpu0
[2023-07-01 07:45:09] Parameter type float32, optimization type float32, casting types false
[2023-07-01 07:45:33] Seen 20,073 samples
[2023-07-01 07:45:33] Starting data epoch 3 in logical epoch 3
[2023-07-01 07:45:33] Training finished
[2023-07-01 07:45:36] [valid] Ep. 3 : Up. 378 : cross-entropy : 226.047 : new best
[2023-07-01 07:56:05] [valid] Ep. 3 : Up. 378 : translation : 0 : new best
[2023-07-01 07:56:05] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 07:56:06] Saving Adam parameters
[2023-07-01 07:56:06] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 07:56:13] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 07:56:13] [marian] Running on node20.datos.cluster.uy as process 39196 with command line:
[2023-07-01 07:56:13] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 3 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 07:56:13] [config] after: 0e
[2023-07-01 07:56:13] [config] after-batches: 0
[2023-07-01 07:56:13] [config] after-epochs: 3
[2023-07-01 07:56:13] [config] all-caps-every: 0
[2023-07-01 07:56:13] [config] allow-unk: false
[2023-07-01 07:56:13] [config] authors: false
[2023-07-01 07:56:13] [config] beam-size: 12
[2023-07-01 07:56:13] [config] bert-class-symbol: "[CLS]"
[2023-07-01 07:56:13] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 07:56:13] [config] bert-masking-fraction: 0.15
[2023-07-01 07:56:13] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 07:56:13] [config] bert-train-type-embeddings: true
[2023-07-01 07:56:13] [config] bert-type-vocab-size: 2
[2023-07-01 07:56:13] [config] build-info: ""
[2023-07-01 07:56:13] [config] check-gradient-nan: false
[2023-07-01 07:56:13] [config] check-nan: false
[2023-07-01 07:56:13] [config] cite: false
[2023-07-01 07:56:13] [config] clip-norm: 5
[2023-07-01 07:56:13] [config] cost-scaling:
[2023-07-01 07:56:13] [config]   []
[2023-07-01 07:56:13] [config] cost-type: ce-sum
[2023-07-01 07:56:13] [config] cpu-threads: 0
[2023-07-01 07:56:13] [config] data-threads: 8
[2023-07-01 07:56:13] [config] data-weighting: ""
[2023-07-01 07:56:13] [config] data-weighting-type: sentence
[2023-07-01 07:56:13] [config] dec-cell: gru
[2023-07-01 07:56:13] [config] dec-cell-base-depth: 2
[2023-07-01 07:56:13] [config] dec-cell-high-depth: 1
[2023-07-01 07:56:13] [config] dec-depth: 2
[2023-07-01 07:56:13] [config] devices:
[2023-07-01 07:56:13] [config]   - 0
[2023-07-01 07:56:13] [config] dim-emb: 512
[2023-07-01 07:56:13] [config] dim-rnn: 1024
[2023-07-01 07:56:13] [config] dim-vocabs:
[2023-07-01 07:56:13] [config]   - 16384
[2023-07-01 07:56:13] [config]   - 16384
[2023-07-01 07:56:13] [config] disp-first: 0
[2023-07-01 07:56:13] [config] disp-freq: 1000u
[2023-07-01 07:56:13] [config] disp-label-counts: true
[2023-07-01 07:56:13] [config] dropout-rnn: 0
[2023-07-01 07:56:13] [config] dropout-src: 0
[2023-07-01 07:56:13] [config] dropout-trg: 0
[2023-07-01 07:56:13] [config] dump-config: ""
[2023-07-01 07:56:13] [config] dynamic-gradient-scaling:
[2023-07-01 07:56:13] [config]   []
[2023-07-01 07:56:13] [config] early-stopping: 10
[2023-07-01 07:56:13] [config] early-stopping-on: first
[2023-07-01 07:56:13] [config] embedding-fix-src: false
[2023-07-01 07:56:13] [config] embedding-fix-trg: false
[2023-07-01 07:56:13] [config] embedding-normalization: false
[2023-07-01 07:56:13] [config] embedding-vectors:
[2023-07-01 07:56:13] [config]   []
[2023-07-01 07:56:13] [config] enc-cell: gru
[2023-07-01 07:56:13] [config] enc-cell-depth: 1
[2023-07-01 07:56:13] [config] enc-depth: 2
[2023-07-01 07:56:13] [config] enc-type: bidirectional
[2023-07-01 07:56:13] [config] english-title-case-every: 0
[2023-07-01 07:56:13] [config] exponential-smoothing: 0.0001
[2023-07-01 07:56:13] [config] factor-weight: 1
[2023-07-01 07:56:13] [config] factors-combine: sum
[2023-07-01 07:56:13] [config] factors-dim-emb: 0
[2023-07-01 07:56:13] [config] gradient-checkpointing: false
[2023-07-01 07:56:13] [config] gradient-norm-average-window: 100
[2023-07-01 07:56:13] [config] guided-alignment: none
[2023-07-01 07:56:13] [config] guided-alignment-cost: mse
[2023-07-01 07:56:13] [config] guided-alignment-weight: 0.1
[2023-07-01 07:56:13] [config] ignore-model-config: false
[2023-07-01 07:56:13] [config] input-types:
[2023-07-01 07:56:13] [config]   []
[2023-07-01 07:56:13] [config] interpolate-env-vars: false
[2023-07-01 07:56:13] [config] keep-best: false
[2023-07-01 07:56:13] [config] label-smoothing: 0.1
[2023-07-01 07:56:13] [config] layer-normalization: false
[2023-07-01 07:56:13] [config] learn-rate: 0.0003
[2023-07-01 07:56:13] [config] lemma-dependency: ""
[2023-07-01 07:56:13] [config] lemma-dim-emb: 0
[2023-07-01 07:56:13] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 07:56:13] [config] log-level: info
[2023-07-01 07:56:13] [config] log-time-zone: ""
[2023-07-01 07:56:13] [config] logical-epoch:
[2023-07-01 07:56:13] [config]   - 1e
[2023-07-01 07:56:13] [config]   - 0
[2023-07-01 07:56:13] [config] lr-decay: 0
[2023-07-01 07:56:13] [config] lr-decay-freq: 50000
[2023-07-01 07:56:13] [config] lr-decay-inv-sqrt:
[2023-07-01 07:56:13] [config]   - 16000
[2023-07-01 07:56:13] [config] lr-decay-repeat-warmup: false
[2023-07-01 07:56:13] [config] lr-decay-reset-optimizer: false
[2023-07-01 07:56:13] [config] lr-decay-start:
[2023-07-01 07:56:13] [config]   - 10
[2023-07-01 07:56:13] [config]   - 1
[2023-07-01 07:56:13] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 07:56:13] [config] lr-report: true
[2023-07-01 07:56:13] [config] lr-warmup: 16000
[2023-07-01 07:56:13] [config] lr-warmup-at-reload: false
[2023-07-01 07:56:13] [config] lr-warmup-cycle: false
[2023-07-01 07:56:13] [config] lr-warmup-start-rate: 0
[2023-07-01 07:56:13] [config] max-length: 100
[2023-07-01 07:56:13] [config] max-length-crop: false
[2023-07-01 07:56:13] [config] max-length-factor: 3
[2023-07-01 07:56:13] [config] maxi-batch: 100
[2023-07-01 07:56:13] [config] maxi-batch-sort: trg
[2023-07-01 07:56:13] [config] mini-batch: 1000
[2023-07-01 07:56:13] [config] mini-batch-fit: true
[2023-07-01 07:56:13] [config] mini-batch-fit-step: 10
[2023-07-01 07:56:13] [config] mini-batch-round-up: true
[2023-07-01 07:56:13] [config] mini-batch-track-lr: false
[2023-07-01 07:56:13] [config] mini-batch-warmup: 0
[2023-07-01 07:56:13] [config] mini-batch-words: 0
[2023-07-01 07:56:13] [config] mini-batch-words-ref: 0
[2023-07-01 07:56:13] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 07:56:13] [config] multi-loss-type: sum
[2023-07-01 07:56:13] [config] n-best: false
[2023-07-01 07:56:13] [config] no-nccl: false
[2023-07-01 07:56:13] [config] no-reload: false
[2023-07-01 07:56:13] [config] no-restore-corpus: false
[2023-07-01 07:56:13] [config] normalize: 1
[2023-07-01 07:56:13] [config] normalize-gradient: false
[2023-07-01 07:56:13] [config] num-devices: 0
[2023-07-01 07:56:13] [config] optimizer: adam
[2023-07-01 07:56:13] [config] optimizer-delay: 1
[2023-07-01 07:56:13] [config] optimizer-params:
[2023-07-01 07:56:13] [config]   - 0.9
[2023-07-01 07:56:13] [config]   - 0.98
[2023-07-01 07:56:13] [config]   - 1e-09
[2023-07-01 07:56:13] [config] output-omit-bias: false
[2023-07-01 07:56:13] [config] overwrite: true
[2023-07-01 07:56:13] [config] precision:
[2023-07-01 07:56:13] [config]   - float32
[2023-07-01 07:56:13] [config]   - float32
[2023-07-01 07:56:13] [config] pretrained-model: ""
[2023-07-01 07:56:13] [config] quantize-biases: false
[2023-07-01 07:56:13] [config] quantize-bits: 0
[2023-07-01 07:56:13] [config] quantize-log-based: false
[2023-07-01 07:56:13] [config] quantize-optimization-steps: 0
[2023-07-01 07:56:13] [config] quiet: false
[2023-07-01 07:56:13] [config] quiet-translation: true
[2023-07-01 07:56:13] [config] relative-paths: false
[2023-07-01 07:56:13] [config] right-left: false
[2023-07-01 07:56:13] [config] save-freq: 10000u
[2023-07-01 07:56:13] [config] seed: 1234
[2023-07-01 07:56:13] [config] sentencepiece-alphas:
[2023-07-01 07:56:13] [config]   []
[2023-07-01 07:56:13] [config] sentencepiece-max-lines: 2000000
[2023-07-01 07:56:13] [config] sentencepiece-options: ""
[2023-07-01 07:56:13] [config] sharding: global
[2023-07-01 07:56:13] [config] shuffle: data
[2023-07-01 07:56:13] [config] shuffle-in-ram: false
[2023-07-01 07:56:13] [config] sigterm: save-and-exit
[2023-07-01 07:56:13] [config] skip: false
[2023-07-01 07:56:13] [config] sqlite: ""
[2023-07-01 07:56:13] [config] sqlite-drop: false
[2023-07-01 07:56:13] [config] sync-freq: 200u
[2023-07-01 07:56:13] [config] sync-sgd: true
[2023-07-01 07:56:13] [config] tempdir: /tmp
[2023-07-01 07:56:13] [config] tied-embeddings: false
[2023-07-01 07:56:13] [config] tied-embeddings-all: true
[2023-07-01 07:56:13] [config] tied-embeddings-src: false
[2023-07-01 07:56:13] [config] train-embedder-rank:
[2023-07-01 07:56:13] [config]   []
[2023-07-01 07:56:13] [config] train-sets:
[2023-07-01 07:56:13] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 07:56:13] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 07:56:13] [config] transformer-aan-activation: swish
[2023-07-01 07:56:13] [config] transformer-aan-depth: 2
[2023-07-01 07:56:13] [config] transformer-aan-nogate: false
[2023-07-01 07:56:13] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 07:56:13] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 07:56:13] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 07:56:13] [config] transformer-depth-scaling: false
[2023-07-01 07:56:13] [config] transformer-dim-aan: 2048
[2023-07-01 07:56:13] [config] transformer-dim-ffn: 2048
[2023-07-01 07:56:13] [config] transformer-dropout: 0.1
[2023-07-01 07:56:13] [config] transformer-dropout-attention: 0
[2023-07-01 07:56:13] [config] transformer-dropout-ffn: 0
[2023-07-01 07:56:13] [config] transformer-ffn-activation: swish
[2023-07-01 07:56:13] [config] transformer-ffn-depth: 2
[2023-07-01 07:56:13] [config] transformer-guided-alignment-layer: last
[2023-07-01 07:56:13] [config] transformer-heads: 8
[2023-07-01 07:56:13] [config] transformer-no-projection: false
[2023-07-01 07:56:13] [config] transformer-pool: false
[2023-07-01 07:56:13] [config] transformer-postprocess: dan
[2023-07-01 07:56:13] [config] transformer-postprocess-emb: d
[2023-07-01 07:56:13] [config] transformer-postprocess-top: ""
[2023-07-01 07:56:13] [config] transformer-preprocess: ""
[2023-07-01 07:56:13] [config] transformer-tied-layers:
[2023-07-01 07:56:13] [config]   []
[2023-07-01 07:56:13] [config] transformer-train-position-embeddings: false
[2023-07-01 07:56:13] [config] tsv: false
[2023-07-01 07:56:13] [config] tsv-fields: 0
[2023-07-01 07:56:13] [config] type: transformer
[2023-07-01 07:56:13] [config] ulr: false
[2023-07-01 07:56:13] [config] ulr-dim-emb: 0
[2023-07-01 07:56:13] [config] ulr-dropout: 0
[2023-07-01 07:56:13] [config] ulr-keys-vectors: ""
[2023-07-01 07:56:13] [config] ulr-query-vectors: ""
[2023-07-01 07:56:13] [config] ulr-softmax-temperature: 1
[2023-07-01 07:56:13] [config] ulr-trainable-transformation: false
[2023-07-01 07:56:13] [config] unlikelihood-loss: false
[2023-07-01 07:56:13] [config] valid-freq: 50000000
[2023-07-01 07:56:13] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 07:56:13] [config] valid-max-length: 1000
[2023-07-01 07:56:13] [config] valid-metrics:
[2023-07-01 07:56:13] [config]   - cross-entropy
[2023-07-01 07:56:13] [config]   - translation
[2023-07-01 07:56:13] [config] valid-mini-batch: 64
[2023-07-01 07:56:13] [config] valid-reset-stalled: false
[2023-07-01 07:56:13] [config] valid-script-args:
[2023-07-01 07:56:13] [config]   []
[2023-07-01 07:56:13] [config] valid-script-path: ""
[2023-07-01 07:56:13] [config] valid-sets:
[2023-07-01 07:56:13] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 07:56:13] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 07:56:13] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 07:56:13] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 07:56:13] [config] vocabs:
[2023-07-01 07:56:13] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 07:56:13] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 07:56:13] [config] word-penalty: 0
[2023-07-01 07:56:13] [config] word-scores: false
[2023-07-01 07:56:13] [config] workspace: 2048
[2023-07-01 07:56:13] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 07:56:13] Using synchronous SGD
[2023-07-01 07:56:14] Synced seed 1234
[2023-07-01 07:56:14] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 07:56:14] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 07:56:14] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 07:56:14] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 07:56:14] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 07:56:14] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 07:56:14] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 07:56:14] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 07:56:14] [comm] Using global sharding
[2023-07-01 07:56:14] [comm] NCCLCommunicators constructed successfully
[2023-07-01 07:56:14] [training] Using 1 GPUs
[2023-07-01 07:56:14] [logits] Applying loss function for 1 factor(s)
[2023-07-01 07:56:14] [memory] Reserving 88 MB, device gpu0
[2023-07-01 07:56:15] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 07:56:15] [memory] Reserving 88 MB, device gpu0
[2023-07-01 07:56:22] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 07:56:22] [valid] No post-processing script given for validating translator
[2023-07-01 07:56:23] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 07:56:23] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 07:56:23] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 07:56:23] [comm] Using global sharding
[2023-07-01 07:56:23] [comm] NCCLCommunicators constructed successfully
[2023-07-01 07:56:23] [training] Using 1 GPUs
[2023-07-01 07:56:23] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 07:56:23] Allocating memory for general optimizer shards
[2023-07-01 07:56:23] [memory] Reserving 88 MB, device gpu0
[2023-07-01 07:56:23] Loading Adam parameters
[2023-07-01 07:56:23] [memory] Reserving 176 MB, device gpu0
[2023-07-01 07:56:24] [memory] Reserving 88 MB, device gpu0
[2023-07-01 07:56:24] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 07:56:24] [data] Restoring the corpus state to epoch 3, batch 378
[2023-07-01 07:56:24] [data] Shuffling data
[2023-07-01 07:56:24] [data] Done reading 20,192 sentences
[2023-07-01 07:56:24] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 07:56:24] Training started
[2023-07-01 07:56:24] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-07-01 07:56:24] [memory] Reserving 88 MB, device gpu0
[2023-07-01 07:56:24] Parameter type float32, optimization type float32, casting types false
[2023-07-01 07:56:47] Seen 20,073 samples
[2023-07-01 07:56:47] Starting data epoch 4 in logical epoch 4
[2023-07-01 07:56:47] Training finished
[2023-07-01 07:56:50] [valid] Ep. 4 : Up. 567 : cross-entropy : 212.062 : new best
[2023-07-01 08:08:44] [valid] Ep. 4 : Up. 567 : translation : 0 : new best
[2023-07-01 08:08:44] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 08:08:45] Saving Adam parameters
[2023-07-01 08:08:46] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 08:08:54] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 08:08:54] [marian] Running on node20.datos.cluster.uy as process 40244 with command line:
[2023-07-01 08:08:54] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 4 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 08:08:54] [config] after: 0e
[2023-07-01 08:08:54] [config] after-batches: 0
[2023-07-01 08:08:54] [config] after-epochs: 4
[2023-07-01 08:08:54] [config] all-caps-every: 0
[2023-07-01 08:08:54] [config] allow-unk: false
[2023-07-01 08:08:54] [config] authors: false
[2023-07-01 08:08:54] [config] beam-size: 12
[2023-07-01 08:08:54] [config] bert-class-symbol: "[CLS]"
[2023-07-01 08:08:54] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 08:08:54] [config] bert-masking-fraction: 0.15
[2023-07-01 08:08:54] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 08:08:54] [config] bert-train-type-embeddings: true
[2023-07-01 08:08:54] [config] bert-type-vocab-size: 2
[2023-07-01 08:08:54] [config] build-info: ""
[2023-07-01 08:08:54] [config] check-gradient-nan: false
[2023-07-01 08:08:54] [config] check-nan: false
[2023-07-01 08:08:54] [config] cite: false
[2023-07-01 08:08:54] [config] clip-norm: 5
[2023-07-01 08:08:54] [config] cost-scaling:
[2023-07-01 08:08:54] [config]   []
[2023-07-01 08:08:54] [config] cost-type: ce-sum
[2023-07-01 08:08:54] [config] cpu-threads: 0
[2023-07-01 08:08:54] [config] data-threads: 8
[2023-07-01 08:08:54] [config] data-weighting: ""
[2023-07-01 08:08:54] [config] data-weighting-type: sentence
[2023-07-01 08:08:54] [config] dec-cell: gru
[2023-07-01 08:08:54] [config] dec-cell-base-depth: 2
[2023-07-01 08:08:54] [config] dec-cell-high-depth: 1
[2023-07-01 08:08:54] [config] dec-depth: 2
[2023-07-01 08:08:54] [config] devices:
[2023-07-01 08:08:54] [config]   - 0
[2023-07-01 08:08:54] [config] dim-emb: 512
[2023-07-01 08:08:54] [config] dim-rnn: 1024
[2023-07-01 08:08:54] [config] dim-vocabs:
[2023-07-01 08:08:54] [config]   - 16384
[2023-07-01 08:08:54] [config]   - 16384
[2023-07-01 08:08:54] [config] disp-first: 0
[2023-07-01 08:08:54] [config] disp-freq: 1000u
[2023-07-01 08:08:54] [config] disp-label-counts: true
[2023-07-01 08:08:54] [config] dropout-rnn: 0
[2023-07-01 08:08:54] [config] dropout-src: 0
[2023-07-01 08:08:54] [config] dropout-trg: 0
[2023-07-01 08:08:54] [config] dump-config: ""
[2023-07-01 08:08:54] [config] dynamic-gradient-scaling:
[2023-07-01 08:08:54] [config]   []
[2023-07-01 08:08:54] [config] early-stopping: 10
[2023-07-01 08:08:54] [config] early-stopping-on: first
[2023-07-01 08:08:54] [config] embedding-fix-src: false
[2023-07-01 08:08:54] [config] embedding-fix-trg: false
[2023-07-01 08:08:54] [config] embedding-normalization: false
[2023-07-01 08:08:54] [config] embedding-vectors:
[2023-07-01 08:08:54] [config]   []
[2023-07-01 08:08:54] [config] enc-cell: gru
[2023-07-01 08:08:54] [config] enc-cell-depth: 1
[2023-07-01 08:08:54] [config] enc-depth: 2
[2023-07-01 08:08:54] [config] enc-type: bidirectional
[2023-07-01 08:08:54] [config] english-title-case-every: 0
[2023-07-01 08:08:54] [config] exponential-smoothing: 0.0001
[2023-07-01 08:08:54] [config] factor-weight: 1
[2023-07-01 08:08:54] [config] factors-combine: sum
[2023-07-01 08:08:54] [config] factors-dim-emb: 0
[2023-07-01 08:08:54] [config] gradient-checkpointing: false
[2023-07-01 08:08:54] [config] gradient-norm-average-window: 100
[2023-07-01 08:08:54] [config] guided-alignment: none
[2023-07-01 08:08:54] [config] guided-alignment-cost: mse
[2023-07-01 08:08:54] [config] guided-alignment-weight: 0.1
[2023-07-01 08:08:54] [config] ignore-model-config: false
[2023-07-01 08:08:54] [config] input-types:
[2023-07-01 08:08:54] [config]   []
[2023-07-01 08:08:54] [config] interpolate-env-vars: false
[2023-07-01 08:08:54] [config] keep-best: false
[2023-07-01 08:08:54] [config] label-smoothing: 0.1
[2023-07-01 08:08:54] [config] layer-normalization: false
[2023-07-01 08:08:54] [config] learn-rate: 0.0003
[2023-07-01 08:08:54] [config] lemma-dependency: ""
[2023-07-01 08:08:54] [config] lemma-dim-emb: 0
[2023-07-01 08:08:54] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 08:08:54] [config] log-level: info
[2023-07-01 08:08:54] [config] log-time-zone: ""
[2023-07-01 08:08:54] [config] logical-epoch:
[2023-07-01 08:08:54] [config]   - 1e
[2023-07-01 08:08:54] [config]   - 0
[2023-07-01 08:08:54] [config] lr-decay: 0
[2023-07-01 08:08:54] [config] lr-decay-freq: 50000
[2023-07-01 08:08:54] [config] lr-decay-inv-sqrt:
[2023-07-01 08:08:54] [config]   - 16000
[2023-07-01 08:08:54] [config] lr-decay-repeat-warmup: false
[2023-07-01 08:08:54] [config] lr-decay-reset-optimizer: false
[2023-07-01 08:08:54] [config] lr-decay-start:
[2023-07-01 08:08:54] [config]   - 10
[2023-07-01 08:08:54] [config]   - 1
[2023-07-01 08:08:54] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 08:08:54] [config] lr-report: true
[2023-07-01 08:08:54] [config] lr-warmup: 16000
[2023-07-01 08:08:54] [config] lr-warmup-at-reload: false
[2023-07-01 08:08:54] [config] lr-warmup-cycle: false
[2023-07-01 08:08:54] [config] lr-warmup-start-rate: 0
[2023-07-01 08:08:54] [config] max-length: 100
[2023-07-01 08:08:54] [config] max-length-crop: false
[2023-07-01 08:08:54] [config] max-length-factor: 3
[2023-07-01 08:08:54] [config] maxi-batch: 100
[2023-07-01 08:08:54] [config] maxi-batch-sort: trg
[2023-07-01 08:08:54] [config] mini-batch: 1000
[2023-07-01 08:08:54] [config] mini-batch-fit: true
[2023-07-01 08:08:54] [config] mini-batch-fit-step: 10
[2023-07-01 08:08:54] [config] mini-batch-round-up: true
[2023-07-01 08:08:54] [config] mini-batch-track-lr: false
[2023-07-01 08:08:54] [config] mini-batch-warmup: 0
[2023-07-01 08:08:54] [config] mini-batch-words: 0
[2023-07-01 08:08:54] [config] mini-batch-words-ref: 0
[2023-07-01 08:08:54] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 08:08:54] [config] multi-loss-type: sum
[2023-07-01 08:08:54] [config] n-best: false
[2023-07-01 08:08:54] [config] no-nccl: false
[2023-07-01 08:08:54] [config] no-reload: false
[2023-07-01 08:08:54] [config] no-restore-corpus: false
[2023-07-01 08:08:54] [config] normalize: 1
[2023-07-01 08:08:54] [config] normalize-gradient: false
[2023-07-01 08:08:54] [config] num-devices: 0
[2023-07-01 08:08:54] [config] optimizer: adam
[2023-07-01 08:08:54] [config] optimizer-delay: 1
[2023-07-01 08:08:54] [config] optimizer-params:
[2023-07-01 08:08:54] [config]   - 0.9
[2023-07-01 08:08:54] [config]   - 0.98
[2023-07-01 08:08:54] [config]   - 1e-09
[2023-07-01 08:08:54] [config] output-omit-bias: false
[2023-07-01 08:08:54] [config] overwrite: true
[2023-07-01 08:08:54] [config] precision:
[2023-07-01 08:08:54] [config]   - float32
[2023-07-01 08:08:54] [config]   - float32
[2023-07-01 08:08:54] [config] pretrained-model: ""
[2023-07-01 08:08:54] [config] quantize-biases: false
[2023-07-01 08:08:54] [config] quantize-bits: 0
[2023-07-01 08:08:54] [config] quantize-log-based: false
[2023-07-01 08:08:54] [config] quantize-optimization-steps: 0
[2023-07-01 08:08:54] [config] quiet: false
[2023-07-01 08:08:54] [config] quiet-translation: true
[2023-07-01 08:08:54] [config] relative-paths: false
[2023-07-01 08:08:54] [config] right-left: false
[2023-07-01 08:08:54] [config] save-freq: 10000u
[2023-07-01 08:08:54] [config] seed: 1234
[2023-07-01 08:08:54] [config] sentencepiece-alphas:
[2023-07-01 08:08:54] [config]   []
[2023-07-01 08:08:54] [config] sentencepiece-max-lines: 2000000
[2023-07-01 08:08:54] [config] sentencepiece-options: ""
[2023-07-01 08:08:54] [config] sharding: global
[2023-07-01 08:08:54] [config] shuffle: data
[2023-07-01 08:08:54] [config] shuffle-in-ram: false
[2023-07-01 08:08:54] [config] sigterm: save-and-exit
[2023-07-01 08:08:54] [config] skip: false
[2023-07-01 08:08:54] [config] sqlite: ""
[2023-07-01 08:08:54] [config] sqlite-drop: false
[2023-07-01 08:08:54] [config] sync-freq: 200u
[2023-07-01 08:08:54] [config] sync-sgd: true
[2023-07-01 08:08:54] [config] tempdir: /tmp
[2023-07-01 08:08:54] [config] tied-embeddings: false
[2023-07-01 08:08:54] [config] tied-embeddings-all: true
[2023-07-01 08:08:54] [config] tied-embeddings-src: false
[2023-07-01 08:08:54] [config] train-embedder-rank:
[2023-07-01 08:08:54] [config]   []
[2023-07-01 08:08:54] [config] train-sets:
[2023-07-01 08:08:54] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 08:08:54] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 08:08:54] [config] transformer-aan-activation: swish
[2023-07-01 08:08:54] [config] transformer-aan-depth: 2
[2023-07-01 08:08:54] [config] transformer-aan-nogate: false
[2023-07-01 08:08:54] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 08:08:54] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 08:08:54] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 08:08:54] [config] transformer-depth-scaling: false
[2023-07-01 08:08:54] [config] transformer-dim-aan: 2048
[2023-07-01 08:08:54] [config] transformer-dim-ffn: 2048
[2023-07-01 08:08:54] [config] transformer-dropout: 0.1
[2023-07-01 08:08:54] [config] transformer-dropout-attention: 0
[2023-07-01 08:08:54] [config] transformer-dropout-ffn: 0
[2023-07-01 08:08:54] [config] transformer-ffn-activation: swish
[2023-07-01 08:08:54] [config] transformer-ffn-depth: 2
[2023-07-01 08:08:54] [config] transformer-guided-alignment-layer: last
[2023-07-01 08:08:54] [config] transformer-heads: 8
[2023-07-01 08:08:54] [config] transformer-no-projection: false
[2023-07-01 08:08:54] [config] transformer-pool: false
[2023-07-01 08:08:54] [config] transformer-postprocess: dan
[2023-07-01 08:08:54] [config] transformer-postprocess-emb: d
[2023-07-01 08:08:54] [config] transformer-postprocess-top: ""
[2023-07-01 08:08:54] [config] transformer-preprocess: ""
[2023-07-01 08:08:54] [config] transformer-tied-layers:
[2023-07-01 08:08:54] [config]   []
[2023-07-01 08:08:54] [config] transformer-train-position-embeddings: false
[2023-07-01 08:08:54] [config] tsv: false
[2023-07-01 08:08:54] [config] tsv-fields: 0
[2023-07-01 08:08:54] [config] type: transformer
[2023-07-01 08:08:54] [config] ulr: false
[2023-07-01 08:08:54] [config] ulr-dim-emb: 0
[2023-07-01 08:08:54] [config] ulr-dropout: 0
[2023-07-01 08:08:54] [config] ulr-keys-vectors: ""
[2023-07-01 08:08:54] [config] ulr-query-vectors: ""
[2023-07-01 08:08:54] [config] ulr-softmax-temperature: 1
[2023-07-01 08:08:54] [config] ulr-trainable-transformation: false
[2023-07-01 08:08:54] [config] unlikelihood-loss: false
[2023-07-01 08:08:54] [config] valid-freq: 50000000
[2023-07-01 08:08:54] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 08:08:54] [config] valid-max-length: 1000
[2023-07-01 08:08:54] [config] valid-metrics:
[2023-07-01 08:08:54] [config]   - cross-entropy
[2023-07-01 08:08:54] [config]   - translation
[2023-07-01 08:08:54] [config] valid-mini-batch: 64
[2023-07-01 08:08:54] [config] valid-reset-stalled: false
[2023-07-01 08:08:54] [config] valid-script-args:
[2023-07-01 08:08:54] [config]   []
[2023-07-01 08:08:54] [config] valid-script-path: ""
[2023-07-01 08:08:54] [config] valid-sets:
[2023-07-01 08:08:54] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 08:08:54] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 08:08:54] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 08:08:54] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 08:08:54] [config] vocabs:
[2023-07-01 08:08:54] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 08:08:54] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 08:08:54] [config] word-penalty: 0
[2023-07-01 08:08:54] [config] word-scores: false
[2023-07-01 08:08:54] [config] workspace: 2048
[2023-07-01 08:08:54] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 08:08:54] Using synchronous SGD
[2023-07-01 08:08:54] Synced seed 1234
[2023-07-01 08:08:54] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 08:08:54] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 08:08:54] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 08:08:54] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 08:08:54] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 08:08:54] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 08:08:55] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 08:08:55] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 08:08:55] [comm] Using global sharding
[2023-07-01 08:08:55] [comm] NCCLCommunicators constructed successfully
[2023-07-01 08:08:55] [training] Using 1 GPUs
[2023-07-01 08:08:55] [logits] Applying loss function for 1 factor(s)
[2023-07-01 08:08:55] [memory] Reserving 88 MB, device gpu0
[2023-07-01 08:08:55] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 08:08:55] [memory] Reserving 88 MB, device gpu0
[2023-07-01 08:09:03] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 08:09:03] [valid] No post-processing script given for validating translator
[2023-07-01 08:09:03] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 08:09:03] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 08:09:03] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 08:09:03] [comm] Using global sharding
[2023-07-01 08:09:03] [comm] NCCLCommunicators constructed successfully
[2023-07-01 08:09:03] [training] Using 1 GPUs
[2023-07-01 08:09:03] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 08:09:04] Allocating memory for general optimizer shards
[2023-07-01 08:09:04] [memory] Reserving 88 MB, device gpu0
[2023-07-01 08:09:04] Loading Adam parameters
[2023-07-01 08:09:04] [memory] Reserving 176 MB, device gpu0
[2023-07-01 08:09:04] [memory] Reserving 88 MB, device gpu0
[2023-07-01 08:09:04] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 08:09:04] [data] Restoring the corpus state to epoch 4, batch 567
[2023-07-01 08:09:04] [data] Shuffling data
[2023-07-01 08:09:04] [data] Done reading 20,192 sentences
[2023-07-01 08:09:04] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 08:09:04] Training started
[2023-07-01 08:09:04] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-07-01 08:09:04] [memory] Reserving 88 MB, device gpu0
[2023-07-01 08:09:04] Parameter type float32, optimization type float32, casting types false
[2023-07-01 08:09:28] Seen 20,073 samples
[2023-07-01 08:09:28] Starting data epoch 5 in logical epoch 5
[2023-07-01 08:09:28] Training finished
[2023-07-01 08:09:31] [valid] Ep. 5 : Up. 756 : cross-entropy : 199.885 : new best
[2023-07-01 08:20:01] [valid] Ep. 5 : Up. 756 : translation : 0 : new best
[2023-07-01 08:20:01] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 08:20:02] Saving Adam parameters
[2023-07-01 08:20:03] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 08:20:11] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 08:20:11] [marian] Running on node20.datos.cluster.uy as process 40880 with command line:
[2023-07-01 08:20:11] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 5 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 08:20:11] [config] after: 0e
[2023-07-01 08:20:11] [config] after-batches: 0
[2023-07-01 08:20:11] [config] after-epochs: 5
[2023-07-01 08:20:11] [config] all-caps-every: 0
[2023-07-01 08:20:11] [config] allow-unk: false
[2023-07-01 08:20:11] [config] authors: false
[2023-07-01 08:20:11] [config] beam-size: 12
[2023-07-01 08:20:11] [config] bert-class-symbol: "[CLS]"
[2023-07-01 08:20:11] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 08:20:11] [config] bert-masking-fraction: 0.15
[2023-07-01 08:20:11] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 08:20:11] [config] bert-train-type-embeddings: true
[2023-07-01 08:20:11] [config] bert-type-vocab-size: 2
[2023-07-01 08:20:11] [config] build-info: ""
[2023-07-01 08:20:11] [config] check-gradient-nan: false
[2023-07-01 08:20:11] [config] check-nan: false
[2023-07-01 08:20:11] [config] cite: false
[2023-07-01 08:20:11] [config] clip-norm: 5
[2023-07-01 08:20:11] [config] cost-scaling:
[2023-07-01 08:20:11] [config]   []
[2023-07-01 08:20:11] [config] cost-type: ce-sum
[2023-07-01 08:20:11] [config] cpu-threads: 0
[2023-07-01 08:20:11] [config] data-threads: 8
[2023-07-01 08:20:11] [config] data-weighting: ""
[2023-07-01 08:20:11] [config] data-weighting-type: sentence
[2023-07-01 08:20:11] [config] dec-cell: gru
[2023-07-01 08:20:11] [config] dec-cell-base-depth: 2
[2023-07-01 08:20:11] [config] dec-cell-high-depth: 1
[2023-07-01 08:20:11] [config] dec-depth: 2
[2023-07-01 08:20:11] [config] devices:
[2023-07-01 08:20:11] [config]   - 0
[2023-07-01 08:20:11] [config] dim-emb: 512
[2023-07-01 08:20:11] [config] dim-rnn: 1024
[2023-07-01 08:20:11] [config] dim-vocabs:
[2023-07-01 08:20:11] [config]   - 16384
[2023-07-01 08:20:11] [config]   - 16384
[2023-07-01 08:20:11] [config] disp-first: 0
[2023-07-01 08:20:11] [config] disp-freq: 1000u
[2023-07-01 08:20:11] [config] disp-label-counts: true
[2023-07-01 08:20:11] [config] dropout-rnn: 0
[2023-07-01 08:20:11] [config] dropout-src: 0
[2023-07-01 08:20:11] [config] dropout-trg: 0
[2023-07-01 08:20:11] [config] dump-config: ""
[2023-07-01 08:20:11] [config] dynamic-gradient-scaling:
[2023-07-01 08:20:11] [config]   []
[2023-07-01 08:20:11] [config] early-stopping: 10
[2023-07-01 08:20:11] [config] early-stopping-on: first
[2023-07-01 08:20:11] [config] embedding-fix-src: false
[2023-07-01 08:20:11] [config] embedding-fix-trg: false
[2023-07-01 08:20:11] [config] embedding-normalization: false
[2023-07-01 08:20:11] [config] embedding-vectors:
[2023-07-01 08:20:11] [config]   []
[2023-07-01 08:20:11] [config] enc-cell: gru
[2023-07-01 08:20:11] [config] enc-cell-depth: 1
[2023-07-01 08:20:11] [config] enc-depth: 2
[2023-07-01 08:20:11] [config] enc-type: bidirectional
[2023-07-01 08:20:11] [config] english-title-case-every: 0
[2023-07-01 08:20:11] [config] exponential-smoothing: 0.0001
[2023-07-01 08:20:11] [config] factor-weight: 1
[2023-07-01 08:20:11] [config] factors-combine: sum
[2023-07-01 08:20:11] [config] factors-dim-emb: 0
[2023-07-01 08:20:11] [config] gradient-checkpointing: false
[2023-07-01 08:20:11] [config] gradient-norm-average-window: 100
[2023-07-01 08:20:11] [config] guided-alignment: none
[2023-07-01 08:20:11] [config] guided-alignment-cost: mse
[2023-07-01 08:20:11] [config] guided-alignment-weight: 0.1
[2023-07-01 08:20:11] [config] ignore-model-config: false
[2023-07-01 08:20:11] [config] input-types:
[2023-07-01 08:20:11] [config]   []
[2023-07-01 08:20:11] [config] interpolate-env-vars: false
[2023-07-01 08:20:11] [config] keep-best: false
[2023-07-01 08:20:11] [config] label-smoothing: 0.1
[2023-07-01 08:20:11] [config] layer-normalization: false
[2023-07-01 08:20:11] [config] learn-rate: 0.0003
[2023-07-01 08:20:11] [config] lemma-dependency: ""
[2023-07-01 08:20:11] [config] lemma-dim-emb: 0
[2023-07-01 08:20:11] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 08:20:11] [config] log-level: info
[2023-07-01 08:20:11] [config] log-time-zone: ""
[2023-07-01 08:20:11] [config] logical-epoch:
[2023-07-01 08:20:11] [config]   - 1e
[2023-07-01 08:20:11] [config]   - 0
[2023-07-01 08:20:11] [config] lr-decay: 0
[2023-07-01 08:20:11] [config] lr-decay-freq: 50000
[2023-07-01 08:20:11] [config] lr-decay-inv-sqrt:
[2023-07-01 08:20:11] [config]   - 16000
[2023-07-01 08:20:11] [config] lr-decay-repeat-warmup: false
[2023-07-01 08:20:11] [config] lr-decay-reset-optimizer: false
[2023-07-01 08:20:11] [config] lr-decay-start:
[2023-07-01 08:20:11] [config]   - 10
[2023-07-01 08:20:11] [config]   - 1
[2023-07-01 08:20:11] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 08:20:11] [config] lr-report: true
[2023-07-01 08:20:11] [config] lr-warmup: 16000
[2023-07-01 08:20:11] [config] lr-warmup-at-reload: false
[2023-07-01 08:20:11] [config] lr-warmup-cycle: false
[2023-07-01 08:20:11] [config] lr-warmup-start-rate: 0
[2023-07-01 08:20:11] [config] max-length: 100
[2023-07-01 08:20:11] [config] max-length-crop: false
[2023-07-01 08:20:11] [config] max-length-factor: 3
[2023-07-01 08:20:11] [config] maxi-batch: 100
[2023-07-01 08:20:11] [config] maxi-batch-sort: trg
[2023-07-01 08:20:11] [config] mini-batch: 1000
[2023-07-01 08:20:11] [config] mini-batch-fit: true
[2023-07-01 08:20:11] [config] mini-batch-fit-step: 10
[2023-07-01 08:20:11] [config] mini-batch-round-up: true
[2023-07-01 08:20:11] [config] mini-batch-track-lr: false
[2023-07-01 08:20:11] [config] mini-batch-warmup: 0
[2023-07-01 08:20:11] [config] mini-batch-words: 0
[2023-07-01 08:20:11] [config] mini-batch-words-ref: 0
[2023-07-01 08:20:11] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 08:20:11] [config] multi-loss-type: sum
[2023-07-01 08:20:11] [config] n-best: false
[2023-07-01 08:20:11] [config] no-nccl: false
[2023-07-01 08:20:11] [config] no-reload: false
[2023-07-01 08:20:11] [config] no-restore-corpus: false
[2023-07-01 08:20:11] [config] normalize: 1
[2023-07-01 08:20:11] [config] normalize-gradient: false
[2023-07-01 08:20:11] [config] num-devices: 0
[2023-07-01 08:20:11] [config] optimizer: adam
[2023-07-01 08:20:11] [config] optimizer-delay: 1
[2023-07-01 08:20:11] [config] optimizer-params:
[2023-07-01 08:20:11] [config]   - 0.9
[2023-07-01 08:20:11] [config]   - 0.98
[2023-07-01 08:20:11] [config]   - 1e-09
[2023-07-01 08:20:11] [config] output-omit-bias: false
[2023-07-01 08:20:11] [config] overwrite: true
[2023-07-01 08:20:11] [config] precision:
[2023-07-01 08:20:11] [config]   - float32
[2023-07-01 08:20:11] [config]   - float32
[2023-07-01 08:20:11] [config] pretrained-model: ""
[2023-07-01 08:20:11] [config] quantize-biases: false
[2023-07-01 08:20:11] [config] quantize-bits: 0
[2023-07-01 08:20:11] [config] quantize-log-based: false
[2023-07-01 08:20:11] [config] quantize-optimization-steps: 0
[2023-07-01 08:20:11] [config] quiet: false
[2023-07-01 08:20:11] [config] quiet-translation: true
[2023-07-01 08:20:11] [config] relative-paths: false
[2023-07-01 08:20:11] [config] right-left: false
[2023-07-01 08:20:11] [config] save-freq: 10000u
[2023-07-01 08:20:11] [config] seed: 1234
[2023-07-01 08:20:11] [config] sentencepiece-alphas:
[2023-07-01 08:20:11] [config]   []
[2023-07-01 08:20:11] [config] sentencepiece-max-lines: 2000000
[2023-07-01 08:20:11] [config] sentencepiece-options: ""
[2023-07-01 08:20:11] [config] sharding: global
[2023-07-01 08:20:11] [config] shuffle: data
[2023-07-01 08:20:11] [config] shuffle-in-ram: false
[2023-07-01 08:20:11] [config] sigterm: save-and-exit
[2023-07-01 08:20:11] [config] skip: false
[2023-07-01 08:20:11] [config] sqlite: ""
[2023-07-01 08:20:11] [config] sqlite-drop: false
[2023-07-01 08:20:11] [config] sync-freq: 200u
[2023-07-01 08:20:11] [config] sync-sgd: true
[2023-07-01 08:20:11] [config] tempdir: /tmp
[2023-07-01 08:20:11] [config] tied-embeddings: false
[2023-07-01 08:20:11] [config] tied-embeddings-all: true
[2023-07-01 08:20:11] [config] tied-embeddings-src: false
[2023-07-01 08:20:11] [config] train-embedder-rank:
[2023-07-01 08:20:11] [config]   []
[2023-07-01 08:20:11] [config] train-sets:
[2023-07-01 08:20:11] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 08:20:11] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 08:20:11] [config] transformer-aan-activation: swish
[2023-07-01 08:20:11] [config] transformer-aan-depth: 2
[2023-07-01 08:20:11] [config] transformer-aan-nogate: false
[2023-07-01 08:20:11] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 08:20:11] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 08:20:11] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 08:20:11] [config] transformer-depth-scaling: false
[2023-07-01 08:20:11] [config] transformer-dim-aan: 2048
[2023-07-01 08:20:11] [config] transformer-dim-ffn: 2048
[2023-07-01 08:20:11] [config] transformer-dropout: 0.1
[2023-07-01 08:20:11] [config] transformer-dropout-attention: 0
[2023-07-01 08:20:11] [config] transformer-dropout-ffn: 0
[2023-07-01 08:20:11] [config] transformer-ffn-activation: swish
[2023-07-01 08:20:11] [config] transformer-ffn-depth: 2
[2023-07-01 08:20:11] [config] transformer-guided-alignment-layer: last
[2023-07-01 08:20:11] [config] transformer-heads: 8
[2023-07-01 08:20:11] [config] transformer-no-projection: false
[2023-07-01 08:20:11] [config] transformer-pool: false
[2023-07-01 08:20:11] [config] transformer-postprocess: dan
[2023-07-01 08:20:11] [config] transformer-postprocess-emb: d
[2023-07-01 08:20:11] [config] transformer-postprocess-top: ""
[2023-07-01 08:20:11] [config] transformer-preprocess: ""
[2023-07-01 08:20:11] [config] transformer-tied-layers:
[2023-07-01 08:20:11] [config]   []
[2023-07-01 08:20:11] [config] transformer-train-position-embeddings: false
[2023-07-01 08:20:11] [config] tsv: false
[2023-07-01 08:20:11] [config] tsv-fields: 0
[2023-07-01 08:20:11] [config] type: transformer
[2023-07-01 08:20:11] [config] ulr: false
[2023-07-01 08:20:11] [config] ulr-dim-emb: 0
[2023-07-01 08:20:11] [config] ulr-dropout: 0
[2023-07-01 08:20:11] [config] ulr-keys-vectors: ""
[2023-07-01 08:20:11] [config] ulr-query-vectors: ""
[2023-07-01 08:20:11] [config] ulr-softmax-temperature: 1
[2023-07-01 08:20:11] [config] ulr-trainable-transformation: false
[2023-07-01 08:20:11] [config] unlikelihood-loss: false
[2023-07-01 08:20:11] [config] valid-freq: 50000000
[2023-07-01 08:20:11] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 08:20:11] [config] valid-max-length: 1000
[2023-07-01 08:20:11] [config] valid-metrics:
[2023-07-01 08:20:11] [config]   - cross-entropy
[2023-07-01 08:20:11] [config]   - translation
[2023-07-01 08:20:11] [config] valid-mini-batch: 64
[2023-07-01 08:20:11] [config] valid-reset-stalled: false
[2023-07-01 08:20:11] [config] valid-script-args:
[2023-07-01 08:20:11] [config]   []
[2023-07-01 08:20:11] [config] valid-script-path: ""
[2023-07-01 08:20:11] [config] valid-sets:
[2023-07-01 08:20:11] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 08:20:11] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 08:20:11] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 08:20:11] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 08:20:11] [config] vocabs:
[2023-07-01 08:20:11] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 08:20:11] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 08:20:11] [config] word-penalty: 0
[2023-07-01 08:20:11] [config] word-scores: false
[2023-07-01 08:20:11] [config] workspace: 2048
[2023-07-01 08:20:11] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 08:20:11] Using synchronous SGD
[2023-07-01 08:20:11] Synced seed 1234
[2023-07-01 08:20:11] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 08:20:11] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 08:20:11] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 08:20:11] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 08:20:11] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 08:20:11] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 08:20:12] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 08:20:12] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 08:20:12] [comm] Using global sharding
[2023-07-01 08:20:12] [comm] NCCLCommunicators constructed successfully
[2023-07-01 08:20:12] [training] Using 1 GPUs
[2023-07-01 08:20:12] [logits] Applying loss function for 1 factor(s)
[2023-07-01 08:20:12] [memory] Reserving 88 MB, device gpu0
[2023-07-01 08:20:12] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 08:20:12] [memory] Reserving 88 MB, device gpu0
[2023-07-01 08:20:20] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 08:20:20] [valid] No post-processing script given for validating translator
[2023-07-01 08:20:20] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 08:20:20] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 08:20:20] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 08:20:20] [comm] Using global sharding
[2023-07-01 08:20:20] [comm] NCCLCommunicators constructed successfully
[2023-07-01 08:20:20] [training] Using 1 GPUs
[2023-07-01 08:20:20] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 08:20:21] Allocating memory for general optimizer shards
[2023-07-01 08:20:21] [memory] Reserving 88 MB, device gpu0
[2023-07-01 08:20:21] Loading Adam parameters
[2023-07-01 08:20:21] [memory] Reserving 176 MB, device gpu0
[2023-07-01 08:20:21] [memory] Reserving 88 MB, device gpu0
[2023-07-01 08:20:21] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 08:20:21] [data] Restoring the corpus state to epoch 5, batch 756
[2023-07-01 08:20:21] [data] Shuffling data
[2023-07-01 08:20:21] [data] Done reading 20,192 sentences
[2023-07-01 08:20:21] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 08:20:21] Training started
[2023-07-01 08:20:22] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-07-01 08:20:22] [memory] Reserving 88 MB, device gpu0
[2023-07-01 08:20:22] Parameter type float32, optimization type float32, casting types false
[2023-07-01 08:20:45] Seen 20,073 samples
[2023-07-01 08:20:45] Starting data epoch 6 in logical epoch 6
[2023-07-01 08:20:45] Training finished
[2023-07-01 08:20:48] [valid] Ep. 6 : Up. 945 : cross-entropy : 192.575 : new best
[2023-07-01 08:31:16] [valid] Ep. 6 : Up. 945 : translation : 0 : new best
[2023-07-01 08:31:16] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 08:31:17] Saving Adam parameters
[2023-07-01 08:31:18] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 08:31:24] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 08:31:24] [marian] Running on node20.datos.cluster.uy as process 885 with command line:
[2023-07-01 08:31:24] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 6 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 08:31:24] [config] after: 0e
[2023-07-01 08:31:24] [config] after-batches: 0
[2023-07-01 08:31:24] [config] after-epochs: 6
[2023-07-01 08:31:24] [config] all-caps-every: 0
[2023-07-01 08:31:24] [config] allow-unk: false
[2023-07-01 08:31:24] [config] authors: false
[2023-07-01 08:31:24] [config] beam-size: 12
[2023-07-01 08:31:24] [config] bert-class-symbol: "[CLS]"
[2023-07-01 08:31:24] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 08:31:24] [config] bert-masking-fraction: 0.15
[2023-07-01 08:31:24] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 08:31:24] [config] bert-train-type-embeddings: true
[2023-07-01 08:31:24] [config] bert-type-vocab-size: 2
[2023-07-01 08:31:24] [config] build-info: ""
[2023-07-01 08:31:24] [config] check-gradient-nan: false
[2023-07-01 08:31:24] [config] check-nan: false
[2023-07-01 08:31:24] [config] cite: false
[2023-07-01 08:31:24] [config] clip-norm: 5
[2023-07-01 08:31:24] [config] cost-scaling:
[2023-07-01 08:31:24] [config]   []
[2023-07-01 08:31:24] [config] cost-type: ce-sum
[2023-07-01 08:31:24] [config] cpu-threads: 0
[2023-07-01 08:31:24] [config] data-threads: 8
[2023-07-01 08:31:24] [config] data-weighting: ""
[2023-07-01 08:31:24] [config] data-weighting-type: sentence
[2023-07-01 08:31:24] [config] dec-cell: gru
[2023-07-01 08:31:24] [config] dec-cell-base-depth: 2
[2023-07-01 08:31:24] [config] dec-cell-high-depth: 1
[2023-07-01 08:31:24] [config] dec-depth: 2
[2023-07-01 08:31:24] [config] devices:
[2023-07-01 08:31:24] [config]   - 0
[2023-07-01 08:31:24] [config] dim-emb: 512
[2023-07-01 08:31:24] [config] dim-rnn: 1024
[2023-07-01 08:31:24] [config] dim-vocabs:
[2023-07-01 08:31:24] [config]   - 16384
[2023-07-01 08:31:24] [config]   - 16384
[2023-07-01 08:31:24] [config] disp-first: 0
[2023-07-01 08:31:24] [config] disp-freq: 1000u
[2023-07-01 08:31:24] [config] disp-label-counts: true
[2023-07-01 08:31:24] [config] dropout-rnn: 0
[2023-07-01 08:31:24] [config] dropout-src: 0
[2023-07-01 08:31:24] [config] dropout-trg: 0
[2023-07-01 08:31:24] [config] dump-config: ""
[2023-07-01 08:31:24] [config] dynamic-gradient-scaling:
[2023-07-01 08:31:24] [config]   []
[2023-07-01 08:31:24] [config] early-stopping: 10
[2023-07-01 08:31:24] [config] early-stopping-on: first
[2023-07-01 08:31:24] [config] embedding-fix-src: false
[2023-07-01 08:31:24] [config] embedding-fix-trg: false
[2023-07-01 08:31:24] [config] embedding-normalization: false
[2023-07-01 08:31:24] [config] embedding-vectors:
[2023-07-01 08:31:24] [config]   []
[2023-07-01 08:31:24] [config] enc-cell: gru
[2023-07-01 08:31:24] [config] enc-cell-depth: 1
[2023-07-01 08:31:24] [config] enc-depth: 2
[2023-07-01 08:31:24] [config] enc-type: bidirectional
[2023-07-01 08:31:24] [config] english-title-case-every: 0
[2023-07-01 08:31:24] [config] exponential-smoothing: 0.0001
[2023-07-01 08:31:24] [config] factor-weight: 1
[2023-07-01 08:31:24] [config] factors-combine: sum
[2023-07-01 08:31:24] [config] factors-dim-emb: 0
[2023-07-01 08:31:24] [config] gradient-checkpointing: false
[2023-07-01 08:31:24] [config] gradient-norm-average-window: 100
[2023-07-01 08:31:24] [config] guided-alignment: none
[2023-07-01 08:31:24] [config] guided-alignment-cost: mse
[2023-07-01 08:31:24] [config] guided-alignment-weight: 0.1
[2023-07-01 08:31:24] [config] ignore-model-config: false
[2023-07-01 08:31:24] [config] input-types:
[2023-07-01 08:31:24] [config]   []
[2023-07-01 08:31:24] [config] interpolate-env-vars: false
[2023-07-01 08:31:24] [config] keep-best: false
[2023-07-01 08:31:24] [config] label-smoothing: 0.1
[2023-07-01 08:31:24] [config] layer-normalization: false
[2023-07-01 08:31:24] [config] learn-rate: 0.0003
[2023-07-01 08:31:24] [config] lemma-dependency: ""
[2023-07-01 08:31:24] [config] lemma-dim-emb: 0
[2023-07-01 08:31:24] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 08:31:24] [config] log-level: info
[2023-07-01 08:31:24] [config] log-time-zone: ""
[2023-07-01 08:31:24] [config] logical-epoch:
[2023-07-01 08:31:24] [config]   - 1e
[2023-07-01 08:31:24] [config]   - 0
[2023-07-01 08:31:24] [config] lr-decay: 0
[2023-07-01 08:31:24] [config] lr-decay-freq: 50000
[2023-07-01 08:31:24] [config] lr-decay-inv-sqrt:
[2023-07-01 08:31:24] [config]   - 16000
[2023-07-01 08:31:24] [config] lr-decay-repeat-warmup: false
[2023-07-01 08:31:24] [config] lr-decay-reset-optimizer: false
[2023-07-01 08:31:24] [config] lr-decay-start:
[2023-07-01 08:31:24] [config]   - 10
[2023-07-01 08:31:24] [config]   - 1
[2023-07-01 08:31:24] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 08:31:24] [config] lr-report: true
[2023-07-01 08:31:24] [config] lr-warmup: 16000
[2023-07-01 08:31:24] [config] lr-warmup-at-reload: false
[2023-07-01 08:31:24] [config] lr-warmup-cycle: false
[2023-07-01 08:31:24] [config] lr-warmup-start-rate: 0
[2023-07-01 08:31:24] [config] max-length: 100
[2023-07-01 08:31:24] [config] max-length-crop: false
[2023-07-01 08:31:24] [config] max-length-factor: 3
[2023-07-01 08:31:24] [config] maxi-batch: 100
[2023-07-01 08:31:24] [config] maxi-batch-sort: trg
[2023-07-01 08:31:24] [config] mini-batch: 1000
[2023-07-01 08:31:24] [config] mini-batch-fit: true
[2023-07-01 08:31:24] [config] mini-batch-fit-step: 10
[2023-07-01 08:31:24] [config] mini-batch-round-up: true
[2023-07-01 08:31:24] [config] mini-batch-track-lr: false
[2023-07-01 08:31:24] [config] mini-batch-warmup: 0
[2023-07-01 08:31:24] [config] mini-batch-words: 0
[2023-07-01 08:31:24] [config] mini-batch-words-ref: 0
[2023-07-01 08:31:24] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 08:31:24] [config] multi-loss-type: sum
[2023-07-01 08:31:24] [config] n-best: false
[2023-07-01 08:31:24] [config] no-nccl: false
[2023-07-01 08:31:24] [config] no-reload: false
[2023-07-01 08:31:24] [config] no-restore-corpus: false
[2023-07-01 08:31:24] [config] normalize: 1
[2023-07-01 08:31:24] [config] normalize-gradient: false
[2023-07-01 08:31:24] [config] num-devices: 0
[2023-07-01 08:31:24] [config] optimizer: adam
[2023-07-01 08:31:24] [config] optimizer-delay: 1
[2023-07-01 08:31:24] [config] optimizer-params:
[2023-07-01 08:31:24] [config]   - 0.9
[2023-07-01 08:31:24] [config]   - 0.98
[2023-07-01 08:31:24] [config]   - 1e-09
[2023-07-01 08:31:24] [config] output-omit-bias: false
[2023-07-01 08:31:24] [config] overwrite: true
[2023-07-01 08:31:24] [config] precision:
[2023-07-01 08:31:24] [config]   - float32
[2023-07-01 08:31:24] [config]   - float32
[2023-07-01 08:31:24] [config] pretrained-model: ""
[2023-07-01 08:31:24] [config] quantize-biases: false
[2023-07-01 08:31:24] [config] quantize-bits: 0
[2023-07-01 08:31:24] [config] quantize-log-based: false
[2023-07-01 08:31:24] [config] quantize-optimization-steps: 0
[2023-07-01 08:31:24] [config] quiet: false
[2023-07-01 08:31:24] [config] quiet-translation: true
[2023-07-01 08:31:24] [config] relative-paths: false
[2023-07-01 08:31:24] [config] right-left: false
[2023-07-01 08:31:24] [config] save-freq: 10000u
[2023-07-01 08:31:24] [config] seed: 1234
[2023-07-01 08:31:24] [config] sentencepiece-alphas:
[2023-07-01 08:31:24] [config]   []
[2023-07-01 08:31:24] [config] sentencepiece-max-lines: 2000000
[2023-07-01 08:31:24] [config] sentencepiece-options: ""
[2023-07-01 08:31:24] [config] sharding: global
[2023-07-01 08:31:24] [config] shuffle: data
[2023-07-01 08:31:24] [config] shuffle-in-ram: false
[2023-07-01 08:31:24] [config] sigterm: save-and-exit
[2023-07-01 08:31:24] [config] skip: false
[2023-07-01 08:31:24] [config] sqlite: ""
[2023-07-01 08:31:24] [config] sqlite-drop: false
[2023-07-01 08:31:24] [config] sync-freq: 200u
[2023-07-01 08:31:24] [config] sync-sgd: true
[2023-07-01 08:31:24] [config] tempdir: /tmp
[2023-07-01 08:31:24] [config] tied-embeddings: false
[2023-07-01 08:31:24] [config] tied-embeddings-all: true
[2023-07-01 08:31:24] [config] tied-embeddings-src: false
[2023-07-01 08:31:24] [config] train-embedder-rank:
[2023-07-01 08:31:24] [config]   []
[2023-07-01 08:31:24] [config] train-sets:
[2023-07-01 08:31:24] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 08:31:24] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 08:31:24] [config] transformer-aan-activation: swish
[2023-07-01 08:31:24] [config] transformer-aan-depth: 2
[2023-07-01 08:31:24] [config] transformer-aan-nogate: false
[2023-07-01 08:31:24] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 08:31:24] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 08:31:24] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 08:31:24] [config] transformer-depth-scaling: false
[2023-07-01 08:31:24] [config] transformer-dim-aan: 2048
[2023-07-01 08:31:24] [config] transformer-dim-ffn: 2048
[2023-07-01 08:31:24] [config] transformer-dropout: 0.1
[2023-07-01 08:31:24] [config] transformer-dropout-attention: 0
[2023-07-01 08:31:24] [config] transformer-dropout-ffn: 0
[2023-07-01 08:31:24] [config] transformer-ffn-activation: swish
[2023-07-01 08:31:24] [config] transformer-ffn-depth: 2
[2023-07-01 08:31:24] [config] transformer-guided-alignment-layer: last
[2023-07-01 08:31:24] [config] transformer-heads: 8
[2023-07-01 08:31:24] [config] transformer-no-projection: false
[2023-07-01 08:31:24] [config] transformer-pool: false
[2023-07-01 08:31:24] [config] transformer-postprocess: dan
[2023-07-01 08:31:24] [config] transformer-postprocess-emb: d
[2023-07-01 08:31:24] [config] transformer-postprocess-top: ""
[2023-07-01 08:31:24] [config] transformer-preprocess: ""
[2023-07-01 08:31:24] [config] transformer-tied-layers:
[2023-07-01 08:31:24] [config]   []
[2023-07-01 08:31:24] [config] transformer-train-position-embeddings: false
[2023-07-01 08:31:24] [config] tsv: false
[2023-07-01 08:31:24] [config] tsv-fields: 0
[2023-07-01 08:31:24] [config] type: transformer
[2023-07-01 08:31:24] [config] ulr: false
[2023-07-01 08:31:24] [config] ulr-dim-emb: 0
[2023-07-01 08:31:24] [config] ulr-dropout: 0
[2023-07-01 08:31:24] [config] ulr-keys-vectors: ""
[2023-07-01 08:31:24] [config] ulr-query-vectors: ""
[2023-07-01 08:31:24] [config] ulr-softmax-temperature: 1
[2023-07-01 08:31:24] [config] ulr-trainable-transformation: false
[2023-07-01 08:31:24] [config] unlikelihood-loss: false
[2023-07-01 08:31:24] [config] valid-freq: 50000000
[2023-07-01 08:31:24] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 08:31:24] [config] valid-max-length: 1000
[2023-07-01 08:31:24] [config] valid-metrics:
[2023-07-01 08:31:24] [config]   - cross-entropy
[2023-07-01 08:31:24] [config]   - translation
[2023-07-01 08:31:24] [config] valid-mini-batch: 64
[2023-07-01 08:31:24] [config] valid-reset-stalled: false
[2023-07-01 08:31:24] [config] valid-script-args:
[2023-07-01 08:31:24] [config]   []
[2023-07-01 08:31:24] [config] valid-script-path: ""
[2023-07-01 08:31:24] [config] valid-sets:
[2023-07-01 08:31:24] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 08:31:24] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 08:31:24] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 08:31:24] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 08:31:24] [config] vocabs:
[2023-07-01 08:31:24] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 08:31:24] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 08:31:24] [config] word-penalty: 0
[2023-07-01 08:31:24] [config] word-scores: false
[2023-07-01 08:31:24] [config] workspace: 2048
[2023-07-01 08:31:24] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 08:31:24] Using synchronous SGD
[2023-07-01 08:31:24] Synced seed 1234
[2023-07-01 08:31:24] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 08:31:24] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 08:31:24] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 08:31:24] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 08:31:24] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 08:31:24] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 08:31:25] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 08:31:25] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 08:31:25] [comm] Using global sharding
[2023-07-01 08:31:25] [comm] NCCLCommunicators constructed successfully
[2023-07-01 08:31:25] [training] Using 1 GPUs
[2023-07-01 08:31:25] [logits] Applying loss function for 1 factor(s)
[2023-07-01 08:31:25] [memory] Reserving 88 MB, device gpu0
[2023-07-01 08:31:25] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 08:31:25] [memory] Reserving 88 MB, device gpu0
[2023-07-01 08:31:33] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 08:31:33] [valid] No post-processing script given for validating translator
[2023-07-01 08:31:33] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 08:31:33] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 08:31:33] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 08:31:33] [comm] Using global sharding
[2023-07-01 08:31:33] [comm] NCCLCommunicators constructed successfully
[2023-07-01 08:31:33] [training] Using 1 GPUs
[2023-07-01 08:31:33] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 08:31:34] Allocating memory for general optimizer shards
[2023-07-01 08:31:34] [memory] Reserving 88 MB, device gpu0
[2023-07-01 08:31:34] Loading Adam parameters
[2023-07-01 08:31:34] [memory] Reserving 176 MB, device gpu0
[2023-07-01 08:31:34] [memory] Reserving 88 MB, device gpu0
[2023-07-01 08:31:34] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 08:31:34] [data] Restoring the corpus state to epoch 6, batch 945
[2023-07-01 08:31:34] [data] Shuffling data
[2023-07-01 08:31:34] [data] Done reading 20,192 sentences
[2023-07-01 08:31:34] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 08:31:34] Training started
[2023-07-01 08:31:34] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-07-01 08:31:34] [memory] Reserving 88 MB, device gpu0
[2023-07-01 08:31:34] Parameter type float32, optimization type float32, casting types false
[2023-07-01 08:31:41] Ep. 6 : Up. 1000 : Sen. 5,772 : Cost 7.89494801 * 3,214,941 @ 4,446 after 3,214,941 : Time 8.06s : 399082.79 words/s : gNorm 1.1046 : L.r. 1.8750e-05
[2023-07-01 08:31:58] Seen 20,073 samples
[2023-07-01 08:31:58] Starting data epoch 7 in logical epoch 7
[2023-07-01 08:31:58] Training finished
[2023-07-01 08:32:01] [valid] Ep. 7 : Up. 1134 : cross-entropy : 187.82 : new best
[2023-07-01 08:43:12] [valid] Ep. 7 : Up. 1134 : translation : 0 : new best
[2023-07-01 08:43:12] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 08:43:13] Saving Adam parameters
[2023-07-01 08:43:14] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 08:43:20] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 08:43:20] [marian] Running on node20.datos.cluster.uy as process 1989 with command line:
[2023-07-01 08:43:20] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 7 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 08:43:20] [config] after: 0e
[2023-07-01 08:43:20] [config] after-batches: 0
[2023-07-01 08:43:20] [config] after-epochs: 7
[2023-07-01 08:43:20] [config] all-caps-every: 0
[2023-07-01 08:43:20] [config] allow-unk: false
[2023-07-01 08:43:20] [config] authors: false
[2023-07-01 08:43:20] [config] beam-size: 12
[2023-07-01 08:43:20] [config] bert-class-symbol: "[CLS]"
[2023-07-01 08:43:20] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 08:43:20] [config] bert-masking-fraction: 0.15
[2023-07-01 08:43:20] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 08:43:20] [config] bert-train-type-embeddings: true
[2023-07-01 08:43:20] [config] bert-type-vocab-size: 2
[2023-07-01 08:43:20] [config] build-info: ""
[2023-07-01 08:43:20] [config] check-gradient-nan: false
[2023-07-01 08:43:20] [config] check-nan: false
[2023-07-01 08:43:20] [config] cite: false
[2023-07-01 08:43:20] [config] clip-norm: 5
[2023-07-01 08:43:20] [config] cost-scaling:
[2023-07-01 08:43:20] [config]   []
[2023-07-01 08:43:20] [config] cost-type: ce-sum
[2023-07-01 08:43:20] [config] cpu-threads: 0
[2023-07-01 08:43:20] [config] data-threads: 8
[2023-07-01 08:43:20] [config] data-weighting: ""
[2023-07-01 08:43:20] [config] data-weighting-type: sentence
[2023-07-01 08:43:20] [config] dec-cell: gru
[2023-07-01 08:43:20] [config] dec-cell-base-depth: 2
[2023-07-01 08:43:20] [config] dec-cell-high-depth: 1
[2023-07-01 08:43:20] [config] dec-depth: 2
[2023-07-01 08:43:20] [config] devices:
[2023-07-01 08:43:20] [config]   - 0
[2023-07-01 08:43:20] [config] dim-emb: 512
[2023-07-01 08:43:20] [config] dim-rnn: 1024
[2023-07-01 08:43:20] [config] dim-vocabs:
[2023-07-01 08:43:20] [config]   - 16384
[2023-07-01 08:43:20] [config]   - 16384
[2023-07-01 08:43:20] [config] disp-first: 0
[2023-07-01 08:43:20] [config] disp-freq: 1000u
[2023-07-01 08:43:20] [config] disp-label-counts: true
[2023-07-01 08:43:20] [config] dropout-rnn: 0
[2023-07-01 08:43:20] [config] dropout-src: 0
[2023-07-01 08:43:20] [config] dropout-trg: 0
[2023-07-01 08:43:20] [config] dump-config: ""
[2023-07-01 08:43:20] [config] dynamic-gradient-scaling:
[2023-07-01 08:43:20] [config]   []
[2023-07-01 08:43:20] [config] early-stopping: 10
[2023-07-01 08:43:20] [config] early-stopping-on: first
[2023-07-01 08:43:20] [config] embedding-fix-src: false
[2023-07-01 08:43:20] [config] embedding-fix-trg: false
[2023-07-01 08:43:20] [config] embedding-normalization: false
[2023-07-01 08:43:20] [config] embedding-vectors:
[2023-07-01 08:43:20] [config]   []
[2023-07-01 08:43:20] [config] enc-cell: gru
[2023-07-01 08:43:20] [config] enc-cell-depth: 1
[2023-07-01 08:43:20] [config] enc-depth: 2
[2023-07-01 08:43:20] [config] enc-type: bidirectional
[2023-07-01 08:43:20] [config] english-title-case-every: 0
[2023-07-01 08:43:20] [config] exponential-smoothing: 0.0001
[2023-07-01 08:43:20] [config] factor-weight: 1
[2023-07-01 08:43:20] [config] factors-combine: sum
[2023-07-01 08:43:20] [config] factors-dim-emb: 0
[2023-07-01 08:43:20] [config] gradient-checkpointing: false
[2023-07-01 08:43:20] [config] gradient-norm-average-window: 100
[2023-07-01 08:43:20] [config] guided-alignment: none
[2023-07-01 08:43:20] [config] guided-alignment-cost: mse
[2023-07-01 08:43:20] [config] guided-alignment-weight: 0.1
[2023-07-01 08:43:20] [config] ignore-model-config: false
[2023-07-01 08:43:20] [config] input-types:
[2023-07-01 08:43:20] [config]   []
[2023-07-01 08:43:20] [config] interpolate-env-vars: false
[2023-07-01 08:43:20] [config] keep-best: false
[2023-07-01 08:43:20] [config] label-smoothing: 0.1
[2023-07-01 08:43:20] [config] layer-normalization: false
[2023-07-01 08:43:20] [config] learn-rate: 0.0003
[2023-07-01 08:43:20] [config] lemma-dependency: ""
[2023-07-01 08:43:20] [config] lemma-dim-emb: 0
[2023-07-01 08:43:20] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 08:43:20] [config] log-level: info
[2023-07-01 08:43:20] [config] log-time-zone: ""
[2023-07-01 08:43:20] [config] logical-epoch:
[2023-07-01 08:43:20] [config]   - 1e
[2023-07-01 08:43:20] [config]   - 0
[2023-07-01 08:43:20] [config] lr-decay: 0
[2023-07-01 08:43:20] [config] lr-decay-freq: 50000
[2023-07-01 08:43:20] [config] lr-decay-inv-sqrt:
[2023-07-01 08:43:20] [config]   - 16000
[2023-07-01 08:43:20] [config] lr-decay-repeat-warmup: false
[2023-07-01 08:43:20] [config] lr-decay-reset-optimizer: false
[2023-07-01 08:43:20] [config] lr-decay-start:
[2023-07-01 08:43:20] [config]   - 10
[2023-07-01 08:43:20] [config]   - 1
[2023-07-01 08:43:20] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 08:43:20] [config] lr-report: true
[2023-07-01 08:43:20] [config] lr-warmup: 16000
[2023-07-01 08:43:20] [config] lr-warmup-at-reload: false
[2023-07-01 08:43:20] [config] lr-warmup-cycle: false
[2023-07-01 08:43:20] [config] lr-warmup-start-rate: 0
[2023-07-01 08:43:20] [config] max-length: 100
[2023-07-01 08:43:20] [config] max-length-crop: false
[2023-07-01 08:43:20] [config] max-length-factor: 3
[2023-07-01 08:43:20] [config] maxi-batch: 100
[2023-07-01 08:43:20] [config] maxi-batch-sort: trg
[2023-07-01 08:43:20] [config] mini-batch: 1000
[2023-07-01 08:43:20] [config] mini-batch-fit: true
[2023-07-01 08:43:20] [config] mini-batch-fit-step: 10
[2023-07-01 08:43:20] [config] mini-batch-round-up: true
[2023-07-01 08:43:20] [config] mini-batch-track-lr: false
[2023-07-01 08:43:20] [config] mini-batch-warmup: 0
[2023-07-01 08:43:20] [config] mini-batch-words: 0
[2023-07-01 08:43:20] [config] mini-batch-words-ref: 0
[2023-07-01 08:43:20] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 08:43:20] [config] multi-loss-type: sum
[2023-07-01 08:43:20] [config] n-best: false
[2023-07-01 08:43:20] [config] no-nccl: false
[2023-07-01 08:43:20] [config] no-reload: false
[2023-07-01 08:43:20] [config] no-restore-corpus: false
[2023-07-01 08:43:20] [config] normalize: 1
[2023-07-01 08:43:20] [config] normalize-gradient: false
[2023-07-01 08:43:20] [config] num-devices: 0
[2023-07-01 08:43:20] [config] optimizer: adam
[2023-07-01 08:43:20] [config] optimizer-delay: 1
[2023-07-01 08:43:20] [config] optimizer-params:
[2023-07-01 08:43:20] [config]   - 0.9
[2023-07-01 08:43:20] [config]   - 0.98
[2023-07-01 08:43:20] [config]   - 1e-09
[2023-07-01 08:43:20] [config] output-omit-bias: false
[2023-07-01 08:43:20] [config] overwrite: true
[2023-07-01 08:43:20] [config] precision:
[2023-07-01 08:43:20] [config]   - float32
[2023-07-01 08:43:20] [config]   - float32
[2023-07-01 08:43:20] [config] pretrained-model: ""
[2023-07-01 08:43:20] [config] quantize-biases: false
[2023-07-01 08:43:20] [config] quantize-bits: 0
[2023-07-01 08:43:20] [config] quantize-log-based: false
[2023-07-01 08:43:20] [config] quantize-optimization-steps: 0
[2023-07-01 08:43:20] [config] quiet: false
[2023-07-01 08:43:20] [config] quiet-translation: true
[2023-07-01 08:43:20] [config] relative-paths: false
[2023-07-01 08:43:20] [config] right-left: false
[2023-07-01 08:43:20] [config] save-freq: 10000u
[2023-07-01 08:43:20] [config] seed: 1234
[2023-07-01 08:43:20] [config] sentencepiece-alphas:
[2023-07-01 08:43:20] [config]   []
[2023-07-01 08:43:20] [config] sentencepiece-max-lines: 2000000
[2023-07-01 08:43:20] [config] sentencepiece-options: ""
[2023-07-01 08:43:20] [config] sharding: global
[2023-07-01 08:43:20] [config] shuffle: data
[2023-07-01 08:43:20] [config] shuffle-in-ram: false
[2023-07-01 08:43:20] [config] sigterm: save-and-exit
[2023-07-01 08:43:20] [config] skip: false
[2023-07-01 08:43:20] [config] sqlite: ""
[2023-07-01 08:43:20] [config] sqlite-drop: false
[2023-07-01 08:43:20] [config] sync-freq: 200u
[2023-07-01 08:43:20] [config] sync-sgd: true
[2023-07-01 08:43:20] [config] tempdir: /tmp
[2023-07-01 08:43:20] [config] tied-embeddings: false
[2023-07-01 08:43:20] [config] tied-embeddings-all: true
[2023-07-01 08:43:20] [config] tied-embeddings-src: false
[2023-07-01 08:43:20] [config] train-embedder-rank:
[2023-07-01 08:43:20] [config]   []
[2023-07-01 08:43:20] [config] train-sets:
[2023-07-01 08:43:20] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 08:43:20] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 08:43:20] [config] transformer-aan-activation: swish
[2023-07-01 08:43:20] [config] transformer-aan-depth: 2
[2023-07-01 08:43:20] [config] transformer-aan-nogate: false
[2023-07-01 08:43:20] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 08:43:20] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 08:43:20] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 08:43:20] [config] transformer-depth-scaling: false
[2023-07-01 08:43:20] [config] transformer-dim-aan: 2048
[2023-07-01 08:43:20] [config] transformer-dim-ffn: 2048
[2023-07-01 08:43:20] [config] transformer-dropout: 0.1
[2023-07-01 08:43:20] [config] transformer-dropout-attention: 0
[2023-07-01 08:43:20] [config] transformer-dropout-ffn: 0
[2023-07-01 08:43:20] [config] transformer-ffn-activation: swish
[2023-07-01 08:43:20] [config] transformer-ffn-depth: 2
[2023-07-01 08:43:20] [config] transformer-guided-alignment-layer: last
[2023-07-01 08:43:20] [config] transformer-heads: 8
[2023-07-01 08:43:20] [config] transformer-no-projection: false
[2023-07-01 08:43:20] [config] transformer-pool: false
[2023-07-01 08:43:20] [config] transformer-postprocess: dan
[2023-07-01 08:43:20] [config] transformer-postprocess-emb: d
[2023-07-01 08:43:20] [config] transformer-postprocess-top: ""
[2023-07-01 08:43:20] [config] transformer-preprocess: ""
[2023-07-01 08:43:20] [config] transformer-tied-layers:
[2023-07-01 08:43:20] [config]   []
[2023-07-01 08:43:20] [config] transformer-train-position-embeddings: false
[2023-07-01 08:43:20] [config] tsv: false
[2023-07-01 08:43:20] [config] tsv-fields: 0
[2023-07-01 08:43:20] [config] type: transformer
[2023-07-01 08:43:20] [config] ulr: false
[2023-07-01 08:43:20] [config] ulr-dim-emb: 0
[2023-07-01 08:43:20] [config] ulr-dropout: 0
[2023-07-01 08:43:20] [config] ulr-keys-vectors: ""
[2023-07-01 08:43:20] [config] ulr-query-vectors: ""
[2023-07-01 08:43:20] [config] ulr-softmax-temperature: 1
[2023-07-01 08:43:20] [config] ulr-trainable-transformation: false
[2023-07-01 08:43:20] [config] unlikelihood-loss: false
[2023-07-01 08:43:20] [config] valid-freq: 50000000
[2023-07-01 08:43:20] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 08:43:20] [config] valid-max-length: 1000
[2023-07-01 08:43:20] [config] valid-metrics:
[2023-07-01 08:43:20] [config]   - cross-entropy
[2023-07-01 08:43:20] [config]   - translation
[2023-07-01 08:43:20] [config] valid-mini-batch: 64
[2023-07-01 08:43:20] [config] valid-reset-stalled: false
[2023-07-01 08:43:20] [config] valid-script-args:
[2023-07-01 08:43:20] [config]   []
[2023-07-01 08:43:20] [config] valid-script-path: ""
[2023-07-01 08:43:20] [config] valid-sets:
[2023-07-01 08:43:20] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 08:43:20] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 08:43:20] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 08:43:20] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 08:43:20] [config] vocabs:
[2023-07-01 08:43:20] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 08:43:20] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 08:43:20] [config] word-penalty: 0
[2023-07-01 08:43:20] [config] word-scores: false
[2023-07-01 08:43:20] [config] workspace: 2048
[2023-07-01 08:43:20] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 08:43:20] Using synchronous SGD
[2023-07-01 08:43:20] Synced seed 1234
[2023-07-01 08:43:20] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 08:43:20] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 08:43:20] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 08:43:20] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 08:43:20] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 08:43:20] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 08:43:21] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 08:43:21] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 08:43:21] [comm] Using global sharding
[2023-07-01 08:43:21] [comm] NCCLCommunicators constructed successfully
[2023-07-01 08:43:21] [training] Using 1 GPUs
[2023-07-01 08:43:21] [logits] Applying loss function for 1 factor(s)
[2023-07-01 08:43:21] [memory] Reserving 88 MB, device gpu0
[2023-07-01 08:43:21] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 08:43:21] [memory] Reserving 88 MB, device gpu0
[2023-07-01 08:43:29] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 08:43:29] [valid] No post-processing script given for validating translator
[2023-07-01 08:43:29] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 08:43:29] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 08:43:29] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 08:43:29] [comm] Using global sharding
[2023-07-01 08:43:29] [comm] NCCLCommunicators constructed successfully
[2023-07-01 08:43:29] [training] Using 1 GPUs
[2023-07-01 08:43:29] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 08:43:30] Allocating memory for general optimizer shards
[2023-07-01 08:43:30] [memory] Reserving 88 MB, device gpu0
[2023-07-01 08:43:30] Loading Adam parameters
[2023-07-01 08:43:30] [memory] Reserving 176 MB, device gpu0
[2023-07-01 08:43:30] [memory] Reserving 88 MB, device gpu0
[2023-07-01 08:43:30] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 08:43:30] [data] Restoring the corpus state to epoch 7, batch 1134
[2023-07-01 08:43:30] [data] Shuffling data
[2023-07-01 08:43:30] [data] Done reading 20,192 sentences
[2023-07-01 08:43:30] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 08:43:30] Training started
[2023-07-01 08:43:30] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-07-01 08:43:30] [memory] Reserving 88 MB, device gpu0
[2023-07-01 08:43:30] Parameter type float32, optimization type float32, casting types false
[2023-07-01 08:43:56] Seen 20,073 samples
[2023-07-01 08:43:56] Starting data epoch 8 in logical epoch 8
[2023-07-01 08:43:56] Training finished
[2023-07-01 08:43:59] [valid] Ep. 8 : Up. 1323 : cross-entropy : 183.995 : new best
[2023-07-01 08:53:54] [valid] Ep. 8 : Up. 1323 : translation : 0 : new best
[2023-07-01 08:53:54] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 08:53:55] Saving Adam parameters
[2023-07-01 08:53:56] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 08:54:02] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 08:54:02] [marian] Running on node20.datos.cluster.uy as process 2607 with command line:
[2023-07-01 08:54:02] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 8 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 08:54:02] [config] after: 0e
[2023-07-01 08:54:02] [config] after-batches: 0
[2023-07-01 08:54:02] [config] after-epochs: 8
[2023-07-01 08:54:02] [config] all-caps-every: 0
[2023-07-01 08:54:02] [config] allow-unk: false
[2023-07-01 08:54:02] [config] authors: false
[2023-07-01 08:54:02] [config] beam-size: 12
[2023-07-01 08:54:02] [config] bert-class-symbol: "[CLS]"
[2023-07-01 08:54:02] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 08:54:02] [config] bert-masking-fraction: 0.15
[2023-07-01 08:54:02] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 08:54:02] [config] bert-train-type-embeddings: true
[2023-07-01 08:54:02] [config] bert-type-vocab-size: 2
[2023-07-01 08:54:02] [config] build-info: ""
[2023-07-01 08:54:02] [config] check-gradient-nan: false
[2023-07-01 08:54:02] [config] check-nan: false
[2023-07-01 08:54:02] [config] cite: false
[2023-07-01 08:54:02] [config] clip-norm: 5
[2023-07-01 08:54:02] [config] cost-scaling:
[2023-07-01 08:54:02] [config]   []
[2023-07-01 08:54:02] [config] cost-type: ce-sum
[2023-07-01 08:54:02] [config] cpu-threads: 0
[2023-07-01 08:54:02] [config] data-threads: 8
[2023-07-01 08:54:02] [config] data-weighting: ""
[2023-07-01 08:54:02] [config] data-weighting-type: sentence
[2023-07-01 08:54:02] [config] dec-cell: gru
[2023-07-01 08:54:02] [config] dec-cell-base-depth: 2
[2023-07-01 08:54:02] [config] dec-cell-high-depth: 1
[2023-07-01 08:54:02] [config] dec-depth: 2
[2023-07-01 08:54:02] [config] devices:
[2023-07-01 08:54:02] [config]   - 0
[2023-07-01 08:54:02] [config] dim-emb: 512
[2023-07-01 08:54:02] [config] dim-rnn: 1024
[2023-07-01 08:54:02] [config] dim-vocabs:
[2023-07-01 08:54:02] [config]   - 16384
[2023-07-01 08:54:02] [config]   - 16384
[2023-07-01 08:54:02] [config] disp-first: 0
[2023-07-01 08:54:02] [config] disp-freq: 1000u
[2023-07-01 08:54:02] [config] disp-label-counts: true
[2023-07-01 08:54:02] [config] dropout-rnn: 0
[2023-07-01 08:54:02] [config] dropout-src: 0
[2023-07-01 08:54:02] [config] dropout-trg: 0
[2023-07-01 08:54:02] [config] dump-config: ""
[2023-07-01 08:54:02] [config] dynamic-gradient-scaling:
[2023-07-01 08:54:02] [config]   []
[2023-07-01 08:54:02] [config] early-stopping: 10
[2023-07-01 08:54:02] [config] early-stopping-on: first
[2023-07-01 08:54:02] [config] embedding-fix-src: false
[2023-07-01 08:54:02] [config] embedding-fix-trg: false
[2023-07-01 08:54:02] [config] embedding-normalization: false
[2023-07-01 08:54:02] [config] embedding-vectors:
[2023-07-01 08:54:02] [config]   []
[2023-07-01 08:54:02] [config] enc-cell: gru
[2023-07-01 08:54:02] [config] enc-cell-depth: 1
[2023-07-01 08:54:02] [config] enc-depth: 2
[2023-07-01 08:54:02] [config] enc-type: bidirectional
[2023-07-01 08:54:02] [config] english-title-case-every: 0
[2023-07-01 08:54:02] [config] exponential-smoothing: 0.0001
[2023-07-01 08:54:02] [config] factor-weight: 1
[2023-07-01 08:54:02] [config] factors-combine: sum
[2023-07-01 08:54:02] [config] factors-dim-emb: 0
[2023-07-01 08:54:02] [config] gradient-checkpointing: false
[2023-07-01 08:54:02] [config] gradient-norm-average-window: 100
[2023-07-01 08:54:02] [config] guided-alignment: none
[2023-07-01 08:54:02] [config] guided-alignment-cost: mse
[2023-07-01 08:54:02] [config] guided-alignment-weight: 0.1
[2023-07-01 08:54:02] [config] ignore-model-config: false
[2023-07-01 08:54:02] [config] input-types:
[2023-07-01 08:54:02] [config]   []
[2023-07-01 08:54:02] [config] interpolate-env-vars: false
[2023-07-01 08:54:02] [config] keep-best: false
[2023-07-01 08:54:02] [config] label-smoothing: 0.1
[2023-07-01 08:54:02] [config] layer-normalization: false
[2023-07-01 08:54:02] [config] learn-rate: 0.0003
[2023-07-01 08:54:02] [config] lemma-dependency: ""
[2023-07-01 08:54:02] [config] lemma-dim-emb: 0
[2023-07-01 08:54:02] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 08:54:02] [config] log-level: info
[2023-07-01 08:54:02] [config] log-time-zone: ""
[2023-07-01 08:54:02] [config] logical-epoch:
[2023-07-01 08:54:02] [config]   - 1e
[2023-07-01 08:54:02] [config]   - 0
[2023-07-01 08:54:02] [config] lr-decay: 0
[2023-07-01 08:54:02] [config] lr-decay-freq: 50000
[2023-07-01 08:54:02] [config] lr-decay-inv-sqrt:
[2023-07-01 08:54:02] [config]   - 16000
[2023-07-01 08:54:02] [config] lr-decay-repeat-warmup: false
[2023-07-01 08:54:02] [config] lr-decay-reset-optimizer: false
[2023-07-01 08:54:02] [config] lr-decay-start:
[2023-07-01 08:54:02] [config]   - 10
[2023-07-01 08:54:02] [config]   - 1
[2023-07-01 08:54:02] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 08:54:02] [config] lr-report: true
[2023-07-01 08:54:02] [config] lr-warmup: 16000
[2023-07-01 08:54:02] [config] lr-warmup-at-reload: false
[2023-07-01 08:54:02] [config] lr-warmup-cycle: false
[2023-07-01 08:54:02] [config] lr-warmup-start-rate: 0
[2023-07-01 08:54:02] [config] max-length: 100
[2023-07-01 08:54:02] [config] max-length-crop: false
[2023-07-01 08:54:02] [config] max-length-factor: 3
[2023-07-01 08:54:02] [config] maxi-batch: 100
[2023-07-01 08:54:02] [config] maxi-batch-sort: trg
[2023-07-01 08:54:02] [config] mini-batch: 1000
[2023-07-01 08:54:02] [config] mini-batch-fit: true
[2023-07-01 08:54:02] [config] mini-batch-fit-step: 10
[2023-07-01 08:54:02] [config] mini-batch-round-up: true
[2023-07-01 08:54:02] [config] mini-batch-track-lr: false
[2023-07-01 08:54:02] [config] mini-batch-warmup: 0
[2023-07-01 08:54:02] [config] mini-batch-words: 0
[2023-07-01 08:54:02] [config] mini-batch-words-ref: 0
[2023-07-01 08:54:02] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 08:54:02] [config] multi-loss-type: sum
[2023-07-01 08:54:02] [config] n-best: false
[2023-07-01 08:54:02] [config] no-nccl: false
[2023-07-01 08:54:02] [config] no-reload: false
[2023-07-01 08:54:02] [config] no-restore-corpus: false
[2023-07-01 08:54:02] [config] normalize: 1
[2023-07-01 08:54:02] [config] normalize-gradient: false
[2023-07-01 08:54:02] [config] num-devices: 0
[2023-07-01 08:54:02] [config] optimizer: adam
[2023-07-01 08:54:02] [config] optimizer-delay: 1
[2023-07-01 08:54:02] [config] optimizer-params:
[2023-07-01 08:54:02] [config]   - 0.9
[2023-07-01 08:54:02] [config]   - 0.98
[2023-07-01 08:54:02] [config]   - 1e-09
[2023-07-01 08:54:02] [config] output-omit-bias: false
[2023-07-01 08:54:02] [config] overwrite: true
[2023-07-01 08:54:02] [config] precision:
[2023-07-01 08:54:02] [config]   - float32
[2023-07-01 08:54:02] [config]   - float32
[2023-07-01 08:54:02] [config] pretrained-model: ""
[2023-07-01 08:54:02] [config] quantize-biases: false
[2023-07-01 08:54:02] [config] quantize-bits: 0
[2023-07-01 08:54:02] [config] quantize-log-based: false
[2023-07-01 08:54:02] [config] quantize-optimization-steps: 0
[2023-07-01 08:54:02] [config] quiet: false
[2023-07-01 08:54:02] [config] quiet-translation: true
[2023-07-01 08:54:02] [config] relative-paths: false
[2023-07-01 08:54:02] [config] right-left: false
[2023-07-01 08:54:02] [config] save-freq: 10000u
[2023-07-01 08:54:02] [config] seed: 1234
[2023-07-01 08:54:02] [config] sentencepiece-alphas:
[2023-07-01 08:54:02] [config]   []
[2023-07-01 08:54:02] [config] sentencepiece-max-lines: 2000000
[2023-07-01 08:54:02] [config] sentencepiece-options: ""
[2023-07-01 08:54:02] [config] sharding: global
[2023-07-01 08:54:02] [config] shuffle: data
[2023-07-01 08:54:02] [config] shuffle-in-ram: false
[2023-07-01 08:54:02] [config] sigterm: save-and-exit
[2023-07-01 08:54:02] [config] skip: false
[2023-07-01 08:54:02] [config] sqlite: ""
[2023-07-01 08:54:02] [config] sqlite-drop: false
[2023-07-01 08:54:02] [config] sync-freq: 200u
[2023-07-01 08:54:02] [config] sync-sgd: true
[2023-07-01 08:54:02] [config] tempdir: /tmp
[2023-07-01 08:54:02] [config] tied-embeddings: false
[2023-07-01 08:54:02] [config] tied-embeddings-all: true
[2023-07-01 08:54:02] [config] tied-embeddings-src: false
[2023-07-01 08:54:02] [config] train-embedder-rank:
[2023-07-01 08:54:02] [config]   []
[2023-07-01 08:54:02] [config] train-sets:
[2023-07-01 08:54:02] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 08:54:02] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 08:54:02] [config] transformer-aan-activation: swish
[2023-07-01 08:54:02] [config] transformer-aan-depth: 2
[2023-07-01 08:54:02] [config] transformer-aan-nogate: false
[2023-07-01 08:54:02] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 08:54:02] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 08:54:02] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 08:54:02] [config] transformer-depth-scaling: false
[2023-07-01 08:54:02] [config] transformer-dim-aan: 2048
[2023-07-01 08:54:02] [config] transformer-dim-ffn: 2048
[2023-07-01 08:54:02] [config] transformer-dropout: 0.1
[2023-07-01 08:54:02] [config] transformer-dropout-attention: 0
[2023-07-01 08:54:02] [config] transformer-dropout-ffn: 0
[2023-07-01 08:54:02] [config] transformer-ffn-activation: swish
[2023-07-01 08:54:02] [config] transformer-ffn-depth: 2
[2023-07-01 08:54:02] [config] transformer-guided-alignment-layer: last
[2023-07-01 08:54:02] [config] transformer-heads: 8
[2023-07-01 08:54:02] [config] transformer-no-projection: false
[2023-07-01 08:54:02] [config] transformer-pool: false
[2023-07-01 08:54:02] [config] transformer-postprocess: dan
[2023-07-01 08:54:02] [config] transformer-postprocess-emb: d
[2023-07-01 08:54:02] [config] transformer-postprocess-top: ""
[2023-07-01 08:54:02] [config] transformer-preprocess: ""
[2023-07-01 08:54:02] [config] transformer-tied-layers:
[2023-07-01 08:54:02] [config]   []
[2023-07-01 08:54:02] [config] transformer-train-position-embeddings: false
[2023-07-01 08:54:02] [config] tsv: false
[2023-07-01 08:54:02] [config] tsv-fields: 0
[2023-07-01 08:54:02] [config] type: transformer
[2023-07-01 08:54:02] [config] ulr: false
[2023-07-01 08:54:02] [config] ulr-dim-emb: 0
[2023-07-01 08:54:02] [config] ulr-dropout: 0
[2023-07-01 08:54:02] [config] ulr-keys-vectors: ""
[2023-07-01 08:54:02] [config] ulr-query-vectors: ""
[2023-07-01 08:54:02] [config] ulr-softmax-temperature: 1
[2023-07-01 08:54:02] [config] ulr-trainable-transformation: false
[2023-07-01 08:54:02] [config] unlikelihood-loss: false
[2023-07-01 08:54:02] [config] valid-freq: 50000000
[2023-07-01 08:54:02] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 08:54:02] [config] valid-max-length: 1000
[2023-07-01 08:54:02] [config] valid-metrics:
[2023-07-01 08:54:02] [config]   - cross-entropy
[2023-07-01 08:54:02] [config]   - translation
[2023-07-01 08:54:02] [config] valid-mini-batch: 64
[2023-07-01 08:54:02] [config] valid-reset-stalled: false
[2023-07-01 08:54:02] [config] valid-script-args:
[2023-07-01 08:54:02] [config]   []
[2023-07-01 08:54:02] [config] valid-script-path: ""
[2023-07-01 08:54:02] [config] valid-sets:
[2023-07-01 08:54:02] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 08:54:02] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 08:54:02] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 08:54:02] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 08:54:02] [config] vocabs:
[2023-07-01 08:54:02] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 08:54:02] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 08:54:02] [config] word-penalty: 0
[2023-07-01 08:54:02] [config] word-scores: false
[2023-07-01 08:54:02] [config] workspace: 2048
[2023-07-01 08:54:02] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 08:54:02] Using synchronous SGD
[2023-07-01 08:54:02] Synced seed 1234
[2023-07-01 08:54:02] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 08:54:02] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 08:54:02] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 08:54:02] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 08:54:02] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 08:54:02] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 08:54:03] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 08:54:03] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 08:54:03] [comm] Using global sharding
[2023-07-01 08:54:03] [comm] NCCLCommunicators constructed successfully
[2023-07-01 08:54:03] [training] Using 1 GPUs
[2023-07-01 08:54:03] [logits] Applying loss function for 1 factor(s)
[2023-07-01 08:54:03] [memory] Reserving 88 MB, device gpu0
[2023-07-01 08:54:03] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 08:54:03] [memory] Reserving 88 MB, device gpu0
[2023-07-01 08:54:11] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 08:54:11] [valid] No post-processing script given for validating translator
[2023-07-01 08:54:11] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 08:54:11] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 08:54:11] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 08:54:11] [comm] Using global sharding
[2023-07-01 08:54:11] [comm] NCCLCommunicators constructed successfully
[2023-07-01 08:54:11] [training] Using 1 GPUs
[2023-07-01 08:54:11] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 08:54:12] Allocating memory for general optimizer shards
[2023-07-01 08:54:12] [memory] Reserving 88 MB, device gpu0
[2023-07-01 08:54:12] Loading Adam parameters
[2023-07-01 08:54:12] [memory] Reserving 176 MB, device gpu0
[2023-07-01 08:54:12] [memory] Reserving 88 MB, device gpu0
[2023-07-01 08:54:12] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 08:54:12] [data] Restoring the corpus state to epoch 8, batch 1323
[2023-07-01 08:54:12] [data] Shuffling data
[2023-07-01 08:54:12] [data] Done reading 20,192 sentences
[2023-07-01 08:54:12] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 08:54:12] Training started
[2023-07-01 08:54:12] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-07-01 08:54:13] [memory] Reserving 88 MB, device gpu0
[2023-07-01 08:54:13] Parameter type float32, optimization type float32, casting types false
[2023-07-01 08:54:36] Seen 20,073 samples
[2023-07-01 08:54:36] Starting data epoch 9 in logical epoch 9
[2023-07-01 08:54:36] Training finished
[2023-07-01 08:54:40] [valid] Ep. 9 : Up. 1512 : cross-entropy : 180.391 : new best
[2023-07-01 09:03:29] [valid] Ep. 9 : Up. 1512 : translation : 0 : new best
[2023-07-01 09:03:29] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 09:03:30] Saving Adam parameters
[2023-07-01 09:03:31] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 09:03:38] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 09:03:38] [marian] Running on node20.datos.cluster.uy as process 3186 with command line:
[2023-07-01 09:03:38] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 9 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 09:03:38] [config] after: 0e
[2023-07-01 09:03:38] [config] after-batches: 0
[2023-07-01 09:03:38] [config] after-epochs: 9
[2023-07-01 09:03:38] [config] all-caps-every: 0
[2023-07-01 09:03:38] [config] allow-unk: false
[2023-07-01 09:03:38] [config] authors: false
[2023-07-01 09:03:38] [config] beam-size: 12
[2023-07-01 09:03:38] [config] bert-class-symbol: "[CLS]"
[2023-07-01 09:03:38] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 09:03:38] [config] bert-masking-fraction: 0.15
[2023-07-01 09:03:38] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 09:03:38] [config] bert-train-type-embeddings: true
[2023-07-01 09:03:38] [config] bert-type-vocab-size: 2
[2023-07-01 09:03:38] [config] build-info: ""
[2023-07-01 09:03:38] [config] check-gradient-nan: false
[2023-07-01 09:03:38] [config] check-nan: false
[2023-07-01 09:03:38] [config] cite: false
[2023-07-01 09:03:38] [config] clip-norm: 5
[2023-07-01 09:03:38] [config] cost-scaling:
[2023-07-01 09:03:38] [config]   []
[2023-07-01 09:03:38] [config] cost-type: ce-sum
[2023-07-01 09:03:38] [config] cpu-threads: 0
[2023-07-01 09:03:38] [config] data-threads: 8
[2023-07-01 09:03:38] [config] data-weighting: ""
[2023-07-01 09:03:38] [config] data-weighting-type: sentence
[2023-07-01 09:03:38] [config] dec-cell: gru
[2023-07-01 09:03:38] [config] dec-cell-base-depth: 2
[2023-07-01 09:03:38] [config] dec-cell-high-depth: 1
[2023-07-01 09:03:38] [config] dec-depth: 2
[2023-07-01 09:03:38] [config] devices:
[2023-07-01 09:03:38] [config]   - 0
[2023-07-01 09:03:38] [config] dim-emb: 512
[2023-07-01 09:03:38] [config] dim-rnn: 1024
[2023-07-01 09:03:38] [config] dim-vocabs:
[2023-07-01 09:03:38] [config]   - 16384
[2023-07-01 09:03:38] [config]   - 16384
[2023-07-01 09:03:38] [config] disp-first: 0
[2023-07-01 09:03:38] [config] disp-freq: 1000u
[2023-07-01 09:03:38] [config] disp-label-counts: true
[2023-07-01 09:03:38] [config] dropout-rnn: 0
[2023-07-01 09:03:38] [config] dropout-src: 0
[2023-07-01 09:03:38] [config] dropout-trg: 0
[2023-07-01 09:03:38] [config] dump-config: ""
[2023-07-01 09:03:38] [config] dynamic-gradient-scaling:
[2023-07-01 09:03:38] [config]   []
[2023-07-01 09:03:38] [config] early-stopping: 10
[2023-07-01 09:03:38] [config] early-stopping-on: first
[2023-07-01 09:03:38] [config] embedding-fix-src: false
[2023-07-01 09:03:38] [config] embedding-fix-trg: false
[2023-07-01 09:03:38] [config] embedding-normalization: false
[2023-07-01 09:03:38] [config] embedding-vectors:
[2023-07-01 09:03:38] [config]   []
[2023-07-01 09:03:38] [config] enc-cell: gru
[2023-07-01 09:03:38] [config] enc-cell-depth: 1
[2023-07-01 09:03:38] [config] enc-depth: 2
[2023-07-01 09:03:38] [config] enc-type: bidirectional
[2023-07-01 09:03:38] [config] english-title-case-every: 0
[2023-07-01 09:03:38] [config] exponential-smoothing: 0.0001
[2023-07-01 09:03:38] [config] factor-weight: 1
[2023-07-01 09:03:38] [config] factors-combine: sum
[2023-07-01 09:03:38] [config] factors-dim-emb: 0
[2023-07-01 09:03:38] [config] gradient-checkpointing: false
[2023-07-01 09:03:38] [config] gradient-norm-average-window: 100
[2023-07-01 09:03:38] [config] guided-alignment: none
[2023-07-01 09:03:38] [config] guided-alignment-cost: mse
[2023-07-01 09:03:38] [config] guided-alignment-weight: 0.1
[2023-07-01 09:03:38] [config] ignore-model-config: false
[2023-07-01 09:03:38] [config] input-types:
[2023-07-01 09:03:38] [config]   []
[2023-07-01 09:03:38] [config] interpolate-env-vars: false
[2023-07-01 09:03:38] [config] keep-best: false
[2023-07-01 09:03:38] [config] label-smoothing: 0.1
[2023-07-01 09:03:38] [config] layer-normalization: false
[2023-07-01 09:03:38] [config] learn-rate: 0.0003
[2023-07-01 09:03:38] [config] lemma-dependency: ""
[2023-07-01 09:03:38] [config] lemma-dim-emb: 0
[2023-07-01 09:03:38] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 09:03:38] [config] log-level: info
[2023-07-01 09:03:38] [config] log-time-zone: ""
[2023-07-01 09:03:38] [config] logical-epoch:
[2023-07-01 09:03:38] [config]   - 1e
[2023-07-01 09:03:38] [config]   - 0
[2023-07-01 09:03:38] [config] lr-decay: 0
[2023-07-01 09:03:38] [config] lr-decay-freq: 50000
[2023-07-01 09:03:38] [config] lr-decay-inv-sqrt:
[2023-07-01 09:03:38] [config]   - 16000
[2023-07-01 09:03:38] [config] lr-decay-repeat-warmup: false
[2023-07-01 09:03:38] [config] lr-decay-reset-optimizer: false
[2023-07-01 09:03:38] [config] lr-decay-start:
[2023-07-01 09:03:38] [config]   - 10
[2023-07-01 09:03:38] [config]   - 1
[2023-07-01 09:03:38] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 09:03:38] [config] lr-report: true
[2023-07-01 09:03:38] [config] lr-warmup: 16000
[2023-07-01 09:03:38] [config] lr-warmup-at-reload: false
[2023-07-01 09:03:38] [config] lr-warmup-cycle: false
[2023-07-01 09:03:38] [config] lr-warmup-start-rate: 0
[2023-07-01 09:03:38] [config] max-length: 100
[2023-07-01 09:03:38] [config] max-length-crop: false
[2023-07-01 09:03:38] [config] max-length-factor: 3
[2023-07-01 09:03:38] [config] maxi-batch: 100
[2023-07-01 09:03:38] [config] maxi-batch-sort: trg
[2023-07-01 09:03:38] [config] mini-batch: 1000
[2023-07-01 09:03:38] [config] mini-batch-fit: true
[2023-07-01 09:03:38] [config] mini-batch-fit-step: 10
[2023-07-01 09:03:38] [config] mini-batch-round-up: true
[2023-07-01 09:03:38] [config] mini-batch-track-lr: false
[2023-07-01 09:03:38] [config] mini-batch-warmup: 0
[2023-07-01 09:03:38] [config] mini-batch-words: 0
[2023-07-01 09:03:38] [config] mini-batch-words-ref: 0
[2023-07-01 09:03:38] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 09:03:38] [config] multi-loss-type: sum
[2023-07-01 09:03:38] [config] n-best: false
[2023-07-01 09:03:38] [config] no-nccl: false
[2023-07-01 09:03:38] [config] no-reload: false
[2023-07-01 09:03:38] [config] no-restore-corpus: false
[2023-07-01 09:03:38] [config] normalize: 1
[2023-07-01 09:03:38] [config] normalize-gradient: false
[2023-07-01 09:03:38] [config] num-devices: 0
[2023-07-01 09:03:38] [config] optimizer: adam
[2023-07-01 09:03:38] [config] optimizer-delay: 1
[2023-07-01 09:03:38] [config] optimizer-params:
[2023-07-01 09:03:38] [config]   - 0.9
[2023-07-01 09:03:38] [config]   - 0.98
[2023-07-01 09:03:38] [config]   - 1e-09
[2023-07-01 09:03:38] [config] output-omit-bias: false
[2023-07-01 09:03:38] [config] overwrite: true
[2023-07-01 09:03:38] [config] precision:
[2023-07-01 09:03:38] [config]   - float32
[2023-07-01 09:03:38] [config]   - float32
[2023-07-01 09:03:38] [config] pretrained-model: ""
[2023-07-01 09:03:38] [config] quantize-biases: false
[2023-07-01 09:03:38] [config] quantize-bits: 0
[2023-07-01 09:03:38] [config] quantize-log-based: false
[2023-07-01 09:03:38] [config] quantize-optimization-steps: 0
[2023-07-01 09:03:38] [config] quiet: false
[2023-07-01 09:03:38] [config] quiet-translation: true
[2023-07-01 09:03:38] [config] relative-paths: false
[2023-07-01 09:03:38] [config] right-left: false
[2023-07-01 09:03:38] [config] save-freq: 10000u
[2023-07-01 09:03:38] [config] seed: 1234
[2023-07-01 09:03:38] [config] sentencepiece-alphas:
[2023-07-01 09:03:38] [config]   []
[2023-07-01 09:03:38] [config] sentencepiece-max-lines: 2000000
[2023-07-01 09:03:38] [config] sentencepiece-options: ""
[2023-07-01 09:03:38] [config] sharding: global
[2023-07-01 09:03:38] [config] shuffle: data
[2023-07-01 09:03:38] [config] shuffle-in-ram: false
[2023-07-01 09:03:38] [config] sigterm: save-and-exit
[2023-07-01 09:03:38] [config] skip: false
[2023-07-01 09:03:38] [config] sqlite: ""
[2023-07-01 09:03:38] [config] sqlite-drop: false
[2023-07-01 09:03:38] [config] sync-freq: 200u
[2023-07-01 09:03:38] [config] sync-sgd: true
[2023-07-01 09:03:38] [config] tempdir: /tmp
[2023-07-01 09:03:38] [config] tied-embeddings: false
[2023-07-01 09:03:38] [config] tied-embeddings-all: true
[2023-07-01 09:03:38] [config] tied-embeddings-src: false
[2023-07-01 09:03:38] [config] train-embedder-rank:
[2023-07-01 09:03:38] [config]   []
[2023-07-01 09:03:38] [config] train-sets:
[2023-07-01 09:03:38] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 09:03:38] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 09:03:38] [config] transformer-aan-activation: swish
[2023-07-01 09:03:38] [config] transformer-aan-depth: 2
[2023-07-01 09:03:38] [config] transformer-aan-nogate: false
[2023-07-01 09:03:38] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 09:03:38] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 09:03:38] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 09:03:38] [config] transformer-depth-scaling: false
[2023-07-01 09:03:38] [config] transformer-dim-aan: 2048
[2023-07-01 09:03:38] [config] transformer-dim-ffn: 2048
[2023-07-01 09:03:38] [config] transformer-dropout: 0.1
[2023-07-01 09:03:38] [config] transformer-dropout-attention: 0
[2023-07-01 09:03:38] [config] transformer-dropout-ffn: 0
[2023-07-01 09:03:38] [config] transformer-ffn-activation: swish
[2023-07-01 09:03:38] [config] transformer-ffn-depth: 2
[2023-07-01 09:03:38] [config] transformer-guided-alignment-layer: last
[2023-07-01 09:03:38] [config] transformer-heads: 8
[2023-07-01 09:03:38] [config] transformer-no-projection: false
[2023-07-01 09:03:38] [config] transformer-pool: false
[2023-07-01 09:03:38] [config] transformer-postprocess: dan
[2023-07-01 09:03:38] [config] transformer-postprocess-emb: d
[2023-07-01 09:03:38] [config] transformer-postprocess-top: ""
[2023-07-01 09:03:38] [config] transformer-preprocess: ""
[2023-07-01 09:03:38] [config] transformer-tied-layers:
[2023-07-01 09:03:38] [config]   []
[2023-07-01 09:03:38] [config] transformer-train-position-embeddings: false
[2023-07-01 09:03:38] [config] tsv: false
[2023-07-01 09:03:38] [config] tsv-fields: 0
[2023-07-01 09:03:38] [config] type: transformer
[2023-07-01 09:03:38] [config] ulr: false
[2023-07-01 09:03:38] [config] ulr-dim-emb: 0
[2023-07-01 09:03:38] [config] ulr-dropout: 0
[2023-07-01 09:03:38] [config] ulr-keys-vectors: ""
[2023-07-01 09:03:38] [config] ulr-query-vectors: ""
[2023-07-01 09:03:38] [config] ulr-softmax-temperature: 1
[2023-07-01 09:03:38] [config] ulr-trainable-transformation: false
[2023-07-01 09:03:38] [config] unlikelihood-loss: false
[2023-07-01 09:03:38] [config] valid-freq: 50000000
[2023-07-01 09:03:38] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 09:03:38] [config] valid-max-length: 1000
[2023-07-01 09:03:38] [config] valid-metrics:
[2023-07-01 09:03:38] [config]   - cross-entropy
[2023-07-01 09:03:38] [config]   - translation
[2023-07-01 09:03:38] [config] valid-mini-batch: 64
[2023-07-01 09:03:38] [config] valid-reset-stalled: false
[2023-07-01 09:03:38] [config] valid-script-args:
[2023-07-01 09:03:38] [config]   []
[2023-07-01 09:03:38] [config] valid-script-path: ""
[2023-07-01 09:03:38] [config] valid-sets:
[2023-07-01 09:03:38] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 09:03:38] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 09:03:38] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 09:03:38] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 09:03:38] [config] vocabs:
[2023-07-01 09:03:38] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 09:03:38] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 09:03:38] [config] word-penalty: 0
[2023-07-01 09:03:38] [config] word-scores: false
[2023-07-01 09:03:38] [config] workspace: 2048
[2023-07-01 09:03:38] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 09:03:38] Using synchronous SGD
[2023-07-01 09:03:38] Synced seed 1234
[2023-07-01 09:03:38] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 09:03:38] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 09:03:38] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 09:03:38] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 09:03:38] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 09:03:38] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 09:03:39] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 09:03:39] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 09:03:39] [comm] Using global sharding
[2023-07-01 09:03:39] [comm] NCCLCommunicators constructed successfully
[2023-07-01 09:03:39] [training] Using 1 GPUs
[2023-07-01 09:03:39] [logits] Applying loss function for 1 factor(s)
[2023-07-01 09:03:39] [memory] Reserving 88 MB, device gpu0
[2023-07-01 09:03:39] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 09:03:39] [memory] Reserving 88 MB, device gpu0
[2023-07-01 09:03:47] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 09:03:47] [valid] No post-processing script given for validating translator
[2023-07-01 09:03:47] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 09:03:47] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 09:03:47] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 09:03:47] [comm] Using global sharding
[2023-07-01 09:03:47] [comm] NCCLCommunicators constructed successfully
[2023-07-01 09:03:47] [training] Using 1 GPUs
[2023-07-01 09:03:47] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 09:03:48] Allocating memory for general optimizer shards
[2023-07-01 09:03:48] [memory] Reserving 88 MB, device gpu0
[2023-07-01 09:03:48] Loading Adam parameters
[2023-07-01 09:03:48] [memory] Reserving 176 MB, device gpu0
[2023-07-01 09:03:48] [memory] Reserving 88 MB, device gpu0
[2023-07-01 09:03:48] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 09:03:48] [data] Restoring the corpus state to epoch 9, batch 1512
[2023-07-01 09:03:48] [data] Shuffling data
[2023-07-01 09:03:48] [data] Done reading 20,192 sentences
[2023-07-01 09:03:48] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 09:03:48] Training started
[2023-07-01 09:03:48] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-07-01 09:03:48] [memory] Reserving 88 MB, device gpu0
[2023-07-01 09:03:48] Parameter type float32, optimization type float32, casting types false
[2023-07-01 09:04:12] Seen 20,073 samples
[2023-07-01 09:04:12] Starting data epoch 10 in logical epoch 10
[2023-07-01 09:04:12] Training finished
[2023-07-01 09:04:15] [valid] Ep. 10 : Up. 1701 : cross-entropy : 176.848 : new best
[2023-07-01 09:11:46] [valid] Ep. 10 : Up. 1701 : translation : 0 : new best
[2023-07-01 09:11:46] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 09:11:47] Saving Adam parameters
[2023-07-01 09:11:48] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 09:11:54] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 09:11:54] [marian] Running on node20.datos.cluster.uy as process 3998 with command line:
[2023-07-01 09:11:54] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 10 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 09:11:54] [config] after: 0e
[2023-07-01 09:11:54] [config] after-batches: 0
[2023-07-01 09:11:54] [config] after-epochs: 10
[2023-07-01 09:11:54] [config] all-caps-every: 0
[2023-07-01 09:11:54] [config] allow-unk: false
[2023-07-01 09:11:54] [config] authors: false
[2023-07-01 09:11:54] [config] beam-size: 12
[2023-07-01 09:11:54] [config] bert-class-symbol: "[CLS]"
[2023-07-01 09:11:54] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 09:11:54] [config] bert-masking-fraction: 0.15
[2023-07-01 09:11:54] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 09:11:54] [config] bert-train-type-embeddings: true
[2023-07-01 09:11:54] [config] bert-type-vocab-size: 2
[2023-07-01 09:11:54] [config] build-info: ""
[2023-07-01 09:11:54] [config] check-gradient-nan: false
[2023-07-01 09:11:54] [config] check-nan: false
[2023-07-01 09:11:54] [config] cite: false
[2023-07-01 09:11:54] [config] clip-norm: 5
[2023-07-01 09:11:54] [config] cost-scaling:
[2023-07-01 09:11:54] [config]   []
[2023-07-01 09:11:54] [config] cost-type: ce-sum
[2023-07-01 09:11:54] [config] cpu-threads: 0
[2023-07-01 09:11:54] [config] data-threads: 8
[2023-07-01 09:11:54] [config] data-weighting: ""
[2023-07-01 09:11:54] [config] data-weighting-type: sentence
[2023-07-01 09:11:54] [config] dec-cell: gru
[2023-07-01 09:11:54] [config] dec-cell-base-depth: 2
[2023-07-01 09:11:54] [config] dec-cell-high-depth: 1
[2023-07-01 09:11:54] [config] dec-depth: 2
[2023-07-01 09:11:54] [config] devices:
[2023-07-01 09:11:54] [config]   - 0
[2023-07-01 09:11:54] [config] dim-emb: 512
[2023-07-01 09:11:54] [config] dim-rnn: 1024
[2023-07-01 09:11:54] [config] dim-vocabs:
[2023-07-01 09:11:54] [config]   - 16384
[2023-07-01 09:11:54] [config]   - 16384
[2023-07-01 09:11:54] [config] disp-first: 0
[2023-07-01 09:11:54] [config] disp-freq: 1000u
[2023-07-01 09:11:54] [config] disp-label-counts: true
[2023-07-01 09:11:54] [config] dropout-rnn: 0
[2023-07-01 09:11:54] [config] dropout-src: 0
[2023-07-01 09:11:54] [config] dropout-trg: 0
[2023-07-01 09:11:54] [config] dump-config: ""
[2023-07-01 09:11:54] [config] dynamic-gradient-scaling:
[2023-07-01 09:11:54] [config]   []
[2023-07-01 09:11:54] [config] early-stopping: 10
[2023-07-01 09:11:54] [config] early-stopping-on: first
[2023-07-01 09:11:54] [config] embedding-fix-src: false
[2023-07-01 09:11:54] [config] embedding-fix-trg: false
[2023-07-01 09:11:54] [config] embedding-normalization: false
[2023-07-01 09:11:54] [config] embedding-vectors:
[2023-07-01 09:11:54] [config]   []
[2023-07-01 09:11:54] [config] enc-cell: gru
[2023-07-01 09:11:54] [config] enc-cell-depth: 1
[2023-07-01 09:11:54] [config] enc-depth: 2
[2023-07-01 09:11:54] [config] enc-type: bidirectional
[2023-07-01 09:11:54] [config] english-title-case-every: 0
[2023-07-01 09:11:54] [config] exponential-smoothing: 0.0001
[2023-07-01 09:11:54] [config] factor-weight: 1
[2023-07-01 09:11:54] [config] factors-combine: sum
[2023-07-01 09:11:54] [config] factors-dim-emb: 0
[2023-07-01 09:11:54] [config] gradient-checkpointing: false
[2023-07-01 09:11:54] [config] gradient-norm-average-window: 100
[2023-07-01 09:11:54] [config] guided-alignment: none
[2023-07-01 09:11:54] [config] guided-alignment-cost: mse
[2023-07-01 09:11:54] [config] guided-alignment-weight: 0.1
[2023-07-01 09:11:54] [config] ignore-model-config: false
[2023-07-01 09:11:54] [config] input-types:
[2023-07-01 09:11:54] [config]   []
[2023-07-01 09:11:54] [config] interpolate-env-vars: false
[2023-07-01 09:11:54] [config] keep-best: false
[2023-07-01 09:11:54] [config] label-smoothing: 0.1
[2023-07-01 09:11:54] [config] layer-normalization: false
[2023-07-01 09:11:54] [config] learn-rate: 0.0003
[2023-07-01 09:11:54] [config] lemma-dependency: ""
[2023-07-01 09:11:54] [config] lemma-dim-emb: 0
[2023-07-01 09:11:54] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 09:11:54] [config] log-level: info
[2023-07-01 09:11:54] [config] log-time-zone: ""
[2023-07-01 09:11:54] [config] logical-epoch:
[2023-07-01 09:11:54] [config]   - 1e
[2023-07-01 09:11:54] [config]   - 0
[2023-07-01 09:11:54] [config] lr-decay: 0
[2023-07-01 09:11:54] [config] lr-decay-freq: 50000
[2023-07-01 09:11:54] [config] lr-decay-inv-sqrt:
[2023-07-01 09:11:54] [config]   - 16000
[2023-07-01 09:11:54] [config] lr-decay-repeat-warmup: false
[2023-07-01 09:11:54] [config] lr-decay-reset-optimizer: false
[2023-07-01 09:11:54] [config] lr-decay-start:
[2023-07-01 09:11:54] [config]   - 10
[2023-07-01 09:11:54] [config]   - 1
[2023-07-01 09:11:54] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 09:11:54] [config] lr-report: true
[2023-07-01 09:11:54] [config] lr-warmup: 16000
[2023-07-01 09:11:54] [config] lr-warmup-at-reload: false
[2023-07-01 09:11:54] [config] lr-warmup-cycle: false
[2023-07-01 09:11:54] [config] lr-warmup-start-rate: 0
[2023-07-01 09:11:54] [config] max-length: 100
[2023-07-01 09:11:54] [config] max-length-crop: false
[2023-07-01 09:11:54] [config] max-length-factor: 3
[2023-07-01 09:11:54] [config] maxi-batch: 100
[2023-07-01 09:11:54] [config] maxi-batch-sort: trg
[2023-07-01 09:11:54] [config] mini-batch: 1000
[2023-07-01 09:11:54] [config] mini-batch-fit: true
[2023-07-01 09:11:54] [config] mini-batch-fit-step: 10
[2023-07-01 09:11:54] [config] mini-batch-round-up: true
[2023-07-01 09:11:54] [config] mini-batch-track-lr: false
[2023-07-01 09:11:54] [config] mini-batch-warmup: 0
[2023-07-01 09:11:54] [config] mini-batch-words: 0
[2023-07-01 09:11:54] [config] mini-batch-words-ref: 0
[2023-07-01 09:11:54] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 09:11:54] [config] multi-loss-type: sum
[2023-07-01 09:11:54] [config] n-best: false
[2023-07-01 09:11:54] [config] no-nccl: false
[2023-07-01 09:11:54] [config] no-reload: false
[2023-07-01 09:11:54] [config] no-restore-corpus: false
[2023-07-01 09:11:54] [config] normalize: 1
[2023-07-01 09:11:54] [config] normalize-gradient: false
[2023-07-01 09:11:54] [config] num-devices: 0
[2023-07-01 09:11:54] [config] optimizer: adam
[2023-07-01 09:11:54] [config] optimizer-delay: 1
[2023-07-01 09:11:54] [config] optimizer-params:
[2023-07-01 09:11:54] [config]   - 0.9
[2023-07-01 09:11:54] [config]   - 0.98
[2023-07-01 09:11:54] [config]   - 1e-09
[2023-07-01 09:11:54] [config] output-omit-bias: false
[2023-07-01 09:11:54] [config] overwrite: true
[2023-07-01 09:11:54] [config] precision:
[2023-07-01 09:11:54] [config]   - float32
[2023-07-01 09:11:54] [config]   - float32
[2023-07-01 09:11:54] [config] pretrained-model: ""
[2023-07-01 09:11:54] [config] quantize-biases: false
[2023-07-01 09:11:54] [config] quantize-bits: 0
[2023-07-01 09:11:54] [config] quantize-log-based: false
[2023-07-01 09:11:54] [config] quantize-optimization-steps: 0
[2023-07-01 09:11:54] [config] quiet: false
[2023-07-01 09:11:54] [config] quiet-translation: true
[2023-07-01 09:11:54] [config] relative-paths: false
[2023-07-01 09:11:54] [config] right-left: false
[2023-07-01 09:11:54] [config] save-freq: 10000u
[2023-07-01 09:11:54] [config] seed: 1234
[2023-07-01 09:11:54] [config] sentencepiece-alphas:
[2023-07-01 09:11:54] [config]   []
[2023-07-01 09:11:54] [config] sentencepiece-max-lines: 2000000
[2023-07-01 09:11:54] [config] sentencepiece-options: ""
[2023-07-01 09:11:54] [config] sharding: global
[2023-07-01 09:11:54] [config] shuffle: data
[2023-07-01 09:11:54] [config] shuffle-in-ram: false
[2023-07-01 09:11:54] [config] sigterm: save-and-exit
[2023-07-01 09:11:54] [config] skip: false
[2023-07-01 09:11:54] [config] sqlite: ""
[2023-07-01 09:11:54] [config] sqlite-drop: false
[2023-07-01 09:11:54] [config] sync-freq: 200u
[2023-07-01 09:11:54] [config] sync-sgd: true
[2023-07-01 09:11:54] [config] tempdir: /tmp
[2023-07-01 09:11:54] [config] tied-embeddings: false
[2023-07-01 09:11:54] [config] tied-embeddings-all: true
[2023-07-01 09:11:54] [config] tied-embeddings-src: false
[2023-07-01 09:11:54] [config] train-embedder-rank:
[2023-07-01 09:11:54] [config]   []
[2023-07-01 09:11:54] [config] train-sets:
[2023-07-01 09:11:54] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 09:11:54] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 09:11:54] [config] transformer-aan-activation: swish
[2023-07-01 09:11:54] [config] transformer-aan-depth: 2
[2023-07-01 09:11:54] [config] transformer-aan-nogate: false
[2023-07-01 09:11:54] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 09:11:54] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 09:11:54] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 09:11:54] [config] transformer-depth-scaling: false
[2023-07-01 09:11:54] [config] transformer-dim-aan: 2048
[2023-07-01 09:11:54] [config] transformer-dim-ffn: 2048
[2023-07-01 09:11:54] [config] transformer-dropout: 0.1
[2023-07-01 09:11:54] [config] transformer-dropout-attention: 0
[2023-07-01 09:11:54] [config] transformer-dropout-ffn: 0
[2023-07-01 09:11:54] [config] transformer-ffn-activation: swish
[2023-07-01 09:11:54] [config] transformer-ffn-depth: 2
[2023-07-01 09:11:54] [config] transformer-guided-alignment-layer: last
[2023-07-01 09:11:54] [config] transformer-heads: 8
[2023-07-01 09:11:54] [config] transformer-no-projection: false
[2023-07-01 09:11:54] [config] transformer-pool: false
[2023-07-01 09:11:54] [config] transformer-postprocess: dan
[2023-07-01 09:11:54] [config] transformer-postprocess-emb: d
[2023-07-01 09:11:54] [config] transformer-postprocess-top: ""
[2023-07-01 09:11:54] [config] transformer-preprocess: ""
[2023-07-01 09:11:54] [config] transformer-tied-layers:
[2023-07-01 09:11:54] [config]   []
[2023-07-01 09:11:54] [config] transformer-train-position-embeddings: false
[2023-07-01 09:11:54] [config] tsv: false
[2023-07-01 09:11:54] [config] tsv-fields: 0
[2023-07-01 09:11:54] [config] type: transformer
[2023-07-01 09:11:54] [config] ulr: false
[2023-07-01 09:11:54] [config] ulr-dim-emb: 0
[2023-07-01 09:11:54] [config] ulr-dropout: 0
[2023-07-01 09:11:54] [config] ulr-keys-vectors: ""
[2023-07-01 09:11:54] [config] ulr-query-vectors: ""
[2023-07-01 09:11:54] [config] ulr-softmax-temperature: 1
[2023-07-01 09:11:54] [config] ulr-trainable-transformation: false
[2023-07-01 09:11:54] [config] unlikelihood-loss: false
[2023-07-01 09:11:54] [config] valid-freq: 50000000
[2023-07-01 09:11:54] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 09:11:54] [config] valid-max-length: 1000
[2023-07-01 09:11:54] [config] valid-metrics:
[2023-07-01 09:11:54] [config]   - cross-entropy
[2023-07-01 09:11:54] [config]   - translation
[2023-07-01 09:11:54] [config] valid-mini-batch: 64
[2023-07-01 09:11:54] [config] valid-reset-stalled: false
[2023-07-01 09:11:54] [config] valid-script-args:
[2023-07-01 09:11:54] [config]   []
[2023-07-01 09:11:54] [config] valid-script-path: ""
[2023-07-01 09:11:54] [config] valid-sets:
[2023-07-01 09:11:54] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 09:11:54] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 09:11:54] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 09:11:54] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 09:11:54] [config] vocabs:
[2023-07-01 09:11:54] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 09:11:54] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 09:11:54] [config] word-penalty: 0
[2023-07-01 09:11:54] [config] word-scores: false
[2023-07-01 09:11:54] [config] workspace: 2048
[2023-07-01 09:11:54] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 09:11:54] Using synchronous SGD
[2023-07-01 09:11:54] Synced seed 1234
[2023-07-01 09:11:54] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 09:11:54] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 09:11:54] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 09:11:54] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 09:11:54] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 09:11:54] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 09:11:55] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 09:11:55] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 09:11:55] [comm] Using global sharding
[2023-07-01 09:11:55] [comm] NCCLCommunicators constructed successfully
[2023-07-01 09:11:55] [training] Using 1 GPUs
[2023-07-01 09:11:55] [logits] Applying loss function for 1 factor(s)
[2023-07-01 09:11:55] [memory] Reserving 88 MB, device gpu0
[2023-07-01 09:11:55] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 09:11:55] [memory] Reserving 88 MB, device gpu0
[2023-07-01 09:12:03] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 09:12:03] [valid] No post-processing script given for validating translator
[2023-07-01 09:12:03] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 09:12:03] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 09:12:03] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 09:12:03] [comm] Using global sharding
[2023-07-01 09:12:03] [comm] NCCLCommunicators constructed successfully
[2023-07-01 09:12:03] [training] Using 1 GPUs
[2023-07-01 09:12:03] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 09:12:04] Allocating memory for general optimizer shards
[2023-07-01 09:12:04] [memory] Reserving 88 MB, device gpu0
[2023-07-01 09:12:04] Loading Adam parameters
[2023-07-01 09:12:04] [memory] Reserving 176 MB, device gpu0
[2023-07-01 09:12:04] [memory] Reserving 88 MB, device gpu0
[2023-07-01 09:12:04] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 09:12:04] [data] Restoring the corpus state to epoch 10, batch 1701
[2023-07-01 09:12:04] [data] Shuffling data
[2023-07-01 09:12:04] [data] Done reading 20,192 sentences
[2023-07-01 09:12:04] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 09:12:04] Training started
[2023-07-01 09:12:04] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-07-01 09:12:04] [memory] Reserving 88 MB, device gpu0
[2023-07-01 09:12:04] Parameter type float32, optimization type float32, casting types false
[2023-07-01 09:12:28] Seen 20,073 samples
[2023-07-01 09:12:28] Starting data epoch 11 in logical epoch 11
[2023-07-01 09:12:28] Training finished
[2023-07-01 09:12:31] [valid] Ep. 11 : Up. 1890 : cross-entropy : 173.49 : new best
[2023-07-01 09:19:08] [valid] Ep. 11 : Up. 1890 : translation : 0 : new best
[2023-07-01 09:19:08] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 09:19:09] Saving Adam parameters
[2023-07-01 09:19:10] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 09:19:16] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 09:19:16] [marian] Running on node20.datos.cluster.uy as process 4436 with command line:
[2023-07-01 09:19:16] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 11 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 09:19:16] [config] after: 0e
[2023-07-01 09:19:16] [config] after-batches: 0
[2023-07-01 09:19:16] [config] after-epochs: 11
[2023-07-01 09:19:16] [config] all-caps-every: 0
[2023-07-01 09:19:16] [config] allow-unk: false
[2023-07-01 09:19:16] [config] authors: false
[2023-07-01 09:19:16] [config] beam-size: 12
[2023-07-01 09:19:16] [config] bert-class-symbol: "[CLS]"
[2023-07-01 09:19:16] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 09:19:16] [config] bert-masking-fraction: 0.15
[2023-07-01 09:19:16] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 09:19:16] [config] bert-train-type-embeddings: true
[2023-07-01 09:19:16] [config] bert-type-vocab-size: 2
[2023-07-01 09:19:16] [config] build-info: ""
[2023-07-01 09:19:16] [config] check-gradient-nan: false
[2023-07-01 09:19:16] [config] check-nan: false
[2023-07-01 09:19:16] [config] cite: false
[2023-07-01 09:19:16] [config] clip-norm: 5
[2023-07-01 09:19:16] [config] cost-scaling:
[2023-07-01 09:19:16] [config]   []
[2023-07-01 09:19:16] [config] cost-type: ce-sum
[2023-07-01 09:19:16] [config] cpu-threads: 0
[2023-07-01 09:19:16] [config] data-threads: 8
[2023-07-01 09:19:16] [config] data-weighting: ""
[2023-07-01 09:19:16] [config] data-weighting-type: sentence
[2023-07-01 09:19:16] [config] dec-cell: gru
[2023-07-01 09:19:16] [config] dec-cell-base-depth: 2
[2023-07-01 09:19:16] [config] dec-cell-high-depth: 1
[2023-07-01 09:19:16] [config] dec-depth: 2
[2023-07-01 09:19:16] [config] devices:
[2023-07-01 09:19:16] [config]   - 0
[2023-07-01 09:19:16] [config] dim-emb: 512
[2023-07-01 09:19:16] [config] dim-rnn: 1024
[2023-07-01 09:19:16] [config] dim-vocabs:
[2023-07-01 09:19:16] [config]   - 16384
[2023-07-01 09:19:16] [config]   - 16384
[2023-07-01 09:19:16] [config] disp-first: 0
[2023-07-01 09:19:16] [config] disp-freq: 1000u
[2023-07-01 09:19:16] [config] disp-label-counts: true
[2023-07-01 09:19:16] [config] dropout-rnn: 0
[2023-07-01 09:19:16] [config] dropout-src: 0
[2023-07-01 09:19:16] [config] dropout-trg: 0
[2023-07-01 09:19:16] [config] dump-config: ""
[2023-07-01 09:19:16] [config] dynamic-gradient-scaling:
[2023-07-01 09:19:16] [config]   []
[2023-07-01 09:19:16] [config] early-stopping: 10
[2023-07-01 09:19:16] [config] early-stopping-on: first
[2023-07-01 09:19:16] [config] embedding-fix-src: false
[2023-07-01 09:19:16] [config] embedding-fix-trg: false
[2023-07-01 09:19:16] [config] embedding-normalization: false
[2023-07-01 09:19:16] [config] embedding-vectors:
[2023-07-01 09:19:16] [config]   []
[2023-07-01 09:19:16] [config] enc-cell: gru
[2023-07-01 09:19:16] [config] enc-cell-depth: 1
[2023-07-01 09:19:16] [config] enc-depth: 2
[2023-07-01 09:19:16] [config] enc-type: bidirectional
[2023-07-01 09:19:16] [config] english-title-case-every: 0
[2023-07-01 09:19:16] [config] exponential-smoothing: 0.0001
[2023-07-01 09:19:16] [config] factor-weight: 1
[2023-07-01 09:19:16] [config] factors-combine: sum
[2023-07-01 09:19:16] [config] factors-dim-emb: 0
[2023-07-01 09:19:16] [config] gradient-checkpointing: false
[2023-07-01 09:19:16] [config] gradient-norm-average-window: 100
[2023-07-01 09:19:16] [config] guided-alignment: none
[2023-07-01 09:19:16] [config] guided-alignment-cost: mse
[2023-07-01 09:19:16] [config] guided-alignment-weight: 0.1
[2023-07-01 09:19:16] [config] ignore-model-config: false
[2023-07-01 09:19:16] [config] input-types:
[2023-07-01 09:19:16] [config]   []
[2023-07-01 09:19:16] [config] interpolate-env-vars: false
[2023-07-01 09:19:16] [config] keep-best: false
[2023-07-01 09:19:16] [config] label-smoothing: 0.1
[2023-07-01 09:19:16] [config] layer-normalization: false
[2023-07-01 09:19:16] [config] learn-rate: 0.0003
[2023-07-01 09:19:16] [config] lemma-dependency: ""
[2023-07-01 09:19:16] [config] lemma-dim-emb: 0
[2023-07-01 09:19:16] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 09:19:16] [config] log-level: info
[2023-07-01 09:19:16] [config] log-time-zone: ""
[2023-07-01 09:19:16] [config] logical-epoch:
[2023-07-01 09:19:16] [config]   - 1e
[2023-07-01 09:19:16] [config]   - 0
[2023-07-01 09:19:16] [config] lr-decay: 0
[2023-07-01 09:19:16] [config] lr-decay-freq: 50000
[2023-07-01 09:19:16] [config] lr-decay-inv-sqrt:
[2023-07-01 09:19:16] [config]   - 16000
[2023-07-01 09:19:16] [config] lr-decay-repeat-warmup: false
[2023-07-01 09:19:16] [config] lr-decay-reset-optimizer: false
[2023-07-01 09:19:16] [config] lr-decay-start:
[2023-07-01 09:19:16] [config]   - 10
[2023-07-01 09:19:16] [config]   - 1
[2023-07-01 09:19:16] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 09:19:16] [config] lr-report: true
[2023-07-01 09:19:16] [config] lr-warmup: 16000
[2023-07-01 09:19:16] [config] lr-warmup-at-reload: false
[2023-07-01 09:19:16] [config] lr-warmup-cycle: false
[2023-07-01 09:19:16] [config] lr-warmup-start-rate: 0
[2023-07-01 09:19:16] [config] max-length: 100
[2023-07-01 09:19:16] [config] max-length-crop: false
[2023-07-01 09:19:16] [config] max-length-factor: 3
[2023-07-01 09:19:16] [config] maxi-batch: 100
[2023-07-01 09:19:16] [config] maxi-batch-sort: trg
[2023-07-01 09:19:16] [config] mini-batch: 1000
[2023-07-01 09:19:16] [config] mini-batch-fit: true
[2023-07-01 09:19:16] [config] mini-batch-fit-step: 10
[2023-07-01 09:19:16] [config] mini-batch-round-up: true
[2023-07-01 09:19:16] [config] mini-batch-track-lr: false
[2023-07-01 09:19:16] [config] mini-batch-warmup: 0
[2023-07-01 09:19:16] [config] mini-batch-words: 0
[2023-07-01 09:19:16] [config] mini-batch-words-ref: 0
[2023-07-01 09:19:16] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 09:19:16] [config] multi-loss-type: sum
[2023-07-01 09:19:16] [config] n-best: false
[2023-07-01 09:19:16] [config] no-nccl: false
[2023-07-01 09:19:16] [config] no-reload: false
[2023-07-01 09:19:16] [config] no-restore-corpus: false
[2023-07-01 09:19:16] [config] normalize: 1
[2023-07-01 09:19:16] [config] normalize-gradient: false
[2023-07-01 09:19:16] [config] num-devices: 0
[2023-07-01 09:19:16] [config] optimizer: adam
[2023-07-01 09:19:16] [config] optimizer-delay: 1
[2023-07-01 09:19:16] [config] optimizer-params:
[2023-07-01 09:19:16] [config]   - 0.9
[2023-07-01 09:19:16] [config]   - 0.98
[2023-07-01 09:19:16] [config]   - 1e-09
[2023-07-01 09:19:16] [config] output-omit-bias: false
[2023-07-01 09:19:16] [config] overwrite: true
[2023-07-01 09:19:16] [config] precision:
[2023-07-01 09:19:16] [config]   - float32
[2023-07-01 09:19:16] [config]   - float32
[2023-07-01 09:19:16] [config] pretrained-model: ""
[2023-07-01 09:19:16] [config] quantize-biases: false
[2023-07-01 09:19:16] [config] quantize-bits: 0
[2023-07-01 09:19:16] [config] quantize-log-based: false
[2023-07-01 09:19:16] [config] quantize-optimization-steps: 0
[2023-07-01 09:19:16] [config] quiet: false
[2023-07-01 09:19:16] [config] quiet-translation: true
[2023-07-01 09:19:16] [config] relative-paths: false
[2023-07-01 09:19:16] [config] right-left: false
[2023-07-01 09:19:16] [config] save-freq: 10000u
[2023-07-01 09:19:16] [config] seed: 1234
[2023-07-01 09:19:16] [config] sentencepiece-alphas:
[2023-07-01 09:19:16] [config]   []
[2023-07-01 09:19:16] [config] sentencepiece-max-lines: 2000000
[2023-07-01 09:19:16] [config] sentencepiece-options: ""
[2023-07-01 09:19:16] [config] sharding: global
[2023-07-01 09:19:16] [config] shuffle: data
[2023-07-01 09:19:16] [config] shuffle-in-ram: false
[2023-07-01 09:19:16] [config] sigterm: save-and-exit
[2023-07-01 09:19:16] [config] skip: false
[2023-07-01 09:19:16] [config] sqlite: ""
[2023-07-01 09:19:16] [config] sqlite-drop: false
[2023-07-01 09:19:16] [config] sync-freq: 200u
[2023-07-01 09:19:16] [config] sync-sgd: true
[2023-07-01 09:19:16] [config] tempdir: /tmp
[2023-07-01 09:19:16] [config] tied-embeddings: false
[2023-07-01 09:19:16] [config] tied-embeddings-all: true
[2023-07-01 09:19:16] [config] tied-embeddings-src: false
[2023-07-01 09:19:16] [config] train-embedder-rank:
[2023-07-01 09:19:16] [config]   []
[2023-07-01 09:19:16] [config] train-sets:
[2023-07-01 09:19:16] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 09:19:16] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 09:19:16] [config] transformer-aan-activation: swish
[2023-07-01 09:19:16] [config] transformer-aan-depth: 2
[2023-07-01 09:19:16] [config] transformer-aan-nogate: false
[2023-07-01 09:19:16] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 09:19:16] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 09:19:16] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 09:19:16] [config] transformer-depth-scaling: false
[2023-07-01 09:19:16] [config] transformer-dim-aan: 2048
[2023-07-01 09:19:16] [config] transformer-dim-ffn: 2048
[2023-07-01 09:19:16] [config] transformer-dropout: 0.1
[2023-07-01 09:19:16] [config] transformer-dropout-attention: 0
[2023-07-01 09:19:16] [config] transformer-dropout-ffn: 0
[2023-07-01 09:19:16] [config] transformer-ffn-activation: swish
[2023-07-01 09:19:16] [config] transformer-ffn-depth: 2
[2023-07-01 09:19:16] [config] transformer-guided-alignment-layer: last
[2023-07-01 09:19:16] [config] transformer-heads: 8
[2023-07-01 09:19:16] [config] transformer-no-projection: false
[2023-07-01 09:19:16] [config] transformer-pool: false
[2023-07-01 09:19:16] [config] transformer-postprocess: dan
[2023-07-01 09:19:16] [config] transformer-postprocess-emb: d
[2023-07-01 09:19:16] [config] transformer-postprocess-top: ""
[2023-07-01 09:19:16] [config] transformer-preprocess: ""
[2023-07-01 09:19:16] [config] transformer-tied-layers:
[2023-07-01 09:19:16] [config]   []
[2023-07-01 09:19:16] [config] transformer-train-position-embeddings: false
[2023-07-01 09:19:16] [config] tsv: false
[2023-07-01 09:19:16] [config] tsv-fields: 0
[2023-07-01 09:19:16] [config] type: transformer
[2023-07-01 09:19:16] [config] ulr: false
[2023-07-01 09:19:16] [config] ulr-dim-emb: 0
[2023-07-01 09:19:16] [config] ulr-dropout: 0
[2023-07-01 09:19:16] [config] ulr-keys-vectors: ""
[2023-07-01 09:19:16] [config] ulr-query-vectors: ""
[2023-07-01 09:19:16] [config] ulr-softmax-temperature: 1
[2023-07-01 09:19:16] [config] ulr-trainable-transformation: false
[2023-07-01 09:19:16] [config] unlikelihood-loss: false
[2023-07-01 09:19:16] [config] valid-freq: 50000000
[2023-07-01 09:19:16] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 09:19:16] [config] valid-max-length: 1000
[2023-07-01 09:19:16] [config] valid-metrics:
[2023-07-01 09:19:16] [config]   - cross-entropy
[2023-07-01 09:19:16] [config]   - translation
[2023-07-01 09:19:16] [config] valid-mini-batch: 64
[2023-07-01 09:19:16] [config] valid-reset-stalled: false
[2023-07-01 09:19:16] [config] valid-script-args:
[2023-07-01 09:19:16] [config]   []
[2023-07-01 09:19:16] [config] valid-script-path: ""
[2023-07-01 09:19:16] [config] valid-sets:
[2023-07-01 09:19:16] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 09:19:16] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 09:19:16] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 09:19:16] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 09:19:16] [config] vocabs:
[2023-07-01 09:19:16] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 09:19:16] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 09:19:16] [config] word-penalty: 0
[2023-07-01 09:19:16] [config] word-scores: false
[2023-07-01 09:19:16] [config] workspace: 2048
[2023-07-01 09:19:16] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 09:19:16] Using synchronous SGD
[2023-07-01 09:19:17] Synced seed 1234
[2023-07-01 09:19:17] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 09:19:17] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 09:19:17] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 09:19:17] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 09:19:17] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 09:19:17] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 09:19:17] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 09:19:17] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 09:19:17] [comm] Using global sharding
[2023-07-01 09:19:17] [comm] NCCLCommunicators constructed successfully
[2023-07-01 09:19:17] [training] Using 1 GPUs
[2023-07-01 09:19:17] [logits] Applying loss function for 1 factor(s)
[2023-07-01 09:19:17] [memory] Reserving 88 MB, device gpu0
[2023-07-01 09:19:18] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 09:19:18] [memory] Reserving 88 MB, device gpu0
[2023-07-01 09:19:25] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 09:19:25] [valid] No post-processing script given for validating translator
[2023-07-01 09:19:25] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 09:19:25] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 09:19:25] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 09:19:25] [comm] Using global sharding
[2023-07-01 09:19:26] [comm] NCCLCommunicators constructed successfully
[2023-07-01 09:19:26] [training] Using 1 GPUs
[2023-07-01 09:19:26] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 09:19:26] Allocating memory for general optimizer shards
[2023-07-01 09:19:26] [memory] Reserving 88 MB, device gpu0
[2023-07-01 09:19:26] Loading Adam parameters
[2023-07-01 09:19:26] [memory] Reserving 176 MB, device gpu0
[2023-07-01 09:19:26] [memory] Reserving 88 MB, device gpu0
[2023-07-01 09:19:27] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 09:19:27] [data] Restoring the corpus state to epoch 11, batch 1890
[2023-07-01 09:19:27] [data] Shuffling data
[2023-07-01 09:19:27] [data] Done reading 20,192 sentences
[2023-07-01 09:19:27] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 09:19:27] Training started
[2023-07-01 09:19:27] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-07-01 09:19:27] [memory] Reserving 88 MB, device gpu0
[2023-07-01 09:19:27] Parameter type float32, optimization type float32, casting types false
[2023-07-01 09:19:40] Ep. 11 : Up. 2000 : Sen. 11,327 : Cost 6.54853392 * 3,203,507 @ 3,584 after 6,418,448 : Time 14.99s : 213705.43 words/s : gNorm 1.4146 : L.r. 3.7500e-05
[2023-07-01 09:19:51] Seen 20,073 samples
[2023-07-01 09:19:51] Starting data epoch 12 in logical epoch 12
[2023-07-01 09:19:51] Training finished
[2023-07-01 09:19:54] [valid] Ep. 12 : Up. 2079 : cross-entropy : 170.264 : new best
[2023-07-01 09:25:49] [valid] Ep. 12 : Up. 2079 : translation : 0 : new best
[2023-07-01 09:25:49] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 09:25:50] Saving Adam parameters
[2023-07-01 09:25:50] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 09:25:56] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 09:25:56] [marian] Running on node20.datos.cluster.uy as process 4832 with command line:
[2023-07-01 09:25:56] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 12 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 09:25:56] [config] after: 0e
[2023-07-01 09:25:56] [config] after-batches: 0
[2023-07-01 09:25:56] [config] after-epochs: 12
[2023-07-01 09:25:56] [config] all-caps-every: 0
[2023-07-01 09:25:56] [config] allow-unk: false
[2023-07-01 09:25:56] [config] authors: false
[2023-07-01 09:25:56] [config] beam-size: 12
[2023-07-01 09:25:56] [config] bert-class-symbol: "[CLS]"
[2023-07-01 09:25:56] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 09:25:56] [config] bert-masking-fraction: 0.15
[2023-07-01 09:25:56] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 09:25:56] [config] bert-train-type-embeddings: true
[2023-07-01 09:25:56] [config] bert-type-vocab-size: 2
[2023-07-01 09:25:56] [config] build-info: ""
[2023-07-01 09:25:56] [config] check-gradient-nan: false
[2023-07-01 09:25:56] [config] check-nan: false
[2023-07-01 09:25:56] [config] cite: false
[2023-07-01 09:25:56] [config] clip-norm: 5
[2023-07-01 09:25:56] [config] cost-scaling:
[2023-07-01 09:25:56] [config]   []
[2023-07-01 09:25:56] [config] cost-type: ce-sum
[2023-07-01 09:25:56] [config] cpu-threads: 0
[2023-07-01 09:25:56] [config] data-threads: 8
[2023-07-01 09:25:56] [config] data-weighting: ""
[2023-07-01 09:25:56] [config] data-weighting-type: sentence
[2023-07-01 09:25:56] [config] dec-cell: gru
[2023-07-01 09:25:56] [config] dec-cell-base-depth: 2
[2023-07-01 09:25:56] [config] dec-cell-high-depth: 1
[2023-07-01 09:25:56] [config] dec-depth: 2
[2023-07-01 09:25:56] [config] devices:
[2023-07-01 09:25:56] [config]   - 0
[2023-07-01 09:25:56] [config] dim-emb: 512
[2023-07-01 09:25:56] [config] dim-rnn: 1024
[2023-07-01 09:25:56] [config] dim-vocabs:
[2023-07-01 09:25:56] [config]   - 16384
[2023-07-01 09:25:56] [config]   - 16384
[2023-07-01 09:25:56] [config] disp-first: 0
[2023-07-01 09:25:56] [config] disp-freq: 1000u
[2023-07-01 09:25:56] [config] disp-label-counts: true
[2023-07-01 09:25:56] [config] dropout-rnn: 0
[2023-07-01 09:25:56] [config] dropout-src: 0
[2023-07-01 09:25:56] [config] dropout-trg: 0
[2023-07-01 09:25:56] [config] dump-config: ""
[2023-07-01 09:25:56] [config] dynamic-gradient-scaling:
[2023-07-01 09:25:56] [config]   []
[2023-07-01 09:25:56] [config] early-stopping: 10
[2023-07-01 09:25:56] [config] early-stopping-on: first
[2023-07-01 09:25:56] [config] embedding-fix-src: false
[2023-07-01 09:25:56] [config] embedding-fix-trg: false
[2023-07-01 09:25:56] [config] embedding-normalization: false
[2023-07-01 09:25:56] [config] embedding-vectors:
[2023-07-01 09:25:56] [config]   []
[2023-07-01 09:25:56] [config] enc-cell: gru
[2023-07-01 09:25:56] [config] enc-cell-depth: 1
[2023-07-01 09:25:56] [config] enc-depth: 2
[2023-07-01 09:25:56] [config] enc-type: bidirectional
[2023-07-01 09:25:56] [config] english-title-case-every: 0
[2023-07-01 09:25:56] [config] exponential-smoothing: 0.0001
[2023-07-01 09:25:56] [config] factor-weight: 1
[2023-07-01 09:25:56] [config] factors-combine: sum
[2023-07-01 09:25:56] [config] factors-dim-emb: 0
[2023-07-01 09:25:56] [config] gradient-checkpointing: false
[2023-07-01 09:25:56] [config] gradient-norm-average-window: 100
[2023-07-01 09:25:56] [config] guided-alignment: none
[2023-07-01 09:25:56] [config] guided-alignment-cost: mse
[2023-07-01 09:25:56] [config] guided-alignment-weight: 0.1
[2023-07-01 09:25:56] [config] ignore-model-config: false
[2023-07-01 09:25:56] [config] input-types:
[2023-07-01 09:25:56] [config]   []
[2023-07-01 09:25:56] [config] interpolate-env-vars: false
[2023-07-01 09:25:56] [config] keep-best: false
[2023-07-01 09:25:56] [config] label-smoothing: 0.1
[2023-07-01 09:25:56] [config] layer-normalization: false
[2023-07-01 09:25:56] [config] learn-rate: 0.0003
[2023-07-01 09:25:56] [config] lemma-dependency: ""
[2023-07-01 09:25:56] [config] lemma-dim-emb: 0
[2023-07-01 09:25:56] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 09:25:56] [config] log-level: info
[2023-07-01 09:25:56] [config] log-time-zone: ""
[2023-07-01 09:25:56] [config] logical-epoch:
[2023-07-01 09:25:56] [config]   - 1e
[2023-07-01 09:25:56] [config]   - 0
[2023-07-01 09:25:56] [config] lr-decay: 0
[2023-07-01 09:25:56] [config] lr-decay-freq: 50000
[2023-07-01 09:25:56] [config] lr-decay-inv-sqrt:
[2023-07-01 09:25:56] [config]   - 16000
[2023-07-01 09:25:56] [config] lr-decay-repeat-warmup: false
[2023-07-01 09:25:56] [config] lr-decay-reset-optimizer: false
[2023-07-01 09:25:56] [config] lr-decay-start:
[2023-07-01 09:25:56] [config]   - 10
[2023-07-01 09:25:56] [config]   - 1
[2023-07-01 09:25:56] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 09:25:56] [config] lr-report: true
[2023-07-01 09:25:56] [config] lr-warmup: 16000
[2023-07-01 09:25:56] [config] lr-warmup-at-reload: false
[2023-07-01 09:25:56] [config] lr-warmup-cycle: false
[2023-07-01 09:25:56] [config] lr-warmup-start-rate: 0
[2023-07-01 09:25:56] [config] max-length: 100
[2023-07-01 09:25:56] [config] max-length-crop: false
[2023-07-01 09:25:56] [config] max-length-factor: 3
[2023-07-01 09:25:56] [config] maxi-batch: 100
[2023-07-01 09:25:56] [config] maxi-batch-sort: trg
[2023-07-01 09:25:56] [config] mini-batch: 1000
[2023-07-01 09:25:56] [config] mini-batch-fit: true
[2023-07-01 09:25:56] [config] mini-batch-fit-step: 10
[2023-07-01 09:25:56] [config] mini-batch-round-up: true
[2023-07-01 09:25:56] [config] mini-batch-track-lr: false
[2023-07-01 09:25:56] [config] mini-batch-warmup: 0
[2023-07-01 09:25:56] [config] mini-batch-words: 0
[2023-07-01 09:25:56] [config] mini-batch-words-ref: 0
[2023-07-01 09:25:56] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 09:25:56] [config] multi-loss-type: sum
[2023-07-01 09:25:56] [config] n-best: false
[2023-07-01 09:25:56] [config] no-nccl: false
[2023-07-01 09:25:56] [config] no-reload: false
[2023-07-01 09:25:56] [config] no-restore-corpus: false
[2023-07-01 09:25:56] [config] normalize: 1
[2023-07-01 09:25:56] [config] normalize-gradient: false
[2023-07-01 09:25:56] [config] num-devices: 0
[2023-07-01 09:25:56] [config] optimizer: adam
[2023-07-01 09:25:56] [config] optimizer-delay: 1
[2023-07-01 09:25:56] [config] optimizer-params:
[2023-07-01 09:25:56] [config]   - 0.9
[2023-07-01 09:25:56] [config]   - 0.98
[2023-07-01 09:25:56] [config]   - 1e-09
[2023-07-01 09:25:56] [config] output-omit-bias: false
[2023-07-01 09:25:56] [config] overwrite: true
[2023-07-01 09:25:56] [config] precision:
[2023-07-01 09:25:56] [config]   - float32
[2023-07-01 09:25:56] [config]   - float32
[2023-07-01 09:25:56] [config] pretrained-model: ""
[2023-07-01 09:25:56] [config] quantize-biases: false
[2023-07-01 09:25:56] [config] quantize-bits: 0
[2023-07-01 09:25:56] [config] quantize-log-based: false
[2023-07-01 09:25:56] [config] quantize-optimization-steps: 0
[2023-07-01 09:25:56] [config] quiet: false
[2023-07-01 09:25:56] [config] quiet-translation: true
[2023-07-01 09:25:56] [config] relative-paths: false
[2023-07-01 09:25:56] [config] right-left: false
[2023-07-01 09:25:56] [config] save-freq: 10000u
[2023-07-01 09:25:56] [config] seed: 1234
[2023-07-01 09:25:56] [config] sentencepiece-alphas:
[2023-07-01 09:25:56] [config]   []
[2023-07-01 09:25:56] [config] sentencepiece-max-lines: 2000000
[2023-07-01 09:25:56] [config] sentencepiece-options: ""
[2023-07-01 09:25:56] [config] sharding: global
[2023-07-01 09:25:56] [config] shuffle: data
[2023-07-01 09:25:56] [config] shuffle-in-ram: false
[2023-07-01 09:25:56] [config] sigterm: save-and-exit
[2023-07-01 09:25:56] [config] skip: false
[2023-07-01 09:25:56] [config] sqlite: ""
[2023-07-01 09:25:56] [config] sqlite-drop: false
[2023-07-01 09:25:56] [config] sync-freq: 200u
[2023-07-01 09:25:56] [config] sync-sgd: true
[2023-07-01 09:25:56] [config] tempdir: /tmp
[2023-07-01 09:25:56] [config] tied-embeddings: false
[2023-07-01 09:25:56] [config] tied-embeddings-all: true
[2023-07-01 09:25:56] [config] tied-embeddings-src: false
[2023-07-01 09:25:56] [config] train-embedder-rank:
[2023-07-01 09:25:56] [config]   []
[2023-07-01 09:25:56] [config] train-sets:
[2023-07-01 09:25:56] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 09:25:56] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 09:25:56] [config] transformer-aan-activation: swish
[2023-07-01 09:25:56] [config] transformer-aan-depth: 2
[2023-07-01 09:25:56] [config] transformer-aan-nogate: false
[2023-07-01 09:25:56] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 09:25:56] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 09:25:56] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 09:25:56] [config] transformer-depth-scaling: false
[2023-07-01 09:25:56] [config] transformer-dim-aan: 2048
[2023-07-01 09:25:56] [config] transformer-dim-ffn: 2048
[2023-07-01 09:25:56] [config] transformer-dropout: 0.1
[2023-07-01 09:25:56] [config] transformer-dropout-attention: 0
[2023-07-01 09:25:56] [config] transformer-dropout-ffn: 0
[2023-07-01 09:25:56] [config] transformer-ffn-activation: swish
[2023-07-01 09:25:56] [config] transformer-ffn-depth: 2
[2023-07-01 09:25:56] [config] transformer-guided-alignment-layer: last
[2023-07-01 09:25:56] [config] transformer-heads: 8
[2023-07-01 09:25:56] [config] transformer-no-projection: false
[2023-07-01 09:25:56] [config] transformer-pool: false
[2023-07-01 09:25:56] [config] transformer-postprocess: dan
[2023-07-01 09:25:56] [config] transformer-postprocess-emb: d
[2023-07-01 09:25:56] [config] transformer-postprocess-top: ""
[2023-07-01 09:25:56] [config] transformer-preprocess: ""
[2023-07-01 09:25:56] [config] transformer-tied-layers:
[2023-07-01 09:25:56] [config]   []
[2023-07-01 09:25:56] [config] transformer-train-position-embeddings: false
[2023-07-01 09:25:56] [config] tsv: false
[2023-07-01 09:25:56] [config] tsv-fields: 0
[2023-07-01 09:25:56] [config] type: transformer
[2023-07-01 09:25:56] [config] ulr: false
[2023-07-01 09:25:56] [config] ulr-dim-emb: 0
[2023-07-01 09:25:56] [config] ulr-dropout: 0
[2023-07-01 09:25:56] [config] ulr-keys-vectors: ""
[2023-07-01 09:25:56] [config] ulr-query-vectors: ""
[2023-07-01 09:25:56] [config] ulr-softmax-temperature: 1
[2023-07-01 09:25:56] [config] ulr-trainable-transformation: false
[2023-07-01 09:25:56] [config] unlikelihood-loss: false
[2023-07-01 09:25:56] [config] valid-freq: 50000000
[2023-07-01 09:25:56] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 09:25:56] [config] valid-max-length: 1000
[2023-07-01 09:25:56] [config] valid-metrics:
[2023-07-01 09:25:56] [config]   - cross-entropy
[2023-07-01 09:25:56] [config]   - translation
[2023-07-01 09:25:56] [config] valid-mini-batch: 64
[2023-07-01 09:25:56] [config] valid-reset-stalled: false
[2023-07-01 09:25:56] [config] valid-script-args:
[2023-07-01 09:25:56] [config]   []
[2023-07-01 09:25:56] [config] valid-script-path: ""
[2023-07-01 09:25:56] [config] valid-sets:
[2023-07-01 09:25:56] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 09:25:56] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 09:25:56] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 09:25:56] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 09:25:56] [config] vocabs:
[2023-07-01 09:25:56] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 09:25:56] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 09:25:56] [config] word-penalty: 0
[2023-07-01 09:25:56] [config] word-scores: false
[2023-07-01 09:25:56] [config] workspace: 2048
[2023-07-01 09:25:56] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 09:25:56] Using synchronous SGD
[2023-07-01 09:25:56] Synced seed 1234
[2023-07-01 09:25:56] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 09:25:56] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 09:25:56] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 09:25:57] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 09:25:57] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 09:25:57] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 09:25:57] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 09:25:57] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 09:25:57] [comm] Using global sharding
[2023-07-01 09:25:57] [comm] NCCLCommunicators constructed successfully
[2023-07-01 09:25:57] [training] Using 1 GPUs
[2023-07-01 09:25:57] [logits] Applying loss function for 1 factor(s)
[2023-07-01 09:25:57] [memory] Reserving 88 MB, device gpu0
[2023-07-01 09:25:58] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 09:25:58] [memory] Reserving 88 MB, device gpu0
[2023-07-01 09:26:05] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 09:26:06] [valid] No post-processing script given for validating translator
[2023-07-01 09:26:06] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 09:26:06] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 09:26:06] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 09:26:06] [comm] Using global sharding
[2023-07-01 09:26:06] [comm] NCCLCommunicators constructed successfully
[2023-07-01 09:26:06] [training] Using 1 GPUs
[2023-07-01 09:26:06] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 09:26:06] Allocating memory for general optimizer shards
[2023-07-01 09:26:06] [memory] Reserving 88 MB, device gpu0
[2023-07-01 09:26:06] Loading Adam parameters
[2023-07-01 09:26:07] [memory] Reserving 176 MB, device gpu0
[2023-07-01 09:26:07] [memory] Reserving 88 MB, device gpu0
[2023-07-01 09:26:07] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 09:26:07] [data] Restoring the corpus state to epoch 12, batch 2079
[2023-07-01 09:26:07] [data] Shuffling data
[2023-07-01 09:26:07] [data] Done reading 20,192 sentences
[2023-07-01 09:26:07] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 09:26:07] Training started
[2023-07-01 09:26:07] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-07-01 09:26:07] [memory] Reserving 88 MB, device gpu0
[2023-07-01 09:26:07] Parameter type float32, optimization type float32, casting types false
[2023-07-01 09:26:31] Seen 20,073 samples
[2023-07-01 09:26:31] Starting data epoch 13 in logical epoch 13
[2023-07-01 09:26:31] Training finished
[2023-07-01 09:26:34] [valid] Ep. 13 : Up. 2268 : cross-entropy : 167.168 : new best
[2023-07-01 09:32:00] [valid] Ep. 13 : Up. 2268 : translation : 0 : new best
[2023-07-01 09:32:00] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 09:32:01] Saving Adam parameters
[2023-07-01 09:32:02] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 09:32:08] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 09:32:08] [marian] Running on node20.datos.cluster.uy as process 5208 with command line:
[2023-07-01 09:32:08] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 13 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 09:32:08] [config] after: 0e
[2023-07-01 09:32:08] [config] after-batches: 0
[2023-07-01 09:32:08] [config] after-epochs: 13
[2023-07-01 09:32:08] [config] all-caps-every: 0
[2023-07-01 09:32:08] [config] allow-unk: false
[2023-07-01 09:32:08] [config] authors: false
[2023-07-01 09:32:08] [config] beam-size: 12
[2023-07-01 09:32:08] [config] bert-class-symbol: "[CLS]"
[2023-07-01 09:32:08] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 09:32:08] [config] bert-masking-fraction: 0.15
[2023-07-01 09:32:08] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 09:32:08] [config] bert-train-type-embeddings: true
[2023-07-01 09:32:08] [config] bert-type-vocab-size: 2
[2023-07-01 09:32:08] [config] build-info: ""
[2023-07-01 09:32:08] [config] check-gradient-nan: false
[2023-07-01 09:32:08] [config] check-nan: false
[2023-07-01 09:32:08] [config] cite: false
[2023-07-01 09:32:08] [config] clip-norm: 5
[2023-07-01 09:32:08] [config] cost-scaling:
[2023-07-01 09:32:08] [config]   []
[2023-07-01 09:32:08] [config] cost-type: ce-sum
[2023-07-01 09:32:08] [config] cpu-threads: 0
[2023-07-01 09:32:08] [config] data-threads: 8
[2023-07-01 09:32:08] [config] data-weighting: ""
[2023-07-01 09:32:08] [config] data-weighting-type: sentence
[2023-07-01 09:32:08] [config] dec-cell: gru
[2023-07-01 09:32:08] [config] dec-cell-base-depth: 2
[2023-07-01 09:32:08] [config] dec-cell-high-depth: 1
[2023-07-01 09:32:08] [config] dec-depth: 2
[2023-07-01 09:32:08] [config] devices:
[2023-07-01 09:32:08] [config]   - 0
[2023-07-01 09:32:08] [config] dim-emb: 512
[2023-07-01 09:32:08] [config] dim-rnn: 1024
[2023-07-01 09:32:08] [config] dim-vocabs:
[2023-07-01 09:32:08] [config]   - 16384
[2023-07-01 09:32:08] [config]   - 16384
[2023-07-01 09:32:08] [config] disp-first: 0
[2023-07-01 09:32:08] [config] disp-freq: 1000u
[2023-07-01 09:32:08] [config] disp-label-counts: true
[2023-07-01 09:32:08] [config] dropout-rnn: 0
[2023-07-01 09:32:08] [config] dropout-src: 0
[2023-07-01 09:32:08] [config] dropout-trg: 0
[2023-07-01 09:32:08] [config] dump-config: ""
[2023-07-01 09:32:08] [config] dynamic-gradient-scaling:
[2023-07-01 09:32:08] [config]   []
[2023-07-01 09:32:08] [config] early-stopping: 10
[2023-07-01 09:32:08] [config] early-stopping-on: first
[2023-07-01 09:32:08] [config] embedding-fix-src: false
[2023-07-01 09:32:08] [config] embedding-fix-trg: false
[2023-07-01 09:32:08] [config] embedding-normalization: false
[2023-07-01 09:32:08] [config] embedding-vectors:
[2023-07-01 09:32:08] [config]   []
[2023-07-01 09:32:08] [config] enc-cell: gru
[2023-07-01 09:32:08] [config] enc-cell-depth: 1
[2023-07-01 09:32:08] [config] enc-depth: 2
[2023-07-01 09:32:08] [config] enc-type: bidirectional
[2023-07-01 09:32:08] [config] english-title-case-every: 0
[2023-07-01 09:32:08] [config] exponential-smoothing: 0.0001
[2023-07-01 09:32:08] [config] factor-weight: 1
[2023-07-01 09:32:08] [config] factors-combine: sum
[2023-07-01 09:32:08] [config] factors-dim-emb: 0
[2023-07-01 09:32:08] [config] gradient-checkpointing: false
[2023-07-01 09:32:08] [config] gradient-norm-average-window: 100
[2023-07-01 09:32:08] [config] guided-alignment: none
[2023-07-01 09:32:08] [config] guided-alignment-cost: mse
[2023-07-01 09:32:08] [config] guided-alignment-weight: 0.1
[2023-07-01 09:32:08] [config] ignore-model-config: false
[2023-07-01 09:32:08] [config] input-types:
[2023-07-01 09:32:08] [config]   []
[2023-07-01 09:32:08] [config] interpolate-env-vars: false
[2023-07-01 09:32:08] [config] keep-best: false
[2023-07-01 09:32:08] [config] label-smoothing: 0.1
[2023-07-01 09:32:08] [config] layer-normalization: false
[2023-07-01 09:32:08] [config] learn-rate: 0.0003
[2023-07-01 09:32:08] [config] lemma-dependency: ""
[2023-07-01 09:32:08] [config] lemma-dim-emb: 0
[2023-07-01 09:32:08] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 09:32:08] [config] log-level: info
[2023-07-01 09:32:08] [config] log-time-zone: ""
[2023-07-01 09:32:08] [config] logical-epoch:
[2023-07-01 09:32:08] [config]   - 1e
[2023-07-01 09:32:08] [config]   - 0
[2023-07-01 09:32:08] [config] lr-decay: 0
[2023-07-01 09:32:08] [config] lr-decay-freq: 50000
[2023-07-01 09:32:08] [config] lr-decay-inv-sqrt:
[2023-07-01 09:32:08] [config]   - 16000
[2023-07-01 09:32:08] [config] lr-decay-repeat-warmup: false
[2023-07-01 09:32:08] [config] lr-decay-reset-optimizer: false
[2023-07-01 09:32:08] [config] lr-decay-start:
[2023-07-01 09:32:08] [config]   - 10
[2023-07-01 09:32:08] [config]   - 1
[2023-07-01 09:32:08] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 09:32:08] [config] lr-report: true
[2023-07-01 09:32:08] [config] lr-warmup: 16000
[2023-07-01 09:32:08] [config] lr-warmup-at-reload: false
[2023-07-01 09:32:08] [config] lr-warmup-cycle: false
[2023-07-01 09:32:08] [config] lr-warmup-start-rate: 0
[2023-07-01 09:32:08] [config] max-length: 100
[2023-07-01 09:32:08] [config] max-length-crop: false
[2023-07-01 09:32:08] [config] max-length-factor: 3
[2023-07-01 09:32:08] [config] maxi-batch: 100
[2023-07-01 09:32:08] [config] maxi-batch-sort: trg
[2023-07-01 09:32:08] [config] mini-batch: 1000
[2023-07-01 09:32:08] [config] mini-batch-fit: true
[2023-07-01 09:32:08] [config] mini-batch-fit-step: 10
[2023-07-01 09:32:08] [config] mini-batch-round-up: true
[2023-07-01 09:32:08] [config] mini-batch-track-lr: false
[2023-07-01 09:32:08] [config] mini-batch-warmup: 0
[2023-07-01 09:32:08] [config] mini-batch-words: 0
[2023-07-01 09:32:08] [config] mini-batch-words-ref: 0
[2023-07-01 09:32:08] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 09:32:08] [config] multi-loss-type: sum
[2023-07-01 09:32:08] [config] n-best: false
[2023-07-01 09:32:08] [config] no-nccl: false
[2023-07-01 09:32:08] [config] no-reload: false
[2023-07-01 09:32:08] [config] no-restore-corpus: false
[2023-07-01 09:32:08] [config] normalize: 1
[2023-07-01 09:32:08] [config] normalize-gradient: false
[2023-07-01 09:32:08] [config] num-devices: 0
[2023-07-01 09:32:08] [config] optimizer: adam
[2023-07-01 09:32:08] [config] optimizer-delay: 1
[2023-07-01 09:32:08] [config] optimizer-params:
[2023-07-01 09:32:08] [config]   - 0.9
[2023-07-01 09:32:08] [config]   - 0.98
[2023-07-01 09:32:08] [config]   - 1e-09
[2023-07-01 09:32:08] [config] output-omit-bias: false
[2023-07-01 09:32:08] [config] overwrite: true
[2023-07-01 09:32:08] [config] precision:
[2023-07-01 09:32:08] [config]   - float32
[2023-07-01 09:32:08] [config]   - float32
[2023-07-01 09:32:08] [config] pretrained-model: ""
[2023-07-01 09:32:08] [config] quantize-biases: false
[2023-07-01 09:32:08] [config] quantize-bits: 0
[2023-07-01 09:32:08] [config] quantize-log-based: false
[2023-07-01 09:32:08] [config] quantize-optimization-steps: 0
[2023-07-01 09:32:08] [config] quiet: false
[2023-07-01 09:32:08] [config] quiet-translation: true
[2023-07-01 09:32:08] [config] relative-paths: false
[2023-07-01 09:32:08] [config] right-left: false
[2023-07-01 09:32:08] [config] save-freq: 10000u
[2023-07-01 09:32:08] [config] seed: 1234
[2023-07-01 09:32:08] [config] sentencepiece-alphas:
[2023-07-01 09:32:08] [config]   []
[2023-07-01 09:32:08] [config] sentencepiece-max-lines: 2000000
[2023-07-01 09:32:08] [config] sentencepiece-options: ""
[2023-07-01 09:32:08] [config] sharding: global
[2023-07-01 09:32:08] [config] shuffle: data
[2023-07-01 09:32:08] [config] shuffle-in-ram: false
[2023-07-01 09:32:08] [config] sigterm: save-and-exit
[2023-07-01 09:32:08] [config] skip: false
[2023-07-01 09:32:08] [config] sqlite: ""
[2023-07-01 09:32:08] [config] sqlite-drop: false
[2023-07-01 09:32:08] [config] sync-freq: 200u
[2023-07-01 09:32:08] [config] sync-sgd: true
[2023-07-01 09:32:08] [config] tempdir: /tmp
[2023-07-01 09:32:08] [config] tied-embeddings: false
[2023-07-01 09:32:08] [config] tied-embeddings-all: true
[2023-07-01 09:32:08] [config] tied-embeddings-src: false
[2023-07-01 09:32:08] [config] train-embedder-rank:
[2023-07-01 09:32:08] [config]   []
[2023-07-01 09:32:08] [config] train-sets:
[2023-07-01 09:32:08] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 09:32:08] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 09:32:08] [config] transformer-aan-activation: swish
[2023-07-01 09:32:08] [config] transformer-aan-depth: 2
[2023-07-01 09:32:08] [config] transformer-aan-nogate: false
[2023-07-01 09:32:08] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 09:32:08] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 09:32:08] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 09:32:08] [config] transformer-depth-scaling: false
[2023-07-01 09:32:08] [config] transformer-dim-aan: 2048
[2023-07-01 09:32:08] [config] transformer-dim-ffn: 2048
[2023-07-01 09:32:08] [config] transformer-dropout: 0.1
[2023-07-01 09:32:08] [config] transformer-dropout-attention: 0
[2023-07-01 09:32:08] [config] transformer-dropout-ffn: 0
[2023-07-01 09:32:08] [config] transformer-ffn-activation: swish
[2023-07-01 09:32:08] [config] transformer-ffn-depth: 2
[2023-07-01 09:32:08] [config] transformer-guided-alignment-layer: last
[2023-07-01 09:32:08] [config] transformer-heads: 8
[2023-07-01 09:32:08] [config] transformer-no-projection: false
[2023-07-01 09:32:08] [config] transformer-pool: false
[2023-07-01 09:32:08] [config] transformer-postprocess: dan
[2023-07-01 09:32:08] [config] transformer-postprocess-emb: d
[2023-07-01 09:32:08] [config] transformer-postprocess-top: ""
[2023-07-01 09:32:08] [config] transformer-preprocess: ""
[2023-07-01 09:32:08] [config] transformer-tied-layers:
[2023-07-01 09:32:08] [config]   []
[2023-07-01 09:32:08] [config] transformer-train-position-embeddings: false
[2023-07-01 09:32:08] [config] tsv: false
[2023-07-01 09:32:08] [config] tsv-fields: 0
[2023-07-01 09:32:08] [config] type: transformer
[2023-07-01 09:32:08] [config] ulr: false
[2023-07-01 09:32:08] [config] ulr-dim-emb: 0
[2023-07-01 09:32:08] [config] ulr-dropout: 0
[2023-07-01 09:32:08] [config] ulr-keys-vectors: ""
[2023-07-01 09:32:08] [config] ulr-query-vectors: ""
[2023-07-01 09:32:08] [config] ulr-softmax-temperature: 1
[2023-07-01 09:32:08] [config] ulr-trainable-transformation: false
[2023-07-01 09:32:08] [config] unlikelihood-loss: false
[2023-07-01 09:32:08] [config] valid-freq: 50000000
[2023-07-01 09:32:08] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 09:32:08] [config] valid-max-length: 1000
[2023-07-01 09:32:08] [config] valid-metrics:
[2023-07-01 09:32:08] [config]   - cross-entropy
[2023-07-01 09:32:08] [config]   - translation
[2023-07-01 09:32:08] [config] valid-mini-batch: 64
[2023-07-01 09:32:08] [config] valid-reset-stalled: false
[2023-07-01 09:32:08] [config] valid-script-args:
[2023-07-01 09:32:08] [config]   []
[2023-07-01 09:32:08] [config] valid-script-path: ""
[2023-07-01 09:32:08] [config] valid-sets:
[2023-07-01 09:32:08] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 09:32:08] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 09:32:08] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 09:32:08] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 09:32:08] [config] vocabs:
[2023-07-01 09:32:08] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 09:32:08] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 09:32:08] [config] word-penalty: 0
[2023-07-01 09:32:08] [config] word-scores: false
[2023-07-01 09:32:08] [config] workspace: 2048
[2023-07-01 09:32:08] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 09:32:08] Using synchronous SGD
[2023-07-01 09:32:09] Synced seed 1234
[2023-07-01 09:32:09] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 09:32:09] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 09:32:09] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 09:32:09] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 09:32:09] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 09:32:09] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 09:32:09] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 09:32:10] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 09:32:10] [comm] Using global sharding
[2023-07-01 09:32:10] [comm] NCCLCommunicators constructed successfully
[2023-07-01 09:32:10] [training] Using 1 GPUs
[2023-07-01 09:32:10] [logits] Applying loss function for 1 factor(s)
[2023-07-01 09:32:10] [memory] Reserving 88 MB, device gpu0
[2023-07-01 09:32:10] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 09:32:10] [memory] Reserving 88 MB, device gpu0
[2023-07-01 09:32:18] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 09:32:18] [valid] No post-processing script given for validating translator
[2023-07-01 09:32:18] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 09:32:18] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 09:32:18] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 09:32:18] [comm] Using global sharding
[2023-07-01 09:32:18] [comm] NCCLCommunicators constructed successfully
[2023-07-01 09:32:18] [training] Using 1 GPUs
[2023-07-01 09:32:18] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 09:32:19] Allocating memory for general optimizer shards
[2023-07-01 09:32:19] [memory] Reserving 88 MB, device gpu0
[2023-07-01 09:32:19] Loading Adam parameters
[2023-07-01 09:32:19] [memory] Reserving 176 MB, device gpu0
[2023-07-01 09:32:19] [memory] Reserving 88 MB, device gpu0
[2023-07-01 09:32:19] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 09:32:19] [data] Restoring the corpus state to epoch 13, batch 2268
[2023-07-01 09:32:19] [data] Shuffling data
[2023-07-01 09:32:19] [data] Done reading 20,192 sentences
[2023-07-01 09:32:19] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 09:32:19] Training started
[2023-07-01 09:32:19] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-07-01 09:32:19] [memory] Reserving 88 MB, device gpu0
[2023-07-01 09:32:19] Parameter type float32, optimization type float32, casting types false
[2023-07-01 09:32:43] Seen 20,073 samples
[2023-07-01 09:32:43] Starting data epoch 14 in logical epoch 14
[2023-07-01 09:32:43] Training finished
[2023-07-01 09:32:46] [valid] Ep. 14 : Up. 2457 : cross-entropy : 164.232 : new best
[2023-07-01 09:37:27] [valid] Ep. 14 : Up. 2457 : translation : 0 : new best
[2023-07-01 09:37:27] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 09:37:28] Saving Adam parameters
[2023-07-01 09:37:28] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 09:37:34] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 09:37:34] [marian] Running on node20.datos.cluster.uy as process 5854 with command line:
[2023-07-01 09:37:34] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 14 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 09:37:34] [config] after: 0e
[2023-07-01 09:37:34] [config] after-batches: 0
[2023-07-01 09:37:34] [config] after-epochs: 14
[2023-07-01 09:37:34] [config] all-caps-every: 0
[2023-07-01 09:37:34] [config] allow-unk: false
[2023-07-01 09:37:34] [config] authors: false
[2023-07-01 09:37:34] [config] beam-size: 12
[2023-07-01 09:37:34] [config] bert-class-symbol: "[CLS]"
[2023-07-01 09:37:34] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 09:37:34] [config] bert-masking-fraction: 0.15
[2023-07-01 09:37:34] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 09:37:34] [config] bert-train-type-embeddings: true
[2023-07-01 09:37:34] [config] bert-type-vocab-size: 2
[2023-07-01 09:37:34] [config] build-info: ""
[2023-07-01 09:37:34] [config] check-gradient-nan: false
[2023-07-01 09:37:34] [config] check-nan: false
[2023-07-01 09:37:34] [config] cite: false
[2023-07-01 09:37:34] [config] clip-norm: 5
[2023-07-01 09:37:34] [config] cost-scaling:
[2023-07-01 09:37:34] [config]   []
[2023-07-01 09:37:34] [config] cost-type: ce-sum
[2023-07-01 09:37:34] [config] cpu-threads: 0
[2023-07-01 09:37:34] [config] data-threads: 8
[2023-07-01 09:37:34] [config] data-weighting: ""
[2023-07-01 09:37:34] [config] data-weighting-type: sentence
[2023-07-01 09:37:34] [config] dec-cell: gru
[2023-07-01 09:37:34] [config] dec-cell-base-depth: 2
[2023-07-01 09:37:34] [config] dec-cell-high-depth: 1
[2023-07-01 09:37:34] [config] dec-depth: 2
[2023-07-01 09:37:34] [config] devices:
[2023-07-01 09:37:34] [config]   - 0
[2023-07-01 09:37:34] [config] dim-emb: 512
[2023-07-01 09:37:34] [config] dim-rnn: 1024
[2023-07-01 09:37:34] [config] dim-vocabs:
[2023-07-01 09:37:34] [config]   - 16384
[2023-07-01 09:37:34] [config]   - 16384
[2023-07-01 09:37:34] [config] disp-first: 0
[2023-07-01 09:37:34] [config] disp-freq: 1000u
[2023-07-01 09:37:34] [config] disp-label-counts: true
[2023-07-01 09:37:34] [config] dropout-rnn: 0
[2023-07-01 09:37:34] [config] dropout-src: 0
[2023-07-01 09:37:34] [config] dropout-trg: 0
[2023-07-01 09:37:34] [config] dump-config: ""
[2023-07-01 09:37:34] [config] dynamic-gradient-scaling:
[2023-07-01 09:37:34] [config]   []
[2023-07-01 09:37:34] [config] early-stopping: 10
[2023-07-01 09:37:34] [config] early-stopping-on: first
[2023-07-01 09:37:34] [config] embedding-fix-src: false
[2023-07-01 09:37:34] [config] embedding-fix-trg: false
[2023-07-01 09:37:34] [config] embedding-normalization: false
[2023-07-01 09:37:34] [config] embedding-vectors:
[2023-07-01 09:37:34] [config]   []
[2023-07-01 09:37:34] [config] enc-cell: gru
[2023-07-01 09:37:34] [config] enc-cell-depth: 1
[2023-07-01 09:37:34] [config] enc-depth: 2
[2023-07-01 09:37:34] [config] enc-type: bidirectional
[2023-07-01 09:37:34] [config] english-title-case-every: 0
[2023-07-01 09:37:34] [config] exponential-smoothing: 0.0001
[2023-07-01 09:37:34] [config] factor-weight: 1
[2023-07-01 09:37:34] [config] factors-combine: sum
[2023-07-01 09:37:34] [config] factors-dim-emb: 0
[2023-07-01 09:37:34] [config] gradient-checkpointing: false
[2023-07-01 09:37:34] [config] gradient-norm-average-window: 100
[2023-07-01 09:37:34] [config] guided-alignment: none
[2023-07-01 09:37:34] [config] guided-alignment-cost: mse
[2023-07-01 09:37:34] [config] guided-alignment-weight: 0.1
[2023-07-01 09:37:34] [config] ignore-model-config: false
[2023-07-01 09:37:34] [config] input-types:
[2023-07-01 09:37:34] [config]   []
[2023-07-01 09:37:34] [config] interpolate-env-vars: false
[2023-07-01 09:37:34] [config] keep-best: false
[2023-07-01 09:37:34] [config] label-smoothing: 0.1
[2023-07-01 09:37:34] [config] layer-normalization: false
[2023-07-01 09:37:34] [config] learn-rate: 0.0003
[2023-07-01 09:37:34] [config] lemma-dependency: ""
[2023-07-01 09:37:34] [config] lemma-dim-emb: 0
[2023-07-01 09:37:34] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 09:37:34] [config] log-level: info
[2023-07-01 09:37:34] [config] log-time-zone: ""
[2023-07-01 09:37:34] [config] logical-epoch:
[2023-07-01 09:37:34] [config]   - 1e
[2023-07-01 09:37:34] [config]   - 0
[2023-07-01 09:37:34] [config] lr-decay: 0
[2023-07-01 09:37:34] [config] lr-decay-freq: 50000
[2023-07-01 09:37:34] [config] lr-decay-inv-sqrt:
[2023-07-01 09:37:34] [config]   - 16000
[2023-07-01 09:37:34] [config] lr-decay-repeat-warmup: false
[2023-07-01 09:37:34] [config] lr-decay-reset-optimizer: false
[2023-07-01 09:37:34] [config] lr-decay-start:
[2023-07-01 09:37:34] [config]   - 10
[2023-07-01 09:37:34] [config]   - 1
[2023-07-01 09:37:34] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 09:37:34] [config] lr-report: true
[2023-07-01 09:37:34] [config] lr-warmup: 16000
[2023-07-01 09:37:34] [config] lr-warmup-at-reload: false
[2023-07-01 09:37:34] [config] lr-warmup-cycle: false
[2023-07-01 09:37:34] [config] lr-warmup-start-rate: 0
[2023-07-01 09:37:34] [config] max-length: 100
[2023-07-01 09:37:34] [config] max-length-crop: false
[2023-07-01 09:37:34] [config] max-length-factor: 3
[2023-07-01 09:37:34] [config] maxi-batch: 100
[2023-07-01 09:37:34] [config] maxi-batch-sort: trg
[2023-07-01 09:37:34] [config] mini-batch: 1000
[2023-07-01 09:37:34] [config] mini-batch-fit: true
[2023-07-01 09:37:34] [config] mini-batch-fit-step: 10
[2023-07-01 09:37:34] [config] mini-batch-round-up: true
[2023-07-01 09:37:34] [config] mini-batch-track-lr: false
[2023-07-01 09:37:34] [config] mini-batch-warmup: 0
[2023-07-01 09:37:34] [config] mini-batch-words: 0
[2023-07-01 09:37:34] [config] mini-batch-words-ref: 0
[2023-07-01 09:37:34] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 09:37:34] [config] multi-loss-type: sum
[2023-07-01 09:37:34] [config] n-best: false
[2023-07-01 09:37:34] [config] no-nccl: false
[2023-07-01 09:37:34] [config] no-reload: false
[2023-07-01 09:37:34] [config] no-restore-corpus: false
[2023-07-01 09:37:34] [config] normalize: 1
[2023-07-01 09:37:34] [config] normalize-gradient: false
[2023-07-01 09:37:34] [config] num-devices: 0
[2023-07-01 09:37:34] [config] optimizer: adam
[2023-07-01 09:37:34] [config] optimizer-delay: 1
[2023-07-01 09:37:34] [config] optimizer-params:
[2023-07-01 09:37:34] [config]   - 0.9
[2023-07-01 09:37:34] [config]   - 0.98
[2023-07-01 09:37:34] [config]   - 1e-09
[2023-07-01 09:37:34] [config] output-omit-bias: false
[2023-07-01 09:37:34] [config] overwrite: true
[2023-07-01 09:37:34] [config] precision:
[2023-07-01 09:37:34] [config]   - float32
[2023-07-01 09:37:34] [config]   - float32
[2023-07-01 09:37:34] [config] pretrained-model: ""
[2023-07-01 09:37:34] [config] quantize-biases: false
[2023-07-01 09:37:34] [config] quantize-bits: 0
[2023-07-01 09:37:34] [config] quantize-log-based: false
[2023-07-01 09:37:34] [config] quantize-optimization-steps: 0
[2023-07-01 09:37:34] [config] quiet: false
[2023-07-01 09:37:34] [config] quiet-translation: true
[2023-07-01 09:37:34] [config] relative-paths: false
[2023-07-01 09:37:34] [config] right-left: false
[2023-07-01 09:37:34] [config] save-freq: 10000u
[2023-07-01 09:37:34] [config] seed: 1234
[2023-07-01 09:37:34] [config] sentencepiece-alphas:
[2023-07-01 09:37:34] [config]   []
[2023-07-01 09:37:34] [config] sentencepiece-max-lines: 2000000
[2023-07-01 09:37:34] [config] sentencepiece-options: ""
[2023-07-01 09:37:34] [config] sharding: global
[2023-07-01 09:37:34] [config] shuffle: data
[2023-07-01 09:37:34] [config] shuffle-in-ram: false
[2023-07-01 09:37:34] [config] sigterm: save-and-exit
[2023-07-01 09:37:34] [config] skip: false
[2023-07-01 09:37:34] [config] sqlite: ""
[2023-07-01 09:37:34] [config] sqlite-drop: false
[2023-07-01 09:37:34] [config] sync-freq: 200u
[2023-07-01 09:37:34] [config] sync-sgd: true
[2023-07-01 09:37:34] [config] tempdir: /tmp
[2023-07-01 09:37:34] [config] tied-embeddings: false
[2023-07-01 09:37:34] [config] tied-embeddings-all: true
[2023-07-01 09:37:34] [config] tied-embeddings-src: false
[2023-07-01 09:37:34] [config] train-embedder-rank:
[2023-07-01 09:37:34] [config]   []
[2023-07-01 09:37:34] [config] train-sets:
[2023-07-01 09:37:34] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 09:37:34] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 09:37:34] [config] transformer-aan-activation: swish
[2023-07-01 09:37:34] [config] transformer-aan-depth: 2
[2023-07-01 09:37:34] [config] transformer-aan-nogate: false
[2023-07-01 09:37:34] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 09:37:34] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 09:37:34] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 09:37:34] [config] transformer-depth-scaling: false
[2023-07-01 09:37:34] [config] transformer-dim-aan: 2048
[2023-07-01 09:37:34] [config] transformer-dim-ffn: 2048
[2023-07-01 09:37:34] [config] transformer-dropout: 0.1
[2023-07-01 09:37:34] [config] transformer-dropout-attention: 0
[2023-07-01 09:37:34] [config] transformer-dropout-ffn: 0
[2023-07-01 09:37:34] [config] transformer-ffn-activation: swish
[2023-07-01 09:37:34] [config] transformer-ffn-depth: 2
[2023-07-01 09:37:34] [config] transformer-guided-alignment-layer: last
[2023-07-01 09:37:34] [config] transformer-heads: 8
[2023-07-01 09:37:34] [config] transformer-no-projection: false
[2023-07-01 09:37:34] [config] transformer-pool: false
[2023-07-01 09:37:34] [config] transformer-postprocess: dan
[2023-07-01 09:37:34] [config] transformer-postprocess-emb: d
[2023-07-01 09:37:34] [config] transformer-postprocess-top: ""
[2023-07-01 09:37:34] [config] transformer-preprocess: ""
[2023-07-01 09:37:34] [config] transformer-tied-layers:
[2023-07-01 09:37:34] [config]   []
[2023-07-01 09:37:34] [config] transformer-train-position-embeddings: false
[2023-07-01 09:37:34] [config] tsv: false
[2023-07-01 09:37:34] [config] tsv-fields: 0
[2023-07-01 09:37:34] [config] type: transformer
[2023-07-01 09:37:34] [config] ulr: false
[2023-07-01 09:37:34] [config] ulr-dim-emb: 0
[2023-07-01 09:37:34] [config] ulr-dropout: 0
[2023-07-01 09:37:34] [config] ulr-keys-vectors: ""
[2023-07-01 09:37:34] [config] ulr-query-vectors: ""
[2023-07-01 09:37:34] [config] ulr-softmax-temperature: 1
[2023-07-01 09:37:34] [config] ulr-trainable-transformation: false
[2023-07-01 09:37:34] [config] unlikelihood-loss: false
[2023-07-01 09:37:34] [config] valid-freq: 50000000
[2023-07-01 09:37:34] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 09:37:34] [config] valid-max-length: 1000
[2023-07-01 09:37:34] [config] valid-metrics:
[2023-07-01 09:37:34] [config]   - cross-entropy
[2023-07-01 09:37:34] [config]   - translation
[2023-07-01 09:37:34] [config] valid-mini-batch: 64
[2023-07-01 09:37:34] [config] valid-reset-stalled: false
[2023-07-01 09:37:34] [config] valid-script-args:
[2023-07-01 09:37:34] [config]   []
[2023-07-01 09:37:34] [config] valid-script-path: ""
[2023-07-01 09:37:34] [config] valid-sets:
[2023-07-01 09:37:34] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 09:37:34] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 09:37:34] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 09:37:34] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 09:37:34] [config] vocabs:
[2023-07-01 09:37:34] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 09:37:34] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 09:37:34] [config] word-penalty: 0
[2023-07-01 09:37:34] [config] word-scores: false
[2023-07-01 09:37:34] [config] workspace: 2048
[2023-07-01 09:37:34] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 09:37:34] Using synchronous SGD
[2023-07-01 09:37:35] Synced seed 1234
[2023-07-01 09:37:35] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 09:37:35] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 09:37:35] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 09:37:35] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 09:37:35] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 09:37:35] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 09:37:36] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 09:37:36] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 09:37:36] [comm] Using global sharding
[2023-07-01 09:37:36] [comm] NCCLCommunicators constructed successfully
[2023-07-01 09:37:36] [training] Using 1 GPUs
[2023-07-01 09:37:36] [logits] Applying loss function for 1 factor(s)
[2023-07-01 09:37:36] [memory] Reserving 88 MB, device gpu0
[2023-07-01 09:37:36] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 09:37:36] [memory] Reserving 88 MB, device gpu0
[2023-07-01 09:37:44] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 09:37:44] [valid] No post-processing script given for validating translator
[2023-07-01 09:37:44] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 09:37:44] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 09:37:44] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 09:37:44] [comm] Using global sharding
[2023-07-01 09:37:44] [comm] NCCLCommunicators constructed successfully
[2023-07-01 09:37:44] [training] Using 1 GPUs
[2023-07-01 09:37:44] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 09:37:45] Allocating memory for general optimizer shards
[2023-07-01 09:37:45] [memory] Reserving 88 MB, device gpu0
[2023-07-01 09:37:45] Loading Adam parameters
[2023-07-01 09:37:45] [memory] Reserving 176 MB, device gpu0
[2023-07-01 09:37:45] [memory] Reserving 88 MB, device gpu0
[2023-07-01 09:37:45] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 09:37:45] [data] Restoring the corpus state to epoch 14, batch 2457
[2023-07-01 09:37:45] [data] Shuffling data
[2023-07-01 09:37:45] [data] Done reading 20,192 sentences
[2023-07-01 09:37:45] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 09:37:45] Training started
[2023-07-01 09:37:45] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-07-01 09:37:45] [memory] Reserving 88 MB, device gpu0
[2023-07-01 09:37:45] Parameter type float32, optimization type float32, casting types false
[2023-07-01 09:38:09] Seen 20,073 samples
[2023-07-01 09:38:09] Starting data epoch 15 in logical epoch 15
[2023-07-01 09:38:09] Training finished
[2023-07-01 09:38:12] [valid] Ep. 15 : Up. 2646 : cross-entropy : 161.398 : new best
[2023-07-01 09:42:43] [valid] Ep. 15 : Up. 2646 : translation : 0 : new best
[2023-07-01 09:42:43] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 09:42:44] Saving Adam parameters
[2023-07-01 09:42:45] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 09:42:51] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 09:42:51] [marian] Running on node20.datos.cluster.uy as process 6180 with command line:
[2023-07-01 09:42:51] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 15 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 09:42:51] [config] after: 0e
[2023-07-01 09:42:51] [config] after-batches: 0
[2023-07-01 09:42:51] [config] after-epochs: 15
[2023-07-01 09:42:51] [config] all-caps-every: 0
[2023-07-01 09:42:51] [config] allow-unk: false
[2023-07-01 09:42:51] [config] authors: false
[2023-07-01 09:42:51] [config] beam-size: 12
[2023-07-01 09:42:51] [config] bert-class-symbol: "[CLS]"
[2023-07-01 09:42:51] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 09:42:51] [config] bert-masking-fraction: 0.15
[2023-07-01 09:42:51] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 09:42:51] [config] bert-train-type-embeddings: true
[2023-07-01 09:42:51] [config] bert-type-vocab-size: 2
[2023-07-01 09:42:51] [config] build-info: ""
[2023-07-01 09:42:51] [config] check-gradient-nan: false
[2023-07-01 09:42:51] [config] check-nan: false
[2023-07-01 09:42:51] [config] cite: false
[2023-07-01 09:42:51] [config] clip-norm: 5
[2023-07-01 09:42:51] [config] cost-scaling:
[2023-07-01 09:42:51] [config]   []
[2023-07-01 09:42:51] [config] cost-type: ce-sum
[2023-07-01 09:42:51] [config] cpu-threads: 0
[2023-07-01 09:42:51] [config] data-threads: 8
[2023-07-01 09:42:51] [config] data-weighting: ""
[2023-07-01 09:42:51] [config] data-weighting-type: sentence
[2023-07-01 09:42:51] [config] dec-cell: gru
[2023-07-01 09:42:51] [config] dec-cell-base-depth: 2
[2023-07-01 09:42:51] [config] dec-cell-high-depth: 1
[2023-07-01 09:42:51] [config] dec-depth: 2
[2023-07-01 09:42:51] [config] devices:
[2023-07-01 09:42:51] [config]   - 0
[2023-07-01 09:42:51] [config] dim-emb: 512
[2023-07-01 09:42:51] [config] dim-rnn: 1024
[2023-07-01 09:42:51] [config] dim-vocabs:
[2023-07-01 09:42:51] [config]   - 16384
[2023-07-01 09:42:51] [config]   - 16384
[2023-07-01 09:42:51] [config] disp-first: 0
[2023-07-01 09:42:51] [config] disp-freq: 1000u
[2023-07-01 09:42:51] [config] disp-label-counts: true
[2023-07-01 09:42:51] [config] dropout-rnn: 0
[2023-07-01 09:42:51] [config] dropout-src: 0
[2023-07-01 09:42:51] [config] dropout-trg: 0
[2023-07-01 09:42:51] [config] dump-config: ""
[2023-07-01 09:42:51] [config] dynamic-gradient-scaling:
[2023-07-01 09:42:51] [config]   []
[2023-07-01 09:42:51] [config] early-stopping: 10
[2023-07-01 09:42:51] [config] early-stopping-on: first
[2023-07-01 09:42:51] [config] embedding-fix-src: false
[2023-07-01 09:42:51] [config] embedding-fix-trg: false
[2023-07-01 09:42:51] [config] embedding-normalization: false
[2023-07-01 09:42:51] [config] embedding-vectors:
[2023-07-01 09:42:51] [config]   []
[2023-07-01 09:42:51] [config] enc-cell: gru
[2023-07-01 09:42:51] [config] enc-cell-depth: 1
[2023-07-01 09:42:51] [config] enc-depth: 2
[2023-07-01 09:42:51] [config] enc-type: bidirectional
[2023-07-01 09:42:51] [config] english-title-case-every: 0
[2023-07-01 09:42:51] [config] exponential-smoothing: 0.0001
[2023-07-01 09:42:51] [config] factor-weight: 1
[2023-07-01 09:42:51] [config] factors-combine: sum
[2023-07-01 09:42:51] [config] factors-dim-emb: 0
[2023-07-01 09:42:51] [config] gradient-checkpointing: false
[2023-07-01 09:42:51] [config] gradient-norm-average-window: 100
[2023-07-01 09:42:51] [config] guided-alignment: none
[2023-07-01 09:42:51] [config] guided-alignment-cost: mse
[2023-07-01 09:42:51] [config] guided-alignment-weight: 0.1
[2023-07-01 09:42:51] [config] ignore-model-config: false
[2023-07-01 09:42:51] [config] input-types:
[2023-07-01 09:42:51] [config]   []
[2023-07-01 09:42:51] [config] interpolate-env-vars: false
[2023-07-01 09:42:51] [config] keep-best: false
[2023-07-01 09:42:51] [config] label-smoothing: 0.1
[2023-07-01 09:42:51] [config] layer-normalization: false
[2023-07-01 09:42:51] [config] learn-rate: 0.0003
[2023-07-01 09:42:51] [config] lemma-dependency: ""
[2023-07-01 09:42:51] [config] lemma-dim-emb: 0
[2023-07-01 09:42:51] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 09:42:51] [config] log-level: info
[2023-07-01 09:42:51] [config] log-time-zone: ""
[2023-07-01 09:42:51] [config] logical-epoch:
[2023-07-01 09:42:51] [config]   - 1e
[2023-07-01 09:42:51] [config]   - 0
[2023-07-01 09:42:51] [config] lr-decay: 0
[2023-07-01 09:42:51] [config] lr-decay-freq: 50000
[2023-07-01 09:42:51] [config] lr-decay-inv-sqrt:
[2023-07-01 09:42:51] [config]   - 16000
[2023-07-01 09:42:51] [config] lr-decay-repeat-warmup: false
[2023-07-01 09:42:51] [config] lr-decay-reset-optimizer: false
[2023-07-01 09:42:51] [config] lr-decay-start:
[2023-07-01 09:42:51] [config]   - 10
[2023-07-01 09:42:51] [config]   - 1
[2023-07-01 09:42:51] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 09:42:51] [config] lr-report: true
[2023-07-01 09:42:51] [config] lr-warmup: 16000
[2023-07-01 09:42:51] [config] lr-warmup-at-reload: false
[2023-07-01 09:42:51] [config] lr-warmup-cycle: false
[2023-07-01 09:42:51] [config] lr-warmup-start-rate: 0
[2023-07-01 09:42:51] [config] max-length: 100
[2023-07-01 09:42:51] [config] max-length-crop: false
[2023-07-01 09:42:51] [config] max-length-factor: 3
[2023-07-01 09:42:51] [config] maxi-batch: 100
[2023-07-01 09:42:51] [config] maxi-batch-sort: trg
[2023-07-01 09:42:51] [config] mini-batch: 1000
[2023-07-01 09:42:51] [config] mini-batch-fit: true
[2023-07-01 09:42:51] [config] mini-batch-fit-step: 10
[2023-07-01 09:42:51] [config] mini-batch-round-up: true
[2023-07-01 09:42:51] [config] mini-batch-track-lr: false
[2023-07-01 09:42:51] [config] mini-batch-warmup: 0
[2023-07-01 09:42:51] [config] mini-batch-words: 0
[2023-07-01 09:42:51] [config] mini-batch-words-ref: 0
[2023-07-01 09:42:51] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 09:42:51] [config] multi-loss-type: sum
[2023-07-01 09:42:51] [config] n-best: false
[2023-07-01 09:42:51] [config] no-nccl: false
[2023-07-01 09:42:51] [config] no-reload: false
[2023-07-01 09:42:51] [config] no-restore-corpus: false
[2023-07-01 09:42:51] [config] normalize: 1
[2023-07-01 09:42:51] [config] normalize-gradient: false
[2023-07-01 09:42:51] [config] num-devices: 0
[2023-07-01 09:42:51] [config] optimizer: adam
[2023-07-01 09:42:51] [config] optimizer-delay: 1
[2023-07-01 09:42:51] [config] optimizer-params:
[2023-07-01 09:42:51] [config]   - 0.9
[2023-07-01 09:42:51] [config]   - 0.98
[2023-07-01 09:42:51] [config]   - 1e-09
[2023-07-01 09:42:51] [config] output-omit-bias: false
[2023-07-01 09:42:51] [config] overwrite: true
[2023-07-01 09:42:51] [config] precision:
[2023-07-01 09:42:51] [config]   - float32
[2023-07-01 09:42:51] [config]   - float32
[2023-07-01 09:42:51] [config] pretrained-model: ""
[2023-07-01 09:42:51] [config] quantize-biases: false
[2023-07-01 09:42:51] [config] quantize-bits: 0
[2023-07-01 09:42:51] [config] quantize-log-based: false
[2023-07-01 09:42:51] [config] quantize-optimization-steps: 0
[2023-07-01 09:42:51] [config] quiet: false
[2023-07-01 09:42:51] [config] quiet-translation: true
[2023-07-01 09:42:51] [config] relative-paths: false
[2023-07-01 09:42:51] [config] right-left: false
[2023-07-01 09:42:51] [config] save-freq: 10000u
[2023-07-01 09:42:51] [config] seed: 1234
[2023-07-01 09:42:51] [config] sentencepiece-alphas:
[2023-07-01 09:42:51] [config]   []
[2023-07-01 09:42:51] [config] sentencepiece-max-lines: 2000000
[2023-07-01 09:42:51] [config] sentencepiece-options: ""
[2023-07-01 09:42:51] [config] sharding: global
[2023-07-01 09:42:51] [config] shuffle: data
[2023-07-01 09:42:51] [config] shuffle-in-ram: false
[2023-07-01 09:42:51] [config] sigterm: save-and-exit
[2023-07-01 09:42:51] [config] skip: false
[2023-07-01 09:42:51] [config] sqlite: ""
[2023-07-01 09:42:51] [config] sqlite-drop: false
[2023-07-01 09:42:51] [config] sync-freq: 200u
[2023-07-01 09:42:51] [config] sync-sgd: true
[2023-07-01 09:42:51] [config] tempdir: /tmp
[2023-07-01 09:42:51] [config] tied-embeddings: false
[2023-07-01 09:42:51] [config] tied-embeddings-all: true
[2023-07-01 09:42:51] [config] tied-embeddings-src: false
[2023-07-01 09:42:51] [config] train-embedder-rank:
[2023-07-01 09:42:51] [config]   []
[2023-07-01 09:42:51] [config] train-sets:
[2023-07-01 09:42:51] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 09:42:51] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 09:42:51] [config] transformer-aan-activation: swish
[2023-07-01 09:42:51] [config] transformer-aan-depth: 2
[2023-07-01 09:42:51] [config] transformer-aan-nogate: false
[2023-07-01 09:42:51] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 09:42:51] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 09:42:51] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 09:42:51] [config] transformer-depth-scaling: false
[2023-07-01 09:42:51] [config] transformer-dim-aan: 2048
[2023-07-01 09:42:51] [config] transformer-dim-ffn: 2048
[2023-07-01 09:42:51] [config] transformer-dropout: 0.1
[2023-07-01 09:42:51] [config] transformer-dropout-attention: 0
[2023-07-01 09:42:51] [config] transformer-dropout-ffn: 0
[2023-07-01 09:42:51] [config] transformer-ffn-activation: swish
[2023-07-01 09:42:51] [config] transformer-ffn-depth: 2
[2023-07-01 09:42:51] [config] transformer-guided-alignment-layer: last
[2023-07-01 09:42:51] [config] transformer-heads: 8
[2023-07-01 09:42:51] [config] transformer-no-projection: false
[2023-07-01 09:42:51] [config] transformer-pool: false
[2023-07-01 09:42:51] [config] transformer-postprocess: dan
[2023-07-01 09:42:51] [config] transformer-postprocess-emb: d
[2023-07-01 09:42:51] [config] transformer-postprocess-top: ""
[2023-07-01 09:42:51] [config] transformer-preprocess: ""
[2023-07-01 09:42:51] [config] transformer-tied-layers:
[2023-07-01 09:42:51] [config]   []
[2023-07-01 09:42:51] [config] transformer-train-position-embeddings: false
[2023-07-01 09:42:51] [config] tsv: false
[2023-07-01 09:42:51] [config] tsv-fields: 0
[2023-07-01 09:42:51] [config] type: transformer
[2023-07-01 09:42:51] [config] ulr: false
[2023-07-01 09:42:51] [config] ulr-dim-emb: 0
[2023-07-01 09:42:51] [config] ulr-dropout: 0
[2023-07-01 09:42:51] [config] ulr-keys-vectors: ""
[2023-07-01 09:42:51] [config] ulr-query-vectors: ""
[2023-07-01 09:42:51] [config] ulr-softmax-temperature: 1
[2023-07-01 09:42:51] [config] ulr-trainable-transformation: false
[2023-07-01 09:42:51] [config] unlikelihood-loss: false
[2023-07-01 09:42:51] [config] valid-freq: 50000000
[2023-07-01 09:42:51] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 09:42:51] [config] valid-max-length: 1000
[2023-07-01 09:42:51] [config] valid-metrics:
[2023-07-01 09:42:51] [config]   - cross-entropy
[2023-07-01 09:42:51] [config]   - translation
[2023-07-01 09:42:51] [config] valid-mini-batch: 64
[2023-07-01 09:42:51] [config] valid-reset-stalled: false
[2023-07-01 09:42:51] [config] valid-script-args:
[2023-07-01 09:42:51] [config]   []
[2023-07-01 09:42:51] [config] valid-script-path: ""
[2023-07-01 09:42:51] [config] valid-sets:
[2023-07-01 09:42:51] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 09:42:51] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 09:42:51] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 09:42:51] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 09:42:51] [config] vocabs:
[2023-07-01 09:42:51] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 09:42:51] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 09:42:51] [config] word-penalty: 0
[2023-07-01 09:42:51] [config] word-scores: false
[2023-07-01 09:42:51] [config] workspace: 2048
[2023-07-01 09:42:51] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 09:42:51] Using synchronous SGD
[2023-07-01 09:42:52] Synced seed 1234
[2023-07-01 09:42:52] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 09:42:52] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 09:42:52] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 09:42:52] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 09:42:52] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 09:42:52] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 09:42:52] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 09:42:52] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 09:42:52] [comm] Using global sharding
[2023-07-01 09:42:53] [comm] NCCLCommunicators constructed successfully
[2023-07-01 09:42:53] [training] Using 1 GPUs
[2023-07-01 09:42:53] [logits] Applying loss function for 1 factor(s)
[2023-07-01 09:42:53] [memory] Reserving 88 MB, device gpu0
[2023-07-01 09:42:53] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 09:42:53] [memory] Reserving 88 MB, device gpu0
[2023-07-01 09:43:00] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 09:43:00] [valid] No post-processing script given for validating translator
[2023-07-01 09:43:00] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 09:43:00] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 09:43:01] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 09:43:01] [comm] Using global sharding
[2023-07-01 09:43:01] [comm] NCCLCommunicators constructed successfully
[2023-07-01 09:43:01] [training] Using 1 GPUs
[2023-07-01 09:43:01] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 09:43:01] Allocating memory for general optimizer shards
[2023-07-01 09:43:01] [memory] Reserving 88 MB, device gpu0
[2023-07-01 09:43:01] Loading Adam parameters
[2023-07-01 09:43:01] [memory] Reserving 176 MB, device gpu0
[2023-07-01 09:43:02] [memory] Reserving 88 MB, device gpu0
[2023-07-01 09:43:02] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 09:43:02] [data] Restoring the corpus state to epoch 15, batch 2646
[2023-07-01 09:43:02] [data] Shuffling data
[2023-07-01 09:43:02] [data] Done reading 20,192 sentences
[2023-07-01 09:43:02] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 09:43:02] Training started
[2023-07-01 09:43:02] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-07-01 09:43:02] [memory] Reserving 88 MB, device gpu0
[2023-07-01 09:43:02] Parameter type float32, optimization type float32, casting types false
[2023-07-01 09:43:25] Seen 20,073 samples
[2023-07-01 09:43:25] Starting data epoch 16 in logical epoch 16
[2023-07-01 09:43:25] Training finished
[2023-07-01 09:43:28] [valid] Ep. 16 : Up. 2835 : cross-entropy : 158.662 : new best
[2023-07-01 09:47:04] [valid] Ep. 16 : Up. 2835 : translation : 0 : new best
[2023-07-01 09:47:04] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 09:47:05] Saving Adam parameters
[2023-07-01 09:47:05] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 09:47:13] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 09:47:13] [marian] Running on node20.datos.cluster.uy as process 6461 with command line:
[2023-07-01 09:47:13] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 16 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 09:47:13] [config] after: 0e
[2023-07-01 09:47:13] [config] after-batches: 0
[2023-07-01 09:47:13] [config] after-epochs: 16
[2023-07-01 09:47:13] [config] all-caps-every: 0
[2023-07-01 09:47:13] [config] allow-unk: false
[2023-07-01 09:47:13] [config] authors: false
[2023-07-01 09:47:13] [config] beam-size: 12
[2023-07-01 09:47:13] [config] bert-class-symbol: "[CLS]"
[2023-07-01 09:47:13] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 09:47:13] [config] bert-masking-fraction: 0.15
[2023-07-01 09:47:13] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 09:47:13] [config] bert-train-type-embeddings: true
[2023-07-01 09:47:13] [config] bert-type-vocab-size: 2
[2023-07-01 09:47:13] [config] build-info: ""
[2023-07-01 09:47:13] [config] check-gradient-nan: false
[2023-07-01 09:47:13] [config] check-nan: false
[2023-07-01 09:47:13] [config] cite: false
[2023-07-01 09:47:13] [config] clip-norm: 5
[2023-07-01 09:47:13] [config] cost-scaling:
[2023-07-01 09:47:13] [config]   []
[2023-07-01 09:47:13] [config] cost-type: ce-sum
[2023-07-01 09:47:13] [config] cpu-threads: 0
[2023-07-01 09:47:13] [config] data-threads: 8
[2023-07-01 09:47:13] [config] data-weighting: ""
[2023-07-01 09:47:13] [config] data-weighting-type: sentence
[2023-07-01 09:47:13] [config] dec-cell: gru
[2023-07-01 09:47:13] [config] dec-cell-base-depth: 2
[2023-07-01 09:47:13] [config] dec-cell-high-depth: 1
[2023-07-01 09:47:13] [config] dec-depth: 2
[2023-07-01 09:47:13] [config] devices:
[2023-07-01 09:47:13] [config]   - 0
[2023-07-01 09:47:13] [config] dim-emb: 512
[2023-07-01 09:47:13] [config] dim-rnn: 1024
[2023-07-01 09:47:13] [config] dim-vocabs:
[2023-07-01 09:47:13] [config]   - 16384
[2023-07-01 09:47:13] [config]   - 16384
[2023-07-01 09:47:13] [config] disp-first: 0
[2023-07-01 09:47:13] [config] disp-freq: 1000u
[2023-07-01 09:47:13] [config] disp-label-counts: true
[2023-07-01 09:47:13] [config] dropout-rnn: 0
[2023-07-01 09:47:13] [config] dropout-src: 0
[2023-07-01 09:47:13] [config] dropout-trg: 0
[2023-07-01 09:47:13] [config] dump-config: ""
[2023-07-01 09:47:13] [config] dynamic-gradient-scaling:
[2023-07-01 09:47:13] [config]   []
[2023-07-01 09:47:13] [config] early-stopping: 10
[2023-07-01 09:47:13] [config] early-stopping-on: first
[2023-07-01 09:47:13] [config] embedding-fix-src: false
[2023-07-01 09:47:13] [config] embedding-fix-trg: false
[2023-07-01 09:47:13] [config] embedding-normalization: false
[2023-07-01 09:47:13] [config] embedding-vectors:
[2023-07-01 09:47:13] [config]   []
[2023-07-01 09:47:13] [config] enc-cell: gru
[2023-07-01 09:47:13] [config] enc-cell-depth: 1
[2023-07-01 09:47:13] [config] enc-depth: 2
[2023-07-01 09:47:13] [config] enc-type: bidirectional
[2023-07-01 09:47:13] [config] english-title-case-every: 0
[2023-07-01 09:47:13] [config] exponential-smoothing: 0.0001
[2023-07-01 09:47:13] [config] factor-weight: 1
[2023-07-01 09:47:13] [config] factors-combine: sum
[2023-07-01 09:47:13] [config] factors-dim-emb: 0
[2023-07-01 09:47:13] [config] gradient-checkpointing: false
[2023-07-01 09:47:13] [config] gradient-norm-average-window: 100
[2023-07-01 09:47:13] [config] guided-alignment: none
[2023-07-01 09:47:13] [config] guided-alignment-cost: mse
[2023-07-01 09:47:13] [config] guided-alignment-weight: 0.1
[2023-07-01 09:47:13] [config] ignore-model-config: false
[2023-07-01 09:47:13] [config] input-types:
[2023-07-01 09:47:13] [config]   []
[2023-07-01 09:47:13] [config] interpolate-env-vars: false
[2023-07-01 09:47:13] [config] keep-best: false
[2023-07-01 09:47:13] [config] label-smoothing: 0.1
[2023-07-01 09:47:13] [config] layer-normalization: false
[2023-07-01 09:47:13] [config] learn-rate: 0.0003
[2023-07-01 09:47:13] [config] lemma-dependency: ""
[2023-07-01 09:47:13] [config] lemma-dim-emb: 0
[2023-07-01 09:47:13] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 09:47:13] [config] log-level: info
[2023-07-01 09:47:13] [config] log-time-zone: ""
[2023-07-01 09:47:13] [config] logical-epoch:
[2023-07-01 09:47:13] [config]   - 1e
[2023-07-01 09:47:13] [config]   - 0
[2023-07-01 09:47:13] [config] lr-decay: 0
[2023-07-01 09:47:13] [config] lr-decay-freq: 50000
[2023-07-01 09:47:13] [config] lr-decay-inv-sqrt:
[2023-07-01 09:47:13] [config]   - 16000
[2023-07-01 09:47:13] [config] lr-decay-repeat-warmup: false
[2023-07-01 09:47:13] [config] lr-decay-reset-optimizer: false
[2023-07-01 09:47:13] [config] lr-decay-start:
[2023-07-01 09:47:13] [config]   - 10
[2023-07-01 09:47:13] [config]   - 1
[2023-07-01 09:47:13] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 09:47:13] [config] lr-report: true
[2023-07-01 09:47:13] [config] lr-warmup: 16000
[2023-07-01 09:47:13] [config] lr-warmup-at-reload: false
[2023-07-01 09:47:13] [config] lr-warmup-cycle: false
[2023-07-01 09:47:13] [config] lr-warmup-start-rate: 0
[2023-07-01 09:47:13] [config] max-length: 100
[2023-07-01 09:47:13] [config] max-length-crop: false
[2023-07-01 09:47:13] [config] max-length-factor: 3
[2023-07-01 09:47:13] [config] maxi-batch: 100
[2023-07-01 09:47:13] [config] maxi-batch-sort: trg
[2023-07-01 09:47:13] [config] mini-batch: 1000
[2023-07-01 09:47:13] [config] mini-batch-fit: true
[2023-07-01 09:47:13] [config] mini-batch-fit-step: 10
[2023-07-01 09:47:13] [config] mini-batch-round-up: true
[2023-07-01 09:47:13] [config] mini-batch-track-lr: false
[2023-07-01 09:47:13] [config] mini-batch-warmup: 0
[2023-07-01 09:47:13] [config] mini-batch-words: 0
[2023-07-01 09:47:13] [config] mini-batch-words-ref: 0
[2023-07-01 09:47:13] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 09:47:13] [config] multi-loss-type: sum
[2023-07-01 09:47:13] [config] n-best: false
[2023-07-01 09:47:13] [config] no-nccl: false
[2023-07-01 09:47:13] [config] no-reload: false
[2023-07-01 09:47:13] [config] no-restore-corpus: false
[2023-07-01 09:47:13] [config] normalize: 1
[2023-07-01 09:47:13] [config] normalize-gradient: false
[2023-07-01 09:47:13] [config] num-devices: 0
[2023-07-01 09:47:13] [config] optimizer: adam
[2023-07-01 09:47:13] [config] optimizer-delay: 1
[2023-07-01 09:47:13] [config] optimizer-params:
[2023-07-01 09:47:13] [config]   - 0.9
[2023-07-01 09:47:13] [config]   - 0.98
[2023-07-01 09:47:13] [config]   - 1e-09
[2023-07-01 09:47:13] [config] output-omit-bias: false
[2023-07-01 09:47:13] [config] overwrite: true
[2023-07-01 09:47:13] [config] precision:
[2023-07-01 09:47:13] [config]   - float32
[2023-07-01 09:47:13] [config]   - float32
[2023-07-01 09:47:13] [config] pretrained-model: ""
[2023-07-01 09:47:13] [config] quantize-biases: false
[2023-07-01 09:47:13] [config] quantize-bits: 0
[2023-07-01 09:47:13] [config] quantize-log-based: false
[2023-07-01 09:47:13] [config] quantize-optimization-steps: 0
[2023-07-01 09:47:13] [config] quiet: false
[2023-07-01 09:47:13] [config] quiet-translation: true
[2023-07-01 09:47:13] [config] relative-paths: false
[2023-07-01 09:47:13] [config] right-left: false
[2023-07-01 09:47:13] [config] save-freq: 10000u
[2023-07-01 09:47:13] [config] seed: 1234
[2023-07-01 09:47:13] [config] sentencepiece-alphas:
[2023-07-01 09:47:13] [config]   []
[2023-07-01 09:47:13] [config] sentencepiece-max-lines: 2000000
[2023-07-01 09:47:13] [config] sentencepiece-options: ""
[2023-07-01 09:47:13] [config] sharding: global
[2023-07-01 09:47:13] [config] shuffle: data
[2023-07-01 09:47:13] [config] shuffle-in-ram: false
[2023-07-01 09:47:13] [config] sigterm: save-and-exit
[2023-07-01 09:47:13] [config] skip: false
[2023-07-01 09:47:13] [config] sqlite: ""
[2023-07-01 09:47:13] [config] sqlite-drop: false
[2023-07-01 09:47:13] [config] sync-freq: 200u
[2023-07-01 09:47:13] [config] sync-sgd: true
[2023-07-01 09:47:13] [config] tempdir: /tmp
[2023-07-01 09:47:13] [config] tied-embeddings: false
[2023-07-01 09:47:13] [config] tied-embeddings-all: true
[2023-07-01 09:47:13] [config] tied-embeddings-src: false
[2023-07-01 09:47:13] [config] train-embedder-rank:
[2023-07-01 09:47:13] [config]   []
[2023-07-01 09:47:13] [config] train-sets:
[2023-07-01 09:47:13] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 09:47:13] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 09:47:13] [config] transformer-aan-activation: swish
[2023-07-01 09:47:13] [config] transformer-aan-depth: 2
[2023-07-01 09:47:13] [config] transformer-aan-nogate: false
[2023-07-01 09:47:13] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 09:47:13] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 09:47:13] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 09:47:13] [config] transformer-depth-scaling: false
[2023-07-01 09:47:13] [config] transformer-dim-aan: 2048
[2023-07-01 09:47:13] [config] transformer-dim-ffn: 2048
[2023-07-01 09:47:13] [config] transformer-dropout: 0.1
[2023-07-01 09:47:13] [config] transformer-dropout-attention: 0
[2023-07-01 09:47:13] [config] transformer-dropout-ffn: 0
[2023-07-01 09:47:13] [config] transformer-ffn-activation: swish
[2023-07-01 09:47:13] [config] transformer-ffn-depth: 2
[2023-07-01 09:47:13] [config] transformer-guided-alignment-layer: last
[2023-07-01 09:47:13] [config] transformer-heads: 8
[2023-07-01 09:47:13] [config] transformer-no-projection: false
[2023-07-01 09:47:13] [config] transformer-pool: false
[2023-07-01 09:47:13] [config] transformer-postprocess: dan
[2023-07-01 09:47:13] [config] transformer-postprocess-emb: d
[2023-07-01 09:47:13] [config] transformer-postprocess-top: ""
[2023-07-01 09:47:13] [config] transformer-preprocess: ""
[2023-07-01 09:47:13] [config] transformer-tied-layers:
[2023-07-01 09:47:13] [config]   []
[2023-07-01 09:47:13] [config] transformer-train-position-embeddings: false
[2023-07-01 09:47:13] [config] tsv: false
[2023-07-01 09:47:13] [config] tsv-fields: 0
[2023-07-01 09:47:13] [config] type: transformer
[2023-07-01 09:47:13] [config] ulr: false
[2023-07-01 09:47:13] [config] ulr-dim-emb: 0
[2023-07-01 09:47:13] [config] ulr-dropout: 0
[2023-07-01 09:47:13] [config] ulr-keys-vectors: ""
[2023-07-01 09:47:13] [config] ulr-query-vectors: ""
[2023-07-01 09:47:13] [config] ulr-softmax-temperature: 1
[2023-07-01 09:47:13] [config] ulr-trainable-transformation: false
[2023-07-01 09:47:13] [config] unlikelihood-loss: false
[2023-07-01 09:47:13] [config] valid-freq: 50000000
[2023-07-01 09:47:13] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 09:47:13] [config] valid-max-length: 1000
[2023-07-01 09:47:13] [config] valid-metrics:
[2023-07-01 09:47:13] [config]   - cross-entropy
[2023-07-01 09:47:13] [config]   - translation
[2023-07-01 09:47:13] [config] valid-mini-batch: 64
[2023-07-01 09:47:13] [config] valid-reset-stalled: false
[2023-07-01 09:47:13] [config] valid-script-args:
[2023-07-01 09:47:13] [config]   []
[2023-07-01 09:47:13] [config] valid-script-path: ""
[2023-07-01 09:47:13] [config] valid-sets:
[2023-07-01 09:47:13] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 09:47:13] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 09:47:13] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 09:47:13] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 09:47:13] [config] vocabs:
[2023-07-01 09:47:13] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 09:47:13] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 09:47:13] [config] word-penalty: 0
[2023-07-01 09:47:13] [config] word-scores: false
[2023-07-01 09:47:13] [config] workspace: 2048
[2023-07-01 09:47:13] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 09:47:13] Using synchronous SGD
[2023-07-01 09:47:13] Synced seed 1234
[2023-07-01 09:47:13] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 09:47:13] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 09:47:13] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 09:47:13] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 09:47:13] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 09:47:13] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 09:47:14] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 09:47:14] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 09:47:14] [comm] Using global sharding
[2023-07-01 09:47:14] [comm] NCCLCommunicators constructed successfully
[2023-07-01 09:47:14] [training] Using 1 GPUs
[2023-07-01 09:47:14] [logits] Applying loss function for 1 factor(s)
[2023-07-01 09:47:14] [memory] Reserving 88 MB, device gpu0
[2023-07-01 09:47:14] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 09:47:14] [memory] Reserving 88 MB, device gpu0
[2023-07-01 09:47:22] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 09:47:22] [valid] No post-processing script given for validating translator
[2023-07-01 09:47:22] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 09:47:22] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 09:47:22] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 09:47:22] [comm] Using global sharding
[2023-07-01 09:47:22] [comm] NCCLCommunicators constructed successfully
[2023-07-01 09:47:22] [training] Using 1 GPUs
[2023-07-01 09:47:22] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 09:47:23] Allocating memory for general optimizer shards
[2023-07-01 09:47:23] [memory] Reserving 88 MB, device gpu0
[2023-07-01 09:47:23] Loading Adam parameters
[2023-07-01 09:47:23] [memory] Reserving 176 MB, device gpu0
[2023-07-01 09:47:23] [memory] Reserving 88 MB, device gpu0
[2023-07-01 09:47:23] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 09:47:23] [data] Restoring the corpus state to epoch 16, batch 2835
[2023-07-01 09:47:23] [data] Shuffling data
[2023-07-01 09:47:23] [data] Done reading 20,192 sentences
[2023-07-01 09:47:23] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 09:47:23] Training started
[2023-07-01 09:47:23] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-07-01 09:47:23] [memory] Reserving 88 MB, device gpu0
[2023-07-01 09:47:23] Parameter type float32, optimization type float32, casting types false
[2023-07-01 09:47:44] Ep. 16 : Up. 3000 : Sen. 17,559 : Cost 5.92053223 * 3,212,186 @ 2,324 after 9,630,634 : Time 21.73s : 147828.71 words/s : gNorm 1.3990 : L.r. 5.6250e-05
[2023-07-01 09:47:47] Seen 20,073 samples
[2023-07-01 09:47:47] Starting data epoch 17 in logical epoch 17
[2023-07-01 09:47:47] Training finished
[2023-07-01 09:47:50] [valid] Ep. 17 : Up. 3024 : cross-entropy : 156.07 : new best
[2023-07-01 09:51:17] [valid] Ep. 17 : Up. 3024 : translation : 0 : new best
[2023-07-01 09:51:17] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 09:51:18] Saving Adam parameters
[2023-07-01 09:51:19] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 09:51:26] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 09:51:26] [marian] Running on node20.datos.cluster.uy as process 6732 with command line:
[2023-07-01 09:51:26] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 17 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 09:51:26] [config] after: 0e
[2023-07-01 09:51:26] [config] after-batches: 0
[2023-07-01 09:51:26] [config] after-epochs: 17
[2023-07-01 09:51:26] [config] all-caps-every: 0
[2023-07-01 09:51:26] [config] allow-unk: false
[2023-07-01 09:51:26] [config] authors: false
[2023-07-01 09:51:26] [config] beam-size: 12
[2023-07-01 09:51:26] [config] bert-class-symbol: "[CLS]"
[2023-07-01 09:51:26] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 09:51:26] [config] bert-masking-fraction: 0.15
[2023-07-01 09:51:26] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 09:51:26] [config] bert-train-type-embeddings: true
[2023-07-01 09:51:26] [config] bert-type-vocab-size: 2
[2023-07-01 09:51:26] [config] build-info: ""
[2023-07-01 09:51:26] [config] check-gradient-nan: false
[2023-07-01 09:51:26] [config] check-nan: false
[2023-07-01 09:51:26] [config] cite: false
[2023-07-01 09:51:26] [config] clip-norm: 5
[2023-07-01 09:51:26] [config] cost-scaling:
[2023-07-01 09:51:26] [config]   []
[2023-07-01 09:51:26] [config] cost-type: ce-sum
[2023-07-01 09:51:26] [config] cpu-threads: 0
[2023-07-01 09:51:26] [config] data-threads: 8
[2023-07-01 09:51:26] [config] data-weighting: ""
[2023-07-01 09:51:26] [config] data-weighting-type: sentence
[2023-07-01 09:51:26] [config] dec-cell: gru
[2023-07-01 09:51:26] [config] dec-cell-base-depth: 2
[2023-07-01 09:51:26] [config] dec-cell-high-depth: 1
[2023-07-01 09:51:26] [config] dec-depth: 2
[2023-07-01 09:51:26] [config] devices:
[2023-07-01 09:51:26] [config]   - 0
[2023-07-01 09:51:26] [config] dim-emb: 512
[2023-07-01 09:51:26] [config] dim-rnn: 1024
[2023-07-01 09:51:26] [config] dim-vocabs:
[2023-07-01 09:51:26] [config]   - 16384
[2023-07-01 09:51:26] [config]   - 16384
[2023-07-01 09:51:26] [config] disp-first: 0
[2023-07-01 09:51:26] [config] disp-freq: 1000u
[2023-07-01 09:51:26] [config] disp-label-counts: true
[2023-07-01 09:51:26] [config] dropout-rnn: 0
[2023-07-01 09:51:26] [config] dropout-src: 0
[2023-07-01 09:51:26] [config] dropout-trg: 0
[2023-07-01 09:51:26] [config] dump-config: ""
[2023-07-01 09:51:26] [config] dynamic-gradient-scaling:
[2023-07-01 09:51:26] [config]   []
[2023-07-01 09:51:26] [config] early-stopping: 10
[2023-07-01 09:51:26] [config] early-stopping-on: first
[2023-07-01 09:51:26] [config] embedding-fix-src: false
[2023-07-01 09:51:26] [config] embedding-fix-trg: false
[2023-07-01 09:51:26] [config] embedding-normalization: false
[2023-07-01 09:51:26] [config] embedding-vectors:
[2023-07-01 09:51:26] [config]   []
[2023-07-01 09:51:26] [config] enc-cell: gru
[2023-07-01 09:51:26] [config] enc-cell-depth: 1
[2023-07-01 09:51:26] [config] enc-depth: 2
[2023-07-01 09:51:26] [config] enc-type: bidirectional
[2023-07-01 09:51:26] [config] english-title-case-every: 0
[2023-07-01 09:51:26] [config] exponential-smoothing: 0.0001
[2023-07-01 09:51:26] [config] factor-weight: 1
[2023-07-01 09:51:26] [config] factors-combine: sum
[2023-07-01 09:51:26] [config] factors-dim-emb: 0
[2023-07-01 09:51:26] [config] gradient-checkpointing: false
[2023-07-01 09:51:26] [config] gradient-norm-average-window: 100
[2023-07-01 09:51:26] [config] guided-alignment: none
[2023-07-01 09:51:26] [config] guided-alignment-cost: mse
[2023-07-01 09:51:26] [config] guided-alignment-weight: 0.1
[2023-07-01 09:51:26] [config] ignore-model-config: false
[2023-07-01 09:51:26] [config] input-types:
[2023-07-01 09:51:26] [config]   []
[2023-07-01 09:51:26] [config] interpolate-env-vars: false
[2023-07-01 09:51:26] [config] keep-best: false
[2023-07-01 09:51:26] [config] label-smoothing: 0.1
[2023-07-01 09:51:26] [config] layer-normalization: false
[2023-07-01 09:51:26] [config] learn-rate: 0.0003
[2023-07-01 09:51:26] [config] lemma-dependency: ""
[2023-07-01 09:51:26] [config] lemma-dim-emb: 0
[2023-07-01 09:51:26] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 09:51:26] [config] log-level: info
[2023-07-01 09:51:26] [config] log-time-zone: ""
[2023-07-01 09:51:26] [config] logical-epoch:
[2023-07-01 09:51:26] [config]   - 1e
[2023-07-01 09:51:26] [config]   - 0
[2023-07-01 09:51:26] [config] lr-decay: 0
[2023-07-01 09:51:26] [config] lr-decay-freq: 50000
[2023-07-01 09:51:26] [config] lr-decay-inv-sqrt:
[2023-07-01 09:51:26] [config]   - 16000
[2023-07-01 09:51:26] [config] lr-decay-repeat-warmup: false
[2023-07-01 09:51:26] [config] lr-decay-reset-optimizer: false
[2023-07-01 09:51:26] [config] lr-decay-start:
[2023-07-01 09:51:26] [config]   - 10
[2023-07-01 09:51:26] [config]   - 1
[2023-07-01 09:51:26] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 09:51:26] [config] lr-report: true
[2023-07-01 09:51:26] [config] lr-warmup: 16000
[2023-07-01 09:51:26] [config] lr-warmup-at-reload: false
[2023-07-01 09:51:26] [config] lr-warmup-cycle: false
[2023-07-01 09:51:26] [config] lr-warmup-start-rate: 0
[2023-07-01 09:51:26] [config] max-length: 100
[2023-07-01 09:51:26] [config] max-length-crop: false
[2023-07-01 09:51:26] [config] max-length-factor: 3
[2023-07-01 09:51:26] [config] maxi-batch: 100
[2023-07-01 09:51:26] [config] maxi-batch-sort: trg
[2023-07-01 09:51:26] [config] mini-batch: 1000
[2023-07-01 09:51:26] [config] mini-batch-fit: true
[2023-07-01 09:51:26] [config] mini-batch-fit-step: 10
[2023-07-01 09:51:26] [config] mini-batch-round-up: true
[2023-07-01 09:51:26] [config] mini-batch-track-lr: false
[2023-07-01 09:51:26] [config] mini-batch-warmup: 0
[2023-07-01 09:51:26] [config] mini-batch-words: 0
[2023-07-01 09:51:26] [config] mini-batch-words-ref: 0
[2023-07-01 09:51:26] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 09:51:26] [config] multi-loss-type: sum
[2023-07-01 09:51:26] [config] n-best: false
[2023-07-01 09:51:26] [config] no-nccl: false
[2023-07-01 09:51:26] [config] no-reload: false
[2023-07-01 09:51:26] [config] no-restore-corpus: false
[2023-07-01 09:51:26] [config] normalize: 1
[2023-07-01 09:51:26] [config] normalize-gradient: false
[2023-07-01 09:51:26] [config] num-devices: 0
[2023-07-01 09:51:26] [config] optimizer: adam
[2023-07-01 09:51:26] [config] optimizer-delay: 1
[2023-07-01 09:51:26] [config] optimizer-params:
[2023-07-01 09:51:26] [config]   - 0.9
[2023-07-01 09:51:26] [config]   - 0.98
[2023-07-01 09:51:26] [config]   - 1e-09
[2023-07-01 09:51:26] [config] output-omit-bias: false
[2023-07-01 09:51:26] [config] overwrite: true
[2023-07-01 09:51:26] [config] precision:
[2023-07-01 09:51:26] [config]   - float32
[2023-07-01 09:51:26] [config]   - float32
[2023-07-01 09:51:26] [config] pretrained-model: ""
[2023-07-01 09:51:26] [config] quantize-biases: false
[2023-07-01 09:51:26] [config] quantize-bits: 0
[2023-07-01 09:51:26] [config] quantize-log-based: false
[2023-07-01 09:51:26] [config] quantize-optimization-steps: 0
[2023-07-01 09:51:26] [config] quiet: false
[2023-07-01 09:51:26] [config] quiet-translation: true
[2023-07-01 09:51:26] [config] relative-paths: false
[2023-07-01 09:51:26] [config] right-left: false
[2023-07-01 09:51:26] [config] save-freq: 10000u
[2023-07-01 09:51:26] [config] seed: 1234
[2023-07-01 09:51:26] [config] sentencepiece-alphas:
[2023-07-01 09:51:26] [config]   []
[2023-07-01 09:51:26] [config] sentencepiece-max-lines: 2000000
[2023-07-01 09:51:26] [config] sentencepiece-options: ""
[2023-07-01 09:51:26] [config] sharding: global
[2023-07-01 09:51:26] [config] shuffle: data
[2023-07-01 09:51:26] [config] shuffle-in-ram: false
[2023-07-01 09:51:26] [config] sigterm: save-and-exit
[2023-07-01 09:51:26] [config] skip: false
[2023-07-01 09:51:26] [config] sqlite: ""
[2023-07-01 09:51:26] [config] sqlite-drop: false
[2023-07-01 09:51:26] [config] sync-freq: 200u
[2023-07-01 09:51:26] [config] sync-sgd: true
[2023-07-01 09:51:26] [config] tempdir: /tmp
[2023-07-01 09:51:26] [config] tied-embeddings: false
[2023-07-01 09:51:26] [config] tied-embeddings-all: true
[2023-07-01 09:51:26] [config] tied-embeddings-src: false
[2023-07-01 09:51:26] [config] train-embedder-rank:
[2023-07-01 09:51:26] [config]   []
[2023-07-01 09:51:26] [config] train-sets:
[2023-07-01 09:51:26] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 09:51:26] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 09:51:26] [config] transformer-aan-activation: swish
[2023-07-01 09:51:26] [config] transformer-aan-depth: 2
[2023-07-01 09:51:26] [config] transformer-aan-nogate: false
[2023-07-01 09:51:26] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 09:51:26] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 09:51:26] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 09:51:26] [config] transformer-depth-scaling: false
[2023-07-01 09:51:26] [config] transformer-dim-aan: 2048
[2023-07-01 09:51:26] [config] transformer-dim-ffn: 2048
[2023-07-01 09:51:26] [config] transformer-dropout: 0.1
[2023-07-01 09:51:26] [config] transformer-dropout-attention: 0
[2023-07-01 09:51:26] [config] transformer-dropout-ffn: 0
[2023-07-01 09:51:26] [config] transformer-ffn-activation: swish
[2023-07-01 09:51:26] [config] transformer-ffn-depth: 2
[2023-07-01 09:51:26] [config] transformer-guided-alignment-layer: last
[2023-07-01 09:51:26] [config] transformer-heads: 8
[2023-07-01 09:51:26] [config] transformer-no-projection: false
[2023-07-01 09:51:26] [config] transformer-pool: false
[2023-07-01 09:51:26] [config] transformer-postprocess: dan
[2023-07-01 09:51:26] [config] transformer-postprocess-emb: d
[2023-07-01 09:51:26] [config] transformer-postprocess-top: ""
[2023-07-01 09:51:26] [config] transformer-preprocess: ""
[2023-07-01 09:51:26] [config] transformer-tied-layers:
[2023-07-01 09:51:26] [config]   []
[2023-07-01 09:51:26] [config] transformer-train-position-embeddings: false
[2023-07-01 09:51:26] [config] tsv: false
[2023-07-01 09:51:26] [config] tsv-fields: 0
[2023-07-01 09:51:26] [config] type: transformer
[2023-07-01 09:51:26] [config] ulr: false
[2023-07-01 09:51:26] [config] ulr-dim-emb: 0
[2023-07-01 09:51:26] [config] ulr-dropout: 0
[2023-07-01 09:51:26] [config] ulr-keys-vectors: ""
[2023-07-01 09:51:26] [config] ulr-query-vectors: ""
[2023-07-01 09:51:26] [config] ulr-softmax-temperature: 1
[2023-07-01 09:51:26] [config] ulr-trainable-transformation: false
[2023-07-01 09:51:26] [config] unlikelihood-loss: false
[2023-07-01 09:51:26] [config] valid-freq: 50000000
[2023-07-01 09:51:26] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 09:51:26] [config] valid-max-length: 1000
[2023-07-01 09:51:26] [config] valid-metrics:
[2023-07-01 09:51:26] [config]   - cross-entropy
[2023-07-01 09:51:26] [config]   - translation
[2023-07-01 09:51:26] [config] valid-mini-batch: 64
[2023-07-01 09:51:26] [config] valid-reset-stalled: false
[2023-07-01 09:51:26] [config] valid-script-args:
[2023-07-01 09:51:26] [config]   []
[2023-07-01 09:51:26] [config] valid-script-path: ""
[2023-07-01 09:51:26] [config] valid-sets:
[2023-07-01 09:51:26] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 09:51:26] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 09:51:26] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 09:51:26] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 09:51:26] [config] vocabs:
[2023-07-01 09:51:26] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 09:51:26] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 09:51:26] [config] word-penalty: 0
[2023-07-01 09:51:26] [config] word-scores: false
[2023-07-01 09:51:26] [config] workspace: 2048
[2023-07-01 09:51:26] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 09:51:26] Using synchronous SGD
[2023-07-01 09:51:26] Synced seed 1234
[2023-07-01 09:51:26] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 09:51:26] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 09:51:26] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 09:51:26] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 09:51:26] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 09:51:26] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 09:51:27] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 09:51:27] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 09:51:27] [comm] Using global sharding
[2023-07-01 09:51:27] [comm] NCCLCommunicators constructed successfully
[2023-07-01 09:51:27] [training] Using 1 GPUs
[2023-07-01 09:51:27] [logits] Applying loss function for 1 factor(s)
[2023-07-01 09:51:27] [memory] Reserving 88 MB, device gpu0
[2023-07-01 09:51:27] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 09:51:27] [memory] Reserving 88 MB, device gpu0
[2023-07-01 09:51:35] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 09:51:35] [valid] No post-processing script given for validating translator
[2023-07-01 09:51:35] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 09:51:35] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 09:51:35] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 09:51:35] [comm] Using global sharding
[2023-07-01 09:51:35] [comm] NCCLCommunicators constructed successfully
[2023-07-01 09:51:35] [training] Using 1 GPUs
[2023-07-01 09:51:35] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 09:51:36] Allocating memory for general optimizer shards
[2023-07-01 09:51:36] [memory] Reserving 88 MB, device gpu0
[2023-07-01 09:51:36] Loading Adam parameters
[2023-07-01 09:51:36] [memory] Reserving 176 MB, device gpu0
[2023-07-01 09:51:36] [memory] Reserving 88 MB, device gpu0
[2023-07-01 09:51:36] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 09:51:36] [data] Restoring the corpus state to epoch 17, batch 3024
[2023-07-01 09:51:36] [data] Shuffling data
[2023-07-01 09:51:36] [data] Done reading 20,192 sentences
[2023-07-01 09:51:36] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 09:51:36] Training started
[2023-07-01 09:51:36] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-07-01 09:51:36] [memory] Reserving 88 MB, device gpu0
[2023-07-01 09:51:36] Parameter type float32, optimization type float32, casting types false
[2023-07-01 09:52:00] Seen 20,073 samples
[2023-07-01 09:52:00] Starting data epoch 18 in logical epoch 18
[2023-07-01 09:52:00] Training finished
[2023-07-01 09:52:03] [valid] Ep. 18 : Up. 3213 : cross-entropy : 153.573 : new best
[2023-07-01 09:55:11] [valid] Ep. 18 : Up. 3213 : translation : 0 : new best
[2023-07-01 09:55:11] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 09:55:12] Saving Adam parameters
[2023-07-01 09:55:12] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 09:55:19] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 09:55:19] [marian] Running on node20.datos.cluster.uy as process 6986 with command line:
[2023-07-01 09:55:19] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 18 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 09:55:19] [config] after: 0e
[2023-07-01 09:55:19] [config] after-batches: 0
[2023-07-01 09:55:19] [config] after-epochs: 18
[2023-07-01 09:55:19] [config] all-caps-every: 0
[2023-07-01 09:55:19] [config] allow-unk: false
[2023-07-01 09:55:19] [config] authors: false
[2023-07-01 09:55:19] [config] beam-size: 12
[2023-07-01 09:55:19] [config] bert-class-symbol: "[CLS]"
[2023-07-01 09:55:19] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 09:55:19] [config] bert-masking-fraction: 0.15
[2023-07-01 09:55:19] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 09:55:19] [config] bert-train-type-embeddings: true
[2023-07-01 09:55:19] [config] bert-type-vocab-size: 2
[2023-07-01 09:55:19] [config] build-info: ""
[2023-07-01 09:55:19] [config] check-gradient-nan: false
[2023-07-01 09:55:19] [config] check-nan: false
[2023-07-01 09:55:19] [config] cite: false
[2023-07-01 09:55:19] [config] clip-norm: 5
[2023-07-01 09:55:19] [config] cost-scaling:
[2023-07-01 09:55:19] [config]   []
[2023-07-01 09:55:19] [config] cost-type: ce-sum
[2023-07-01 09:55:19] [config] cpu-threads: 0
[2023-07-01 09:55:19] [config] data-threads: 8
[2023-07-01 09:55:19] [config] data-weighting: ""
[2023-07-01 09:55:19] [config] data-weighting-type: sentence
[2023-07-01 09:55:19] [config] dec-cell: gru
[2023-07-01 09:55:19] [config] dec-cell-base-depth: 2
[2023-07-01 09:55:19] [config] dec-cell-high-depth: 1
[2023-07-01 09:55:19] [config] dec-depth: 2
[2023-07-01 09:55:19] [config] devices:
[2023-07-01 09:55:19] [config]   - 0
[2023-07-01 09:55:19] [config] dim-emb: 512
[2023-07-01 09:55:19] [config] dim-rnn: 1024
[2023-07-01 09:55:19] [config] dim-vocabs:
[2023-07-01 09:55:19] [config]   - 16384
[2023-07-01 09:55:19] [config]   - 16384
[2023-07-01 09:55:19] [config] disp-first: 0
[2023-07-01 09:55:19] [config] disp-freq: 1000u
[2023-07-01 09:55:19] [config] disp-label-counts: true
[2023-07-01 09:55:19] [config] dropout-rnn: 0
[2023-07-01 09:55:19] [config] dropout-src: 0
[2023-07-01 09:55:19] [config] dropout-trg: 0
[2023-07-01 09:55:19] [config] dump-config: ""
[2023-07-01 09:55:19] [config] dynamic-gradient-scaling:
[2023-07-01 09:55:19] [config]   []
[2023-07-01 09:55:19] [config] early-stopping: 10
[2023-07-01 09:55:19] [config] early-stopping-on: first
[2023-07-01 09:55:19] [config] embedding-fix-src: false
[2023-07-01 09:55:19] [config] embedding-fix-trg: false
[2023-07-01 09:55:19] [config] embedding-normalization: false
[2023-07-01 09:55:19] [config] embedding-vectors:
[2023-07-01 09:55:19] [config]   []
[2023-07-01 09:55:19] [config] enc-cell: gru
[2023-07-01 09:55:19] [config] enc-cell-depth: 1
[2023-07-01 09:55:19] [config] enc-depth: 2
[2023-07-01 09:55:19] [config] enc-type: bidirectional
[2023-07-01 09:55:19] [config] english-title-case-every: 0
[2023-07-01 09:55:19] [config] exponential-smoothing: 0.0001
[2023-07-01 09:55:19] [config] factor-weight: 1
[2023-07-01 09:55:19] [config] factors-combine: sum
[2023-07-01 09:55:19] [config] factors-dim-emb: 0
[2023-07-01 09:55:19] [config] gradient-checkpointing: false
[2023-07-01 09:55:19] [config] gradient-norm-average-window: 100
[2023-07-01 09:55:19] [config] guided-alignment: none
[2023-07-01 09:55:19] [config] guided-alignment-cost: mse
[2023-07-01 09:55:19] [config] guided-alignment-weight: 0.1
[2023-07-01 09:55:19] [config] ignore-model-config: false
[2023-07-01 09:55:19] [config] input-types:
[2023-07-01 09:55:19] [config]   []
[2023-07-01 09:55:19] [config] interpolate-env-vars: false
[2023-07-01 09:55:19] [config] keep-best: false
[2023-07-01 09:55:19] [config] label-smoothing: 0.1
[2023-07-01 09:55:19] [config] layer-normalization: false
[2023-07-01 09:55:19] [config] learn-rate: 0.0003
[2023-07-01 09:55:19] [config] lemma-dependency: ""
[2023-07-01 09:55:19] [config] lemma-dim-emb: 0
[2023-07-01 09:55:19] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 09:55:19] [config] log-level: info
[2023-07-01 09:55:19] [config] log-time-zone: ""
[2023-07-01 09:55:19] [config] logical-epoch:
[2023-07-01 09:55:19] [config]   - 1e
[2023-07-01 09:55:19] [config]   - 0
[2023-07-01 09:55:19] [config] lr-decay: 0
[2023-07-01 09:55:19] [config] lr-decay-freq: 50000
[2023-07-01 09:55:19] [config] lr-decay-inv-sqrt:
[2023-07-01 09:55:19] [config]   - 16000
[2023-07-01 09:55:19] [config] lr-decay-repeat-warmup: false
[2023-07-01 09:55:19] [config] lr-decay-reset-optimizer: false
[2023-07-01 09:55:19] [config] lr-decay-start:
[2023-07-01 09:55:19] [config]   - 10
[2023-07-01 09:55:19] [config]   - 1
[2023-07-01 09:55:19] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 09:55:19] [config] lr-report: true
[2023-07-01 09:55:19] [config] lr-warmup: 16000
[2023-07-01 09:55:19] [config] lr-warmup-at-reload: false
[2023-07-01 09:55:19] [config] lr-warmup-cycle: false
[2023-07-01 09:55:19] [config] lr-warmup-start-rate: 0
[2023-07-01 09:55:19] [config] max-length: 100
[2023-07-01 09:55:19] [config] max-length-crop: false
[2023-07-01 09:55:19] [config] max-length-factor: 3
[2023-07-01 09:55:19] [config] maxi-batch: 100
[2023-07-01 09:55:19] [config] maxi-batch-sort: trg
[2023-07-01 09:55:19] [config] mini-batch: 1000
[2023-07-01 09:55:19] [config] mini-batch-fit: true
[2023-07-01 09:55:19] [config] mini-batch-fit-step: 10
[2023-07-01 09:55:19] [config] mini-batch-round-up: true
[2023-07-01 09:55:19] [config] mini-batch-track-lr: false
[2023-07-01 09:55:19] [config] mini-batch-warmup: 0
[2023-07-01 09:55:19] [config] mini-batch-words: 0
[2023-07-01 09:55:19] [config] mini-batch-words-ref: 0
[2023-07-01 09:55:19] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 09:55:19] [config] multi-loss-type: sum
[2023-07-01 09:55:19] [config] n-best: false
[2023-07-01 09:55:19] [config] no-nccl: false
[2023-07-01 09:55:19] [config] no-reload: false
[2023-07-01 09:55:19] [config] no-restore-corpus: false
[2023-07-01 09:55:19] [config] normalize: 1
[2023-07-01 09:55:19] [config] normalize-gradient: false
[2023-07-01 09:55:19] [config] num-devices: 0
[2023-07-01 09:55:19] [config] optimizer: adam
[2023-07-01 09:55:19] [config] optimizer-delay: 1
[2023-07-01 09:55:19] [config] optimizer-params:
[2023-07-01 09:55:19] [config]   - 0.9
[2023-07-01 09:55:19] [config]   - 0.98
[2023-07-01 09:55:19] [config]   - 1e-09
[2023-07-01 09:55:19] [config] output-omit-bias: false
[2023-07-01 09:55:19] [config] overwrite: true
[2023-07-01 09:55:19] [config] precision:
[2023-07-01 09:55:19] [config]   - float32
[2023-07-01 09:55:19] [config]   - float32
[2023-07-01 09:55:19] [config] pretrained-model: ""
[2023-07-01 09:55:19] [config] quantize-biases: false
[2023-07-01 09:55:19] [config] quantize-bits: 0
[2023-07-01 09:55:19] [config] quantize-log-based: false
[2023-07-01 09:55:19] [config] quantize-optimization-steps: 0
[2023-07-01 09:55:19] [config] quiet: false
[2023-07-01 09:55:19] [config] quiet-translation: true
[2023-07-01 09:55:19] [config] relative-paths: false
[2023-07-01 09:55:19] [config] right-left: false
[2023-07-01 09:55:19] [config] save-freq: 10000u
[2023-07-01 09:55:19] [config] seed: 1234
[2023-07-01 09:55:19] [config] sentencepiece-alphas:
[2023-07-01 09:55:19] [config]   []
[2023-07-01 09:55:19] [config] sentencepiece-max-lines: 2000000
[2023-07-01 09:55:19] [config] sentencepiece-options: ""
[2023-07-01 09:55:19] [config] sharding: global
[2023-07-01 09:55:19] [config] shuffle: data
[2023-07-01 09:55:19] [config] shuffle-in-ram: false
[2023-07-01 09:55:19] [config] sigterm: save-and-exit
[2023-07-01 09:55:19] [config] skip: false
[2023-07-01 09:55:19] [config] sqlite: ""
[2023-07-01 09:55:19] [config] sqlite-drop: false
[2023-07-01 09:55:19] [config] sync-freq: 200u
[2023-07-01 09:55:19] [config] sync-sgd: true
[2023-07-01 09:55:19] [config] tempdir: /tmp
[2023-07-01 09:55:19] [config] tied-embeddings: false
[2023-07-01 09:55:19] [config] tied-embeddings-all: true
[2023-07-01 09:55:19] [config] tied-embeddings-src: false
[2023-07-01 09:55:19] [config] train-embedder-rank:
[2023-07-01 09:55:19] [config]   []
[2023-07-01 09:55:19] [config] train-sets:
[2023-07-01 09:55:19] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 09:55:19] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 09:55:19] [config] transformer-aan-activation: swish
[2023-07-01 09:55:19] [config] transformer-aan-depth: 2
[2023-07-01 09:55:19] [config] transformer-aan-nogate: false
[2023-07-01 09:55:19] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 09:55:19] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 09:55:19] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 09:55:19] [config] transformer-depth-scaling: false
[2023-07-01 09:55:19] [config] transformer-dim-aan: 2048
[2023-07-01 09:55:19] [config] transformer-dim-ffn: 2048
[2023-07-01 09:55:19] [config] transformer-dropout: 0.1
[2023-07-01 09:55:19] [config] transformer-dropout-attention: 0
[2023-07-01 09:55:19] [config] transformer-dropout-ffn: 0
[2023-07-01 09:55:19] [config] transformer-ffn-activation: swish
[2023-07-01 09:55:19] [config] transformer-ffn-depth: 2
[2023-07-01 09:55:19] [config] transformer-guided-alignment-layer: last
[2023-07-01 09:55:19] [config] transformer-heads: 8
[2023-07-01 09:55:19] [config] transformer-no-projection: false
[2023-07-01 09:55:19] [config] transformer-pool: false
[2023-07-01 09:55:19] [config] transformer-postprocess: dan
[2023-07-01 09:55:19] [config] transformer-postprocess-emb: d
[2023-07-01 09:55:19] [config] transformer-postprocess-top: ""
[2023-07-01 09:55:19] [config] transformer-preprocess: ""
[2023-07-01 09:55:19] [config] transformer-tied-layers:
[2023-07-01 09:55:19] [config]   []
[2023-07-01 09:55:19] [config] transformer-train-position-embeddings: false
[2023-07-01 09:55:19] [config] tsv: false
[2023-07-01 09:55:19] [config] tsv-fields: 0
[2023-07-01 09:55:19] [config] type: transformer
[2023-07-01 09:55:19] [config] ulr: false
[2023-07-01 09:55:19] [config] ulr-dim-emb: 0
[2023-07-01 09:55:19] [config] ulr-dropout: 0
[2023-07-01 09:55:19] [config] ulr-keys-vectors: ""
[2023-07-01 09:55:19] [config] ulr-query-vectors: ""
[2023-07-01 09:55:19] [config] ulr-softmax-temperature: 1
[2023-07-01 09:55:19] [config] ulr-trainable-transformation: false
[2023-07-01 09:55:19] [config] unlikelihood-loss: false
[2023-07-01 09:55:19] [config] valid-freq: 50000000
[2023-07-01 09:55:19] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 09:55:19] [config] valid-max-length: 1000
[2023-07-01 09:55:19] [config] valid-metrics:
[2023-07-01 09:55:19] [config]   - cross-entropy
[2023-07-01 09:55:19] [config]   - translation
[2023-07-01 09:55:19] [config] valid-mini-batch: 64
[2023-07-01 09:55:19] [config] valid-reset-stalled: false
[2023-07-01 09:55:19] [config] valid-script-args:
[2023-07-01 09:55:19] [config]   []
[2023-07-01 09:55:19] [config] valid-script-path: ""
[2023-07-01 09:55:19] [config] valid-sets:
[2023-07-01 09:55:19] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 09:55:19] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 09:55:19] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 09:55:19] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 09:55:19] [config] vocabs:
[2023-07-01 09:55:19] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 09:55:19] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 09:55:19] [config] word-penalty: 0
[2023-07-01 09:55:19] [config] word-scores: false
[2023-07-01 09:55:19] [config] workspace: 2048
[2023-07-01 09:55:19] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 09:55:19] Using synchronous SGD
[2023-07-01 09:55:19] Synced seed 1234
[2023-07-01 09:55:19] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 09:55:19] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 09:55:19] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 09:55:20] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 09:55:20] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 09:55:20] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 09:55:20] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 09:55:20] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 09:55:20] [comm] Using global sharding
[2023-07-01 09:55:20] [comm] NCCLCommunicators constructed successfully
[2023-07-01 09:55:20] [training] Using 1 GPUs
[2023-07-01 09:55:20] [logits] Applying loss function for 1 factor(s)
[2023-07-01 09:55:20] [memory] Reserving 88 MB, device gpu0
[2023-07-01 09:55:21] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 09:55:21] [memory] Reserving 88 MB, device gpu0
[2023-07-01 09:55:28] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 09:55:28] [valid] No post-processing script given for validating translator
[2023-07-01 09:55:28] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 09:55:28] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 09:55:28] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 09:55:28] [comm] Using global sharding
[2023-07-01 09:55:28] [comm] NCCLCommunicators constructed successfully
[2023-07-01 09:55:28] [training] Using 1 GPUs
[2023-07-01 09:55:28] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 09:55:29] Allocating memory for general optimizer shards
[2023-07-01 09:55:29] [memory] Reserving 88 MB, device gpu0
[2023-07-01 09:55:29] Loading Adam parameters
[2023-07-01 09:55:29] [memory] Reserving 176 MB, device gpu0
[2023-07-01 09:55:29] [memory] Reserving 88 MB, device gpu0
[2023-07-01 09:55:29] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 09:55:29] [data] Restoring the corpus state to epoch 18, batch 3213
[2023-07-01 09:55:29] [data] Shuffling data
[2023-07-01 09:55:29] [data] Done reading 20,192 sentences
[2023-07-01 09:55:29] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 09:55:29] Training started
[2023-07-01 09:55:30] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-07-01 09:55:30] [memory] Reserving 88 MB, device gpu0
[2023-07-01 09:55:30] Parameter type float32, optimization type float32, casting types false
[2023-07-01 09:55:53] Seen 20,073 samples
[2023-07-01 09:55:53] Starting data epoch 19 in logical epoch 19
[2023-07-01 09:55:53] Training finished
[2023-07-01 09:55:56] [valid] Ep. 19 : Up. 3402 : cross-entropy : 151.166 : new best
[2023-07-01 09:59:00] [valid] Ep. 19 : Up. 3402 : translation : 0 : new best
[2023-07-01 09:59:00] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 09:59:01] Saving Adam parameters
[2023-07-01 09:59:01] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 09:59:07] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 09:59:07] [marian] Running on node20.datos.cluster.uy as process 7234 with command line:
[2023-07-01 09:59:07] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 19 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 09:59:07] [config] after: 0e
[2023-07-01 09:59:07] [config] after-batches: 0
[2023-07-01 09:59:07] [config] after-epochs: 19
[2023-07-01 09:59:07] [config] all-caps-every: 0
[2023-07-01 09:59:07] [config] allow-unk: false
[2023-07-01 09:59:07] [config] authors: false
[2023-07-01 09:59:07] [config] beam-size: 12
[2023-07-01 09:59:07] [config] bert-class-symbol: "[CLS]"
[2023-07-01 09:59:07] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 09:59:07] [config] bert-masking-fraction: 0.15
[2023-07-01 09:59:07] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 09:59:07] [config] bert-train-type-embeddings: true
[2023-07-01 09:59:07] [config] bert-type-vocab-size: 2
[2023-07-01 09:59:07] [config] build-info: ""
[2023-07-01 09:59:07] [config] check-gradient-nan: false
[2023-07-01 09:59:07] [config] check-nan: false
[2023-07-01 09:59:07] [config] cite: false
[2023-07-01 09:59:07] [config] clip-norm: 5
[2023-07-01 09:59:07] [config] cost-scaling:
[2023-07-01 09:59:07] [config]   []
[2023-07-01 09:59:07] [config] cost-type: ce-sum
[2023-07-01 09:59:07] [config] cpu-threads: 0
[2023-07-01 09:59:07] [config] data-threads: 8
[2023-07-01 09:59:07] [config] data-weighting: ""
[2023-07-01 09:59:07] [config] data-weighting-type: sentence
[2023-07-01 09:59:07] [config] dec-cell: gru
[2023-07-01 09:59:07] [config] dec-cell-base-depth: 2
[2023-07-01 09:59:07] [config] dec-cell-high-depth: 1
[2023-07-01 09:59:07] [config] dec-depth: 2
[2023-07-01 09:59:07] [config] devices:
[2023-07-01 09:59:07] [config]   - 0
[2023-07-01 09:59:07] [config] dim-emb: 512
[2023-07-01 09:59:07] [config] dim-rnn: 1024
[2023-07-01 09:59:07] [config] dim-vocabs:
[2023-07-01 09:59:07] [config]   - 16384
[2023-07-01 09:59:07] [config]   - 16384
[2023-07-01 09:59:07] [config] disp-first: 0
[2023-07-01 09:59:07] [config] disp-freq: 1000u
[2023-07-01 09:59:07] [config] disp-label-counts: true
[2023-07-01 09:59:07] [config] dropout-rnn: 0
[2023-07-01 09:59:07] [config] dropout-src: 0
[2023-07-01 09:59:07] [config] dropout-trg: 0
[2023-07-01 09:59:07] [config] dump-config: ""
[2023-07-01 09:59:07] [config] dynamic-gradient-scaling:
[2023-07-01 09:59:07] [config]   []
[2023-07-01 09:59:07] [config] early-stopping: 10
[2023-07-01 09:59:07] [config] early-stopping-on: first
[2023-07-01 09:59:07] [config] embedding-fix-src: false
[2023-07-01 09:59:07] [config] embedding-fix-trg: false
[2023-07-01 09:59:07] [config] embedding-normalization: false
[2023-07-01 09:59:07] [config] embedding-vectors:
[2023-07-01 09:59:07] [config]   []
[2023-07-01 09:59:07] [config] enc-cell: gru
[2023-07-01 09:59:07] [config] enc-cell-depth: 1
[2023-07-01 09:59:07] [config] enc-depth: 2
[2023-07-01 09:59:07] [config] enc-type: bidirectional
[2023-07-01 09:59:07] [config] english-title-case-every: 0
[2023-07-01 09:59:07] [config] exponential-smoothing: 0.0001
[2023-07-01 09:59:07] [config] factor-weight: 1
[2023-07-01 09:59:07] [config] factors-combine: sum
[2023-07-01 09:59:07] [config] factors-dim-emb: 0
[2023-07-01 09:59:07] [config] gradient-checkpointing: false
[2023-07-01 09:59:07] [config] gradient-norm-average-window: 100
[2023-07-01 09:59:07] [config] guided-alignment: none
[2023-07-01 09:59:07] [config] guided-alignment-cost: mse
[2023-07-01 09:59:07] [config] guided-alignment-weight: 0.1
[2023-07-01 09:59:07] [config] ignore-model-config: false
[2023-07-01 09:59:07] [config] input-types:
[2023-07-01 09:59:07] [config]   []
[2023-07-01 09:59:07] [config] interpolate-env-vars: false
[2023-07-01 09:59:07] [config] keep-best: false
[2023-07-01 09:59:07] [config] label-smoothing: 0.1
[2023-07-01 09:59:07] [config] layer-normalization: false
[2023-07-01 09:59:07] [config] learn-rate: 0.0003
[2023-07-01 09:59:07] [config] lemma-dependency: ""
[2023-07-01 09:59:07] [config] lemma-dim-emb: 0
[2023-07-01 09:59:07] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 09:59:07] [config] log-level: info
[2023-07-01 09:59:07] [config] log-time-zone: ""
[2023-07-01 09:59:07] [config] logical-epoch:
[2023-07-01 09:59:07] [config]   - 1e
[2023-07-01 09:59:07] [config]   - 0
[2023-07-01 09:59:07] [config] lr-decay: 0
[2023-07-01 09:59:07] [config] lr-decay-freq: 50000
[2023-07-01 09:59:07] [config] lr-decay-inv-sqrt:
[2023-07-01 09:59:07] [config]   - 16000
[2023-07-01 09:59:07] [config] lr-decay-repeat-warmup: false
[2023-07-01 09:59:07] [config] lr-decay-reset-optimizer: false
[2023-07-01 09:59:07] [config] lr-decay-start:
[2023-07-01 09:59:07] [config]   - 10
[2023-07-01 09:59:07] [config]   - 1
[2023-07-01 09:59:07] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 09:59:07] [config] lr-report: true
[2023-07-01 09:59:07] [config] lr-warmup: 16000
[2023-07-01 09:59:07] [config] lr-warmup-at-reload: false
[2023-07-01 09:59:07] [config] lr-warmup-cycle: false
[2023-07-01 09:59:07] [config] lr-warmup-start-rate: 0
[2023-07-01 09:59:07] [config] max-length: 100
[2023-07-01 09:59:07] [config] max-length-crop: false
[2023-07-01 09:59:07] [config] max-length-factor: 3
[2023-07-01 09:59:07] [config] maxi-batch: 100
[2023-07-01 09:59:07] [config] maxi-batch-sort: trg
[2023-07-01 09:59:07] [config] mini-batch: 1000
[2023-07-01 09:59:07] [config] mini-batch-fit: true
[2023-07-01 09:59:07] [config] mini-batch-fit-step: 10
[2023-07-01 09:59:07] [config] mini-batch-round-up: true
[2023-07-01 09:59:07] [config] mini-batch-track-lr: false
[2023-07-01 09:59:07] [config] mini-batch-warmup: 0
[2023-07-01 09:59:07] [config] mini-batch-words: 0
[2023-07-01 09:59:07] [config] mini-batch-words-ref: 0
[2023-07-01 09:59:07] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 09:59:07] [config] multi-loss-type: sum
[2023-07-01 09:59:07] [config] n-best: false
[2023-07-01 09:59:07] [config] no-nccl: false
[2023-07-01 09:59:07] [config] no-reload: false
[2023-07-01 09:59:07] [config] no-restore-corpus: false
[2023-07-01 09:59:07] [config] normalize: 1
[2023-07-01 09:59:07] [config] normalize-gradient: false
[2023-07-01 09:59:07] [config] num-devices: 0
[2023-07-01 09:59:07] [config] optimizer: adam
[2023-07-01 09:59:07] [config] optimizer-delay: 1
[2023-07-01 09:59:07] [config] optimizer-params:
[2023-07-01 09:59:07] [config]   - 0.9
[2023-07-01 09:59:07] [config]   - 0.98
[2023-07-01 09:59:07] [config]   - 1e-09
[2023-07-01 09:59:07] [config] output-omit-bias: false
[2023-07-01 09:59:07] [config] overwrite: true
[2023-07-01 09:59:07] [config] precision:
[2023-07-01 09:59:07] [config]   - float32
[2023-07-01 09:59:07] [config]   - float32
[2023-07-01 09:59:07] [config] pretrained-model: ""
[2023-07-01 09:59:07] [config] quantize-biases: false
[2023-07-01 09:59:07] [config] quantize-bits: 0
[2023-07-01 09:59:07] [config] quantize-log-based: false
[2023-07-01 09:59:07] [config] quantize-optimization-steps: 0
[2023-07-01 09:59:07] [config] quiet: false
[2023-07-01 09:59:07] [config] quiet-translation: true
[2023-07-01 09:59:07] [config] relative-paths: false
[2023-07-01 09:59:07] [config] right-left: false
[2023-07-01 09:59:07] [config] save-freq: 10000u
[2023-07-01 09:59:07] [config] seed: 1234
[2023-07-01 09:59:07] [config] sentencepiece-alphas:
[2023-07-01 09:59:07] [config]   []
[2023-07-01 09:59:07] [config] sentencepiece-max-lines: 2000000
[2023-07-01 09:59:07] [config] sentencepiece-options: ""
[2023-07-01 09:59:07] [config] sharding: global
[2023-07-01 09:59:07] [config] shuffle: data
[2023-07-01 09:59:07] [config] shuffle-in-ram: false
[2023-07-01 09:59:07] [config] sigterm: save-and-exit
[2023-07-01 09:59:07] [config] skip: false
[2023-07-01 09:59:07] [config] sqlite: ""
[2023-07-01 09:59:07] [config] sqlite-drop: false
[2023-07-01 09:59:07] [config] sync-freq: 200u
[2023-07-01 09:59:07] [config] sync-sgd: true
[2023-07-01 09:59:07] [config] tempdir: /tmp
[2023-07-01 09:59:07] [config] tied-embeddings: false
[2023-07-01 09:59:07] [config] tied-embeddings-all: true
[2023-07-01 09:59:07] [config] tied-embeddings-src: false
[2023-07-01 09:59:07] [config] train-embedder-rank:
[2023-07-01 09:59:07] [config]   []
[2023-07-01 09:59:07] [config] train-sets:
[2023-07-01 09:59:07] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 09:59:07] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 09:59:07] [config] transformer-aan-activation: swish
[2023-07-01 09:59:07] [config] transformer-aan-depth: 2
[2023-07-01 09:59:07] [config] transformer-aan-nogate: false
[2023-07-01 09:59:07] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 09:59:07] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 09:59:07] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 09:59:07] [config] transformer-depth-scaling: false
[2023-07-01 09:59:07] [config] transformer-dim-aan: 2048
[2023-07-01 09:59:07] [config] transformer-dim-ffn: 2048
[2023-07-01 09:59:07] [config] transformer-dropout: 0.1
[2023-07-01 09:59:07] [config] transformer-dropout-attention: 0
[2023-07-01 09:59:07] [config] transformer-dropout-ffn: 0
[2023-07-01 09:59:07] [config] transformer-ffn-activation: swish
[2023-07-01 09:59:07] [config] transformer-ffn-depth: 2
[2023-07-01 09:59:07] [config] transformer-guided-alignment-layer: last
[2023-07-01 09:59:07] [config] transformer-heads: 8
[2023-07-01 09:59:07] [config] transformer-no-projection: false
[2023-07-01 09:59:07] [config] transformer-pool: false
[2023-07-01 09:59:07] [config] transformer-postprocess: dan
[2023-07-01 09:59:07] [config] transformer-postprocess-emb: d
[2023-07-01 09:59:07] [config] transformer-postprocess-top: ""
[2023-07-01 09:59:07] [config] transformer-preprocess: ""
[2023-07-01 09:59:07] [config] transformer-tied-layers:
[2023-07-01 09:59:07] [config]   []
[2023-07-01 09:59:07] [config] transformer-train-position-embeddings: false
[2023-07-01 09:59:07] [config] tsv: false
[2023-07-01 09:59:07] [config] tsv-fields: 0
[2023-07-01 09:59:07] [config] type: transformer
[2023-07-01 09:59:07] [config] ulr: false
[2023-07-01 09:59:07] [config] ulr-dim-emb: 0
[2023-07-01 09:59:07] [config] ulr-dropout: 0
[2023-07-01 09:59:07] [config] ulr-keys-vectors: ""
[2023-07-01 09:59:07] [config] ulr-query-vectors: ""
[2023-07-01 09:59:07] [config] ulr-softmax-temperature: 1
[2023-07-01 09:59:07] [config] ulr-trainable-transformation: false
[2023-07-01 09:59:07] [config] unlikelihood-loss: false
[2023-07-01 09:59:07] [config] valid-freq: 50000000
[2023-07-01 09:59:07] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 09:59:07] [config] valid-max-length: 1000
[2023-07-01 09:59:07] [config] valid-metrics:
[2023-07-01 09:59:07] [config]   - cross-entropy
[2023-07-01 09:59:07] [config]   - translation
[2023-07-01 09:59:07] [config] valid-mini-batch: 64
[2023-07-01 09:59:07] [config] valid-reset-stalled: false
[2023-07-01 09:59:07] [config] valid-script-args:
[2023-07-01 09:59:07] [config]   []
[2023-07-01 09:59:07] [config] valid-script-path: ""
[2023-07-01 09:59:07] [config] valid-sets:
[2023-07-01 09:59:07] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 09:59:07] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 09:59:07] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 09:59:07] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 09:59:07] [config] vocabs:
[2023-07-01 09:59:07] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 09:59:07] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 09:59:07] [config] word-penalty: 0
[2023-07-01 09:59:07] [config] word-scores: false
[2023-07-01 09:59:07] [config] workspace: 2048
[2023-07-01 09:59:07] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 09:59:07] Using synchronous SGD
[2023-07-01 09:59:07] Synced seed 1234
[2023-07-01 09:59:07] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 09:59:07] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 09:59:07] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 09:59:07] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 09:59:07] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 09:59:07] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 09:59:08] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 09:59:08] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 09:59:08] [comm] Using global sharding
[2023-07-01 09:59:08] [comm] NCCLCommunicators constructed successfully
[2023-07-01 09:59:08] [training] Using 1 GPUs
[2023-07-01 09:59:08] [logits] Applying loss function for 1 factor(s)
[2023-07-01 09:59:08] [memory] Reserving 88 MB, device gpu0
[2023-07-01 09:59:08] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 09:59:09] [memory] Reserving 88 MB, device gpu0
[2023-07-01 09:59:16] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 09:59:16] [valid] No post-processing script given for validating translator
[2023-07-01 09:59:16] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 09:59:16] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 09:59:16] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 09:59:16] [comm] Using global sharding
[2023-07-01 09:59:16] [comm] NCCLCommunicators constructed successfully
[2023-07-01 09:59:16] [training] Using 1 GPUs
[2023-07-01 09:59:16] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 09:59:17] Allocating memory for general optimizer shards
[2023-07-01 09:59:17] [memory] Reserving 88 MB, device gpu0
[2023-07-01 09:59:17] Loading Adam parameters
[2023-07-01 09:59:17] [memory] Reserving 176 MB, device gpu0
[2023-07-01 09:59:17] [memory] Reserving 88 MB, device gpu0
[2023-07-01 09:59:17] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 09:59:17] [data] Restoring the corpus state to epoch 19, batch 3402
[2023-07-01 09:59:17] [data] Shuffling data
[2023-07-01 09:59:17] [data] Done reading 20,192 sentences
[2023-07-01 09:59:17] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 09:59:17] Training started
[2023-07-01 09:59:17] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-07-01 09:59:17] [memory] Reserving 88 MB, device gpu0
[2023-07-01 09:59:18] Parameter type float32, optimization type float32, casting types false
[2023-07-01 09:59:41] Seen 20,073 samples
[2023-07-01 09:59:41] Starting data epoch 20 in logical epoch 20
[2023-07-01 09:59:41] Training finished
[2023-07-01 09:59:44] [valid] Ep. 20 : Up. 3591 : cross-entropy : 148.839 : new best
[2023-07-01 10:02:21] [valid] Ep. 20 : Up. 3591 : translation : 0 : new best
[2023-07-01 10:02:21] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:02:22] Saving Adam parameters
[2023-07-01 10:02:23] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 10:02:31] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:02:31] [marian] Running on node20.datos.cluster.uy as process 7478 with command line:
[2023-07-01 10:02:31] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 20 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 10:02:31] [config] after: 0e
[2023-07-01 10:02:31] [config] after-batches: 0
[2023-07-01 10:02:31] [config] after-epochs: 20
[2023-07-01 10:02:31] [config] all-caps-every: 0
[2023-07-01 10:02:31] [config] allow-unk: false
[2023-07-01 10:02:31] [config] authors: false
[2023-07-01 10:02:31] [config] beam-size: 12
[2023-07-01 10:02:31] [config] bert-class-symbol: "[CLS]"
[2023-07-01 10:02:31] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 10:02:31] [config] bert-masking-fraction: 0.15
[2023-07-01 10:02:31] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 10:02:31] [config] bert-train-type-embeddings: true
[2023-07-01 10:02:31] [config] bert-type-vocab-size: 2
[2023-07-01 10:02:31] [config] build-info: ""
[2023-07-01 10:02:31] [config] check-gradient-nan: false
[2023-07-01 10:02:31] [config] check-nan: false
[2023-07-01 10:02:31] [config] cite: false
[2023-07-01 10:02:31] [config] clip-norm: 5
[2023-07-01 10:02:31] [config] cost-scaling:
[2023-07-01 10:02:31] [config]   []
[2023-07-01 10:02:31] [config] cost-type: ce-sum
[2023-07-01 10:02:31] [config] cpu-threads: 0
[2023-07-01 10:02:31] [config] data-threads: 8
[2023-07-01 10:02:31] [config] data-weighting: ""
[2023-07-01 10:02:31] [config] data-weighting-type: sentence
[2023-07-01 10:02:31] [config] dec-cell: gru
[2023-07-01 10:02:31] [config] dec-cell-base-depth: 2
[2023-07-01 10:02:31] [config] dec-cell-high-depth: 1
[2023-07-01 10:02:31] [config] dec-depth: 2
[2023-07-01 10:02:31] [config] devices:
[2023-07-01 10:02:31] [config]   - 0
[2023-07-01 10:02:31] [config] dim-emb: 512
[2023-07-01 10:02:31] [config] dim-rnn: 1024
[2023-07-01 10:02:31] [config] dim-vocabs:
[2023-07-01 10:02:31] [config]   - 16384
[2023-07-01 10:02:31] [config]   - 16384
[2023-07-01 10:02:31] [config] disp-first: 0
[2023-07-01 10:02:31] [config] disp-freq: 1000u
[2023-07-01 10:02:31] [config] disp-label-counts: true
[2023-07-01 10:02:31] [config] dropout-rnn: 0
[2023-07-01 10:02:31] [config] dropout-src: 0
[2023-07-01 10:02:31] [config] dropout-trg: 0
[2023-07-01 10:02:31] [config] dump-config: ""
[2023-07-01 10:02:31] [config] dynamic-gradient-scaling:
[2023-07-01 10:02:31] [config]   []
[2023-07-01 10:02:31] [config] early-stopping: 10
[2023-07-01 10:02:31] [config] early-stopping-on: first
[2023-07-01 10:02:31] [config] embedding-fix-src: false
[2023-07-01 10:02:31] [config] embedding-fix-trg: false
[2023-07-01 10:02:31] [config] embedding-normalization: false
[2023-07-01 10:02:31] [config] embedding-vectors:
[2023-07-01 10:02:31] [config]   []
[2023-07-01 10:02:31] [config] enc-cell: gru
[2023-07-01 10:02:31] [config] enc-cell-depth: 1
[2023-07-01 10:02:31] [config] enc-depth: 2
[2023-07-01 10:02:31] [config] enc-type: bidirectional
[2023-07-01 10:02:31] [config] english-title-case-every: 0
[2023-07-01 10:02:31] [config] exponential-smoothing: 0.0001
[2023-07-01 10:02:31] [config] factor-weight: 1
[2023-07-01 10:02:31] [config] factors-combine: sum
[2023-07-01 10:02:31] [config] factors-dim-emb: 0
[2023-07-01 10:02:31] [config] gradient-checkpointing: false
[2023-07-01 10:02:31] [config] gradient-norm-average-window: 100
[2023-07-01 10:02:31] [config] guided-alignment: none
[2023-07-01 10:02:31] [config] guided-alignment-cost: mse
[2023-07-01 10:02:31] [config] guided-alignment-weight: 0.1
[2023-07-01 10:02:31] [config] ignore-model-config: false
[2023-07-01 10:02:31] [config] input-types:
[2023-07-01 10:02:31] [config]   []
[2023-07-01 10:02:31] [config] interpolate-env-vars: false
[2023-07-01 10:02:31] [config] keep-best: false
[2023-07-01 10:02:31] [config] label-smoothing: 0.1
[2023-07-01 10:02:31] [config] layer-normalization: false
[2023-07-01 10:02:31] [config] learn-rate: 0.0003
[2023-07-01 10:02:31] [config] lemma-dependency: ""
[2023-07-01 10:02:31] [config] lemma-dim-emb: 0
[2023-07-01 10:02:31] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 10:02:31] [config] log-level: info
[2023-07-01 10:02:31] [config] log-time-zone: ""
[2023-07-01 10:02:31] [config] logical-epoch:
[2023-07-01 10:02:31] [config]   - 1e
[2023-07-01 10:02:31] [config]   - 0
[2023-07-01 10:02:31] [config] lr-decay: 0
[2023-07-01 10:02:31] [config] lr-decay-freq: 50000
[2023-07-01 10:02:31] [config] lr-decay-inv-sqrt:
[2023-07-01 10:02:31] [config]   - 16000
[2023-07-01 10:02:31] [config] lr-decay-repeat-warmup: false
[2023-07-01 10:02:31] [config] lr-decay-reset-optimizer: false
[2023-07-01 10:02:31] [config] lr-decay-start:
[2023-07-01 10:02:31] [config]   - 10
[2023-07-01 10:02:31] [config]   - 1
[2023-07-01 10:02:31] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 10:02:31] [config] lr-report: true
[2023-07-01 10:02:31] [config] lr-warmup: 16000
[2023-07-01 10:02:31] [config] lr-warmup-at-reload: false
[2023-07-01 10:02:31] [config] lr-warmup-cycle: false
[2023-07-01 10:02:31] [config] lr-warmup-start-rate: 0
[2023-07-01 10:02:31] [config] max-length: 100
[2023-07-01 10:02:31] [config] max-length-crop: false
[2023-07-01 10:02:31] [config] max-length-factor: 3
[2023-07-01 10:02:31] [config] maxi-batch: 100
[2023-07-01 10:02:31] [config] maxi-batch-sort: trg
[2023-07-01 10:02:31] [config] mini-batch: 1000
[2023-07-01 10:02:31] [config] mini-batch-fit: true
[2023-07-01 10:02:31] [config] mini-batch-fit-step: 10
[2023-07-01 10:02:31] [config] mini-batch-round-up: true
[2023-07-01 10:02:31] [config] mini-batch-track-lr: false
[2023-07-01 10:02:31] [config] mini-batch-warmup: 0
[2023-07-01 10:02:31] [config] mini-batch-words: 0
[2023-07-01 10:02:31] [config] mini-batch-words-ref: 0
[2023-07-01 10:02:31] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:02:31] [config] multi-loss-type: sum
[2023-07-01 10:02:31] [config] n-best: false
[2023-07-01 10:02:31] [config] no-nccl: false
[2023-07-01 10:02:31] [config] no-reload: false
[2023-07-01 10:02:31] [config] no-restore-corpus: false
[2023-07-01 10:02:31] [config] normalize: 1
[2023-07-01 10:02:31] [config] normalize-gradient: false
[2023-07-01 10:02:31] [config] num-devices: 0
[2023-07-01 10:02:31] [config] optimizer: adam
[2023-07-01 10:02:31] [config] optimizer-delay: 1
[2023-07-01 10:02:31] [config] optimizer-params:
[2023-07-01 10:02:31] [config]   - 0.9
[2023-07-01 10:02:31] [config]   - 0.98
[2023-07-01 10:02:31] [config]   - 1e-09
[2023-07-01 10:02:31] [config] output-omit-bias: false
[2023-07-01 10:02:31] [config] overwrite: true
[2023-07-01 10:02:31] [config] precision:
[2023-07-01 10:02:31] [config]   - float32
[2023-07-01 10:02:31] [config]   - float32
[2023-07-01 10:02:31] [config] pretrained-model: ""
[2023-07-01 10:02:31] [config] quantize-biases: false
[2023-07-01 10:02:31] [config] quantize-bits: 0
[2023-07-01 10:02:31] [config] quantize-log-based: false
[2023-07-01 10:02:31] [config] quantize-optimization-steps: 0
[2023-07-01 10:02:31] [config] quiet: false
[2023-07-01 10:02:31] [config] quiet-translation: true
[2023-07-01 10:02:31] [config] relative-paths: false
[2023-07-01 10:02:31] [config] right-left: false
[2023-07-01 10:02:31] [config] save-freq: 10000u
[2023-07-01 10:02:31] [config] seed: 1234
[2023-07-01 10:02:31] [config] sentencepiece-alphas:
[2023-07-01 10:02:31] [config]   []
[2023-07-01 10:02:31] [config] sentencepiece-max-lines: 2000000
[2023-07-01 10:02:31] [config] sentencepiece-options: ""
[2023-07-01 10:02:31] [config] sharding: global
[2023-07-01 10:02:31] [config] shuffle: data
[2023-07-01 10:02:31] [config] shuffle-in-ram: false
[2023-07-01 10:02:31] [config] sigterm: save-and-exit
[2023-07-01 10:02:31] [config] skip: false
[2023-07-01 10:02:31] [config] sqlite: ""
[2023-07-01 10:02:31] [config] sqlite-drop: false
[2023-07-01 10:02:31] [config] sync-freq: 200u
[2023-07-01 10:02:31] [config] sync-sgd: true
[2023-07-01 10:02:31] [config] tempdir: /tmp
[2023-07-01 10:02:31] [config] tied-embeddings: false
[2023-07-01 10:02:31] [config] tied-embeddings-all: true
[2023-07-01 10:02:31] [config] tied-embeddings-src: false
[2023-07-01 10:02:31] [config] train-embedder-rank:
[2023-07-01 10:02:31] [config]   []
[2023-07-01 10:02:31] [config] train-sets:
[2023-07-01 10:02:31] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 10:02:31] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 10:02:31] [config] transformer-aan-activation: swish
[2023-07-01 10:02:31] [config] transformer-aan-depth: 2
[2023-07-01 10:02:31] [config] transformer-aan-nogate: false
[2023-07-01 10:02:31] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 10:02:31] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 10:02:31] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 10:02:31] [config] transformer-depth-scaling: false
[2023-07-01 10:02:31] [config] transformer-dim-aan: 2048
[2023-07-01 10:02:31] [config] transformer-dim-ffn: 2048
[2023-07-01 10:02:31] [config] transformer-dropout: 0.1
[2023-07-01 10:02:31] [config] transformer-dropout-attention: 0
[2023-07-01 10:02:31] [config] transformer-dropout-ffn: 0
[2023-07-01 10:02:31] [config] transformer-ffn-activation: swish
[2023-07-01 10:02:31] [config] transformer-ffn-depth: 2
[2023-07-01 10:02:31] [config] transformer-guided-alignment-layer: last
[2023-07-01 10:02:31] [config] transformer-heads: 8
[2023-07-01 10:02:31] [config] transformer-no-projection: false
[2023-07-01 10:02:31] [config] transformer-pool: false
[2023-07-01 10:02:31] [config] transformer-postprocess: dan
[2023-07-01 10:02:31] [config] transformer-postprocess-emb: d
[2023-07-01 10:02:31] [config] transformer-postprocess-top: ""
[2023-07-01 10:02:31] [config] transformer-preprocess: ""
[2023-07-01 10:02:31] [config] transformer-tied-layers:
[2023-07-01 10:02:31] [config]   []
[2023-07-01 10:02:31] [config] transformer-train-position-embeddings: false
[2023-07-01 10:02:31] [config] tsv: false
[2023-07-01 10:02:31] [config] tsv-fields: 0
[2023-07-01 10:02:31] [config] type: transformer
[2023-07-01 10:02:31] [config] ulr: false
[2023-07-01 10:02:31] [config] ulr-dim-emb: 0
[2023-07-01 10:02:31] [config] ulr-dropout: 0
[2023-07-01 10:02:31] [config] ulr-keys-vectors: ""
[2023-07-01 10:02:31] [config] ulr-query-vectors: ""
[2023-07-01 10:02:31] [config] ulr-softmax-temperature: 1
[2023-07-01 10:02:31] [config] ulr-trainable-transformation: false
[2023-07-01 10:02:31] [config] unlikelihood-loss: false
[2023-07-01 10:02:31] [config] valid-freq: 50000000
[2023-07-01 10:02:31] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 10:02:31] [config] valid-max-length: 1000
[2023-07-01 10:02:31] [config] valid-metrics:
[2023-07-01 10:02:31] [config]   - cross-entropy
[2023-07-01 10:02:31] [config]   - translation
[2023-07-01 10:02:31] [config] valid-mini-batch: 64
[2023-07-01 10:02:31] [config] valid-reset-stalled: false
[2023-07-01 10:02:31] [config] valid-script-args:
[2023-07-01 10:02:31] [config]   []
[2023-07-01 10:02:31] [config] valid-script-path: ""
[2023-07-01 10:02:31] [config] valid-sets:
[2023-07-01 10:02:31] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 10:02:31] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 10:02:31] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 10:02:31] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:02:31] [config] vocabs:
[2023-07-01 10:02:31] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 10:02:31] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 10:02:31] [config] word-penalty: 0
[2023-07-01 10:02:31] [config] word-scores: false
[2023-07-01 10:02:31] [config] workspace: 2048
[2023-07-01 10:02:31] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:02:31] Using synchronous SGD
[2023-07-01 10:02:31] Synced seed 1234
[2023-07-01 10:02:31] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 10:02:31] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 10:02:31] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 10:02:31] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 10:02:31] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 10:02:31] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 10:02:32] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 10:02:32] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 10:02:32] [comm] Using global sharding
[2023-07-01 10:02:32] [comm] NCCLCommunicators constructed successfully
[2023-07-01 10:02:32] [training] Using 1 GPUs
[2023-07-01 10:02:32] [logits] Applying loss function for 1 factor(s)
[2023-07-01 10:02:32] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:02:32] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 10:02:32] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:02:40] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 10:02:40] [valid] No post-processing script given for validating translator
[2023-07-01 10:02:40] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 10:02:40] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 10:02:40] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 10:02:40] [comm] Using global sharding
[2023-07-01 10:02:40] [comm] NCCLCommunicators constructed successfully
[2023-07-01 10:02:40] [training] Using 1 GPUs
[2023-07-01 10:02:40] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:02:41] Allocating memory for general optimizer shards
[2023-07-01 10:02:41] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:02:41] Loading Adam parameters
[2023-07-01 10:02:41] [memory] Reserving 176 MB, device gpu0
[2023-07-01 10:02:41] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:02:41] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 10:02:41] [data] Restoring the corpus state to epoch 20, batch 3591
[2023-07-01 10:02:41] [data] Shuffling data
[2023-07-01 10:02:41] [data] Done reading 20,192 sentences
[2023-07-01 10:02:41] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 10:02:41] Training started
[2023-07-01 10:02:41] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-07-01 10:02:41] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:02:41] Parameter type float32, optimization type float32, casting types false
[2023-07-01 10:03:05] Seen 20,073 samples
[2023-07-01 10:03:05] Starting data epoch 21 in logical epoch 21
[2023-07-01 10:03:05] Training finished
[2023-07-01 10:03:08] [valid] Ep. 21 : Up. 3780 : cross-entropy : 146.617 : new best
[2023-07-01 10:05:30] [valid] Ep. 21 : Up. 3780 : translation : 0 : new best
[2023-07-01 10:05:30] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:05:31] Saving Adam parameters
[2023-07-01 10:05:31] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 10:05:37] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:05:37] [marian] Running on node20.datos.cluster.uy as process 7687 with command line:
[2023-07-01 10:05:37] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 21 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 10:05:37] [config] after: 0e
[2023-07-01 10:05:37] [config] after-batches: 0
[2023-07-01 10:05:37] [config] after-epochs: 21
[2023-07-01 10:05:37] [config] all-caps-every: 0
[2023-07-01 10:05:37] [config] allow-unk: false
[2023-07-01 10:05:37] [config] authors: false
[2023-07-01 10:05:37] [config] beam-size: 12
[2023-07-01 10:05:37] [config] bert-class-symbol: "[CLS]"
[2023-07-01 10:05:37] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 10:05:37] [config] bert-masking-fraction: 0.15
[2023-07-01 10:05:37] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 10:05:37] [config] bert-train-type-embeddings: true
[2023-07-01 10:05:37] [config] bert-type-vocab-size: 2
[2023-07-01 10:05:37] [config] build-info: ""
[2023-07-01 10:05:37] [config] check-gradient-nan: false
[2023-07-01 10:05:37] [config] check-nan: false
[2023-07-01 10:05:37] [config] cite: false
[2023-07-01 10:05:37] [config] clip-norm: 5
[2023-07-01 10:05:37] [config] cost-scaling:
[2023-07-01 10:05:37] [config]   []
[2023-07-01 10:05:37] [config] cost-type: ce-sum
[2023-07-01 10:05:37] [config] cpu-threads: 0
[2023-07-01 10:05:37] [config] data-threads: 8
[2023-07-01 10:05:37] [config] data-weighting: ""
[2023-07-01 10:05:37] [config] data-weighting-type: sentence
[2023-07-01 10:05:37] [config] dec-cell: gru
[2023-07-01 10:05:37] [config] dec-cell-base-depth: 2
[2023-07-01 10:05:37] [config] dec-cell-high-depth: 1
[2023-07-01 10:05:37] [config] dec-depth: 2
[2023-07-01 10:05:37] [config] devices:
[2023-07-01 10:05:37] [config]   - 0
[2023-07-01 10:05:37] [config] dim-emb: 512
[2023-07-01 10:05:37] [config] dim-rnn: 1024
[2023-07-01 10:05:37] [config] dim-vocabs:
[2023-07-01 10:05:37] [config]   - 16384
[2023-07-01 10:05:37] [config]   - 16384
[2023-07-01 10:05:37] [config] disp-first: 0
[2023-07-01 10:05:37] [config] disp-freq: 1000u
[2023-07-01 10:05:37] [config] disp-label-counts: true
[2023-07-01 10:05:37] [config] dropout-rnn: 0
[2023-07-01 10:05:37] [config] dropout-src: 0
[2023-07-01 10:05:37] [config] dropout-trg: 0
[2023-07-01 10:05:37] [config] dump-config: ""
[2023-07-01 10:05:37] [config] dynamic-gradient-scaling:
[2023-07-01 10:05:37] [config]   []
[2023-07-01 10:05:37] [config] early-stopping: 10
[2023-07-01 10:05:37] [config] early-stopping-on: first
[2023-07-01 10:05:37] [config] embedding-fix-src: false
[2023-07-01 10:05:37] [config] embedding-fix-trg: false
[2023-07-01 10:05:37] [config] embedding-normalization: false
[2023-07-01 10:05:37] [config] embedding-vectors:
[2023-07-01 10:05:37] [config]   []
[2023-07-01 10:05:37] [config] enc-cell: gru
[2023-07-01 10:05:37] [config] enc-cell-depth: 1
[2023-07-01 10:05:37] [config] enc-depth: 2
[2023-07-01 10:05:37] [config] enc-type: bidirectional
[2023-07-01 10:05:37] [config] english-title-case-every: 0
[2023-07-01 10:05:37] [config] exponential-smoothing: 0.0001
[2023-07-01 10:05:37] [config] factor-weight: 1
[2023-07-01 10:05:37] [config] factors-combine: sum
[2023-07-01 10:05:37] [config] factors-dim-emb: 0
[2023-07-01 10:05:37] [config] gradient-checkpointing: false
[2023-07-01 10:05:37] [config] gradient-norm-average-window: 100
[2023-07-01 10:05:37] [config] guided-alignment: none
[2023-07-01 10:05:37] [config] guided-alignment-cost: mse
[2023-07-01 10:05:37] [config] guided-alignment-weight: 0.1
[2023-07-01 10:05:37] [config] ignore-model-config: false
[2023-07-01 10:05:37] [config] input-types:
[2023-07-01 10:05:37] [config]   []
[2023-07-01 10:05:37] [config] interpolate-env-vars: false
[2023-07-01 10:05:37] [config] keep-best: false
[2023-07-01 10:05:37] [config] label-smoothing: 0.1
[2023-07-01 10:05:37] [config] layer-normalization: false
[2023-07-01 10:05:37] [config] learn-rate: 0.0003
[2023-07-01 10:05:37] [config] lemma-dependency: ""
[2023-07-01 10:05:37] [config] lemma-dim-emb: 0
[2023-07-01 10:05:37] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 10:05:37] [config] log-level: info
[2023-07-01 10:05:37] [config] log-time-zone: ""
[2023-07-01 10:05:37] [config] logical-epoch:
[2023-07-01 10:05:37] [config]   - 1e
[2023-07-01 10:05:37] [config]   - 0
[2023-07-01 10:05:37] [config] lr-decay: 0
[2023-07-01 10:05:37] [config] lr-decay-freq: 50000
[2023-07-01 10:05:37] [config] lr-decay-inv-sqrt:
[2023-07-01 10:05:37] [config]   - 16000
[2023-07-01 10:05:37] [config] lr-decay-repeat-warmup: false
[2023-07-01 10:05:37] [config] lr-decay-reset-optimizer: false
[2023-07-01 10:05:37] [config] lr-decay-start:
[2023-07-01 10:05:37] [config]   - 10
[2023-07-01 10:05:37] [config]   - 1
[2023-07-01 10:05:37] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 10:05:37] [config] lr-report: true
[2023-07-01 10:05:37] [config] lr-warmup: 16000
[2023-07-01 10:05:37] [config] lr-warmup-at-reload: false
[2023-07-01 10:05:37] [config] lr-warmup-cycle: false
[2023-07-01 10:05:37] [config] lr-warmup-start-rate: 0
[2023-07-01 10:05:37] [config] max-length: 100
[2023-07-01 10:05:37] [config] max-length-crop: false
[2023-07-01 10:05:37] [config] max-length-factor: 3
[2023-07-01 10:05:37] [config] maxi-batch: 100
[2023-07-01 10:05:37] [config] maxi-batch-sort: trg
[2023-07-01 10:05:37] [config] mini-batch: 1000
[2023-07-01 10:05:37] [config] mini-batch-fit: true
[2023-07-01 10:05:37] [config] mini-batch-fit-step: 10
[2023-07-01 10:05:37] [config] mini-batch-round-up: true
[2023-07-01 10:05:37] [config] mini-batch-track-lr: false
[2023-07-01 10:05:37] [config] mini-batch-warmup: 0
[2023-07-01 10:05:37] [config] mini-batch-words: 0
[2023-07-01 10:05:37] [config] mini-batch-words-ref: 0
[2023-07-01 10:05:37] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:05:37] [config] multi-loss-type: sum
[2023-07-01 10:05:37] [config] n-best: false
[2023-07-01 10:05:37] [config] no-nccl: false
[2023-07-01 10:05:37] [config] no-reload: false
[2023-07-01 10:05:37] [config] no-restore-corpus: false
[2023-07-01 10:05:37] [config] normalize: 1
[2023-07-01 10:05:37] [config] normalize-gradient: false
[2023-07-01 10:05:37] [config] num-devices: 0
[2023-07-01 10:05:37] [config] optimizer: adam
[2023-07-01 10:05:37] [config] optimizer-delay: 1
[2023-07-01 10:05:37] [config] optimizer-params:
[2023-07-01 10:05:37] [config]   - 0.9
[2023-07-01 10:05:37] [config]   - 0.98
[2023-07-01 10:05:37] [config]   - 1e-09
[2023-07-01 10:05:37] [config] output-omit-bias: false
[2023-07-01 10:05:37] [config] overwrite: true
[2023-07-01 10:05:37] [config] precision:
[2023-07-01 10:05:37] [config]   - float32
[2023-07-01 10:05:37] [config]   - float32
[2023-07-01 10:05:37] [config] pretrained-model: ""
[2023-07-01 10:05:37] [config] quantize-biases: false
[2023-07-01 10:05:37] [config] quantize-bits: 0
[2023-07-01 10:05:37] [config] quantize-log-based: false
[2023-07-01 10:05:37] [config] quantize-optimization-steps: 0
[2023-07-01 10:05:37] [config] quiet: false
[2023-07-01 10:05:37] [config] quiet-translation: true
[2023-07-01 10:05:37] [config] relative-paths: false
[2023-07-01 10:05:37] [config] right-left: false
[2023-07-01 10:05:37] [config] save-freq: 10000u
[2023-07-01 10:05:37] [config] seed: 1234
[2023-07-01 10:05:37] [config] sentencepiece-alphas:
[2023-07-01 10:05:37] [config]   []
[2023-07-01 10:05:37] [config] sentencepiece-max-lines: 2000000
[2023-07-01 10:05:37] [config] sentencepiece-options: ""
[2023-07-01 10:05:37] [config] sharding: global
[2023-07-01 10:05:37] [config] shuffle: data
[2023-07-01 10:05:37] [config] shuffle-in-ram: false
[2023-07-01 10:05:37] [config] sigterm: save-and-exit
[2023-07-01 10:05:37] [config] skip: false
[2023-07-01 10:05:37] [config] sqlite: ""
[2023-07-01 10:05:37] [config] sqlite-drop: false
[2023-07-01 10:05:37] [config] sync-freq: 200u
[2023-07-01 10:05:37] [config] sync-sgd: true
[2023-07-01 10:05:37] [config] tempdir: /tmp
[2023-07-01 10:05:37] [config] tied-embeddings: false
[2023-07-01 10:05:37] [config] tied-embeddings-all: true
[2023-07-01 10:05:37] [config] tied-embeddings-src: false
[2023-07-01 10:05:37] [config] train-embedder-rank:
[2023-07-01 10:05:37] [config]   []
[2023-07-01 10:05:37] [config] train-sets:
[2023-07-01 10:05:37] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 10:05:37] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 10:05:37] [config] transformer-aan-activation: swish
[2023-07-01 10:05:37] [config] transformer-aan-depth: 2
[2023-07-01 10:05:37] [config] transformer-aan-nogate: false
[2023-07-01 10:05:37] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 10:05:37] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 10:05:37] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 10:05:37] [config] transformer-depth-scaling: false
[2023-07-01 10:05:37] [config] transformer-dim-aan: 2048
[2023-07-01 10:05:37] [config] transformer-dim-ffn: 2048
[2023-07-01 10:05:37] [config] transformer-dropout: 0.1
[2023-07-01 10:05:37] [config] transformer-dropout-attention: 0
[2023-07-01 10:05:37] [config] transformer-dropout-ffn: 0
[2023-07-01 10:05:37] [config] transformer-ffn-activation: swish
[2023-07-01 10:05:37] [config] transformer-ffn-depth: 2
[2023-07-01 10:05:37] [config] transformer-guided-alignment-layer: last
[2023-07-01 10:05:37] [config] transformer-heads: 8
[2023-07-01 10:05:37] [config] transformer-no-projection: false
[2023-07-01 10:05:37] [config] transformer-pool: false
[2023-07-01 10:05:37] [config] transformer-postprocess: dan
[2023-07-01 10:05:37] [config] transformer-postprocess-emb: d
[2023-07-01 10:05:37] [config] transformer-postprocess-top: ""
[2023-07-01 10:05:37] [config] transformer-preprocess: ""
[2023-07-01 10:05:37] [config] transformer-tied-layers:
[2023-07-01 10:05:37] [config]   []
[2023-07-01 10:05:37] [config] transformer-train-position-embeddings: false
[2023-07-01 10:05:37] [config] tsv: false
[2023-07-01 10:05:37] [config] tsv-fields: 0
[2023-07-01 10:05:37] [config] type: transformer
[2023-07-01 10:05:37] [config] ulr: false
[2023-07-01 10:05:37] [config] ulr-dim-emb: 0
[2023-07-01 10:05:37] [config] ulr-dropout: 0
[2023-07-01 10:05:37] [config] ulr-keys-vectors: ""
[2023-07-01 10:05:37] [config] ulr-query-vectors: ""
[2023-07-01 10:05:37] [config] ulr-softmax-temperature: 1
[2023-07-01 10:05:37] [config] ulr-trainable-transformation: false
[2023-07-01 10:05:37] [config] unlikelihood-loss: false
[2023-07-01 10:05:37] [config] valid-freq: 50000000
[2023-07-01 10:05:37] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 10:05:37] [config] valid-max-length: 1000
[2023-07-01 10:05:37] [config] valid-metrics:
[2023-07-01 10:05:37] [config]   - cross-entropy
[2023-07-01 10:05:37] [config]   - translation
[2023-07-01 10:05:37] [config] valid-mini-batch: 64
[2023-07-01 10:05:37] [config] valid-reset-stalled: false
[2023-07-01 10:05:37] [config] valid-script-args:
[2023-07-01 10:05:37] [config]   []
[2023-07-01 10:05:37] [config] valid-script-path: ""
[2023-07-01 10:05:37] [config] valid-sets:
[2023-07-01 10:05:37] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 10:05:37] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 10:05:37] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 10:05:37] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:05:37] [config] vocabs:
[2023-07-01 10:05:37] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 10:05:37] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 10:05:37] [config] word-penalty: 0
[2023-07-01 10:05:37] [config] word-scores: false
[2023-07-01 10:05:37] [config] workspace: 2048
[2023-07-01 10:05:37] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:05:37] Using synchronous SGD
[2023-07-01 10:05:37] Synced seed 1234
[2023-07-01 10:05:37] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 10:05:37] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 10:05:37] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 10:05:37] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 10:05:37] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 10:05:37] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 10:05:38] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 10:05:38] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 10:05:38] [comm] Using global sharding
[2023-07-01 10:05:38] [comm] NCCLCommunicators constructed successfully
[2023-07-01 10:05:38] [training] Using 1 GPUs
[2023-07-01 10:05:38] [logits] Applying loss function for 1 factor(s)
[2023-07-01 10:05:38] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:05:39] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 10:05:39] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:05:46] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 10:05:46] [valid] No post-processing script given for validating translator
[2023-07-01 10:05:46] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 10:05:46] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 10:05:46] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 10:05:46] [comm] Using global sharding
[2023-07-01 10:05:47] [comm] NCCLCommunicators constructed successfully
[2023-07-01 10:05:47] [training] Using 1 GPUs
[2023-07-01 10:05:47] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:05:47] Allocating memory for general optimizer shards
[2023-07-01 10:05:47] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:05:47] Loading Adam parameters
[2023-07-01 10:05:47] [memory] Reserving 176 MB, device gpu0
[2023-07-01 10:05:47] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:05:47] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 10:05:47] [data] Restoring the corpus state to epoch 21, batch 3780
[2023-07-01 10:05:47] [data] Shuffling data
[2023-07-01 10:05:48] [data] Done reading 20,192 sentences
[2023-07-01 10:05:48] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 10:05:48] Training started
[2023-07-01 10:05:48] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-07-01 10:05:48] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:05:48] Parameter type float32, optimization type float32, casting types false
[2023-07-01 10:06:12] Seen 20,073 samples
[2023-07-01 10:06:12] Starting data epoch 22 in logical epoch 22
[2023-07-01 10:06:12] Training finished
[2023-07-01 10:06:15] [valid] Ep. 22 : Up. 3969 : cross-entropy : 144.517 : new best
[2023-07-01 10:08:26] [valid] Ep. 22 : Up. 3969 : translation : 0 : new best
[2023-07-01 10:08:26] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:08:27] Saving Adam parameters
[2023-07-01 10:08:28] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 10:08:34] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:08:34] [marian] Running on node20.datos.cluster.uy as process 8210 with command line:
[2023-07-01 10:08:34] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 22 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 10:08:34] [config] after: 0e
[2023-07-01 10:08:34] [config] after-batches: 0
[2023-07-01 10:08:34] [config] after-epochs: 22
[2023-07-01 10:08:34] [config] all-caps-every: 0
[2023-07-01 10:08:34] [config] allow-unk: false
[2023-07-01 10:08:34] [config] authors: false
[2023-07-01 10:08:34] [config] beam-size: 12
[2023-07-01 10:08:34] [config] bert-class-symbol: "[CLS]"
[2023-07-01 10:08:34] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 10:08:34] [config] bert-masking-fraction: 0.15
[2023-07-01 10:08:34] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 10:08:34] [config] bert-train-type-embeddings: true
[2023-07-01 10:08:34] [config] bert-type-vocab-size: 2
[2023-07-01 10:08:34] [config] build-info: ""
[2023-07-01 10:08:34] [config] check-gradient-nan: false
[2023-07-01 10:08:34] [config] check-nan: false
[2023-07-01 10:08:34] [config] cite: false
[2023-07-01 10:08:34] [config] clip-norm: 5
[2023-07-01 10:08:34] [config] cost-scaling:
[2023-07-01 10:08:34] [config]   []
[2023-07-01 10:08:34] [config] cost-type: ce-sum
[2023-07-01 10:08:34] [config] cpu-threads: 0
[2023-07-01 10:08:34] [config] data-threads: 8
[2023-07-01 10:08:34] [config] data-weighting: ""
[2023-07-01 10:08:34] [config] data-weighting-type: sentence
[2023-07-01 10:08:34] [config] dec-cell: gru
[2023-07-01 10:08:34] [config] dec-cell-base-depth: 2
[2023-07-01 10:08:34] [config] dec-cell-high-depth: 1
[2023-07-01 10:08:34] [config] dec-depth: 2
[2023-07-01 10:08:34] [config] devices:
[2023-07-01 10:08:34] [config]   - 0
[2023-07-01 10:08:34] [config] dim-emb: 512
[2023-07-01 10:08:34] [config] dim-rnn: 1024
[2023-07-01 10:08:34] [config] dim-vocabs:
[2023-07-01 10:08:34] [config]   - 16384
[2023-07-01 10:08:34] [config]   - 16384
[2023-07-01 10:08:34] [config] disp-first: 0
[2023-07-01 10:08:34] [config] disp-freq: 1000u
[2023-07-01 10:08:34] [config] disp-label-counts: true
[2023-07-01 10:08:34] [config] dropout-rnn: 0
[2023-07-01 10:08:34] [config] dropout-src: 0
[2023-07-01 10:08:34] [config] dropout-trg: 0
[2023-07-01 10:08:34] [config] dump-config: ""
[2023-07-01 10:08:34] [config] dynamic-gradient-scaling:
[2023-07-01 10:08:34] [config]   []
[2023-07-01 10:08:34] [config] early-stopping: 10
[2023-07-01 10:08:34] [config] early-stopping-on: first
[2023-07-01 10:08:34] [config] embedding-fix-src: false
[2023-07-01 10:08:34] [config] embedding-fix-trg: false
[2023-07-01 10:08:34] [config] embedding-normalization: false
[2023-07-01 10:08:34] [config] embedding-vectors:
[2023-07-01 10:08:34] [config]   []
[2023-07-01 10:08:34] [config] enc-cell: gru
[2023-07-01 10:08:34] [config] enc-cell-depth: 1
[2023-07-01 10:08:34] [config] enc-depth: 2
[2023-07-01 10:08:34] [config] enc-type: bidirectional
[2023-07-01 10:08:34] [config] english-title-case-every: 0
[2023-07-01 10:08:34] [config] exponential-smoothing: 0.0001
[2023-07-01 10:08:34] [config] factor-weight: 1
[2023-07-01 10:08:34] [config] factors-combine: sum
[2023-07-01 10:08:34] [config] factors-dim-emb: 0
[2023-07-01 10:08:34] [config] gradient-checkpointing: false
[2023-07-01 10:08:34] [config] gradient-norm-average-window: 100
[2023-07-01 10:08:34] [config] guided-alignment: none
[2023-07-01 10:08:34] [config] guided-alignment-cost: mse
[2023-07-01 10:08:34] [config] guided-alignment-weight: 0.1
[2023-07-01 10:08:34] [config] ignore-model-config: false
[2023-07-01 10:08:34] [config] input-types:
[2023-07-01 10:08:34] [config]   []
[2023-07-01 10:08:34] [config] interpolate-env-vars: false
[2023-07-01 10:08:34] [config] keep-best: false
[2023-07-01 10:08:34] [config] label-smoothing: 0.1
[2023-07-01 10:08:34] [config] layer-normalization: false
[2023-07-01 10:08:34] [config] learn-rate: 0.0003
[2023-07-01 10:08:34] [config] lemma-dependency: ""
[2023-07-01 10:08:34] [config] lemma-dim-emb: 0
[2023-07-01 10:08:34] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 10:08:34] [config] log-level: info
[2023-07-01 10:08:34] [config] log-time-zone: ""
[2023-07-01 10:08:34] [config] logical-epoch:
[2023-07-01 10:08:34] [config]   - 1e
[2023-07-01 10:08:34] [config]   - 0
[2023-07-01 10:08:34] [config] lr-decay: 0
[2023-07-01 10:08:34] [config] lr-decay-freq: 50000
[2023-07-01 10:08:34] [config] lr-decay-inv-sqrt:
[2023-07-01 10:08:34] [config]   - 16000
[2023-07-01 10:08:34] [config] lr-decay-repeat-warmup: false
[2023-07-01 10:08:34] [config] lr-decay-reset-optimizer: false
[2023-07-01 10:08:34] [config] lr-decay-start:
[2023-07-01 10:08:34] [config]   - 10
[2023-07-01 10:08:34] [config]   - 1
[2023-07-01 10:08:34] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 10:08:34] [config] lr-report: true
[2023-07-01 10:08:34] [config] lr-warmup: 16000
[2023-07-01 10:08:34] [config] lr-warmup-at-reload: false
[2023-07-01 10:08:34] [config] lr-warmup-cycle: false
[2023-07-01 10:08:34] [config] lr-warmup-start-rate: 0
[2023-07-01 10:08:34] [config] max-length: 100
[2023-07-01 10:08:34] [config] max-length-crop: false
[2023-07-01 10:08:34] [config] max-length-factor: 3
[2023-07-01 10:08:34] [config] maxi-batch: 100
[2023-07-01 10:08:34] [config] maxi-batch-sort: trg
[2023-07-01 10:08:34] [config] mini-batch: 1000
[2023-07-01 10:08:34] [config] mini-batch-fit: true
[2023-07-01 10:08:34] [config] mini-batch-fit-step: 10
[2023-07-01 10:08:34] [config] mini-batch-round-up: true
[2023-07-01 10:08:34] [config] mini-batch-track-lr: false
[2023-07-01 10:08:34] [config] mini-batch-warmup: 0
[2023-07-01 10:08:34] [config] mini-batch-words: 0
[2023-07-01 10:08:34] [config] mini-batch-words-ref: 0
[2023-07-01 10:08:34] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:08:34] [config] multi-loss-type: sum
[2023-07-01 10:08:34] [config] n-best: false
[2023-07-01 10:08:34] [config] no-nccl: false
[2023-07-01 10:08:34] [config] no-reload: false
[2023-07-01 10:08:34] [config] no-restore-corpus: false
[2023-07-01 10:08:34] [config] normalize: 1
[2023-07-01 10:08:34] [config] normalize-gradient: false
[2023-07-01 10:08:34] [config] num-devices: 0
[2023-07-01 10:08:34] [config] optimizer: adam
[2023-07-01 10:08:34] [config] optimizer-delay: 1
[2023-07-01 10:08:34] [config] optimizer-params:
[2023-07-01 10:08:34] [config]   - 0.9
[2023-07-01 10:08:34] [config]   - 0.98
[2023-07-01 10:08:34] [config]   - 1e-09
[2023-07-01 10:08:34] [config] output-omit-bias: false
[2023-07-01 10:08:34] [config] overwrite: true
[2023-07-01 10:08:34] [config] precision:
[2023-07-01 10:08:34] [config]   - float32
[2023-07-01 10:08:34] [config]   - float32
[2023-07-01 10:08:34] [config] pretrained-model: ""
[2023-07-01 10:08:34] [config] quantize-biases: false
[2023-07-01 10:08:34] [config] quantize-bits: 0
[2023-07-01 10:08:34] [config] quantize-log-based: false
[2023-07-01 10:08:34] [config] quantize-optimization-steps: 0
[2023-07-01 10:08:34] [config] quiet: false
[2023-07-01 10:08:34] [config] quiet-translation: true
[2023-07-01 10:08:34] [config] relative-paths: false
[2023-07-01 10:08:34] [config] right-left: false
[2023-07-01 10:08:34] [config] save-freq: 10000u
[2023-07-01 10:08:34] [config] seed: 1234
[2023-07-01 10:08:34] [config] sentencepiece-alphas:
[2023-07-01 10:08:34] [config]   []
[2023-07-01 10:08:34] [config] sentencepiece-max-lines: 2000000
[2023-07-01 10:08:34] [config] sentencepiece-options: ""
[2023-07-01 10:08:34] [config] sharding: global
[2023-07-01 10:08:34] [config] shuffle: data
[2023-07-01 10:08:34] [config] shuffle-in-ram: false
[2023-07-01 10:08:34] [config] sigterm: save-and-exit
[2023-07-01 10:08:34] [config] skip: false
[2023-07-01 10:08:34] [config] sqlite: ""
[2023-07-01 10:08:34] [config] sqlite-drop: false
[2023-07-01 10:08:34] [config] sync-freq: 200u
[2023-07-01 10:08:34] [config] sync-sgd: true
[2023-07-01 10:08:34] [config] tempdir: /tmp
[2023-07-01 10:08:34] [config] tied-embeddings: false
[2023-07-01 10:08:34] [config] tied-embeddings-all: true
[2023-07-01 10:08:34] [config] tied-embeddings-src: false
[2023-07-01 10:08:34] [config] train-embedder-rank:
[2023-07-01 10:08:34] [config]   []
[2023-07-01 10:08:34] [config] train-sets:
[2023-07-01 10:08:34] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 10:08:34] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 10:08:34] [config] transformer-aan-activation: swish
[2023-07-01 10:08:34] [config] transformer-aan-depth: 2
[2023-07-01 10:08:34] [config] transformer-aan-nogate: false
[2023-07-01 10:08:34] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 10:08:34] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 10:08:34] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 10:08:34] [config] transformer-depth-scaling: false
[2023-07-01 10:08:34] [config] transformer-dim-aan: 2048
[2023-07-01 10:08:34] [config] transformer-dim-ffn: 2048
[2023-07-01 10:08:34] [config] transformer-dropout: 0.1
[2023-07-01 10:08:34] [config] transformer-dropout-attention: 0
[2023-07-01 10:08:34] [config] transformer-dropout-ffn: 0
[2023-07-01 10:08:34] [config] transformer-ffn-activation: swish
[2023-07-01 10:08:34] [config] transformer-ffn-depth: 2
[2023-07-01 10:08:34] [config] transformer-guided-alignment-layer: last
[2023-07-01 10:08:34] [config] transformer-heads: 8
[2023-07-01 10:08:34] [config] transformer-no-projection: false
[2023-07-01 10:08:34] [config] transformer-pool: false
[2023-07-01 10:08:34] [config] transformer-postprocess: dan
[2023-07-01 10:08:34] [config] transformer-postprocess-emb: d
[2023-07-01 10:08:34] [config] transformer-postprocess-top: ""
[2023-07-01 10:08:34] [config] transformer-preprocess: ""
[2023-07-01 10:08:34] [config] transformer-tied-layers:
[2023-07-01 10:08:34] [config]   []
[2023-07-01 10:08:34] [config] transformer-train-position-embeddings: false
[2023-07-01 10:08:34] [config] tsv: false
[2023-07-01 10:08:34] [config] tsv-fields: 0
[2023-07-01 10:08:34] [config] type: transformer
[2023-07-01 10:08:34] [config] ulr: false
[2023-07-01 10:08:34] [config] ulr-dim-emb: 0
[2023-07-01 10:08:34] [config] ulr-dropout: 0
[2023-07-01 10:08:34] [config] ulr-keys-vectors: ""
[2023-07-01 10:08:34] [config] ulr-query-vectors: ""
[2023-07-01 10:08:34] [config] ulr-softmax-temperature: 1
[2023-07-01 10:08:34] [config] ulr-trainable-transformation: false
[2023-07-01 10:08:34] [config] unlikelihood-loss: false
[2023-07-01 10:08:34] [config] valid-freq: 50000000
[2023-07-01 10:08:34] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 10:08:34] [config] valid-max-length: 1000
[2023-07-01 10:08:34] [config] valid-metrics:
[2023-07-01 10:08:34] [config]   - cross-entropy
[2023-07-01 10:08:34] [config]   - translation
[2023-07-01 10:08:34] [config] valid-mini-batch: 64
[2023-07-01 10:08:34] [config] valid-reset-stalled: false
[2023-07-01 10:08:34] [config] valid-script-args:
[2023-07-01 10:08:34] [config]   []
[2023-07-01 10:08:34] [config] valid-script-path: ""
[2023-07-01 10:08:34] [config] valid-sets:
[2023-07-01 10:08:34] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 10:08:34] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 10:08:34] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 10:08:34] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:08:34] [config] vocabs:
[2023-07-01 10:08:34] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 10:08:34] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 10:08:34] [config] word-penalty: 0
[2023-07-01 10:08:34] [config] word-scores: false
[2023-07-01 10:08:34] [config] workspace: 2048
[2023-07-01 10:08:34] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:08:34] Using synchronous SGD
[2023-07-01 10:08:34] Synced seed 1234
[2023-07-01 10:08:34] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 10:08:34] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 10:08:34] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 10:08:34] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 10:08:34] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 10:08:34] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 10:08:35] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 10:08:35] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 10:08:35] [comm] Using global sharding
[2023-07-01 10:08:35] [comm] NCCLCommunicators constructed successfully
[2023-07-01 10:08:35] [training] Using 1 GPUs
[2023-07-01 10:08:35] [logits] Applying loss function for 1 factor(s)
[2023-07-01 10:08:35] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:08:36] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 10:08:36] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:08:43] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 10:08:43] [valid] No post-processing script given for validating translator
[2023-07-01 10:08:43] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 10:08:43] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 10:08:43] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 10:08:43] [comm] Using global sharding
[2023-07-01 10:08:43] [comm] NCCLCommunicators constructed successfully
[2023-07-01 10:08:43] [training] Using 1 GPUs
[2023-07-01 10:08:43] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:08:44] Allocating memory for general optimizer shards
[2023-07-01 10:08:44] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:08:44] Loading Adam parameters
[2023-07-01 10:08:44] [memory] Reserving 176 MB, device gpu0
[2023-07-01 10:08:44] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:08:44] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 10:08:44] [data] Restoring the corpus state to epoch 22, batch 3969
[2023-07-01 10:08:44] [data] Shuffling data
[2023-07-01 10:08:44] [data] Done reading 20,192 sentences
[2023-07-01 10:08:45] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 10:08:45] Training started
[2023-07-01 10:08:45] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-07-01 10:08:45] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:08:45] Parameter type float32, optimization type float32, casting types false
[2023-07-01 10:08:48] Ep. 22 : Up. 4000 : Sen. 3,464 : Cost 5.36688852 * 3,207,855 @ 4,097 after 12,838,489 : Time 5.10s : 628782.96 words/s : gNorm 1.4927 : L.r. 7.5000e-05
[2023-07-01 10:09:08] Seen 20,073 samples
[2023-07-01 10:09:08] Starting data epoch 23 in logical epoch 23
[2023-07-01 10:09:08] Training finished
[2023-07-01 10:09:12] [valid] Ep. 23 : Up. 4158 : cross-entropy : 142.528 : new best
[2023-07-01 10:11:13] [valid] Ep. 23 : Up. 4158 : translation : 0 : new best
[2023-07-01 10:11:13] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:11:14] Saving Adam parameters
[2023-07-01 10:11:14] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 10:11:20] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:11:20] [marian] Running on node20.datos.cluster.uy as process 8403 with command line:
[2023-07-01 10:11:20] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 23 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 10:11:20] [config] after: 0e
[2023-07-01 10:11:20] [config] after-batches: 0
[2023-07-01 10:11:20] [config] after-epochs: 23
[2023-07-01 10:11:20] [config] all-caps-every: 0
[2023-07-01 10:11:20] [config] allow-unk: false
[2023-07-01 10:11:20] [config] authors: false
[2023-07-01 10:11:20] [config] beam-size: 12
[2023-07-01 10:11:20] [config] bert-class-symbol: "[CLS]"
[2023-07-01 10:11:20] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 10:11:20] [config] bert-masking-fraction: 0.15
[2023-07-01 10:11:20] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 10:11:20] [config] bert-train-type-embeddings: true
[2023-07-01 10:11:20] [config] bert-type-vocab-size: 2
[2023-07-01 10:11:20] [config] build-info: ""
[2023-07-01 10:11:20] [config] check-gradient-nan: false
[2023-07-01 10:11:20] [config] check-nan: false
[2023-07-01 10:11:20] [config] cite: false
[2023-07-01 10:11:20] [config] clip-norm: 5
[2023-07-01 10:11:20] [config] cost-scaling:
[2023-07-01 10:11:20] [config]   []
[2023-07-01 10:11:20] [config] cost-type: ce-sum
[2023-07-01 10:11:20] [config] cpu-threads: 0
[2023-07-01 10:11:20] [config] data-threads: 8
[2023-07-01 10:11:20] [config] data-weighting: ""
[2023-07-01 10:11:20] [config] data-weighting-type: sentence
[2023-07-01 10:11:20] [config] dec-cell: gru
[2023-07-01 10:11:20] [config] dec-cell-base-depth: 2
[2023-07-01 10:11:20] [config] dec-cell-high-depth: 1
[2023-07-01 10:11:20] [config] dec-depth: 2
[2023-07-01 10:11:20] [config] devices:
[2023-07-01 10:11:20] [config]   - 0
[2023-07-01 10:11:20] [config] dim-emb: 512
[2023-07-01 10:11:20] [config] dim-rnn: 1024
[2023-07-01 10:11:20] [config] dim-vocabs:
[2023-07-01 10:11:20] [config]   - 16384
[2023-07-01 10:11:20] [config]   - 16384
[2023-07-01 10:11:20] [config] disp-first: 0
[2023-07-01 10:11:20] [config] disp-freq: 1000u
[2023-07-01 10:11:20] [config] disp-label-counts: true
[2023-07-01 10:11:20] [config] dropout-rnn: 0
[2023-07-01 10:11:20] [config] dropout-src: 0
[2023-07-01 10:11:20] [config] dropout-trg: 0
[2023-07-01 10:11:20] [config] dump-config: ""
[2023-07-01 10:11:20] [config] dynamic-gradient-scaling:
[2023-07-01 10:11:20] [config]   []
[2023-07-01 10:11:20] [config] early-stopping: 10
[2023-07-01 10:11:20] [config] early-stopping-on: first
[2023-07-01 10:11:20] [config] embedding-fix-src: false
[2023-07-01 10:11:20] [config] embedding-fix-trg: false
[2023-07-01 10:11:20] [config] embedding-normalization: false
[2023-07-01 10:11:20] [config] embedding-vectors:
[2023-07-01 10:11:20] [config]   []
[2023-07-01 10:11:20] [config] enc-cell: gru
[2023-07-01 10:11:20] [config] enc-cell-depth: 1
[2023-07-01 10:11:20] [config] enc-depth: 2
[2023-07-01 10:11:20] [config] enc-type: bidirectional
[2023-07-01 10:11:20] [config] english-title-case-every: 0
[2023-07-01 10:11:20] [config] exponential-smoothing: 0.0001
[2023-07-01 10:11:20] [config] factor-weight: 1
[2023-07-01 10:11:20] [config] factors-combine: sum
[2023-07-01 10:11:20] [config] factors-dim-emb: 0
[2023-07-01 10:11:20] [config] gradient-checkpointing: false
[2023-07-01 10:11:20] [config] gradient-norm-average-window: 100
[2023-07-01 10:11:20] [config] guided-alignment: none
[2023-07-01 10:11:20] [config] guided-alignment-cost: mse
[2023-07-01 10:11:20] [config] guided-alignment-weight: 0.1
[2023-07-01 10:11:20] [config] ignore-model-config: false
[2023-07-01 10:11:20] [config] input-types:
[2023-07-01 10:11:20] [config]   []
[2023-07-01 10:11:20] [config] interpolate-env-vars: false
[2023-07-01 10:11:20] [config] keep-best: false
[2023-07-01 10:11:20] [config] label-smoothing: 0.1
[2023-07-01 10:11:20] [config] layer-normalization: false
[2023-07-01 10:11:20] [config] learn-rate: 0.0003
[2023-07-01 10:11:20] [config] lemma-dependency: ""
[2023-07-01 10:11:20] [config] lemma-dim-emb: 0
[2023-07-01 10:11:20] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 10:11:20] [config] log-level: info
[2023-07-01 10:11:20] [config] log-time-zone: ""
[2023-07-01 10:11:20] [config] logical-epoch:
[2023-07-01 10:11:20] [config]   - 1e
[2023-07-01 10:11:20] [config]   - 0
[2023-07-01 10:11:20] [config] lr-decay: 0
[2023-07-01 10:11:20] [config] lr-decay-freq: 50000
[2023-07-01 10:11:20] [config] lr-decay-inv-sqrt:
[2023-07-01 10:11:20] [config]   - 16000
[2023-07-01 10:11:20] [config] lr-decay-repeat-warmup: false
[2023-07-01 10:11:20] [config] lr-decay-reset-optimizer: false
[2023-07-01 10:11:20] [config] lr-decay-start:
[2023-07-01 10:11:20] [config]   - 10
[2023-07-01 10:11:20] [config]   - 1
[2023-07-01 10:11:20] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 10:11:20] [config] lr-report: true
[2023-07-01 10:11:20] [config] lr-warmup: 16000
[2023-07-01 10:11:20] [config] lr-warmup-at-reload: false
[2023-07-01 10:11:20] [config] lr-warmup-cycle: false
[2023-07-01 10:11:20] [config] lr-warmup-start-rate: 0
[2023-07-01 10:11:20] [config] max-length: 100
[2023-07-01 10:11:20] [config] max-length-crop: false
[2023-07-01 10:11:20] [config] max-length-factor: 3
[2023-07-01 10:11:20] [config] maxi-batch: 100
[2023-07-01 10:11:20] [config] maxi-batch-sort: trg
[2023-07-01 10:11:20] [config] mini-batch: 1000
[2023-07-01 10:11:20] [config] mini-batch-fit: true
[2023-07-01 10:11:20] [config] mini-batch-fit-step: 10
[2023-07-01 10:11:20] [config] mini-batch-round-up: true
[2023-07-01 10:11:20] [config] mini-batch-track-lr: false
[2023-07-01 10:11:20] [config] mini-batch-warmup: 0
[2023-07-01 10:11:20] [config] mini-batch-words: 0
[2023-07-01 10:11:20] [config] mini-batch-words-ref: 0
[2023-07-01 10:11:20] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:11:20] [config] multi-loss-type: sum
[2023-07-01 10:11:20] [config] n-best: false
[2023-07-01 10:11:20] [config] no-nccl: false
[2023-07-01 10:11:20] [config] no-reload: false
[2023-07-01 10:11:20] [config] no-restore-corpus: false
[2023-07-01 10:11:20] [config] normalize: 1
[2023-07-01 10:11:20] [config] normalize-gradient: false
[2023-07-01 10:11:20] [config] num-devices: 0
[2023-07-01 10:11:20] [config] optimizer: adam
[2023-07-01 10:11:20] [config] optimizer-delay: 1
[2023-07-01 10:11:20] [config] optimizer-params:
[2023-07-01 10:11:20] [config]   - 0.9
[2023-07-01 10:11:20] [config]   - 0.98
[2023-07-01 10:11:20] [config]   - 1e-09
[2023-07-01 10:11:20] [config] output-omit-bias: false
[2023-07-01 10:11:20] [config] overwrite: true
[2023-07-01 10:11:20] [config] precision:
[2023-07-01 10:11:20] [config]   - float32
[2023-07-01 10:11:20] [config]   - float32
[2023-07-01 10:11:20] [config] pretrained-model: ""
[2023-07-01 10:11:20] [config] quantize-biases: false
[2023-07-01 10:11:20] [config] quantize-bits: 0
[2023-07-01 10:11:20] [config] quantize-log-based: false
[2023-07-01 10:11:20] [config] quantize-optimization-steps: 0
[2023-07-01 10:11:20] [config] quiet: false
[2023-07-01 10:11:20] [config] quiet-translation: true
[2023-07-01 10:11:20] [config] relative-paths: false
[2023-07-01 10:11:20] [config] right-left: false
[2023-07-01 10:11:20] [config] save-freq: 10000u
[2023-07-01 10:11:20] [config] seed: 1234
[2023-07-01 10:11:20] [config] sentencepiece-alphas:
[2023-07-01 10:11:20] [config]   []
[2023-07-01 10:11:20] [config] sentencepiece-max-lines: 2000000
[2023-07-01 10:11:20] [config] sentencepiece-options: ""
[2023-07-01 10:11:20] [config] sharding: global
[2023-07-01 10:11:20] [config] shuffle: data
[2023-07-01 10:11:20] [config] shuffle-in-ram: false
[2023-07-01 10:11:20] [config] sigterm: save-and-exit
[2023-07-01 10:11:20] [config] skip: false
[2023-07-01 10:11:20] [config] sqlite: ""
[2023-07-01 10:11:20] [config] sqlite-drop: false
[2023-07-01 10:11:20] [config] sync-freq: 200u
[2023-07-01 10:11:20] [config] sync-sgd: true
[2023-07-01 10:11:20] [config] tempdir: /tmp
[2023-07-01 10:11:20] [config] tied-embeddings: false
[2023-07-01 10:11:20] [config] tied-embeddings-all: true
[2023-07-01 10:11:20] [config] tied-embeddings-src: false
[2023-07-01 10:11:20] [config] train-embedder-rank:
[2023-07-01 10:11:20] [config]   []
[2023-07-01 10:11:20] [config] train-sets:
[2023-07-01 10:11:20] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 10:11:20] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 10:11:20] [config] transformer-aan-activation: swish
[2023-07-01 10:11:20] [config] transformer-aan-depth: 2
[2023-07-01 10:11:20] [config] transformer-aan-nogate: false
[2023-07-01 10:11:20] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 10:11:20] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 10:11:20] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 10:11:20] [config] transformer-depth-scaling: false
[2023-07-01 10:11:20] [config] transformer-dim-aan: 2048
[2023-07-01 10:11:20] [config] transformer-dim-ffn: 2048
[2023-07-01 10:11:20] [config] transformer-dropout: 0.1
[2023-07-01 10:11:20] [config] transformer-dropout-attention: 0
[2023-07-01 10:11:20] [config] transformer-dropout-ffn: 0
[2023-07-01 10:11:20] [config] transformer-ffn-activation: swish
[2023-07-01 10:11:20] [config] transformer-ffn-depth: 2
[2023-07-01 10:11:20] [config] transformer-guided-alignment-layer: last
[2023-07-01 10:11:20] [config] transformer-heads: 8
[2023-07-01 10:11:20] [config] transformer-no-projection: false
[2023-07-01 10:11:20] [config] transformer-pool: false
[2023-07-01 10:11:20] [config] transformer-postprocess: dan
[2023-07-01 10:11:20] [config] transformer-postprocess-emb: d
[2023-07-01 10:11:20] [config] transformer-postprocess-top: ""
[2023-07-01 10:11:20] [config] transformer-preprocess: ""
[2023-07-01 10:11:20] [config] transformer-tied-layers:
[2023-07-01 10:11:20] [config]   []
[2023-07-01 10:11:20] [config] transformer-train-position-embeddings: false
[2023-07-01 10:11:20] [config] tsv: false
[2023-07-01 10:11:20] [config] tsv-fields: 0
[2023-07-01 10:11:20] [config] type: transformer
[2023-07-01 10:11:20] [config] ulr: false
[2023-07-01 10:11:20] [config] ulr-dim-emb: 0
[2023-07-01 10:11:20] [config] ulr-dropout: 0
[2023-07-01 10:11:20] [config] ulr-keys-vectors: ""
[2023-07-01 10:11:20] [config] ulr-query-vectors: ""
[2023-07-01 10:11:20] [config] ulr-softmax-temperature: 1
[2023-07-01 10:11:20] [config] ulr-trainable-transformation: false
[2023-07-01 10:11:20] [config] unlikelihood-loss: false
[2023-07-01 10:11:20] [config] valid-freq: 50000000
[2023-07-01 10:11:20] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 10:11:20] [config] valid-max-length: 1000
[2023-07-01 10:11:20] [config] valid-metrics:
[2023-07-01 10:11:20] [config]   - cross-entropy
[2023-07-01 10:11:20] [config]   - translation
[2023-07-01 10:11:20] [config] valid-mini-batch: 64
[2023-07-01 10:11:20] [config] valid-reset-stalled: false
[2023-07-01 10:11:20] [config] valid-script-args:
[2023-07-01 10:11:20] [config]   []
[2023-07-01 10:11:20] [config] valid-script-path: ""
[2023-07-01 10:11:20] [config] valid-sets:
[2023-07-01 10:11:20] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 10:11:20] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 10:11:20] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 10:11:20] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:11:20] [config] vocabs:
[2023-07-01 10:11:20] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 10:11:20] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 10:11:20] [config] word-penalty: 0
[2023-07-01 10:11:20] [config] word-scores: false
[2023-07-01 10:11:20] [config] workspace: 2048
[2023-07-01 10:11:20] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:11:20] Using synchronous SGD
[2023-07-01 10:11:20] Synced seed 1234
[2023-07-01 10:11:20] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 10:11:20] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 10:11:20] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 10:11:20] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 10:11:20] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 10:11:20] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 10:11:21] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 10:11:21] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 10:11:21] [comm] Using global sharding
[2023-07-01 10:11:21] [comm] NCCLCommunicators constructed successfully
[2023-07-01 10:11:21] [training] Using 1 GPUs
[2023-07-01 10:11:21] [logits] Applying loss function for 1 factor(s)
[2023-07-01 10:11:21] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:11:22] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 10:11:22] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:11:29] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 10:11:29] [valid] No post-processing script given for validating translator
[2023-07-01 10:11:29] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 10:11:29] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 10:11:29] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 10:11:29] [comm] Using global sharding
[2023-07-01 10:11:29] [comm] NCCLCommunicators constructed successfully
[2023-07-01 10:11:29] [training] Using 1 GPUs
[2023-07-01 10:11:29] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:11:30] Allocating memory for general optimizer shards
[2023-07-01 10:11:30] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:11:30] Loading Adam parameters
[2023-07-01 10:11:30] [memory] Reserving 176 MB, device gpu0
[2023-07-01 10:11:30] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:11:30] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 10:11:30] [data] Restoring the corpus state to epoch 23, batch 4158
[2023-07-01 10:11:30] [data] Shuffling data
[2023-07-01 10:11:30] [data] Done reading 20,192 sentences
[2023-07-01 10:11:30] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 10:11:30] Training started
[2023-07-01 10:11:31] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-07-01 10:11:31] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:11:31] Parameter type float32, optimization type float32, casting types false
[2023-07-01 10:11:54] Seen 20,073 samples
[2023-07-01 10:11:54] Starting data epoch 24 in logical epoch 24
[2023-07-01 10:11:54] Training finished
[2023-07-01 10:11:58] [valid] Ep. 24 : Up. 4347 : cross-entropy : 140.649 : new best
[2023-07-01 10:13:54] [valid] Ep. 24 : Up. 4347 : translation : 0 : new best
[2023-07-01 10:13:54] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:13:55] Saving Adam parameters
[2023-07-01 10:13:55] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 10:14:01] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:14:01] [marian] Running on node20.datos.cluster.uy as process 8605 with command line:
[2023-07-01 10:14:01] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 24 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 10:14:01] [config] after: 0e
[2023-07-01 10:14:01] [config] after-batches: 0
[2023-07-01 10:14:01] [config] after-epochs: 24
[2023-07-01 10:14:01] [config] all-caps-every: 0
[2023-07-01 10:14:01] [config] allow-unk: false
[2023-07-01 10:14:01] [config] authors: false
[2023-07-01 10:14:01] [config] beam-size: 12
[2023-07-01 10:14:01] [config] bert-class-symbol: "[CLS]"
[2023-07-01 10:14:01] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 10:14:01] [config] bert-masking-fraction: 0.15
[2023-07-01 10:14:01] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 10:14:01] [config] bert-train-type-embeddings: true
[2023-07-01 10:14:01] [config] bert-type-vocab-size: 2
[2023-07-01 10:14:01] [config] build-info: ""
[2023-07-01 10:14:01] [config] check-gradient-nan: false
[2023-07-01 10:14:01] [config] check-nan: false
[2023-07-01 10:14:01] [config] cite: false
[2023-07-01 10:14:01] [config] clip-norm: 5
[2023-07-01 10:14:01] [config] cost-scaling:
[2023-07-01 10:14:01] [config]   []
[2023-07-01 10:14:01] [config] cost-type: ce-sum
[2023-07-01 10:14:01] [config] cpu-threads: 0
[2023-07-01 10:14:01] [config] data-threads: 8
[2023-07-01 10:14:01] [config] data-weighting: ""
[2023-07-01 10:14:01] [config] data-weighting-type: sentence
[2023-07-01 10:14:01] [config] dec-cell: gru
[2023-07-01 10:14:01] [config] dec-cell-base-depth: 2
[2023-07-01 10:14:01] [config] dec-cell-high-depth: 1
[2023-07-01 10:14:01] [config] dec-depth: 2
[2023-07-01 10:14:01] [config] devices:
[2023-07-01 10:14:01] [config]   - 0
[2023-07-01 10:14:01] [config] dim-emb: 512
[2023-07-01 10:14:01] [config] dim-rnn: 1024
[2023-07-01 10:14:01] [config] dim-vocabs:
[2023-07-01 10:14:01] [config]   - 16384
[2023-07-01 10:14:01] [config]   - 16384
[2023-07-01 10:14:01] [config] disp-first: 0
[2023-07-01 10:14:01] [config] disp-freq: 1000u
[2023-07-01 10:14:01] [config] disp-label-counts: true
[2023-07-01 10:14:01] [config] dropout-rnn: 0
[2023-07-01 10:14:01] [config] dropout-src: 0
[2023-07-01 10:14:01] [config] dropout-trg: 0
[2023-07-01 10:14:01] [config] dump-config: ""
[2023-07-01 10:14:01] [config] dynamic-gradient-scaling:
[2023-07-01 10:14:01] [config]   []
[2023-07-01 10:14:01] [config] early-stopping: 10
[2023-07-01 10:14:01] [config] early-stopping-on: first
[2023-07-01 10:14:01] [config] embedding-fix-src: false
[2023-07-01 10:14:01] [config] embedding-fix-trg: false
[2023-07-01 10:14:01] [config] embedding-normalization: false
[2023-07-01 10:14:01] [config] embedding-vectors:
[2023-07-01 10:14:01] [config]   []
[2023-07-01 10:14:01] [config] enc-cell: gru
[2023-07-01 10:14:01] [config] enc-cell-depth: 1
[2023-07-01 10:14:01] [config] enc-depth: 2
[2023-07-01 10:14:01] [config] enc-type: bidirectional
[2023-07-01 10:14:01] [config] english-title-case-every: 0
[2023-07-01 10:14:01] [config] exponential-smoothing: 0.0001
[2023-07-01 10:14:01] [config] factor-weight: 1
[2023-07-01 10:14:01] [config] factors-combine: sum
[2023-07-01 10:14:01] [config] factors-dim-emb: 0
[2023-07-01 10:14:01] [config] gradient-checkpointing: false
[2023-07-01 10:14:01] [config] gradient-norm-average-window: 100
[2023-07-01 10:14:01] [config] guided-alignment: none
[2023-07-01 10:14:01] [config] guided-alignment-cost: mse
[2023-07-01 10:14:01] [config] guided-alignment-weight: 0.1
[2023-07-01 10:14:01] [config] ignore-model-config: false
[2023-07-01 10:14:01] [config] input-types:
[2023-07-01 10:14:01] [config]   []
[2023-07-01 10:14:01] [config] interpolate-env-vars: false
[2023-07-01 10:14:01] [config] keep-best: false
[2023-07-01 10:14:01] [config] label-smoothing: 0.1
[2023-07-01 10:14:01] [config] layer-normalization: false
[2023-07-01 10:14:01] [config] learn-rate: 0.0003
[2023-07-01 10:14:01] [config] lemma-dependency: ""
[2023-07-01 10:14:01] [config] lemma-dim-emb: 0
[2023-07-01 10:14:01] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 10:14:01] [config] log-level: info
[2023-07-01 10:14:01] [config] log-time-zone: ""
[2023-07-01 10:14:01] [config] logical-epoch:
[2023-07-01 10:14:01] [config]   - 1e
[2023-07-01 10:14:01] [config]   - 0
[2023-07-01 10:14:01] [config] lr-decay: 0
[2023-07-01 10:14:01] [config] lr-decay-freq: 50000
[2023-07-01 10:14:01] [config] lr-decay-inv-sqrt:
[2023-07-01 10:14:01] [config]   - 16000
[2023-07-01 10:14:01] [config] lr-decay-repeat-warmup: false
[2023-07-01 10:14:01] [config] lr-decay-reset-optimizer: false
[2023-07-01 10:14:01] [config] lr-decay-start:
[2023-07-01 10:14:01] [config]   - 10
[2023-07-01 10:14:01] [config]   - 1
[2023-07-01 10:14:01] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 10:14:01] [config] lr-report: true
[2023-07-01 10:14:01] [config] lr-warmup: 16000
[2023-07-01 10:14:01] [config] lr-warmup-at-reload: false
[2023-07-01 10:14:01] [config] lr-warmup-cycle: false
[2023-07-01 10:14:01] [config] lr-warmup-start-rate: 0
[2023-07-01 10:14:01] [config] max-length: 100
[2023-07-01 10:14:01] [config] max-length-crop: false
[2023-07-01 10:14:01] [config] max-length-factor: 3
[2023-07-01 10:14:01] [config] maxi-batch: 100
[2023-07-01 10:14:01] [config] maxi-batch-sort: trg
[2023-07-01 10:14:01] [config] mini-batch: 1000
[2023-07-01 10:14:01] [config] mini-batch-fit: true
[2023-07-01 10:14:01] [config] mini-batch-fit-step: 10
[2023-07-01 10:14:01] [config] mini-batch-round-up: true
[2023-07-01 10:14:01] [config] mini-batch-track-lr: false
[2023-07-01 10:14:01] [config] mini-batch-warmup: 0
[2023-07-01 10:14:01] [config] mini-batch-words: 0
[2023-07-01 10:14:01] [config] mini-batch-words-ref: 0
[2023-07-01 10:14:01] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:14:01] [config] multi-loss-type: sum
[2023-07-01 10:14:01] [config] n-best: false
[2023-07-01 10:14:01] [config] no-nccl: false
[2023-07-01 10:14:01] [config] no-reload: false
[2023-07-01 10:14:01] [config] no-restore-corpus: false
[2023-07-01 10:14:01] [config] normalize: 1
[2023-07-01 10:14:01] [config] normalize-gradient: false
[2023-07-01 10:14:01] [config] num-devices: 0
[2023-07-01 10:14:01] [config] optimizer: adam
[2023-07-01 10:14:01] [config] optimizer-delay: 1
[2023-07-01 10:14:01] [config] optimizer-params:
[2023-07-01 10:14:01] [config]   - 0.9
[2023-07-01 10:14:01] [config]   - 0.98
[2023-07-01 10:14:01] [config]   - 1e-09
[2023-07-01 10:14:01] [config] output-omit-bias: false
[2023-07-01 10:14:01] [config] overwrite: true
[2023-07-01 10:14:01] [config] precision:
[2023-07-01 10:14:01] [config]   - float32
[2023-07-01 10:14:01] [config]   - float32
[2023-07-01 10:14:01] [config] pretrained-model: ""
[2023-07-01 10:14:01] [config] quantize-biases: false
[2023-07-01 10:14:01] [config] quantize-bits: 0
[2023-07-01 10:14:01] [config] quantize-log-based: false
[2023-07-01 10:14:01] [config] quantize-optimization-steps: 0
[2023-07-01 10:14:01] [config] quiet: false
[2023-07-01 10:14:01] [config] quiet-translation: true
[2023-07-01 10:14:01] [config] relative-paths: false
[2023-07-01 10:14:01] [config] right-left: false
[2023-07-01 10:14:01] [config] save-freq: 10000u
[2023-07-01 10:14:01] [config] seed: 1234
[2023-07-01 10:14:01] [config] sentencepiece-alphas:
[2023-07-01 10:14:01] [config]   []
[2023-07-01 10:14:01] [config] sentencepiece-max-lines: 2000000
[2023-07-01 10:14:01] [config] sentencepiece-options: ""
[2023-07-01 10:14:01] [config] sharding: global
[2023-07-01 10:14:01] [config] shuffle: data
[2023-07-01 10:14:01] [config] shuffle-in-ram: false
[2023-07-01 10:14:01] [config] sigterm: save-and-exit
[2023-07-01 10:14:01] [config] skip: false
[2023-07-01 10:14:01] [config] sqlite: ""
[2023-07-01 10:14:01] [config] sqlite-drop: false
[2023-07-01 10:14:01] [config] sync-freq: 200u
[2023-07-01 10:14:01] [config] sync-sgd: true
[2023-07-01 10:14:01] [config] tempdir: /tmp
[2023-07-01 10:14:01] [config] tied-embeddings: false
[2023-07-01 10:14:01] [config] tied-embeddings-all: true
[2023-07-01 10:14:01] [config] tied-embeddings-src: false
[2023-07-01 10:14:01] [config] train-embedder-rank:
[2023-07-01 10:14:01] [config]   []
[2023-07-01 10:14:01] [config] train-sets:
[2023-07-01 10:14:01] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 10:14:01] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 10:14:01] [config] transformer-aan-activation: swish
[2023-07-01 10:14:01] [config] transformer-aan-depth: 2
[2023-07-01 10:14:01] [config] transformer-aan-nogate: false
[2023-07-01 10:14:01] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 10:14:01] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 10:14:01] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 10:14:01] [config] transformer-depth-scaling: false
[2023-07-01 10:14:01] [config] transformer-dim-aan: 2048
[2023-07-01 10:14:01] [config] transformer-dim-ffn: 2048
[2023-07-01 10:14:01] [config] transformer-dropout: 0.1
[2023-07-01 10:14:01] [config] transformer-dropout-attention: 0
[2023-07-01 10:14:01] [config] transformer-dropout-ffn: 0
[2023-07-01 10:14:01] [config] transformer-ffn-activation: swish
[2023-07-01 10:14:01] [config] transformer-ffn-depth: 2
[2023-07-01 10:14:01] [config] transformer-guided-alignment-layer: last
[2023-07-01 10:14:01] [config] transformer-heads: 8
[2023-07-01 10:14:01] [config] transformer-no-projection: false
[2023-07-01 10:14:01] [config] transformer-pool: false
[2023-07-01 10:14:01] [config] transformer-postprocess: dan
[2023-07-01 10:14:01] [config] transformer-postprocess-emb: d
[2023-07-01 10:14:01] [config] transformer-postprocess-top: ""
[2023-07-01 10:14:01] [config] transformer-preprocess: ""
[2023-07-01 10:14:01] [config] transformer-tied-layers:
[2023-07-01 10:14:01] [config]   []
[2023-07-01 10:14:01] [config] transformer-train-position-embeddings: false
[2023-07-01 10:14:01] [config] tsv: false
[2023-07-01 10:14:01] [config] tsv-fields: 0
[2023-07-01 10:14:01] [config] type: transformer
[2023-07-01 10:14:01] [config] ulr: false
[2023-07-01 10:14:01] [config] ulr-dim-emb: 0
[2023-07-01 10:14:01] [config] ulr-dropout: 0
[2023-07-01 10:14:01] [config] ulr-keys-vectors: ""
[2023-07-01 10:14:01] [config] ulr-query-vectors: ""
[2023-07-01 10:14:01] [config] ulr-softmax-temperature: 1
[2023-07-01 10:14:01] [config] ulr-trainable-transformation: false
[2023-07-01 10:14:01] [config] unlikelihood-loss: false
[2023-07-01 10:14:01] [config] valid-freq: 50000000
[2023-07-01 10:14:01] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 10:14:01] [config] valid-max-length: 1000
[2023-07-01 10:14:01] [config] valid-metrics:
[2023-07-01 10:14:01] [config]   - cross-entropy
[2023-07-01 10:14:01] [config]   - translation
[2023-07-01 10:14:01] [config] valid-mini-batch: 64
[2023-07-01 10:14:01] [config] valid-reset-stalled: false
[2023-07-01 10:14:01] [config] valid-script-args:
[2023-07-01 10:14:01] [config]   []
[2023-07-01 10:14:01] [config] valid-script-path: ""
[2023-07-01 10:14:01] [config] valid-sets:
[2023-07-01 10:14:01] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 10:14:01] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 10:14:01] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 10:14:01] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:14:01] [config] vocabs:
[2023-07-01 10:14:01] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 10:14:01] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 10:14:01] [config] word-penalty: 0
[2023-07-01 10:14:01] [config] word-scores: false
[2023-07-01 10:14:01] [config] workspace: 2048
[2023-07-01 10:14:01] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:14:01] Using synchronous SGD
[2023-07-01 10:14:02] Synced seed 1234
[2023-07-01 10:14:02] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 10:14:02] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 10:14:02] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 10:14:02] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 10:14:02] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 10:14:02] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 10:14:02] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 10:14:02] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 10:14:02] [comm] Using global sharding
[2023-07-01 10:14:02] [comm] NCCLCommunicators constructed successfully
[2023-07-01 10:14:02] [training] Using 1 GPUs
[2023-07-01 10:14:02] [logits] Applying loss function for 1 factor(s)
[2023-07-01 10:14:02] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:14:03] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 10:14:03] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:14:10] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 10:14:10] [valid] No post-processing script given for validating translator
[2023-07-01 10:14:11] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 10:14:11] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 10:14:11] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 10:14:11] [comm] Using global sharding
[2023-07-01 10:14:11] [comm] NCCLCommunicators constructed successfully
[2023-07-01 10:14:11] [training] Using 1 GPUs
[2023-07-01 10:14:11] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:14:12] Allocating memory for general optimizer shards
[2023-07-01 10:14:12] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:14:12] Loading Adam parameters
[2023-07-01 10:14:12] [memory] Reserving 176 MB, device gpu0
[2023-07-01 10:14:12] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:14:12] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 10:14:12] [data] Restoring the corpus state to epoch 24, batch 4347
[2023-07-01 10:14:12] [data] Shuffling data
[2023-07-01 10:14:12] [data] Done reading 20,192 sentences
[2023-07-01 10:14:12] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 10:14:12] Training started
[2023-07-01 10:14:12] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-07-01 10:14:12] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:14:12] Parameter type float32, optimization type float32, casting types false
[2023-07-01 10:14:36] Seen 20,073 samples
[2023-07-01 10:14:36] Starting data epoch 25 in logical epoch 25
[2023-07-01 10:14:36] Training finished
[2023-07-01 10:14:39] [valid] Ep. 25 : Up. 4536 : cross-entropy : 138.882 : new best
[2023-07-01 10:16:35] [valid] Ep. 25 : Up. 4536 : translation : 0 : new best
[2023-07-01 10:16:35] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:16:36] Saving Adam parameters
[2023-07-01 10:16:36] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 10:16:43] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:16:43] [marian] Running on node20.datos.cluster.uy as process 8794 with command line:
[2023-07-01 10:16:43] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 25 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 10:16:43] [config] after: 0e
[2023-07-01 10:16:43] [config] after-batches: 0
[2023-07-01 10:16:43] [config] after-epochs: 25
[2023-07-01 10:16:43] [config] all-caps-every: 0
[2023-07-01 10:16:43] [config] allow-unk: false
[2023-07-01 10:16:43] [config] authors: false
[2023-07-01 10:16:43] [config] beam-size: 12
[2023-07-01 10:16:43] [config] bert-class-symbol: "[CLS]"
[2023-07-01 10:16:43] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 10:16:43] [config] bert-masking-fraction: 0.15
[2023-07-01 10:16:43] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 10:16:43] [config] bert-train-type-embeddings: true
[2023-07-01 10:16:43] [config] bert-type-vocab-size: 2
[2023-07-01 10:16:43] [config] build-info: ""
[2023-07-01 10:16:43] [config] check-gradient-nan: false
[2023-07-01 10:16:43] [config] check-nan: false
[2023-07-01 10:16:43] [config] cite: false
[2023-07-01 10:16:43] [config] clip-norm: 5
[2023-07-01 10:16:43] [config] cost-scaling:
[2023-07-01 10:16:43] [config]   []
[2023-07-01 10:16:43] [config] cost-type: ce-sum
[2023-07-01 10:16:43] [config] cpu-threads: 0
[2023-07-01 10:16:43] [config] data-threads: 8
[2023-07-01 10:16:43] [config] data-weighting: ""
[2023-07-01 10:16:43] [config] data-weighting-type: sentence
[2023-07-01 10:16:43] [config] dec-cell: gru
[2023-07-01 10:16:43] [config] dec-cell-base-depth: 2
[2023-07-01 10:16:43] [config] dec-cell-high-depth: 1
[2023-07-01 10:16:43] [config] dec-depth: 2
[2023-07-01 10:16:43] [config] devices:
[2023-07-01 10:16:43] [config]   - 0
[2023-07-01 10:16:43] [config] dim-emb: 512
[2023-07-01 10:16:43] [config] dim-rnn: 1024
[2023-07-01 10:16:43] [config] dim-vocabs:
[2023-07-01 10:16:43] [config]   - 16384
[2023-07-01 10:16:43] [config]   - 16384
[2023-07-01 10:16:43] [config] disp-first: 0
[2023-07-01 10:16:43] [config] disp-freq: 1000u
[2023-07-01 10:16:43] [config] disp-label-counts: true
[2023-07-01 10:16:43] [config] dropout-rnn: 0
[2023-07-01 10:16:43] [config] dropout-src: 0
[2023-07-01 10:16:43] [config] dropout-trg: 0
[2023-07-01 10:16:43] [config] dump-config: ""
[2023-07-01 10:16:43] [config] dynamic-gradient-scaling:
[2023-07-01 10:16:43] [config]   []
[2023-07-01 10:16:43] [config] early-stopping: 10
[2023-07-01 10:16:43] [config] early-stopping-on: first
[2023-07-01 10:16:43] [config] embedding-fix-src: false
[2023-07-01 10:16:43] [config] embedding-fix-trg: false
[2023-07-01 10:16:43] [config] embedding-normalization: false
[2023-07-01 10:16:43] [config] embedding-vectors:
[2023-07-01 10:16:43] [config]   []
[2023-07-01 10:16:43] [config] enc-cell: gru
[2023-07-01 10:16:43] [config] enc-cell-depth: 1
[2023-07-01 10:16:43] [config] enc-depth: 2
[2023-07-01 10:16:43] [config] enc-type: bidirectional
[2023-07-01 10:16:43] [config] english-title-case-every: 0
[2023-07-01 10:16:43] [config] exponential-smoothing: 0.0001
[2023-07-01 10:16:43] [config] factor-weight: 1
[2023-07-01 10:16:43] [config] factors-combine: sum
[2023-07-01 10:16:43] [config] factors-dim-emb: 0
[2023-07-01 10:16:43] [config] gradient-checkpointing: false
[2023-07-01 10:16:43] [config] gradient-norm-average-window: 100
[2023-07-01 10:16:43] [config] guided-alignment: none
[2023-07-01 10:16:43] [config] guided-alignment-cost: mse
[2023-07-01 10:16:43] [config] guided-alignment-weight: 0.1
[2023-07-01 10:16:43] [config] ignore-model-config: false
[2023-07-01 10:16:43] [config] input-types:
[2023-07-01 10:16:43] [config]   []
[2023-07-01 10:16:43] [config] interpolate-env-vars: false
[2023-07-01 10:16:43] [config] keep-best: false
[2023-07-01 10:16:43] [config] label-smoothing: 0.1
[2023-07-01 10:16:43] [config] layer-normalization: false
[2023-07-01 10:16:43] [config] learn-rate: 0.0003
[2023-07-01 10:16:43] [config] lemma-dependency: ""
[2023-07-01 10:16:43] [config] lemma-dim-emb: 0
[2023-07-01 10:16:43] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 10:16:43] [config] log-level: info
[2023-07-01 10:16:43] [config] log-time-zone: ""
[2023-07-01 10:16:43] [config] logical-epoch:
[2023-07-01 10:16:43] [config]   - 1e
[2023-07-01 10:16:43] [config]   - 0
[2023-07-01 10:16:43] [config] lr-decay: 0
[2023-07-01 10:16:43] [config] lr-decay-freq: 50000
[2023-07-01 10:16:43] [config] lr-decay-inv-sqrt:
[2023-07-01 10:16:43] [config]   - 16000
[2023-07-01 10:16:43] [config] lr-decay-repeat-warmup: false
[2023-07-01 10:16:43] [config] lr-decay-reset-optimizer: false
[2023-07-01 10:16:43] [config] lr-decay-start:
[2023-07-01 10:16:43] [config]   - 10
[2023-07-01 10:16:43] [config]   - 1
[2023-07-01 10:16:43] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 10:16:43] [config] lr-report: true
[2023-07-01 10:16:43] [config] lr-warmup: 16000
[2023-07-01 10:16:43] [config] lr-warmup-at-reload: false
[2023-07-01 10:16:43] [config] lr-warmup-cycle: false
[2023-07-01 10:16:43] [config] lr-warmup-start-rate: 0
[2023-07-01 10:16:43] [config] max-length: 100
[2023-07-01 10:16:43] [config] max-length-crop: false
[2023-07-01 10:16:43] [config] max-length-factor: 3
[2023-07-01 10:16:43] [config] maxi-batch: 100
[2023-07-01 10:16:43] [config] maxi-batch-sort: trg
[2023-07-01 10:16:43] [config] mini-batch: 1000
[2023-07-01 10:16:43] [config] mini-batch-fit: true
[2023-07-01 10:16:43] [config] mini-batch-fit-step: 10
[2023-07-01 10:16:43] [config] mini-batch-round-up: true
[2023-07-01 10:16:43] [config] mini-batch-track-lr: false
[2023-07-01 10:16:43] [config] mini-batch-warmup: 0
[2023-07-01 10:16:43] [config] mini-batch-words: 0
[2023-07-01 10:16:43] [config] mini-batch-words-ref: 0
[2023-07-01 10:16:43] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:16:43] [config] multi-loss-type: sum
[2023-07-01 10:16:43] [config] n-best: false
[2023-07-01 10:16:43] [config] no-nccl: false
[2023-07-01 10:16:43] [config] no-reload: false
[2023-07-01 10:16:43] [config] no-restore-corpus: false
[2023-07-01 10:16:43] [config] normalize: 1
[2023-07-01 10:16:43] [config] normalize-gradient: false
[2023-07-01 10:16:43] [config] num-devices: 0
[2023-07-01 10:16:43] [config] optimizer: adam
[2023-07-01 10:16:43] [config] optimizer-delay: 1
[2023-07-01 10:16:43] [config] optimizer-params:
[2023-07-01 10:16:43] [config]   - 0.9
[2023-07-01 10:16:43] [config]   - 0.98
[2023-07-01 10:16:43] [config]   - 1e-09
[2023-07-01 10:16:43] [config] output-omit-bias: false
[2023-07-01 10:16:43] [config] overwrite: true
[2023-07-01 10:16:43] [config] precision:
[2023-07-01 10:16:43] [config]   - float32
[2023-07-01 10:16:43] [config]   - float32
[2023-07-01 10:16:43] [config] pretrained-model: ""
[2023-07-01 10:16:43] [config] quantize-biases: false
[2023-07-01 10:16:43] [config] quantize-bits: 0
[2023-07-01 10:16:43] [config] quantize-log-based: false
[2023-07-01 10:16:43] [config] quantize-optimization-steps: 0
[2023-07-01 10:16:43] [config] quiet: false
[2023-07-01 10:16:43] [config] quiet-translation: true
[2023-07-01 10:16:43] [config] relative-paths: false
[2023-07-01 10:16:43] [config] right-left: false
[2023-07-01 10:16:43] [config] save-freq: 10000u
[2023-07-01 10:16:43] [config] seed: 1234
[2023-07-01 10:16:43] [config] sentencepiece-alphas:
[2023-07-01 10:16:43] [config]   []
[2023-07-01 10:16:43] [config] sentencepiece-max-lines: 2000000
[2023-07-01 10:16:43] [config] sentencepiece-options: ""
[2023-07-01 10:16:43] [config] sharding: global
[2023-07-01 10:16:43] [config] shuffle: data
[2023-07-01 10:16:43] [config] shuffle-in-ram: false
[2023-07-01 10:16:43] [config] sigterm: save-and-exit
[2023-07-01 10:16:43] [config] skip: false
[2023-07-01 10:16:43] [config] sqlite: ""
[2023-07-01 10:16:43] [config] sqlite-drop: false
[2023-07-01 10:16:43] [config] sync-freq: 200u
[2023-07-01 10:16:43] [config] sync-sgd: true
[2023-07-01 10:16:43] [config] tempdir: /tmp
[2023-07-01 10:16:43] [config] tied-embeddings: false
[2023-07-01 10:16:43] [config] tied-embeddings-all: true
[2023-07-01 10:16:43] [config] tied-embeddings-src: false
[2023-07-01 10:16:43] [config] train-embedder-rank:
[2023-07-01 10:16:43] [config]   []
[2023-07-01 10:16:43] [config] train-sets:
[2023-07-01 10:16:43] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 10:16:43] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 10:16:43] [config] transformer-aan-activation: swish
[2023-07-01 10:16:43] [config] transformer-aan-depth: 2
[2023-07-01 10:16:43] [config] transformer-aan-nogate: false
[2023-07-01 10:16:43] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 10:16:43] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 10:16:43] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 10:16:43] [config] transformer-depth-scaling: false
[2023-07-01 10:16:43] [config] transformer-dim-aan: 2048
[2023-07-01 10:16:43] [config] transformer-dim-ffn: 2048
[2023-07-01 10:16:43] [config] transformer-dropout: 0.1
[2023-07-01 10:16:43] [config] transformer-dropout-attention: 0
[2023-07-01 10:16:43] [config] transformer-dropout-ffn: 0
[2023-07-01 10:16:43] [config] transformer-ffn-activation: swish
[2023-07-01 10:16:43] [config] transformer-ffn-depth: 2
[2023-07-01 10:16:43] [config] transformer-guided-alignment-layer: last
[2023-07-01 10:16:43] [config] transformer-heads: 8
[2023-07-01 10:16:43] [config] transformer-no-projection: false
[2023-07-01 10:16:43] [config] transformer-pool: false
[2023-07-01 10:16:43] [config] transformer-postprocess: dan
[2023-07-01 10:16:43] [config] transformer-postprocess-emb: d
[2023-07-01 10:16:43] [config] transformer-postprocess-top: ""
[2023-07-01 10:16:43] [config] transformer-preprocess: ""
[2023-07-01 10:16:43] [config] transformer-tied-layers:
[2023-07-01 10:16:43] [config]   []
[2023-07-01 10:16:43] [config] transformer-train-position-embeddings: false
[2023-07-01 10:16:43] [config] tsv: false
[2023-07-01 10:16:43] [config] tsv-fields: 0
[2023-07-01 10:16:43] [config] type: transformer
[2023-07-01 10:16:43] [config] ulr: false
[2023-07-01 10:16:43] [config] ulr-dim-emb: 0
[2023-07-01 10:16:43] [config] ulr-dropout: 0
[2023-07-01 10:16:43] [config] ulr-keys-vectors: ""
[2023-07-01 10:16:43] [config] ulr-query-vectors: ""
[2023-07-01 10:16:43] [config] ulr-softmax-temperature: 1
[2023-07-01 10:16:43] [config] ulr-trainable-transformation: false
[2023-07-01 10:16:43] [config] unlikelihood-loss: false
[2023-07-01 10:16:43] [config] valid-freq: 50000000
[2023-07-01 10:16:43] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 10:16:43] [config] valid-max-length: 1000
[2023-07-01 10:16:43] [config] valid-metrics:
[2023-07-01 10:16:43] [config]   - cross-entropy
[2023-07-01 10:16:43] [config]   - translation
[2023-07-01 10:16:43] [config] valid-mini-batch: 64
[2023-07-01 10:16:43] [config] valid-reset-stalled: false
[2023-07-01 10:16:43] [config] valid-script-args:
[2023-07-01 10:16:43] [config]   []
[2023-07-01 10:16:43] [config] valid-script-path: ""
[2023-07-01 10:16:43] [config] valid-sets:
[2023-07-01 10:16:43] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 10:16:43] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 10:16:43] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 10:16:43] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:16:43] [config] vocabs:
[2023-07-01 10:16:43] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 10:16:43] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 10:16:43] [config] word-penalty: 0
[2023-07-01 10:16:43] [config] word-scores: false
[2023-07-01 10:16:43] [config] workspace: 2048
[2023-07-01 10:16:43] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:16:43] Using synchronous SGD
[2023-07-01 10:16:43] Synced seed 1234
[2023-07-01 10:16:43] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 10:16:43] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 10:16:43] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 10:16:43] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 10:16:43] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 10:16:43] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 10:16:44] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 10:16:44] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 10:16:44] [comm] Using global sharding
[2023-07-01 10:16:44] [comm] NCCLCommunicators constructed successfully
[2023-07-01 10:16:44] [training] Using 1 GPUs
[2023-07-01 10:16:44] [logits] Applying loss function for 1 factor(s)
[2023-07-01 10:16:44] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:16:44] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 10:16:44] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:16:52] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 10:16:52] [valid] No post-processing script given for validating translator
[2023-07-01 10:16:52] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 10:16:52] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 10:16:52] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 10:16:52] [comm] Using global sharding
[2023-07-01 10:16:52] [comm] NCCLCommunicators constructed successfully
[2023-07-01 10:16:52] [training] Using 1 GPUs
[2023-07-01 10:16:52] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:16:53] Allocating memory for general optimizer shards
[2023-07-01 10:16:53] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:16:53] Loading Adam parameters
[2023-07-01 10:16:53] [memory] Reserving 176 MB, device gpu0
[2023-07-01 10:16:53] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:16:53] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 10:16:53] [data] Restoring the corpus state to epoch 25, batch 4536
[2023-07-01 10:16:53] [data] Shuffling data
[2023-07-01 10:16:53] [data] Done reading 20,192 sentences
[2023-07-01 10:16:53] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 10:16:53] Training started
[2023-07-01 10:16:53] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-07-01 10:16:53] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:16:53] Parameter type float32, optimization type float32, casting types false
[2023-07-01 10:17:18] Seen 20,073 samples
[2023-07-01 10:17:18] Starting data epoch 26 in logical epoch 26
[2023-07-01 10:17:18] Training finished
[2023-07-01 10:17:21] [valid] Ep. 26 : Up. 4725 : cross-entropy : 137.213 : new best
[2023-07-01 10:19:08] [valid] Ep. 26 : Up. 4725 : translation : 0 : new best
[2023-07-01 10:19:08] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:19:09] Saving Adam parameters
[2023-07-01 10:19:09] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 10:19:15] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:19:15] [marian] Running on node20.datos.cluster.uy as process 8980 with command line:
[2023-07-01 10:19:15] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 26 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 10:19:15] [config] after: 0e
[2023-07-01 10:19:15] [config] after-batches: 0
[2023-07-01 10:19:15] [config] after-epochs: 26
[2023-07-01 10:19:15] [config] all-caps-every: 0
[2023-07-01 10:19:15] [config] allow-unk: false
[2023-07-01 10:19:15] [config] authors: false
[2023-07-01 10:19:15] [config] beam-size: 12
[2023-07-01 10:19:15] [config] bert-class-symbol: "[CLS]"
[2023-07-01 10:19:15] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 10:19:15] [config] bert-masking-fraction: 0.15
[2023-07-01 10:19:15] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 10:19:15] [config] bert-train-type-embeddings: true
[2023-07-01 10:19:15] [config] bert-type-vocab-size: 2
[2023-07-01 10:19:15] [config] build-info: ""
[2023-07-01 10:19:15] [config] check-gradient-nan: false
[2023-07-01 10:19:15] [config] check-nan: false
[2023-07-01 10:19:15] [config] cite: false
[2023-07-01 10:19:15] [config] clip-norm: 5
[2023-07-01 10:19:15] [config] cost-scaling:
[2023-07-01 10:19:15] [config]   []
[2023-07-01 10:19:15] [config] cost-type: ce-sum
[2023-07-01 10:19:15] [config] cpu-threads: 0
[2023-07-01 10:19:15] [config] data-threads: 8
[2023-07-01 10:19:15] [config] data-weighting: ""
[2023-07-01 10:19:15] [config] data-weighting-type: sentence
[2023-07-01 10:19:15] [config] dec-cell: gru
[2023-07-01 10:19:15] [config] dec-cell-base-depth: 2
[2023-07-01 10:19:15] [config] dec-cell-high-depth: 1
[2023-07-01 10:19:15] [config] dec-depth: 2
[2023-07-01 10:19:15] [config] devices:
[2023-07-01 10:19:15] [config]   - 0
[2023-07-01 10:19:15] [config] dim-emb: 512
[2023-07-01 10:19:15] [config] dim-rnn: 1024
[2023-07-01 10:19:15] [config] dim-vocabs:
[2023-07-01 10:19:15] [config]   - 16384
[2023-07-01 10:19:15] [config]   - 16384
[2023-07-01 10:19:15] [config] disp-first: 0
[2023-07-01 10:19:15] [config] disp-freq: 1000u
[2023-07-01 10:19:15] [config] disp-label-counts: true
[2023-07-01 10:19:15] [config] dropout-rnn: 0
[2023-07-01 10:19:15] [config] dropout-src: 0
[2023-07-01 10:19:15] [config] dropout-trg: 0
[2023-07-01 10:19:15] [config] dump-config: ""
[2023-07-01 10:19:15] [config] dynamic-gradient-scaling:
[2023-07-01 10:19:15] [config]   []
[2023-07-01 10:19:15] [config] early-stopping: 10
[2023-07-01 10:19:15] [config] early-stopping-on: first
[2023-07-01 10:19:15] [config] embedding-fix-src: false
[2023-07-01 10:19:15] [config] embedding-fix-trg: false
[2023-07-01 10:19:15] [config] embedding-normalization: false
[2023-07-01 10:19:15] [config] embedding-vectors:
[2023-07-01 10:19:15] [config]   []
[2023-07-01 10:19:15] [config] enc-cell: gru
[2023-07-01 10:19:15] [config] enc-cell-depth: 1
[2023-07-01 10:19:15] [config] enc-depth: 2
[2023-07-01 10:19:15] [config] enc-type: bidirectional
[2023-07-01 10:19:15] [config] english-title-case-every: 0
[2023-07-01 10:19:15] [config] exponential-smoothing: 0.0001
[2023-07-01 10:19:15] [config] factor-weight: 1
[2023-07-01 10:19:15] [config] factors-combine: sum
[2023-07-01 10:19:15] [config] factors-dim-emb: 0
[2023-07-01 10:19:15] [config] gradient-checkpointing: false
[2023-07-01 10:19:15] [config] gradient-norm-average-window: 100
[2023-07-01 10:19:15] [config] guided-alignment: none
[2023-07-01 10:19:15] [config] guided-alignment-cost: mse
[2023-07-01 10:19:15] [config] guided-alignment-weight: 0.1
[2023-07-01 10:19:15] [config] ignore-model-config: false
[2023-07-01 10:19:15] [config] input-types:
[2023-07-01 10:19:15] [config]   []
[2023-07-01 10:19:15] [config] interpolate-env-vars: false
[2023-07-01 10:19:15] [config] keep-best: false
[2023-07-01 10:19:15] [config] label-smoothing: 0.1
[2023-07-01 10:19:15] [config] layer-normalization: false
[2023-07-01 10:19:15] [config] learn-rate: 0.0003
[2023-07-01 10:19:15] [config] lemma-dependency: ""
[2023-07-01 10:19:15] [config] lemma-dim-emb: 0
[2023-07-01 10:19:15] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 10:19:15] [config] log-level: info
[2023-07-01 10:19:15] [config] log-time-zone: ""
[2023-07-01 10:19:15] [config] logical-epoch:
[2023-07-01 10:19:15] [config]   - 1e
[2023-07-01 10:19:15] [config]   - 0
[2023-07-01 10:19:15] [config] lr-decay: 0
[2023-07-01 10:19:15] [config] lr-decay-freq: 50000
[2023-07-01 10:19:15] [config] lr-decay-inv-sqrt:
[2023-07-01 10:19:15] [config]   - 16000
[2023-07-01 10:19:15] [config] lr-decay-repeat-warmup: false
[2023-07-01 10:19:15] [config] lr-decay-reset-optimizer: false
[2023-07-01 10:19:15] [config] lr-decay-start:
[2023-07-01 10:19:15] [config]   - 10
[2023-07-01 10:19:15] [config]   - 1
[2023-07-01 10:19:15] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 10:19:15] [config] lr-report: true
[2023-07-01 10:19:15] [config] lr-warmup: 16000
[2023-07-01 10:19:15] [config] lr-warmup-at-reload: false
[2023-07-01 10:19:15] [config] lr-warmup-cycle: false
[2023-07-01 10:19:15] [config] lr-warmup-start-rate: 0
[2023-07-01 10:19:15] [config] max-length: 100
[2023-07-01 10:19:15] [config] max-length-crop: false
[2023-07-01 10:19:15] [config] max-length-factor: 3
[2023-07-01 10:19:15] [config] maxi-batch: 100
[2023-07-01 10:19:15] [config] maxi-batch-sort: trg
[2023-07-01 10:19:15] [config] mini-batch: 1000
[2023-07-01 10:19:15] [config] mini-batch-fit: true
[2023-07-01 10:19:15] [config] mini-batch-fit-step: 10
[2023-07-01 10:19:15] [config] mini-batch-round-up: true
[2023-07-01 10:19:15] [config] mini-batch-track-lr: false
[2023-07-01 10:19:15] [config] mini-batch-warmup: 0
[2023-07-01 10:19:15] [config] mini-batch-words: 0
[2023-07-01 10:19:15] [config] mini-batch-words-ref: 0
[2023-07-01 10:19:15] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:19:15] [config] multi-loss-type: sum
[2023-07-01 10:19:15] [config] n-best: false
[2023-07-01 10:19:15] [config] no-nccl: false
[2023-07-01 10:19:15] [config] no-reload: false
[2023-07-01 10:19:15] [config] no-restore-corpus: false
[2023-07-01 10:19:15] [config] normalize: 1
[2023-07-01 10:19:15] [config] normalize-gradient: false
[2023-07-01 10:19:15] [config] num-devices: 0
[2023-07-01 10:19:15] [config] optimizer: adam
[2023-07-01 10:19:15] [config] optimizer-delay: 1
[2023-07-01 10:19:15] [config] optimizer-params:
[2023-07-01 10:19:15] [config]   - 0.9
[2023-07-01 10:19:15] [config]   - 0.98
[2023-07-01 10:19:15] [config]   - 1e-09
[2023-07-01 10:19:15] [config] output-omit-bias: false
[2023-07-01 10:19:15] [config] overwrite: true
[2023-07-01 10:19:15] [config] precision:
[2023-07-01 10:19:15] [config]   - float32
[2023-07-01 10:19:15] [config]   - float32
[2023-07-01 10:19:15] [config] pretrained-model: ""
[2023-07-01 10:19:15] [config] quantize-biases: false
[2023-07-01 10:19:15] [config] quantize-bits: 0
[2023-07-01 10:19:15] [config] quantize-log-based: false
[2023-07-01 10:19:15] [config] quantize-optimization-steps: 0
[2023-07-01 10:19:15] [config] quiet: false
[2023-07-01 10:19:15] [config] quiet-translation: true
[2023-07-01 10:19:15] [config] relative-paths: false
[2023-07-01 10:19:15] [config] right-left: false
[2023-07-01 10:19:15] [config] save-freq: 10000u
[2023-07-01 10:19:15] [config] seed: 1234
[2023-07-01 10:19:15] [config] sentencepiece-alphas:
[2023-07-01 10:19:15] [config]   []
[2023-07-01 10:19:15] [config] sentencepiece-max-lines: 2000000
[2023-07-01 10:19:15] [config] sentencepiece-options: ""
[2023-07-01 10:19:15] [config] sharding: global
[2023-07-01 10:19:15] [config] shuffle: data
[2023-07-01 10:19:15] [config] shuffle-in-ram: false
[2023-07-01 10:19:15] [config] sigterm: save-and-exit
[2023-07-01 10:19:15] [config] skip: false
[2023-07-01 10:19:15] [config] sqlite: ""
[2023-07-01 10:19:15] [config] sqlite-drop: false
[2023-07-01 10:19:15] [config] sync-freq: 200u
[2023-07-01 10:19:15] [config] sync-sgd: true
[2023-07-01 10:19:15] [config] tempdir: /tmp
[2023-07-01 10:19:15] [config] tied-embeddings: false
[2023-07-01 10:19:15] [config] tied-embeddings-all: true
[2023-07-01 10:19:15] [config] tied-embeddings-src: false
[2023-07-01 10:19:15] [config] train-embedder-rank:
[2023-07-01 10:19:15] [config]   []
[2023-07-01 10:19:15] [config] train-sets:
[2023-07-01 10:19:15] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 10:19:15] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 10:19:15] [config] transformer-aan-activation: swish
[2023-07-01 10:19:15] [config] transformer-aan-depth: 2
[2023-07-01 10:19:15] [config] transformer-aan-nogate: false
[2023-07-01 10:19:15] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 10:19:15] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 10:19:15] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 10:19:15] [config] transformer-depth-scaling: false
[2023-07-01 10:19:15] [config] transformer-dim-aan: 2048
[2023-07-01 10:19:15] [config] transformer-dim-ffn: 2048
[2023-07-01 10:19:15] [config] transformer-dropout: 0.1
[2023-07-01 10:19:15] [config] transformer-dropout-attention: 0
[2023-07-01 10:19:15] [config] transformer-dropout-ffn: 0
[2023-07-01 10:19:15] [config] transformer-ffn-activation: swish
[2023-07-01 10:19:15] [config] transformer-ffn-depth: 2
[2023-07-01 10:19:15] [config] transformer-guided-alignment-layer: last
[2023-07-01 10:19:15] [config] transformer-heads: 8
[2023-07-01 10:19:15] [config] transformer-no-projection: false
[2023-07-01 10:19:15] [config] transformer-pool: false
[2023-07-01 10:19:15] [config] transformer-postprocess: dan
[2023-07-01 10:19:15] [config] transformer-postprocess-emb: d
[2023-07-01 10:19:15] [config] transformer-postprocess-top: ""
[2023-07-01 10:19:15] [config] transformer-preprocess: ""
[2023-07-01 10:19:15] [config] transformer-tied-layers:
[2023-07-01 10:19:15] [config]   []
[2023-07-01 10:19:15] [config] transformer-train-position-embeddings: false
[2023-07-01 10:19:15] [config] tsv: false
[2023-07-01 10:19:15] [config] tsv-fields: 0
[2023-07-01 10:19:15] [config] type: transformer
[2023-07-01 10:19:15] [config] ulr: false
[2023-07-01 10:19:15] [config] ulr-dim-emb: 0
[2023-07-01 10:19:15] [config] ulr-dropout: 0
[2023-07-01 10:19:15] [config] ulr-keys-vectors: ""
[2023-07-01 10:19:15] [config] ulr-query-vectors: ""
[2023-07-01 10:19:15] [config] ulr-softmax-temperature: 1
[2023-07-01 10:19:15] [config] ulr-trainable-transformation: false
[2023-07-01 10:19:15] [config] unlikelihood-loss: false
[2023-07-01 10:19:15] [config] valid-freq: 50000000
[2023-07-01 10:19:15] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 10:19:15] [config] valid-max-length: 1000
[2023-07-01 10:19:15] [config] valid-metrics:
[2023-07-01 10:19:15] [config]   - cross-entropy
[2023-07-01 10:19:15] [config]   - translation
[2023-07-01 10:19:15] [config] valid-mini-batch: 64
[2023-07-01 10:19:15] [config] valid-reset-stalled: false
[2023-07-01 10:19:15] [config] valid-script-args:
[2023-07-01 10:19:15] [config]   []
[2023-07-01 10:19:15] [config] valid-script-path: ""
[2023-07-01 10:19:15] [config] valid-sets:
[2023-07-01 10:19:15] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 10:19:15] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 10:19:15] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 10:19:15] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:19:15] [config] vocabs:
[2023-07-01 10:19:15] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 10:19:15] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 10:19:15] [config] word-penalty: 0
[2023-07-01 10:19:15] [config] word-scores: false
[2023-07-01 10:19:15] [config] workspace: 2048
[2023-07-01 10:19:15] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:19:15] Using synchronous SGD
[2023-07-01 10:19:16] Synced seed 1234
[2023-07-01 10:19:16] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 10:19:16] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 10:19:16] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 10:19:16] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 10:19:16] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 10:19:16] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 10:19:16] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 10:19:16] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 10:19:16] [comm] Using global sharding
[2023-07-01 10:19:16] [comm] NCCLCommunicators constructed successfully
[2023-07-01 10:19:16] [training] Using 1 GPUs
[2023-07-01 10:19:16] [logits] Applying loss function for 1 factor(s)
[2023-07-01 10:19:16] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:19:17] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 10:19:17] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:19:24] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 10:19:25] [valid] No post-processing script given for validating translator
[2023-07-01 10:19:25] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 10:19:25] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 10:19:25] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 10:19:25] [comm] Using global sharding
[2023-07-01 10:19:25] [comm] NCCLCommunicators constructed successfully
[2023-07-01 10:19:25] [training] Using 1 GPUs
[2023-07-01 10:19:25] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:19:25] Allocating memory for general optimizer shards
[2023-07-01 10:19:25] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:19:25] Loading Adam parameters
[2023-07-01 10:19:26] [memory] Reserving 176 MB, device gpu0
[2023-07-01 10:19:26] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:19:26] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 10:19:26] [data] Restoring the corpus state to epoch 26, batch 4725
[2023-07-01 10:19:26] [data] Shuffling data
[2023-07-01 10:19:26] [data] Done reading 20,192 sentences
[2023-07-01 10:19:26] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 10:19:26] Training started
[2023-07-01 10:19:26] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-07-01 10:19:26] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:19:26] Parameter type float32, optimization type float32, casting types false
[2023-07-01 10:19:51] Seen 20,073 samples
[2023-07-01 10:19:51] Starting data epoch 27 in logical epoch 27
[2023-07-01 10:19:51] Training finished
[2023-07-01 10:19:54] [valid] Ep. 27 : Up. 4914 : cross-entropy : 135.642 : new best
[2023-07-01 10:21:38] [valid] Ep. 27 : Up. 4914 : translation : 0 : new best
[2023-07-01 10:21:38] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:21:39] Saving Adam parameters
[2023-07-01 10:21:40] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 10:21:46] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:21:46] [marian] Running on node20.datos.cluster.uy as process 9159 with command line:
[2023-07-01 10:21:46] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 27 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 10:21:46] [config] after: 0e
[2023-07-01 10:21:46] [config] after-batches: 0
[2023-07-01 10:21:46] [config] after-epochs: 27
[2023-07-01 10:21:46] [config] all-caps-every: 0
[2023-07-01 10:21:46] [config] allow-unk: false
[2023-07-01 10:21:46] [config] authors: false
[2023-07-01 10:21:46] [config] beam-size: 12
[2023-07-01 10:21:46] [config] bert-class-symbol: "[CLS]"
[2023-07-01 10:21:46] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 10:21:46] [config] bert-masking-fraction: 0.15
[2023-07-01 10:21:46] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 10:21:46] [config] bert-train-type-embeddings: true
[2023-07-01 10:21:46] [config] bert-type-vocab-size: 2
[2023-07-01 10:21:46] [config] build-info: ""
[2023-07-01 10:21:46] [config] check-gradient-nan: false
[2023-07-01 10:21:46] [config] check-nan: false
[2023-07-01 10:21:46] [config] cite: false
[2023-07-01 10:21:46] [config] clip-norm: 5
[2023-07-01 10:21:46] [config] cost-scaling:
[2023-07-01 10:21:46] [config]   []
[2023-07-01 10:21:46] [config] cost-type: ce-sum
[2023-07-01 10:21:46] [config] cpu-threads: 0
[2023-07-01 10:21:46] [config] data-threads: 8
[2023-07-01 10:21:46] [config] data-weighting: ""
[2023-07-01 10:21:46] [config] data-weighting-type: sentence
[2023-07-01 10:21:46] [config] dec-cell: gru
[2023-07-01 10:21:46] [config] dec-cell-base-depth: 2
[2023-07-01 10:21:46] [config] dec-cell-high-depth: 1
[2023-07-01 10:21:46] [config] dec-depth: 2
[2023-07-01 10:21:46] [config] devices:
[2023-07-01 10:21:46] [config]   - 0
[2023-07-01 10:21:46] [config] dim-emb: 512
[2023-07-01 10:21:46] [config] dim-rnn: 1024
[2023-07-01 10:21:46] [config] dim-vocabs:
[2023-07-01 10:21:46] [config]   - 16384
[2023-07-01 10:21:46] [config]   - 16384
[2023-07-01 10:21:46] [config] disp-first: 0
[2023-07-01 10:21:46] [config] disp-freq: 1000u
[2023-07-01 10:21:46] [config] disp-label-counts: true
[2023-07-01 10:21:46] [config] dropout-rnn: 0
[2023-07-01 10:21:46] [config] dropout-src: 0
[2023-07-01 10:21:46] [config] dropout-trg: 0
[2023-07-01 10:21:46] [config] dump-config: ""
[2023-07-01 10:21:46] [config] dynamic-gradient-scaling:
[2023-07-01 10:21:46] [config]   []
[2023-07-01 10:21:46] [config] early-stopping: 10
[2023-07-01 10:21:46] [config] early-stopping-on: first
[2023-07-01 10:21:46] [config] embedding-fix-src: false
[2023-07-01 10:21:46] [config] embedding-fix-trg: false
[2023-07-01 10:21:46] [config] embedding-normalization: false
[2023-07-01 10:21:46] [config] embedding-vectors:
[2023-07-01 10:21:46] [config]   []
[2023-07-01 10:21:46] [config] enc-cell: gru
[2023-07-01 10:21:46] [config] enc-cell-depth: 1
[2023-07-01 10:21:46] [config] enc-depth: 2
[2023-07-01 10:21:46] [config] enc-type: bidirectional
[2023-07-01 10:21:46] [config] english-title-case-every: 0
[2023-07-01 10:21:46] [config] exponential-smoothing: 0.0001
[2023-07-01 10:21:46] [config] factor-weight: 1
[2023-07-01 10:21:46] [config] factors-combine: sum
[2023-07-01 10:21:46] [config] factors-dim-emb: 0
[2023-07-01 10:21:46] [config] gradient-checkpointing: false
[2023-07-01 10:21:46] [config] gradient-norm-average-window: 100
[2023-07-01 10:21:46] [config] guided-alignment: none
[2023-07-01 10:21:46] [config] guided-alignment-cost: mse
[2023-07-01 10:21:46] [config] guided-alignment-weight: 0.1
[2023-07-01 10:21:46] [config] ignore-model-config: false
[2023-07-01 10:21:46] [config] input-types:
[2023-07-01 10:21:46] [config]   []
[2023-07-01 10:21:46] [config] interpolate-env-vars: false
[2023-07-01 10:21:46] [config] keep-best: false
[2023-07-01 10:21:46] [config] label-smoothing: 0.1
[2023-07-01 10:21:46] [config] layer-normalization: false
[2023-07-01 10:21:46] [config] learn-rate: 0.0003
[2023-07-01 10:21:46] [config] lemma-dependency: ""
[2023-07-01 10:21:46] [config] lemma-dim-emb: 0
[2023-07-01 10:21:46] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 10:21:46] [config] log-level: info
[2023-07-01 10:21:46] [config] log-time-zone: ""
[2023-07-01 10:21:46] [config] logical-epoch:
[2023-07-01 10:21:46] [config]   - 1e
[2023-07-01 10:21:46] [config]   - 0
[2023-07-01 10:21:46] [config] lr-decay: 0
[2023-07-01 10:21:46] [config] lr-decay-freq: 50000
[2023-07-01 10:21:46] [config] lr-decay-inv-sqrt:
[2023-07-01 10:21:46] [config]   - 16000
[2023-07-01 10:21:46] [config] lr-decay-repeat-warmup: false
[2023-07-01 10:21:46] [config] lr-decay-reset-optimizer: false
[2023-07-01 10:21:46] [config] lr-decay-start:
[2023-07-01 10:21:46] [config]   - 10
[2023-07-01 10:21:46] [config]   - 1
[2023-07-01 10:21:46] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 10:21:46] [config] lr-report: true
[2023-07-01 10:21:46] [config] lr-warmup: 16000
[2023-07-01 10:21:46] [config] lr-warmup-at-reload: false
[2023-07-01 10:21:46] [config] lr-warmup-cycle: false
[2023-07-01 10:21:46] [config] lr-warmup-start-rate: 0
[2023-07-01 10:21:46] [config] max-length: 100
[2023-07-01 10:21:46] [config] max-length-crop: false
[2023-07-01 10:21:46] [config] max-length-factor: 3
[2023-07-01 10:21:46] [config] maxi-batch: 100
[2023-07-01 10:21:46] [config] maxi-batch-sort: trg
[2023-07-01 10:21:46] [config] mini-batch: 1000
[2023-07-01 10:21:46] [config] mini-batch-fit: true
[2023-07-01 10:21:46] [config] mini-batch-fit-step: 10
[2023-07-01 10:21:46] [config] mini-batch-round-up: true
[2023-07-01 10:21:46] [config] mini-batch-track-lr: false
[2023-07-01 10:21:46] [config] mini-batch-warmup: 0
[2023-07-01 10:21:46] [config] mini-batch-words: 0
[2023-07-01 10:21:46] [config] mini-batch-words-ref: 0
[2023-07-01 10:21:46] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:21:46] [config] multi-loss-type: sum
[2023-07-01 10:21:46] [config] n-best: false
[2023-07-01 10:21:46] [config] no-nccl: false
[2023-07-01 10:21:46] [config] no-reload: false
[2023-07-01 10:21:46] [config] no-restore-corpus: false
[2023-07-01 10:21:46] [config] normalize: 1
[2023-07-01 10:21:46] [config] normalize-gradient: false
[2023-07-01 10:21:46] [config] num-devices: 0
[2023-07-01 10:21:46] [config] optimizer: adam
[2023-07-01 10:21:46] [config] optimizer-delay: 1
[2023-07-01 10:21:46] [config] optimizer-params:
[2023-07-01 10:21:46] [config]   - 0.9
[2023-07-01 10:21:46] [config]   - 0.98
[2023-07-01 10:21:46] [config]   - 1e-09
[2023-07-01 10:21:46] [config] output-omit-bias: false
[2023-07-01 10:21:46] [config] overwrite: true
[2023-07-01 10:21:46] [config] precision:
[2023-07-01 10:21:46] [config]   - float32
[2023-07-01 10:21:46] [config]   - float32
[2023-07-01 10:21:46] [config] pretrained-model: ""
[2023-07-01 10:21:46] [config] quantize-biases: false
[2023-07-01 10:21:46] [config] quantize-bits: 0
[2023-07-01 10:21:46] [config] quantize-log-based: false
[2023-07-01 10:21:46] [config] quantize-optimization-steps: 0
[2023-07-01 10:21:46] [config] quiet: false
[2023-07-01 10:21:46] [config] quiet-translation: true
[2023-07-01 10:21:46] [config] relative-paths: false
[2023-07-01 10:21:46] [config] right-left: false
[2023-07-01 10:21:46] [config] save-freq: 10000u
[2023-07-01 10:21:46] [config] seed: 1234
[2023-07-01 10:21:46] [config] sentencepiece-alphas:
[2023-07-01 10:21:46] [config]   []
[2023-07-01 10:21:46] [config] sentencepiece-max-lines: 2000000
[2023-07-01 10:21:46] [config] sentencepiece-options: ""
[2023-07-01 10:21:46] [config] sharding: global
[2023-07-01 10:21:46] [config] shuffle: data
[2023-07-01 10:21:46] [config] shuffle-in-ram: false
[2023-07-01 10:21:46] [config] sigterm: save-and-exit
[2023-07-01 10:21:46] [config] skip: false
[2023-07-01 10:21:46] [config] sqlite: ""
[2023-07-01 10:21:46] [config] sqlite-drop: false
[2023-07-01 10:21:46] [config] sync-freq: 200u
[2023-07-01 10:21:46] [config] sync-sgd: true
[2023-07-01 10:21:46] [config] tempdir: /tmp
[2023-07-01 10:21:46] [config] tied-embeddings: false
[2023-07-01 10:21:46] [config] tied-embeddings-all: true
[2023-07-01 10:21:46] [config] tied-embeddings-src: false
[2023-07-01 10:21:46] [config] train-embedder-rank:
[2023-07-01 10:21:46] [config]   []
[2023-07-01 10:21:46] [config] train-sets:
[2023-07-01 10:21:46] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 10:21:46] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 10:21:46] [config] transformer-aan-activation: swish
[2023-07-01 10:21:46] [config] transformer-aan-depth: 2
[2023-07-01 10:21:46] [config] transformer-aan-nogate: false
[2023-07-01 10:21:46] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 10:21:46] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 10:21:46] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 10:21:46] [config] transformer-depth-scaling: false
[2023-07-01 10:21:46] [config] transformer-dim-aan: 2048
[2023-07-01 10:21:46] [config] transformer-dim-ffn: 2048
[2023-07-01 10:21:46] [config] transformer-dropout: 0.1
[2023-07-01 10:21:46] [config] transformer-dropout-attention: 0
[2023-07-01 10:21:46] [config] transformer-dropout-ffn: 0
[2023-07-01 10:21:46] [config] transformer-ffn-activation: swish
[2023-07-01 10:21:46] [config] transformer-ffn-depth: 2
[2023-07-01 10:21:46] [config] transformer-guided-alignment-layer: last
[2023-07-01 10:21:46] [config] transformer-heads: 8
[2023-07-01 10:21:46] [config] transformer-no-projection: false
[2023-07-01 10:21:46] [config] transformer-pool: false
[2023-07-01 10:21:46] [config] transformer-postprocess: dan
[2023-07-01 10:21:46] [config] transformer-postprocess-emb: d
[2023-07-01 10:21:46] [config] transformer-postprocess-top: ""
[2023-07-01 10:21:46] [config] transformer-preprocess: ""
[2023-07-01 10:21:46] [config] transformer-tied-layers:
[2023-07-01 10:21:46] [config]   []
[2023-07-01 10:21:46] [config] transformer-train-position-embeddings: false
[2023-07-01 10:21:46] [config] tsv: false
[2023-07-01 10:21:46] [config] tsv-fields: 0
[2023-07-01 10:21:46] [config] type: transformer
[2023-07-01 10:21:46] [config] ulr: false
[2023-07-01 10:21:46] [config] ulr-dim-emb: 0
[2023-07-01 10:21:46] [config] ulr-dropout: 0
[2023-07-01 10:21:46] [config] ulr-keys-vectors: ""
[2023-07-01 10:21:46] [config] ulr-query-vectors: ""
[2023-07-01 10:21:46] [config] ulr-softmax-temperature: 1
[2023-07-01 10:21:46] [config] ulr-trainable-transformation: false
[2023-07-01 10:21:46] [config] unlikelihood-loss: false
[2023-07-01 10:21:46] [config] valid-freq: 50000000
[2023-07-01 10:21:46] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 10:21:46] [config] valid-max-length: 1000
[2023-07-01 10:21:46] [config] valid-metrics:
[2023-07-01 10:21:46] [config]   - cross-entropy
[2023-07-01 10:21:46] [config]   - translation
[2023-07-01 10:21:46] [config] valid-mini-batch: 64
[2023-07-01 10:21:46] [config] valid-reset-stalled: false
[2023-07-01 10:21:46] [config] valid-script-args:
[2023-07-01 10:21:46] [config]   []
[2023-07-01 10:21:46] [config] valid-script-path: ""
[2023-07-01 10:21:46] [config] valid-sets:
[2023-07-01 10:21:46] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 10:21:46] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 10:21:46] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 10:21:46] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:21:46] [config] vocabs:
[2023-07-01 10:21:46] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 10:21:46] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 10:21:46] [config] word-penalty: 0
[2023-07-01 10:21:46] [config] word-scores: false
[2023-07-01 10:21:46] [config] workspace: 2048
[2023-07-01 10:21:46] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:21:46] Using synchronous SGD
[2023-07-01 10:21:46] Synced seed 1234
[2023-07-01 10:21:46] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 10:21:46] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 10:21:46] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 10:21:46] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 10:21:46] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 10:21:46] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 10:21:47] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 10:21:47] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 10:21:47] [comm] Using global sharding
[2023-07-01 10:21:47] [comm] NCCLCommunicators constructed successfully
[2023-07-01 10:21:47] [training] Using 1 GPUs
[2023-07-01 10:21:47] [logits] Applying loss function for 1 factor(s)
[2023-07-01 10:21:47] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:21:47] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 10:21:47] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:21:55] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 10:21:55] [valid] No post-processing script given for validating translator
[2023-07-01 10:21:55] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 10:21:55] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 10:21:55] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 10:21:55] [comm] Using global sharding
[2023-07-01 10:21:55] [comm] NCCLCommunicators constructed successfully
[2023-07-01 10:21:55] [training] Using 1 GPUs
[2023-07-01 10:21:55] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:21:56] Allocating memory for general optimizer shards
[2023-07-01 10:21:56] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:21:56] Loading Adam parameters
[2023-07-01 10:21:56] [memory] Reserving 176 MB, device gpu0
[2023-07-01 10:21:56] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:21:56] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 10:21:56] [data] Restoring the corpus state to epoch 27, batch 4914
[2023-07-01 10:21:56] [data] Shuffling data
[2023-07-01 10:21:56] [data] Done reading 20,192 sentences
[2023-07-01 10:21:56] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 10:21:56] Training started
[2023-07-01 10:21:56] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-07-01 10:21:56] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:21:56] Parameter type float32, optimization type float32, casting types false
[2023-07-01 10:22:07] Ep. 27 : Up. 5000 : Sen. 8,814 : Cost 4.85571194 * 3,211,188 @ 3,870 after 16,049,677 : Time 11.95s : 268780.63 words/s : gNorm 1.5699 : L.r. 9.3750e-05
[2023-07-01 10:22:20] Seen 20,073 samples
[2023-07-01 10:22:20] Starting data epoch 28 in logical epoch 28
[2023-07-01 10:22:20] Training finished
[2023-07-01 10:22:23] [valid] Ep. 28 : Up. 5103 : cross-entropy : 134.176 : new best
[2023-07-01 10:24:04] [valid] Ep. 28 : Up. 5103 : translation : 0 : new best
[2023-07-01 10:24:04] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:24:06] Saving Adam parameters
[2023-07-01 10:24:07] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 10:24:12] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:24:12] [marian] Running on node20.datos.cluster.uy as process 9338 with command line:
[2023-07-01 10:24:12] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 28 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 10:24:12] [config] after: 0e
[2023-07-01 10:24:12] [config] after-batches: 0
[2023-07-01 10:24:12] [config] after-epochs: 28
[2023-07-01 10:24:12] [config] all-caps-every: 0
[2023-07-01 10:24:12] [config] allow-unk: false
[2023-07-01 10:24:12] [config] authors: false
[2023-07-01 10:24:12] [config] beam-size: 12
[2023-07-01 10:24:12] [config] bert-class-symbol: "[CLS]"
[2023-07-01 10:24:12] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 10:24:12] [config] bert-masking-fraction: 0.15
[2023-07-01 10:24:12] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 10:24:12] [config] bert-train-type-embeddings: true
[2023-07-01 10:24:12] [config] bert-type-vocab-size: 2
[2023-07-01 10:24:12] [config] build-info: ""
[2023-07-01 10:24:12] [config] check-gradient-nan: false
[2023-07-01 10:24:12] [config] check-nan: false
[2023-07-01 10:24:12] [config] cite: false
[2023-07-01 10:24:12] [config] clip-norm: 5
[2023-07-01 10:24:12] [config] cost-scaling:
[2023-07-01 10:24:12] [config]   []
[2023-07-01 10:24:12] [config] cost-type: ce-sum
[2023-07-01 10:24:12] [config] cpu-threads: 0
[2023-07-01 10:24:12] [config] data-threads: 8
[2023-07-01 10:24:12] [config] data-weighting: ""
[2023-07-01 10:24:12] [config] data-weighting-type: sentence
[2023-07-01 10:24:12] [config] dec-cell: gru
[2023-07-01 10:24:12] [config] dec-cell-base-depth: 2
[2023-07-01 10:24:12] [config] dec-cell-high-depth: 1
[2023-07-01 10:24:12] [config] dec-depth: 2
[2023-07-01 10:24:12] [config] devices:
[2023-07-01 10:24:12] [config]   - 0
[2023-07-01 10:24:12] [config] dim-emb: 512
[2023-07-01 10:24:12] [config] dim-rnn: 1024
[2023-07-01 10:24:12] [config] dim-vocabs:
[2023-07-01 10:24:12] [config]   - 16384
[2023-07-01 10:24:12] [config]   - 16384
[2023-07-01 10:24:12] [config] disp-first: 0
[2023-07-01 10:24:12] [config] disp-freq: 1000u
[2023-07-01 10:24:12] [config] disp-label-counts: true
[2023-07-01 10:24:12] [config] dropout-rnn: 0
[2023-07-01 10:24:12] [config] dropout-src: 0
[2023-07-01 10:24:12] [config] dropout-trg: 0
[2023-07-01 10:24:12] [config] dump-config: ""
[2023-07-01 10:24:12] [config] dynamic-gradient-scaling:
[2023-07-01 10:24:12] [config]   []
[2023-07-01 10:24:12] [config] early-stopping: 10
[2023-07-01 10:24:12] [config] early-stopping-on: first
[2023-07-01 10:24:12] [config] embedding-fix-src: false
[2023-07-01 10:24:12] [config] embedding-fix-trg: false
[2023-07-01 10:24:12] [config] embedding-normalization: false
[2023-07-01 10:24:12] [config] embedding-vectors:
[2023-07-01 10:24:12] [config]   []
[2023-07-01 10:24:12] [config] enc-cell: gru
[2023-07-01 10:24:12] [config] enc-cell-depth: 1
[2023-07-01 10:24:12] [config] enc-depth: 2
[2023-07-01 10:24:12] [config] enc-type: bidirectional
[2023-07-01 10:24:12] [config] english-title-case-every: 0
[2023-07-01 10:24:12] [config] exponential-smoothing: 0.0001
[2023-07-01 10:24:12] [config] factor-weight: 1
[2023-07-01 10:24:12] [config] factors-combine: sum
[2023-07-01 10:24:12] [config] factors-dim-emb: 0
[2023-07-01 10:24:12] [config] gradient-checkpointing: false
[2023-07-01 10:24:12] [config] gradient-norm-average-window: 100
[2023-07-01 10:24:12] [config] guided-alignment: none
[2023-07-01 10:24:12] [config] guided-alignment-cost: mse
[2023-07-01 10:24:12] [config] guided-alignment-weight: 0.1
[2023-07-01 10:24:12] [config] ignore-model-config: false
[2023-07-01 10:24:12] [config] input-types:
[2023-07-01 10:24:12] [config]   []
[2023-07-01 10:24:12] [config] interpolate-env-vars: false
[2023-07-01 10:24:12] [config] keep-best: false
[2023-07-01 10:24:12] [config] label-smoothing: 0.1
[2023-07-01 10:24:12] [config] layer-normalization: false
[2023-07-01 10:24:12] [config] learn-rate: 0.0003
[2023-07-01 10:24:12] [config] lemma-dependency: ""
[2023-07-01 10:24:12] [config] lemma-dim-emb: 0
[2023-07-01 10:24:12] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 10:24:12] [config] log-level: info
[2023-07-01 10:24:12] [config] log-time-zone: ""
[2023-07-01 10:24:12] [config] logical-epoch:
[2023-07-01 10:24:12] [config]   - 1e
[2023-07-01 10:24:12] [config]   - 0
[2023-07-01 10:24:12] [config] lr-decay: 0
[2023-07-01 10:24:12] [config] lr-decay-freq: 50000
[2023-07-01 10:24:12] [config] lr-decay-inv-sqrt:
[2023-07-01 10:24:12] [config]   - 16000
[2023-07-01 10:24:12] [config] lr-decay-repeat-warmup: false
[2023-07-01 10:24:12] [config] lr-decay-reset-optimizer: false
[2023-07-01 10:24:12] [config] lr-decay-start:
[2023-07-01 10:24:12] [config]   - 10
[2023-07-01 10:24:12] [config]   - 1
[2023-07-01 10:24:12] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 10:24:12] [config] lr-report: true
[2023-07-01 10:24:12] [config] lr-warmup: 16000
[2023-07-01 10:24:12] [config] lr-warmup-at-reload: false
[2023-07-01 10:24:12] [config] lr-warmup-cycle: false
[2023-07-01 10:24:12] [config] lr-warmup-start-rate: 0
[2023-07-01 10:24:12] [config] max-length: 100
[2023-07-01 10:24:12] [config] max-length-crop: false
[2023-07-01 10:24:12] [config] max-length-factor: 3
[2023-07-01 10:24:12] [config] maxi-batch: 100
[2023-07-01 10:24:12] [config] maxi-batch-sort: trg
[2023-07-01 10:24:12] [config] mini-batch: 1000
[2023-07-01 10:24:12] [config] mini-batch-fit: true
[2023-07-01 10:24:12] [config] mini-batch-fit-step: 10
[2023-07-01 10:24:12] [config] mini-batch-round-up: true
[2023-07-01 10:24:12] [config] mini-batch-track-lr: false
[2023-07-01 10:24:12] [config] mini-batch-warmup: 0
[2023-07-01 10:24:12] [config] mini-batch-words: 0
[2023-07-01 10:24:12] [config] mini-batch-words-ref: 0
[2023-07-01 10:24:12] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:24:12] [config] multi-loss-type: sum
[2023-07-01 10:24:12] [config] n-best: false
[2023-07-01 10:24:12] [config] no-nccl: false
[2023-07-01 10:24:12] [config] no-reload: false
[2023-07-01 10:24:12] [config] no-restore-corpus: false
[2023-07-01 10:24:12] [config] normalize: 1
[2023-07-01 10:24:12] [config] normalize-gradient: false
[2023-07-01 10:24:12] [config] num-devices: 0
[2023-07-01 10:24:12] [config] optimizer: adam
[2023-07-01 10:24:12] [config] optimizer-delay: 1
[2023-07-01 10:24:12] [config] optimizer-params:
[2023-07-01 10:24:12] [config]   - 0.9
[2023-07-01 10:24:12] [config]   - 0.98
[2023-07-01 10:24:12] [config]   - 1e-09
[2023-07-01 10:24:12] [config] output-omit-bias: false
[2023-07-01 10:24:12] [config] overwrite: true
[2023-07-01 10:24:12] [config] precision:
[2023-07-01 10:24:12] [config]   - float32
[2023-07-01 10:24:12] [config]   - float32
[2023-07-01 10:24:12] [config] pretrained-model: ""
[2023-07-01 10:24:12] [config] quantize-biases: false
[2023-07-01 10:24:12] [config] quantize-bits: 0
[2023-07-01 10:24:12] [config] quantize-log-based: false
[2023-07-01 10:24:12] [config] quantize-optimization-steps: 0
[2023-07-01 10:24:12] [config] quiet: false
[2023-07-01 10:24:12] [config] quiet-translation: true
[2023-07-01 10:24:12] [config] relative-paths: false
[2023-07-01 10:24:12] [config] right-left: false
[2023-07-01 10:24:12] [config] save-freq: 10000u
[2023-07-01 10:24:12] [config] seed: 1234
[2023-07-01 10:24:12] [config] sentencepiece-alphas:
[2023-07-01 10:24:12] [config]   []
[2023-07-01 10:24:12] [config] sentencepiece-max-lines: 2000000
[2023-07-01 10:24:12] [config] sentencepiece-options: ""
[2023-07-01 10:24:12] [config] sharding: global
[2023-07-01 10:24:12] [config] shuffle: data
[2023-07-01 10:24:12] [config] shuffle-in-ram: false
[2023-07-01 10:24:12] [config] sigterm: save-and-exit
[2023-07-01 10:24:12] [config] skip: false
[2023-07-01 10:24:12] [config] sqlite: ""
[2023-07-01 10:24:12] [config] sqlite-drop: false
[2023-07-01 10:24:12] [config] sync-freq: 200u
[2023-07-01 10:24:12] [config] sync-sgd: true
[2023-07-01 10:24:12] [config] tempdir: /tmp
[2023-07-01 10:24:12] [config] tied-embeddings: false
[2023-07-01 10:24:12] [config] tied-embeddings-all: true
[2023-07-01 10:24:12] [config] tied-embeddings-src: false
[2023-07-01 10:24:12] [config] train-embedder-rank:
[2023-07-01 10:24:12] [config]   []
[2023-07-01 10:24:12] [config] train-sets:
[2023-07-01 10:24:12] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 10:24:12] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 10:24:12] [config] transformer-aan-activation: swish
[2023-07-01 10:24:12] [config] transformer-aan-depth: 2
[2023-07-01 10:24:12] [config] transformer-aan-nogate: false
[2023-07-01 10:24:12] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 10:24:12] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 10:24:12] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 10:24:12] [config] transformer-depth-scaling: false
[2023-07-01 10:24:12] [config] transformer-dim-aan: 2048
[2023-07-01 10:24:12] [config] transformer-dim-ffn: 2048
[2023-07-01 10:24:12] [config] transformer-dropout: 0.1
[2023-07-01 10:24:12] [config] transformer-dropout-attention: 0
[2023-07-01 10:24:12] [config] transformer-dropout-ffn: 0
[2023-07-01 10:24:12] [config] transformer-ffn-activation: swish
[2023-07-01 10:24:12] [config] transformer-ffn-depth: 2
[2023-07-01 10:24:12] [config] transformer-guided-alignment-layer: last
[2023-07-01 10:24:12] [config] transformer-heads: 8
[2023-07-01 10:24:12] [config] transformer-no-projection: false
[2023-07-01 10:24:12] [config] transformer-pool: false
[2023-07-01 10:24:12] [config] transformer-postprocess: dan
[2023-07-01 10:24:12] [config] transformer-postprocess-emb: d
[2023-07-01 10:24:12] [config] transformer-postprocess-top: ""
[2023-07-01 10:24:12] [config] transformer-preprocess: ""
[2023-07-01 10:24:12] [config] transformer-tied-layers:
[2023-07-01 10:24:12] [config]   []
[2023-07-01 10:24:12] [config] transformer-train-position-embeddings: false
[2023-07-01 10:24:12] [config] tsv: false
[2023-07-01 10:24:12] [config] tsv-fields: 0
[2023-07-01 10:24:12] [config] type: transformer
[2023-07-01 10:24:12] [config] ulr: false
[2023-07-01 10:24:12] [config] ulr-dim-emb: 0
[2023-07-01 10:24:12] [config] ulr-dropout: 0
[2023-07-01 10:24:12] [config] ulr-keys-vectors: ""
[2023-07-01 10:24:12] [config] ulr-query-vectors: ""
[2023-07-01 10:24:12] [config] ulr-softmax-temperature: 1
[2023-07-01 10:24:12] [config] ulr-trainable-transformation: false
[2023-07-01 10:24:12] [config] unlikelihood-loss: false
[2023-07-01 10:24:12] [config] valid-freq: 50000000
[2023-07-01 10:24:12] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 10:24:12] [config] valid-max-length: 1000
[2023-07-01 10:24:12] [config] valid-metrics:
[2023-07-01 10:24:12] [config]   - cross-entropy
[2023-07-01 10:24:12] [config]   - translation
[2023-07-01 10:24:12] [config] valid-mini-batch: 64
[2023-07-01 10:24:12] [config] valid-reset-stalled: false
[2023-07-01 10:24:12] [config] valid-script-args:
[2023-07-01 10:24:12] [config]   []
[2023-07-01 10:24:12] [config] valid-script-path: ""
[2023-07-01 10:24:12] [config] valid-sets:
[2023-07-01 10:24:12] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 10:24:12] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 10:24:12] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 10:24:12] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:24:12] [config] vocabs:
[2023-07-01 10:24:12] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 10:24:12] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 10:24:12] [config] word-penalty: 0
[2023-07-01 10:24:12] [config] word-scores: false
[2023-07-01 10:24:12] [config] workspace: 2048
[2023-07-01 10:24:12] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:24:12] Using synchronous SGD
[2023-07-01 10:24:13] Synced seed 1234
[2023-07-01 10:24:13] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 10:24:13] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 10:24:13] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 10:24:13] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 10:24:13] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 10:24:13] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 10:24:13] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 10:24:13] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 10:24:13] [comm] Using global sharding
[2023-07-01 10:24:14] [comm] NCCLCommunicators constructed successfully
[2023-07-01 10:24:14] [training] Using 1 GPUs
[2023-07-01 10:24:14] [logits] Applying loss function for 1 factor(s)
[2023-07-01 10:24:14] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:24:14] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 10:24:14] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:24:21] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 10:24:22] [valid] No post-processing script given for validating translator
[2023-07-01 10:24:22] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 10:24:22] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 10:24:22] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 10:24:22] [comm] Using global sharding
[2023-07-01 10:24:22] [comm] NCCLCommunicators constructed successfully
[2023-07-01 10:24:22] [training] Using 1 GPUs
[2023-07-01 10:24:22] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:24:22] Allocating memory for general optimizer shards
[2023-07-01 10:24:22] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:24:22] Loading Adam parameters
[2023-07-01 10:24:23] [memory] Reserving 176 MB, device gpu0
[2023-07-01 10:24:23] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:24:23] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 10:24:23] [data] Restoring the corpus state to epoch 28, batch 5103
[2023-07-01 10:24:23] [data] Shuffling data
[2023-07-01 10:24:23] [data] Done reading 20,192 sentences
[2023-07-01 10:24:23] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 10:24:23] Training started
[2023-07-01 10:24:23] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-07-01 10:24:23] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:24:23] Parameter type float32, optimization type float32, casting types false
[2023-07-01 10:24:47] Seen 20,073 samples
[2023-07-01 10:24:47] Starting data epoch 29 in logical epoch 29
[2023-07-01 10:24:47] Training finished
[2023-07-01 10:24:50] [valid] Ep. 29 : Up. 5292 : cross-entropy : 132.822 : new best
[2023-07-01 10:26:29] [valid] Ep. 29 : Up. 5292 : translation : 0 : new best
[2023-07-01 10:26:29] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:26:31] Saving Adam parameters
[2023-07-01 10:26:31] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 10:26:38] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:26:38] [marian] Running on node20.datos.cluster.uy as process 9513 with command line:
[2023-07-01 10:26:38] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 29 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 10:26:38] [config] after: 0e
[2023-07-01 10:26:38] [config] after-batches: 0
[2023-07-01 10:26:38] [config] after-epochs: 29
[2023-07-01 10:26:38] [config] all-caps-every: 0
[2023-07-01 10:26:38] [config] allow-unk: false
[2023-07-01 10:26:38] [config] authors: false
[2023-07-01 10:26:38] [config] beam-size: 12
[2023-07-01 10:26:38] [config] bert-class-symbol: "[CLS]"
[2023-07-01 10:26:38] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 10:26:38] [config] bert-masking-fraction: 0.15
[2023-07-01 10:26:38] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 10:26:38] [config] bert-train-type-embeddings: true
[2023-07-01 10:26:38] [config] bert-type-vocab-size: 2
[2023-07-01 10:26:38] [config] build-info: ""
[2023-07-01 10:26:38] [config] check-gradient-nan: false
[2023-07-01 10:26:38] [config] check-nan: false
[2023-07-01 10:26:38] [config] cite: false
[2023-07-01 10:26:38] [config] clip-norm: 5
[2023-07-01 10:26:38] [config] cost-scaling:
[2023-07-01 10:26:38] [config]   []
[2023-07-01 10:26:38] [config] cost-type: ce-sum
[2023-07-01 10:26:38] [config] cpu-threads: 0
[2023-07-01 10:26:38] [config] data-threads: 8
[2023-07-01 10:26:38] [config] data-weighting: ""
[2023-07-01 10:26:38] [config] data-weighting-type: sentence
[2023-07-01 10:26:38] [config] dec-cell: gru
[2023-07-01 10:26:38] [config] dec-cell-base-depth: 2
[2023-07-01 10:26:38] [config] dec-cell-high-depth: 1
[2023-07-01 10:26:38] [config] dec-depth: 2
[2023-07-01 10:26:38] [config] devices:
[2023-07-01 10:26:38] [config]   - 0
[2023-07-01 10:26:38] [config] dim-emb: 512
[2023-07-01 10:26:38] [config] dim-rnn: 1024
[2023-07-01 10:26:38] [config] dim-vocabs:
[2023-07-01 10:26:38] [config]   - 16384
[2023-07-01 10:26:38] [config]   - 16384
[2023-07-01 10:26:38] [config] disp-first: 0
[2023-07-01 10:26:38] [config] disp-freq: 1000u
[2023-07-01 10:26:38] [config] disp-label-counts: true
[2023-07-01 10:26:38] [config] dropout-rnn: 0
[2023-07-01 10:26:38] [config] dropout-src: 0
[2023-07-01 10:26:38] [config] dropout-trg: 0
[2023-07-01 10:26:38] [config] dump-config: ""
[2023-07-01 10:26:38] [config] dynamic-gradient-scaling:
[2023-07-01 10:26:38] [config]   []
[2023-07-01 10:26:38] [config] early-stopping: 10
[2023-07-01 10:26:38] [config] early-stopping-on: first
[2023-07-01 10:26:38] [config] embedding-fix-src: false
[2023-07-01 10:26:38] [config] embedding-fix-trg: false
[2023-07-01 10:26:38] [config] embedding-normalization: false
[2023-07-01 10:26:38] [config] embedding-vectors:
[2023-07-01 10:26:38] [config]   []
[2023-07-01 10:26:38] [config] enc-cell: gru
[2023-07-01 10:26:38] [config] enc-cell-depth: 1
[2023-07-01 10:26:38] [config] enc-depth: 2
[2023-07-01 10:26:38] [config] enc-type: bidirectional
[2023-07-01 10:26:38] [config] english-title-case-every: 0
[2023-07-01 10:26:38] [config] exponential-smoothing: 0.0001
[2023-07-01 10:26:38] [config] factor-weight: 1
[2023-07-01 10:26:38] [config] factors-combine: sum
[2023-07-01 10:26:38] [config] factors-dim-emb: 0
[2023-07-01 10:26:38] [config] gradient-checkpointing: false
[2023-07-01 10:26:38] [config] gradient-norm-average-window: 100
[2023-07-01 10:26:38] [config] guided-alignment: none
[2023-07-01 10:26:38] [config] guided-alignment-cost: mse
[2023-07-01 10:26:38] [config] guided-alignment-weight: 0.1
[2023-07-01 10:26:38] [config] ignore-model-config: false
[2023-07-01 10:26:38] [config] input-types:
[2023-07-01 10:26:38] [config]   []
[2023-07-01 10:26:38] [config] interpolate-env-vars: false
[2023-07-01 10:26:38] [config] keep-best: false
[2023-07-01 10:26:38] [config] label-smoothing: 0.1
[2023-07-01 10:26:38] [config] layer-normalization: false
[2023-07-01 10:26:38] [config] learn-rate: 0.0003
[2023-07-01 10:26:38] [config] lemma-dependency: ""
[2023-07-01 10:26:38] [config] lemma-dim-emb: 0
[2023-07-01 10:26:38] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 10:26:38] [config] log-level: info
[2023-07-01 10:26:38] [config] log-time-zone: ""
[2023-07-01 10:26:38] [config] logical-epoch:
[2023-07-01 10:26:38] [config]   - 1e
[2023-07-01 10:26:38] [config]   - 0
[2023-07-01 10:26:38] [config] lr-decay: 0
[2023-07-01 10:26:38] [config] lr-decay-freq: 50000
[2023-07-01 10:26:38] [config] lr-decay-inv-sqrt:
[2023-07-01 10:26:38] [config]   - 16000
[2023-07-01 10:26:38] [config] lr-decay-repeat-warmup: false
[2023-07-01 10:26:38] [config] lr-decay-reset-optimizer: false
[2023-07-01 10:26:38] [config] lr-decay-start:
[2023-07-01 10:26:38] [config]   - 10
[2023-07-01 10:26:38] [config]   - 1
[2023-07-01 10:26:38] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 10:26:38] [config] lr-report: true
[2023-07-01 10:26:38] [config] lr-warmup: 16000
[2023-07-01 10:26:38] [config] lr-warmup-at-reload: false
[2023-07-01 10:26:38] [config] lr-warmup-cycle: false
[2023-07-01 10:26:38] [config] lr-warmup-start-rate: 0
[2023-07-01 10:26:38] [config] max-length: 100
[2023-07-01 10:26:38] [config] max-length-crop: false
[2023-07-01 10:26:38] [config] max-length-factor: 3
[2023-07-01 10:26:38] [config] maxi-batch: 100
[2023-07-01 10:26:38] [config] maxi-batch-sort: trg
[2023-07-01 10:26:38] [config] mini-batch: 1000
[2023-07-01 10:26:38] [config] mini-batch-fit: true
[2023-07-01 10:26:38] [config] mini-batch-fit-step: 10
[2023-07-01 10:26:38] [config] mini-batch-round-up: true
[2023-07-01 10:26:38] [config] mini-batch-track-lr: false
[2023-07-01 10:26:38] [config] mini-batch-warmup: 0
[2023-07-01 10:26:38] [config] mini-batch-words: 0
[2023-07-01 10:26:38] [config] mini-batch-words-ref: 0
[2023-07-01 10:26:38] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:26:38] [config] multi-loss-type: sum
[2023-07-01 10:26:38] [config] n-best: false
[2023-07-01 10:26:38] [config] no-nccl: false
[2023-07-01 10:26:38] [config] no-reload: false
[2023-07-01 10:26:38] [config] no-restore-corpus: false
[2023-07-01 10:26:38] [config] normalize: 1
[2023-07-01 10:26:38] [config] normalize-gradient: false
[2023-07-01 10:26:38] [config] num-devices: 0
[2023-07-01 10:26:38] [config] optimizer: adam
[2023-07-01 10:26:38] [config] optimizer-delay: 1
[2023-07-01 10:26:38] [config] optimizer-params:
[2023-07-01 10:26:38] [config]   - 0.9
[2023-07-01 10:26:38] [config]   - 0.98
[2023-07-01 10:26:38] [config]   - 1e-09
[2023-07-01 10:26:38] [config] output-omit-bias: false
[2023-07-01 10:26:38] [config] overwrite: true
[2023-07-01 10:26:38] [config] precision:
[2023-07-01 10:26:38] [config]   - float32
[2023-07-01 10:26:38] [config]   - float32
[2023-07-01 10:26:38] [config] pretrained-model: ""
[2023-07-01 10:26:38] [config] quantize-biases: false
[2023-07-01 10:26:38] [config] quantize-bits: 0
[2023-07-01 10:26:38] [config] quantize-log-based: false
[2023-07-01 10:26:38] [config] quantize-optimization-steps: 0
[2023-07-01 10:26:38] [config] quiet: false
[2023-07-01 10:26:38] [config] quiet-translation: true
[2023-07-01 10:26:38] [config] relative-paths: false
[2023-07-01 10:26:38] [config] right-left: false
[2023-07-01 10:26:38] [config] save-freq: 10000u
[2023-07-01 10:26:38] [config] seed: 1234
[2023-07-01 10:26:38] [config] sentencepiece-alphas:
[2023-07-01 10:26:38] [config]   []
[2023-07-01 10:26:38] [config] sentencepiece-max-lines: 2000000
[2023-07-01 10:26:38] [config] sentencepiece-options: ""
[2023-07-01 10:26:38] [config] sharding: global
[2023-07-01 10:26:38] [config] shuffle: data
[2023-07-01 10:26:38] [config] shuffle-in-ram: false
[2023-07-01 10:26:38] [config] sigterm: save-and-exit
[2023-07-01 10:26:38] [config] skip: false
[2023-07-01 10:26:38] [config] sqlite: ""
[2023-07-01 10:26:38] [config] sqlite-drop: false
[2023-07-01 10:26:38] [config] sync-freq: 200u
[2023-07-01 10:26:38] [config] sync-sgd: true
[2023-07-01 10:26:38] [config] tempdir: /tmp
[2023-07-01 10:26:38] [config] tied-embeddings: false
[2023-07-01 10:26:38] [config] tied-embeddings-all: true
[2023-07-01 10:26:38] [config] tied-embeddings-src: false
[2023-07-01 10:26:38] [config] train-embedder-rank:
[2023-07-01 10:26:38] [config]   []
[2023-07-01 10:26:38] [config] train-sets:
[2023-07-01 10:26:38] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 10:26:38] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 10:26:38] [config] transformer-aan-activation: swish
[2023-07-01 10:26:38] [config] transformer-aan-depth: 2
[2023-07-01 10:26:38] [config] transformer-aan-nogate: false
[2023-07-01 10:26:38] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 10:26:38] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 10:26:38] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 10:26:38] [config] transformer-depth-scaling: false
[2023-07-01 10:26:38] [config] transformer-dim-aan: 2048
[2023-07-01 10:26:38] [config] transformer-dim-ffn: 2048
[2023-07-01 10:26:38] [config] transformer-dropout: 0.1
[2023-07-01 10:26:38] [config] transformer-dropout-attention: 0
[2023-07-01 10:26:38] [config] transformer-dropout-ffn: 0
[2023-07-01 10:26:38] [config] transformer-ffn-activation: swish
[2023-07-01 10:26:38] [config] transformer-ffn-depth: 2
[2023-07-01 10:26:38] [config] transformer-guided-alignment-layer: last
[2023-07-01 10:26:38] [config] transformer-heads: 8
[2023-07-01 10:26:38] [config] transformer-no-projection: false
[2023-07-01 10:26:38] [config] transformer-pool: false
[2023-07-01 10:26:38] [config] transformer-postprocess: dan
[2023-07-01 10:26:38] [config] transformer-postprocess-emb: d
[2023-07-01 10:26:38] [config] transformer-postprocess-top: ""
[2023-07-01 10:26:38] [config] transformer-preprocess: ""
[2023-07-01 10:26:38] [config] transformer-tied-layers:
[2023-07-01 10:26:38] [config]   []
[2023-07-01 10:26:38] [config] transformer-train-position-embeddings: false
[2023-07-01 10:26:38] [config] tsv: false
[2023-07-01 10:26:38] [config] tsv-fields: 0
[2023-07-01 10:26:38] [config] type: transformer
[2023-07-01 10:26:38] [config] ulr: false
[2023-07-01 10:26:38] [config] ulr-dim-emb: 0
[2023-07-01 10:26:38] [config] ulr-dropout: 0
[2023-07-01 10:26:38] [config] ulr-keys-vectors: ""
[2023-07-01 10:26:38] [config] ulr-query-vectors: ""
[2023-07-01 10:26:38] [config] ulr-softmax-temperature: 1
[2023-07-01 10:26:38] [config] ulr-trainable-transformation: false
[2023-07-01 10:26:38] [config] unlikelihood-loss: false
[2023-07-01 10:26:38] [config] valid-freq: 50000000
[2023-07-01 10:26:38] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 10:26:38] [config] valid-max-length: 1000
[2023-07-01 10:26:38] [config] valid-metrics:
[2023-07-01 10:26:38] [config]   - cross-entropy
[2023-07-01 10:26:38] [config]   - translation
[2023-07-01 10:26:38] [config] valid-mini-batch: 64
[2023-07-01 10:26:38] [config] valid-reset-stalled: false
[2023-07-01 10:26:38] [config] valid-script-args:
[2023-07-01 10:26:38] [config]   []
[2023-07-01 10:26:38] [config] valid-script-path: ""
[2023-07-01 10:26:38] [config] valid-sets:
[2023-07-01 10:26:38] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 10:26:38] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 10:26:38] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 10:26:38] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:26:38] [config] vocabs:
[2023-07-01 10:26:38] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 10:26:38] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 10:26:38] [config] word-penalty: 0
[2023-07-01 10:26:38] [config] word-scores: false
[2023-07-01 10:26:38] [config] workspace: 2048
[2023-07-01 10:26:38] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:26:38] Using synchronous SGD
[2023-07-01 10:26:38] Synced seed 1234
[2023-07-01 10:26:38] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 10:26:38] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 10:26:38] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 10:26:38] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 10:26:38] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 10:26:38] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 10:26:39] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 10:26:39] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 10:26:39] [comm] Using global sharding
[2023-07-01 10:26:39] [comm] NCCLCommunicators constructed successfully
[2023-07-01 10:26:39] [training] Using 1 GPUs
[2023-07-01 10:26:39] [logits] Applying loss function for 1 factor(s)
[2023-07-01 10:26:39] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:26:39] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 10:26:40] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:26:47] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 10:26:47] [valid] No post-processing script given for validating translator
[2023-07-01 10:26:47] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 10:26:47] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 10:26:47] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 10:26:47] [comm] Using global sharding
[2023-07-01 10:26:47] [comm] NCCLCommunicators constructed successfully
[2023-07-01 10:26:47] [training] Using 1 GPUs
[2023-07-01 10:26:47] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:26:48] Allocating memory for general optimizer shards
[2023-07-01 10:26:48] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:26:48] Loading Adam parameters
[2023-07-01 10:26:48] [memory] Reserving 176 MB, device gpu0
[2023-07-01 10:26:48] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:26:48] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 10:26:48] [data] Restoring the corpus state to epoch 29, batch 5292
[2023-07-01 10:26:48] [data] Shuffling data
[2023-07-01 10:26:48] [data] Done reading 20,192 sentences
[2023-07-01 10:26:48] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 10:26:48] Training started
[2023-07-01 10:26:48] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-07-01 10:26:48] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:26:49] Parameter type float32, optimization type float32, casting types false
[2023-07-01 10:27:12] Seen 20,073 samples
[2023-07-01 10:27:12] Starting data epoch 30 in logical epoch 30
[2023-07-01 10:27:12] Training finished
[2023-07-01 10:27:15] [valid] Ep. 30 : Up. 5481 : cross-entropy : 131.565 : new best
[2023-07-01 10:28:50] [valid] Ep. 30 : Up. 5481 : translation : 0 : new best
[2023-07-01 10:28:50] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:28:51] Saving Adam parameters
[2023-07-01 10:28:51] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 10:28:56] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:28:56] [marian] Running on node20.datos.cluster.uy as process 9684 with command line:
[2023-07-01 10:28:56] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 30 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 10:28:56] [config] after: 0e
[2023-07-01 10:28:56] [config] after-batches: 0
[2023-07-01 10:28:56] [config] after-epochs: 30
[2023-07-01 10:28:56] [config] all-caps-every: 0
[2023-07-01 10:28:56] [config] allow-unk: false
[2023-07-01 10:28:56] [config] authors: false
[2023-07-01 10:28:56] [config] beam-size: 12
[2023-07-01 10:28:56] [config] bert-class-symbol: "[CLS]"
[2023-07-01 10:28:56] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 10:28:56] [config] bert-masking-fraction: 0.15
[2023-07-01 10:28:56] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 10:28:56] [config] bert-train-type-embeddings: true
[2023-07-01 10:28:56] [config] bert-type-vocab-size: 2
[2023-07-01 10:28:56] [config] build-info: ""
[2023-07-01 10:28:56] [config] check-gradient-nan: false
[2023-07-01 10:28:56] [config] check-nan: false
[2023-07-01 10:28:56] [config] cite: false
[2023-07-01 10:28:56] [config] clip-norm: 5
[2023-07-01 10:28:56] [config] cost-scaling:
[2023-07-01 10:28:56] [config]   []
[2023-07-01 10:28:56] [config] cost-type: ce-sum
[2023-07-01 10:28:56] [config] cpu-threads: 0
[2023-07-01 10:28:56] [config] data-threads: 8
[2023-07-01 10:28:56] [config] data-weighting: ""
[2023-07-01 10:28:56] [config] data-weighting-type: sentence
[2023-07-01 10:28:56] [config] dec-cell: gru
[2023-07-01 10:28:56] [config] dec-cell-base-depth: 2
[2023-07-01 10:28:56] [config] dec-cell-high-depth: 1
[2023-07-01 10:28:56] [config] dec-depth: 2
[2023-07-01 10:28:56] [config] devices:
[2023-07-01 10:28:56] [config]   - 0
[2023-07-01 10:28:56] [config] dim-emb: 512
[2023-07-01 10:28:56] [config] dim-rnn: 1024
[2023-07-01 10:28:56] [config] dim-vocabs:
[2023-07-01 10:28:56] [config]   - 16384
[2023-07-01 10:28:56] [config]   - 16384
[2023-07-01 10:28:56] [config] disp-first: 0
[2023-07-01 10:28:56] [config] disp-freq: 1000u
[2023-07-01 10:28:56] [config] disp-label-counts: true
[2023-07-01 10:28:56] [config] dropout-rnn: 0
[2023-07-01 10:28:56] [config] dropout-src: 0
[2023-07-01 10:28:56] [config] dropout-trg: 0
[2023-07-01 10:28:56] [config] dump-config: ""
[2023-07-01 10:28:56] [config] dynamic-gradient-scaling:
[2023-07-01 10:28:56] [config]   []
[2023-07-01 10:28:56] [config] early-stopping: 10
[2023-07-01 10:28:56] [config] early-stopping-on: first
[2023-07-01 10:28:56] [config] embedding-fix-src: false
[2023-07-01 10:28:56] [config] embedding-fix-trg: false
[2023-07-01 10:28:56] [config] embedding-normalization: false
[2023-07-01 10:28:56] [config] embedding-vectors:
[2023-07-01 10:28:56] [config]   []
[2023-07-01 10:28:56] [config] enc-cell: gru
[2023-07-01 10:28:56] [config] enc-cell-depth: 1
[2023-07-01 10:28:56] [config] enc-depth: 2
[2023-07-01 10:28:56] [config] enc-type: bidirectional
[2023-07-01 10:28:56] [config] english-title-case-every: 0
[2023-07-01 10:28:56] [config] exponential-smoothing: 0.0001
[2023-07-01 10:28:56] [config] factor-weight: 1
[2023-07-01 10:28:56] [config] factors-combine: sum
[2023-07-01 10:28:56] [config] factors-dim-emb: 0
[2023-07-01 10:28:56] [config] gradient-checkpointing: false
[2023-07-01 10:28:56] [config] gradient-norm-average-window: 100
[2023-07-01 10:28:56] [config] guided-alignment: none
[2023-07-01 10:28:56] [config] guided-alignment-cost: mse
[2023-07-01 10:28:56] [config] guided-alignment-weight: 0.1
[2023-07-01 10:28:56] [config] ignore-model-config: false
[2023-07-01 10:28:56] [config] input-types:
[2023-07-01 10:28:56] [config]   []
[2023-07-01 10:28:56] [config] interpolate-env-vars: false
[2023-07-01 10:28:56] [config] keep-best: false
[2023-07-01 10:28:56] [config] label-smoothing: 0.1
[2023-07-01 10:28:56] [config] layer-normalization: false
[2023-07-01 10:28:56] [config] learn-rate: 0.0003
[2023-07-01 10:28:56] [config] lemma-dependency: ""
[2023-07-01 10:28:56] [config] lemma-dim-emb: 0
[2023-07-01 10:28:56] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 10:28:56] [config] log-level: info
[2023-07-01 10:28:56] [config] log-time-zone: ""
[2023-07-01 10:28:56] [config] logical-epoch:
[2023-07-01 10:28:56] [config]   - 1e
[2023-07-01 10:28:56] [config]   - 0
[2023-07-01 10:28:56] [config] lr-decay: 0
[2023-07-01 10:28:56] [config] lr-decay-freq: 50000
[2023-07-01 10:28:56] [config] lr-decay-inv-sqrt:
[2023-07-01 10:28:56] [config]   - 16000
[2023-07-01 10:28:56] [config] lr-decay-repeat-warmup: false
[2023-07-01 10:28:56] [config] lr-decay-reset-optimizer: false
[2023-07-01 10:28:56] [config] lr-decay-start:
[2023-07-01 10:28:56] [config]   - 10
[2023-07-01 10:28:56] [config]   - 1
[2023-07-01 10:28:56] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 10:28:56] [config] lr-report: true
[2023-07-01 10:28:56] [config] lr-warmup: 16000
[2023-07-01 10:28:56] [config] lr-warmup-at-reload: false
[2023-07-01 10:28:56] [config] lr-warmup-cycle: false
[2023-07-01 10:28:56] [config] lr-warmup-start-rate: 0
[2023-07-01 10:28:56] [config] max-length: 100
[2023-07-01 10:28:56] [config] max-length-crop: false
[2023-07-01 10:28:56] [config] max-length-factor: 3
[2023-07-01 10:28:56] [config] maxi-batch: 100
[2023-07-01 10:28:56] [config] maxi-batch-sort: trg
[2023-07-01 10:28:56] [config] mini-batch: 1000
[2023-07-01 10:28:56] [config] mini-batch-fit: true
[2023-07-01 10:28:56] [config] mini-batch-fit-step: 10
[2023-07-01 10:28:56] [config] mini-batch-round-up: true
[2023-07-01 10:28:56] [config] mini-batch-track-lr: false
[2023-07-01 10:28:56] [config] mini-batch-warmup: 0
[2023-07-01 10:28:56] [config] mini-batch-words: 0
[2023-07-01 10:28:56] [config] mini-batch-words-ref: 0
[2023-07-01 10:28:56] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:28:56] [config] multi-loss-type: sum
[2023-07-01 10:28:56] [config] n-best: false
[2023-07-01 10:28:56] [config] no-nccl: false
[2023-07-01 10:28:56] [config] no-reload: false
[2023-07-01 10:28:56] [config] no-restore-corpus: false
[2023-07-01 10:28:56] [config] normalize: 1
[2023-07-01 10:28:56] [config] normalize-gradient: false
[2023-07-01 10:28:56] [config] num-devices: 0
[2023-07-01 10:28:56] [config] optimizer: adam
[2023-07-01 10:28:56] [config] optimizer-delay: 1
[2023-07-01 10:28:56] [config] optimizer-params:
[2023-07-01 10:28:56] [config]   - 0.9
[2023-07-01 10:28:56] [config]   - 0.98
[2023-07-01 10:28:56] [config]   - 1e-09
[2023-07-01 10:28:56] [config] output-omit-bias: false
[2023-07-01 10:28:56] [config] overwrite: true
[2023-07-01 10:28:56] [config] precision:
[2023-07-01 10:28:56] [config]   - float32
[2023-07-01 10:28:56] [config]   - float32
[2023-07-01 10:28:56] [config] pretrained-model: ""
[2023-07-01 10:28:56] [config] quantize-biases: false
[2023-07-01 10:28:56] [config] quantize-bits: 0
[2023-07-01 10:28:56] [config] quantize-log-based: false
[2023-07-01 10:28:56] [config] quantize-optimization-steps: 0
[2023-07-01 10:28:56] [config] quiet: false
[2023-07-01 10:28:56] [config] quiet-translation: true
[2023-07-01 10:28:56] [config] relative-paths: false
[2023-07-01 10:28:56] [config] right-left: false
[2023-07-01 10:28:56] [config] save-freq: 10000u
[2023-07-01 10:28:56] [config] seed: 1234
[2023-07-01 10:28:56] [config] sentencepiece-alphas:
[2023-07-01 10:28:56] [config]   []
[2023-07-01 10:28:56] [config] sentencepiece-max-lines: 2000000
[2023-07-01 10:28:56] [config] sentencepiece-options: ""
[2023-07-01 10:28:56] [config] sharding: global
[2023-07-01 10:28:56] [config] shuffle: data
[2023-07-01 10:28:56] [config] shuffle-in-ram: false
[2023-07-01 10:28:56] [config] sigterm: save-and-exit
[2023-07-01 10:28:56] [config] skip: false
[2023-07-01 10:28:56] [config] sqlite: ""
[2023-07-01 10:28:56] [config] sqlite-drop: false
[2023-07-01 10:28:56] [config] sync-freq: 200u
[2023-07-01 10:28:56] [config] sync-sgd: true
[2023-07-01 10:28:56] [config] tempdir: /tmp
[2023-07-01 10:28:56] [config] tied-embeddings: false
[2023-07-01 10:28:56] [config] tied-embeddings-all: true
[2023-07-01 10:28:56] [config] tied-embeddings-src: false
[2023-07-01 10:28:56] [config] train-embedder-rank:
[2023-07-01 10:28:56] [config]   []
[2023-07-01 10:28:56] [config] train-sets:
[2023-07-01 10:28:56] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 10:28:56] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 10:28:56] [config] transformer-aan-activation: swish
[2023-07-01 10:28:56] [config] transformer-aan-depth: 2
[2023-07-01 10:28:56] [config] transformer-aan-nogate: false
[2023-07-01 10:28:56] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 10:28:56] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 10:28:56] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 10:28:56] [config] transformer-depth-scaling: false
[2023-07-01 10:28:56] [config] transformer-dim-aan: 2048
[2023-07-01 10:28:56] [config] transformer-dim-ffn: 2048
[2023-07-01 10:28:56] [config] transformer-dropout: 0.1
[2023-07-01 10:28:56] [config] transformer-dropout-attention: 0
[2023-07-01 10:28:56] [config] transformer-dropout-ffn: 0
[2023-07-01 10:28:56] [config] transformer-ffn-activation: swish
[2023-07-01 10:28:56] [config] transformer-ffn-depth: 2
[2023-07-01 10:28:56] [config] transformer-guided-alignment-layer: last
[2023-07-01 10:28:56] [config] transformer-heads: 8
[2023-07-01 10:28:56] [config] transformer-no-projection: false
[2023-07-01 10:28:56] [config] transformer-pool: false
[2023-07-01 10:28:56] [config] transformer-postprocess: dan
[2023-07-01 10:28:56] [config] transformer-postprocess-emb: d
[2023-07-01 10:28:56] [config] transformer-postprocess-top: ""
[2023-07-01 10:28:56] [config] transformer-preprocess: ""
[2023-07-01 10:28:56] [config] transformer-tied-layers:
[2023-07-01 10:28:56] [config]   []
[2023-07-01 10:28:56] [config] transformer-train-position-embeddings: false
[2023-07-01 10:28:56] [config] tsv: false
[2023-07-01 10:28:56] [config] tsv-fields: 0
[2023-07-01 10:28:56] [config] type: transformer
[2023-07-01 10:28:56] [config] ulr: false
[2023-07-01 10:28:56] [config] ulr-dim-emb: 0
[2023-07-01 10:28:56] [config] ulr-dropout: 0
[2023-07-01 10:28:56] [config] ulr-keys-vectors: ""
[2023-07-01 10:28:56] [config] ulr-query-vectors: ""
[2023-07-01 10:28:56] [config] ulr-softmax-temperature: 1
[2023-07-01 10:28:56] [config] ulr-trainable-transformation: false
[2023-07-01 10:28:56] [config] unlikelihood-loss: false
[2023-07-01 10:28:56] [config] valid-freq: 50000000
[2023-07-01 10:28:56] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 10:28:56] [config] valid-max-length: 1000
[2023-07-01 10:28:56] [config] valid-metrics:
[2023-07-01 10:28:56] [config]   - cross-entropy
[2023-07-01 10:28:56] [config]   - translation
[2023-07-01 10:28:56] [config] valid-mini-batch: 64
[2023-07-01 10:28:56] [config] valid-reset-stalled: false
[2023-07-01 10:28:56] [config] valid-script-args:
[2023-07-01 10:28:56] [config]   []
[2023-07-01 10:28:56] [config] valid-script-path: ""
[2023-07-01 10:28:56] [config] valid-sets:
[2023-07-01 10:28:56] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 10:28:56] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 10:28:56] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 10:28:56] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:28:56] [config] vocabs:
[2023-07-01 10:28:56] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 10:28:56] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 10:28:56] [config] word-penalty: 0
[2023-07-01 10:28:56] [config] word-scores: false
[2023-07-01 10:28:56] [config] workspace: 2048
[2023-07-01 10:28:56] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:28:56] Using synchronous SGD
[2023-07-01 10:28:57] Synced seed 1234
[2023-07-01 10:28:57] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 10:28:57] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 10:28:57] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 10:28:57] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 10:28:57] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 10:28:57] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 10:28:58] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 10:28:58] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 10:28:58] [comm] Using global sharding
[2023-07-01 10:28:58] [comm] NCCLCommunicators constructed successfully
[2023-07-01 10:28:58] [training] Using 1 GPUs
[2023-07-01 10:28:58] [logits] Applying loss function for 1 factor(s)
[2023-07-01 10:28:58] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:28:58] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 10:28:58] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:29:06] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 10:29:06] [valid] No post-processing script given for validating translator
[2023-07-01 10:29:06] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 10:29:06] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 10:29:06] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 10:29:06] [comm] Using global sharding
[2023-07-01 10:29:06] [comm] NCCLCommunicators constructed successfully
[2023-07-01 10:29:06] [training] Using 1 GPUs
[2023-07-01 10:29:06] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:29:07] Allocating memory for general optimizer shards
[2023-07-01 10:29:07] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:29:07] Loading Adam parameters
[2023-07-01 10:29:07] [memory] Reserving 176 MB, device gpu0
[2023-07-01 10:29:07] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:29:07] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 10:29:07] [data] Restoring the corpus state to epoch 30, batch 5481
[2023-07-01 10:29:07] [data] Shuffling data
[2023-07-01 10:29:07] [data] Done reading 20,192 sentences
[2023-07-01 10:29:07] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 10:29:07] Training started
[2023-07-01 10:29:07] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-07-01 10:29:07] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:29:07] Parameter type float32, optimization type float32, casting types false
[2023-07-01 10:29:31] Seen 20,073 samples
[2023-07-01 10:29:31] Starting data epoch 31 in logical epoch 31
[2023-07-01 10:29:31] Training finished
[2023-07-01 10:29:34] [valid] Ep. 31 : Up. 5670 : cross-entropy : 130.404 : new best
[2023-07-01 10:31:14] [valid] Ep. 31 : Up. 5670 : translation : 0 : new best
[2023-07-01 10:31:14] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:31:15] Saving Adam parameters
[2023-07-01 10:31:16] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 10:31:22] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:31:22] [marian] Running on node20.datos.cluster.uy as process 9886 with command line:
[2023-07-01 10:31:22] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 31 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 10:31:22] [config] after: 0e
[2023-07-01 10:31:22] [config] after-batches: 0
[2023-07-01 10:31:22] [config] after-epochs: 31
[2023-07-01 10:31:22] [config] all-caps-every: 0
[2023-07-01 10:31:22] [config] allow-unk: false
[2023-07-01 10:31:22] [config] authors: false
[2023-07-01 10:31:22] [config] beam-size: 12
[2023-07-01 10:31:22] [config] bert-class-symbol: "[CLS]"
[2023-07-01 10:31:22] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 10:31:22] [config] bert-masking-fraction: 0.15
[2023-07-01 10:31:22] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 10:31:22] [config] bert-train-type-embeddings: true
[2023-07-01 10:31:22] [config] bert-type-vocab-size: 2
[2023-07-01 10:31:22] [config] build-info: ""
[2023-07-01 10:31:22] [config] check-gradient-nan: false
[2023-07-01 10:31:22] [config] check-nan: false
[2023-07-01 10:31:22] [config] cite: false
[2023-07-01 10:31:22] [config] clip-norm: 5
[2023-07-01 10:31:22] [config] cost-scaling:
[2023-07-01 10:31:22] [config]   []
[2023-07-01 10:31:22] [config] cost-type: ce-sum
[2023-07-01 10:31:22] [config] cpu-threads: 0
[2023-07-01 10:31:22] [config] data-threads: 8
[2023-07-01 10:31:22] [config] data-weighting: ""
[2023-07-01 10:31:22] [config] data-weighting-type: sentence
[2023-07-01 10:31:22] [config] dec-cell: gru
[2023-07-01 10:31:22] [config] dec-cell-base-depth: 2
[2023-07-01 10:31:22] [config] dec-cell-high-depth: 1
[2023-07-01 10:31:22] [config] dec-depth: 2
[2023-07-01 10:31:22] [config] devices:
[2023-07-01 10:31:22] [config]   - 0
[2023-07-01 10:31:22] [config] dim-emb: 512
[2023-07-01 10:31:22] [config] dim-rnn: 1024
[2023-07-01 10:31:22] [config] dim-vocabs:
[2023-07-01 10:31:22] [config]   - 16384
[2023-07-01 10:31:22] [config]   - 16384
[2023-07-01 10:31:22] [config] disp-first: 0
[2023-07-01 10:31:22] [config] disp-freq: 1000u
[2023-07-01 10:31:22] [config] disp-label-counts: true
[2023-07-01 10:31:22] [config] dropout-rnn: 0
[2023-07-01 10:31:22] [config] dropout-src: 0
[2023-07-01 10:31:22] [config] dropout-trg: 0
[2023-07-01 10:31:22] [config] dump-config: ""
[2023-07-01 10:31:22] [config] dynamic-gradient-scaling:
[2023-07-01 10:31:22] [config]   []
[2023-07-01 10:31:22] [config] early-stopping: 10
[2023-07-01 10:31:22] [config] early-stopping-on: first
[2023-07-01 10:31:22] [config] embedding-fix-src: false
[2023-07-01 10:31:22] [config] embedding-fix-trg: false
[2023-07-01 10:31:22] [config] embedding-normalization: false
[2023-07-01 10:31:22] [config] embedding-vectors:
[2023-07-01 10:31:22] [config]   []
[2023-07-01 10:31:22] [config] enc-cell: gru
[2023-07-01 10:31:22] [config] enc-cell-depth: 1
[2023-07-01 10:31:22] [config] enc-depth: 2
[2023-07-01 10:31:22] [config] enc-type: bidirectional
[2023-07-01 10:31:22] [config] english-title-case-every: 0
[2023-07-01 10:31:22] [config] exponential-smoothing: 0.0001
[2023-07-01 10:31:22] [config] factor-weight: 1
[2023-07-01 10:31:22] [config] factors-combine: sum
[2023-07-01 10:31:22] [config] factors-dim-emb: 0
[2023-07-01 10:31:22] [config] gradient-checkpointing: false
[2023-07-01 10:31:22] [config] gradient-norm-average-window: 100
[2023-07-01 10:31:22] [config] guided-alignment: none
[2023-07-01 10:31:22] [config] guided-alignment-cost: mse
[2023-07-01 10:31:22] [config] guided-alignment-weight: 0.1
[2023-07-01 10:31:22] [config] ignore-model-config: false
[2023-07-01 10:31:22] [config] input-types:
[2023-07-01 10:31:22] [config]   []
[2023-07-01 10:31:22] [config] interpolate-env-vars: false
[2023-07-01 10:31:22] [config] keep-best: false
[2023-07-01 10:31:22] [config] label-smoothing: 0.1
[2023-07-01 10:31:22] [config] layer-normalization: false
[2023-07-01 10:31:22] [config] learn-rate: 0.0003
[2023-07-01 10:31:22] [config] lemma-dependency: ""
[2023-07-01 10:31:22] [config] lemma-dim-emb: 0
[2023-07-01 10:31:22] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 10:31:22] [config] log-level: info
[2023-07-01 10:31:22] [config] log-time-zone: ""
[2023-07-01 10:31:22] [config] logical-epoch:
[2023-07-01 10:31:22] [config]   - 1e
[2023-07-01 10:31:22] [config]   - 0
[2023-07-01 10:31:22] [config] lr-decay: 0
[2023-07-01 10:31:22] [config] lr-decay-freq: 50000
[2023-07-01 10:31:22] [config] lr-decay-inv-sqrt:
[2023-07-01 10:31:22] [config]   - 16000
[2023-07-01 10:31:22] [config] lr-decay-repeat-warmup: false
[2023-07-01 10:31:22] [config] lr-decay-reset-optimizer: false
[2023-07-01 10:31:22] [config] lr-decay-start:
[2023-07-01 10:31:22] [config]   - 10
[2023-07-01 10:31:22] [config]   - 1
[2023-07-01 10:31:22] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 10:31:22] [config] lr-report: true
[2023-07-01 10:31:22] [config] lr-warmup: 16000
[2023-07-01 10:31:22] [config] lr-warmup-at-reload: false
[2023-07-01 10:31:22] [config] lr-warmup-cycle: false
[2023-07-01 10:31:22] [config] lr-warmup-start-rate: 0
[2023-07-01 10:31:22] [config] max-length: 100
[2023-07-01 10:31:22] [config] max-length-crop: false
[2023-07-01 10:31:22] [config] max-length-factor: 3
[2023-07-01 10:31:22] [config] maxi-batch: 100
[2023-07-01 10:31:22] [config] maxi-batch-sort: trg
[2023-07-01 10:31:22] [config] mini-batch: 1000
[2023-07-01 10:31:22] [config] mini-batch-fit: true
[2023-07-01 10:31:22] [config] mini-batch-fit-step: 10
[2023-07-01 10:31:22] [config] mini-batch-round-up: true
[2023-07-01 10:31:22] [config] mini-batch-track-lr: false
[2023-07-01 10:31:22] [config] mini-batch-warmup: 0
[2023-07-01 10:31:22] [config] mini-batch-words: 0
[2023-07-01 10:31:22] [config] mini-batch-words-ref: 0
[2023-07-01 10:31:22] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:31:22] [config] multi-loss-type: sum
[2023-07-01 10:31:22] [config] n-best: false
[2023-07-01 10:31:22] [config] no-nccl: false
[2023-07-01 10:31:22] [config] no-reload: false
[2023-07-01 10:31:22] [config] no-restore-corpus: false
[2023-07-01 10:31:22] [config] normalize: 1
[2023-07-01 10:31:22] [config] normalize-gradient: false
[2023-07-01 10:31:22] [config] num-devices: 0
[2023-07-01 10:31:22] [config] optimizer: adam
[2023-07-01 10:31:22] [config] optimizer-delay: 1
[2023-07-01 10:31:22] [config] optimizer-params:
[2023-07-01 10:31:22] [config]   - 0.9
[2023-07-01 10:31:22] [config]   - 0.98
[2023-07-01 10:31:22] [config]   - 1e-09
[2023-07-01 10:31:22] [config] output-omit-bias: false
[2023-07-01 10:31:22] [config] overwrite: true
[2023-07-01 10:31:22] [config] precision:
[2023-07-01 10:31:22] [config]   - float32
[2023-07-01 10:31:22] [config]   - float32
[2023-07-01 10:31:22] [config] pretrained-model: ""
[2023-07-01 10:31:22] [config] quantize-biases: false
[2023-07-01 10:31:22] [config] quantize-bits: 0
[2023-07-01 10:31:22] [config] quantize-log-based: false
[2023-07-01 10:31:22] [config] quantize-optimization-steps: 0
[2023-07-01 10:31:22] [config] quiet: false
[2023-07-01 10:31:22] [config] quiet-translation: true
[2023-07-01 10:31:22] [config] relative-paths: false
[2023-07-01 10:31:22] [config] right-left: false
[2023-07-01 10:31:22] [config] save-freq: 10000u
[2023-07-01 10:31:22] [config] seed: 1234
[2023-07-01 10:31:22] [config] sentencepiece-alphas:
[2023-07-01 10:31:22] [config]   []
[2023-07-01 10:31:22] [config] sentencepiece-max-lines: 2000000
[2023-07-01 10:31:22] [config] sentencepiece-options: ""
[2023-07-01 10:31:22] [config] sharding: global
[2023-07-01 10:31:22] [config] shuffle: data
[2023-07-01 10:31:22] [config] shuffle-in-ram: false
[2023-07-01 10:31:22] [config] sigterm: save-and-exit
[2023-07-01 10:31:22] [config] skip: false
[2023-07-01 10:31:22] [config] sqlite: ""
[2023-07-01 10:31:22] [config] sqlite-drop: false
[2023-07-01 10:31:22] [config] sync-freq: 200u
[2023-07-01 10:31:22] [config] sync-sgd: true
[2023-07-01 10:31:22] [config] tempdir: /tmp
[2023-07-01 10:31:22] [config] tied-embeddings: false
[2023-07-01 10:31:22] [config] tied-embeddings-all: true
[2023-07-01 10:31:22] [config] tied-embeddings-src: false
[2023-07-01 10:31:22] [config] train-embedder-rank:
[2023-07-01 10:31:22] [config]   []
[2023-07-01 10:31:22] [config] train-sets:
[2023-07-01 10:31:22] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 10:31:22] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 10:31:22] [config] transformer-aan-activation: swish
[2023-07-01 10:31:22] [config] transformer-aan-depth: 2
[2023-07-01 10:31:22] [config] transformer-aan-nogate: false
[2023-07-01 10:31:22] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 10:31:22] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 10:31:22] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 10:31:22] [config] transformer-depth-scaling: false
[2023-07-01 10:31:22] [config] transformer-dim-aan: 2048
[2023-07-01 10:31:22] [config] transformer-dim-ffn: 2048
[2023-07-01 10:31:22] [config] transformer-dropout: 0.1
[2023-07-01 10:31:22] [config] transformer-dropout-attention: 0
[2023-07-01 10:31:22] [config] transformer-dropout-ffn: 0
[2023-07-01 10:31:22] [config] transformer-ffn-activation: swish
[2023-07-01 10:31:22] [config] transformer-ffn-depth: 2
[2023-07-01 10:31:22] [config] transformer-guided-alignment-layer: last
[2023-07-01 10:31:22] [config] transformer-heads: 8
[2023-07-01 10:31:22] [config] transformer-no-projection: false
[2023-07-01 10:31:22] [config] transformer-pool: false
[2023-07-01 10:31:22] [config] transformer-postprocess: dan
[2023-07-01 10:31:22] [config] transformer-postprocess-emb: d
[2023-07-01 10:31:22] [config] transformer-postprocess-top: ""
[2023-07-01 10:31:22] [config] transformer-preprocess: ""
[2023-07-01 10:31:22] [config] transformer-tied-layers:
[2023-07-01 10:31:22] [config]   []
[2023-07-01 10:31:22] [config] transformer-train-position-embeddings: false
[2023-07-01 10:31:22] [config] tsv: false
[2023-07-01 10:31:22] [config] tsv-fields: 0
[2023-07-01 10:31:22] [config] type: transformer
[2023-07-01 10:31:22] [config] ulr: false
[2023-07-01 10:31:22] [config] ulr-dim-emb: 0
[2023-07-01 10:31:22] [config] ulr-dropout: 0
[2023-07-01 10:31:22] [config] ulr-keys-vectors: ""
[2023-07-01 10:31:22] [config] ulr-query-vectors: ""
[2023-07-01 10:31:22] [config] ulr-softmax-temperature: 1
[2023-07-01 10:31:22] [config] ulr-trainable-transformation: false
[2023-07-01 10:31:22] [config] unlikelihood-loss: false
[2023-07-01 10:31:22] [config] valid-freq: 50000000
[2023-07-01 10:31:22] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 10:31:22] [config] valid-max-length: 1000
[2023-07-01 10:31:22] [config] valid-metrics:
[2023-07-01 10:31:22] [config]   - cross-entropy
[2023-07-01 10:31:22] [config]   - translation
[2023-07-01 10:31:22] [config] valid-mini-batch: 64
[2023-07-01 10:31:22] [config] valid-reset-stalled: false
[2023-07-01 10:31:22] [config] valid-script-args:
[2023-07-01 10:31:22] [config]   []
[2023-07-01 10:31:22] [config] valid-script-path: ""
[2023-07-01 10:31:22] [config] valid-sets:
[2023-07-01 10:31:22] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 10:31:22] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 10:31:22] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 10:31:22] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:31:22] [config] vocabs:
[2023-07-01 10:31:22] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 10:31:22] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 10:31:22] [config] word-penalty: 0
[2023-07-01 10:31:22] [config] word-scores: false
[2023-07-01 10:31:22] [config] workspace: 2048
[2023-07-01 10:31:22] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:31:22] Using synchronous SGD
[2023-07-01 10:31:22] Synced seed 1234
[2023-07-01 10:31:22] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 10:31:22] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 10:31:22] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 10:31:22] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 10:31:22] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 10:31:22] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 10:31:23] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 10:31:23] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 10:31:23] [comm] Using global sharding
[2023-07-01 10:31:23] [comm] NCCLCommunicators constructed successfully
[2023-07-01 10:31:23] [training] Using 1 GPUs
[2023-07-01 10:31:23] [logits] Applying loss function for 1 factor(s)
[2023-07-01 10:31:23] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:31:23] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 10:31:23] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:31:31] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 10:31:31] [valid] No post-processing script given for validating translator
[2023-07-01 10:31:31] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 10:31:31] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 10:31:31] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 10:31:31] [comm] Using global sharding
[2023-07-01 10:31:31] [comm] NCCLCommunicators constructed successfully
[2023-07-01 10:31:31] [training] Using 1 GPUs
[2023-07-01 10:31:31] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:31:32] Allocating memory for general optimizer shards
[2023-07-01 10:31:32] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:31:32] Loading Adam parameters
[2023-07-01 10:31:32] [memory] Reserving 176 MB, device gpu0
[2023-07-01 10:31:32] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:31:32] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 10:31:32] [data] Restoring the corpus state to epoch 31, batch 5670
[2023-07-01 10:31:32] [data] Shuffling data
[2023-07-01 10:31:32] [data] Done reading 20,192 sentences
[2023-07-01 10:31:32] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 10:31:32] Training started
[2023-07-01 10:31:33] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-07-01 10:31:33] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:31:33] Parameter type float32, optimization type float32, casting types false
[2023-07-01 10:31:57] Seen 20,073 samples
[2023-07-01 10:31:57] Starting data epoch 32 in logical epoch 32
[2023-07-01 10:31:57] Training finished
[2023-07-01 10:32:00] [valid] Ep. 32 : Up. 5859 : cross-entropy : 129.353 : new best
[2023-07-01 10:33:35] [valid] Ep. 32 : Up. 5859 : translation : 0 : new best
[2023-07-01 10:33:35] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:33:36] Saving Adam parameters
[2023-07-01 10:33:37] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 10:33:44] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:33:44] [marian] Running on node20.datos.cluster.uy as process 10059 with command line:
[2023-07-01 10:33:44] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 32 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 10:33:44] [config] after: 0e
[2023-07-01 10:33:44] [config] after-batches: 0
[2023-07-01 10:33:44] [config] after-epochs: 32
[2023-07-01 10:33:44] [config] all-caps-every: 0
[2023-07-01 10:33:44] [config] allow-unk: false
[2023-07-01 10:33:44] [config] authors: false
[2023-07-01 10:33:44] [config] beam-size: 12
[2023-07-01 10:33:44] [config] bert-class-symbol: "[CLS]"
[2023-07-01 10:33:44] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 10:33:44] [config] bert-masking-fraction: 0.15
[2023-07-01 10:33:44] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 10:33:44] [config] bert-train-type-embeddings: true
[2023-07-01 10:33:44] [config] bert-type-vocab-size: 2
[2023-07-01 10:33:44] [config] build-info: ""
[2023-07-01 10:33:44] [config] check-gradient-nan: false
[2023-07-01 10:33:44] [config] check-nan: false
[2023-07-01 10:33:44] [config] cite: false
[2023-07-01 10:33:44] [config] clip-norm: 5
[2023-07-01 10:33:44] [config] cost-scaling:
[2023-07-01 10:33:44] [config]   []
[2023-07-01 10:33:44] [config] cost-type: ce-sum
[2023-07-01 10:33:44] [config] cpu-threads: 0
[2023-07-01 10:33:44] [config] data-threads: 8
[2023-07-01 10:33:44] [config] data-weighting: ""
[2023-07-01 10:33:44] [config] data-weighting-type: sentence
[2023-07-01 10:33:44] [config] dec-cell: gru
[2023-07-01 10:33:44] [config] dec-cell-base-depth: 2
[2023-07-01 10:33:44] [config] dec-cell-high-depth: 1
[2023-07-01 10:33:44] [config] dec-depth: 2
[2023-07-01 10:33:44] [config] devices:
[2023-07-01 10:33:44] [config]   - 0
[2023-07-01 10:33:44] [config] dim-emb: 512
[2023-07-01 10:33:44] [config] dim-rnn: 1024
[2023-07-01 10:33:44] [config] dim-vocabs:
[2023-07-01 10:33:44] [config]   - 16384
[2023-07-01 10:33:44] [config]   - 16384
[2023-07-01 10:33:44] [config] disp-first: 0
[2023-07-01 10:33:44] [config] disp-freq: 1000u
[2023-07-01 10:33:44] [config] disp-label-counts: true
[2023-07-01 10:33:44] [config] dropout-rnn: 0
[2023-07-01 10:33:44] [config] dropout-src: 0
[2023-07-01 10:33:44] [config] dropout-trg: 0
[2023-07-01 10:33:44] [config] dump-config: ""
[2023-07-01 10:33:44] [config] dynamic-gradient-scaling:
[2023-07-01 10:33:44] [config]   []
[2023-07-01 10:33:44] [config] early-stopping: 10
[2023-07-01 10:33:44] [config] early-stopping-on: first
[2023-07-01 10:33:44] [config] embedding-fix-src: false
[2023-07-01 10:33:44] [config] embedding-fix-trg: false
[2023-07-01 10:33:44] [config] embedding-normalization: false
[2023-07-01 10:33:44] [config] embedding-vectors:
[2023-07-01 10:33:44] [config]   []
[2023-07-01 10:33:44] [config] enc-cell: gru
[2023-07-01 10:33:44] [config] enc-cell-depth: 1
[2023-07-01 10:33:44] [config] enc-depth: 2
[2023-07-01 10:33:44] [config] enc-type: bidirectional
[2023-07-01 10:33:44] [config] english-title-case-every: 0
[2023-07-01 10:33:44] [config] exponential-smoothing: 0.0001
[2023-07-01 10:33:44] [config] factor-weight: 1
[2023-07-01 10:33:44] [config] factors-combine: sum
[2023-07-01 10:33:44] [config] factors-dim-emb: 0
[2023-07-01 10:33:44] [config] gradient-checkpointing: false
[2023-07-01 10:33:44] [config] gradient-norm-average-window: 100
[2023-07-01 10:33:44] [config] guided-alignment: none
[2023-07-01 10:33:44] [config] guided-alignment-cost: mse
[2023-07-01 10:33:44] [config] guided-alignment-weight: 0.1
[2023-07-01 10:33:44] [config] ignore-model-config: false
[2023-07-01 10:33:44] [config] input-types:
[2023-07-01 10:33:44] [config]   []
[2023-07-01 10:33:44] [config] interpolate-env-vars: false
[2023-07-01 10:33:44] [config] keep-best: false
[2023-07-01 10:33:44] [config] label-smoothing: 0.1
[2023-07-01 10:33:44] [config] layer-normalization: false
[2023-07-01 10:33:44] [config] learn-rate: 0.0003
[2023-07-01 10:33:44] [config] lemma-dependency: ""
[2023-07-01 10:33:44] [config] lemma-dim-emb: 0
[2023-07-01 10:33:44] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 10:33:44] [config] log-level: info
[2023-07-01 10:33:44] [config] log-time-zone: ""
[2023-07-01 10:33:44] [config] logical-epoch:
[2023-07-01 10:33:44] [config]   - 1e
[2023-07-01 10:33:44] [config]   - 0
[2023-07-01 10:33:44] [config] lr-decay: 0
[2023-07-01 10:33:44] [config] lr-decay-freq: 50000
[2023-07-01 10:33:44] [config] lr-decay-inv-sqrt:
[2023-07-01 10:33:44] [config]   - 16000
[2023-07-01 10:33:44] [config] lr-decay-repeat-warmup: false
[2023-07-01 10:33:44] [config] lr-decay-reset-optimizer: false
[2023-07-01 10:33:44] [config] lr-decay-start:
[2023-07-01 10:33:44] [config]   - 10
[2023-07-01 10:33:44] [config]   - 1
[2023-07-01 10:33:44] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 10:33:44] [config] lr-report: true
[2023-07-01 10:33:44] [config] lr-warmup: 16000
[2023-07-01 10:33:44] [config] lr-warmup-at-reload: false
[2023-07-01 10:33:44] [config] lr-warmup-cycle: false
[2023-07-01 10:33:44] [config] lr-warmup-start-rate: 0
[2023-07-01 10:33:44] [config] max-length: 100
[2023-07-01 10:33:44] [config] max-length-crop: false
[2023-07-01 10:33:44] [config] max-length-factor: 3
[2023-07-01 10:33:44] [config] maxi-batch: 100
[2023-07-01 10:33:44] [config] maxi-batch-sort: trg
[2023-07-01 10:33:44] [config] mini-batch: 1000
[2023-07-01 10:33:44] [config] mini-batch-fit: true
[2023-07-01 10:33:44] [config] mini-batch-fit-step: 10
[2023-07-01 10:33:44] [config] mini-batch-round-up: true
[2023-07-01 10:33:44] [config] mini-batch-track-lr: false
[2023-07-01 10:33:44] [config] mini-batch-warmup: 0
[2023-07-01 10:33:44] [config] mini-batch-words: 0
[2023-07-01 10:33:44] [config] mini-batch-words-ref: 0
[2023-07-01 10:33:44] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:33:44] [config] multi-loss-type: sum
[2023-07-01 10:33:44] [config] n-best: false
[2023-07-01 10:33:44] [config] no-nccl: false
[2023-07-01 10:33:44] [config] no-reload: false
[2023-07-01 10:33:44] [config] no-restore-corpus: false
[2023-07-01 10:33:44] [config] normalize: 1
[2023-07-01 10:33:44] [config] normalize-gradient: false
[2023-07-01 10:33:44] [config] num-devices: 0
[2023-07-01 10:33:44] [config] optimizer: adam
[2023-07-01 10:33:44] [config] optimizer-delay: 1
[2023-07-01 10:33:44] [config] optimizer-params:
[2023-07-01 10:33:44] [config]   - 0.9
[2023-07-01 10:33:44] [config]   - 0.98
[2023-07-01 10:33:44] [config]   - 1e-09
[2023-07-01 10:33:44] [config] output-omit-bias: false
[2023-07-01 10:33:44] [config] overwrite: true
[2023-07-01 10:33:44] [config] precision:
[2023-07-01 10:33:44] [config]   - float32
[2023-07-01 10:33:44] [config]   - float32
[2023-07-01 10:33:44] [config] pretrained-model: ""
[2023-07-01 10:33:44] [config] quantize-biases: false
[2023-07-01 10:33:44] [config] quantize-bits: 0
[2023-07-01 10:33:44] [config] quantize-log-based: false
[2023-07-01 10:33:44] [config] quantize-optimization-steps: 0
[2023-07-01 10:33:44] [config] quiet: false
[2023-07-01 10:33:44] [config] quiet-translation: true
[2023-07-01 10:33:44] [config] relative-paths: false
[2023-07-01 10:33:44] [config] right-left: false
[2023-07-01 10:33:44] [config] save-freq: 10000u
[2023-07-01 10:33:44] [config] seed: 1234
[2023-07-01 10:33:44] [config] sentencepiece-alphas:
[2023-07-01 10:33:44] [config]   []
[2023-07-01 10:33:44] [config] sentencepiece-max-lines: 2000000
[2023-07-01 10:33:44] [config] sentencepiece-options: ""
[2023-07-01 10:33:44] [config] sharding: global
[2023-07-01 10:33:44] [config] shuffle: data
[2023-07-01 10:33:44] [config] shuffle-in-ram: false
[2023-07-01 10:33:44] [config] sigterm: save-and-exit
[2023-07-01 10:33:44] [config] skip: false
[2023-07-01 10:33:44] [config] sqlite: ""
[2023-07-01 10:33:44] [config] sqlite-drop: false
[2023-07-01 10:33:44] [config] sync-freq: 200u
[2023-07-01 10:33:44] [config] sync-sgd: true
[2023-07-01 10:33:44] [config] tempdir: /tmp
[2023-07-01 10:33:44] [config] tied-embeddings: false
[2023-07-01 10:33:44] [config] tied-embeddings-all: true
[2023-07-01 10:33:44] [config] tied-embeddings-src: false
[2023-07-01 10:33:44] [config] train-embedder-rank:
[2023-07-01 10:33:44] [config]   []
[2023-07-01 10:33:44] [config] train-sets:
[2023-07-01 10:33:44] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 10:33:44] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 10:33:44] [config] transformer-aan-activation: swish
[2023-07-01 10:33:44] [config] transformer-aan-depth: 2
[2023-07-01 10:33:44] [config] transformer-aan-nogate: false
[2023-07-01 10:33:44] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 10:33:44] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 10:33:44] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 10:33:44] [config] transformer-depth-scaling: false
[2023-07-01 10:33:44] [config] transformer-dim-aan: 2048
[2023-07-01 10:33:44] [config] transformer-dim-ffn: 2048
[2023-07-01 10:33:44] [config] transformer-dropout: 0.1
[2023-07-01 10:33:44] [config] transformer-dropout-attention: 0
[2023-07-01 10:33:44] [config] transformer-dropout-ffn: 0
[2023-07-01 10:33:44] [config] transformer-ffn-activation: swish
[2023-07-01 10:33:44] [config] transformer-ffn-depth: 2
[2023-07-01 10:33:44] [config] transformer-guided-alignment-layer: last
[2023-07-01 10:33:44] [config] transformer-heads: 8
[2023-07-01 10:33:44] [config] transformer-no-projection: false
[2023-07-01 10:33:44] [config] transformer-pool: false
[2023-07-01 10:33:44] [config] transformer-postprocess: dan
[2023-07-01 10:33:44] [config] transformer-postprocess-emb: d
[2023-07-01 10:33:44] [config] transformer-postprocess-top: ""
[2023-07-01 10:33:44] [config] transformer-preprocess: ""
[2023-07-01 10:33:44] [config] transformer-tied-layers:
[2023-07-01 10:33:44] [config]   []
[2023-07-01 10:33:44] [config] transformer-train-position-embeddings: false
[2023-07-01 10:33:44] [config] tsv: false
[2023-07-01 10:33:44] [config] tsv-fields: 0
[2023-07-01 10:33:44] [config] type: transformer
[2023-07-01 10:33:44] [config] ulr: false
[2023-07-01 10:33:44] [config] ulr-dim-emb: 0
[2023-07-01 10:33:44] [config] ulr-dropout: 0
[2023-07-01 10:33:44] [config] ulr-keys-vectors: ""
[2023-07-01 10:33:44] [config] ulr-query-vectors: ""
[2023-07-01 10:33:44] [config] ulr-softmax-temperature: 1
[2023-07-01 10:33:44] [config] ulr-trainable-transformation: false
[2023-07-01 10:33:44] [config] unlikelihood-loss: false
[2023-07-01 10:33:44] [config] valid-freq: 50000000
[2023-07-01 10:33:44] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 10:33:44] [config] valid-max-length: 1000
[2023-07-01 10:33:44] [config] valid-metrics:
[2023-07-01 10:33:44] [config]   - cross-entropy
[2023-07-01 10:33:44] [config]   - translation
[2023-07-01 10:33:44] [config] valid-mini-batch: 64
[2023-07-01 10:33:44] [config] valid-reset-stalled: false
[2023-07-01 10:33:44] [config] valid-script-args:
[2023-07-01 10:33:44] [config]   []
[2023-07-01 10:33:44] [config] valid-script-path: ""
[2023-07-01 10:33:44] [config] valid-sets:
[2023-07-01 10:33:44] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 10:33:44] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 10:33:44] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 10:33:44] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:33:44] [config] vocabs:
[2023-07-01 10:33:44] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 10:33:44] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 10:33:44] [config] word-penalty: 0
[2023-07-01 10:33:44] [config] word-scores: false
[2023-07-01 10:33:44] [config] workspace: 2048
[2023-07-01 10:33:44] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:33:44] Using synchronous SGD
[2023-07-01 10:33:44] Synced seed 1234
[2023-07-01 10:33:44] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 10:33:44] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 10:33:44] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 10:33:44] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 10:33:44] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 10:33:44] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 10:33:45] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 10:33:45] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 10:33:45] [comm] Using global sharding
[2023-07-01 10:33:45] [comm] NCCLCommunicators constructed successfully
[2023-07-01 10:33:45] [training] Using 1 GPUs
[2023-07-01 10:33:45] [logits] Applying loss function for 1 factor(s)
[2023-07-01 10:33:45] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:33:45] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 10:33:45] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:33:53] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 10:33:53] [valid] No post-processing script given for validating translator
[2023-07-01 10:33:53] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 10:33:53] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 10:33:53] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 10:33:53] [comm] Using global sharding
[2023-07-01 10:33:53] [comm] NCCLCommunicators constructed successfully
[2023-07-01 10:33:53] [training] Using 1 GPUs
[2023-07-01 10:33:53] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:33:54] Allocating memory for general optimizer shards
[2023-07-01 10:33:54] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:33:54] Loading Adam parameters
[2023-07-01 10:33:54] [memory] Reserving 176 MB, device gpu0
[2023-07-01 10:33:54] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:33:54] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 10:33:54] [data] Restoring the corpus state to epoch 32, batch 5859
[2023-07-01 10:33:54] [data] Shuffling data
[2023-07-01 10:33:54] [data] Done reading 20,192 sentences
[2023-07-01 10:33:54] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 10:33:54] Training started
[2023-07-01 10:33:54] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-07-01 10:33:54] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:33:54] Parameter type float32, optimization type float32, casting types false
[2023-07-01 10:34:12] Ep. 32 : Up. 6000 : Sen. 15,340 : Cost 4.37574863 * 3,206,652 @ 3,462 after 19,256,329 : Time 19.06s : 168242.38 words/s : gNorm 1.8932 : L.r. 1.1250e-04
[2023-07-01 10:34:18] Seen 20,073 samples
[2023-07-01 10:34:18] Starting data epoch 33 in logical epoch 33
[2023-07-01 10:34:18] Training finished
[2023-07-01 10:34:22] [valid] Ep. 33 : Up. 6048 : cross-entropy : 128.41 : new best
[2023-07-01 10:35:59] [valid] Ep. 33 : Up. 6048 : translation : 0 : new best
[2023-07-01 10:35:59] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:36:00] Saving Adam parameters
[2023-07-01 10:36:00] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 10:36:07] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:36:07] [marian] Running on node20.datos.cluster.uy as process 10235 with command line:
[2023-07-01 10:36:07] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 33 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 10:36:07] [config] after: 0e
[2023-07-01 10:36:07] [config] after-batches: 0
[2023-07-01 10:36:07] [config] after-epochs: 33
[2023-07-01 10:36:07] [config] all-caps-every: 0
[2023-07-01 10:36:07] [config] allow-unk: false
[2023-07-01 10:36:07] [config] authors: false
[2023-07-01 10:36:07] [config] beam-size: 12
[2023-07-01 10:36:07] [config] bert-class-symbol: "[CLS]"
[2023-07-01 10:36:07] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 10:36:07] [config] bert-masking-fraction: 0.15
[2023-07-01 10:36:07] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 10:36:07] [config] bert-train-type-embeddings: true
[2023-07-01 10:36:07] [config] bert-type-vocab-size: 2
[2023-07-01 10:36:07] [config] build-info: ""
[2023-07-01 10:36:07] [config] check-gradient-nan: false
[2023-07-01 10:36:07] [config] check-nan: false
[2023-07-01 10:36:07] [config] cite: false
[2023-07-01 10:36:07] [config] clip-norm: 5
[2023-07-01 10:36:07] [config] cost-scaling:
[2023-07-01 10:36:07] [config]   []
[2023-07-01 10:36:07] [config] cost-type: ce-sum
[2023-07-01 10:36:07] [config] cpu-threads: 0
[2023-07-01 10:36:07] [config] data-threads: 8
[2023-07-01 10:36:07] [config] data-weighting: ""
[2023-07-01 10:36:07] [config] data-weighting-type: sentence
[2023-07-01 10:36:07] [config] dec-cell: gru
[2023-07-01 10:36:07] [config] dec-cell-base-depth: 2
[2023-07-01 10:36:07] [config] dec-cell-high-depth: 1
[2023-07-01 10:36:07] [config] dec-depth: 2
[2023-07-01 10:36:07] [config] devices:
[2023-07-01 10:36:07] [config]   - 0
[2023-07-01 10:36:07] [config] dim-emb: 512
[2023-07-01 10:36:07] [config] dim-rnn: 1024
[2023-07-01 10:36:07] [config] dim-vocabs:
[2023-07-01 10:36:07] [config]   - 16384
[2023-07-01 10:36:07] [config]   - 16384
[2023-07-01 10:36:07] [config] disp-first: 0
[2023-07-01 10:36:07] [config] disp-freq: 1000u
[2023-07-01 10:36:07] [config] disp-label-counts: true
[2023-07-01 10:36:07] [config] dropout-rnn: 0
[2023-07-01 10:36:07] [config] dropout-src: 0
[2023-07-01 10:36:07] [config] dropout-trg: 0
[2023-07-01 10:36:07] [config] dump-config: ""
[2023-07-01 10:36:07] [config] dynamic-gradient-scaling:
[2023-07-01 10:36:07] [config]   []
[2023-07-01 10:36:07] [config] early-stopping: 10
[2023-07-01 10:36:07] [config] early-stopping-on: first
[2023-07-01 10:36:07] [config] embedding-fix-src: false
[2023-07-01 10:36:07] [config] embedding-fix-trg: false
[2023-07-01 10:36:07] [config] embedding-normalization: false
[2023-07-01 10:36:07] [config] embedding-vectors:
[2023-07-01 10:36:07] [config]   []
[2023-07-01 10:36:07] [config] enc-cell: gru
[2023-07-01 10:36:07] [config] enc-cell-depth: 1
[2023-07-01 10:36:07] [config] enc-depth: 2
[2023-07-01 10:36:07] [config] enc-type: bidirectional
[2023-07-01 10:36:07] [config] english-title-case-every: 0
[2023-07-01 10:36:07] [config] exponential-smoothing: 0.0001
[2023-07-01 10:36:07] [config] factor-weight: 1
[2023-07-01 10:36:07] [config] factors-combine: sum
[2023-07-01 10:36:07] [config] factors-dim-emb: 0
[2023-07-01 10:36:07] [config] gradient-checkpointing: false
[2023-07-01 10:36:07] [config] gradient-norm-average-window: 100
[2023-07-01 10:36:07] [config] guided-alignment: none
[2023-07-01 10:36:07] [config] guided-alignment-cost: mse
[2023-07-01 10:36:07] [config] guided-alignment-weight: 0.1
[2023-07-01 10:36:07] [config] ignore-model-config: false
[2023-07-01 10:36:07] [config] input-types:
[2023-07-01 10:36:07] [config]   []
[2023-07-01 10:36:07] [config] interpolate-env-vars: false
[2023-07-01 10:36:07] [config] keep-best: false
[2023-07-01 10:36:07] [config] label-smoothing: 0.1
[2023-07-01 10:36:07] [config] layer-normalization: false
[2023-07-01 10:36:07] [config] learn-rate: 0.0003
[2023-07-01 10:36:07] [config] lemma-dependency: ""
[2023-07-01 10:36:07] [config] lemma-dim-emb: 0
[2023-07-01 10:36:07] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 10:36:07] [config] log-level: info
[2023-07-01 10:36:07] [config] log-time-zone: ""
[2023-07-01 10:36:07] [config] logical-epoch:
[2023-07-01 10:36:07] [config]   - 1e
[2023-07-01 10:36:07] [config]   - 0
[2023-07-01 10:36:07] [config] lr-decay: 0
[2023-07-01 10:36:07] [config] lr-decay-freq: 50000
[2023-07-01 10:36:07] [config] lr-decay-inv-sqrt:
[2023-07-01 10:36:07] [config]   - 16000
[2023-07-01 10:36:07] [config] lr-decay-repeat-warmup: false
[2023-07-01 10:36:07] [config] lr-decay-reset-optimizer: false
[2023-07-01 10:36:07] [config] lr-decay-start:
[2023-07-01 10:36:07] [config]   - 10
[2023-07-01 10:36:07] [config]   - 1
[2023-07-01 10:36:07] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 10:36:07] [config] lr-report: true
[2023-07-01 10:36:07] [config] lr-warmup: 16000
[2023-07-01 10:36:07] [config] lr-warmup-at-reload: false
[2023-07-01 10:36:07] [config] lr-warmup-cycle: false
[2023-07-01 10:36:07] [config] lr-warmup-start-rate: 0
[2023-07-01 10:36:07] [config] max-length: 100
[2023-07-01 10:36:07] [config] max-length-crop: false
[2023-07-01 10:36:07] [config] max-length-factor: 3
[2023-07-01 10:36:07] [config] maxi-batch: 100
[2023-07-01 10:36:07] [config] maxi-batch-sort: trg
[2023-07-01 10:36:07] [config] mini-batch: 1000
[2023-07-01 10:36:07] [config] mini-batch-fit: true
[2023-07-01 10:36:07] [config] mini-batch-fit-step: 10
[2023-07-01 10:36:07] [config] mini-batch-round-up: true
[2023-07-01 10:36:07] [config] mini-batch-track-lr: false
[2023-07-01 10:36:07] [config] mini-batch-warmup: 0
[2023-07-01 10:36:07] [config] mini-batch-words: 0
[2023-07-01 10:36:07] [config] mini-batch-words-ref: 0
[2023-07-01 10:36:07] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:36:07] [config] multi-loss-type: sum
[2023-07-01 10:36:07] [config] n-best: false
[2023-07-01 10:36:07] [config] no-nccl: false
[2023-07-01 10:36:07] [config] no-reload: false
[2023-07-01 10:36:07] [config] no-restore-corpus: false
[2023-07-01 10:36:07] [config] normalize: 1
[2023-07-01 10:36:07] [config] normalize-gradient: false
[2023-07-01 10:36:07] [config] num-devices: 0
[2023-07-01 10:36:07] [config] optimizer: adam
[2023-07-01 10:36:07] [config] optimizer-delay: 1
[2023-07-01 10:36:07] [config] optimizer-params:
[2023-07-01 10:36:07] [config]   - 0.9
[2023-07-01 10:36:07] [config]   - 0.98
[2023-07-01 10:36:07] [config]   - 1e-09
[2023-07-01 10:36:07] [config] output-omit-bias: false
[2023-07-01 10:36:07] [config] overwrite: true
[2023-07-01 10:36:07] [config] precision:
[2023-07-01 10:36:07] [config]   - float32
[2023-07-01 10:36:07] [config]   - float32
[2023-07-01 10:36:07] [config] pretrained-model: ""
[2023-07-01 10:36:07] [config] quantize-biases: false
[2023-07-01 10:36:07] [config] quantize-bits: 0
[2023-07-01 10:36:07] [config] quantize-log-based: false
[2023-07-01 10:36:07] [config] quantize-optimization-steps: 0
[2023-07-01 10:36:07] [config] quiet: false
[2023-07-01 10:36:07] [config] quiet-translation: true
[2023-07-01 10:36:07] [config] relative-paths: false
[2023-07-01 10:36:07] [config] right-left: false
[2023-07-01 10:36:07] [config] save-freq: 10000u
[2023-07-01 10:36:07] [config] seed: 1234
[2023-07-01 10:36:07] [config] sentencepiece-alphas:
[2023-07-01 10:36:07] [config]   []
[2023-07-01 10:36:07] [config] sentencepiece-max-lines: 2000000
[2023-07-01 10:36:07] [config] sentencepiece-options: ""
[2023-07-01 10:36:07] [config] sharding: global
[2023-07-01 10:36:07] [config] shuffle: data
[2023-07-01 10:36:07] [config] shuffle-in-ram: false
[2023-07-01 10:36:07] [config] sigterm: save-and-exit
[2023-07-01 10:36:07] [config] skip: false
[2023-07-01 10:36:07] [config] sqlite: ""
[2023-07-01 10:36:07] [config] sqlite-drop: false
[2023-07-01 10:36:07] [config] sync-freq: 200u
[2023-07-01 10:36:07] [config] sync-sgd: true
[2023-07-01 10:36:07] [config] tempdir: /tmp
[2023-07-01 10:36:07] [config] tied-embeddings: false
[2023-07-01 10:36:07] [config] tied-embeddings-all: true
[2023-07-01 10:36:07] [config] tied-embeddings-src: false
[2023-07-01 10:36:07] [config] train-embedder-rank:
[2023-07-01 10:36:07] [config]   []
[2023-07-01 10:36:07] [config] train-sets:
[2023-07-01 10:36:07] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 10:36:07] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 10:36:07] [config] transformer-aan-activation: swish
[2023-07-01 10:36:07] [config] transformer-aan-depth: 2
[2023-07-01 10:36:07] [config] transformer-aan-nogate: false
[2023-07-01 10:36:07] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 10:36:07] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 10:36:07] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 10:36:07] [config] transformer-depth-scaling: false
[2023-07-01 10:36:07] [config] transformer-dim-aan: 2048
[2023-07-01 10:36:07] [config] transformer-dim-ffn: 2048
[2023-07-01 10:36:07] [config] transformer-dropout: 0.1
[2023-07-01 10:36:07] [config] transformer-dropout-attention: 0
[2023-07-01 10:36:07] [config] transformer-dropout-ffn: 0
[2023-07-01 10:36:07] [config] transformer-ffn-activation: swish
[2023-07-01 10:36:07] [config] transformer-ffn-depth: 2
[2023-07-01 10:36:07] [config] transformer-guided-alignment-layer: last
[2023-07-01 10:36:07] [config] transformer-heads: 8
[2023-07-01 10:36:07] [config] transformer-no-projection: false
[2023-07-01 10:36:07] [config] transformer-pool: false
[2023-07-01 10:36:07] [config] transformer-postprocess: dan
[2023-07-01 10:36:07] [config] transformer-postprocess-emb: d
[2023-07-01 10:36:07] [config] transformer-postprocess-top: ""
[2023-07-01 10:36:07] [config] transformer-preprocess: ""
[2023-07-01 10:36:07] [config] transformer-tied-layers:
[2023-07-01 10:36:07] [config]   []
[2023-07-01 10:36:07] [config] transformer-train-position-embeddings: false
[2023-07-01 10:36:07] [config] tsv: false
[2023-07-01 10:36:07] [config] tsv-fields: 0
[2023-07-01 10:36:07] [config] type: transformer
[2023-07-01 10:36:07] [config] ulr: false
[2023-07-01 10:36:07] [config] ulr-dim-emb: 0
[2023-07-01 10:36:07] [config] ulr-dropout: 0
[2023-07-01 10:36:07] [config] ulr-keys-vectors: ""
[2023-07-01 10:36:07] [config] ulr-query-vectors: ""
[2023-07-01 10:36:07] [config] ulr-softmax-temperature: 1
[2023-07-01 10:36:07] [config] ulr-trainable-transformation: false
[2023-07-01 10:36:07] [config] unlikelihood-loss: false
[2023-07-01 10:36:07] [config] valid-freq: 50000000
[2023-07-01 10:36:07] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 10:36:07] [config] valid-max-length: 1000
[2023-07-01 10:36:07] [config] valid-metrics:
[2023-07-01 10:36:07] [config]   - cross-entropy
[2023-07-01 10:36:07] [config]   - translation
[2023-07-01 10:36:07] [config] valid-mini-batch: 64
[2023-07-01 10:36:07] [config] valid-reset-stalled: false
[2023-07-01 10:36:07] [config] valid-script-args:
[2023-07-01 10:36:07] [config]   []
[2023-07-01 10:36:07] [config] valid-script-path: ""
[2023-07-01 10:36:07] [config] valid-sets:
[2023-07-01 10:36:07] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 10:36:07] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 10:36:07] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 10:36:07] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:36:07] [config] vocabs:
[2023-07-01 10:36:07] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 10:36:07] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 10:36:07] [config] word-penalty: 0
[2023-07-01 10:36:07] [config] word-scores: false
[2023-07-01 10:36:07] [config] workspace: 2048
[2023-07-01 10:36:07] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:36:07] Using synchronous SGD
[2023-07-01 10:36:07] Synced seed 1234
[2023-07-01 10:36:07] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 10:36:07] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 10:36:07] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 10:36:07] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 10:36:07] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 10:36:07] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 10:36:08] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 10:36:08] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 10:36:08] [comm] Using global sharding
[2023-07-01 10:36:08] [comm] NCCLCommunicators constructed successfully
[2023-07-01 10:36:08] [training] Using 1 GPUs
[2023-07-01 10:36:08] [logits] Applying loss function for 1 factor(s)
[2023-07-01 10:36:08] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:36:08] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 10:36:08] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:36:16] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 10:36:16] [valid] No post-processing script given for validating translator
[2023-07-01 10:36:16] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 10:36:16] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 10:36:16] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 10:36:16] [comm] Using global sharding
[2023-07-01 10:36:16] [comm] NCCLCommunicators constructed successfully
[2023-07-01 10:36:16] [training] Using 1 GPUs
[2023-07-01 10:36:16] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:36:17] Allocating memory for general optimizer shards
[2023-07-01 10:36:17] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:36:17] Loading Adam parameters
[2023-07-01 10:36:17] [memory] Reserving 176 MB, device gpu0
[2023-07-01 10:36:17] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:36:17] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 10:36:17] [data] Restoring the corpus state to epoch 33, batch 6048
[2023-07-01 10:36:17] [data] Shuffling data
[2023-07-01 10:36:17] [data] Done reading 20,192 sentences
[2023-07-01 10:36:17] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 10:36:17] Training started
[2023-07-01 10:36:17] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-07-01 10:36:17] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:36:17] Parameter type float32, optimization type float32, casting types false
[2023-07-01 10:36:41] Seen 20,073 samples
[2023-07-01 10:36:41] Starting data epoch 34 in logical epoch 34
[2023-07-01 10:36:41] Training finished
[2023-07-01 10:36:44] [valid] Ep. 34 : Up. 6237 : cross-entropy : 127.573 : new best
[2023-07-01 10:38:22] [valid] Ep. 34 : Up. 6237 : translation : 0 : new best
[2023-07-01 10:38:22] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:38:23] Saving Adam parameters
[2023-07-01 10:38:24] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 10:38:30] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:38:30] [marian] Running on node20.datos.cluster.uy as process 10718 with command line:
[2023-07-01 10:38:30] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 34 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 10:38:30] [config] after: 0e
[2023-07-01 10:38:30] [config] after-batches: 0
[2023-07-01 10:38:30] [config] after-epochs: 34
[2023-07-01 10:38:30] [config] all-caps-every: 0
[2023-07-01 10:38:30] [config] allow-unk: false
[2023-07-01 10:38:30] [config] authors: false
[2023-07-01 10:38:30] [config] beam-size: 12
[2023-07-01 10:38:30] [config] bert-class-symbol: "[CLS]"
[2023-07-01 10:38:30] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 10:38:30] [config] bert-masking-fraction: 0.15
[2023-07-01 10:38:30] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 10:38:30] [config] bert-train-type-embeddings: true
[2023-07-01 10:38:30] [config] bert-type-vocab-size: 2
[2023-07-01 10:38:30] [config] build-info: ""
[2023-07-01 10:38:30] [config] check-gradient-nan: false
[2023-07-01 10:38:30] [config] check-nan: false
[2023-07-01 10:38:30] [config] cite: false
[2023-07-01 10:38:30] [config] clip-norm: 5
[2023-07-01 10:38:30] [config] cost-scaling:
[2023-07-01 10:38:30] [config]   []
[2023-07-01 10:38:30] [config] cost-type: ce-sum
[2023-07-01 10:38:30] [config] cpu-threads: 0
[2023-07-01 10:38:30] [config] data-threads: 8
[2023-07-01 10:38:30] [config] data-weighting: ""
[2023-07-01 10:38:30] [config] data-weighting-type: sentence
[2023-07-01 10:38:30] [config] dec-cell: gru
[2023-07-01 10:38:30] [config] dec-cell-base-depth: 2
[2023-07-01 10:38:30] [config] dec-cell-high-depth: 1
[2023-07-01 10:38:30] [config] dec-depth: 2
[2023-07-01 10:38:30] [config] devices:
[2023-07-01 10:38:30] [config]   - 0
[2023-07-01 10:38:30] [config] dim-emb: 512
[2023-07-01 10:38:30] [config] dim-rnn: 1024
[2023-07-01 10:38:30] [config] dim-vocabs:
[2023-07-01 10:38:30] [config]   - 16384
[2023-07-01 10:38:30] [config]   - 16384
[2023-07-01 10:38:30] [config] disp-first: 0
[2023-07-01 10:38:30] [config] disp-freq: 1000u
[2023-07-01 10:38:30] [config] disp-label-counts: true
[2023-07-01 10:38:30] [config] dropout-rnn: 0
[2023-07-01 10:38:30] [config] dropout-src: 0
[2023-07-01 10:38:30] [config] dropout-trg: 0
[2023-07-01 10:38:30] [config] dump-config: ""
[2023-07-01 10:38:30] [config] dynamic-gradient-scaling:
[2023-07-01 10:38:30] [config]   []
[2023-07-01 10:38:30] [config] early-stopping: 10
[2023-07-01 10:38:30] [config] early-stopping-on: first
[2023-07-01 10:38:30] [config] embedding-fix-src: false
[2023-07-01 10:38:30] [config] embedding-fix-trg: false
[2023-07-01 10:38:30] [config] embedding-normalization: false
[2023-07-01 10:38:30] [config] embedding-vectors:
[2023-07-01 10:38:30] [config]   []
[2023-07-01 10:38:30] [config] enc-cell: gru
[2023-07-01 10:38:30] [config] enc-cell-depth: 1
[2023-07-01 10:38:30] [config] enc-depth: 2
[2023-07-01 10:38:30] [config] enc-type: bidirectional
[2023-07-01 10:38:30] [config] english-title-case-every: 0
[2023-07-01 10:38:30] [config] exponential-smoothing: 0.0001
[2023-07-01 10:38:30] [config] factor-weight: 1
[2023-07-01 10:38:30] [config] factors-combine: sum
[2023-07-01 10:38:30] [config] factors-dim-emb: 0
[2023-07-01 10:38:30] [config] gradient-checkpointing: false
[2023-07-01 10:38:30] [config] gradient-norm-average-window: 100
[2023-07-01 10:38:30] [config] guided-alignment: none
[2023-07-01 10:38:30] [config] guided-alignment-cost: mse
[2023-07-01 10:38:30] [config] guided-alignment-weight: 0.1
[2023-07-01 10:38:30] [config] ignore-model-config: false
[2023-07-01 10:38:30] [config] input-types:
[2023-07-01 10:38:30] [config]   []
[2023-07-01 10:38:30] [config] interpolate-env-vars: false
[2023-07-01 10:38:30] [config] keep-best: false
[2023-07-01 10:38:30] [config] label-smoothing: 0.1
[2023-07-01 10:38:30] [config] layer-normalization: false
[2023-07-01 10:38:30] [config] learn-rate: 0.0003
[2023-07-01 10:38:30] [config] lemma-dependency: ""
[2023-07-01 10:38:30] [config] lemma-dim-emb: 0
[2023-07-01 10:38:30] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 10:38:30] [config] log-level: info
[2023-07-01 10:38:30] [config] log-time-zone: ""
[2023-07-01 10:38:30] [config] logical-epoch:
[2023-07-01 10:38:30] [config]   - 1e
[2023-07-01 10:38:30] [config]   - 0
[2023-07-01 10:38:30] [config] lr-decay: 0
[2023-07-01 10:38:30] [config] lr-decay-freq: 50000
[2023-07-01 10:38:30] [config] lr-decay-inv-sqrt:
[2023-07-01 10:38:30] [config]   - 16000
[2023-07-01 10:38:30] [config] lr-decay-repeat-warmup: false
[2023-07-01 10:38:30] [config] lr-decay-reset-optimizer: false
[2023-07-01 10:38:30] [config] lr-decay-start:
[2023-07-01 10:38:30] [config]   - 10
[2023-07-01 10:38:30] [config]   - 1
[2023-07-01 10:38:30] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 10:38:30] [config] lr-report: true
[2023-07-01 10:38:30] [config] lr-warmup: 16000
[2023-07-01 10:38:30] [config] lr-warmup-at-reload: false
[2023-07-01 10:38:30] [config] lr-warmup-cycle: false
[2023-07-01 10:38:30] [config] lr-warmup-start-rate: 0
[2023-07-01 10:38:30] [config] max-length: 100
[2023-07-01 10:38:30] [config] max-length-crop: false
[2023-07-01 10:38:30] [config] max-length-factor: 3
[2023-07-01 10:38:30] [config] maxi-batch: 100
[2023-07-01 10:38:30] [config] maxi-batch-sort: trg
[2023-07-01 10:38:30] [config] mini-batch: 1000
[2023-07-01 10:38:30] [config] mini-batch-fit: true
[2023-07-01 10:38:30] [config] mini-batch-fit-step: 10
[2023-07-01 10:38:30] [config] mini-batch-round-up: true
[2023-07-01 10:38:30] [config] mini-batch-track-lr: false
[2023-07-01 10:38:30] [config] mini-batch-warmup: 0
[2023-07-01 10:38:30] [config] mini-batch-words: 0
[2023-07-01 10:38:30] [config] mini-batch-words-ref: 0
[2023-07-01 10:38:30] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:38:30] [config] multi-loss-type: sum
[2023-07-01 10:38:30] [config] n-best: false
[2023-07-01 10:38:30] [config] no-nccl: false
[2023-07-01 10:38:30] [config] no-reload: false
[2023-07-01 10:38:30] [config] no-restore-corpus: false
[2023-07-01 10:38:30] [config] normalize: 1
[2023-07-01 10:38:30] [config] normalize-gradient: false
[2023-07-01 10:38:30] [config] num-devices: 0
[2023-07-01 10:38:30] [config] optimizer: adam
[2023-07-01 10:38:30] [config] optimizer-delay: 1
[2023-07-01 10:38:30] [config] optimizer-params:
[2023-07-01 10:38:30] [config]   - 0.9
[2023-07-01 10:38:30] [config]   - 0.98
[2023-07-01 10:38:30] [config]   - 1e-09
[2023-07-01 10:38:30] [config] output-omit-bias: false
[2023-07-01 10:38:30] [config] overwrite: true
[2023-07-01 10:38:30] [config] precision:
[2023-07-01 10:38:30] [config]   - float32
[2023-07-01 10:38:30] [config]   - float32
[2023-07-01 10:38:30] [config] pretrained-model: ""
[2023-07-01 10:38:30] [config] quantize-biases: false
[2023-07-01 10:38:30] [config] quantize-bits: 0
[2023-07-01 10:38:30] [config] quantize-log-based: false
[2023-07-01 10:38:30] [config] quantize-optimization-steps: 0
[2023-07-01 10:38:30] [config] quiet: false
[2023-07-01 10:38:30] [config] quiet-translation: true
[2023-07-01 10:38:30] [config] relative-paths: false
[2023-07-01 10:38:30] [config] right-left: false
[2023-07-01 10:38:30] [config] save-freq: 10000u
[2023-07-01 10:38:30] [config] seed: 1234
[2023-07-01 10:38:30] [config] sentencepiece-alphas:
[2023-07-01 10:38:30] [config]   []
[2023-07-01 10:38:30] [config] sentencepiece-max-lines: 2000000
[2023-07-01 10:38:30] [config] sentencepiece-options: ""
[2023-07-01 10:38:30] [config] sharding: global
[2023-07-01 10:38:30] [config] shuffle: data
[2023-07-01 10:38:30] [config] shuffle-in-ram: false
[2023-07-01 10:38:30] [config] sigterm: save-and-exit
[2023-07-01 10:38:30] [config] skip: false
[2023-07-01 10:38:30] [config] sqlite: ""
[2023-07-01 10:38:30] [config] sqlite-drop: false
[2023-07-01 10:38:30] [config] sync-freq: 200u
[2023-07-01 10:38:30] [config] sync-sgd: true
[2023-07-01 10:38:30] [config] tempdir: /tmp
[2023-07-01 10:38:30] [config] tied-embeddings: false
[2023-07-01 10:38:30] [config] tied-embeddings-all: true
[2023-07-01 10:38:30] [config] tied-embeddings-src: false
[2023-07-01 10:38:30] [config] train-embedder-rank:
[2023-07-01 10:38:30] [config]   []
[2023-07-01 10:38:30] [config] train-sets:
[2023-07-01 10:38:30] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 10:38:30] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 10:38:30] [config] transformer-aan-activation: swish
[2023-07-01 10:38:30] [config] transformer-aan-depth: 2
[2023-07-01 10:38:30] [config] transformer-aan-nogate: false
[2023-07-01 10:38:30] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 10:38:30] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 10:38:30] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 10:38:30] [config] transformer-depth-scaling: false
[2023-07-01 10:38:30] [config] transformer-dim-aan: 2048
[2023-07-01 10:38:30] [config] transformer-dim-ffn: 2048
[2023-07-01 10:38:30] [config] transformer-dropout: 0.1
[2023-07-01 10:38:30] [config] transformer-dropout-attention: 0
[2023-07-01 10:38:30] [config] transformer-dropout-ffn: 0
[2023-07-01 10:38:30] [config] transformer-ffn-activation: swish
[2023-07-01 10:38:30] [config] transformer-ffn-depth: 2
[2023-07-01 10:38:30] [config] transformer-guided-alignment-layer: last
[2023-07-01 10:38:30] [config] transformer-heads: 8
[2023-07-01 10:38:30] [config] transformer-no-projection: false
[2023-07-01 10:38:30] [config] transformer-pool: false
[2023-07-01 10:38:30] [config] transformer-postprocess: dan
[2023-07-01 10:38:30] [config] transformer-postprocess-emb: d
[2023-07-01 10:38:30] [config] transformer-postprocess-top: ""
[2023-07-01 10:38:30] [config] transformer-preprocess: ""
[2023-07-01 10:38:30] [config] transformer-tied-layers:
[2023-07-01 10:38:30] [config]   []
[2023-07-01 10:38:30] [config] transformer-train-position-embeddings: false
[2023-07-01 10:38:30] [config] tsv: false
[2023-07-01 10:38:30] [config] tsv-fields: 0
[2023-07-01 10:38:30] [config] type: transformer
[2023-07-01 10:38:30] [config] ulr: false
[2023-07-01 10:38:30] [config] ulr-dim-emb: 0
[2023-07-01 10:38:30] [config] ulr-dropout: 0
[2023-07-01 10:38:30] [config] ulr-keys-vectors: ""
[2023-07-01 10:38:30] [config] ulr-query-vectors: ""
[2023-07-01 10:38:30] [config] ulr-softmax-temperature: 1
[2023-07-01 10:38:30] [config] ulr-trainable-transformation: false
[2023-07-01 10:38:30] [config] unlikelihood-loss: false
[2023-07-01 10:38:30] [config] valid-freq: 50000000
[2023-07-01 10:38:30] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 10:38:30] [config] valid-max-length: 1000
[2023-07-01 10:38:30] [config] valid-metrics:
[2023-07-01 10:38:30] [config]   - cross-entropy
[2023-07-01 10:38:30] [config]   - translation
[2023-07-01 10:38:30] [config] valid-mini-batch: 64
[2023-07-01 10:38:30] [config] valid-reset-stalled: false
[2023-07-01 10:38:30] [config] valid-script-args:
[2023-07-01 10:38:30] [config]   []
[2023-07-01 10:38:30] [config] valid-script-path: ""
[2023-07-01 10:38:30] [config] valid-sets:
[2023-07-01 10:38:30] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 10:38:30] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 10:38:30] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 10:38:30] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:38:30] [config] vocabs:
[2023-07-01 10:38:30] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 10:38:30] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 10:38:30] [config] word-penalty: 0
[2023-07-01 10:38:30] [config] word-scores: false
[2023-07-01 10:38:30] [config] workspace: 2048
[2023-07-01 10:38:30] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:38:30] Using synchronous SGD
[2023-07-01 10:38:30] Synced seed 1234
[2023-07-01 10:38:30] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 10:38:30] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 10:38:30] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 10:38:30] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 10:38:30] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 10:38:30] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 10:38:31] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 10:38:31] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 10:38:31] [comm] Using global sharding
[2023-07-01 10:38:31] [comm] NCCLCommunicators constructed successfully
[2023-07-01 10:38:31] [training] Using 1 GPUs
[2023-07-01 10:38:31] [logits] Applying loss function for 1 factor(s)
[2023-07-01 10:38:31] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:38:32] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 10:38:32] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:38:39] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 10:38:39] [valid] No post-processing script given for validating translator
[2023-07-01 10:38:39] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 10:38:39] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 10:38:39] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 10:38:39] [comm] Using global sharding
[2023-07-01 10:38:39] [comm] NCCLCommunicators constructed successfully
[2023-07-01 10:38:39] [training] Using 1 GPUs
[2023-07-01 10:38:39] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:38:40] Allocating memory for general optimizer shards
[2023-07-01 10:38:40] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:38:40] Loading Adam parameters
[2023-07-01 10:38:40] [memory] Reserving 176 MB, device gpu0
[2023-07-01 10:38:40] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:38:40] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 10:38:40] [data] Restoring the corpus state to epoch 34, batch 6237
[2023-07-01 10:38:40] [data] Shuffling data
[2023-07-01 10:38:40] [data] Done reading 20,192 sentences
[2023-07-01 10:38:40] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 10:38:40] Training started
[2023-07-01 10:38:41] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-07-01 10:38:41] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:38:41] Parameter type float32, optimization type float32, casting types false
[2023-07-01 10:39:05] Seen 20,073 samples
[2023-07-01 10:39:05] Starting data epoch 35 in logical epoch 35
[2023-07-01 10:39:05] Training finished
[2023-07-01 10:39:08] [valid] Ep. 35 : Up. 6426 : cross-entropy : 126.839 : new best
[2023-07-01 10:40:39] [valid] Ep. 35 : Up. 6426 : translation : 0 : new best
[2023-07-01 10:40:39] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:40:40] Saving Adam parameters
[2023-07-01 10:40:40] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 10:40:46] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:40:46] [marian] Running on node20.datos.cluster.uy as process 10886 with command line:
[2023-07-01 10:40:46] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 35 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 10:40:46] [config] after: 0e
[2023-07-01 10:40:46] [config] after-batches: 0
[2023-07-01 10:40:46] [config] after-epochs: 35
[2023-07-01 10:40:46] [config] all-caps-every: 0
[2023-07-01 10:40:46] [config] allow-unk: false
[2023-07-01 10:40:46] [config] authors: false
[2023-07-01 10:40:46] [config] beam-size: 12
[2023-07-01 10:40:46] [config] bert-class-symbol: "[CLS]"
[2023-07-01 10:40:46] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 10:40:46] [config] bert-masking-fraction: 0.15
[2023-07-01 10:40:46] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 10:40:46] [config] bert-train-type-embeddings: true
[2023-07-01 10:40:46] [config] bert-type-vocab-size: 2
[2023-07-01 10:40:46] [config] build-info: ""
[2023-07-01 10:40:46] [config] check-gradient-nan: false
[2023-07-01 10:40:46] [config] check-nan: false
[2023-07-01 10:40:46] [config] cite: false
[2023-07-01 10:40:46] [config] clip-norm: 5
[2023-07-01 10:40:46] [config] cost-scaling:
[2023-07-01 10:40:46] [config]   []
[2023-07-01 10:40:46] [config] cost-type: ce-sum
[2023-07-01 10:40:46] [config] cpu-threads: 0
[2023-07-01 10:40:46] [config] data-threads: 8
[2023-07-01 10:40:46] [config] data-weighting: ""
[2023-07-01 10:40:46] [config] data-weighting-type: sentence
[2023-07-01 10:40:46] [config] dec-cell: gru
[2023-07-01 10:40:46] [config] dec-cell-base-depth: 2
[2023-07-01 10:40:46] [config] dec-cell-high-depth: 1
[2023-07-01 10:40:46] [config] dec-depth: 2
[2023-07-01 10:40:46] [config] devices:
[2023-07-01 10:40:46] [config]   - 0
[2023-07-01 10:40:46] [config] dim-emb: 512
[2023-07-01 10:40:46] [config] dim-rnn: 1024
[2023-07-01 10:40:46] [config] dim-vocabs:
[2023-07-01 10:40:46] [config]   - 16384
[2023-07-01 10:40:46] [config]   - 16384
[2023-07-01 10:40:46] [config] disp-first: 0
[2023-07-01 10:40:46] [config] disp-freq: 1000u
[2023-07-01 10:40:46] [config] disp-label-counts: true
[2023-07-01 10:40:46] [config] dropout-rnn: 0
[2023-07-01 10:40:46] [config] dropout-src: 0
[2023-07-01 10:40:46] [config] dropout-trg: 0
[2023-07-01 10:40:46] [config] dump-config: ""
[2023-07-01 10:40:46] [config] dynamic-gradient-scaling:
[2023-07-01 10:40:46] [config]   []
[2023-07-01 10:40:46] [config] early-stopping: 10
[2023-07-01 10:40:46] [config] early-stopping-on: first
[2023-07-01 10:40:46] [config] embedding-fix-src: false
[2023-07-01 10:40:46] [config] embedding-fix-trg: false
[2023-07-01 10:40:46] [config] embedding-normalization: false
[2023-07-01 10:40:46] [config] embedding-vectors:
[2023-07-01 10:40:46] [config]   []
[2023-07-01 10:40:46] [config] enc-cell: gru
[2023-07-01 10:40:46] [config] enc-cell-depth: 1
[2023-07-01 10:40:46] [config] enc-depth: 2
[2023-07-01 10:40:46] [config] enc-type: bidirectional
[2023-07-01 10:40:46] [config] english-title-case-every: 0
[2023-07-01 10:40:46] [config] exponential-smoothing: 0.0001
[2023-07-01 10:40:46] [config] factor-weight: 1
[2023-07-01 10:40:46] [config] factors-combine: sum
[2023-07-01 10:40:46] [config] factors-dim-emb: 0
[2023-07-01 10:40:46] [config] gradient-checkpointing: false
[2023-07-01 10:40:46] [config] gradient-norm-average-window: 100
[2023-07-01 10:40:46] [config] guided-alignment: none
[2023-07-01 10:40:46] [config] guided-alignment-cost: mse
[2023-07-01 10:40:46] [config] guided-alignment-weight: 0.1
[2023-07-01 10:40:46] [config] ignore-model-config: false
[2023-07-01 10:40:46] [config] input-types:
[2023-07-01 10:40:46] [config]   []
[2023-07-01 10:40:46] [config] interpolate-env-vars: false
[2023-07-01 10:40:46] [config] keep-best: false
[2023-07-01 10:40:46] [config] label-smoothing: 0.1
[2023-07-01 10:40:46] [config] layer-normalization: false
[2023-07-01 10:40:46] [config] learn-rate: 0.0003
[2023-07-01 10:40:46] [config] lemma-dependency: ""
[2023-07-01 10:40:46] [config] lemma-dim-emb: 0
[2023-07-01 10:40:46] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 10:40:46] [config] log-level: info
[2023-07-01 10:40:46] [config] log-time-zone: ""
[2023-07-01 10:40:46] [config] logical-epoch:
[2023-07-01 10:40:46] [config]   - 1e
[2023-07-01 10:40:46] [config]   - 0
[2023-07-01 10:40:46] [config] lr-decay: 0
[2023-07-01 10:40:46] [config] lr-decay-freq: 50000
[2023-07-01 10:40:46] [config] lr-decay-inv-sqrt:
[2023-07-01 10:40:46] [config]   - 16000
[2023-07-01 10:40:46] [config] lr-decay-repeat-warmup: false
[2023-07-01 10:40:46] [config] lr-decay-reset-optimizer: false
[2023-07-01 10:40:46] [config] lr-decay-start:
[2023-07-01 10:40:46] [config]   - 10
[2023-07-01 10:40:46] [config]   - 1
[2023-07-01 10:40:46] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 10:40:46] [config] lr-report: true
[2023-07-01 10:40:46] [config] lr-warmup: 16000
[2023-07-01 10:40:46] [config] lr-warmup-at-reload: false
[2023-07-01 10:40:46] [config] lr-warmup-cycle: false
[2023-07-01 10:40:46] [config] lr-warmup-start-rate: 0
[2023-07-01 10:40:46] [config] max-length: 100
[2023-07-01 10:40:46] [config] max-length-crop: false
[2023-07-01 10:40:46] [config] max-length-factor: 3
[2023-07-01 10:40:46] [config] maxi-batch: 100
[2023-07-01 10:40:46] [config] maxi-batch-sort: trg
[2023-07-01 10:40:46] [config] mini-batch: 1000
[2023-07-01 10:40:46] [config] mini-batch-fit: true
[2023-07-01 10:40:46] [config] mini-batch-fit-step: 10
[2023-07-01 10:40:46] [config] mini-batch-round-up: true
[2023-07-01 10:40:46] [config] mini-batch-track-lr: false
[2023-07-01 10:40:46] [config] mini-batch-warmup: 0
[2023-07-01 10:40:46] [config] mini-batch-words: 0
[2023-07-01 10:40:46] [config] mini-batch-words-ref: 0
[2023-07-01 10:40:46] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:40:46] [config] multi-loss-type: sum
[2023-07-01 10:40:46] [config] n-best: false
[2023-07-01 10:40:46] [config] no-nccl: false
[2023-07-01 10:40:46] [config] no-reload: false
[2023-07-01 10:40:46] [config] no-restore-corpus: false
[2023-07-01 10:40:46] [config] normalize: 1
[2023-07-01 10:40:46] [config] normalize-gradient: false
[2023-07-01 10:40:46] [config] num-devices: 0
[2023-07-01 10:40:46] [config] optimizer: adam
[2023-07-01 10:40:46] [config] optimizer-delay: 1
[2023-07-01 10:40:46] [config] optimizer-params:
[2023-07-01 10:40:46] [config]   - 0.9
[2023-07-01 10:40:46] [config]   - 0.98
[2023-07-01 10:40:46] [config]   - 1e-09
[2023-07-01 10:40:46] [config] output-omit-bias: false
[2023-07-01 10:40:46] [config] overwrite: true
[2023-07-01 10:40:46] [config] precision:
[2023-07-01 10:40:46] [config]   - float32
[2023-07-01 10:40:46] [config]   - float32
[2023-07-01 10:40:46] [config] pretrained-model: ""
[2023-07-01 10:40:46] [config] quantize-biases: false
[2023-07-01 10:40:46] [config] quantize-bits: 0
[2023-07-01 10:40:46] [config] quantize-log-based: false
[2023-07-01 10:40:46] [config] quantize-optimization-steps: 0
[2023-07-01 10:40:46] [config] quiet: false
[2023-07-01 10:40:46] [config] quiet-translation: true
[2023-07-01 10:40:46] [config] relative-paths: false
[2023-07-01 10:40:46] [config] right-left: false
[2023-07-01 10:40:46] [config] save-freq: 10000u
[2023-07-01 10:40:46] [config] seed: 1234
[2023-07-01 10:40:46] [config] sentencepiece-alphas:
[2023-07-01 10:40:46] [config]   []
[2023-07-01 10:40:46] [config] sentencepiece-max-lines: 2000000
[2023-07-01 10:40:46] [config] sentencepiece-options: ""
[2023-07-01 10:40:46] [config] sharding: global
[2023-07-01 10:40:46] [config] shuffle: data
[2023-07-01 10:40:46] [config] shuffle-in-ram: false
[2023-07-01 10:40:46] [config] sigterm: save-and-exit
[2023-07-01 10:40:46] [config] skip: false
[2023-07-01 10:40:46] [config] sqlite: ""
[2023-07-01 10:40:46] [config] sqlite-drop: false
[2023-07-01 10:40:46] [config] sync-freq: 200u
[2023-07-01 10:40:46] [config] sync-sgd: true
[2023-07-01 10:40:46] [config] tempdir: /tmp
[2023-07-01 10:40:46] [config] tied-embeddings: false
[2023-07-01 10:40:46] [config] tied-embeddings-all: true
[2023-07-01 10:40:46] [config] tied-embeddings-src: false
[2023-07-01 10:40:46] [config] train-embedder-rank:
[2023-07-01 10:40:46] [config]   []
[2023-07-01 10:40:46] [config] train-sets:
[2023-07-01 10:40:46] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 10:40:46] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 10:40:46] [config] transformer-aan-activation: swish
[2023-07-01 10:40:46] [config] transformer-aan-depth: 2
[2023-07-01 10:40:46] [config] transformer-aan-nogate: false
[2023-07-01 10:40:46] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 10:40:46] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 10:40:46] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 10:40:46] [config] transformer-depth-scaling: false
[2023-07-01 10:40:46] [config] transformer-dim-aan: 2048
[2023-07-01 10:40:46] [config] transformer-dim-ffn: 2048
[2023-07-01 10:40:46] [config] transformer-dropout: 0.1
[2023-07-01 10:40:46] [config] transformer-dropout-attention: 0
[2023-07-01 10:40:46] [config] transformer-dropout-ffn: 0
[2023-07-01 10:40:46] [config] transformer-ffn-activation: swish
[2023-07-01 10:40:46] [config] transformer-ffn-depth: 2
[2023-07-01 10:40:46] [config] transformer-guided-alignment-layer: last
[2023-07-01 10:40:46] [config] transformer-heads: 8
[2023-07-01 10:40:46] [config] transformer-no-projection: false
[2023-07-01 10:40:46] [config] transformer-pool: false
[2023-07-01 10:40:46] [config] transformer-postprocess: dan
[2023-07-01 10:40:46] [config] transformer-postprocess-emb: d
[2023-07-01 10:40:46] [config] transformer-postprocess-top: ""
[2023-07-01 10:40:46] [config] transformer-preprocess: ""
[2023-07-01 10:40:46] [config] transformer-tied-layers:
[2023-07-01 10:40:46] [config]   []
[2023-07-01 10:40:46] [config] transformer-train-position-embeddings: false
[2023-07-01 10:40:46] [config] tsv: false
[2023-07-01 10:40:46] [config] tsv-fields: 0
[2023-07-01 10:40:46] [config] type: transformer
[2023-07-01 10:40:46] [config] ulr: false
[2023-07-01 10:40:46] [config] ulr-dim-emb: 0
[2023-07-01 10:40:46] [config] ulr-dropout: 0
[2023-07-01 10:40:46] [config] ulr-keys-vectors: ""
[2023-07-01 10:40:46] [config] ulr-query-vectors: ""
[2023-07-01 10:40:46] [config] ulr-softmax-temperature: 1
[2023-07-01 10:40:46] [config] ulr-trainable-transformation: false
[2023-07-01 10:40:46] [config] unlikelihood-loss: false
[2023-07-01 10:40:46] [config] valid-freq: 50000000
[2023-07-01 10:40:46] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 10:40:46] [config] valid-max-length: 1000
[2023-07-01 10:40:46] [config] valid-metrics:
[2023-07-01 10:40:46] [config]   - cross-entropy
[2023-07-01 10:40:46] [config]   - translation
[2023-07-01 10:40:46] [config] valid-mini-batch: 64
[2023-07-01 10:40:46] [config] valid-reset-stalled: false
[2023-07-01 10:40:46] [config] valid-script-args:
[2023-07-01 10:40:46] [config]   []
[2023-07-01 10:40:46] [config] valid-script-path: ""
[2023-07-01 10:40:46] [config] valid-sets:
[2023-07-01 10:40:46] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 10:40:46] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 10:40:46] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 10:40:46] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:40:46] [config] vocabs:
[2023-07-01 10:40:46] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 10:40:46] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 10:40:46] [config] word-penalty: 0
[2023-07-01 10:40:46] [config] word-scores: false
[2023-07-01 10:40:46] [config] workspace: 2048
[2023-07-01 10:40:46] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:40:46] Using synchronous SGD
[2023-07-01 10:40:47] Synced seed 1234
[2023-07-01 10:40:47] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 10:40:47] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 10:40:47] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 10:40:47] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 10:40:47] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 10:40:47] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 10:40:47] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 10:40:47] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 10:40:47] [comm] Using global sharding
[2023-07-01 10:40:48] [comm] NCCLCommunicators constructed successfully
[2023-07-01 10:40:48] [training] Using 1 GPUs
[2023-07-01 10:40:48] [logits] Applying loss function for 1 factor(s)
[2023-07-01 10:40:48] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:40:48] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 10:40:48] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:40:56] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 10:40:56] [valid] No post-processing script given for validating translator
[2023-07-01 10:40:56] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 10:40:56] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 10:40:56] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 10:40:56] [comm] Using global sharding
[2023-07-01 10:40:56] [comm] NCCLCommunicators constructed successfully
[2023-07-01 10:40:56] [training] Using 1 GPUs
[2023-07-01 10:40:56] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:40:57] Allocating memory for general optimizer shards
[2023-07-01 10:40:57] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:40:57] Loading Adam parameters
[2023-07-01 10:40:57] [memory] Reserving 176 MB, device gpu0
[2023-07-01 10:40:57] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:40:57] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 10:40:57] [data] Restoring the corpus state to epoch 35, batch 6426
[2023-07-01 10:40:57] [data] Shuffling data
[2023-07-01 10:40:57] [data] Done reading 20,192 sentences
[2023-07-01 10:40:57] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 10:40:57] Training started
[2023-07-01 10:40:57] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-07-01 10:40:57] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:40:57] Parameter type float32, optimization type float32, casting types false
[2023-07-01 10:41:21] Seen 20,073 samples
[2023-07-01 10:41:21] Starting data epoch 36 in logical epoch 36
[2023-07-01 10:41:21] Training finished
[2023-07-01 10:41:24] [valid] Ep. 36 : Up. 6615 : cross-entropy : 126.214 : new best
[2023-07-01 10:42:59] [valid] Ep. 36 : Up. 6615 : translation : 0 : new best
[2023-07-01 10:42:59] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:43:00] Saving Adam parameters
[2023-07-01 10:43:00] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 10:43:06] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:43:06] [marian] Running on node20.datos.cluster.uy as process 11060 with command line:
[2023-07-01 10:43:06] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 36 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 10:43:06] [config] after: 0e
[2023-07-01 10:43:06] [config] after-batches: 0
[2023-07-01 10:43:06] [config] after-epochs: 36
[2023-07-01 10:43:06] [config] all-caps-every: 0
[2023-07-01 10:43:06] [config] allow-unk: false
[2023-07-01 10:43:06] [config] authors: false
[2023-07-01 10:43:06] [config] beam-size: 12
[2023-07-01 10:43:06] [config] bert-class-symbol: "[CLS]"
[2023-07-01 10:43:06] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 10:43:06] [config] bert-masking-fraction: 0.15
[2023-07-01 10:43:06] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 10:43:06] [config] bert-train-type-embeddings: true
[2023-07-01 10:43:06] [config] bert-type-vocab-size: 2
[2023-07-01 10:43:06] [config] build-info: ""
[2023-07-01 10:43:06] [config] check-gradient-nan: false
[2023-07-01 10:43:06] [config] check-nan: false
[2023-07-01 10:43:06] [config] cite: false
[2023-07-01 10:43:06] [config] clip-norm: 5
[2023-07-01 10:43:06] [config] cost-scaling:
[2023-07-01 10:43:06] [config]   []
[2023-07-01 10:43:06] [config] cost-type: ce-sum
[2023-07-01 10:43:06] [config] cpu-threads: 0
[2023-07-01 10:43:06] [config] data-threads: 8
[2023-07-01 10:43:06] [config] data-weighting: ""
[2023-07-01 10:43:06] [config] data-weighting-type: sentence
[2023-07-01 10:43:06] [config] dec-cell: gru
[2023-07-01 10:43:06] [config] dec-cell-base-depth: 2
[2023-07-01 10:43:06] [config] dec-cell-high-depth: 1
[2023-07-01 10:43:06] [config] dec-depth: 2
[2023-07-01 10:43:06] [config] devices:
[2023-07-01 10:43:06] [config]   - 0
[2023-07-01 10:43:06] [config] dim-emb: 512
[2023-07-01 10:43:06] [config] dim-rnn: 1024
[2023-07-01 10:43:06] [config] dim-vocabs:
[2023-07-01 10:43:06] [config]   - 16384
[2023-07-01 10:43:06] [config]   - 16384
[2023-07-01 10:43:06] [config] disp-first: 0
[2023-07-01 10:43:06] [config] disp-freq: 1000u
[2023-07-01 10:43:06] [config] disp-label-counts: true
[2023-07-01 10:43:06] [config] dropout-rnn: 0
[2023-07-01 10:43:06] [config] dropout-src: 0
[2023-07-01 10:43:06] [config] dropout-trg: 0
[2023-07-01 10:43:06] [config] dump-config: ""
[2023-07-01 10:43:06] [config] dynamic-gradient-scaling:
[2023-07-01 10:43:06] [config]   []
[2023-07-01 10:43:06] [config] early-stopping: 10
[2023-07-01 10:43:06] [config] early-stopping-on: first
[2023-07-01 10:43:06] [config] embedding-fix-src: false
[2023-07-01 10:43:06] [config] embedding-fix-trg: false
[2023-07-01 10:43:06] [config] embedding-normalization: false
[2023-07-01 10:43:06] [config] embedding-vectors:
[2023-07-01 10:43:06] [config]   []
[2023-07-01 10:43:06] [config] enc-cell: gru
[2023-07-01 10:43:06] [config] enc-cell-depth: 1
[2023-07-01 10:43:06] [config] enc-depth: 2
[2023-07-01 10:43:06] [config] enc-type: bidirectional
[2023-07-01 10:43:06] [config] english-title-case-every: 0
[2023-07-01 10:43:06] [config] exponential-smoothing: 0.0001
[2023-07-01 10:43:06] [config] factor-weight: 1
[2023-07-01 10:43:06] [config] factors-combine: sum
[2023-07-01 10:43:06] [config] factors-dim-emb: 0
[2023-07-01 10:43:06] [config] gradient-checkpointing: false
[2023-07-01 10:43:06] [config] gradient-norm-average-window: 100
[2023-07-01 10:43:06] [config] guided-alignment: none
[2023-07-01 10:43:06] [config] guided-alignment-cost: mse
[2023-07-01 10:43:06] [config] guided-alignment-weight: 0.1
[2023-07-01 10:43:06] [config] ignore-model-config: false
[2023-07-01 10:43:06] [config] input-types:
[2023-07-01 10:43:06] [config]   []
[2023-07-01 10:43:06] [config] interpolate-env-vars: false
[2023-07-01 10:43:06] [config] keep-best: false
[2023-07-01 10:43:06] [config] label-smoothing: 0.1
[2023-07-01 10:43:06] [config] layer-normalization: false
[2023-07-01 10:43:06] [config] learn-rate: 0.0003
[2023-07-01 10:43:06] [config] lemma-dependency: ""
[2023-07-01 10:43:06] [config] lemma-dim-emb: 0
[2023-07-01 10:43:06] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 10:43:06] [config] log-level: info
[2023-07-01 10:43:06] [config] log-time-zone: ""
[2023-07-01 10:43:06] [config] logical-epoch:
[2023-07-01 10:43:06] [config]   - 1e
[2023-07-01 10:43:06] [config]   - 0
[2023-07-01 10:43:06] [config] lr-decay: 0
[2023-07-01 10:43:06] [config] lr-decay-freq: 50000
[2023-07-01 10:43:06] [config] lr-decay-inv-sqrt:
[2023-07-01 10:43:06] [config]   - 16000
[2023-07-01 10:43:06] [config] lr-decay-repeat-warmup: false
[2023-07-01 10:43:06] [config] lr-decay-reset-optimizer: false
[2023-07-01 10:43:06] [config] lr-decay-start:
[2023-07-01 10:43:06] [config]   - 10
[2023-07-01 10:43:06] [config]   - 1
[2023-07-01 10:43:06] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 10:43:06] [config] lr-report: true
[2023-07-01 10:43:06] [config] lr-warmup: 16000
[2023-07-01 10:43:06] [config] lr-warmup-at-reload: false
[2023-07-01 10:43:06] [config] lr-warmup-cycle: false
[2023-07-01 10:43:06] [config] lr-warmup-start-rate: 0
[2023-07-01 10:43:06] [config] max-length: 100
[2023-07-01 10:43:06] [config] max-length-crop: false
[2023-07-01 10:43:06] [config] max-length-factor: 3
[2023-07-01 10:43:06] [config] maxi-batch: 100
[2023-07-01 10:43:06] [config] maxi-batch-sort: trg
[2023-07-01 10:43:06] [config] mini-batch: 1000
[2023-07-01 10:43:06] [config] mini-batch-fit: true
[2023-07-01 10:43:06] [config] mini-batch-fit-step: 10
[2023-07-01 10:43:06] [config] mini-batch-round-up: true
[2023-07-01 10:43:06] [config] mini-batch-track-lr: false
[2023-07-01 10:43:06] [config] mini-batch-warmup: 0
[2023-07-01 10:43:06] [config] mini-batch-words: 0
[2023-07-01 10:43:06] [config] mini-batch-words-ref: 0
[2023-07-01 10:43:06] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:43:06] [config] multi-loss-type: sum
[2023-07-01 10:43:06] [config] n-best: false
[2023-07-01 10:43:06] [config] no-nccl: false
[2023-07-01 10:43:06] [config] no-reload: false
[2023-07-01 10:43:06] [config] no-restore-corpus: false
[2023-07-01 10:43:06] [config] normalize: 1
[2023-07-01 10:43:06] [config] normalize-gradient: false
[2023-07-01 10:43:06] [config] num-devices: 0
[2023-07-01 10:43:06] [config] optimizer: adam
[2023-07-01 10:43:06] [config] optimizer-delay: 1
[2023-07-01 10:43:06] [config] optimizer-params:
[2023-07-01 10:43:06] [config]   - 0.9
[2023-07-01 10:43:06] [config]   - 0.98
[2023-07-01 10:43:06] [config]   - 1e-09
[2023-07-01 10:43:06] [config] output-omit-bias: false
[2023-07-01 10:43:06] [config] overwrite: true
[2023-07-01 10:43:06] [config] precision:
[2023-07-01 10:43:06] [config]   - float32
[2023-07-01 10:43:06] [config]   - float32
[2023-07-01 10:43:06] [config] pretrained-model: ""
[2023-07-01 10:43:06] [config] quantize-biases: false
[2023-07-01 10:43:06] [config] quantize-bits: 0
[2023-07-01 10:43:06] [config] quantize-log-based: false
[2023-07-01 10:43:06] [config] quantize-optimization-steps: 0
[2023-07-01 10:43:06] [config] quiet: false
[2023-07-01 10:43:06] [config] quiet-translation: true
[2023-07-01 10:43:06] [config] relative-paths: false
[2023-07-01 10:43:06] [config] right-left: false
[2023-07-01 10:43:06] [config] save-freq: 10000u
[2023-07-01 10:43:06] [config] seed: 1234
[2023-07-01 10:43:06] [config] sentencepiece-alphas:
[2023-07-01 10:43:06] [config]   []
[2023-07-01 10:43:06] [config] sentencepiece-max-lines: 2000000
[2023-07-01 10:43:06] [config] sentencepiece-options: ""
[2023-07-01 10:43:06] [config] sharding: global
[2023-07-01 10:43:06] [config] shuffle: data
[2023-07-01 10:43:06] [config] shuffle-in-ram: false
[2023-07-01 10:43:06] [config] sigterm: save-and-exit
[2023-07-01 10:43:06] [config] skip: false
[2023-07-01 10:43:06] [config] sqlite: ""
[2023-07-01 10:43:06] [config] sqlite-drop: false
[2023-07-01 10:43:06] [config] sync-freq: 200u
[2023-07-01 10:43:06] [config] sync-sgd: true
[2023-07-01 10:43:06] [config] tempdir: /tmp
[2023-07-01 10:43:06] [config] tied-embeddings: false
[2023-07-01 10:43:06] [config] tied-embeddings-all: true
[2023-07-01 10:43:06] [config] tied-embeddings-src: false
[2023-07-01 10:43:06] [config] train-embedder-rank:
[2023-07-01 10:43:06] [config]   []
[2023-07-01 10:43:06] [config] train-sets:
[2023-07-01 10:43:06] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 10:43:06] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 10:43:06] [config] transformer-aan-activation: swish
[2023-07-01 10:43:06] [config] transformer-aan-depth: 2
[2023-07-01 10:43:06] [config] transformer-aan-nogate: false
[2023-07-01 10:43:06] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 10:43:06] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 10:43:06] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 10:43:06] [config] transformer-depth-scaling: false
[2023-07-01 10:43:06] [config] transformer-dim-aan: 2048
[2023-07-01 10:43:06] [config] transformer-dim-ffn: 2048
[2023-07-01 10:43:06] [config] transformer-dropout: 0.1
[2023-07-01 10:43:06] [config] transformer-dropout-attention: 0
[2023-07-01 10:43:06] [config] transformer-dropout-ffn: 0
[2023-07-01 10:43:06] [config] transformer-ffn-activation: swish
[2023-07-01 10:43:06] [config] transformer-ffn-depth: 2
[2023-07-01 10:43:06] [config] transformer-guided-alignment-layer: last
[2023-07-01 10:43:06] [config] transformer-heads: 8
[2023-07-01 10:43:06] [config] transformer-no-projection: false
[2023-07-01 10:43:06] [config] transformer-pool: false
[2023-07-01 10:43:06] [config] transformer-postprocess: dan
[2023-07-01 10:43:06] [config] transformer-postprocess-emb: d
[2023-07-01 10:43:06] [config] transformer-postprocess-top: ""
[2023-07-01 10:43:06] [config] transformer-preprocess: ""
[2023-07-01 10:43:06] [config] transformer-tied-layers:
[2023-07-01 10:43:06] [config]   []
[2023-07-01 10:43:06] [config] transformer-train-position-embeddings: false
[2023-07-01 10:43:06] [config] tsv: false
[2023-07-01 10:43:06] [config] tsv-fields: 0
[2023-07-01 10:43:06] [config] type: transformer
[2023-07-01 10:43:06] [config] ulr: false
[2023-07-01 10:43:06] [config] ulr-dim-emb: 0
[2023-07-01 10:43:06] [config] ulr-dropout: 0
[2023-07-01 10:43:06] [config] ulr-keys-vectors: ""
[2023-07-01 10:43:06] [config] ulr-query-vectors: ""
[2023-07-01 10:43:06] [config] ulr-softmax-temperature: 1
[2023-07-01 10:43:06] [config] ulr-trainable-transformation: false
[2023-07-01 10:43:06] [config] unlikelihood-loss: false
[2023-07-01 10:43:06] [config] valid-freq: 50000000
[2023-07-01 10:43:06] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 10:43:06] [config] valid-max-length: 1000
[2023-07-01 10:43:06] [config] valid-metrics:
[2023-07-01 10:43:06] [config]   - cross-entropy
[2023-07-01 10:43:06] [config]   - translation
[2023-07-01 10:43:06] [config] valid-mini-batch: 64
[2023-07-01 10:43:06] [config] valid-reset-stalled: false
[2023-07-01 10:43:06] [config] valid-script-args:
[2023-07-01 10:43:06] [config]   []
[2023-07-01 10:43:06] [config] valid-script-path: ""
[2023-07-01 10:43:06] [config] valid-sets:
[2023-07-01 10:43:06] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 10:43:06] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 10:43:06] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 10:43:06] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:43:06] [config] vocabs:
[2023-07-01 10:43:06] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 10:43:06] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 10:43:06] [config] word-penalty: 0
[2023-07-01 10:43:06] [config] word-scores: false
[2023-07-01 10:43:06] [config] workspace: 2048
[2023-07-01 10:43:06] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:43:06] Using synchronous SGD
[2023-07-01 10:43:07] Synced seed 1234
[2023-07-01 10:43:07] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 10:43:07] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 10:43:07] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 10:43:07] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 10:43:07] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 10:43:07] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 10:43:07] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 10:43:07] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 10:43:07] [comm] Using global sharding
[2023-07-01 10:43:08] [comm] NCCLCommunicators constructed successfully
[2023-07-01 10:43:08] [training] Using 1 GPUs
[2023-07-01 10:43:08] [logits] Applying loss function for 1 factor(s)
[2023-07-01 10:43:08] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:43:08] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 10:43:08] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:43:15] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 10:43:16] [valid] No post-processing script given for validating translator
[2023-07-01 10:43:16] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 10:43:16] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 10:43:16] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 10:43:16] [comm] Using global sharding
[2023-07-01 10:43:16] [comm] NCCLCommunicators constructed successfully
[2023-07-01 10:43:16] [training] Using 1 GPUs
[2023-07-01 10:43:16] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:43:16] Allocating memory for general optimizer shards
[2023-07-01 10:43:16] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:43:16] Loading Adam parameters
[2023-07-01 10:43:17] [memory] Reserving 176 MB, device gpu0
[2023-07-01 10:43:17] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:43:17] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 10:43:17] [data] Restoring the corpus state to epoch 36, batch 6615
[2023-07-01 10:43:17] [data] Shuffling data
[2023-07-01 10:43:17] [data] Done reading 20,192 sentences
[2023-07-01 10:43:17] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 10:43:17] Training started
[2023-07-01 10:43:17] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-07-01 10:43:17] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:43:17] Parameter type float32, optimization type float32, casting types false
[2023-07-01 10:43:40] Seen 20,073 samples
[2023-07-01 10:43:40] Starting data epoch 37 in logical epoch 37
[2023-07-01 10:43:40] Training finished
[2023-07-01 10:43:44] [valid] Ep. 37 : Up. 6804 : cross-entropy : 125.669 : new best
[2023-07-01 10:45:22] [valid] Ep. 37 : Up. 6804 : translation : 0 : new best
[2023-07-01 10:45:22] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:45:24] Saving Adam parameters
[2023-07-01 10:45:24] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 10:45:30] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:45:30] [marian] Running on node20.datos.cluster.uy as process 11234 with command line:
[2023-07-01 10:45:30] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 37 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 10:45:30] [config] after: 0e
[2023-07-01 10:45:30] [config] after-batches: 0
[2023-07-01 10:45:30] [config] after-epochs: 37
[2023-07-01 10:45:30] [config] all-caps-every: 0
[2023-07-01 10:45:30] [config] allow-unk: false
[2023-07-01 10:45:30] [config] authors: false
[2023-07-01 10:45:30] [config] beam-size: 12
[2023-07-01 10:45:30] [config] bert-class-symbol: "[CLS]"
[2023-07-01 10:45:30] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 10:45:30] [config] bert-masking-fraction: 0.15
[2023-07-01 10:45:30] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 10:45:30] [config] bert-train-type-embeddings: true
[2023-07-01 10:45:30] [config] bert-type-vocab-size: 2
[2023-07-01 10:45:30] [config] build-info: ""
[2023-07-01 10:45:30] [config] check-gradient-nan: false
[2023-07-01 10:45:30] [config] check-nan: false
[2023-07-01 10:45:30] [config] cite: false
[2023-07-01 10:45:30] [config] clip-norm: 5
[2023-07-01 10:45:30] [config] cost-scaling:
[2023-07-01 10:45:30] [config]   []
[2023-07-01 10:45:30] [config] cost-type: ce-sum
[2023-07-01 10:45:30] [config] cpu-threads: 0
[2023-07-01 10:45:30] [config] data-threads: 8
[2023-07-01 10:45:30] [config] data-weighting: ""
[2023-07-01 10:45:30] [config] data-weighting-type: sentence
[2023-07-01 10:45:30] [config] dec-cell: gru
[2023-07-01 10:45:30] [config] dec-cell-base-depth: 2
[2023-07-01 10:45:30] [config] dec-cell-high-depth: 1
[2023-07-01 10:45:30] [config] dec-depth: 2
[2023-07-01 10:45:30] [config] devices:
[2023-07-01 10:45:30] [config]   - 0
[2023-07-01 10:45:30] [config] dim-emb: 512
[2023-07-01 10:45:30] [config] dim-rnn: 1024
[2023-07-01 10:45:30] [config] dim-vocabs:
[2023-07-01 10:45:30] [config]   - 16384
[2023-07-01 10:45:30] [config]   - 16384
[2023-07-01 10:45:30] [config] disp-first: 0
[2023-07-01 10:45:30] [config] disp-freq: 1000u
[2023-07-01 10:45:30] [config] disp-label-counts: true
[2023-07-01 10:45:30] [config] dropout-rnn: 0
[2023-07-01 10:45:30] [config] dropout-src: 0
[2023-07-01 10:45:30] [config] dropout-trg: 0
[2023-07-01 10:45:30] [config] dump-config: ""
[2023-07-01 10:45:30] [config] dynamic-gradient-scaling:
[2023-07-01 10:45:30] [config]   []
[2023-07-01 10:45:30] [config] early-stopping: 10
[2023-07-01 10:45:30] [config] early-stopping-on: first
[2023-07-01 10:45:30] [config] embedding-fix-src: false
[2023-07-01 10:45:30] [config] embedding-fix-trg: false
[2023-07-01 10:45:30] [config] embedding-normalization: false
[2023-07-01 10:45:30] [config] embedding-vectors:
[2023-07-01 10:45:30] [config]   []
[2023-07-01 10:45:30] [config] enc-cell: gru
[2023-07-01 10:45:30] [config] enc-cell-depth: 1
[2023-07-01 10:45:30] [config] enc-depth: 2
[2023-07-01 10:45:30] [config] enc-type: bidirectional
[2023-07-01 10:45:30] [config] english-title-case-every: 0
[2023-07-01 10:45:30] [config] exponential-smoothing: 0.0001
[2023-07-01 10:45:30] [config] factor-weight: 1
[2023-07-01 10:45:30] [config] factors-combine: sum
[2023-07-01 10:45:30] [config] factors-dim-emb: 0
[2023-07-01 10:45:30] [config] gradient-checkpointing: false
[2023-07-01 10:45:30] [config] gradient-norm-average-window: 100
[2023-07-01 10:45:30] [config] guided-alignment: none
[2023-07-01 10:45:30] [config] guided-alignment-cost: mse
[2023-07-01 10:45:30] [config] guided-alignment-weight: 0.1
[2023-07-01 10:45:30] [config] ignore-model-config: false
[2023-07-01 10:45:30] [config] input-types:
[2023-07-01 10:45:30] [config]   []
[2023-07-01 10:45:30] [config] interpolate-env-vars: false
[2023-07-01 10:45:30] [config] keep-best: false
[2023-07-01 10:45:30] [config] label-smoothing: 0.1
[2023-07-01 10:45:30] [config] layer-normalization: false
[2023-07-01 10:45:30] [config] learn-rate: 0.0003
[2023-07-01 10:45:30] [config] lemma-dependency: ""
[2023-07-01 10:45:30] [config] lemma-dim-emb: 0
[2023-07-01 10:45:30] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 10:45:30] [config] log-level: info
[2023-07-01 10:45:30] [config] log-time-zone: ""
[2023-07-01 10:45:30] [config] logical-epoch:
[2023-07-01 10:45:30] [config]   - 1e
[2023-07-01 10:45:30] [config]   - 0
[2023-07-01 10:45:30] [config] lr-decay: 0
[2023-07-01 10:45:30] [config] lr-decay-freq: 50000
[2023-07-01 10:45:30] [config] lr-decay-inv-sqrt:
[2023-07-01 10:45:30] [config]   - 16000
[2023-07-01 10:45:30] [config] lr-decay-repeat-warmup: false
[2023-07-01 10:45:30] [config] lr-decay-reset-optimizer: false
[2023-07-01 10:45:30] [config] lr-decay-start:
[2023-07-01 10:45:30] [config]   - 10
[2023-07-01 10:45:30] [config]   - 1
[2023-07-01 10:45:30] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 10:45:30] [config] lr-report: true
[2023-07-01 10:45:30] [config] lr-warmup: 16000
[2023-07-01 10:45:30] [config] lr-warmup-at-reload: false
[2023-07-01 10:45:30] [config] lr-warmup-cycle: false
[2023-07-01 10:45:30] [config] lr-warmup-start-rate: 0
[2023-07-01 10:45:30] [config] max-length: 100
[2023-07-01 10:45:30] [config] max-length-crop: false
[2023-07-01 10:45:30] [config] max-length-factor: 3
[2023-07-01 10:45:30] [config] maxi-batch: 100
[2023-07-01 10:45:30] [config] maxi-batch-sort: trg
[2023-07-01 10:45:30] [config] mini-batch: 1000
[2023-07-01 10:45:30] [config] mini-batch-fit: true
[2023-07-01 10:45:30] [config] mini-batch-fit-step: 10
[2023-07-01 10:45:30] [config] mini-batch-round-up: true
[2023-07-01 10:45:30] [config] mini-batch-track-lr: false
[2023-07-01 10:45:30] [config] mini-batch-warmup: 0
[2023-07-01 10:45:30] [config] mini-batch-words: 0
[2023-07-01 10:45:30] [config] mini-batch-words-ref: 0
[2023-07-01 10:45:30] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:45:30] [config] multi-loss-type: sum
[2023-07-01 10:45:30] [config] n-best: false
[2023-07-01 10:45:30] [config] no-nccl: false
[2023-07-01 10:45:30] [config] no-reload: false
[2023-07-01 10:45:30] [config] no-restore-corpus: false
[2023-07-01 10:45:30] [config] normalize: 1
[2023-07-01 10:45:30] [config] normalize-gradient: false
[2023-07-01 10:45:30] [config] num-devices: 0
[2023-07-01 10:45:30] [config] optimizer: adam
[2023-07-01 10:45:30] [config] optimizer-delay: 1
[2023-07-01 10:45:30] [config] optimizer-params:
[2023-07-01 10:45:30] [config]   - 0.9
[2023-07-01 10:45:30] [config]   - 0.98
[2023-07-01 10:45:30] [config]   - 1e-09
[2023-07-01 10:45:30] [config] output-omit-bias: false
[2023-07-01 10:45:30] [config] overwrite: true
[2023-07-01 10:45:30] [config] precision:
[2023-07-01 10:45:30] [config]   - float32
[2023-07-01 10:45:30] [config]   - float32
[2023-07-01 10:45:30] [config] pretrained-model: ""
[2023-07-01 10:45:30] [config] quantize-biases: false
[2023-07-01 10:45:30] [config] quantize-bits: 0
[2023-07-01 10:45:30] [config] quantize-log-based: false
[2023-07-01 10:45:30] [config] quantize-optimization-steps: 0
[2023-07-01 10:45:30] [config] quiet: false
[2023-07-01 10:45:30] [config] quiet-translation: true
[2023-07-01 10:45:30] [config] relative-paths: false
[2023-07-01 10:45:30] [config] right-left: false
[2023-07-01 10:45:30] [config] save-freq: 10000u
[2023-07-01 10:45:30] [config] seed: 1234
[2023-07-01 10:45:30] [config] sentencepiece-alphas:
[2023-07-01 10:45:30] [config]   []
[2023-07-01 10:45:30] [config] sentencepiece-max-lines: 2000000
[2023-07-01 10:45:30] [config] sentencepiece-options: ""
[2023-07-01 10:45:30] [config] sharding: global
[2023-07-01 10:45:30] [config] shuffle: data
[2023-07-01 10:45:30] [config] shuffle-in-ram: false
[2023-07-01 10:45:30] [config] sigterm: save-and-exit
[2023-07-01 10:45:30] [config] skip: false
[2023-07-01 10:45:30] [config] sqlite: ""
[2023-07-01 10:45:30] [config] sqlite-drop: false
[2023-07-01 10:45:30] [config] sync-freq: 200u
[2023-07-01 10:45:30] [config] sync-sgd: true
[2023-07-01 10:45:30] [config] tempdir: /tmp
[2023-07-01 10:45:30] [config] tied-embeddings: false
[2023-07-01 10:45:30] [config] tied-embeddings-all: true
[2023-07-01 10:45:30] [config] tied-embeddings-src: false
[2023-07-01 10:45:30] [config] train-embedder-rank:
[2023-07-01 10:45:30] [config]   []
[2023-07-01 10:45:30] [config] train-sets:
[2023-07-01 10:45:30] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 10:45:30] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 10:45:30] [config] transformer-aan-activation: swish
[2023-07-01 10:45:30] [config] transformer-aan-depth: 2
[2023-07-01 10:45:30] [config] transformer-aan-nogate: false
[2023-07-01 10:45:30] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 10:45:30] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 10:45:30] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 10:45:30] [config] transformer-depth-scaling: false
[2023-07-01 10:45:30] [config] transformer-dim-aan: 2048
[2023-07-01 10:45:30] [config] transformer-dim-ffn: 2048
[2023-07-01 10:45:30] [config] transformer-dropout: 0.1
[2023-07-01 10:45:30] [config] transformer-dropout-attention: 0
[2023-07-01 10:45:30] [config] transformer-dropout-ffn: 0
[2023-07-01 10:45:30] [config] transformer-ffn-activation: swish
[2023-07-01 10:45:30] [config] transformer-ffn-depth: 2
[2023-07-01 10:45:30] [config] transformer-guided-alignment-layer: last
[2023-07-01 10:45:30] [config] transformer-heads: 8
[2023-07-01 10:45:30] [config] transformer-no-projection: false
[2023-07-01 10:45:30] [config] transformer-pool: false
[2023-07-01 10:45:30] [config] transformer-postprocess: dan
[2023-07-01 10:45:30] [config] transformer-postprocess-emb: d
[2023-07-01 10:45:30] [config] transformer-postprocess-top: ""
[2023-07-01 10:45:30] [config] transformer-preprocess: ""
[2023-07-01 10:45:30] [config] transformer-tied-layers:
[2023-07-01 10:45:30] [config]   []
[2023-07-01 10:45:30] [config] transformer-train-position-embeddings: false
[2023-07-01 10:45:30] [config] tsv: false
[2023-07-01 10:45:30] [config] tsv-fields: 0
[2023-07-01 10:45:30] [config] type: transformer
[2023-07-01 10:45:30] [config] ulr: false
[2023-07-01 10:45:30] [config] ulr-dim-emb: 0
[2023-07-01 10:45:30] [config] ulr-dropout: 0
[2023-07-01 10:45:30] [config] ulr-keys-vectors: ""
[2023-07-01 10:45:30] [config] ulr-query-vectors: ""
[2023-07-01 10:45:30] [config] ulr-softmax-temperature: 1
[2023-07-01 10:45:30] [config] ulr-trainable-transformation: false
[2023-07-01 10:45:30] [config] unlikelihood-loss: false
[2023-07-01 10:45:30] [config] valid-freq: 50000000
[2023-07-01 10:45:30] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 10:45:30] [config] valid-max-length: 1000
[2023-07-01 10:45:30] [config] valid-metrics:
[2023-07-01 10:45:30] [config]   - cross-entropy
[2023-07-01 10:45:30] [config]   - translation
[2023-07-01 10:45:30] [config] valid-mini-batch: 64
[2023-07-01 10:45:30] [config] valid-reset-stalled: false
[2023-07-01 10:45:30] [config] valid-script-args:
[2023-07-01 10:45:30] [config]   []
[2023-07-01 10:45:30] [config] valid-script-path: ""
[2023-07-01 10:45:30] [config] valid-sets:
[2023-07-01 10:45:30] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 10:45:30] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 10:45:30] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 10:45:30] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:45:30] [config] vocabs:
[2023-07-01 10:45:30] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 10:45:30] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 10:45:30] [config] word-penalty: 0
[2023-07-01 10:45:30] [config] word-scores: false
[2023-07-01 10:45:30] [config] workspace: 2048
[2023-07-01 10:45:30] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:45:30] Using synchronous SGD
[2023-07-01 10:45:30] Synced seed 1234
[2023-07-01 10:45:30] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 10:45:30] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 10:45:30] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 10:45:30] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 10:45:30] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 10:45:30] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 10:45:31] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 10:45:31] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 10:45:31] [comm] Using global sharding
[2023-07-01 10:45:31] [comm] NCCLCommunicators constructed successfully
[2023-07-01 10:45:31] [training] Using 1 GPUs
[2023-07-01 10:45:31] [logits] Applying loss function for 1 factor(s)
[2023-07-01 10:45:31] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:45:31] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 10:45:31] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:45:39] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 10:45:39] [valid] No post-processing script given for validating translator
[2023-07-01 10:45:39] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 10:45:39] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 10:45:39] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 10:45:39] [comm] Using global sharding
[2023-07-01 10:45:39] [comm] NCCLCommunicators constructed successfully
[2023-07-01 10:45:39] [training] Using 1 GPUs
[2023-07-01 10:45:39] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:45:40] Allocating memory for general optimizer shards
[2023-07-01 10:45:40] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:45:40] Loading Adam parameters
[2023-07-01 10:45:40] [memory] Reserving 176 MB, device gpu0
[2023-07-01 10:45:40] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:45:40] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 10:45:40] [data] Restoring the corpus state to epoch 37, batch 6804
[2023-07-01 10:45:40] [data] Shuffling data
[2023-07-01 10:45:40] [data] Done reading 20,192 sentences
[2023-07-01 10:45:40] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 10:45:40] Training started
[2023-07-01 10:45:40] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-07-01 10:45:40] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:45:41] Parameter type float32, optimization type float32, casting types false
[2023-07-01 10:46:04] Seen 20,073 samples
[2023-07-01 10:46:04] Starting data epoch 38 in logical epoch 38
[2023-07-01 10:46:04] Training finished
[2023-07-01 10:46:07] [valid] Ep. 38 : Up. 6993 : cross-entropy : 125.223 : new best
[2023-07-01 10:47:41] [valid] Ep. 38 : Up. 6993 : translation : 0 : new best
[2023-07-01 10:47:41] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:47:42] Saving Adam parameters
[2023-07-01 10:47:43] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 10:47:49] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:47:49] [marian] Running on node20.datos.cluster.uy as process 11405 with command line:
[2023-07-01 10:47:49] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 38 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 10:47:49] [config] after: 0e
[2023-07-01 10:47:49] [config] after-batches: 0
[2023-07-01 10:47:49] [config] after-epochs: 38
[2023-07-01 10:47:49] [config] all-caps-every: 0
[2023-07-01 10:47:49] [config] allow-unk: false
[2023-07-01 10:47:49] [config] authors: false
[2023-07-01 10:47:49] [config] beam-size: 12
[2023-07-01 10:47:49] [config] bert-class-symbol: "[CLS]"
[2023-07-01 10:47:49] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 10:47:49] [config] bert-masking-fraction: 0.15
[2023-07-01 10:47:49] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 10:47:49] [config] bert-train-type-embeddings: true
[2023-07-01 10:47:49] [config] bert-type-vocab-size: 2
[2023-07-01 10:47:49] [config] build-info: ""
[2023-07-01 10:47:49] [config] check-gradient-nan: false
[2023-07-01 10:47:49] [config] check-nan: false
[2023-07-01 10:47:49] [config] cite: false
[2023-07-01 10:47:49] [config] clip-norm: 5
[2023-07-01 10:47:49] [config] cost-scaling:
[2023-07-01 10:47:49] [config]   []
[2023-07-01 10:47:49] [config] cost-type: ce-sum
[2023-07-01 10:47:49] [config] cpu-threads: 0
[2023-07-01 10:47:49] [config] data-threads: 8
[2023-07-01 10:47:49] [config] data-weighting: ""
[2023-07-01 10:47:49] [config] data-weighting-type: sentence
[2023-07-01 10:47:49] [config] dec-cell: gru
[2023-07-01 10:47:49] [config] dec-cell-base-depth: 2
[2023-07-01 10:47:49] [config] dec-cell-high-depth: 1
[2023-07-01 10:47:49] [config] dec-depth: 2
[2023-07-01 10:47:49] [config] devices:
[2023-07-01 10:47:49] [config]   - 0
[2023-07-01 10:47:49] [config] dim-emb: 512
[2023-07-01 10:47:49] [config] dim-rnn: 1024
[2023-07-01 10:47:49] [config] dim-vocabs:
[2023-07-01 10:47:49] [config]   - 16384
[2023-07-01 10:47:49] [config]   - 16384
[2023-07-01 10:47:49] [config] disp-first: 0
[2023-07-01 10:47:49] [config] disp-freq: 1000u
[2023-07-01 10:47:49] [config] disp-label-counts: true
[2023-07-01 10:47:49] [config] dropout-rnn: 0
[2023-07-01 10:47:49] [config] dropout-src: 0
[2023-07-01 10:47:49] [config] dropout-trg: 0
[2023-07-01 10:47:49] [config] dump-config: ""
[2023-07-01 10:47:49] [config] dynamic-gradient-scaling:
[2023-07-01 10:47:49] [config]   []
[2023-07-01 10:47:49] [config] early-stopping: 10
[2023-07-01 10:47:49] [config] early-stopping-on: first
[2023-07-01 10:47:49] [config] embedding-fix-src: false
[2023-07-01 10:47:49] [config] embedding-fix-trg: false
[2023-07-01 10:47:49] [config] embedding-normalization: false
[2023-07-01 10:47:49] [config] embedding-vectors:
[2023-07-01 10:47:49] [config]   []
[2023-07-01 10:47:49] [config] enc-cell: gru
[2023-07-01 10:47:49] [config] enc-cell-depth: 1
[2023-07-01 10:47:49] [config] enc-depth: 2
[2023-07-01 10:47:49] [config] enc-type: bidirectional
[2023-07-01 10:47:49] [config] english-title-case-every: 0
[2023-07-01 10:47:49] [config] exponential-smoothing: 0.0001
[2023-07-01 10:47:49] [config] factor-weight: 1
[2023-07-01 10:47:49] [config] factors-combine: sum
[2023-07-01 10:47:49] [config] factors-dim-emb: 0
[2023-07-01 10:47:49] [config] gradient-checkpointing: false
[2023-07-01 10:47:49] [config] gradient-norm-average-window: 100
[2023-07-01 10:47:49] [config] guided-alignment: none
[2023-07-01 10:47:49] [config] guided-alignment-cost: mse
[2023-07-01 10:47:49] [config] guided-alignment-weight: 0.1
[2023-07-01 10:47:49] [config] ignore-model-config: false
[2023-07-01 10:47:49] [config] input-types:
[2023-07-01 10:47:49] [config]   []
[2023-07-01 10:47:49] [config] interpolate-env-vars: false
[2023-07-01 10:47:49] [config] keep-best: false
[2023-07-01 10:47:49] [config] label-smoothing: 0.1
[2023-07-01 10:47:49] [config] layer-normalization: false
[2023-07-01 10:47:49] [config] learn-rate: 0.0003
[2023-07-01 10:47:49] [config] lemma-dependency: ""
[2023-07-01 10:47:49] [config] lemma-dim-emb: 0
[2023-07-01 10:47:49] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 10:47:49] [config] log-level: info
[2023-07-01 10:47:49] [config] log-time-zone: ""
[2023-07-01 10:47:49] [config] logical-epoch:
[2023-07-01 10:47:49] [config]   - 1e
[2023-07-01 10:47:49] [config]   - 0
[2023-07-01 10:47:49] [config] lr-decay: 0
[2023-07-01 10:47:49] [config] lr-decay-freq: 50000
[2023-07-01 10:47:49] [config] lr-decay-inv-sqrt:
[2023-07-01 10:47:49] [config]   - 16000
[2023-07-01 10:47:49] [config] lr-decay-repeat-warmup: false
[2023-07-01 10:47:49] [config] lr-decay-reset-optimizer: false
[2023-07-01 10:47:49] [config] lr-decay-start:
[2023-07-01 10:47:49] [config]   - 10
[2023-07-01 10:47:49] [config]   - 1
[2023-07-01 10:47:49] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 10:47:49] [config] lr-report: true
[2023-07-01 10:47:49] [config] lr-warmup: 16000
[2023-07-01 10:47:49] [config] lr-warmup-at-reload: false
[2023-07-01 10:47:49] [config] lr-warmup-cycle: false
[2023-07-01 10:47:49] [config] lr-warmup-start-rate: 0
[2023-07-01 10:47:49] [config] max-length: 100
[2023-07-01 10:47:49] [config] max-length-crop: false
[2023-07-01 10:47:49] [config] max-length-factor: 3
[2023-07-01 10:47:49] [config] maxi-batch: 100
[2023-07-01 10:47:49] [config] maxi-batch-sort: trg
[2023-07-01 10:47:49] [config] mini-batch: 1000
[2023-07-01 10:47:49] [config] mini-batch-fit: true
[2023-07-01 10:47:49] [config] mini-batch-fit-step: 10
[2023-07-01 10:47:49] [config] mini-batch-round-up: true
[2023-07-01 10:47:49] [config] mini-batch-track-lr: false
[2023-07-01 10:47:49] [config] mini-batch-warmup: 0
[2023-07-01 10:47:49] [config] mini-batch-words: 0
[2023-07-01 10:47:49] [config] mini-batch-words-ref: 0
[2023-07-01 10:47:49] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:47:49] [config] multi-loss-type: sum
[2023-07-01 10:47:49] [config] n-best: false
[2023-07-01 10:47:49] [config] no-nccl: false
[2023-07-01 10:47:49] [config] no-reload: false
[2023-07-01 10:47:49] [config] no-restore-corpus: false
[2023-07-01 10:47:49] [config] normalize: 1
[2023-07-01 10:47:49] [config] normalize-gradient: false
[2023-07-01 10:47:49] [config] num-devices: 0
[2023-07-01 10:47:49] [config] optimizer: adam
[2023-07-01 10:47:49] [config] optimizer-delay: 1
[2023-07-01 10:47:49] [config] optimizer-params:
[2023-07-01 10:47:49] [config]   - 0.9
[2023-07-01 10:47:49] [config]   - 0.98
[2023-07-01 10:47:49] [config]   - 1e-09
[2023-07-01 10:47:49] [config] output-omit-bias: false
[2023-07-01 10:47:49] [config] overwrite: true
[2023-07-01 10:47:49] [config] precision:
[2023-07-01 10:47:49] [config]   - float32
[2023-07-01 10:47:49] [config]   - float32
[2023-07-01 10:47:49] [config] pretrained-model: ""
[2023-07-01 10:47:49] [config] quantize-biases: false
[2023-07-01 10:47:49] [config] quantize-bits: 0
[2023-07-01 10:47:49] [config] quantize-log-based: false
[2023-07-01 10:47:49] [config] quantize-optimization-steps: 0
[2023-07-01 10:47:49] [config] quiet: false
[2023-07-01 10:47:49] [config] quiet-translation: true
[2023-07-01 10:47:49] [config] relative-paths: false
[2023-07-01 10:47:49] [config] right-left: false
[2023-07-01 10:47:49] [config] save-freq: 10000u
[2023-07-01 10:47:49] [config] seed: 1234
[2023-07-01 10:47:49] [config] sentencepiece-alphas:
[2023-07-01 10:47:49] [config]   []
[2023-07-01 10:47:49] [config] sentencepiece-max-lines: 2000000
[2023-07-01 10:47:49] [config] sentencepiece-options: ""
[2023-07-01 10:47:49] [config] sharding: global
[2023-07-01 10:47:49] [config] shuffle: data
[2023-07-01 10:47:49] [config] shuffle-in-ram: false
[2023-07-01 10:47:49] [config] sigterm: save-and-exit
[2023-07-01 10:47:49] [config] skip: false
[2023-07-01 10:47:49] [config] sqlite: ""
[2023-07-01 10:47:49] [config] sqlite-drop: false
[2023-07-01 10:47:49] [config] sync-freq: 200u
[2023-07-01 10:47:49] [config] sync-sgd: true
[2023-07-01 10:47:49] [config] tempdir: /tmp
[2023-07-01 10:47:49] [config] tied-embeddings: false
[2023-07-01 10:47:49] [config] tied-embeddings-all: true
[2023-07-01 10:47:49] [config] tied-embeddings-src: false
[2023-07-01 10:47:49] [config] train-embedder-rank:
[2023-07-01 10:47:49] [config]   []
[2023-07-01 10:47:49] [config] train-sets:
[2023-07-01 10:47:49] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 10:47:49] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 10:47:49] [config] transformer-aan-activation: swish
[2023-07-01 10:47:49] [config] transformer-aan-depth: 2
[2023-07-01 10:47:49] [config] transformer-aan-nogate: false
[2023-07-01 10:47:49] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 10:47:49] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 10:47:49] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 10:47:49] [config] transformer-depth-scaling: false
[2023-07-01 10:47:49] [config] transformer-dim-aan: 2048
[2023-07-01 10:47:49] [config] transformer-dim-ffn: 2048
[2023-07-01 10:47:49] [config] transformer-dropout: 0.1
[2023-07-01 10:47:49] [config] transformer-dropout-attention: 0
[2023-07-01 10:47:49] [config] transformer-dropout-ffn: 0
[2023-07-01 10:47:49] [config] transformer-ffn-activation: swish
[2023-07-01 10:47:49] [config] transformer-ffn-depth: 2
[2023-07-01 10:47:49] [config] transformer-guided-alignment-layer: last
[2023-07-01 10:47:49] [config] transformer-heads: 8
[2023-07-01 10:47:49] [config] transformer-no-projection: false
[2023-07-01 10:47:49] [config] transformer-pool: false
[2023-07-01 10:47:49] [config] transformer-postprocess: dan
[2023-07-01 10:47:49] [config] transformer-postprocess-emb: d
[2023-07-01 10:47:49] [config] transformer-postprocess-top: ""
[2023-07-01 10:47:49] [config] transformer-preprocess: ""
[2023-07-01 10:47:49] [config] transformer-tied-layers:
[2023-07-01 10:47:49] [config]   []
[2023-07-01 10:47:49] [config] transformer-train-position-embeddings: false
[2023-07-01 10:47:49] [config] tsv: false
[2023-07-01 10:47:49] [config] tsv-fields: 0
[2023-07-01 10:47:49] [config] type: transformer
[2023-07-01 10:47:49] [config] ulr: false
[2023-07-01 10:47:49] [config] ulr-dim-emb: 0
[2023-07-01 10:47:49] [config] ulr-dropout: 0
[2023-07-01 10:47:49] [config] ulr-keys-vectors: ""
[2023-07-01 10:47:49] [config] ulr-query-vectors: ""
[2023-07-01 10:47:49] [config] ulr-softmax-temperature: 1
[2023-07-01 10:47:49] [config] ulr-trainable-transformation: false
[2023-07-01 10:47:49] [config] unlikelihood-loss: false
[2023-07-01 10:47:49] [config] valid-freq: 50000000
[2023-07-01 10:47:49] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 10:47:49] [config] valid-max-length: 1000
[2023-07-01 10:47:49] [config] valid-metrics:
[2023-07-01 10:47:49] [config]   - cross-entropy
[2023-07-01 10:47:49] [config]   - translation
[2023-07-01 10:47:49] [config] valid-mini-batch: 64
[2023-07-01 10:47:49] [config] valid-reset-stalled: false
[2023-07-01 10:47:49] [config] valid-script-args:
[2023-07-01 10:47:49] [config]   []
[2023-07-01 10:47:49] [config] valid-script-path: ""
[2023-07-01 10:47:49] [config] valid-sets:
[2023-07-01 10:47:49] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 10:47:49] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 10:47:49] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 10:47:49] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:47:49] [config] vocabs:
[2023-07-01 10:47:49] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 10:47:49] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 10:47:49] [config] word-penalty: 0
[2023-07-01 10:47:49] [config] word-scores: false
[2023-07-01 10:47:49] [config] workspace: 2048
[2023-07-01 10:47:49] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:47:49] Using synchronous SGD
[2023-07-01 10:47:49] Synced seed 1234
[2023-07-01 10:47:49] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 10:47:49] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 10:47:49] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 10:47:49] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 10:47:49] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 10:47:49] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 10:47:50] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 10:47:50] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 10:47:50] [comm] Using global sharding
[2023-07-01 10:47:50] [comm] NCCLCommunicators constructed successfully
[2023-07-01 10:47:50] [training] Using 1 GPUs
[2023-07-01 10:47:50] [logits] Applying loss function for 1 factor(s)
[2023-07-01 10:47:50] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:47:50] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 10:47:51] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:47:58] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 10:47:58] [valid] No post-processing script given for validating translator
[2023-07-01 10:47:58] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 10:47:58] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 10:47:58] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 10:47:58] [comm] Using global sharding
[2023-07-01 10:47:58] [comm] NCCLCommunicators constructed successfully
[2023-07-01 10:47:58] [training] Using 1 GPUs
[2023-07-01 10:47:58] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:47:59] Allocating memory for general optimizer shards
[2023-07-01 10:47:59] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:47:59] Loading Adam parameters
[2023-07-01 10:47:59] [memory] Reserving 176 MB, device gpu0
[2023-07-01 10:47:59] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:47:59] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 10:47:59] [data] Restoring the corpus state to epoch 38, batch 6993
[2023-07-01 10:47:59] [data] Shuffling data
[2023-07-01 10:47:59] [data] Done reading 20,192 sentences
[2023-07-01 10:47:59] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 10:47:59] Training started
[2023-07-01 10:47:59] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-07-01 10:47:59] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:47:59] Parameter type float32, optimization type float32, casting types false
[2023-07-01 10:48:00] Ep. 38 : Up. 7000 : Sen. 736 : Cost 3.91452408 * 3,207,334 @ 3,333 after 22,463,663 : Time 2.11s : 1518050.54 words/s : gNorm 1.7097 : L.r. 1.3125e-04
[2023-07-01 10:48:23] Seen 20,073 samples
[2023-07-01 10:48:23] Starting data epoch 39 in logical epoch 39
[2023-07-01 10:48:23] Training finished
[2023-07-01 10:48:27] [valid] Ep. 39 : Up. 7182 : cross-entropy : 124.879 : new best
[2023-07-01 10:49:59] [valid] Ep. 39 : Up. 7182 : translation : 0 : new best
[2023-07-01 10:49:59] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:50:00] Saving Adam parameters
[2023-07-01 10:50:01] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 10:50:06] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:50:06] [marian] Running on node20.datos.cluster.uy as process 11575 with command line:
[2023-07-01 10:50:06] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 39 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 10:50:06] [config] after: 0e
[2023-07-01 10:50:06] [config] after-batches: 0
[2023-07-01 10:50:06] [config] after-epochs: 39
[2023-07-01 10:50:06] [config] all-caps-every: 0
[2023-07-01 10:50:06] [config] allow-unk: false
[2023-07-01 10:50:06] [config] authors: false
[2023-07-01 10:50:06] [config] beam-size: 12
[2023-07-01 10:50:06] [config] bert-class-symbol: "[CLS]"
[2023-07-01 10:50:06] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 10:50:06] [config] bert-masking-fraction: 0.15
[2023-07-01 10:50:06] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 10:50:06] [config] bert-train-type-embeddings: true
[2023-07-01 10:50:06] [config] bert-type-vocab-size: 2
[2023-07-01 10:50:06] [config] build-info: ""
[2023-07-01 10:50:06] [config] check-gradient-nan: false
[2023-07-01 10:50:06] [config] check-nan: false
[2023-07-01 10:50:06] [config] cite: false
[2023-07-01 10:50:06] [config] clip-norm: 5
[2023-07-01 10:50:06] [config] cost-scaling:
[2023-07-01 10:50:06] [config]   []
[2023-07-01 10:50:06] [config] cost-type: ce-sum
[2023-07-01 10:50:06] [config] cpu-threads: 0
[2023-07-01 10:50:06] [config] data-threads: 8
[2023-07-01 10:50:06] [config] data-weighting: ""
[2023-07-01 10:50:06] [config] data-weighting-type: sentence
[2023-07-01 10:50:06] [config] dec-cell: gru
[2023-07-01 10:50:06] [config] dec-cell-base-depth: 2
[2023-07-01 10:50:06] [config] dec-cell-high-depth: 1
[2023-07-01 10:50:06] [config] dec-depth: 2
[2023-07-01 10:50:06] [config] devices:
[2023-07-01 10:50:06] [config]   - 0
[2023-07-01 10:50:06] [config] dim-emb: 512
[2023-07-01 10:50:06] [config] dim-rnn: 1024
[2023-07-01 10:50:06] [config] dim-vocabs:
[2023-07-01 10:50:06] [config]   - 16384
[2023-07-01 10:50:06] [config]   - 16384
[2023-07-01 10:50:06] [config] disp-first: 0
[2023-07-01 10:50:06] [config] disp-freq: 1000u
[2023-07-01 10:50:06] [config] disp-label-counts: true
[2023-07-01 10:50:06] [config] dropout-rnn: 0
[2023-07-01 10:50:06] [config] dropout-src: 0
[2023-07-01 10:50:06] [config] dropout-trg: 0
[2023-07-01 10:50:06] [config] dump-config: ""
[2023-07-01 10:50:06] [config] dynamic-gradient-scaling:
[2023-07-01 10:50:06] [config]   []
[2023-07-01 10:50:06] [config] early-stopping: 10
[2023-07-01 10:50:06] [config] early-stopping-on: first
[2023-07-01 10:50:06] [config] embedding-fix-src: false
[2023-07-01 10:50:06] [config] embedding-fix-trg: false
[2023-07-01 10:50:06] [config] embedding-normalization: false
[2023-07-01 10:50:06] [config] embedding-vectors:
[2023-07-01 10:50:06] [config]   []
[2023-07-01 10:50:06] [config] enc-cell: gru
[2023-07-01 10:50:06] [config] enc-cell-depth: 1
[2023-07-01 10:50:06] [config] enc-depth: 2
[2023-07-01 10:50:06] [config] enc-type: bidirectional
[2023-07-01 10:50:06] [config] english-title-case-every: 0
[2023-07-01 10:50:06] [config] exponential-smoothing: 0.0001
[2023-07-01 10:50:06] [config] factor-weight: 1
[2023-07-01 10:50:06] [config] factors-combine: sum
[2023-07-01 10:50:06] [config] factors-dim-emb: 0
[2023-07-01 10:50:06] [config] gradient-checkpointing: false
[2023-07-01 10:50:06] [config] gradient-norm-average-window: 100
[2023-07-01 10:50:06] [config] guided-alignment: none
[2023-07-01 10:50:06] [config] guided-alignment-cost: mse
[2023-07-01 10:50:06] [config] guided-alignment-weight: 0.1
[2023-07-01 10:50:06] [config] ignore-model-config: false
[2023-07-01 10:50:06] [config] input-types:
[2023-07-01 10:50:06] [config]   []
[2023-07-01 10:50:06] [config] interpolate-env-vars: false
[2023-07-01 10:50:06] [config] keep-best: false
[2023-07-01 10:50:06] [config] label-smoothing: 0.1
[2023-07-01 10:50:06] [config] layer-normalization: false
[2023-07-01 10:50:06] [config] learn-rate: 0.0003
[2023-07-01 10:50:06] [config] lemma-dependency: ""
[2023-07-01 10:50:06] [config] lemma-dim-emb: 0
[2023-07-01 10:50:06] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 10:50:06] [config] log-level: info
[2023-07-01 10:50:06] [config] log-time-zone: ""
[2023-07-01 10:50:06] [config] logical-epoch:
[2023-07-01 10:50:06] [config]   - 1e
[2023-07-01 10:50:06] [config]   - 0
[2023-07-01 10:50:06] [config] lr-decay: 0
[2023-07-01 10:50:06] [config] lr-decay-freq: 50000
[2023-07-01 10:50:06] [config] lr-decay-inv-sqrt:
[2023-07-01 10:50:06] [config]   - 16000
[2023-07-01 10:50:06] [config] lr-decay-repeat-warmup: false
[2023-07-01 10:50:06] [config] lr-decay-reset-optimizer: false
[2023-07-01 10:50:06] [config] lr-decay-start:
[2023-07-01 10:50:06] [config]   - 10
[2023-07-01 10:50:06] [config]   - 1
[2023-07-01 10:50:06] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 10:50:06] [config] lr-report: true
[2023-07-01 10:50:06] [config] lr-warmup: 16000
[2023-07-01 10:50:06] [config] lr-warmup-at-reload: false
[2023-07-01 10:50:06] [config] lr-warmup-cycle: false
[2023-07-01 10:50:06] [config] lr-warmup-start-rate: 0
[2023-07-01 10:50:06] [config] max-length: 100
[2023-07-01 10:50:06] [config] max-length-crop: false
[2023-07-01 10:50:06] [config] max-length-factor: 3
[2023-07-01 10:50:06] [config] maxi-batch: 100
[2023-07-01 10:50:06] [config] maxi-batch-sort: trg
[2023-07-01 10:50:06] [config] mini-batch: 1000
[2023-07-01 10:50:06] [config] mini-batch-fit: true
[2023-07-01 10:50:06] [config] mini-batch-fit-step: 10
[2023-07-01 10:50:06] [config] mini-batch-round-up: true
[2023-07-01 10:50:06] [config] mini-batch-track-lr: false
[2023-07-01 10:50:06] [config] mini-batch-warmup: 0
[2023-07-01 10:50:06] [config] mini-batch-words: 0
[2023-07-01 10:50:06] [config] mini-batch-words-ref: 0
[2023-07-01 10:50:06] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:50:06] [config] multi-loss-type: sum
[2023-07-01 10:50:06] [config] n-best: false
[2023-07-01 10:50:06] [config] no-nccl: false
[2023-07-01 10:50:06] [config] no-reload: false
[2023-07-01 10:50:06] [config] no-restore-corpus: false
[2023-07-01 10:50:06] [config] normalize: 1
[2023-07-01 10:50:06] [config] normalize-gradient: false
[2023-07-01 10:50:06] [config] num-devices: 0
[2023-07-01 10:50:06] [config] optimizer: adam
[2023-07-01 10:50:06] [config] optimizer-delay: 1
[2023-07-01 10:50:06] [config] optimizer-params:
[2023-07-01 10:50:06] [config]   - 0.9
[2023-07-01 10:50:06] [config]   - 0.98
[2023-07-01 10:50:06] [config]   - 1e-09
[2023-07-01 10:50:06] [config] output-omit-bias: false
[2023-07-01 10:50:06] [config] overwrite: true
[2023-07-01 10:50:06] [config] precision:
[2023-07-01 10:50:06] [config]   - float32
[2023-07-01 10:50:06] [config]   - float32
[2023-07-01 10:50:06] [config] pretrained-model: ""
[2023-07-01 10:50:06] [config] quantize-biases: false
[2023-07-01 10:50:06] [config] quantize-bits: 0
[2023-07-01 10:50:06] [config] quantize-log-based: false
[2023-07-01 10:50:06] [config] quantize-optimization-steps: 0
[2023-07-01 10:50:06] [config] quiet: false
[2023-07-01 10:50:06] [config] quiet-translation: true
[2023-07-01 10:50:06] [config] relative-paths: false
[2023-07-01 10:50:06] [config] right-left: false
[2023-07-01 10:50:06] [config] save-freq: 10000u
[2023-07-01 10:50:06] [config] seed: 1234
[2023-07-01 10:50:06] [config] sentencepiece-alphas:
[2023-07-01 10:50:06] [config]   []
[2023-07-01 10:50:06] [config] sentencepiece-max-lines: 2000000
[2023-07-01 10:50:06] [config] sentencepiece-options: ""
[2023-07-01 10:50:06] [config] sharding: global
[2023-07-01 10:50:06] [config] shuffle: data
[2023-07-01 10:50:06] [config] shuffle-in-ram: false
[2023-07-01 10:50:06] [config] sigterm: save-and-exit
[2023-07-01 10:50:06] [config] skip: false
[2023-07-01 10:50:06] [config] sqlite: ""
[2023-07-01 10:50:06] [config] sqlite-drop: false
[2023-07-01 10:50:06] [config] sync-freq: 200u
[2023-07-01 10:50:06] [config] sync-sgd: true
[2023-07-01 10:50:06] [config] tempdir: /tmp
[2023-07-01 10:50:06] [config] tied-embeddings: false
[2023-07-01 10:50:06] [config] tied-embeddings-all: true
[2023-07-01 10:50:06] [config] tied-embeddings-src: false
[2023-07-01 10:50:06] [config] train-embedder-rank:
[2023-07-01 10:50:06] [config]   []
[2023-07-01 10:50:06] [config] train-sets:
[2023-07-01 10:50:06] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 10:50:06] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 10:50:06] [config] transformer-aan-activation: swish
[2023-07-01 10:50:06] [config] transformer-aan-depth: 2
[2023-07-01 10:50:06] [config] transformer-aan-nogate: false
[2023-07-01 10:50:06] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 10:50:06] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 10:50:06] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 10:50:06] [config] transformer-depth-scaling: false
[2023-07-01 10:50:06] [config] transformer-dim-aan: 2048
[2023-07-01 10:50:06] [config] transformer-dim-ffn: 2048
[2023-07-01 10:50:06] [config] transformer-dropout: 0.1
[2023-07-01 10:50:06] [config] transformer-dropout-attention: 0
[2023-07-01 10:50:06] [config] transformer-dropout-ffn: 0
[2023-07-01 10:50:06] [config] transformer-ffn-activation: swish
[2023-07-01 10:50:06] [config] transformer-ffn-depth: 2
[2023-07-01 10:50:06] [config] transformer-guided-alignment-layer: last
[2023-07-01 10:50:06] [config] transformer-heads: 8
[2023-07-01 10:50:06] [config] transformer-no-projection: false
[2023-07-01 10:50:06] [config] transformer-pool: false
[2023-07-01 10:50:06] [config] transformer-postprocess: dan
[2023-07-01 10:50:06] [config] transformer-postprocess-emb: d
[2023-07-01 10:50:06] [config] transformer-postprocess-top: ""
[2023-07-01 10:50:06] [config] transformer-preprocess: ""
[2023-07-01 10:50:06] [config] transformer-tied-layers:
[2023-07-01 10:50:06] [config]   []
[2023-07-01 10:50:06] [config] transformer-train-position-embeddings: false
[2023-07-01 10:50:06] [config] tsv: false
[2023-07-01 10:50:06] [config] tsv-fields: 0
[2023-07-01 10:50:06] [config] type: transformer
[2023-07-01 10:50:06] [config] ulr: false
[2023-07-01 10:50:06] [config] ulr-dim-emb: 0
[2023-07-01 10:50:06] [config] ulr-dropout: 0
[2023-07-01 10:50:06] [config] ulr-keys-vectors: ""
[2023-07-01 10:50:06] [config] ulr-query-vectors: ""
[2023-07-01 10:50:06] [config] ulr-softmax-temperature: 1
[2023-07-01 10:50:06] [config] ulr-trainable-transformation: false
[2023-07-01 10:50:06] [config] unlikelihood-loss: false
[2023-07-01 10:50:06] [config] valid-freq: 50000000
[2023-07-01 10:50:06] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 10:50:06] [config] valid-max-length: 1000
[2023-07-01 10:50:06] [config] valid-metrics:
[2023-07-01 10:50:06] [config]   - cross-entropy
[2023-07-01 10:50:06] [config]   - translation
[2023-07-01 10:50:06] [config] valid-mini-batch: 64
[2023-07-01 10:50:06] [config] valid-reset-stalled: false
[2023-07-01 10:50:06] [config] valid-script-args:
[2023-07-01 10:50:06] [config]   []
[2023-07-01 10:50:06] [config] valid-script-path: ""
[2023-07-01 10:50:06] [config] valid-sets:
[2023-07-01 10:50:06] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 10:50:06] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 10:50:06] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 10:50:06] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:50:06] [config] vocabs:
[2023-07-01 10:50:06] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 10:50:06] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 10:50:06] [config] word-penalty: 0
[2023-07-01 10:50:06] [config] word-scores: false
[2023-07-01 10:50:06] [config] workspace: 2048
[2023-07-01 10:50:06] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:50:06] Using synchronous SGD
[2023-07-01 10:50:07] Synced seed 1234
[2023-07-01 10:50:07] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 10:50:07] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 10:50:07] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 10:50:07] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 10:50:07] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 10:50:07] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 10:50:08] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 10:50:08] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 10:50:08] [comm] Using global sharding
[2023-07-01 10:50:08] [comm] NCCLCommunicators constructed successfully
[2023-07-01 10:50:08] [training] Using 1 GPUs
[2023-07-01 10:50:08] [logits] Applying loss function for 1 factor(s)
[2023-07-01 10:50:08] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:50:08] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 10:50:08] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:50:16] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 10:50:16] [valid] No post-processing script given for validating translator
[2023-07-01 10:50:16] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 10:50:16] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 10:50:16] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 10:50:16] [comm] Using global sharding
[2023-07-01 10:50:16] [comm] NCCLCommunicators constructed successfully
[2023-07-01 10:50:16] [training] Using 1 GPUs
[2023-07-01 10:50:16] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:50:17] Allocating memory for general optimizer shards
[2023-07-01 10:50:17] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:50:17] Loading Adam parameters
[2023-07-01 10:50:17] [memory] Reserving 176 MB, device gpu0
[2023-07-01 10:50:17] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:50:17] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 10:50:17] [data] Restoring the corpus state to epoch 39, batch 7182
[2023-07-01 10:50:17] [data] Shuffling data
[2023-07-01 10:50:17] [data] Done reading 20,192 sentences
[2023-07-01 10:50:17] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 10:50:17] Training started
[2023-07-01 10:50:17] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-07-01 10:50:17] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:50:17] Parameter type float32, optimization type float32, casting types false
[2023-07-01 10:50:41] Seen 20,073 samples
[2023-07-01 10:50:41] Starting data epoch 40 in logical epoch 40
[2023-07-01 10:50:41] Training finished
[2023-07-01 10:50:44] [valid] Ep. 40 : Up. 7371 : cross-entropy : 124.6 : new best
[2023-07-01 10:52:16] [valid] Ep. 40 : Up. 7371 : translation : 0 : new best
[2023-07-01 10:52:16] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:52:17] Saving Adam parameters
[2023-07-01 10:52:18] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 10:52:24] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:52:24] [marian] Running on node20.datos.cluster.uy as process 11748 with command line:
[2023-07-01 10:52:24] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 40 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 10:52:24] [config] after: 0e
[2023-07-01 10:52:24] [config] after-batches: 0
[2023-07-01 10:52:24] [config] after-epochs: 40
[2023-07-01 10:52:24] [config] all-caps-every: 0
[2023-07-01 10:52:24] [config] allow-unk: false
[2023-07-01 10:52:24] [config] authors: false
[2023-07-01 10:52:24] [config] beam-size: 12
[2023-07-01 10:52:24] [config] bert-class-symbol: "[CLS]"
[2023-07-01 10:52:24] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 10:52:24] [config] bert-masking-fraction: 0.15
[2023-07-01 10:52:24] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 10:52:24] [config] bert-train-type-embeddings: true
[2023-07-01 10:52:24] [config] bert-type-vocab-size: 2
[2023-07-01 10:52:24] [config] build-info: ""
[2023-07-01 10:52:24] [config] check-gradient-nan: false
[2023-07-01 10:52:24] [config] check-nan: false
[2023-07-01 10:52:24] [config] cite: false
[2023-07-01 10:52:24] [config] clip-norm: 5
[2023-07-01 10:52:24] [config] cost-scaling:
[2023-07-01 10:52:24] [config]   []
[2023-07-01 10:52:24] [config] cost-type: ce-sum
[2023-07-01 10:52:24] [config] cpu-threads: 0
[2023-07-01 10:52:24] [config] data-threads: 8
[2023-07-01 10:52:24] [config] data-weighting: ""
[2023-07-01 10:52:24] [config] data-weighting-type: sentence
[2023-07-01 10:52:24] [config] dec-cell: gru
[2023-07-01 10:52:24] [config] dec-cell-base-depth: 2
[2023-07-01 10:52:24] [config] dec-cell-high-depth: 1
[2023-07-01 10:52:24] [config] dec-depth: 2
[2023-07-01 10:52:24] [config] devices:
[2023-07-01 10:52:24] [config]   - 0
[2023-07-01 10:52:24] [config] dim-emb: 512
[2023-07-01 10:52:24] [config] dim-rnn: 1024
[2023-07-01 10:52:24] [config] dim-vocabs:
[2023-07-01 10:52:24] [config]   - 16384
[2023-07-01 10:52:24] [config]   - 16384
[2023-07-01 10:52:24] [config] disp-first: 0
[2023-07-01 10:52:24] [config] disp-freq: 1000u
[2023-07-01 10:52:24] [config] disp-label-counts: true
[2023-07-01 10:52:24] [config] dropout-rnn: 0
[2023-07-01 10:52:24] [config] dropout-src: 0
[2023-07-01 10:52:24] [config] dropout-trg: 0
[2023-07-01 10:52:24] [config] dump-config: ""
[2023-07-01 10:52:24] [config] dynamic-gradient-scaling:
[2023-07-01 10:52:24] [config]   []
[2023-07-01 10:52:24] [config] early-stopping: 10
[2023-07-01 10:52:24] [config] early-stopping-on: first
[2023-07-01 10:52:24] [config] embedding-fix-src: false
[2023-07-01 10:52:24] [config] embedding-fix-trg: false
[2023-07-01 10:52:24] [config] embedding-normalization: false
[2023-07-01 10:52:24] [config] embedding-vectors:
[2023-07-01 10:52:24] [config]   []
[2023-07-01 10:52:24] [config] enc-cell: gru
[2023-07-01 10:52:24] [config] enc-cell-depth: 1
[2023-07-01 10:52:24] [config] enc-depth: 2
[2023-07-01 10:52:24] [config] enc-type: bidirectional
[2023-07-01 10:52:24] [config] english-title-case-every: 0
[2023-07-01 10:52:24] [config] exponential-smoothing: 0.0001
[2023-07-01 10:52:24] [config] factor-weight: 1
[2023-07-01 10:52:24] [config] factors-combine: sum
[2023-07-01 10:52:24] [config] factors-dim-emb: 0
[2023-07-01 10:52:24] [config] gradient-checkpointing: false
[2023-07-01 10:52:24] [config] gradient-norm-average-window: 100
[2023-07-01 10:52:24] [config] guided-alignment: none
[2023-07-01 10:52:24] [config] guided-alignment-cost: mse
[2023-07-01 10:52:24] [config] guided-alignment-weight: 0.1
[2023-07-01 10:52:24] [config] ignore-model-config: false
[2023-07-01 10:52:24] [config] input-types:
[2023-07-01 10:52:24] [config]   []
[2023-07-01 10:52:24] [config] interpolate-env-vars: false
[2023-07-01 10:52:24] [config] keep-best: false
[2023-07-01 10:52:24] [config] label-smoothing: 0.1
[2023-07-01 10:52:24] [config] layer-normalization: false
[2023-07-01 10:52:24] [config] learn-rate: 0.0003
[2023-07-01 10:52:24] [config] lemma-dependency: ""
[2023-07-01 10:52:24] [config] lemma-dim-emb: 0
[2023-07-01 10:52:24] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 10:52:24] [config] log-level: info
[2023-07-01 10:52:24] [config] log-time-zone: ""
[2023-07-01 10:52:24] [config] logical-epoch:
[2023-07-01 10:52:24] [config]   - 1e
[2023-07-01 10:52:24] [config]   - 0
[2023-07-01 10:52:24] [config] lr-decay: 0
[2023-07-01 10:52:24] [config] lr-decay-freq: 50000
[2023-07-01 10:52:24] [config] lr-decay-inv-sqrt:
[2023-07-01 10:52:24] [config]   - 16000
[2023-07-01 10:52:24] [config] lr-decay-repeat-warmup: false
[2023-07-01 10:52:24] [config] lr-decay-reset-optimizer: false
[2023-07-01 10:52:24] [config] lr-decay-start:
[2023-07-01 10:52:24] [config]   - 10
[2023-07-01 10:52:24] [config]   - 1
[2023-07-01 10:52:24] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 10:52:24] [config] lr-report: true
[2023-07-01 10:52:24] [config] lr-warmup: 16000
[2023-07-01 10:52:24] [config] lr-warmup-at-reload: false
[2023-07-01 10:52:24] [config] lr-warmup-cycle: false
[2023-07-01 10:52:24] [config] lr-warmup-start-rate: 0
[2023-07-01 10:52:24] [config] max-length: 100
[2023-07-01 10:52:24] [config] max-length-crop: false
[2023-07-01 10:52:24] [config] max-length-factor: 3
[2023-07-01 10:52:24] [config] maxi-batch: 100
[2023-07-01 10:52:24] [config] maxi-batch-sort: trg
[2023-07-01 10:52:24] [config] mini-batch: 1000
[2023-07-01 10:52:24] [config] mini-batch-fit: true
[2023-07-01 10:52:24] [config] mini-batch-fit-step: 10
[2023-07-01 10:52:24] [config] mini-batch-round-up: true
[2023-07-01 10:52:24] [config] mini-batch-track-lr: false
[2023-07-01 10:52:24] [config] mini-batch-warmup: 0
[2023-07-01 10:52:24] [config] mini-batch-words: 0
[2023-07-01 10:52:24] [config] mini-batch-words-ref: 0
[2023-07-01 10:52:24] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:52:24] [config] multi-loss-type: sum
[2023-07-01 10:52:24] [config] n-best: false
[2023-07-01 10:52:24] [config] no-nccl: false
[2023-07-01 10:52:24] [config] no-reload: false
[2023-07-01 10:52:24] [config] no-restore-corpus: false
[2023-07-01 10:52:24] [config] normalize: 1
[2023-07-01 10:52:24] [config] normalize-gradient: false
[2023-07-01 10:52:24] [config] num-devices: 0
[2023-07-01 10:52:24] [config] optimizer: adam
[2023-07-01 10:52:24] [config] optimizer-delay: 1
[2023-07-01 10:52:24] [config] optimizer-params:
[2023-07-01 10:52:24] [config]   - 0.9
[2023-07-01 10:52:24] [config]   - 0.98
[2023-07-01 10:52:24] [config]   - 1e-09
[2023-07-01 10:52:24] [config] output-omit-bias: false
[2023-07-01 10:52:24] [config] overwrite: true
[2023-07-01 10:52:24] [config] precision:
[2023-07-01 10:52:24] [config]   - float32
[2023-07-01 10:52:24] [config]   - float32
[2023-07-01 10:52:24] [config] pretrained-model: ""
[2023-07-01 10:52:24] [config] quantize-biases: false
[2023-07-01 10:52:24] [config] quantize-bits: 0
[2023-07-01 10:52:24] [config] quantize-log-based: false
[2023-07-01 10:52:24] [config] quantize-optimization-steps: 0
[2023-07-01 10:52:24] [config] quiet: false
[2023-07-01 10:52:24] [config] quiet-translation: true
[2023-07-01 10:52:24] [config] relative-paths: false
[2023-07-01 10:52:24] [config] right-left: false
[2023-07-01 10:52:24] [config] save-freq: 10000u
[2023-07-01 10:52:24] [config] seed: 1234
[2023-07-01 10:52:24] [config] sentencepiece-alphas:
[2023-07-01 10:52:24] [config]   []
[2023-07-01 10:52:24] [config] sentencepiece-max-lines: 2000000
[2023-07-01 10:52:24] [config] sentencepiece-options: ""
[2023-07-01 10:52:24] [config] sharding: global
[2023-07-01 10:52:24] [config] shuffle: data
[2023-07-01 10:52:24] [config] shuffle-in-ram: false
[2023-07-01 10:52:24] [config] sigterm: save-and-exit
[2023-07-01 10:52:24] [config] skip: false
[2023-07-01 10:52:24] [config] sqlite: ""
[2023-07-01 10:52:24] [config] sqlite-drop: false
[2023-07-01 10:52:24] [config] sync-freq: 200u
[2023-07-01 10:52:24] [config] sync-sgd: true
[2023-07-01 10:52:24] [config] tempdir: /tmp
[2023-07-01 10:52:24] [config] tied-embeddings: false
[2023-07-01 10:52:24] [config] tied-embeddings-all: true
[2023-07-01 10:52:24] [config] tied-embeddings-src: false
[2023-07-01 10:52:24] [config] train-embedder-rank:
[2023-07-01 10:52:24] [config]   []
[2023-07-01 10:52:24] [config] train-sets:
[2023-07-01 10:52:24] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 10:52:24] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 10:52:24] [config] transformer-aan-activation: swish
[2023-07-01 10:52:24] [config] transformer-aan-depth: 2
[2023-07-01 10:52:24] [config] transformer-aan-nogate: false
[2023-07-01 10:52:24] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 10:52:24] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 10:52:24] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 10:52:24] [config] transformer-depth-scaling: false
[2023-07-01 10:52:24] [config] transformer-dim-aan: 2048
[2023-07-01 10:52:24] [config] transformer-dim-ffn: 2048
[2023-07-01 10:52:24] [config] transformer-dropout: 0.1
[2023-07-01 10:52:24] [config] transformer-dropout-attention: 0
[2023-07-01 10:52:24] [config] transformer-dropout-ffn: 0
[2023-07-01 10:52:24] [config] transformer-ffn-activation: swish
[2023-07-01 10:52:24] [config] transformer-ffn-depth: 2
[2023-07-01 10:52:24] [config] transformer-guided-alignment-layer: last
[2023-07-01 10:52:24] [config] transformer-heads: 8
[2023-07-01 10:52:24] [config] transformer-no-projection: false
[2023-07-01 10:52:24] [config] transformer-pool: false
[2023-07-01 10:52:24] [config] transformer-postprocess: dan
[2023-07-01 10:52:24] [config] transformer-postprocess-emb: d
[2023-07-01 10:52:24] [config] transformer-postprocess-top: ""
[2023-07-01 10:52:24] [config] transformer-preprocess: ""
[2023-07-01 10:52:24] [config] transformer-tied-layers:
[2023-07-01 10:52:24] [config]   []
[2023-07-01 10:52:24] [config] transformer-train-position-embeddings: false
[2023-07-01 10:52:24] [config] tsv: false
[2023-07-01 10:52:24] [config] tsv-fields: 0
[2023-07-01 10:52:24] [config] type: transformer
[2023-07-01 10:52:24] [config] ulr: false
[2023-07-01 10:52:24] [config] ulr-dim-emb: 0
[2023-07-01 10:52:24] [config] ulr-dropout: 0
[2023-07-01 10:52:24] [config] ulr-keys-vectors: ""
[2023-07-01 10:52:24] [config] ulr-query-vectors: ""
[2023-07-01 10:52:24] [config] ulr-softmax-temperature: 1
[2023-07-01 10:52:24] [config] ulr-trainable-transformation: false
[2023-07-01 10:52:24] [config] unlikelihood-loss: false
[2023-07-01 10:52:24] [config] valid-freq: 50000000
[2023-07-01 10:52:24] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 10:52:24] [config] valid-max-length: 1000
[2023-07-01 10:52:24] [config] valid-metrics:
[2023-07-01 10:52:24] [config]   - cross-entropy
[2023-07-01 10:52:24] [config]   - translation
[2023-07-01 10:52:24] [config] valid-mini-batch: 64
[2023-07-01 10:52:24] [config] valid-reset-stalled: false
[2023-07-01 10:52:24] [config] valid-script-args:
[2023-07-01 10:52:24] [config]   []
[2023-07-01 10:52:24] [config] valid-script-path: ""
[2023-07-01 10:52:24] [config] valid-sets:
[2023-07-01 10:52:24] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 10:52:24] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 10:52:24] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 10:52:24] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:52:24] [config] vocabs:
[2023-07-01 10:52:24] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 10:52:24] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 10:52:24] [config] word-penalty: 0
[2023-07-01 10:52:24] [config] word-scores: false
[2023-07-01 10:52:24] [config] workspace: 2048
[2023-07-01 10:52:24] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:52:24] Using synchronous SGD
[2023-07-01 10:52:24] Synced seed 1234
[2023-07-01 10:52:24] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 10:52:24] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 10:52:24] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 10:52:24] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 10:52:24] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 10:52:24] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 10:52:25] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 10:52:25] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 10:52:25] [comm] Using global sharding
[2023-07-01 10:52:25] [comm] NCCLCommunicators constructed successfully
[2023-07-01 10:52:25] [training] Using 1 GPUs
[2023-07-01 10:52:25] [logits] Applying loss function for 1 factor(s)
[2023-07-01 10:52:25] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:52:25] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 10:52:25] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:52:33] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 10:52:33] [valid] No post-processing script given for validating translator
[2023-07-01 10:52:33] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 10:52:33] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 10:52:33] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 10:52:33] [comm] Using global sharding
[2023-07-01 10:52:33] [comm] NCCLCommunicators constructed successfully
[2023-07-01 10:52:33] [training] Using 1 GPUs
[2023-07-01 10:52:33] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:52:34] Allocating memory for general optimizer shards
[2023-07-01 10:52:34] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:52:34] Loading Adam parameters
[2023-07-01 10:52:34] [memory] Reserving 176 MB, device gpu0
[2023-07-01 10:52:34] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:52:34] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 10:52:34] [data] Restoring the corpus state to epoch 40, batch 7371
[2023-07-01 10:52:34] [data] Shuffling data
[2023-07-01 10:52:34] [data] Done reading 20,192 sentences
[2023-07-01 10:52:34] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 10:52:34] Training started
[2023-07-01 10:52:34] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-07-01 10:52:34] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:52:35] Parameter type float32, optimization type float32, casting types false
[2023-07-01 10:53:01] Seen 20,073 samples
[2023-07-01 10:53:01] Starting data epoch 41 in logical epoch 41
[2023-07-01 10:53:01] Training finished
[2023-07-01 10:53:04] [valid] Ep. 41 : Up. 7560 : cross-entropy : 124.411 : new best
[2023-07-01 10:54:35] [valid] Ep. 41 : Up. 7560 : translation : 0 : new best
[2023-07-01 10:54:35] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:54:36] Saving Adam parameters
[2023-07-01 10:54:37] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 10:54:43] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:54:43] [marian] Running on node20.datos.cluster.uy as process 11916 with command line:
[2023-07-01 10:54:43] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 41 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 10:54:43] [config] after: 0e
[2023-07-01 10:54:43] [config] after-batches: 0
[2023-07-01 10:54:43] [config] after-epochs: 41
[2023-07-01 10:54:43] [config] all-caps-every: 0
[2023-07-01 10:54:43] [config] allow-unk: false
[2023-07-01 10:54:43] [config] authors: false
[2023-07-01 10:54:43] [config] beam-size: 12
[2023-07-01 10:54:43] [config] bert-class-symbol: "[CLS]"
[2023-07-01 10:54:43] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 10:54:43] [config] bert-masking-fraction: 0.15
[2023-07-01 10:54:43] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 10:54:43] [config] bert-train-type-embeddings: true
[2023-07-01 10:54:43] [config] bert-type-vocab-size: 2
[2023-07-01 10:54:43] [config] build-info: ""
[2023-07-01 10:54:43] [config] check-gradient-nan: false
[2023-07-01 10:54:43] [config] check-nan: false
[2023-07-01 10:54:43] [config] cite: false
[2023-07-01 10:54:43] [config] clip-norm: 5
[2023-07-01 10:54:43] [config] cost-scaling:
[2023-07-01 10:54:43] [config]   []
[2023-07-01 10:54:43] [config] cost-type: ce-sum
[2023-07-01 10:54:43] [config] cpu-threads: 0
[2023-07-01 10:54:43] [config] data-threads: 8
[2023-07-01 10:54:43] [config] data-weighting: ""
[2023-07-01 10:54:43] [config] data-weighting-type: sentence
[2023-07-01 10:54:43] [config] dec-cell: gru
[2023-07-01 10:54:43] [config] dec-cell-base-depth: 2
[2023-07-01 10:54:43] [config] dec-cell-high-depth: 1
[2023-07-01 10:54:43] [config] dec-depth: 2
[2023-07-01 10:54:43] [config] devices:
[2023-07-01 10:54:43] [config]   - 0
[2023-07-01 10:54:43] [config] dim-emb: 512
[2023-07-01 10:54:43] [config] dim-rnn: 1024
[2023-07-01 10:54:43] [config] dim-vocabs:
[2023-07-01 10:54:43] [config]   - 16384
[2023-07-01 10:54:43] [config]   - 16384
[2023-07-01 10:54:43] [config] disp-first: 0
[2023-07-01 10:54:43] [config] disp-freq: 1000u
[2023-07-01 10:54:43] [config] disp-label-counts: true
[2023-07-01 10:54:43] [config] dropout-rnn: 0
[2023-07-01 10:54:43] [config] dropout-src: 0
[2023-07-01 10:54:43] [config] dropout-trg: 0
[2023-07-01 10:54:43] [config] dump-config: ""
[2023-07-01 10:54:43] [config] dynamic-gradient-scaling:
[2023-07-01 10:54:43] [config]   []
[2023-07-01 10:54:43] [config] early-stopping: 10
[2023-07-01 10:54:43] [config] early-stopping-on: first
[2023-07-01 10:54:43] [config] embedding-fix-src: false
[2023-07-01 10:54:43] [config] embedding-fix-trg: false
[2023-07-01 10:54:43] [config] embedding-normalization: false
[2023-07-01 10:54:43] [config] embedding-vectors:
[2023-07-01 10:54:43] [config]   []
[2023-07-01 10:54:43] [config] enc-cell: gru
[2023-07-01 10:54:43] [config] enc-cell-depth: 1
[2023-07-01 10:54:43] [config] enc-depth: 2
[2023-07-01 10:54:43] [config] enc-type: bidirectional
[2023-07-01 10:54:43] [config] english-title-case-every: 0
[2023-07-01 10:54:43] [config] exponential-smoothing: 0.0001
[2023-07-01 10:54:43] [config] factor-weight: 1
[2023-07-01 10:54:43] [config] factors-combine: sum
[2023-07-01 10:54:43] [config] factors-dim-emb: 0
[2023-07-01 10:54:43] [config] gradient-checkpointing: false
[2023-07-01 10:54:43] [config] gradient-norm-average-window: 100
[2023-07-01 10:54:43] [config] guided-alignment: none
[2023-07-01 10:54:43] [config] guided-alignment-cost: mse
[2023-07-01 10:54:43] [config] guided-alignment-weight: 0.1
[2023-07-01 10:54:43] [config] ignore-model-config: false
[2023-07-01 10:54:43] [config] input-types:
[2023-07-01 10:54:43] [config]   []
[2023-07-01 10:54:43] [config] interpolate-env-vars: false
[2023-07-01 10:54:43] [config] keep-best: false
[2023-07-01 10:54:43] [config] label-smoothing: 0.1
[2023-07-01 10:54:43] [config] layer-normalization: false
[2023-07-01 10:54:43] [config] learn-rate: 0.0003
[2023-07-01 10:54:43] [config] lemma-dependency: ""
[2023-07-01 10:54:43] [config] lemma-dim-emb: 0
[2023-07-01 10:54:43] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 10:54:43] [config] log-level: info
[2023-07-01 10:54:43] [config] log-time-zone: ""
[2023-07-01 10:54:43] [config] logical-epoch:
[2023-07-01 10:54:43] [config]   - 1e
[2023-07-01 10:54:43] [config]   - 0
[2023-07-01 10:54:43] [config] lr-decay: 0
[2023-07-01 10:54:43] [config] lr-decay-freq: 50000
[2023-07-01 10:54:43] [config] lr-decay-inv-sqrt:
[2023-07-01 10:54:43] [config]   - 16000
[2023-07-01 10:54:43] [config] lr-decay-repeat-warmup: false
[2023-07-01 10:54:43] [config] lr-decay-reset-optimizer: false
[2023-07-01 10:54:43] [config] lr-decay-start:
[2023-07-01 10:54:43] [config]   - 10
[2023-07-01 10:54:43] [config]   - 1
[2023-07-01 10:54:43] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 10:54:43] [config] lr-report: true
[2023-07-01 10:54:43] [config] lr-warmup: 16000
[2023-07-01 10:54:43] [config] lr-warmup-at-reload: false
[2023-07-01 10:54:43] [config] lr-warmup-cycle: false
[2023-07-01 10:54:43] [config] lr-warmup-start-rate: 0
[2023-07-01 10:54:43] [config] max-length: 100
[2023-07-01 10:54:43] [config] max-length-crop: false
[2023-07-01 10:54:43] [config] max-length-factor: 3
[2023-07-01 10:54:43] [config] maxi-batch: 100
[2023-07-01 10:54:43] [config] maxi-batch-sort: trg
[2023-07-01 10:54:43] [config] mini-batch: 1000
[2023-07-01 10:54:43] [config] mini-batch-fit: true
[2023-07-01 10:54:43] [config] mini-batch-fit-step: 10
[2023-07-01 10:54:43] [config] mini-batch-round-up: true
[2023-07-01 10:54:43] [config] mini-batch-track-lr: false
[2023-07-01 10:54:43] [config] mini-batch-warmup: 0
[2023-07-01 10:54:43] [config] mini-batch-words: 0
[2023-07-01 10:54:43] [config] mini-batch-words-ref: 0
[2023-07-01 10:54:43] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:54:43] [config] multi-loss-type: sum
[2023-07-01 10:54:43] [config] n-best: false
[2023-07-01 10:54:43] [config] no-nccl: false
[2023-07-01 10:54:43] [config] no-reload: false
[2023-07-01 10:54:43] [config] no-restore-corpus: false
[2023-07-01 10:54:43] [config] normalize: 1
[2023-07-01 10:54:43] [config] normalize-gradient: false
[2023-07-01 10:54:43] [config] num-devices: 0
[2023-07-01 10:54:43] [config] optimizer: adam
[2023-07-01 10:54:43] [config] optimizer-delay: 1
[2023-07-01 10:54:43] [config] optimizer-params:
[2023-07-01 10:54:43] [config]   - 0.9
[2023-07-01 10:54:43] [config]   - 0.98
[2023-07-01 10:54:43] [config]   - 1e-09
[2023-07-01 10:54:43] [config] output-omit-bias: false
[2023-07-01 10:54:43] [config] overwrite: true
[2023-07-01 10:54:43] [config] precision:
[2023-07-01 10:54:43] [config]   - float32
[2023-07-01 10:54:43] [config]   - float32
[2023-07-01 10:54:43] [config] pretrained-model: ""
[2023-07-01 10:54:43] [config] quantize-biases: false
[2023-07-01 10:54:43] [config] quantize-bits: 0
[2023-07-01 10:54:43] [config] quantize-log-based: false
[2023-07-01 10:54:43] [config] quantize-optimization-steps: 0
[2023-07-01 10:54:43] [config] quiet: false
[2023-07-01 10:54:43] [config] quiet-translation: true
[2023-07-01 10:54:43] [config] relative-paths: false
[2023-07-01 10:54:43] [config] right-left: false
[2023-07-01 10:54:43] [config] save-freq: 10000u
[2023-07-01 10:54:43] [config] seed: 1234
[2023-07-01 10:54:43] [config] sentencepiece-alphas:
[2023-07-01 10:54:43] [config]   []
[2023-07-01 10:54:43] [config] sentencepiece-max-lines: 2000000
[2023-07-01 10:54:43] [config] sentencepiece-options: ""
[2023-07-01 10:54:43] [config] sharding: global
[2023-07-01 10:54:43] [config] shuffle: data
[2023-07-01 10:54:43] [config] shuffle-in-ram: false
[2023-07-01 10:54:43] [config] sigterm: save-and-exit
[2023-07-01 10:54:43] [config] skip: false
[2023-07-01 10:54:43] [config] sqlite: ""
[2023-07-01 10:54:43] [config] sqlite-drop: false
[2023-07-01 10:54:43] [config] sync-freq: 200u
[2023-07-01 10:54:43] [config] sync-sgd: true
[2023-07-01 10:54:43] [config] tempdir: /tmp
[2023-07-01 10:54:43] [config] tied-embeddings: false
[2023-07-01 10:54:43] [config] tied-embeddings-all: true
[2023-07-01 10:54:43] [config] tied-embeddings-src: false
[2023-07-01 10:54:43] [config] train-embedder-rank:
[2023-07-01 10:54:43] [config]   []
[2023-07-01 10:54:43] [config] train-sets:
[2023-07-01 10:54:43] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 10:54:43] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 10:54:43] [config] transformer-aan-activation: swish
[2023-07-01 10:54:43] [config] transformer-aan-depth: 2
[2023-07-01 10:54:43] [config] transformer-aan-nogate: false
[2023-07-01 10:54:43] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 10:54:43] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 10:54:43] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 10:54:43] [config] transformer-depth-scaling: false
[2023-07-01 10:54:43] [config] transformer-dim-aan: 2048
[2023-07-01 10:54:43] [config] transformer-dim-ffn: 2048
[2023-07-01 10:54:43] [config] transformer-dropout: 0.1
[2023-07-01 10:54:43] [config] transformer-dropout-attention: 0
[2023-07-01 10:54:43] [config] transformer-dropout-ffn: 0
[2023-07-01 10:54:43] [config] transformer-ffn-activation: swish
[2023-07-01 10:54:43] [config] transformer-ffn-depth: 2
[2023-07-01 10:54:43] [config] transformer-guided-alignment-layer: last
[2023-07-01 10:54:43] [config] transformer-heads: 8
[2023-07-01 10:54:43] [config] transformer-no-projection: false
[2023-07-01 10:54:43] [config] transformer-pool: false
[2023-07-01 10:54:43] [config] transformer-postprocess: dan
[2023-07-01 10:54:43] [config] transformer-postprocess-emb: d
[2023-07-01 10:54:43] [config] transformer-postprocess-top: ""
[2023-07-01 10:54:43] [config] transformer-preprocess: ""
[2023-07-01 10:54:43] [config] transformer-tied-layers:
[2023-07-01 10:54:43] [config]   []
[2023-07-01 10:54:43] [config] transformer-train-position-embeddings: false
[2023-07-01 10:54:43] [config] tsv: false
[2023-07-01 10:54:43] [config] tsv-fields: 0
[2023-07-01 10:54:43] [config] type: transformer
[2023-07-01 10:54:43] [config] ulr: false
[2023-07-01 10:54:43] [config] ulr-dim-emb: 0
[2023-07-01 10:54:43] [config] ulr-dropout: 0
[2023-07-01 10:54:43] [config] ulr-keys-vectors: ""
[2023-07-01 10:54:43] [config] ulr-query-vectors: ""
[2023-07-01 10:54:43] [config] ulr-softmax-temperature: 1
[2023-07-01 10:54:43] [config] ulr-trainable-transformation: false
[2023-07-01 10:54:43] [config] unlikelihood-loss: false
[2023-07-01 10:54:43] [config] valid-freq: 50000000
[2023-07-01 10:54:43] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 10:54:43] [config] valid-max-length: 1000
[2023-07-01 10:54:43] [config] valid-metrics:
[2023-07-01 10:54:43] [config]   - cross-entropy
[2023-07-01 10:54:43] [config]   - translation
[2023-07-01 10:54:43] [config] valid-mini-batch: 64
[2023-07-01 10:54:43] [config] valid-reset-stalled: false
[2023-07-01 10:54:43] [config] valid-script-args:
[2023-07-01 10:54:43] [config]   []
[2023-07-01 10:54:43] [config] valid-script-path: ""
[2023-07-01 10:54:43] [config] valid-sets:
[2023-07-01 10:54:43] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 10:54:43] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 10:54:43] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 10:54:43] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:54:43] [config] vocabs:
[2023-07-01 10:54:43] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 10:54:43] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 10:54:43] [config] word-penalty: 0
[2023-07-01 10:54:43] [config] word-scores: false
[2023-07-01 10:54:43] [config] workspace: 2048
[2023-07-01 10:54:43] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:54:43] Using synchronous SGD
[2023-07-01 10:54:43] Synced seed 1234
[2023-07-01 10:54:43] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 10:54:43] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 10:54:43] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 10:54:43] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 10:54:43] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 10:54:43] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 10:54:44] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 10:54:44] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 10:54:44] [comm] Using global sharding
[2023-07-01 10:54:44] [comm] NCCLCommunicators constructed successfully
[2023-07-01 10:54:44] [training] Using 1 GPUs
[2023-07-01 10:54:44] [logits] Applying loss function for 1 factor(s)
[2023-07-01 10:54:44] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:54:44] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 10:54:45] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:54:52] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 10:54:52] [valid] No post-processing script given for validating translator
[2023-07-01 10:54:52] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 10:54:52] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 10:54:52] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 10:54:52] [comm] Using global sharding
[2023-07-01 10:54:52] [comm] NCCLCommunicators constructed successfully
[2023-07-01 10:54:52] [training] Using 1 GPUs
[2023-07-01 10:54:52] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:54:53] Allocating memory for general optimizer shards
[2023-07-01 10:54:53] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:54:53] Loading Adam parameters
[2023-07-01 10:54:53] [memory] Reserving 176 MB, device gpu0
[2023-07-01 10:54:53] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:54:53] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 10:54:53] [data] Restoring the corpus state to epoch 41, batch 7560
[2023-07-01 10:54:53] [data] Shuffling data
[2023-07-01 10:54:53] [data] Done reading 20,192 sentences
[2023-07-01 10:54:53] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 10:54:53] Training started
[2023-07-01 10:54:53] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-07-01 10:54:54] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:54:54] Parameter type float32, optimization type float32, casting types false
[2023-07-01 10:55:18] Seen 20,073 samples
[2023-07-01 10:55:18] Starting data epoch 42 in logical epoch 42
[2023-07-01 10:55:18] Training finished
[2023-07-01 10:55:21] [valid] Ep. 42 : Up. 7749 : cross-entropy : 124.299 : new best
[2023-07-01 10:56:52] [valid] Ep. 42 : Up. 7749 : translation : 0 : new best
[2023-07-01 10:56:52] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:56:53] Saving Adam parameters
[2023-07-01 10:56:53] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 10:56:59] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:56:59] [marian] Running on node20.datos.cluster.uy as process 12084 with command line:
[2023-07-01 10:56:59] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 42 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 10:56:59] [config] after: 0e
[2023-07-01 10:56:59] [config] after-batches: 0
[2023-07-01 10:56:59] [config] after-epochs: 42
[2023-07-01 10:56:59] [config] all-caps-every: 0
[2023-07-01 10:56:59] [config] allow-unk: false
[2023-07-01 10:56:59] [config] authors: false
[2023-07-01 10:56:59] [config] beam-size: 12
[2023-07-01 10:56:59] [config] bert-class-symbol: "[CLS]"
[2023-07-01 10:56:59] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 10:56:59] [config] bert-masking-fraction: 0.15
[2023-07-01 10:56:59] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 10:56:59] [config] bert-train-type-embeddings: true
[2023-07-01 10:56:59] [config] bert-type-vocab-size: 2
[2023-07-01 10:56:59] [config] build-info: ""
[2023-07-01 10:56:59] [config] check-gradient-nan: false
[2023-07-01 10:56:59] [config] check-nan: false
[2023-07-01 10:56:59] [config] cite: false
[2023-07-01 10:56:59] [config] clip-norm: 5
[2023-07-01 10:56:59] [config] cost-scaling:
[2023-07-01 10:56:59] [config]   []
[2023-07-01 10:56:59] [config] cost-type: ce-sum
[2023-07-01 10:56:59] [config] cpu-threads: 0
[2023-07-01 10:56:59] [config] data-threads: 8
[2023-07-01 10:56:59] [config] data-weighting: ""
[2023-07-01 10:56:59] [config] data-weighting-type: sentence
[2023-07-01 10:56:59] [config] dec-cell: gru
[2023-07-01 10:56:59] [config] dec-cell-base-depth: 2
[2023-07-01 10:56:59] [config] dec-cell-high-depth: 1
[2023-07-01 10:56:59] [config] dec-depth: 2
[2023-07-01 10:56:59] [config] devices:
[2023-07-01 10:56:59] [config]   - 0
[2023-07-01 10:56:59] [config] dim-emb: 512
[2023-07-01 10:56:59] [config] dim-rnn: 1024
[2023-07-01 10:56:59] [config] dim-vocabs:
[2023-07-01 10:56:59] [config]   - 16384
[2023-07-01 10:56:59] [config]   - 16384
[2023-07-01 10:56:59] [config] disp-first: 0
[2023-07-01 10:56:59] [config] disp-freq: 1000u
[2023-07-01 10:56:59] [config] disp-label-counts: true
[2023-07-01 10:56:59] [config] dropout-rnn: 0
[2023-07-01 10:56:59] [config] dropout-src: 0
[2023-07-01 10:56:59] [config] dropout-trg: 0
[2023-07-01 10:56:59] [config] dump-config: ""
[2023-07-01 10:56:59] [config] dynamic-gradient-scaling:
[2023-07-01 10:56:59] [config]   []
[2023-07-01 10:56:59] [config] early-stopping: 10
[2023-07-01 10:56:59] [config] early-stopping-on: first
[2023-07-01 10:56:59] [config] embedding-fix-src: false
[2023-07-01 10:56:59] [config] embedding-fix-trg: false
[2023-07-01 10:56:59] [config] embedding-normalization: false
[2023-07-01 10:56:59] [config] embedding-vectors:
[2023-07-01 10:56:59] [config]   []
[2023-07-01 10:56:59] [config] enc-cell: gru
[2023-07-01 10:56:59] [config] enc-cell-depth: 1
[2023-07-01 10:56:59] [config] enc-depth: 2
[2023-07-01 10:56:59] [config] enc-type: bidirectional
[2023-07-01 10:56:59] [config] english-title-case-every: 0
[2023-07-01 10:56:59] [config] exponential-smoothing: 0.0001
[2023-07-01 10:56:59] [config] factor-weight: 1
[2023-07-01 10:56:59] [config] factors-combine: sum
[2023-07-01 10:56:59] [config] factors-dim-emb: 0
[2023-07-01 10:56:59] [config] gradient-checkpointing: false
[2023-07-01 10:56:59] [config] gradient-norm-average-window: 100
[2023-07-01 10:56:59] [config] guided-alignment: none
[2023-07-01 10:56:59] [config] guided-alignment-cost: mse
[2023-07-01 10:56:59] [config] guided-alignment-weight: 0.1
[2023-07-01 10:56:59] [config] ignore-model-config: false
[2023-07-01 10:56:59] [config] input-types:
[2023-07-01 10:56:59] [config]   []
[2023-07-01 10:56:59] [config] interpolate-env-vars: false
[2023-07-01 10:56:59] [config] keep-best: false
[2023-07-01 10:56:59] [config] label-smoothing: 0.1
[2023-07-01 10:56:59] [config] layer-normalization: false
[2023-07-01 10:56:59] [config] learn-rate: 0.0003
[2023-07-01 10:56:59] [config] lemma-dependency: ""
[2023-07-01 10:56:59] [config] lemma-dim-emb: 0
[2023-07-01 10:56:59] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 10:56:59] [config] log-level: info
[2023-07-01 10:56:59] [config] log-time-zone: ""
[2023-07-01 10:56:59] [config] logical-epoch:
[2023-07-01 10:56:59] [config]   - 1e
[2023-07-01 10:56:59] [config]   - 0
[2023-07-01 10:56:59] [config] lr-decay: 0
[2023-07-01 10:56:59] [config] lr-decay-freq: 50000
[2023-07-01 10:56:59] [config] lr-decay-inv-sqrt:
[2023-07-01 10:56:59] [config]   - 16000
[2023-07-01 10:56:59] [config] lr-decay-repeat-warmup: false
[2023-07-01 10:56:59] [config] lr-decay-reset-optimizer: false
[2023-07-01 10:56:59] [config] lr-decay-start:
[2023-07-01 10:56:59] [config]   - 10
[2023-07-01 10:56:59] [config]   - 1
[2023-07-01 10:56:59] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 10:56:59] [config] lr-report: true
[2023-07-01 10:56:59] [config] lr-warmup: 16000
[2023-07-01 10:56:59] [config] lr-warmup-at-reload: false
[2023-07-01 10:56:59] [config] lr-warmup-cycle: false
[2023-07-01 10:56:59] [config] lr-warmup-start-rate: 0
[2023-07-01 10:56:59] [config] max-length: 100
[2023-07-01 10:56:59] [config] max-length-crop: false
[2023-07-01 10:56:59] [config] max-length-factor: 3
[2023-07-01 10:56:59] [config] maxi-batch: 100
[2023-07-01 10:56:59] [config] maxi-batch-sort: trg
[2023-07-01 10:56:59] [config] mini-batch: 1000
[2023-07-01 10:56:59] [config] mini-batch-fit: true
[2023-07-01 10:56:59] [config] mini-batch-fit-step: 10
[2023-07-01 10:56:59] [config] mini-batch-round-up: true
[2023-07-01 10:56:59] [config] mini-batch-track-lr: false
[2023-07-01 10:56:59] [config] mini-batch-warmup: 0
[2023-07-01 10:56:59] [config] mini-batch-words: 0
[2023-07-01 10:56:59] [config] mini-batch-words-ref: 0
[2023-07-01 10:56:59] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:56:59] [config] multi-loss-type: sum
[2023-07-01 10:56:59] [config] n-best: false
[2023-07-01 10:56:59] [config] no-nccl: false
[2023-07-01 10:56:59] [config] no-reload: false
[2023-07-01 10:56:59] [config] no-restore-corpus: false
[2023-07-01 10:56:59] [config] normalize: 1
[2023-07-01 10:56:59] [config] normalize-gradient: false
[2023-07-01 10:56:59] [config] num-devices: 0
[2023-07-01 10:56:59] [config] optimizer: adam
[2023-07-01 10:56:59] [config] optimizer-delay: 1
[2023-07-01 10:56:59] [config] optimizer-params:
[2023-07-01 10:56:59] [config]   - 0.9
[2023-07-01 10:56:59] [config]   - 0.98
[2023-07-01 10:56:59] [config]   - 1e-09
[2023-07-01 10:56:59] [config] output-omit-bias: false
[2023-07-01 10:56:59] [config] overwrite: true
[2023-07-01 10:56:59] [config] precision:
[2023-07-01 10:56:59] [config]   - float32
[2023-07-01 10:56:59] [config]   - float32
[2023-07-01 10:56:59] [config] pretrained-model: ""
[2023-07-01 10:56:59] [config] quantize-biases: false
[2023-07-01 10:56:59] [config] quantize-bits: 0
[2023-07-01 10:56:59] [config] quantize-log-based: false
[2023-07-01 10:56:59] [config] quantize-optimization-steps: 0
[2023-07-01 10:56:59] [config] quiet: false
[2023-07-01 10:56:59] [config] quiet-translation: true
[2023-07-01 10:56:59] [config] relative-paths: false
[2023-07-01 10:56:59] [config] right-left: false
[2023-07-01 10:56:59] [config] save-freq: 10000u
[2023-07-01 10:56:59] [config] seed: 1234
[2023-07-01 10:56:59] [config] sentencepiece-alphas:
[2023-07-01 10:56:59] [config]   []
[2023-07-01 10:56:59] [config] sentencepiece-max-lines: 2000000
[2023-07-01 10:56:59] [config] sentencepiece-options: ""
[2023-07-01 10:56:59] [config] sharding: global
[2023-07-01 10:56:59] [config] shuffle: data
[2023-07-01 10:56:59] [config] shuffle-in-ram: false
[2023-07-01 10:56:59] [config] sigterm: save-and-exit
[2023-07-01 10:56:59] [config] skip: false
[2023-07-01 10:56:59] [config] sqlite: ""
[2023-07-01 10:56:59] [config] sqlite-drop: false
[2023-07-01 10:56:59] [config] sync-freq: 200u
[2023-07-01 10:56:59] [config] sync-sgd: true
[2023-07-01 10:56:59] [config] tempdir: /tmp
[2023-07-01 10:56:59] [config] tied-embeddings: false
[2023-07-01 10:56:59] [config] tied-embeddings-all: true
[2023-07-01 10:56:59] [config] tied-embeddings-src: false
[2023-07-01 10:56:59] [config] train-embedder-rank:
[2023-07-01 10:56:59] [config]   []
[2023-07-01 10:56:59] [config] train-sets:
[2023-07-01 10:56:59] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 10:56:59] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 10:56:59] [config] transformer-aan-activation: swish
[2023-07-01 10:56:59] [config] transformer-aan-depth: 2
[2023-07-01 10:56:59] [config] transformer-aan-nogate: false
[2023-07-01 10:56:59] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 10:56:59] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 10:56:59] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 10:56:59] [config] transformer-depth-scaling: false
[2023-07-01 10:56:59] [config] transformer-dim-aan: 2048
[2023-07-01 10:56:59] [config] transformer-dim-ffn: 2048
[2023-07-01 10:56:59] [config] transformer-dropout: 0.1
[2023-07-01 10:56:59] [config] transformer-dropout-attention: 0
[2023-07-01 10:56:59] [config] transformer-dropout-ffn: 0
[2023-07-01 10:56:59] [config] transformer-ffn-activation: swish
[2023-07-01 10:56:59] [config] transformer-ffn-depth: 2
[2023-07-01 10:56:59] [config] transformer-guided-alignment-layer: last
[2023-07-01 10:56:59] [config] transformer-heads: 8
[2023-07-01 10:56:59] [config] transformer-no-projection: false
[2023-07-01 10:56:59] [config] transformer-pool: false
[2023-07-01 10:56:59] [config] transformer-postprocess: dan
[2023-07-01 10:56:59] [config] transformer-postprocess-emb: d
[2023-07-01 10:56:59] [config] transformer-postprocess-top: ""
[2023-07-01 10:56:59] [config] transformer-preprocess: ""
[2023-07-01 10:56:59] [config] transformer-tied-layers:
[2023-07-01 10:56:59] [config]   []
[2023-07-01 10:56:59] [config] transformer-train-position-embeddings: false
[2023-07-01 10:56:59] [config] tsv: false
[2023-07-01 10:56:59] [config] tsv-fields: 0
[2023-07-01 10:56:59] [config] type: transformer
[2023-07-01 10:56:59] [config] ulr: false
[2023-07-01 10:56:59] [config] ulr-dim-emb: 0
[2023-07-01 10:56:59] [config] ulr-dropout: 0
[2023-07-01 10:56:59] [config] ulr-keys-vectors: ""
[2023-07-01 10:56:59] [config] ulr-query-vectors: ""
[2023-07-01 10:56:59] [config] ulr-softmax-temperature: 1
[2023-07-01 10:56:59] [config] ulr-trainable-transformation: false
[2023-07-01 10:56:59] [config] unlikelihood-loss: false
[2023-07-01 10:56:59] [config] valid-freq: 50000000
[2023-07-01 10:56:59] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 10:56:59] [config] valid-max-length: 1000
[2023-07-01 10:56:59] [config] valid-metrics:
[2023-07-01 10:56:59] [config]   - cross-entropy
[2023-07-01 10:56:59] [config]   - translation
[2023-07-01 10:56:59] [config] valid-mini-batch: 64
[2023-07-01 10:56:59] [config] valid-reset-stalled: false
[2023-07-01 10:56:59] [config] valid-script-args:
[2023-07-01 10:56:59] [config]   []
[2023-07-01 10:56:59] [config] valid-script-path: ""
[2023-07-01 10:56:59] [config] valid-sets:
[2023-07-01 10:56:59] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 10:56:59] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 10:56:59] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 10:56:59] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:56:59] [config] vocabs:
[2023-07-01 10:56:59] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 10:56:59] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 10:56:59] [config] word-penalty: 0
[2023-07-01 10:56:59] [config] word-scores: false
[2023-07-01 10:56:59] [config] workspace: 2048
[2023-07-01 10:56:59] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:56:59] Using synchronous SGD
[2023-07-01 10:57:00] Synced seed 1234
[2023-07-01 10:57:00] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 10:57:00] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 10:57:00] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 10:57:00] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 10:57:00] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 10:57:00] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 10:57:00] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 10:57:01] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 10:57:01] [comm] Using global sharding
[2023-07-01 10:57:01] [comm] NCCLCommunicators constructed successfully
[2023-07-01 10:57:01] [training] Using 1 GPUs
[2023-07-01 10:57:01] [logits] Applying loss function for 1 factor(s)
[2023-07-01 10:57:01] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:57:01] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 10:57:01] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:57:09] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 10:57:09] [valid] No post-processing script given for validating translator
[2023-07-01 10:57:09] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 10:57:09] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 10:57:09] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 10:57:09] [comm] Using global sharding
[2023-07-01 10:57:09] [comm] NCCLCommunicators constructed successfully
[2023-07-01 10:57:09] [training] Using 1 GPUs
[2023-07-01 10:57:09] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:57:10] Allocating memory for general optimizer shards
[2023-07-01 10:57:10] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:57:10] Loading Adam parameters
[2023-07-01 10:57:10] [memory] Reserving 176 MB, device gpu0
[2023-07-01 10:57:10] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:57:10] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 10:57:10] [data] Restoring the corpus state to epoch 42, batch 7749
[2023-07-01 10:57:10] [data] Shuffling data
[2023-07-01 10:57:10] [data] Done reading 20,192 sentences
[2023-07-01 10:57:10] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 10:57:10] Training started
[2023-07-01 10:57:10] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-07-01 10:57:10] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:57:10] Parameter type float32, optimization type float32, casting types false
[2023-07-01 10:57:34] Seen 20,073 samples
[2023-07-01 10:57:34] Starting data epoch 43 in logical epoch 43
[2023-07-01 10:57:34] Training finished
[2023-07-01 10:57:37] [valid] Ep. 43 : Up. 7938 : cross-entropy : 124.257 : new best
[2023-07-01 10:59:02] [valid] Ep. 43 : Up. 7938 : translation : 0 : new best
[2023-07-01 10:59:02] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:59:03] Saving Adam parameters
[2023-07-01 10:59:04] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 10:59:11] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:59:11] [marian] Running on node20.datos.cluster.uy as process 12250 with command line:
[2023-07-01 10:59:11] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 43 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 10:59:11] [config] after: 0e
[2023-07-01 10:59:11] [config] after-batches: 0
[2023-07-01 10:59:11] [config] after-epochs: 43
[2023-07-01 10:59:11] [config] all-caps-every: 0
[2023-07-01 10:59:11] [config] allow-unk: false
[2023-07-01 10:59:11] [config] authors: false
[2023-07-01 10:59:11] [config] beam-size: 12
[2023-07-01 10:59:11] [config] bert-class-symbol: "[CLS]"
[2023-07-01 10:59:11] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 10:59:11] [config] bert-masking-fraction: 0.15
[2023-07-01 10:59:11] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 10:59:11] [config] bert-train-type-embeddings: true
[2023-07-01 10:59:11] [config] bert-type-vocab-size: 2
[2023-07-01 10:59:11] [config] build-info: ""
[2023-07-01 10:59:11] [config] check-gradient-nan: false
[2023-07-01 10:59:11] [config] check-nan: false
[2023-07-01 10:59:11] [config] cite: false
[2023-07-01 10:59:11] [config] clip-norm: 5
[2023-07-01 10:59:11] [config] cost-scaling:
[2023-07-01 10:59:11] [config]   []
[2023-07-01 10:59:11] [config] cost-type: ce-sum
[2023-07-01 10:59:11] [config] cpu-threads: 0
[2023-07-01 10:59:11] [config] data-threads: 8
[2023-07-01 10:59:11] [config] data-weighting: ""
[2023-07-01 10:59:11] [config] data-weighting-type: sentence
[2023-07-01 10:59:11] [config] dec-cell: gru
[2023-07-01 10:59:11] [config] dec-cell-base-depth: 2
[2023-07-01 10:59:11] [config] dec-cell-high-depth: 1
[2023-07-01 10:59:11] [config] dec-depth: 2
[2023-07-01 10:59:11] [config] devices:
[2023-07-01 10:59:11] [config]   - 0
[2023-07-01 10:59:11] [config] dim-emb: 512
[2023-07-01 10:59:11] [config] dim-rnn: 1024
[2023-07-01 10:59:11] [config] dim-vocabs:
[2023-07-01 10:59:11] [config]   - 16384
[2023-07-01 10:59:11] [config]   - 16384
[2023-07-01 10:59:11] [config] disp-first: 0
[2023-07-01 10:59:11] [config] disp-freq: 1000u
[2023-07-01 10:59:11] [config] disp-label-counts: true
[2023-07-01 10:59:11] [config] dropout-rnn: 0
[2023-07-01 10:59:11] [config] dropout-src: 0
[2023-07-01 10:59:11] [config] dropout-trg: 0
[2023-07-01 10:59:11] [config] dump-config: ""
[2023-07-01 10:59:11] [config] dynamic-gradient-scaling:
[2023-07-01 10:59:11] [config]   []
[2023-07-01 10:59:11] [config] early-stopping: 10
[2023-07-01 10:59:11] [config] early-stopping-on: first
[2023-07-01 10:59:11] [config] embedding-fix-src: false
[2023-07-01 10:59:11] [config] embedding-fix-trg: false
[2023-07-01 10:59:11] [config] embedding-normalization: false
[2023-07-01 10:59:11] [config] embedding-vectors:
[2023-07-01 10:59:11] [config]   []
[2023-07-01 10:59:11] [config] enc-cell: gru
[2023-07-01 10:59:11] [config] enc-cell-depth: 1
[2023-07-01 10:59:11] [config] enc-depth: 2
[2023-07-01 10:59:11] [config] enc-type: bidirectional
[2023-07-01 10:59:11] [config] english-title-case-every: 0
[2023-07-01 10:59:11] [config] exponential-smoothing: 0.0001
[2023-07-01 10:59:11] [config] factor-weight: 1
[2023-07-01 10:59:11] [config] factors-combine: sum
[2023-07-01 10:59:11] [config] factors-dim-emb: 0
[2023-07-01 10:59:11] [config] gradient-checkpointing: false
[2023-07-01 10:59:11] [config] gradient-norm-average-window: 100
[2023-07-01 10:59:11] [config] guided-alignment: none
[2023-07-01 10:59:11] [config] guided-alignment-cost: mse
[2023-07-01 10:59:11] [config] guided-alignment-weight: 0.1
[2023-07-01 10:59:11] [config] ignore-model-config: false
[2023-07-01 10:59:11] [config] input-types:
[2023-07-01 10:59:11] [config]   []
[2023-07-01 10:59:11] [config] interpolate-env-vars: false
[2023-07-01 10:59:11] [config] keep-best: false
[2023-07-01 10:59:11] [config] label-smoothing: 0.1
[2023-07-01 10:59:11] [config] layer-normalization: false
[2023-07-01 10:59:11] [config] learn-rate: 0.0003
[2023-07-01 10:59:11] [config] lemma-dependency: ""
[2023-07-01 10:59:11] [config] lemma-dim-emb: 0
[2023-07-01 10:59:11] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 10:59:11] [config] log-level: info
[2023-07-01 10:59:11] [config] log-time-zone: ""
[2023-07-01 10:59:11] [config] logical-epoch:
[2023-07-01 10:59:11] [config]   - 1e
[2023-07-01 10:59:11] [config]   - 0
[2023-07-01 10:59:11] [config] lr-decay: 0
[2023-07-01 10:59:11] [config] lr-decay-freq: 50000
[2023-07-01 10:59:11] [config] lr-decay-inv-sqrt:
[2023-07-01 10:59:11] [config]   - 16000
[2023-07-01 10:59:11] [config] lr-decay-repeat-warmup: false
[2023-07-01 10:59:11] [config] lr-decay-reset-optimizer: false
[2023-07-01 10:59:11] [config] lr-decay-start:
[2023-07-01 10:59:11] [config]   - 10
[2023-07-01 10:59:11] [config]   - 1
[2023-07-01 10:59:11] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 10:59:11] [config] lr-report: true
[2023-07-01 10:59:11] [config] lr-warmup: 16000
[2023-07-01 10:59:11] [config] lr-warmup-at-reload: false
[2023-07-01 10:59:11] [config] lr-warmup-cycle: false
[2023-07-01 10:59:11] [config] lr-warmup-start-rate: 0
[2023-07-01 10:59:11] [config] max-length: 100
[2023-07-01 10:59:11] [config] max-length-crop: false
[2023-07-01 10:59:11] [config] max-length-factor: 3
[2023-07-01 10:59:11] [config] maxi-batch: 100
[2023-07-01 10:59:11] [config] maxi-batch-sort: trg
[2023-07-01 10:59:11] [config] mini-batch: 1000
[2023-07-01 10:59:11] [config] mini-batch-fit: true
[2023-07-01 10:59:11] [config] mini-batch-fit-step: 10
[2023-07-01 10:59:11] [config] mini-batch-round-up: true
[2023-07-01 10:59:11] [config] mini-batch-track-lr: false
[2023-07-01 10:59:11] [config] mini-batch-warmup: 0
[2023-07-01 10:59:11] [config] mini-batch-words: 0
[2023-07-01 10:59:11] [config] mini-batch-words-ref: 0
[2023-07-01 10:59:11] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:59:11] [config] multi-loss-type: sum
[2023-07-01 10:59:11] [config] n-best: false
[2023-07-01 10:59:11] [config] no-nccl: false
[2023-07-01 10:59:11] [config] no-reload: false
[2023-07-01 10:59:11] [config] no-restore-corpus: false
[2023-07-01 10:59:11] [config] normalize: 1
[2023-07-01 10:59:11] [config] normalize-gradient: false
[2023-07-01 10:59:11] [config] num-devices: 0
[2023-07-01 10:59:11] [config] optimizer: adam
[2023-07-01 10:59:11] [config] optimizer-delay: 1
[2023-07-01 10:59:11] [config] optimizer-params:
[2023-07-01 10:59:11] [config]   - 0.9
[2023-07-01 10:59:11] [config]   - 0.98
[2023-07-01 10:59:11] [config]   - 1e-09
[2023-07-01 10:59:11] [config] output-omit-bias: false
[2023-07-01 10:59:11] [config] overwrite: true
[2023-07-01 10:59:11] [config] precision:
[2023-07-01 10:59:11] [config]   - float32
[2023-07-01 10:59:11] [config]   - float32
[2023-07-01 10:59:11] [config] pretrained-model: ""
[2023-07-01 10:59:11] [config] quantize-biases: false
[2023-07-01 10:59:11] [config] quantize-bits: 0
[2023-07-01 10:59:11] [config] quantize-log-based: false
[2023-07-01 10:59:11] [config] quantize-optimization-steps: 0
[2023-07-01 10:59:11] [config] quiet: false
[2023-07-01 10:59:11] [config] quiet-translation: true
[2023-07-01 10:59:11] [config] relative-paths: false
[2023-07-01 10:59:11] [config] right-left: false
[2023-07-01 10:59:11] [config] save-freq: 10000u
[2023-07-01 10:59:11] [config] seed: 1234
[2023-07-01 10:59:11] [config] sentencepiece-alphas:
[2023-07-01 10:59:11] [config]   []
[2023-07-01 10:59:11] [config] sentencepiece-max-lines: 2000000
[2023-07-01 10:59:11] [config] sentencepiece-options: ""
[2023-07-01 10:59:11] [config] sharding: global
[2023-07-01 10:59:11] [config] shuffle: data
[2023-07-01 10:59:11] [config] shuffle-in-ram: false
[2023-07-01 10:59:11] [config] sigterm: save-and-exit
[2023-07-01 10:59:11] [config] skip: false
[2023-07-01 10:59:11] [config] sqlite: ""
[2023-07-01 10:59:11] [config] sqlite-drop: false
[2023-07-01 10:59:11] [config] sync-freq: 200u
[2023-07-01 10:59:11] [config] sync-sgd: true
[2023-07-01 10:59:11] [config] tempdir: /tmp
[2023-07-01 10:59:11] [config] tied-embeddings: false
[2023-07-01 10:59:11] [config] tied-embeddings-all: true
[2023-07-01 10:59:11] [config] tied-embeddings-src: false
[2023-07-01 10:59:11] [config] train-embedder-rank:
[2023-07-01 10:59:11] [config]   []
[2023-07-01 10:59:11] [config] train-sets:
[2023-07-01 10:59:11] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 10:59:11] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 10:59:11] [config] transformer-aan-activation: swish
[2023-07-01 10:59:11] [config] transformer-aan-depth: 2
[2023-07-01 10:59:11] [config] transformer-aan-nogate: false
[2023-07-01 10:59:11] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 10:59:11] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 10:59:11] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 10:59:11] [config] transformer-depth-scaling: false
[2023-07-01 10:59:11] [config] transformer-dim-aan: 2048
[2023-07-01 10:59:11] [config] transformer-dim-ffn: 2048
[2023-07-01 10:59:11] [config] transformer-dropout: 0.1
[2023-07-01 10:59:11] [config] transformer-dropout-attention: 0
[2023-07-01 10:59:11] [config] transformer-dropout-ffn: 0
[2023-07-01 10:59:11] [config] transformer-ffn-activation: swish
[2023-07-01 10:59:11] [config] transformer-ffn-depth: 2
[2023-07-01 10:59:11] [config] transformer-guided-alignment-layer: last
[2023-07-01 10:59:11] [config] transformer-heads: 8
[2023-07-01 10:59:11] [config] transformer-no-projection: false
[2023-07-01 10:59:11] [config] transformer-pool: false
[2023-07-01 10:59:11] [config] transformer-postprocess: dan
[2023-07-01 10:59:11] [config] transformer-postprocess-emb: d
[2023-07-01 10:59:11] [config] transformer-postprocess-top: ""
[2023-07-01 10:59:11] [config] transformer-preprocess: ""
[2023-07-01 10:59:11] [config] transformer-tied-layers:
[2023-07-01 10:59:11] [config]   []
[2023-07-01 10:59:11] [config] transformer-train-position-embeddings: false
[2023-07-01 10:59:11] [config] tsv: false
[2023-07-01 10:59:11] [config] tsv-fields: 0
[2023-07-01 10:59:11] [config] type: transformer
[2023-07-01 10:59:11] [config] ulr: false
[2023-07-01 10:59:11] [config] ulr-dim-emb: 0
[2023-07-01 10:59:11] [config] ulr-dropout: 0
[2023-07-01 10:59:11] [config] ulr-keys-vectors: ""
[2023-07-01 10:59:11] [config] ulr-query-vectors: ""
[2023-07-01 10:59:11] [config] ulr-softmax-temperature: 1
[2023-07-01 10:59:11] [config] ulr-trainable-transformation: false
[2023-07-01 10:59:11] [config] unlikelihood-loss: false
[2023-07-01 10:59:11] [config] valid-freq: 50000000
[2023-07-01 10:59:11] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 10:59:11] [config] valid-max-length: 1000
[2023-07-01 10:59:11] [config] valid-metrics:
[2023-07-01 10:59:11] [config]   - cross-entropy
[2023-07-01 10:59:11] [config]   - translation
[2023-07-01 10:59:11] [config] valid-mini-batch: 64
[2023-07-01 10:59:11] [config] valid-reset-stalled: false
[2023-07-01 10:59:11] [config] valid-script-args:
[2023-07-01 10:59:11] [config]   []
[2023-07-01 10:59:11] [config] valid-script-path: ""
[2023-07-01 10:59:11] [config] valid-sets:
[2023-07-01 10:59:11] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 10:59:11] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 10:59:11] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 10:59:11] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:59:11] [config] vocabs:
[2023-07-01 10:59:11] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 10:59:11] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 10:59:11] [config] word-penalty: 0
[2023-07-01 10:59:11] [config] word-scores: false
[2023-07-01 10:59:11] [config] workspace: 2048
[2023-07-01 10:59:11] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 10:59:11] Using synchronous SGD
[2023-07-01 10:59:11] Synced seed 1234
[2023-07-01 10:59:11] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 10:59:11] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 10:59:11] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 10:59:11] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 10:59:11] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 10:59:11] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 10:59:12] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 10:59:12] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 10:59:12] [comm] Using global sharding
[2023-07-01 10:59:12] [comm] NCCLCommunicators constructed successfully
[2023-07-01 10:59:12] [training] Using 1 GPUs
[2023-07-01 10:59:12] [logits] Applying loss function for 1 factor(s)
[2023-07-01 10:59:12] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:59:12] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 10:59:12] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:59:20] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 10:59:20] [valid] No post-processing script given for validating translator
[2023-07-01 10:59:20] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 10:59:20] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 10:59:20] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 10:59:20] [comm] Using global sharding
[2023-07-01 10:59:20] [comm] NCCLCommunicators constructed successfully
[2023-07-01 10:59:20] [training] Using 1 GPUs
[2023-07-01 10:59:20] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 10:59:21] Allocating memory for general optimizer shards
[2023-07-01 10:59:21] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:59:21] Loading Adam parameters
[2023-07-01 10:59:21] [memory] Reserving 176 MB, device gpu0
[2023-07-01 10:59:21] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:59:21] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 10:59:21] [data] Restoring the corpus state to epoch 43, batch 7938
[2023-07-01 10:59:21] [data] Shuffling data
[2023-07-01 10:59:21] [data] Done reading 20,192 sentences
[2023-07-01 10:59:21] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 10:59:21] Training started
[2023-07-01 10:59:21] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-07-01 10:59:21] [memory] Reserving 88 MB, device gpu0
[2023-07-01 10:59:21] Parameter type float32, optimization type float32, casting types false
[2023-07-01 10:59:29] Ep. 43 : Up. 8000 : Sen. 6,689 : Cost 3.46803212 * 3,212,890 @ 1,840 after 25,676,553 : Time 9.26s : 347093.97 words/s : gNorm 1.7809 : L.r. 1.5000e-04
[2023-07-01 10:59:46] Seen 20,073 samples
[2023-07-01 10:59:46] Starting data epoch 44 in logical epoch 44
[2023-07-01 10:59:46] Training finished
[2023-07-01 10:59:49] [valid] Ep. 44 : Up. 8127 : cross-entropy : 124.305 : stalled 1 times (last best: 124.257)
[2023-07-01 11:01:15] [valid] Ep. 44 : Up. 8127 : translation : 0 : new best
[2023-07-01 11:01:15] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:01:16] Saving Adam parameters
[2023-07-01 11:01:17] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:01:23] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:01:23] [marian] Running on node20.datos.cluster.uy as process 12430 with command line:
[2023-07-01 11:01:23] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 44 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:01:23] [config] after: 0e
[2023-07-01 11:01:23] [config] after-batches: 0
[2023-07-01 11:01:23] [config] after-epochs: 44
[2023-07-01 11:01:23] [config] all-caps-every: 0
[2023-07-01 11:01:23] [config] allow-unk: false
[2023-07-01 11:01:23] [config] authors: false
[2023-07-01 11:01:23] [config] beam-size: 12
[2023-07-01 11:01:23] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:01:23] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:01:23] [config] bert-masking-fraction: 0.15
[2023-07-01 11:01:23] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:01:23] [config] bert-train-type-embeddings: true
[2023-07-01 11:01:23] [config] bert-type-vocab-size: 2
[2023-07-01 11:01:23] [config] build-info: ""
[2023-07-01 11:01:23] [config] check-gradient-nan: false
[2023-07-01 11:01:23] [config] check-nan: false
[2023-07-01 11:01:23] [config] cite: false
[2023-07-01 11:01:23] [config] clip-norm: 5
[2023-07-01 11:01:23] [config] cost-scaling:
[2023-07-01 11:01:23] [config]   []
[2023-07-01 11:01:23] [config] cost-type: ce-sum
[2023-07-01 11:01:23] [config] cpu-threads: 0
[2023-07-01 11:01:23] [config] data-threads: 8
[2023-07-01 11:01:23] [config] data-weighting: ""
[2023-07-01 11:01:23] [config] data-weighting-type: sentence
[2023-07-01 11:01:23] [config] dec-cell: gru
[2023-07-01 11:01:23] [config] dec-cell-base-depth: 2
[2023-07-01 11:01:23] [config] dec-cell-high-depth: 1
[2023-07-01 11:01:23] [config] dec-depth: 2
[2023-07-01 11:01:23] [config] devices:
[2023-07-01 11:01:23] [config]   - 0
[2023-07-01 11:01:23] [config] dim-emb: 512
[2023-07-01 11:01:23] [config] dim-rnn: 1024
[2023-07-01 11:01:23] [config] dim-vocabs:
[2023-07-01 11:01:23] [config]   - 16384
[2023-07-01 11:01:23] [config]   - 16384
[2023-07-01 11:01:23] [config] disp-first: 0
[2023-07-01 11:01:23] [config] disp-freq: 1000u
[2023-07-01 11:01:23] [config] disp-label-counts: true
[2023-07-01 11:01:23] [config] dropout-rnn: 0
[2023-07-01 11:01:23] [config] dropout-src: 0
[2023-07-01 11:01:23] [config] dropout-trg: 0
[2023-07-01 11:01:23] [config] dump-config: ""
[2023-07-01 11:01:23] [config] dynamic-gradient-scaling:
[2023-07-01 11:01:23] [config]   []
[2023-07-01 11:01:23] [config] early-stopping: 10
[2023-07-01 11:01:23] [config] early-stopping-on: first
[2023-07-01 11:01:23] [config] embedding-fix-src: false
[2023-07-01 11:01:23] [config] embedding-fix-trg: false
[2023-07-01 11:01:23] [config] embedding-normalization: false
[2023-07-01 11:01:23] [config] embedding-vectors:
[2023-07-01 11:01:23] [config]   []
[2023-07-01 11:01:23] [config] enc-cell: gru
[2023-07-01 11:01:23] [config] enc-cell-depth: 1
[2023-07-01 11:01:23] [config] enc-depth: 2
[2023-07-01 11:01:23] [config] enc-type: bidirectional
[2023-07-01 11:01:23] [config] english-title-case-every: 0
[2023-07-01 11:01:23] [config] exponential-smoothing: 0.0001
[2023-07-01 11:01:23] [config] factor-weight: 1
[2023-07-01 11:01:23] [config] factors-combine: sum
[2023-07-01 11:01:23] [config] factors-dim-emb: 0
[2023-07-01 11:01:23] [config] gradient-checkpointing: false
[2023-07-01 11:01:23] [config] gradient-norm-average-window: 100
[2023-07-01 11:01:23] [config] guided-alignment: none
[2023-07-01 11:01:23] [config] guided-alignment-cost: mse
[2023-07-01 11:01:23] [config] guided-alignment-weight: 0.1
[2023-07-01 11:01:23] [config] ignore-model-config: false
[2023-07-01 11:01:23] [config] input-types:
[2023-07-01 11:01:23] [config]   []
[2023-07-01 11:01:23] [config] interpolate-env-vars: false
[2023-07-01 11:01:23] [config] keep-best: false
[2023-07-01 11:01:23] [config] label-smoothing: 0.1
[2023-07-01 11:01:23] [config] layer-normalization: false
[2023-07-01 11:01:23] [config] learn-rate: 0.0003
[2023-07-01 11:01:23] [config] lemma-dependency: ""
[2023-07-01 11:01:23] [config] lemma-dim-emb: 0
[2023-07-01 11:01:23] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:01:23] [config] log-level: info
[2023-07-01 11:01:23] [config] log-time-zone: ""
[2023-07-01 11:01:23] [config] logical-epoch:
[2023-07-01 11:01:23] [config]   - 1e
[2023-07-01 11:01:23] [config]   - 0
[2023-07-01 11:01:23] [config] lr-decay: 0
[2023-07-01 11:01:23] [config] lr-decay-freq: 50000
[2023-07-01 11:01:23] [config] lr-decay-inv-sqrt:
[2023-07-01 11:01:23] [config]   - 16000
[2023-07-01 11:01:23] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:01:23] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:01:23] [config] lr-decay-start:
[2023-07-01 11:01:23] [config]   - 10
[2023-07-01 11:01:23] [config]   - 1
[2023-07-01 11:01:23] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:01:23] [config] lr-report: true
[2023-07-01 11:01:23] [config] lr-warmup: 16000
[2023-07-01 11:01:23] [config] lr-warmup-at-reload: false
[2023-07-01 11:01:23] [config] lr-warmup-cycle: false
[2023-07-01 11:01:23] [config] lr-warmup-start-rate: 0
[2023-07-01 11:01:23] [config] max-length: 100
[2023-07-01 11:01:23] [config] max-length-crop: false
[2023-07-01 11:01:23] [config] max-length-factor: 3
[2023-07-01 11:01:23] [config] maxi-batch: 100
[2023-07-01 11:01:23] [config] maxi-batch-sort: trg
[2023-07-01 11:01:23] [config] mini-batch: 1000
[2023-07-01 11:01:23] [config] mini-batch-fit: true
[2023-07-01 11:01:23] [config] mini-batch-fit-step: 10
[2023-07-01 11:01:23] [config] mini-batch-round-up: true
[2023-07-01 11:01:23] [config] mini-batch-track-lr: false
[2023-07-01 11:01:23] [config] mini-batch-warmup: 0
[2023-07-01 11:01:23] [config] mini-batch-words: 0
[2023-07-01 11:01:23] [config] mini-batch-words-ref: 0
[2023-07-01 11:01:23] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:01:23] [config] multi-loss-type: sum
[2023-07-01 11:01:23] [config] n-best: false
[2023-07-01 11:01:23] [config] no-nccl: false
[2023-07-01 11:01:23] [config] no-reload: false
[2023-07-01 11:01:23] [config] no-restore-corpus: false
[2023-07-01 11:01:23] [config] normalize: 1
[2023-07-01 11:01:23] [config] normalize-gradient: false
[2023-07-01 11:01:23] [config] num-devices: 0
[2023-07-01 11:01:23] [config] optimizer: adam
[2023-07-01 11:01:23] [config] optimizer-delay: 1
[2023-07-01 11:01:23] [config] optimizer-params:
[2023-07-01 11:01:23] [config]   - 0.9
[2023-07-01 11:01:23] [config]   - 0.98
[2023-07-01 11:01:23] [config]   - 1e-09
[2023-07-01 11:01:23] [config] output-omit-bias: false
[2023-07-01 11:01:23] [config] overwrite: true
[2023-07-01 11:01:23] [config] precision:
[2023-07-01 11:01:23] [config]   - float32
[2023-07-01 11:01:23] [config]   - float32
[2023-07-01 11:01:23] [config] pretrained-model: ""
[2023-07-01 11:01:23] [config] quantize-biases: false
[2023-07-01 11:01:23] [config] quantize-bits: 0
[2023-07-01 11:01:23] [config] quantize-log-based: false
[2023-07-01 11:01:23] [config] quantize-optimization-steps: 0
[2023-07-01 11:01:23] [config] quiet: false
[2023-07-01 11:01:23] [config] quiet-translation: true
[2023-07-01 11:01:23] [config] relative-paths: false
[2023-07-01 11:01:23] [config] right-left: false
[2023-07-01 11:01:23] [config] save-freq: 10000u
[2023-07-01 11:01:23] [config] seed: 1234
[2023-07-01 11:01:23] [config] sentencepiece-alphas:
[2023-07-01 11:01:23] [config]   []
[2023-07-01 11:01:23] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:01:23] [config] sentencepiece-options: ""
[2023-07-01 11:01:23] [config] sharding: global
[2023-07-01 11:01:23] [config] shuffle: data
[2023-07-01 11:01:23] [config] shuffle-in-ram: false
[2023-07-01 11:01:23] [config] sigterm: save-and-exit
[2023-07-01 11:01:23] [config] skip: false
[2023-07-01 11:01:23] [config] sqlite: ""
[2023-07-01 11:01:23] [config] sqlite-drop: false
[2023-07-01 11:01:23] [config] sync-freq: 200u
[2023-07-01 11:01:23] [config] sync-sgd: true
[2023-07-01 11:01:23] [config] tempdir: /tmp
[2023-07-01 11:01:23] [config] tied-embeddings: false
[2023-07-01 11:01:23] [config] tied-embeddings-all: true
[2023-07-01 11:01:23] [config] tied-embeddings-src: false
[2023-07-01 11:01:23] [config] train-embedder-rank:
[2023-07-01 11:01:23] [config]   []
[2023-07-01 11:01:23] [config] train-sets:
[2023-07-01 11:01:23] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:01:23] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:01:23] [config] transformer-aan-activation: swish
[2023-07-01 11:01:23] [config] transformer-aan-depth: 2
[2023-07-01 11:01:23] [config] transformer-aan-nogate: false
[2023-07-01 11:01:23] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:01:23] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:01:23] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:01:23] [config] transformer-depth-scaling: false
[2023-07-01 11:01:23] [config] transformer-dim-aan: 2048
[2023-07-01 11:01:23] [config] transformer-dim-ffn: 2048
[2023-07-01 11:01:23] [config] transformer-dropout: 0.1
[2023-07-01 11:01:23] [config] transformer-dropout-attention: 0
[2023-07-01 11:01:23] [config] transformer-dropout-ffn: 0
[2023-07-01 11:01:23] [config] transformer-ffn-activation: swish
[2023-07-01 11:01:23] [config] transformer-ffn-depth: 2
[2023-07-01 11:01:23] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:01:23] [config] transformer-heads: 8
[2023-07-01 11:01:23] [config] transformer-no-projection: false
[2023-07-01 11:01:23] [config] transformer-pool: false
[2023-07-01 11:01:23] [config] transformer-postprocess: dan
[2023-07-01 11:01:23] [config] transformer-postprocess-emb: d
[2023-07-01 11:01:23] [config] transformer-postprocess-top: ""
[2023-07-01 11:01:23] [config] transformer-preprocess: ""
[2023-07-01 11:01:23] [config] transformer-tied-layers:
[2023-07-01 11:01:23] [config]   []
[2023-07-01 11:01:23] [config] transformer-train-position-embeddings: false
[2023-07-01 11:01:23] [config] tsv: false
[2023-07-01 11:01:23] [config] tsv-fields: 0
[2023-07-01 11:01:23] [config] type: transformer
[2023-07-01 11:01:23] [config] ulr: false
[2023-07-01 11:01:23] [config] ulr-dim-emb: 0
[2023-07-01 11:01:23] [config] ulr-dropout: 0
[2023-07-01 11:01:23] [config] ulr-keys-vectors: ""
[2023-07-01 11:01:23] [config] ulr-query-vectors: ""
[2023-07-01 11:01:23] [config] ulr-softmax-temperature: 1
[2023-07-01 11:01:23] [config] ulr-trainable-transformation: false
[2023-07-01 11:01:23] [config] unlikelihood-loss: false
[2023-07-01 11:01:23] [config] valid-freq: 50000000
[2023-07-01 11:01:23] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:01:23] [config] valid-max-length: 1000
[2023-07-01 11:01:23] [config] valid-metrics:
[2023-07-01 11:01:23] [config]   - cross-entropy
[2023-07-01 11:01:23] [config]   - translation
[2023-07-01 11:01:23] [config] valid-mini-batch: 64
[2023-07-01 11:01:23] [config] valid-reset-stalled: false
[2023-07-01 11:01:23] [config] valid-script-args:
[2023-07-01 11:01:23] [config]   []
[2023-07-01 11:01:23] [config] valid-script-path: ""
[2023-07-01 11:01:23] [config] valid-sets:
[2023-07-01 11:01:23] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:01:23] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:01:23] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:01:23] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:01:23] [config] vocabs:
[2023-07-01 11:01:23] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:01:23] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:01:23] [config] word-penalty: 0
[2023-07-01 11:01:23] [config] word-scores: false
[2023-07-01 11:01:23] [config] workspace: 2048
[2023-07-01 11:01:23] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:01:23] Using synchronous SGD
[2023-07-01 11:01:23] Synced seed 1234
[2023-07-01 11:01:23] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:01:23] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:01:23] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:01:23] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:01:23] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:01:23] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:01:24] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:01:24] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:01:24] [comm] Using global sharding
[2023-07-01 11:01:24] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:01:24] [training] Using 1 GPUs
[2023-07-01 11:01:24] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:01:24] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:01:24] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:01:24] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:01:32] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:01:32] [valid] No post-processing script given for validating translator
[2023-07-01 11:01:32] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:01:32] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:01:32] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:01:32] [comm] Using global sharding
[2023-07-01 11:01:32] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:01:32] [training] Using 1 GPUs
[2023-07-01 11:01:32] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:01:33] Allocating memory for general optimizer shards
[2023-07-01 11:01:33] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:01:33] Loading Adam parameters
[2023-07-01 11:01:33] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:01:33] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:01:33] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:01:33] [data] Restoring the corpus state to epoch 44, batch 8127
[2023-07-01 11:01:33] [data] Shuffling data
[2023-07-01 11:01:33] [data] Done reading 20,192 sentences
[2023-07-01 11:01:33] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:01:33] Training started
[2023-07-01 11:01:33] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-07-01 11:01:34] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:01:34] Parameter type float32, optimization type float32, casting types false
[2023-07-01 11:01:59] Seen 20,073 samples
[2023-07-01 11:01:59] Starting data epoch 45 in logical epoch 45
[2023-07-01 11:01:59] Training finished
[2023-07-01 11:02:02] [valid] Ep. 45 : Up. 8316 : cross-entropy : 124.388 : stalled 2 times (last best: 124.257)
[2023-07-01 11:03:26] [valid] Ep. 45 : Up. 8316 : translation : 0 : new best
[2023-07-01 11:03:26] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:03:27] Saving Adam parameters
[2023-07-01 11:03:27] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:03:33] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:03:33] [marian] Running on node20.datos.cluster.uy as process 12595 with command line:
[2023-07-01 11:03:33] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 45 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:03:33] [config] after: 0e
[2023-07-01 11:03:33] [config] after-batches: 0
[2023-07-01 11:03:33] [config] after-epochs: 45
[2023-07-01 11:03:33] [config] all-caps-every: 0
[2023-07-01 11:03:33] [config] allow-unk: false
[2023-07-01 11:03:33] [config] authors: false
[2023-07-01 11:03:33] [config] beam-size: 12
[2023-07-01 11:03:33] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:03:33] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:03:33] [config] bert-masking-fraction: 0.15
[2023-07-01 11:03:33] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:03:33] [config] bert-train-type-embeddings: true
[2023-07-01 11:03:33] [config] bert-type-vocab-size: 2
[2023-07-01 11:03:33] [config] build-info: ""
[2023-07-01 11:03:33] [config] check-gradient-nan: false
[2023-07-01 11:03:33] [config] check-nan: false
[2023-07-01 11:03:33] [config] cite: false
[2023-07-01 11:03:33] [config] clip-norm: 5
[2023-07-01 11:03:33] [config] cost-scaling:
[2023-07-01 11:03:33] [config]   []
[2023-07-01 11:03:33] [config] cost-type: ce-sum
[2023-07-01 11:03:33] [config] cpu-threads: 0
[2023-07-01 11:03:33] [config] data-threads: 8
[2023-07-01 11:03:33] [config] data-weighting: ""
[2023-07-01 11:03:33] [config] data-weighting-type: sentence
[2023-07-01 11:03:33] [config] dec-cell: gru
[2023-07-01 11:03:33] [config] dec-cell-base-depth: 2
[2023-07-01 11:03:33] [config] dec-cell-high-depth: 1
[2023-07-01 11:03:33] [config] dec-depth: 2
[2023-07-01 11:03:33] [config] devices:
[2023-07-01 11:03:33] [config]   - 0
[2023-07-01 11:03:33] [config] dim-emb: 512
[2023-07-01 11:03:33] [config] dim-rnn: 1024
[2023-07-01 11:03:33] [config] dim-vocabs:
[2023-07-01 11:03:33] [config]   - 16384
[2023-07-01 11:03:33] [config]   - 16384
[2023-07-01 11:03:33] [config] disp-first: 0
[2023-07-01 11:03:33] [config] disp-freq: 1000u
[2023-07-01 11:03:33] [config] disp-label-counts: true
[2023-07-01 11:03:33] [config] dropout-rnn: 0
[2023-07-01 11:03:33] [config] dropout-src: 0
[2023-07-01 11:03:33] [config] dropout-trg: 0
[2023-07-01 11:03:33] [config] dump-config: ""
[2023-07-01 11:03:33] [config] dynamic-gradient-scaling:
[2023-07-01 11:03:33] [config]   []
[2023-07-01 11:03:33] [config] early-stopping: 10
[2023-07-01 11:03:33] [config] early-stopping-on: first
[2023-07-01 11:03:33] [config] embedding-fix-src: false
[2023-07-01 11:03:33] [config] embedding-fix-trg: false
[2023-07-01 11:03:33] [config] embedding-normalization: false
[2023-07-01 11:03:33] [config] embedding-vectors:
[2023-07-01 11:03:33] [config]   []
[2023-07-01 11:03:33] [config] enc-cell: gru
[2023-07-01 11:03:33] [config] enc-cell-depth: 1
[2023-07-01 11:03:33] [config] enc-depth: 2
[2023-07-01 11:03:33] [config] enc-type: bidirectional
[2023-07-01 11:03:33] [config] english-title-case-every: 0
[2023-07-01 11:03:33] [config] exponential-smoothing: 0.0001
[2023-07-01 11:03:33] [config] factor-weight: 1
[2023-07-01 11:03:33] [config] factors-combine: sum
[2023-07-01 11:03:33] [config] factors-dim-emb: 0
[2023-07-01 11:03:33] [config] gradient-checkpointing: false
[2023-07-01 11:03:33] [config] gradient-norm-average-window: 100
[2023-07-01 11:03:33] [config] guided-alignment: none
[2023-07-01 11:03:33] [config] guided-alignment-cost: mse
[2023-07-01 11:03:33] [config] guided-alignment-weight: 0.1
[2023-07-01 11:03:33] [config] ignore-model-config: false
[2023-07-01 11:03:33] [config] input-types:
[2023-07-01 11:03:33] [config]   []
[2023-07-01 11:03:33] [config] interpolate-env-vars: false
[2023-07-01 11:03:33] [config] keep-best: false
[2023-07-01 11:03:33] [config] label-smoothing: 0.1
[2023-07-01 11:03:33] [config] layer-normalization: false
[2023-07-01 11:03:33] [config] learn-rate: 0.0003
[2023-07-01 11:03:33] [config] lemma-dependency: ""
[2023-07-01 11:03:33] [config] lemma-dim-emb: 0
[2023-07-01 11:03:33] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:03:33] [config] log-level: info
[2023-07-01 11:03:33] [config] log-time-zone: ""
[2023-07-01 11:03:33] [config] logical-epoch:
[2023-07-01 11:03:33] [config]   - 1e
[2023-07-01 11:03:33] [config]   - 0
[2023-07-01 11:03:33] [config] lr-decay: 0
[2023-07-01 11:03:33] [config] lr-decay-freq: 50000
[2023-07-01 11:03:33] [config] lr-decay-inv-sqrt:
[2023-07-01 11:03:33] [config]   - 16000
[2023-07-01 11:03:33] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:03:33] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:03:33] [config] lr-decay-start:
[2023-07-01 11:03:33] [config]   - 10
[2023-07-01 11:03:33] [config]   - 1
[2023-07-01 11:03:33] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:03:33] [config] lr-report: true
[2023-07-01 11:03:33] [config] lr-warmup: 16000
[2023-07-01 11:03:33] [config] lr-warmup-at-reload: false
[2023-07-01 11:03:33] [config] lr-warmup-cycle: false
[2023-07-01 11:03:33] [config] lr-warmup-start-rate: 0
[2023-07-01 11:03:33] [config] max-length: 100
[2023-07-01 11:03:33] [config] max-length-crop: false
[2023-07-01 11:03:33] [config] max-length-factor: 3
[2023-07-01 11:03:33] [config] maxi-batch: 100
[2023-07-01 11:03:33] [config] maxi-batch-sort: trg
[2023-07-01 11:03:33] [config] mini-batch: 1000
[2023-07-01 11:03:33] [config] mini-batch-fit: true
[2023-07-01 11:03:33] [config] mini-batch-fit-step: 10
[2023-07-01 11:03:33] [config] mini-batch-round-up: true
[2023-07-01 11:03:33] [config] mini-batch-track-lr: false
[2023-07-01 11:03:33] [config] mini-batch-warmup: 0
[2023-07-01 11:03:33] [config] mini-batch-words: 0
[2023-07-01 11:03:33] [config] mini-batch-words-ref: 0
[2023-07-01 11:03:33] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:03:33] [config] multi-loss-type: sum
[2023-07-01 11:03:33] [config] n-best: false
[2023-07-01 11:03:33] [config] no-nccl: false
[2023-07-01 11:03:33] [config] no-reload: false
[2023-07-01 11:03:33] [config] no-restore-corpus: false
[2023-07-01 11:03:33] [config] normalize: 1
[2023-07-01 11:03:33] [config] normalize-gradient: false
[2023-07-01 11:03:33] [config] num-devices: 0
[2023-07-01 11:03:33] [config] optimizer: adam
[2023-07-01 11:03:33] [config] optimizer-delay: 1
[2023-07-01 11:03:33] [config] optimizer-params:
[2023-07-01 11:03:33] [config]   - 0.9
[2023-07-01 11:03:33] [config]   - 0.98
[2023-07-01 11:03:33] [config]   - 1e-09
[2023-07-01 11:03:33] [config] output-omit-bias: false
[2023-07-01 11:03:33] [config] overwrite: true
[2023-07-01 11:03:33] [config] precision:
[2023-07-01 11:03:33] [config]   - float32
[2023-07-01 11:03:33] [config]   - float32
[2023-07-01 11:03:33] [config] pretrained-model: ""
[2023-07-01 11:03:33] [config] quantize-biases: false
[2023-07-01 11:03:33] [config] quantize-bits: 0
[2023-07-01 11:03:33] [config] quantize-log-based: false
[2023-07-01 11:03:33] [config] quantize-optimization-steps: 0
[2023-07-01 11:03:33] [config] quiet: false
[2023-07-01 11:03:33] [config] quiet-translation: true
[2023-07-01 11:03:33] [config] relative-paths: false
[2023-07-01 11:03:33] [config] right-left: false
[2023-07-01 11:03:33] [config] save-freq: 10000u
[2023-07-01 11:03:33] [config] seed: 1234
[2023-07-01 11:03:33] [config] sentencepiece-alphas:
[2023-07-01 11:03:33] [config]   []
[2023-07-01 11:03:33] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:03:33] [config] sentencepiece-options: ""
[2023-07-01 11:03:33] [config] sharding: global
[2023-07-01 11:03:33] [config] shuffle: data
[2023-07-01 11:03:33] [config] shuffle-in-ram: false
[2023-07-01 11:03:33] [config] sigterm: save-and-exit
[2023-07-01 11:03:33] [config] skip: false
[2023-07-01 11:03:33] [config] sqlite: ""
[2023-07-01 11:03:33] [config] sqlite-drop: false
[2023-07-01 11:03:33] [config] sync-freq: 200u
[2023-07-01 11:03:33] [config] sync-sgd: true
[2023-07-01 11:03:33] [config] tempdir: /tmp
[2023-07-01 11:03:33] [config] tied-embeddings: false
[2023-07-01 11:03:33] [config] tied-embeddings-all: true
[2023-07-01 11:03:33] [config] tied-embeddings-src: false
[2023-07-01 11:03:33] [config] train-embedder-rank:
[2023-07-01 11:03:33] [config]   []
[2023-07-01 11:03:33] [config] train-sets:
[2023-07-01 11:03:33] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:03:33] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:03:33] [config] transformer-aan-activation: swish
[2023-07-01 11:03:33] [config] transformer-aan-depth: 2
[2023-07-01 11:03:33] [config] transformer-aan-nogate: false
[2023-07-01 11:03:33] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:03:33] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:03:33] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:03:33] [config] transformer-depth-scaling: false
[2023-07-01 11:03:33] [config] transformer-dim-aan: 2048
[2023-07-01 11:03:33] [config] transformer-dim-ffn: 2048
[2023-07-01 11:03:33] [config] transformer-dropout: 0.1
[2023-07-01 11:03:33] [config] transformer-dropout-attention: 0
[2023-07-01 11:03:33] [config] transformer-dropout-ffn: 0
[2023-07-01 11:03:33] [config] transformer-ffn-activation: swish
[2023-07-01 11:03:33] [config] transformer-ffn-depth: 2
[2023-07-01 11:03:33] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:03:33] [config] transformer-heads: 8
[2023-07-01 11:03:33] [config] transformer-no-projection: false
[2023-07-01 11:03:33] [config] transformer-pool: false
[2023-07-01 11:03:33] [config] transformer-postprocess: dan
[2023-07-01 11:03:33] [config] transformer-postprocess-emb: d
[2023-07-01 11:03:33] [config] transformer-postprocess-top: ""
[2023-07-01 11:03:33] [config] transformer-preprocess: ""
[2023-07-01 11:03:33] [config] transformer-tied-layers:
[2023-07-01 11:03:33] [config]   []
[2023-07-01 11:03:33] [config] transformer-train-position-embeddings: false
[2023-07-01 11:03:33] [config] tsv: false
[2023-07-01 11:03:33] [config] tsv-fields: 0
[2023-07-01 11:03:33] [config] type: transformer
[2023-07-01 11:03:33] [config] ulr: false
[2023-07-01 11:03:33] [config] ulr-dim-emb: 0
[2023-07-01 11:03:33] [config] ulr-dropout: 0
[2023-07-01 11:03:33] [config] ulr-keys-vectors: ""
[2023-07-01 11:03:33] [config] ulr-query-vectors: ""
[2023-07-01 11:03:33] [config] ulr-softmax-temperature: 1
[2023-07-01 11:03:33] [config] ulr-trainable-transformation: false
[2023-07-01 11:03:33] [config] unlikelihood-loss: false
[2023-07-01 11:03:33] [config] valid-freq: 50000000
[2023-07-01 11:03:33] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:03:33] [config] valid-max-length: 1000
[2023-07-01 11:03:33] [config] valid-metrics:
[2023-07-01 11:03:33] [config]   - cross-entropy
[2023-07-01 11:03:33] [config]   - translation
[2023-07-01 11:03:33] [config] valid-mini-batch: 64
[2023-07-01 11:03:33] [config] valid-reset-stalled: false
[2023-07-01 11:03:33] [config] valid-script-args:
[2023-07-01 11:03:33] [config]   []
[2023-07-01 11:03:33] [config] valid-script-path: ""
[2023-07-01 11:03:33] [config] valid-sets:
[2023-07-01 11:03:33] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:03:33] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:03:33] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:03:33] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:03:33] [config] vocabs:
[2023-07-01 11:03:33] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:03:33] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:03:33] [config] word-penalty: 0
[2023-07-01 11:03:33] [config] word-scores: false
[2023-07-01 11:03:33] [config] workspace: 2048
[2023-07-01 11:03:33] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:03:33] Using synchronous SGD
[2023-07-01 11:03:33] Synced seed 1234
[2023-07-01 11:03:33] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:03:33] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:03:33] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:03:33] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:03:33] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:03:33] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:03:34] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:03:34] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:03:34] [comm] Using global sharding
[2023-07-01 11:03:34] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:03:34] [training] Using 1 GPUs
[2023-07-01 11:03:34] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:03:34] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:03:35] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:03:35] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:03:42] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:03:42] [valid] No post-processing script given for validating translator
[2023-07-01 11:03:43] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:03:43] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:03:43] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:03:43] [comm] Using global sharding
[2023-07-01 11:03:43] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:03:43] [training] Using 1 GPUs
[2023-07-01 11:03:43] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:03:43] Allocating memory for general optimizer shards
[2023-07-01 11:03:43] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:03:43] Loading Adam parameters
[2023-07-01 11:03:43] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:03:43] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:03:44] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:03:44] [data] Restoring the corpus state to epoch 45, batch 8316
[2023-07-01 11:03:44] [data] Shuffling data
[2023-07-01 11:03:44] [data] Done reading 20,192 sentences
[2023-07-01 11:03:44] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:03:44] Training started
[2023-07-01 11:03:44] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-07-01 11:03:44] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:03:44] Parameter type float32, optimization type float32, casting types false
[2023-07-01 11:04:09] Seen 20,073 samples
[2023-07-01 11:04:09] Starting data epoch 46 in logical epoch 46
[2023-07-01 11:04:09] Training finished
[2023-07-01 11:04:13] [valid] Ep. 46 : Up. 8505 : cross-entropy : 124.564 : stalled 3 times (last best: 124.257)
[2023-07-01 11:05:40] [valid] Ep. 46 : Up. 8505 : translation : 0 : new best
[2023-07-01 11:05:40] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:05:41] Saving Adam parameters
[2023-07-01 11:05:41] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:05:47] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:05:47] [marian] Running on node20.datos.cluster.uy as process 12757 with command line:
[2023-07-01 11:05:47] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 46 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:05:47] [config] after: 0e
[2023-07-01 11:05:47] [config] after-batches: 0
[2023-07-01 11:05:47] [config] after-epochs: 46
[2023-07-01 11:05:47] [config] all-caps-every: 0
[2023-07-01 11:05:47] [config] allow-unk: false
[2023-07-01 11:05:47] [config] authors: false
[2023-07-01 11:05:47] [config] beam-size: 12
[2023-07-01 11:05:47] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:05:47] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:05:47] [config] bert-masking-fraction: 0.15
[2023-07-01 11:05:47] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:05:47] [config] bert-train-type-embeddings: true
[2023-07-01 11:05:47] [config] bert-type-vocab-size: 2
[2023-07-01 11:05:47] [config] build-info: ""
[2023-07-01 11:05:47] [config] check-gradient-nan: false
[2023-07-01 11:05:47] [config] check-nan: false
[2023-07-01 11:05:47] [config] cite: false
[2023-07-01 11:05:47] [config] clip-norm: 5
[2023-07-01 11:05:47] [config] cost-scaling:
[2023-07-01 11:05:47] [config]   []
[2023-07-01 11:05:47] [config] cost-type: ce-sum
[2023-07-01 11:05:47] [config] cpu-threads: 0
[2023-07-01 11:05:47] [config] data-threads: 8
[2023-07-01 11:05:47] [config] data-weighting: ""
[2023-07-01 11:05:47] [config] data-weighting-type: sentence
[2023-07-01 11:05:47] [config] dec-cell: gru
[2023-07-01 11:05:47] [config] dec-cell-base-depth: 2
[2023-07-01 11:05:47] [config] dec-cell-high-depth: 1
[2023-07-01 11:05:47] [config] dec-depth: 2
[2023-07-01 11:05:47] [config] devices:
[2023-07-01 11:05:47] [config]   - 0
[2023-07-01 11:05:47] [config] dim-emb: 512
[2023-07-01 11:05:47] [config] dim-rnn: 1024
[2023-07-01 11:05:47] [config] dim-vocabs:
[2023-07-01 11:05:47] [config]   - 16384
[2023-07-01 11:05:47] [config]   - 16384
[2023-07-01 11:05:47] [config] disp-first: 0
[2023-07-01 11:05:47] [config] disp-freq: 1000u
[2023-07-01 11:05:47] [config] disp-label-counts: true
[2023-07-01 11:05:47] [config] dropout-rnn: 0
[2023-07-01 11:05:47] [config] dropout-src: 0
[2023-07-01 11:05:47] [config] dropout-trg: 0
[2023-07-01 11:05:47] [config] dump-config: ""
[2023-07-01 11:05:47] [config] dynamic-gradient-scaling:
[2023-07-01 11:05:47] [config]   []
[2023-07-01 11:05:47] [config] early-stopping: 10
[2023-07-01 11:05:47] [config] early-stopping-on: first
[2023-07-01 11:05:47] [config] embedding-fix-src: false
[2023-07-01 11:05:47] [config] embedding-fix-trg: false
[2023-07-01 11:05:47] [config] embedding-normalization: false
[2023-07-01 11:05:47] [config] embedding-vectors:
[2023-07-01 11:05:47] [config]   []
[2023-07-01 11:05:47] [config] enc-cell: gru
[2023-07-01 11:05:47] [config] enc-cell-depth: 1
[2023-07-01 11:05:47] [config] enc-depth: 2
[2023-07-01 11:05:47] [config] enc-type: bidirectional
[2023-07-01 11:05:47] [config] english-title-case-every: 0
[2023-07-01 11:05:47] [config] exponential-smoothing: 0.0001
[2023-07-01 11:05:47] [config] factor-weight: 1
[2023-07-01 11:05:47] [config] factors-combine: sum
[2023-07-01 11:05:47] [config] factors-dim-emb: 0
[2023-07-01 11:05:47] [config] gradient-checkpointing: false
[2023-07-01 11:05:47] [config] gradient-norm-average-window: 100
[2023-07-01 11:05:47] [config] guided-alignment: none
[2023-07-01 11:05:47] [config] guided-alignment-cost: mse
[2023-07-01 11:05:47] [config] guided-alignment-weight: 0.1
[2023-07-01 11:05:47] [config] ignore-model-config: false
[2023-07-01 11:05:47] [config] input-types:
[2023-07-01 11:05:47] [config]   []
[2023-07-01 11:05:47] [config] interpolate-env-vars: false
[2023-07-01 11:05:47] [config] keep-best: false
[2023-07-01 11:05:47] [config] label-smoothing: 0.1
[2023-07-01 11:05:47] [config] layer-normalization: false
[2023-07-01 11:05:47] [config] learn-rate: 0.0003
[2023-07-01 11:05:47] [config] lemma-dependency: ""
[2023-07-01 11:05:47] [config] lemma-dim-emb: 0
[2023-07-01 11:05:47] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:05:47] [config] log-level: info
[2023-07-01 11:05:47] [config] log-time-zone: ""
[2023-07-01 11:05:47] [config] logical-epoch:
[2023-07-01 11:05:47] [config]   - 1e
[2023-07-01 11:05:47] [config]   - 0
[2023-07-01 11:05:47] [config] lr-decay: 0
[2023-07-01 11:05:47] [config] lr-decay-freq: 50000
[2023-07-01 11:05:47] [config] lr-decay-inv-sqrt:
[2023-07-01 11:05:47] [config]   - 16000
[2023-07-01 11:05:47] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:05:47] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:05:47] [config] lr-decay-start:
[2023-07-01 11:05:47] [config]   - 10
[2023-07-01 11:05:47] [config]   - 1
[2023-07-01 11:05:47] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:05:47] [config] lr-report: true
[2023-07-01 11:05:47] [config] lr-warmup: 16000
[2023-07-01 11:05:47] [config] lr-warmup-at-reload: false
[2023-07-01 11:05:47] [config] lr-warmup-cycle: false
[2023-07-01 11:05:47] [config] lr-warmup-start-rate: 0
[2023-07-01 11:05:47] [config] max-length: 100
[2023-07-01 11:05:47] [config] max-length-crop: false
[2023-07-01 11:05:47] [config] max-length-factor: 3
[2023-07-01 11:05:47] [config] maxi-batch: 100
[2023-07-01 11:05:47] [config] maxi-batch-sort: trg
[2023-07-01 11:05:47] [config] mini-batch: 1000
[2023-07-01 11:05:47] [config] mini-batch-fit: true
[2023-07-01 11:05:47] [config] mini-batch-fit-step: 10
[2023-07-01 11:05:47] [config] mini-batch-round-up: true
[2023-07-01 11:05:47] [config] mini-batch-track-lr: false
[2023-07-01 11:05:47] [config] mini-batch-warmup: 0
[2023-07-01 11:05:47] [config] mini-batch-words: 0
[2023-07-01 11:05:47] [config] mini-batch-words-ref: 0
[2023-07-01 11:05:47] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:05:47] [config] multi-loss-type: sum
[2023-07-01 11:05:47] [config] n-best: false
[2023-07-01 11:05:47] [config] no-nccl: false
[2023-07-01 11:05:47] [config] no-reload: false
[2023-07-01 11:05:47] [config] no-restore-corpus: false
[2023-07-01 11:05:47] [config] normalize: 1
[2023-07-01 11:05:47] [config] normalize-gradient: false
[2023-07-01 11:05:47] [config] num-devices: 0
[2023-07-01 11:05:47] [config] optimizer: adam
[2023-07-01 11:05:47] [config] optimizer-delay: 1
[2023-07-01 11:05:47] [config] optimizer-params:
[2023-07-01 11:05:47] [config]   - 0.9
[2023-07-01 11:05:47] [config]   - 0.98
[2023-07-01 11:05:47] [config]   - 1e-09
[2023-07-01 11:05:47] [config] output-omit-bias: false
[2023-07-01 11:05:47] [config] overwrite: true
[2023-07-01 11:05:47] [config] precision:
[2023-07-01 11:05:47] [config]   - float32
[2023-07-01 11:05:47] [config]   - float32
[2023-07-01 11:05:47] [config] pretrained-model: ""
[2023-07-01 11:05:47] [config] quantize-biases: false
[2023-07-01 11:05:47] [config] quantize-bits: 0
[2023-07-01 11:05:47] [config] quantize-log-based: false
[2023-07-01 11:05:47] [config] quantize-optimization-steps: 0
[2023-07-01 11:05:47] [config] quiet: false
[2023-07-01 11:05:47] [config] quiet-translation: true
[2023-07-01 11:05:47] [config] relative-paths: false
[2023-07-01 11:05:47] [config] right-left: false
[2023-07-01 11:05:47] [config] save-freq: 10000u
[2023-07-01 11:05:47] [config] seed: 1234
[2023-07-01 11:05:47] [config] sentencepiece-alphas:
[2023-07-01 11:05:47] [config]   []
[2023-07-01 11:05:47] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:05:47] [config] sentencepiece-options: ""
[2023-07-01 11:05:47] [config] sharding: global
[2023-07-01 11:05:47] [config] shuffle: data
[2023-07-01 11:05:47] [config] shuffle-in-ram: false
[2023-07-01 11:05:47] [config] sigterm: save-and-exit
[2023-07-01 11:05:47] [config] skip: false
[2023-07-01 11:05:47] [config] sqlite: ""
[2023-07-01 11:05:47] [config] sqlite-drop: false
[2023-07-01 11:05:47] [config] sync-freq: 200u
[2023-07-01 11:05:47] [config] sync-sgd: true
[2023-07-01 11:05:47] [config] tempdir: /tmp
[2023-07-01 11:05:47] [config] tied-embeddings: false
[2023-07-01 11:05:47] [config] tied-embeddings-all: true
[2023-07-01 11:05:47] [config] tied-embeddings-src: false
[2023-07-01 11:05:47] [config] train-embedder-rank:
[2023-07-01 11:05:47] [config]   []
[2023-07-01 11:05:47] [config] train-sets:
[2023-07-01 11:05:47] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:05:47] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:05:47] [config] transformer-aan-activation: swish
[2023-07-01 11:05:47] [config] transformer-aan-depth: 2
[2023-07-01 11:05:47] [config] transformer-aan-nogate: false
[2023-07-01 11:05:47] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:05:47] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:05:47] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:05:47] [config] transformer-depth-scaling: false
[2023-07-01 11:05:47] [config] transformer-dim-aan: 2048
[2023-07-01 11:05:47] [config] transformer-dim-ffn: 2048
[2023-07-01 11:05:47] [config] transformer-dropout: 0.1
[2023-07-01 11:05:47] [config] transformer-dropout-attention: 0
[2023-07-01 11:05:47] [config] transformer-dropout-ffn: 0
[2023-07-01 11:05:47] [config] transformer-ffn-activation: swish
[2023-07-01 11:05:47] [config] transformer-ffn-depth: 2
[2023-07-01 11:05:47] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:05:47] [config] transformer-heads: 8
[2023-07-01 11:05:47] [config] transformer-no-projection: false
[2023-07-01 11:05:47] [config] transformer-pool: false
[2023-07-01 11:05:47] [config] transformer-postprocess: dan
[2023-07-01 11:05:47] [config] transformer-postprocess-emb: d
[2023-07-01 11:05:47] [config] transformer-postprocess-top: ""
[2023-07-01 11:05:47] [config] transformer-preprocess: ""
[2023-07-01 11:05:47] [config] transformer-tied-layers:
[2023-07-01 11:05:47] [config]   []
[2023-07-01 11:05:47] [config] transformer-train-position-embeddings: false
[2023-07-01 11:05:47] [config] tsv: false
[2023-07-01 11:05:47] [config] tsv-fields: 0
[2023-07-01 11:05:47] [config] type: transformer
[2023-07-01 11:05:47] [config] ulr: false
[2023-07-01 11:05:47] [config] ulr-dim-emb: 0
[2023-07-01 11:05:47] [config] ulr-dropout: 0
[2023-07-01 11:05:47] [config] ulr-keys-vectors: ""
[2023-07-01 11:05:47] [config] ulr-query-vectors: ""
[2023-07-01 11:05:47] [config] ulr-softmax-temperature: 1
[2023-07-01 11:05:47] [config] ulr-trainable-transformation: false
[2023-07-01 11:05:47] [config] unlikelihood-loss: false
[2023-07-01 11:05:47] [config] valid-freq: 50000000
[2023-07-01 11:05:47] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:05:47] [config] valid-max-length: 1000
[2023-07-01 11:05:47] [config] valid-metrics:
[2023-07-01 11:05:47] [config]   - cross-entropy
[2023-07-01 11:05:47] [config]   - translation
[2023-07-01 11:05:47] [config] valid-mini-batch: 64
[2023-07-01 11:05:47] [config] valid-reset-stalled: false
[2023-07-01 11:05:47] [config] valid-script-args:
[2023-07-01 11:05:47] [config]   []
[2023-07-01 11:05:47] [config] valid-script-path: ""
[2023-07-01 11:05:47] [config] valid-sets:
[2023-07-01 11:05:47] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:05:47] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:05:47] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:05:47] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:05:47] [config] vocabs:
[2023-07-01 11:05:47] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:05:47] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:05:47] [config] word-penalty: 0
[2023-07-01 11:05:47] [config] word-scores: false
[2023-07-01 11:05:47] [config] workspace: 2048
[2023-07-01 11:05:47] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:05:47] Using synchronous SGD
[2023-07-01 11:05:48] Synced seed 1234
[2023-07-01 11:05:48] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:05:48] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:05:48] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:05:48] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:05:48] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:05:48] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:05:49] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:05:49] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:05:49] [comm] Using global sharding
[2023-07-01 11:05:49] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:05:49] [training] Using 1 GPUs
[2023-07-01 11:05:49] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:05:49] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:05:49] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:05:49] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:05:57] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:05:57] [valid] No post-processing script given for validating translator
[2023-07-01 11:05:57] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:05:57] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:05:57] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:05:57] [comm] Using global sharding
[2023-07-01 11:05:57] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:05:57] [training] Using 1 GPUs
[2023-07-01 11:05:57] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:05:58] Allocating memory for general optimizer shards
[2023-07-01 11:05:58] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:05:58] Loading Adam parameters
[2023-07-01 11:05:58] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:05:58] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:05:58] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:05:58] [data] Restoring the corpus state to epoch 46, batch 8505
[2023-07-01 11:05:58] [data] Shuffling data
[2023-07-01 11:05:58] [data] Done reading 20,192 sentences
[2023-07-01 11:05:58] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:05:58] Training started
[2023-07-01 11:05:58] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-07-01 11:05:58] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:05:58] Parameter type float32, optimization type float32, casting types false
[2023-07-01 11:06:22] Seen 20,073 samples
[2023-07-01 11:06:22] Starting data epoch 47 in logical epoch 47
[2023-07-01 11:06:22] Training finished
[2023-07-01 11:06:25] [valid] Ep. 47 : Up. 8694 : cross-entropy : 124.793 : stalled 4 times (last best: 124.257)
[2023-07-01 11:07:52] [valid] Ep. 47 : Up. 8694 : translation : 0 : new best
[2023-07-01 11:07:52] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:07:53] Saving Adam parameters
[2023-07-01 11:07:53] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:08:00] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:08:00] [marian] Running on node20.datos.cluster.uy as process 13235 with command line:
[2023-07-01 11:08:00] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 47 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:08:00] [config] after: 0e
[2023-07-01 11:08:00] [config] after-batches: 0
[2023-07-01 11:08:00] [config] after-epochs: 47
[2023-07-01 11:08:00] [config] all-caps-every: 0
[2023-07-01 11:08:00] [config] allow-unk: false
[2023-07-01 11:08:00] [config] authors: false
[2023-07-01 11:08:00] [config] beam-size: 12
[2023-07-01 11:08:00] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:08:00] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:08:00] [config] bert-masking-fraction: 0.15
[2023-07-01 11:08:00] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:08:00] [config] bert-train-type-embeddings: true
[2023-07-01 11:08:00] [config] bert-type-vocab-size: 2
[2023-07-01 11:08:00] [config] build-info: ""
[2023-07-01 11:08:00] [config] check-gradient-nan: false
[2023-07-01 11:08:00] [config] check-nan: false
[2023-07-01 11:08:00] [config] cite: false
[2023-07-01 11:08:00] [config] clip-norm: 5
[2023-07-01 11:08:00] [config] cost-scaling:
[2023-07-01 11:08:00] [config]   []
[2023-07-01 11:08:00] [config] cost-type: ce-sum
[2023-07-01 11:08:00] [config] cpu-threads: 0
[2023-07-01 11:08:00] [config] data-threads: 8
[2023-07-01 11:08:00] [config] data-weighting: ""
[2023-07-01 11:08:00] [config] data-weighting-type: sentence
[2023-07-01 11:08:00] [config] dec-cell: gru
[2023-07-01 11:08:00] [config] dec-cell-base-depth: 2
[2023-07-01 11:08:00] [config] dec-cell-high-depth: 1
[2023-07-01 11:08:00] [config] dec-depth: 2
[2023-07-01 11:08:00] [config] devices:
[2023-07-01 11:08:00] [config]   - 0
[2023-07-01 11:08:00] [config] dim-emb: 512
[2023-07-01 11:08:00] [config] dim-rnn: 1024
[2023-07-01 11:08:00] [config] dim-vocabs:
[2023-07-01 11:08:00] [config]   - 16384
[2023-07-01 11:08:00] [config]   - 16384
[2023-07-01 11:08:00] [config] disp-first: 0
[2023-07-01 11:08:00] [config] disp-freq: 1000u
[2023-07-01 11:08:00] [config] disp-label-counts: true
[2023-07-01 11:08:00] [config] dropout-rnn: 0
[2023-07-01 11:08:00] [config] dropout-src: 0
[2023-07-01 11:08:00] [config] dropout-trg: 0
[2023-07-01 11:08:00] [config] dump-config: ""
[2023-07-01 11:08:00] [config] dynamic-gradient-scaling:
[2023-07-01 11:08:00] [config]   []
[2023-07-01 11:08:00] [config] early-stopping: 10
[2023-07-01 11:08:00] [config] early-stopping-on: first
[2023-07-01 11:08:00] [config] embedding-fix-src: false
[2023-07-01 11:08:00] [config] embedding-fix-trg: false
[2023-07-01 11:08:00] [config] embedding-normalization: false
[2023-07-01 11:08:00] [config] embedding-vectors:
[2023-07-01 11:08:00] [config]   []
[2023-07-01 11:08:00] [config] enc-cell: gru
[2023-07-01 11:08:00] [config] enc-cell-depth: 1
[2023-07-01 11:08:00] [config] enc-depth: 2
[2023-07-01 11:08:00] [config] enc-type: bidirectional
[2023-07-01 11:08:00] [config] english-title-case-every: 0
[2023-07-01 11:08:00] [config] exponential-smoothing: 0.0001
[2023-07-01 11:08:00] [config] factor-weight: 1
[2023-07-01 11:08:00] [config] factors-combine: sum
[2023-07-01 11:08:00] [config] factors-dim-emb: 0
[2023-07-01 11:08:00] [config] gradient-checkpointing: false
[2023-07-01 11:08:00] [config] gradient-norm-average-window: 100
[2023-07-01 11:08:00] [config] guided-alignment: none
[2023-07-01 11:08:00] [config] guided-alignment-cost: mse
[2023-07-01 11:08:00] [config] guided-alignment-weight: 0.1
[2023-07-01 11:08:00] [config] ignore-model-config: false
[2023-07-01 11:08:00] [config] input-types:
[2023-07-01 11:08:00] [config]   []
[2023-07-01 11:08:00] [config] interpolate-env-vars: false
[2023-07-01 11:08:00] [config] keep-best: false
[2023-07-01 11:08:00] [config] label-smoothing: 0.1
[2023-07-01 11:08:00] [config] layer-normalization: false
[2023-07-01 11:08:00] [config] learn-rate: 0.0003
[2023-07-01 11:08:00] [config] lemma-dependency: ""
[2023-07-01 11:08:00] [config] lemma-dim-emb: 0
[2023-07-01 11:08:00] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:08:00] [config] log-level: info
[2023-07-01 11:08:00] [config] log-time-zone: ""
[2023-07-01 11:08:00] [config] logical-epoch:
[2023-07-01 11:08:00] [config]   - 1e
[2023-07-01 11:08:00] [config]   - 0
[2023-07-01 11:08:00] [config] lr-decay: 0
[2023-07-01 11:08:00] [config] lr-decay-freq: 50000
[2023-07-01 11:08:00] [config] lr-decay-inv-sqrt:
[2023-07-01 11:08:00] [config]   - 16000
[2023-07-01 11:08:00] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:08:00] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:08:00] [config] lr-decay-start:
[2023-07-01 11:08:00] [config]   - 10
[2023-07-01 11:08:00] [config]   - 1
[2023-07-01 11:08:00] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:08:00] [config] lr-report: true
[2023-07-01 11:08:00] [config] lr-warmup: 16000
[2023-07-01 11:08:00] [config] lr-warmup-at-reload: false
[2023-07-01 11:08:00] [config] lr-warmup-cycle: false
[2023-07-01 11:08:00] [config] lr-warmup-start-rate: 0
[2023-07-01 11:08:00] [config] max-length: 100
[2023-07-01 11:08:00] [config] max-length-crop: false
[2023-07-01 11:08:00] [config] max-length-factor: 3
[2023-07-01 11:08:00] [config] maxi-batch: 100
[2023-07-01 11:08:00] [config] maxi-batch-sort: trg
[2023-07-01 11:08:00] [config] mini-batch: 1000
[2023-07-01 11:08:00] [config] mini-batch-fit: true
[2023-07-01 11:08:00] [config] mini-batch-fit-step: 10
[2023-07-01 11:08:00] [config] mini-batch-round-up: true
[2023-07-01 11:08:00] [config] mini-batch-track-lr: false
[2023-07-01 11:08:00] [config] mini-batch-warmup: 0
[2023-07-01 11:08:00] [config] mini-batch-words: 0
[2023-07-01 11:08:00] [config] mini-batch-words-ref: 0
[2023-07-01 11:08:00] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:08:00] [config] multi-loss-type: sum
[2023-07-01 11:08:00] [config] n-best: false
[2023-07-01 11:08:00] [config] no-nccl: false
[2023-07-01 11:08:00] [config] no-reload: false
[2023-07-01 11:08:00] [config] no-restore-corpus: false
[2023-07-01 11:08:00] [config] normalize: 1
[2023-07-01 11:08:00] [config] normalize-gradient: false
[2023-07-01 11:08:00] [config] num-devices: 0
[2023-07-01 11:08:00] [config] optimizer: adam
[2023-07-01 11:08:00] [config] optimizer-delay: 1
[2023-07-01 11:08:00] [config] optimizer-params:
[2023-07-01 11:08:00] [config]   - 0.9
[2023-07-01 11:08:00] [config]   - 0.98
[2023-07-01 11:08:00] [config]   - 1e-09
[2023-07-01 11:08:00] [config] output-omit-bias: false
[2023-07-01 11:08:00] [config] overwrite: true
[2023-07-01 11:08:00] [config] precision:
[2023-07-01 11:08:00] [config]   - float32
[2023-07-01 11:08:00] [config]   - float32
[2023-07-01 11:08:00] [config] pretrained-model: ""
[2023-07-01 11:08:00] [config] quantize-biases: false
[2023-07-01 11:08:00] [config] quantize-bits: 0
[2023-07-01 11:08:00] [config] quantize-log-based: false
[2023-07-01 11:08:00] [config] quantize-optimization-steps: 0
[2023-07-01 11:08:00] [config] quiet: false
[2023-07-01 11:08:00] [config] quiet-translation: true
[2023-07-01 11:08:00] [config] relative-paths: false
[2023-07-01 11:08:00] [config] right-left: false
[2023-07-01 11:08:00] [config] save-freq: 10000u
[2023-07-01 11:08:00] [config] seed: 1234
[2023-07-01 11:08:00] [config] sentencepiece-alphas:
[2023-07-01 11:08:00] [config]   []
[2023-07-01 11:08:00] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:08:00] [config] sentencepiece-options: ""
[2023-07-01 11:08:00] [config] sharding: global
[2023-07-01 11:08:00] [config] shuffle: data
[2023-07-01 11:08:00] [config] shuffle-in-ram: false
[2023-07-01 11:08:00] [config] sigterm: save-and-exit
[2023-07-01 11:08:00] [config] skip: false
[2023-07-01 11:08:00] [config] sqlite: ""
[2023-07-01 11:08:00] [config] sqlite-drop: false
[2023-07-01 11:08:00] [config] sync-freq: 200u
[2023-07-01 11:08:00] [config] sync-sgd: true
[2023-07-01 11:08:00] [config] tempdir: /tmp
[2023-07-01 11:08:00] [config] tied-embeddings: false
[2023-07-01 11:08:00] [config] tied-embeddings-all: true
[2023-07-01 11:08:00] [config] tied-embeddings-src: false
[2023-07-01 11:08:00] [config] train-embedder-rank:
[2023-07-01 11:08:00] [config]   []
[2023-07-01 11:08:00] [config] train-sets:
[2023-07-01 11:08:00] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:08:00] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:08:00] [config] transformer-aan-activation: swish
[2023-07-01 11:08:00] [config] transformer-aan-depth: 2
[2023-07-01 11:08:00] [config] transformer-aan-nogate: false
[2023-07-01 11:08:00] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:08:00] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:08:00] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:08:00] [config] transformer-depth-scaling: false
[2023-07-01 11:08:00] [config] transformer-dim-aan: 2048
[2023-07-01 11:08:00] [config] transformer-dim-ffn: 2048
[2023-07-01 11:08:00] [config] transformer-dropout: 0.1
[2023-07-01 11:08:00] [config] transformer-dropout-attention: 0
[2023-07-01 11:08:00] [config] transformer-dropout-ffn: 0
[2023-07-01 11:08:00] [config] transformer-ffn-activation: swish
[2023-07-01 11:08:00] [config] transformer-ffn-depth: 2
[2023-07-01 11:08:00] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:08:00] [config] transformer-heads: 8
[2023-07-01 11:08:00] [config] transformer-no-projection: false
[2023-07-01 11:08:00] [config] transformer-pool: false
[2023-07-01 11:08:00] [config] transformer-postprocess: dan
[2023-07-01 11:08:00] [config] transformer-postprocess-emb: d
[2023-07-01 11:08:00] [config] transformer-postprocess-top: ""
[2023-07-01 11:08:00] [config] transformer-preprocess: ""
[2023-07-01 11:08:00] [config] transformer-tied-layers:
[2023-07-01 11:08:00] [config]   []
[2023-07-01 11:08:00] [config] transformer-train-position-embeddings: false
[2023-07-01 11:08:00] [config] tsv: false
[2023-07-01 11:08:00] [config] tsv-fields: 0
[2023-07-01 11:08:00] [config] type: transformer
[2023-07-01 11:08:00] [config] ulr: false
[2023-07-01 11:08:00] [config] ulr-dim-emb: 0
[2023-07-01 11:08:00] [config] ulr-dropout: 0
[2023-07-01 11:08:00] [config] ulr-keys-vectors: ""
[2023-07-01 11:08:00] [config] ulr-query-vectors: ""
[2023-07-01 11:08:00] [config] ulr-softmax-temperature: 1
[2023-07-01 11:08:00] [config] ulr-trainable-transformation: false
[2023-07-01 11:08:00] [config] unlikelihood-loss: false
[2023-07-01 11:08:00] [config] valid-freq: 50000000
[2023-07-01 11:08:00] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:08:00] [config] valid-max-length: 1000
[2023-07-01 11:08:00] [config] valid-metrics:
[2023-07-01 11:08:00] [config]   - cross-entropy
[2023-07-01 11:08:00] [config]   - translation
[2023-07-01 11:08:00] [config] valid-mini-batch: 64
[2023-07-01 11:08:00] [config] valid-reset-stalled: false
[2023-07-01 11:08:00] [config] valid-script-args:
[2023-07-01 11:08:00] [config]   []
[2023-07-01 11:08:00] [config] valid-script-path: ""
[2023-07-01 11:08:00] [config] valid-sets:
[2023-07-01 11:08:00] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:08:00] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:08:00] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:08:00] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:08:00] [config] vocabs:
[2023-07-01 11:08:00] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:08:00] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:08:00] [config] word-penalty: 0
[2023-07-01 11:08:00] [config] word-scores: false
[2023-07-01 11:08:00] [config] workspace: 2048
[2023-07-01 11:08:00] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:08:00] Using synchronous SGD
[2023-07-01 11:08:00] Synced seed 1234
[2023-07-01 11:08:00] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:08:00] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:08:00] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:08:00] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:08:00] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:08:00] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:08:01] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:08:01] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:08:01] [comm] Using global sharding
[2023-07-01 11:08:01] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:08:01] [training] Using 1 GPUs
[2023-07-01 11:08:01] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:08:01] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:08:01] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:08:01] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:08:09] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:08:09] [valid] No post-processing script given for validating translator
[2023-07-01 11:08:09] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:08:09] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:08:09] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:08:09] [comm] Using global sharding
[2023-07-01 11:08:09] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:08:09] [training] Using 1 GPUs
[2023-07-01 11:08:09] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:08:10] Allocating memory for general optimizer shards
[2023-07-01 11:08:10] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:08:10] Loading Adam parameters
[2023-07-01 11:08:10] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:08:10] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:08:10] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:08:10] [data] Restoring the corpus state to epoch 47, batch 8694
[2023-07-01 11:08:10] [data] Shuffling data
[2023-07-01 11:08:10] [data] Done reading 20,192 sentences
[2023-07-01 11:08:10] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:08:10] Training started
[2023-07-01 11:08:10] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-07-01 11:08:10] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:08:10] Parameter type float32, optimization type float32, casting types false
[2023-07-01 11:08:34] Seen 20,073 samples
[2023-07-01 11:08:34] Starting data epoch 48 in logical epoch 48
[2023-07-01 11:08:34] Training finished
[2023-07-01 11:08:38] [valid] Ep. 48 : Up. 8883 : cross-entropy : 125.093 : stalled 5 times (last best: 124.257)
[2023-07-01 11:10:04] [valid] Ep. 48 : Up. 8883 : translation : 0 : new best
[2023-07-01 11:10:04] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:10:05] Saving Adam parameters
[2023-07-01 11:10:05] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:10:11] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:10:11] [marian] Running on node20.datos.cluster.uy as process 13399 with command line:
[2023-07-01 11:10:11] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 48 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:10:11] [config] after: 0e
[2023-07-01 11:10:11] [config] after-batches: 0
[2023-07-01 11:10:11] [config] after-epochs: 48
[2023-07-01 11:10:11] [config] all-caps-every: 0
[2023-07-01 11:10:11] [config] allow-unk: false
[2023-07-01 11:10:11] [config] authors: false
[2023-07-01 11:10:11] [config] beam-size: 12
[2023-07-01 11:10:11] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:10:11] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:10:11] [config] bert-masking-fraction: 0.15
[2023-07-01 11:10:11] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:10:11] [config] bert-train-type-embeddings: true
[2023-07-01 11:10:11] [config] bert-type-vocab-size: 2
[2023-07-01 11:10:11] [config] build-info: ""
[2023-07-01 11:10:11] [config] check-gradient-nan: false
[2023-07-01 11:10:11] [config] check-nan: false
[2023-07-01 11:10:11] [config] cite: false
[2023-07-01 11:10:11] [config] clip-norm: 5
[2023-07-01 11:10:11] [config] cost-scaling:
[2023-07-01 11:10:11] [config]   []
[2023-07-01 11:10:11] [config] cost-type: ce-sum
[2023-07-01 11:10:11] [config] cpu-threads: 0
[2023-07-01 11:10:11] [config] data-threads: 8
[2023-07-01 11:10:11] [config] data-weighting: ""
[2023-07-01 11:10:11] [config] data-weighting-type: sentence
[2023-07-01 11:10:11] [config] dec-cell: gru
[2023-07-01 11:10:11] [config] dec-cell-base-depth: 2
[2023-07-01 11:10:11] [config] dec-cell-high-depth: 1
[2023-07-01 11:10:11] [config] dec-depth: 2
[2023-07-01 11:10:11] [config] devices:
[2023-07-01 11:10:11] [config]   - 0
[2023-07-01 11:10:11] [config] dim-emb: 512
[2023-07-01 11:10:11] [config] dim-rnn: 1024
[2023-07-01 11:10:11] [config] dim-vocabs:
[2023-07-01 11:10:11] [config]   - 16384
[2023-07-01 11:10:11] [config]   - 16384
[2023-07-01 11:10:11] [config] disp-first: 0
[2023-07-01 11:10:11] [config] disp-freq: 1000u
[2023-07-01 11:10:11] [config] disp-label-counts: true
[2023-07-01 11:10:11] [config] dropout-rnn: 0
[2023-07-01 11:10:11] [config] dropout-src: 0
[2023-07-01 11:10:11] [config] dropout-trg: 0
[2023-07-01 11:10:11] [config] dump-config: ""
[2023-07-01 11:10:11] [config] dynamic-gradient-scaling:
[2023-07-01 11:10:11] [config]   []
[2023-07-01 11:10:11] [config] early-stopping: 10
[2023-07-01 11:10:11] [config] early-stopping-on: first
[2023-07-01 11:10:11] [config] embedding-fix-src: false
[2023-07-01 11:10:11] [config] embedding-fix-trg: false
[2023-07-01 11:10:11] [config] embedding-normalization: false
[2023-07-01 11:10:11] [config] embedding-vectors:
[2023-07-01 11:10:11] [config]   []
[2023-07-01 11:10:11] [config] enc-cell: gru
[2023-07-01 11:10:11] [config] enc-cell-depth: 1
[2023-07-01 11:10:11] [config] enc-depth: 2
[2023-07-01 11:10:11] [config] enc-type: bidirectional
[2023-07-01 11:10:11] [config] english-title-case-every: 0
[2023-07-01 11:10:11] [config] exponential-smoothing: 0.0001
[2023-07-01 11:10:11] [config] factor-weight: 1
[2023-07-01 11:10:11] [config] factors-combine: sum
[2023-07-01 11:10:11] [config] factors-dim-emb: 0
[2023-07-01 11:10:11] [config] gradient-checkpointing: false
[2023-07-01 11:10:11] [config] gradient-norm-average-window: 100
[2023-07-01 11:10:11] [config] guided-alignment: none
[2023-07-01 11:10:11] [config] guided-alignment-cost: mse
[2023-07-01 11:10:11] [config] guided-alignment-weight: 0.1
[2023-07-01 11:10:11] [config] ignore-model-config: false
[2023-07-01 11:10:11] [config] input-types:
[2023-07-01 11:10:11] [config]   []
[2023-07-01 11:10:11] [config] interpolate-env-vars: false
[2023-07-01 11:10:11] [config] keep-best: false
[2023-07-01 11:10:11] [config] label-smoothing: 0.1
[2023-07-01 11:10:11] [config] layer-normalization: false
[2023-07-01 11:10:11] [config] learn-rate: 0.0003
[2023-07-01 11:10:11] [config] lemma-dependency: ""
[2023-07-01 11:10:11] [config] lemma-dim-emb: 0
[2023-07-01 11:10:11] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:10:11] [config] log-level: info
[2023-07-01 11:10:11] [config] log-time-zone: ""
[2023-07-01 11:10:11] [config] logical-epoch:
[2023-07-01 11:10:11] [config]   - 1e
[2023-07-01 11:10:11] [config]   - 0
[2023-07-01 11:10:11] [config] lr-decay: 0
[2023-07-01 11:10:11] [config] lr-decay-freq: 50000
[2023-07-01 11:10:11] [config] lr-decay-inv-sqrt:
[2023-07-01 11:10:11] [config]   - 16000
[2023-07-01 11:10:11] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:10:11] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:10:11] [config] lr-decay-start:
[2023-07-01 11:10:11] [config]   - 10
[2023-07-01 11:10:11] [config]   - 1
[2023-07-01 11:10:11] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:10:11] [config] lr-report: true
[2023-07-01 11:10:11] [config] lr-warmup: 16000
[2023-07-01 11:10:11] [config] lr-warmup-at-reload: false
[2023-07-01 11:10:11] [config] lr-warmup-cycle: false
[2023-07-01 11:10:11] [config] lr-warmup-start-rate: 0
[2023-07-01 11:10:11] [config] max-length: 100
[2023-07-01 11:10:11] [config] max-length-crop: false
[2023-07-01 11:10:11] [config] max-length-factor: 3
[2023-07-01 11:10:11] [config] maxi-batch: 100
[2023-07-01 11:10:11] [config] maxi-batch-sort: trg
[2023-07-01 11:10:11] [config] mini-batch: 1000
[2023-07-01 11:10:11] [config] mini-batch-fit: true
[2023-07-01 11:10:11] [config] mini-batch-fit-step: 10
[2023-07-01 11:10:11] [config] mini-batch-round-up: true
[2023-07-01 11:10:11] [config] mini-batch-track-lr: false
[2023-07-01 11:10:11] [config] mini-batch-warmup: 0
[2023-07-01 11:10:11] [config] mini-batch-words: 0
[2023-07-01 11:10:11] [config] mini-batch-words-ref: 0
[2023-07-01 11:10:11] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:10:11] [config] multi-loss-type: sum
[2023-07-01 11:10:11] [config] n-best: false
[2023-07-01 11:10:11] [config] no-nccl: false
[2023-07-01 11:10:11] [config] no-reload: false
[2023-07-01 11:10:11] [config] no-restore-corpus: false
[2023-07-01 11:10:11] [config] normalize: 1
[2023-07-01 11:10:11] [config] normalize-gradient: false
[2023-07-01 11:10:11] [config] num-devices: 0
[2023-07-01 11:10:11] [config] optimizer: adam
[2023-07-01 11:10:11] [config] optimizer-delay: 1
[2023-07-01 11:10:11] [config] optimizer-params:
[2023-07-01 11:10:11] [config]   - 0.9
[2023-07-01 11:10:11] [config]   - 0.98
[2023-07-01 11:10:11] [config]   - 1e-09
[2023-07-01 11:10:11] [config] output-omit-bias: false
[2023-07-01 11:10:11] [config] overwrite: true
[2023-07-01 11:10:11] [config] precision:
[2023-07-01 11:10:11] [config]   - float32
[2023-07-01 11:10:11] [config]   - float32
[2023-07-01 11:10:11] [config] pretrained-model: ""
[2023-07-01 11:10:11] [config] quantize-biases: false
[2023-07-01 11:10:11] [config] quantize-bits: 0
[2023-07-01 11:10:11] [config] quantize-log-based: false
[2023-07-01 11:10:11] [config] quantize-optimization-steps: 0
[2023-07-01 11:10:11] [config] quiet: false
[2023-07-01 11:10:11] [config] quiet-translation: true
[2023-07-01 11:10:11] [config] relative-paths: false
[2023-07-01 11:10:11] [config] right-left: false
[2023-07-01 11:10:11] [config] save-freq: 10000u
[2023-07-01 11:10:11] [config] seed: 1234
[2023-07-01 11:10:11] [config] sentencepiece-alphas:
[2023-07-01 11:10:11] [config]   []
[2023-07-01 11:10:11] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:10:11] [config] sentencepiece-options: ""
[2023-07-01 11:10:11] [config] sharding: global
[2023-07-01 11:10:11] [config] shuffle: data
[2023-07-01 11:10:11] [config] shuffle-in-ram: false
[2023-07-01 11:10:11] [config] sigterm: save-and-exit
[2023-07-01 11:10:11] [config] skip: false
[2023-07-01 11:10:11] [config] sqlite: ""
[2023-07-01 11:10:11] [config] sqlite-drop: false
[2023-07-01 11:10:11] [config] sync-freq: 200u
[2023-07-01 11:10:11] [config] sync-sgd: true
[2023-07-01 11:10:11] [config] tempdir: /tmp
[2023-07-01 11:10:11] [config] tied-embeddings: false
[2023-07-01 11:10:11] [config] tied-embeddings-all: true
[2023-07-01 11:10:11] [config] tied-embeddings-src: false
[2023-07-01 11:10:11] [config] train-embedder-rank:
[2023-07-01 11:10:11] [config]   []
[2023-07-01 11:10:11] [config] train-sets:
[2023-07-01 11:10:11] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:10:11] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:10:11] [config] transformer-aan-activation: swish
[2023-07-01 11:10:11] [config] transformer-aan-depth: 2
[2023-07-01 11:10:11] [config] transformer-aan-nogate: false
[2023-07-01 11:10:11] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:10:11] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:10:11] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:10:11] [config] transformer-depth-scaling: false
[2023-07-01 11:10:11] [config] transformer-dim-aan: 2048
[2023-07-01 11:10:11] [config] transformer-dim-ffn: 2048
[2023-07-01 11:10:11] [config] transformer-dropout: 0.1
[2023-07-01 11:10:11] [config] transformer-dropout-attention: 0
[2023-07-01 11:10:11] [config] transformer-dropout-ffn: 0
[2023-07-01 11:10:11] [config] transformer-ffn-activation: swish
[2023-07-01 11:10:11] [config] transformer-ffn-depth: 2
[2023-07-01 11:10:11] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:10:11] [config] transformer-heads: 8
[2023-07-01 11:10:11] [config] transformer-no-projection: false
[2023-07-01 11:10:11] [config] transformer-pool: false
[2023-07-01 11:10:11] [config] transformer-postprocess: dan
[2023-07-01 11:10:11] [config] transformer-postprocess-emb: d
[2023-07-01 11:10:11] [config] transformer-postprocess-top: ""
[2023-07-01 11:10:11] [config] transformer-preprocess: ""
[2023-07-01 11:10:11] [config] transformer-tied-layers:
[2023-07-01 11:10:11] [config]   []
[2023-07-01 11:10:11] [config] transformer-train-position-embeddings: false
[2023-07-01 11:10:11] [config] tsv: false
[2023-07-01 11:10:11] [config] tsv-fields: 0
[2023-07-01 11:10:11] [config] type: transformer
[2023-07-01 11:10:11] [config] ulr: false
[2023-07-01 11:10:11] [config] ulr-dim-emb: 0
[2023-07-01 11:10:11] [config] ulr-dropout: 0
[2023-07-01 11:10:11] [config] ulr-keys-vectors: ""
[2023-07-01 11:10:11] [config] ulr-query-vectors: ""
[2023-07-01 11:10:11] [config] ulr-softmax-temperature: 1
[2023-07-01 11:10:11] [config] ulr-trainable-transformation: false
[2023-07-01 11:10:11] [config] unlikelihood-loss: false
[2023-07-01 11:10:11] [config] valid-freq: 50000000
[2023-07-01 11:10:11] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:10:11] [config] valid-max-length: 1000
[2023-07-01 11:10:11] [config] valid-metrics:
[2023-07-01 11:10:11] [config]   - cross-entropy
[2023-07-01 11:10:11] [config]   - translation
[2023-07-01 11:10:11] [config] valid-mini-batch: 64
[2023-07-01 11:10:11] [config] valid-reset-stalled: false
[2023-07-01 11:10:11] [config] valid-script-args:
[2023-07-01 11:10:11] [config]   []
[2023-07-01 11:10:11] [config] valid-script-path: ""
[2023-07-01 11:10:11] [config] valid-sets:
[2023-07-01 11:10:11] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:10:11] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:10:11] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:10:11] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:10:11] [config] vocabs:
[2023-07-01 11:10:11] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:10:11] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:10:11] [config] word-penalty: 0
[2023-07-01 11:10:11] [config] word-scores: false
[2023-07-01 11:10:11] [config] workspace: 2048
[2023-07-01 11:10:11] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:10:11] Using synchronous SGD
[2023-07-01 11:10:12] Synced seed 1234
[2023-07-01 11:10:12] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:10:12] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:10:12] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:10:12] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:10:12] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:10:12] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:10:12] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:10:12] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:10:12] [comm] Using global sharding
[2023-07-01 11:10:12] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:10:12] [training] Using 1 GPUs
[2023-07-01 11:10:12] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:10:12] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:10:13] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:10:13] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:10:20] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:10:20] [valid] No post-processing script given for validating translator
[2023-07-01 11:10:20] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:10:20] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:10:21] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:10:21] [comm] Using global sharding
[2023-07-01 11:10:21] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:10:21] [training] Using 1 GPUs
[2023-07-01 11:10:21] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:10:21] Allocating memory for general optimizer shards
[2023-07-01 11:10:21] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:10:21] Loading Adam parameters
[2023-07-01 11:10:21] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:10:22] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:10:22] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:10:22] [data] Restoring the corpus state to epoch 48, batch 8883
[2023-07-01 11:10:22] [data] Shuffling data
[2023-07-01 11:10:22] [data] Done reading 20,192 sentences
[2023-07-01 11:10:22] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:10:22] Training started
[2023-07-01 11:10:22] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-07-01 11:10:22] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:10:22] Parameter type float32, optimization type float32, casting types false
[2023-07-01 11:10:37] Ep. 48 : Up. 9000 : Sen. 12,041 : Cost 3.06361723 * 3,206,456 @ 3,740 after 28,883,009 : Time 16.12s : 198860.01 words/s : gNorm 1.8918 : L.r. 1.6875e-04
[2023-07-01 11:10:46] Seen 20,073 samples
[2023-07-01 11:10:46] Starting data epoch 49 in logical epoch 49
[2023-07-01 11:10:46] Training finished
[2023-07-01 11:10:49] [valid] Ep. 49 : Up. 9072 : cross-entropy : 125.448 : stalled 6 times (last best: 124.257)
[2023-07-01 11:12:14] [valid] Ep. 49 : Up. 9072 : translation : 0 : new best
[2023-07-01 11:12:14] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:12:15] Saving Adam parameters
[2023-07-01 11:12:15] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:12:21] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:12:21] [marian] Running on node20.datos.cluster.uy as process 13564 with command line:
[2023-07-01 11:12:21] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 49 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:12:21] [config] after: 0e
[2023-07-01 11:12:21] [config] after-batches: 0
[2023-07-01 11:12:21] [config] after-epochs: 49
[2023-07-01 11:12:21] [config] all-caps-every: 0
[2023-07-01 11:12:21] [config] allow-unk: false
[2023-07-01 11:12:21] [config] authors: false
[2023-07-01 11:12:21] [config] beam-size: 12
[2023-07-01 11:12:21] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:12:21] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:12:21] [config] bert-masking-fraction: 0.15
[2023-07-01 11:12:21] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:12:21] [config] bert-train-type-embeddings: true
[2023-07-01 11:12:21] [config] bert-type-vocab-size: 2
[2023-07-01 11:12:21] [config] build-info: ""
[2023-07-01 11:12:21] [config] check-gradient-nan: false
[2023-07-01 11:12:21] [config] check-nan: false
[2023-07-01 11:12:21] [config] cite: false
[2023-07-01 11:12:21] [config] clip-norm: 5
[2023-07-01 11:12:21] [config] cost-scaling:
[2023-07-01 11:12:21] [config]   []
[2023-07-01 11:12:21] [config] cost-type: ce-sum
[2023-07-01 11:12:21] [config] cpu-threads: 0
[2023-07-01 11:12:21] [config] data-threads: 8
[2023-07-01 11:12:21] [config] data-weighting: ""
[2023-07-01 11:12:21] [config] data-weighting-type: sentence
[2023-07-01 11:12:21] [config] dec-cell: gru
[2023-07-01 11:12:21] [config] dec-cell-base-depth: 2
[2023-07-01 11:12:21] [config] dec-cell-high-depth: 1
[2023-07-01 11:12:21] [config] dec-depth: 2
[2023-07-01 11:12:21] [config] devices:
[2023-07-01 11:12:21] [config]   - 0
[2023-07-01 11:12:21] [config] dim-emb: 512
[2023-07-01 11:12:21] [config] dim-rnn: 1024
[2023-07-01 11:12:21] [config] dim-vocabs:
[2023-07-01 11:12:21] [config]   - 16384
[2023-07-01 11:12:21] [config]   - 16384
[2023-07-01 11:12:21] [config] disp-first: 0
[2023-07-01 11:12:21] [config] disp-freq: 1000u
[2023-07-01 11:12:21] [config] disp-label-counts: true
[2023-07-01 11:12:21] [config] dropout-rnn: 0
[2023-07-01 11:12:21] [config] dropout-src: 0
[2023-07-01 11:12:21] [config] dropout-trg: 0
[2023-07-01 11:12:21] [config] dump-config: ""
[2023-07-01 11:12:21] [config] dynamic-gradient-scaling:
[2023-07-01 11:12:21] [config]   []
[2023-07-01 11:12:21] [config] early-stopping: 10
[2023-07-01 11:12:21] [config] early-stopping-on: first
[2023-07-01 11:12:21] [config] embedding-fix-src: false
[2023-07-01 11:12:21] [config] embedding-fix-trg: false
[2023-07-01 11:12:21] [config] embedding-normalization: false
[2023-07-01 11:12:21] [config] embedding-vectors:
[2023-07-01 11:12:21] [config]   []
[2023-07-01 11:12:21] [config] enc-cell: gru
[2023-07-01 11:12:21] [config] enc-cell-depth: 1
[2023-07-01 11:12:21] [config] enc-depth: 2
[2023-07-01 11:12:21] [config] enc-type: bidirectional
[2023-07-01 11:12:21] [config] english-title-case-every: 0
[2023-07-01 11:12:21] [config] exponential-smoothing: 0.0001
[2023-07-01 11:12:21] [config] factor-weight: 1
[2023-07-01 11:12:21] [config] factors-combine: sum
[2023-07-01 11:12:21] [config] factors-dim-emb: 0
[2023-07-01 11:12:21] [config] gradient-checkpointing: false
[2023-07-01 11:12:21] [config] gradient-norm-average-window: 100
[2023-07-01 11:12:21] [config] guided-alignment: none
[2023-07-01 11:12:21] [config] guided-alignment-cost: mse
[2023-07-01 11:12:21] [config] guided-alignment-weight: 0.1
[2023-07-01 11:12:21] [config] ignore-model-config: false
[2023-07-01 11:12:21] [config] input-types:
[2023-07-01 11:12:21] [config]   []
[2023-07-01 11:12:21] [config] interpolate-env-vars: false
[2023-07-01 11:12:21] [config] keep-best: false
[2023-07-01 11:12:21] [config] label-smoothing: 0.1
[2023-07-01 11:12:21] [config] layer-normalization: false
[2023-07-01 11:12:21] [config] learn-rate: 0.0003
[2023-07-01 11:12:21] [config] lemma-dependency: ""
[2023-07-01 11:12:21] [config] lemma-dim-emb: 0
[2023-07-01 11:12:21] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:12:21] [config] log-level: info
[2023-07-01 11:12:21] [config] log-time-zone: ""
[2023-07-01 11:12:21] [config] logical-epoch:
[2023-07-01 11:12:21] [config]   - 1e
[2023-07-01 11:12:21] [config]   - 0
[2023-07-01 11:12:21] [config] lr-decay: 0
[2023-07-01 11:12:21] [config] lr-decay-freq: 50000
[2023-07-01 11:12:21] [config] lr-decay-inv-sqrt:
[2023-07-01 11:12:21] [config]   - 16000
[2023-07-01 11:12:21] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:12:21] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:12:21] [config] lr-decay-start:
[2023-07-01 11:12:21] [config]   - 10
[2023-07-01 11:12:21] [config]   - 1
[2023-07-01 11:12:21] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:12:21] [config] lr-report: true
[2023-07-01 11:12:21] [config] lr-warmup: 16000
[2023-07-01 11:12:21] [config] lr-warmup-at-reload: false
[2023-07-01 11:12:21] [config] lr-warmup-cycle: false
[2023-07-01 11:12:21] [config] lr-warmup-start-rate: 0
[2023-07-01 11:12:21] [config] max-length: 100
[2023-07-01 11:12:21] [config] max-length-crop: false
[2023-07-01 11:12:21] [config] max-length-factor: 3
[2023-07-01 11:12:21] [config] maxi-batch: 100
[2023-07-01 11:12:21] [config] maxi-batch-sort: trg
[2023-07-01 11:12:21] [config] mini-batch: 1000
[2023-07-01 11:12:21] [config] mini-batch-fit: true
[2023-07-01 11:12:21] [config] mini-batch-fit-step: 10
[2023-07-01 11:12:21] [config] mini-batch-round-up: true
[2023-07-01 11:12:21] [config] mini-batch-track-lr: false
[2023-07-01 11:12:21] [config] mini-batch-warmup: 0
[2023-07-01 11:12:21] [config] mini-batch-words: 0
[2023-07-01 11:12:21] [config] mini-batch-words-ref: 0
[2023-07-01 11:12:21] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:12:21] [config] multi-loss-type: sum
[2023-07-01 11:12:21] [config] n-best: false
[2023-07-01 11:12:21] [config] no-nccl: false
[2023-07-01 11:12:21] [config] no-reload: false
[2023-07-01 11:12:21] [config] no-restore-corpus: false
[2023-07-01 11:12:21] [config] normalize: 1
[2023-07-01 11:12:21] [config] normalize-gradient: false
[2023-07-01 11:12:21] [config] num-devices: 0
[2023-07-01 11:12:21] [config] optimizer: adam
[2023-07-01 11:12:21] [config] optimizer-delay: 1
[2023-07-01 11:12:21] [config] optimizer-params:
[2023-07-01 11:12:21] [config]   - 0.9
[2023-07-01 11:12:21] [config]   - 0.98
[2023-07-01 11:12:21] [config]   - 1e-09
[2023-07-01 11:12:21] [config] output-omit-bias: false
[2023-07-01 11:12:21] [config] overwrite: true
[2023-07-01 11:12:21] [config] precision:
[2023-07-01 11:12:21] [config]   - float32
[2023-07-01 11:12:21] [config]   - float32
[2023-07-01 11:12:21] [config] pretrained-model: ""
[2023-07-01 11:12:21] [config] quantize-biases: false
[2023-07-01 11:12:21] [config] quantize-bits: 0
[2023-07-01 11:12:21] [config] quantize-log-based: false
[2023-07-01 11:12:21] [config] quantize-optimization-steps: 0
[2023-07-01 11:12:21] [config] quiet: false
[2023-07-01 11:12:21] [config] quiet-translation: true
[2023-07-01 11:12:21] [config] relative-paths: false
[2023-07-01 11:12:21] [config] right-left: false
[2023-07-01 11:12:21] [config] save-freq: 10000u
[2023-07-01 11:12:21] [config] seed: 1234
[2023-07-01 11:12:21] [config] sentencepiece-alphas:
[2023-07-01 11:12:21] [config]   []
[2023-07-01 11:12:21] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:12:21] [config] sentencepiece-options: ""
[2023-07-01 11:12:21] [config] sharding: global
[2023-07-01 11:12:21] [config] shuffle: data
[2023-07-01 11:12:21] [config] shuffle-in-ram: false
[2023-07-01 11:12:21] [config] sigterm: save-and-exit
[2023-07-01 11:12:21] [config] skip: false
[2023-07-01 11:12:21] [config] sqlite: ""
[2023-07-01 11:12:21] [config] sqlite-drop: false
[2023-07-01 11:12:21] [config] sync-freq: 200u
[2023-07-01 11:12:21] [config] sync-sgd: true
[2023-07-01 11:12:21] [config] tempdir: /tmp
[2023-07-01 11:12:21] [config] tied-embeddings: false
[2023-07-01 11:12:21] [config] tied-embeddings-all: true
[2023-07-01 11:12:21] [config] tied-embeddings-src: false
[2023-07-01 11:12:21] [config] train-embedder-rank:
[2023-07-01 11:12:21] [config]   []
[2023-07-01 11:12:21] [config] train-sets:
[2023-07-01 11:12:21] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:12:21] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:12:21] [config] transformer-aan-activation: swish
[2023-07-01 11:12:21] [config] transformer-aan-depth: 2
[2023-07-01 11:12:21] [config] transformer-aan-nogate: false
[2023-07-01 11:12:21] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:12:21] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:12:21] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:12:21] [config] transformer-depth-scaling: false
[2023-07-01 11:12:21] [config] transformer-dim-aan: 2048
[2023-07-01 11:12:21] [config] transformer-dim-ffn: 2048
[2023-07-01 11:12:21] [config] transformer-dropout: 0.1
[2023-07-01 11:12:21] [config] transformer-dropout-attention: 0
[2023-07-01 11:12:21] [config] transformer-dropout-ffn: 0
[2023-07-01 11:12:21] [config] transformer-ffn-activation: swish
[2023-07-01 11:12:21] [config] transformer-ffn-depth: 2
[2023-07-01 11:12:21] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:12:21] [config] transformer-heads: 8
[2023-07-01 11:12:21] [config] transformer-no-projection: false
[2023-07-01 11:12:21] [config] transformer-pool: false
[2023-07-01 11:12:21] [config] transformer-postprocess: dan
[2023-07-01 11:12:21] [config] transformer-postprocess-emb: d
[2023-07-01 11:12:21] [config] transformer-postprocess-top: ""
[2023-07-01 11:12:21] [config] transformer-preprocess: ""
[2023-07-01 11:12:21] [config] transformer-tied-layers:
[2023-07-01 11:12:21] [config]   []
[2023-07-01 11:12:21] [config] transformer-train-position-embeddings: false
[2023-07-01 11:12:21] [config] tsv: false
[2023-07-01 11:12:21] [config] tsv-fields: 0
[2023-07-01 11:12:21] [config] type: transformer
[2023-07-01 11:12:21] [config] ulr: false
[2023-07-01 11:12:21] [config] ulr-dim-emb: 0
[2023-07-01 11:12:21] [config] ulr-dropout: 0
[2023-07-01 11:12:21] [config] ulr-keys-vectors: ""
[2023-07-01 11:12:21] [config] ulr-query-vectors: ""
[2023-07-01 11:12:21] [config] ulr-softmax-temperature: 1
[2023-07-01 11:12:21] [config] ulr-trainable-transformation: false
[2023-07-01 11:12:21] [config] unlikelihood-loss: false
[2023-07-01 11:12:21] [config] valid-freq: 50000000
[2023-07-01 11:12:21] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:12:21] [config] valid-max-length: 1000
[2023-07-01 11:12:21] [config] valid-metrics:
[2023-07-01 11:12:21] [config]   - cross-entropy
[2023-07-01 11:12:21] [config]   - translation
[2023-07-01 11:12:21] [config] valid-mini-batch: 64
[2023-07-01 11:12:21] [config] valid-reset-stalled: false
[2023-07-01 11:12:21] [config] valid-script-args:
[2023-07-01 11:12:21] [config]   []
[2023-07-01 11:12:21] [config] valid-script-path: ""
[2023-07-01 11:12:21] [config] valid-sets:
[2023-07-01 11:12:21] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:12:21] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:12:21] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:12:21] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:12:21] [config] vocabs:
[2023-07-01 11:12:21] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:12:21] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:12:21] [config] word-penalty: 0
[2023-07-01 11:12:21] [config] word-scores: false
[2023-07-01 11:12:21] [config] workspace: 2048
[2023-07-01 11:12:21] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:12:21] Using synchronous SGD
[2023-07-01 11:12:22] Synced seed 1234
[2023-07-01 11:12:22] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:12:22] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:12:22] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:12:22] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:12:22] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:12:22] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:12:23] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:12:23] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:12:23] [comm] Using global sharding
[2023-07-01 11:12:23] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:12:23] [training] Using 1 GPUs
[2023-07-01 11:12:23] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:12:23] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:12:23] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:12:23] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:12:31] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:12:31] [valid] No post-processing script given for validating translator
[2023-07-01 11:12:31] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:12:31] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:12:31] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:12:31] [comm] Using global sharding
[2023-07-01 11:12:31] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:12:31] [training] Using 1 GPUs
[2023-07-01 11:12:31] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:12:32] Allocating memory for general optimizer shards
[2023-07-01 11:12:32] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:12:32] Loading Adam parameters
[2023-07-01 11:12:32] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:12:32] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:12:32] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:12:32] [data] Restoring the corpus state to epoch 49, batch 9072
[2023-07-01 11:12:32] [data] Shuffling data
[2023-07-01 11:12:32] [data] Done reading 20,192 sentences
[2023-07-01 11:12:32] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:12:32] Training started
[2023-07-01 11:12:32] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-07-01 11:12:32] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:12:32] Parameter type float32, optimization type float32, casting types false
[2023-07-01 11:12:56] Seen 20,073 samples
[2023-07-01 11:12:56] Starting data epoch 50 in logical epoch 50
[2023-07-01 11:12:56] Training finished
[2023-07-01 11:12:59] [valid] Ep. 50 : Up. 9261 : cross-entropy : 125.851 : stalled 7 times (last best: 124.257)
[2023-07-01 11:14:23] [valid] Ep. 50 : Up. 9261 : translation : 0 : new best
[2023-07-01 11:14:23] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:14:24] Saving Adam parameters
[2023-07-01 11:14:24] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:14:30] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:14:30] [marian] Running on node20.datos.cluster.uy as process 13726 with command line:
[2023-07-01 11:14:30] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 50 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:14:30] [config] after: 0e
[2023-07-01 11:14:30] [config] after-batches: 0
[2023-07-01 11:14:30] [config] after-epochs: 50
[2023-07-01 11:14:30] [config] all-caps-every: 0
[2023-07-01 11:14:30] [config] allow-unk: false
[2023-07-01 11:14:30] [config] authors: false
[2023-07-01 11:14:30] [config] beam-size: 12
[2023-07-01 11:14:30] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:14:30] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:14:30] [config] bert-masking-fraction: 0.15
[2023-07-01 11:14:30] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:14:30] [config] bert-train-type-embeddings: true
[2023-07-01 11:14:30] [config] bert-type-vocab-size: 2
[2023-07-01 11:14:30] [config] build-info: ""
[2023-07-01 11:14:30] [config] check-gradient-nan: false
[2023-07-01 11:14:30] [config] check-nan: false
[2023-07-01 11:14:30] [config] cite: false
[2023-07-01 11:14:30] [config] clip-norm: 5
[2023-07-01 11:14:30] [config] cost-scaling:
[2023-07-01 11:14:30] [config]   []
[2023-07-01 11:14:30] [config] cost-type: ce-sum
[2023-07-01 11:14:30] [config] cpu-threads: 0
[2023-07-01 11:14:30] [config] data-threads: 8
[2023-07-01 11:14:30] [config] data-weighting: ""
[2023-07-01 11:14:30] [config] data-weighting-type: sentence
[2023-07-01 11:14:30] [config] dec-cell: gru
[2023-07-01 11:14:30] [config] dec-cell-base-depth: 2
[2023-07-01 11:14:30] [config] dec-cell-high-depth: 1
[2023-07-01 11:14:30] [config] dec-depth: 2
[2023-07-01 11:14:30] [config] devices:
[2023-07-01 11:14:30] [config]   - 0
[2023-07-01 11:14:30] [config] dim-emb: 512
[2023-07-01 11:14:30] [config] dim-rnn: 1024
[2023-07-01 11:14:30] [config] dim-vocabs:
[2023-07-01 11:14:30] [config]   - 16384
[2023-07-01 11:14:30] [config]   - 16384
[2023-07-01 11:14:30] [config] disp-first: 0
[2023-07-01 11:14:30] [config] disp-freq: 1000u
[2023-07-01 11:14:30] [config] disp-label-counts: true
[2023-07-01 11:14:30] [config] dropout-rnn: 0
[2023-07-01 11:14:30] [config] dropout-src: 0
[2023-07-01 11:14:30] [config] dropout-trg: 0
[2023-07-01 11:14:30] [config] dump-config: ""
[2023-07-01 11:14:30] [config] dynamic-gradient-scaling:
[2023-07-01 11:14:30] [config]   []
[2023-07-01 11:14:30] [config] early-stopping: 10
[2023-07-01 11:14:30] [config] early-stopping-on: first
[2023-07-01 11:14:30] [config] embedding-fix-src: false
[2023-07-01 11:14:30] [config] embedding-fix-trg: false
[2023-07-01 11:14:30] [config] embedding-normalization: false
[2023-07-01 11:14:30] [config] embedding-vectors:
[2023-07-01 11:14:30] [config]   []
[2023-07-01 11:14:30] [config] enc-cell: gru
[2023-07-01 11:14:30] [config] enc-cell-depth: 1
[2023-07-01 11:14:30] [config] enc-depth: 2
[2023-07-01 11:14:30] [config] enc-type: bidirectional
[2023-07-01 11:14:30] [config] english-title-case-every: 0
[2023-07-01 11:14:30] [config] exponential-smoothing: 0.0001
[2023-07-01 11:14:30] [config] factor-weight: 1
[2023-07-01 11:14:30] [config] factors-combine: sum
[2023-07-01 11:14:30] [config] factors-dim-emb: 0
[2023-07-01 11:14:30] [config] gradient-checkpointing: false
[2023-07-01 11:14:30] [config] gradient-norm-average-window: 100
[2023-07-01 11:14:30] [config] guided-alignment: none
[2023-07-01 11:14:30] [config] guided-alignment-cost: mse
[2023-07-01 11:14:30] [config] guided-alignment-weight: 0.1
[2023-07-01 11:14:30] [config] ignore-model-config: false
[2023-07-01 11:14:30] [config] input-types:
[2023-07-01 11:14:30] [config]   []
[2023-07-01 11:14:30] [config] interpolate-env-vars: false
[2023-07-01 11:14:30] [config] keep-best: false
[2023-07-01 11:14:30] [config] label-smoothing: 0.1
[2023-07-01 11:14:30] [config] layer-normalization: false
[2023-07-01 11:14:30] [config] learn-rate: 0.0003
[2023-07-01 11:14:30] [config] lemma-dependency: ""
[2023-07-01 11:14:30] [config] lemma-dim-emb: 0
[2023-07-01 11:14:30] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:14:30] [config] log-level: info
[2023-07-01 11:14:30] [config] log-time-zone: ""
[2023-07-01 11:14:30] [config] logical-epoch:
[2023-07-01 11:14:30] [config]   - 1e
[2023-07-01 11:14:30] [config]   - 0
[2023-07-01 11:14:30] [config] lr-decay: 0
[2023-07-01 11:14:30] [config] lr-decay-freq: 50000
[2023-07-01 11:14:30] [config] lr-decay-inv-sqrt:
[2023-07-01 11:14:30] [config]   - 16000
[2023-07-01 11:14:30] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:14:30] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:14:30] [config] lr-decay-start:
[2023-07-01 11:14:30] [config]   - 10
[2023-07-01 11:14:30] [config]   - 1
[2023-07-01 11:14:30] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:14:30] [config] lr-report: true
[2023-07-01 11:14:30] [config] lr-warmup: 16000
[2023-07-01 11:14:30] [config] lr-warmup-at-reload: false
[2023-07-01 11:14:30] [config] lr-warmup-cycle: false
[2023-07-01 11:14:30] [config] lr-warmup-start-rate: 0
[2023-07-01 11:14:30] [config] max-length: 100
[2023-07-01 11:14:30] [config] max-length-crop: false
[2023-07-01 11:14:30] [config] max-length-factor: 3
[2023-07-01 11:14:30] [config] maxi-batch: 100
[2023-07-01 11:14:30] [config] maxi-batch-sort: trg
[2023-07-01 11:14:30] [config] mini-batch: 1000
[2023-07-01 11:14:30] [config] mini-batch-fit: true
[2023-07-01 11:14:30] [config] mini-batch-fit-step: 10
[2023-07-01 11:14:30] [config] mini-batch-round-up: true
[2023-07-01 11:14:30] [config] mini-batch-track-lr: false
[2023-07-01 11:14:30] [config] mini-batch-warmup: 0
[2023-07-01 11:14:30] [config] mini-batch-words: 0
[2023-07-01 11:14:30] [config] mini-batch-words-ref: 0
[2023-07-01 11:14:30] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:14:30] [config] multi-loss-type: sum
[2023-07-01 11:14:30] [config] n-best: false
[2023-07-01 11:14:30] [config] no-nccl: false
[2023-07-01 11:14:30] [config] no-reload: false
[2023-07-01 11:14:30] [config] no-restore-corpus: false
[2023-07-01 11:14:30] [config] normalize: 1
[2023-07-01 11:14:30] [config] normalize-gradient: false
[2023-07-01 11:14:30] [config] num-devices: 0
[2023-07-01 11:14:30] [config] optimizer: adam
[2023-07-01 11:14:30] [config] optimizer-delay: 1
[2023-07-01 11:14:30] [config] optimizer-params:
[2023-07-01 11:14:30] [config]   - 0.9
[2023-07-01 11:14:30] [config]   - 0.98
[2023-07-01 11:14:30] [config]   - 1e-09
[2023-07-01 11:14:30] [config] output-omit-bias: false
[2023-07-01 11:14:30] [config] overwrite: true
[2023-07-01 11:14:30] [config] precision:
[2023-07-01 11:14:30] [config]   - float32
[2023-07-01 11:14:30] [config]   - float32
[2023-07-01 11:14:30] [config] pretrained-model: ""
[2023-07-01 11:14:30] [config] quantize-biases: false
[2023-07-01 11:14:30] [config] quantize-bits: 0
[2023-07-01 11:14:30] [config] quantize-log-based: false
[2023-07-01 11:14:30] [config] quantize-optimization-steps: 0
[2023-07-01 11:14:30] [config] quiet: false
[2023-07-01 11:14:30] [config] quiet-translation: true
[2023-07-01 11:14:30] [config] relative-paths: false
[2023-07-01 11:14:30] [config] right-left: false
[2023-07-01 11:14:30] [config] save-freq: 10000u
[2023-07-01 11:14:30] [config] seed: 1234
[2023-07-01 11:14:30] [config] sentencepiece-alphas:
[2023-07-01 11:14:30] [config]   []
[2023-07-01 11:14:30] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:14:30] [config] sentencepiece-options: ""
[2023-07-01 11:14:30] [config] sharding: global
[2023-07-01 11:14:30] [config] shuffle: data
[2023-07-01 11:14:30] [config] shuffle-in-ram: false
[2023-07-01 11:14:30] [config] sigterm: save-and-exit
[2023-07-01 11:14:30] [config] skip: false
[2023-07-01 11:14:30] [config] sqlite: ""
[2023-07-01 11:14:30] [config] sqlite-drop: false
[2023-07-01 11:14:30] [config] sync-freq: 200u
[2023-07-01 11:14:30] [config] sync-sgd: true
[2023-07-01 11:14:30] [config] tempdir: /tmp
[2023-07-01 11:14:30] [config] tied-embeddings: false
[2023-07-01 11:14:30] [config] tied-embeddings-all: true
[2023-07-01 11:14:30] [config] tied-embeddings-src: false
[2023-07-01 11:14:30] [config] train-embedder-rank:
[2023-07-01 11:14:30] [config]   []
[2023-07-01 11:14:30] [config] train-sets:
[2023-07-01 11:14:30] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:14:30] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:14:30] [config] transformer-aan-activation: swish
[2023-07-01 11:14:30] [config] transformer-aan-depth: 2
[2023-07-01 11:14:30] [config] transformer-aan-nogate: false
[2023-07-01 11:14:30] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:14:30] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:14:30] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:14:30] [config] transformer-depth-scaling: false
[2023-07-01 11:14:30] [config] transformer-dim-aan: 2048
[2023-07-01 11:14:30] [config] transformer-dim-ffn: 2048
[2023-07-01 11:14:30] [config] transformer-dropout: 0.1
[2023-07-01 11:14:30] [config] transformer-dropout-attention: 0
[2023-07-01 11:14:30] [config] transformer-dropout-ffn: 0
[2023-07-01 11:14:30] [config] transformer-ffn-activation: swish
[2023-07-01 11:14:30] [config] transformer-ffn-depth: 2
[2023-07-01 11:14:30] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:14:30] [config] transformer-heads: 8
[2023-07-01 11:14:30] [config] transformer-no-projection: false
[2023-07-01 11:14:30] [config] transformer-pool: false
[2023-07-01 11:14:30] [config] transformer-postprocess: dan
[2023-07-01 11:14:30] [config] transformer-postprocess-emb: d
[2023-07-01 11:14:30] [config] transformer-postprocess-top: ""
[2023-07-01 11:14:30] [config] transformer-preprocess: ""
[2023-07-01 11:14:30] [config] transformer-tied-layers:
[2023-07-01 11:14:30] [config]   []
[2023-07-01 11:14:30] [config] transformer-train-position-embeddings: false
[2023-07-01 11:14:30] [config] tsv: false
[2023-07-01 11:14:30] [config] tsv-fields: 0
[2023-07-01 11:14:30] [config] type: transformer
[2023-07-01 11:14:30] [config] ulr: false
[2023-07-01 11:14:30] [config] ulr-dim-emb: 0
[2023-07-01 11:14:30] [config] ulr-dropout: 0
[2023-07-01 11:14:30] [config] ulr-keys-vectors: ""
[2023-07-01 11:14:30] [config] ulr-query-vectors: ""
[2023-07-01 11:14:30] [config] ulr-softmax-temperature: 1
[2023-07-01 11:14:30] [config] ulr-trainable-transformation: false
[2023-07-01 11:14:30] [config] unlikelihood-loss: false
[2023-07-01 11:14:30] [config] valid-freq: 50000000
[2023-07-01 11:14:30] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:14:30] [config] valid-max-length: 1000
[2023-07-01 11:14:30] [config] valid-metrics:
[2023-07-01 11:14:30] [config]   - cross-entropy
[2023-07-01 11:14:30] [config]   - translation
[2023-07-01 11:14:30] [config] valid-mini-batch: 64
[2023-07-01 11:14:30] [config] valid-reset-stalled: false
[2023-07-01 11:14:30] [config] valid-script-args:
[2023-07-01 11:14:30] [config]   []
[2023-07-01 11:14:30] [config] valid-script-path: ""
[2023-07-01 11:14:30] [config] valid-sets:
[2023-07-01 11:14:30] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:14:30] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:14:30] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:14:30] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:14:30] [config] vocabs:
[2023-07-01 11:14:30] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:14:30] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:14:30] [config] word-penalty: 0
[2023-07-01 11:14:30] [config] word-scores: false
[2023-07-01 11:14:30] [config] workspace: 2048
[2023-07-01 11:14:30] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:14:30] Using synchronous SGD
[2023-07-01 11:14:31] Synced seed 1234
[2023-07-01 11:14:31] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:14:31] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:14:31] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:14:31] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:14:31] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:14:31] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:14:31] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:14:31] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:14:31] [comm] Using global sharding
[2023-07-01 11:14:32] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:14:32] [training] Using 1 GPUs
[2023-07-01 11:14:32] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:14:32] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:14:32] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:14:32] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:14:39] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:14:40] [valid] No post-processing script given for validating translator
[2023-07-01 11:14:40] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:14:40] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:14:40] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:14:40] [comm] Using global sharding
[2023-07-01 11:14:40] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:14:40] [training] Using 1 GPUs
[2023-07-01 11:14:40] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:14:41] Allocating memory for general optimizer shards
[2023-07-01 11:14:41] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:14:41] Loading Adam parameters
[2023-07-01 11:14:41] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:14:41] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:14:41] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:14:41] [data] Restoring the corpus state to epoch 50, batch 9261
[2023-07-01 11:14:41] [data] Shuffling data
[2023-07-01 11:14:41] [data] Done reading 20,192 sentences
[2023-07-01 11:14:41] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:14:41] Training started
[2023-07-01 11:14:41] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-07-01 11:14:41] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:14:41] Parameter type float32, optimization type float32, casting types false
[2023-07-01 11:15:05] Seen 20,073 samples
[2023-07-01 11:15:05] Starting data epoch 51 in logical epoch 51
[2023-07-01 11:15:05] Training finished
[2023-07-01 11:15:08] [valid] Ep. 51 : Up. 9450 : cross-entropy : 126.296 : stalled 8 times (last best: 124.257)
[2023-07-01 11:16:33] [valid] Ep. 51 : Up. 9450 : translation : 0 : new best
[2023-07-01 11:16:33] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:16:34] Saving Adam parameters
[2023-07-01 11:16:34] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:16:40] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:16:40] [marian] Running on node20.datos.cluster.uy as process 13887 with command line:
[2023-07-01 11:16:40] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 51 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:16:40] [config] after: 0e
[2023-07-01 11:16:40] [config] after-batches: 0
[2023-07-01 11:16:40] [config] after-epochs: 51
[2023-07-01 11:16:40] [config] all-caps-every: 0
[2023-07-01 11:16:40] [config] allow-unk: false
[2023-07-01 11:16:40] [config] authors: false
[2023-07-01 11:16:40] [config] beam-size: 12
[2023-07-01 11:16:40] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:16:40] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:16:40] [config] bert-masking-fraction: 0.15
[2023-07-01 11:16:40] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:16:40] [config] bert-train-type-embeddings: true
[2023-07-01 11:16:40] [config] bert-type-vocab-size: 2
[2023-07-01 11:16:40] [config] build-info: ""
[2023-07-01 11:16:40] [config] check-gradient-nan: false
[2023-07-01 11:16:40] [config] check-nan: false
[2023-07-01 11:16:40] [config] cite: false
[2023-07-01 11:16:40] [config] clip-norm: 5
[2023-07-01 11:16:40] [config] cost-scaling:
[2023-07-01 11:16:40] [config]   []
[2023-07-01 11:16:40] [config] cost-type: ce-sum
[2023-07-01 11:16:40] [config] cpu-threads: 0
[2023-07-01 11:16:40] [config] data-threads: 8
[2023-07-01 11:16:40] [config] data-weighting: ""
[2023-07-01 11:16:40] [config] data-weighting-type: sentence
[2023-07-01 11:16:40] [config] dec-cell: gru
[2023-07-01 11:16:40] [config] dec-cell-base-depth: 2
[2023-07-01 11:16:40] [config] dec-cell-high-depth: 1
[2023-07-01 11:16:40] [config] dec-depth: 2
[2023-07-01 11:16:40] [config] devices:
[2023-07-01 11:16:40] [config]   - 0
[2023-07-01 11:16:40] [config] dim-emb: 512
[2023-07-01 11:16:40] [config] dim-rnn: 1024
[2023-07-01 11:16:40] [config] dim-vocabs:
[2023-07-01 11:16:40] [config]   - 16384
[2023-07-01 11:16:40] [config]   - 16384
[2023-07-01 11:16:40] [config] disp-first: 0
[2023-07-01 11:16:40] [config] disp-freq: 1000u
[2023-07-01 11:16:40] [config] disp-label-counts: true
[2023-07-01 11:16:40] [config] dropout-rnn: 0
[2023-07-01 11:16:40] [config] dropout-src: 0
[2023-07-01 11:16:40] [config] dropout-trg: 0
[2023-07-01 11:16:40] [config] dump-config: ""
[2023-07-01 11:16:40] [config] dynamic-gradient-scaling:
[2023-07-01 11:16:40] [config]   []
[2023-07-01 11:16:40] [config] early-stopping: 10
[2023-07-01 11:16:40] [config] early-stopping-on: first
[2023-07-01 11:16:40] [config] embedding-fix-src: false
[2023-07-01 11:16:40] [config] embedding-fix-trg: false
[2023-07-01 11:16:40] [config] embedding-normalization: false
[2023-07-01 11:16:40] [config] embedding-vectors:
[2023-07-01 11:16:40] [config]   []
[2023-07-01 11:16:40] [config] enc-cell: gru
[2023-07-01 11:16:40] [config] enc-cell-depth: 1
[2023-07-01 11:16:40] [config] enc-depth: 2
[2023-07-01 11:16:40] [config] enc-type: bidirectional
[2023-07-01 11:16:40] [config] english-title-case-every: 0
[2023-07-01 11:16:40] [config] exponential-smoothing: 0.0001
[2023-07-01 11:16:40] [config] factor-weight: 1
[2023-07-01 11:16:40] [config] factors-combine: sum
[2023-07-01 11:16:40] [config] factors-dim-emb: 0
[2023-07-01 11:16:40] [config] gradient-checkpointing: false
[2023-07-01 11:16:40] [config] gradient-norm-average-window: 100
[2023-07-01 11:16:40] [config] guided-alignment: none
[2023-07-01 11:16:40] [config] guided-alignment-cost: mse
[2023-07-01 11:16:40] [config] guided-alignment-weight: 0.1
[2023-07-01 11:16:40] [config] ignore-model-config: false
[2023-07-01 11:16:40] [config] input-types:
[2023-07-01 11:16:40] [config]   []
[2023-07-01 11:16:40] [config] interpolate-env-vars: false
[2023-07-01 11:16:40] [config] keep-best: false
[2023-07-01 11:16:40] [config] label-smoothing: 0.1
[2023-07-01 11:16:40] [config] layer-normalization: false
[2023-07-01 11:16:40] [config] learn-rate: 0.0003
[2023-07-01 11:16:40] [config] lemma-dependency: ""
[2023-07-01 11:16:40] [config] lemma-dim-emb: 0
[2023-07-01 11:16:40] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:16:40] [config] log-level: info
[2023-07-01 11:16:40] [config] log-time-zone: ""
[2023-07-01 11:16:40] [config] logical-epoch:
[2023-07-01 11:16:40] [config]   - 1e
[2023-07-01 11:16:40] [config]   - 0
[2023-07-01 11:16:40] [config] lr-decay: 0
[2023-07-01 11:16:40] [config] lr-decay-freq: 50000
[2023-07-01 11:16:40] [config] lr-decay-inv-sqrt:
[2023-07-01 11:16:40] [config]   - 16000
[2023-07-01 11:16:40] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:16:40] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:16:40] [config] lr-decay-start:
[2023-07-01 11:16:40] [config]   - 10
[2023-07-01 11:16:40] [config]   - 1
[2023-07-01 11:16:40] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:16:40] [config] lr-report: true
[2023-07-01 11:16:40] [config] lr-warmup: 16000
[2023-07-01 11:16:40] [config] lr-warmup-at-reload: false
[2023-07-01 11:16:40] [config] lr-warmup-cycle: false
[2023-07-01 11:16:40] [config] lr-warmup-start-rate: 0
[2023-07-01 11:16:40] [config] max-length: 100
[2023-07-01 11:16:40] [config] max-length-crop: false
[2023-07-01 11:16:40] [config] max-length-factor: 3
[2023-07-01 11:16:40] [config] maxi-batch: 100
[2023-07-01 11:16:40] [config] maxi-batch-sort: trg
[2023-07-01 11:16:40] [config] mini-batch: 1000
[2023-07-01 11:16:40] [config] mini-batch-fit: true
[2023-07-01 11:16:40] [config] mini-batch-fit-step: 10
[2023-07-01 11:16:40] [config] mini-batch-round-up: true
[2023-07-01 11:16:40] [config] mini-batch-track-lr: false
[2023-07-01 11:16:40] [config] mini-batch-warmup: 0
[2023-07-01 11:16:40] [config] mini-batch-words: 0
[2023-07-01 11:16:40] [config] mini-batch-words-ref: 0
[2023-07-01 11:16:40] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:16:40] [config] multi-loss-type: sum
[2023-07-01 11:16:40] [config] n-best: false
[2023-07-01 11:16:40] [config] no-nccl: false
[2023-07-01 11:16:40] [config] no-reload: false
[2023-07-01 11:16:40] [config] no-restore-corpus: false
[2023-07-01 11:16:40] [config] normalize: 1
[2023-07-01 11:16:40] [config] normalize-gradient: false
[2023-07-01 11:16:40] [config] num-devices: 0
[2023-07-01 11:16:40] [config] optimizer: adam
[2023-07-01 11:16:40] [config] optimizer-delay: 1
[2023-07-01 11:16:40] [config] optimizer-params:
[2023-07-01 11:16:40] [config]   - 0.9
[2023-07-01 11:16:40] [config]   - 0.98
[2023-07-01 11:16:40] [config]   - 1e-09
[2023-07-01 11:16:40] [config] output-omit-bias: false
[2023-07-01 11:16:40] [config] overwrite: true
[2023-07-01 11:16:40] [config] precision:
[2023-07-01 11:16:40] [config]   - float32
[2023-07-01 11:16:40] [config]   - float32
[2023-07-01 11:16:40] [config] pretrained-model: ""
[2023-07-01 11:16:40] [config] quantize-biases: false
[2023-07-01 11:16:40] [config] quantize-bits: 0
[2023-07-01 11:16:40] [config] quantize-log-based: false
[2023-07-01 11:16:40] [config] quantize-optimization-steps: 0
[2023-07-01 11:16:40] [config] quiet: false
[2023-07-01 11:16:40] [config] quiet-translation: true
[2023-07-01 11:16:40] [config] relative-paths: false
[2023-07-01 11:16:40] [config] right-left: false
[2023-07-01 11:16:40] [config] save-freq: 10000u
[2023-07-01 11:16:40] [config] seed: 1234
[2023-07-01 11:16:40] [config] sentencepiece-alphas:
[2023-07-01 11:16:40] [config]   []
[2023-07-01 11:16:40] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:16:40] [config] sentencepiece-options: ""
[2023-07-01 11:16:40] [config] sharding: global
[2023-07-01 11:16:40] [config] shuffle: data
[2023-07-01 11:16:40] [config] shuffle-in-ram: false
[2023-07-01 11:16:40] [config] sigterm: save-and-exit
[2023-07-01 11:16:40] [config] skip: false
[2023-07-01 11:16:40] [config] sqlite: ""
[2023-07-01 11:16:40] [config] sqlite-drop: false
[2023-07-01 11:16:40] [config] sync-freq: 200u
[2023-07-01 11:16:40] [config] sync-sgd: true
[2023-07-01 11:16:40] [config] tempdir: /tmp
[2023-07-01 11:16:40] [config] tied-embeddings: false
[2023-07-01 11:16:40] [config] tied-embeddings-all: true
[2023-07-01 11:16:40] [config] tied-embeddings-src: false
[2023-07-01 11:16:40] [config] train-embedder-rank:
[2023-07-01 11:16:40] [config]   []
[2023-07-01 11:16:40] [config] train-sets:
[2023-07-01 11:16:40] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:16:40] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:16:40] [config] transformer-aan-activation: swish
[2023-07-01 11:16:40] [config] transformer-aan-depth: 2
[2023-07-01 11:16:40] [config] transformer-aan-nogate: false
[2023-07-01 11:16:40] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:16:40] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:16:40] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:16:40] [config] transformer-depth-scaling: false
[2023-07-01 11:16:40] [config] transformer-dim-aan: 2048
[2023-07-01 11:16:40] [config] transformer-dim-ffn: 2048
[2023-07-01 11:16:40] [config] transformer-dropout: 0.1
[2023-07-01 11:16:40] [config] transformer-dropout-attention: 0
[2023-07-01 11:16:40] [config] transformer-dropout-ffn: 0
[2023-07-01 11:16:40] [config] transformer-ffn-activation: swish
[2023-07-01 11:16:40] [config] transformer-ffn-depth: 2
[2023-07-01 11:16:40] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:16:40] [config] transformer-heads: 8
[2023-07-01 11:16:40] [config] transformer-no-projection: false
[2023-07-01 11:16:40] [config] transformer-pool: false
[2023-07-01 11:16:40] [config] transformer-postprocess: dan
[2023-07-01 11:16:40] [config] transformer-postprocess-emb: d
[2023-07-01 11:16:40] [config] transformer-postprocess-top: ""
[2023-07-01 11:16:40] [config] transformer-preprocess: ""
[2023-07-01 11:16:40] [config] transformer-tied-layers:
[2023-07-01 11:16:40] [config]   []
[2023-07-01 11:16:40] [config] transformer-train-position-embeddings: false
[2023-07-01 11:16:40] [config] tsv: false
[2023-07-01 11:16:40] [config] tsv-fields: 0
[2023-07-01 11:16:40] [config] type: transformer
[2023-07-01 11:16:40] [config] ulr: false
[2023-07-01 11:16:40] [config] ulr-dim-emb: 0
[2023-07-01 11:16:40] [config] ulr-dropout: 0
[2023-07-01 11:16:40] [config] ulr-keys-vectors: ""
[2023-07-01 11:16:40] [config] ulr-query-vectors: ""
[2023-07-01 11:16:40] [config] ulr-softmax-temperature: 1
[2023-07-01 11:16:40] [config] ulr-trainable-transformation: false
[2023-07-01 11:16:40] [config] unlikelihood-loss: false
[2023-07-01 11:16:40] [config] valid-freq: 50000000
[2023-07-01 11:16:40] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:16:40] [config] valid-max-length: 1000
[2023-07-01 11:16:40] [config] valid-metrics:
[2023-07-01 11:16:40] [config]   - cross-entropy
[2023-07-01 11:16:40] [config]   - translation
[2023-07-01 11:16:40] [config] valid-mini-batch: 64
[2023-07-01 11:16:40] [config] valid-reset-stalled: false
[2023-07-01 11:16:40] [config] valid-script-args:
[2023-07-01 11:16:40] [config]   []
[2023-07-01 11:16:40] [config] valid-script-path: ""
[2023-07-01 11:16:40] [config] valid-sets:
[2023-07-01 11:16:40] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:16:40] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:16:40] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:16:40] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:16:40] [config] vocabs:
[2023-07-01 11:16:40] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:16:40] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:16:40] [config] word-penalty: 0
[2023-07-01 11:16:40] [config] word-scores: false
[2023-07-01 11:16:40] [config] workspace: 2048
[2023-07-01 11:16:40] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:16:40] Using synchronous SGD
[2023-07-01 11:16:41] Synced seed 1234
[2023-07-01 11:16:41] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:16:41] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:16:41] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:16:41] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:16:41] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:16:41] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:16:41] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:16:41] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:16:41] [comm] Using global sharding
[2023-07-01 11:16:42] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:16:42] [training] Using 1 GPUs
[2023-07-01 11:16:42] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:16:42] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:16:42] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:16:42] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:16:49] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:16:49] [valid] No post-processing script given for validating translator
[2023-07-01 11:16:49] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:16:49] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:16:49] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:16:49] [comm] Using global sharding
[2023-07-01 11:16:50] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:16:50] [training] Using 1 GPUs
[2023-07-01 11:16:50] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:16:50] Allocating memory for general optimizer shards
[2023-07-01 11:16:50] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:16:50] Loading Adam parameters
[2023-07-01 11:16:50] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:16:50] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:16:51] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:16:51] [data] Restoring the corpus state to epoch 51, batch 9450
[2023-07-01 11:16:51] [data] Shuffling data
[2023-07-01 11:16:51] [data] Done reading 20,192 sentences
[2023-07-01 11:16:51] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:16:51] Training started
[2023-07-01 11:16:51] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-07-01 11:16:51] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:16:51] Parameter type float32, optimization type float32, casting types false
[2023-07-01 11:17:15] Seen 20,073 samples
[2023-07-01 11:17:15] Starting data epoch 52 in logical epoch 52
[2023-07-01 11:17:15] Training finished
[2023-07-01 11:17:18] [valid] Ep. 52 : Up. 9639 : cross-entropy : 126.778 : stalled 9 times (last best: 124.257)
[2023-07-01 11:18:40] [valid] Ep. 52 : Up. 9639 : translation : 0 : new best
[2023-07-01 11:18:40] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:18:41] Saving Adam parameters
[2023-07-01 11:18:41] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:18:48] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:18:48] [marian] Running on node20.datos.cluster.uy as process 14051 with command line:
[2023-07-01 11:18:48] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 52 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:18:48] [config] after: 0e
[2023-07-01 11:18:48] [config] after-batches: 0
[2023-07-01 11:18:48] [config] after-epochs: 52
[2023-07-01 11:18:48] [config] all-caps-every: 0
[2023-07-01 11:18:48] [config] allow-unk: false
[2023-07-01 11:18:48] [config] authors: false
[2023-07-01 11:18:48] [config] beam-size: 12
[2023-07-01 11:18:48] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:18:48] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:18:48] [config] bert-masking-fraction: 0.15
[2023-07-01 11:18:48] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:18:48] [config] bert-train-type-embeddings: true
[2023-07-01 11:18:48] [config] bert-type-vocab-size: 2
[2023-07-01 11:18:48] [config] build-info: ""
[2023-07-01 11:18:48] [config] check-gradient-nan: false
[2023-07-01 11:18:48] [config] check-nan: false
[2023-07-01 11:18:48] [config] cite: false
[2023-07-01 11:18:48] [config] clip-norm: 5
[2023-07-01 11:18:48] [config] cost-scaling:
[2023-07-01 11:18:48] [config]   []
[2023-07-01 11:18:48] [config] cost-type: ce-sum
[2023-07-01 11:18:48] [config] cpu-threads: 0
[2023-07-01 11:18:48] [config] data-threads: 8
[2023-07-01 11:18:48] [config] data-weighting: ""
[2023-07-01 11:18:48] [config] data-weighting-type: sentence
[2023-07-01 11:18:48] [config] dec-cell: gru
[2023-07-01 11:18:48] [config] dec-cell-base-depth: 2
[2023-07-01 11:18:48] [config] dec-cell-high-depth: 1
[2023-07-01 11:18:48] [config] dec-depth: 2
[2023-07-01 11:18:48] [config] devices:
[2023-07-01 11:18:48] [config]   - 0
[2023-07-01 11:18:48] [config] dim-emb: 512
[2023-07-01 11:18:48] [config] dim-rnn: 1024
[2023-07-01 11:18:48] [config] dim-vocabs:
[2023-07-01 11:18:48] [config]   - 16384
[2023-07-01 11:18:48] [config]   - 16384
[2023-07-01 11:18:48] [config] disp-first: 0
[2023-07-01 11:18:48] [config] disp-freq: 1000u
[2023-07-01 11:18:48] [config] disp-label-counts: true
[2023-07-01 11:18:48] [config] dropout-rnn: 0
[2023-07-01 11:18:48] [config] dropout-src: 0
[2023-07-01 11:18:48] [config] dropout-trg: 0
[2023-07-01 11:18:48] [config] dump-config: ""
[2023-07-01 11:18:48] [config] dynamic-gradient-scaling:
[2023-07-01 11:18:48] [config]   []
[2023-07-01 11:18:48] [config] early-stopping: 10
[2023-07-01 11:18:48] [config] early-stopping-on: first
[2023-07-01 11:18:48] [config] embedding-fix-src: false
[2023-07-01 11:18:48] [config] embedding-fix-trg: false
[2023-07-01 11:18:48] [config] embedding-normalization: false
[2023-07-01 11:18:48] [config] embedding-vectors:
[2023-07-01 11:18:48] [config]   []
[2023-07-01 11:18:48] [config] enc-cell: gru
[2023-07-01 11:18:48] [config] enc-cell-depth: 1
[2023-07-01 11:18:48] [config] enc-depth: 2
[2023-07-01 11:18:48] [config] enc-type: bidirectional
[2023-07-01 11:18:48] [config] english-title-case-every: 0
[2023-07-01 11:18:48] [config] exponential-smoothing: 0.0001
[2023-07-01 11:18:48] [config] factor-weight: 1
[2023-07-01 11:18:48] [config] factors-combine: sum
[2023-07-01 11:18:48] [config] factors-dim-emb: 0
[2023-07-01 11:18:48] [config] gradient-checkpointing: false
[2023-07-01 11:18:48] [config] gradient-norm-average-window: 100
[2023-07-01 11:18:48] [config] guided-alignment: none
[2023-07-01 11:18:48] [config] guided-alignment-cost: mse
[2023-07-01 11:18:48] [config] guided-alignment-weight: 0.1
[2023-07-01 11:18:48] [config] ignore-model-config: false
[2023-07-01 11:18:48] [config] input-types:
[2023-07-01 11:18:48] [config]   []
[2023-07-01 11:18:48] [config] interpolate-env-vars: false
[2023-07-01 11:18:48] [config] keep-best: false
[2023-07-01 11:18:48] [config] label-smoothing: 0.1
[2023-07-01 11:18:48] [config] layer-normalization: false
[2023-07-01 11:18:48] [config] learn-rate: 0.0003
[2023-07-01 11:18:48] [config] lemma-dependency: ""
[2023-07-01 11:18:48] [config] lemma-dim-emb: 0
[2023-07-01 11:18:48] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:18:48] [config] log-level: info
[2023-07-01 11:18:48] [config] log-time-zone: ""
[2023-07-01 11:18:48] [config] logical-epoch:
[2023-07-01 11:18:48] [config]   - 1e
[2023-07-01 11:18:48] [config]   - 0
[2023-07-01 11:18:48] [config] lr-decay: 0
[2023-07-01 11:18:48] [config] lr-decay-freq: 50000
[2023-07-01 11:18:48] [config] lr-decay-inv-sqrt:
[2023-07-01 11:18:48] [config]   - 16000
[2023-07-01 11:18:48] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:18:48] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:18:48] [config] lr-decay-start:
[2023-07-01 11:18:48] [config]   - 10
[2023-07-01 11:18:48] [config]   - 1
[2023-07-01 11:18:48] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:18:48] [config] lr-report: true
[2023-07-01 11:18:48] [config] lr-warmup: 16000
[2023-07-01 11:18:48] [config] lr-warmup-at-reload: false
[2023-07-01 11:18:48] [config] lr-warmup-cycle: false
[2023-07-01 11:18:48] [config] lr-warmup-start-rate: 0
[2023-07-01 11:18:48] [config] max-length: 100
[2023-07-01 11:18:48] [config] max-length-crop: false
[2023-07-01 11:18:48] [config] max-length-factor: 3
[2023-07-01 11:18:48] [config] maxi-batch: 100
[2023-07-01 11:18:48] [config] maxi-batch-sort: trg
[2023-07-01 11:18:48] [config] mini-batch: 1000
[2023-07-01 11:18:48] [config] mini-batch-fit: true
[2023-07-01 11:18:48] [config] mini-batch-fit-step: 10
[2023-07-01 11:18:48] [config] mini-batch-round-up: true
[2023-07-01 11:18:48] [config] mini-batch-track-lr: false
[2023-07-01 11:18:48] [config] mini-batch-warmup: 0
[2023-07-01 11:18:48] [config] mini-batch-words: 0
[2023-07-01 11:18:48] [config] mini-batch-words-ref: 0
[2023-07-01 11:18:48] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:18:48] [config] multi-loss-type: sum
[2023-07-01 11:18:48] [config] n-best: false
[2023-07-01 11:18:48] [config] no-nccl: false
[2023-07-01 11:18:48] [config] no-reload: false
[2023-07-01 11:18:48] [config] no-restore-corpus: false
[2023-07-01 11:18:48] [config] normalize: 1
[2023-07-01 11:18:48] [config] normalize-gradient: false
[2023-07-01 11:18:48] [config] num-devices: 0
[2023-07-01 11:18:48] [config] optimizer: adam
[2023-07-01 11:18:48] [config] optimizer-delay: 1
[2023-07-01 11:18:48] [config] optimizer-params:
[2023-07-01 11:18:48] [config]   - 0.9
[2023-07-01 11:18:48] [config]   - 0.98
[2023-07-01 11:18:48] [config]   - 1e-09
[2023-07-01 11:18:48] [config] output-omit-bias: false
[2023-07-01 11:18:48] [config] overwrite: true
[2023-07-01 11:18:48] [config] precision:
[2023-07-01 11:18:48] [config]   - float32
[2023-07-01 11:18:48] [config]   - float32
[2023-07-01 11:18:48] [config] pretrained-model: ""
[2023-07-01 11:18:48] [config] quantize-biases: false
[2023-07-01 11:18:48] [config] quantize-bits: 0
[2023-07-01 11:18:48] [config] quantize-log-based: false
[2023-07-01 11:18:48] [config] quantize-optimization-steps: 0
[2023-07-01 11:18:48] [config] quiet: false
[2023-07-01 11:18:48] [config] quiet-translation: true
[2023-07-01 11:18:48] [config] relative-paths: false
[2023-07-01 11:18:48] [config] right-left: false
[2023-07-01 11:18:48] [config] save-freq: 10000u
[2023-07-01 11:18:48] [config] seed: 1234
[2023-07-01 11:18:48] [config] sentencepiece-alphas:
[2023-07-01 11:18:48] [config]   []
[2023-07-01 11:18:48] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:18:48] [config] sentencepiece-options: ""
[2023-07-01 11:18:48] [config] sharding: global
[2023-07-01 11:18:48] [config] shuffle: data
[2023-07-01 11:18:48] [config] shuffle-in-ram: false
[2023-07-01 11:18:48] [config] sigterm: save-and-exit
[2023-07-01 11:18:48] [config] skip: false
[2023-07-01 11:18:48] [config] sqlite: ""
[2023-07-01 11:18:48] [config] sqlite-drop: false
[2023-07-01 11:18:48] [config] sync-freq: 200u
[2023-07-01 11:18:48] [config] sync-sgd: true
[2023-07-01 11:18:48] [config] tempdir: /tmp
[2023-07-01 11:18:48] [config] tied-embeddings: false
[2023-07-01 11:18:48] [config] tied-embeddings-all: true
[2023-07-01 11:18:48] [config] tied-embeddings-src: false
[2023-07-01 11:18:48] [config] train-embedder-rank:
[2023-07-01 11:18:48] [config]   []
[2023-07-01 11:18:48] [config] train-sets:
[2023-07-01 11:18:48] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:18:48] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:18:48] [config] transformer-aan-activation: swish
[2023-07-01 11:18:48] [config] transformer-aan-depth: 2
[2023-07-01 11:18:48] [config] transformer-aan-nogate: false
[2023-07-01 11:18:48] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:18:48] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:18:48] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:18:48] [config] transformer-depth-scaling: false
[2023-07-01 11:18:48] [config] transformer-dim-aan: 2048
[2023-07-01 11:18:48] [config] transformer-dim-ffn: 2048
[2023-07-01 11:18:48] [config] transformer-dropout: 0.1
[2023-07-01 11:18:48] [config] transformer-dropout-attention: 0
[2023-07-01 11:18:48] [config] transformer-dropout-ffn: 0
[2023-07-01 11:18:48] [config] transformer-ffn-activation: swish
[2023-07-01 11:18:48] [config] transformer-ffn-depth: 2
[2023-07-01 11:18:48] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:18:48] [config] transformer-heads: 8
[2023-07-01 11:18:48] [config] transformer-no-projection: false
[2023-07-01 11:18:48] [config] transformer-pool: false
[2023-07-01 11:18:48] [config] transformer-postprocess: dan
[2023-07-01 11:18:48] [config] transformer-postprocess-emb: d
[2023-07-01 11:18:48] [config] transformer-postprocess-top: ""
[2023-07-01 11:18:48] [config] transformer-preprocess: ""
[2023-07-01 11:18:48] [config] transformer-tied-layers:
[2023-07-01 11:18:48] [config]   []
[2023-07-01 11:18:48] [config] transformer-train-position-embeddings: false
[2023-07-01 11:18:48] [config] tsv: false
[2023-07-01 11:18:48] [config] tsv-fields: 0
[2023-07-01 11:18:48] [config] type: transformer
[2023-07-01 11:18:48] [config] ulr: false
[2023-07-01 11:18:48] [config] ulr-dim-emb: 0
[2023-07-01 11:18:48] [config] ulr-dropout: 0
[2023-07-01 11:18:48] [config] ulr-keys-vectors: ""
[2023-07-01 11:18:48] [config] ulr-query-vectors: ""
[2023-07-01 11:18:48] [config] ulr-softmax-temperature: 1
[2023-07-01 11:18:48] [config] ulr-trainable-transformation: false
[2023-07-01 11:18:48] [config] unlikelihood-loss: false
[2023-07-01 11:18:48] [config] valid-freq: 50000000
[2023-07-01 11:18:48] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:18:48] [config] valid-max-length: 1000
[2023-07-01 11:18:48] [config] valid-metrics:
[2023-07-01 11:18:48] [config]   - cross-entropy
[2023-07-01 11:18:48] [config]   - translation
[2023-07-01 11:18:48] [config] valid-mini-batch: 64
[2023-07-01 11:18:48] [config] valid-reset-stalled: false
[2023-07-01 11:18:48] [config] valid-script-args:
[2023-07-01 11:18:48] [config]   []
[2023-07-01 11:18:48] [config] valid-script-path: ""
[2023-07-01 11:18:48] [config] valid-sets:
[2023-07-01 11:18:48] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:18:48] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:18:48] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:18:48] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:18:48] [config] vocabs:
[2023-07-01 11:18:48] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:18:48] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:18:48] [config] word-penalty: 0
[2023-07-01 11:18:48] [config] word-scores: false
[2023-07-01 11:18:48] [config] workspace: 2048
[2023-07-01 11:18:48] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:18:48] Using synchronous SGD
[2023-07-01 11:18:48] Synced seed 1234
[2023-07-01 11:18:48] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:18:48] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:18:48] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:18:48] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:18:48] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:18:48] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:18:49] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:18:49] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:18:49] [comm] Using global sharding
[2023-07-01 11:18:49] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:18:49] [training] Using 1 GPUs
[2023-07-01 11:18:49] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:18:49] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:18:49] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:18:49] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:18:57] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:18:57] [valid] No post-processing script given for validating translator
[2023-07-01 11:18:57] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:18:57] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:18:57] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:18:57] [comm] Using global sharding
[2023-07-01 11:18:57] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:18:57] [training] Using 1 GPUs
[2023-07-01 11:18:57] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:18:58] Allocating memory for general optimizer shards
[2023-07-01 11:18:58] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:18:58] Loading Adam parameters
[2023-07-01 11:18:58] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:18:58] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:18:58] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:18:58] [data] Restoring the corpus state to epoch 52, batch 9639
[2023-07-01 11:18:58] [data] Shuffling data
[2023-07-01 11:18:58] [data] Done reading 20,192 sentences
[2023-07-01 11:18:58] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:18:58] Training started
[2023-07-01 11:18:58] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-07-01 11:18:58] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:18:58] Parameter type float32, optimization type float32, casting types false
[2023-07-01 11:19:22] Seen 20,073 samples
[2023-07-01 11:19:22] Starting data epoch 53 in logical epoch 53
[2023-07-01 11:19:22] Training finished
[2023-07-01 11:19:25] [valid] Ep. 53 : Up. 9828 : cross-entropy : 127.313 : stalled 10 times (last best: 124.257)
[2023-07-01 11:20:46] [valid] Ep. 53 : Up. 9828 : translation : 0 : new best
[2023-07-01 11:20:46] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:20:47] Saving Adam parameters
[2023-07-01 11:20:47] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:20:53] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:20:53] [marian] Running on node20.datos.cluster.uy as process 14207 with command line:
[2023-07-01 11:20:53] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 53 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:20:53] [config] after: 0e
[2023-07-01 11:20:53] [config] after-batches: 0
[2023-07-01 11:20:53] [config] after-epochs: 53
[2023-07-01 11:20:53] [config] all-caps-every: 0
[2023-07-01 11:20:53] [config] allow-unk: false
[2023-07-01 11:20:53] [config] authors: false
[2023-07-01 11:20:53] [config] beam-size: 12
[2023-07-01 11:20:53] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:20:53] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:20:53] [config] bert-masking-fraction: 0.15
[2023-07-01 11:20:53] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:20:53] [config] bert-train-type-embeddings: true
[2023-07-01 11:20:53] [config] bert-type-vocab-size: 2
[2023-07-01 11:20:53] [config] build-info: ""
[2023-07-01 11:20:53] [config] check-gradient-nan: false
[2023-07-01 11:20:53] [config] check-nan: false
[2023-07-01 11:20:53] [config] cite: false
[2023-07-01 11:20:53] [config] clip-norm: 5
[2023-07-01 11:20:53] [config] cost-scaling:
[2023-07-01 11:20:53] [config]   []
[2023-07-01 11:20:53] [config] cost-type: ce-sum
[2023-07-01 11:20:53] [config] cpu-threads: 0
[2023-07-01 11:20:53] [config] data-threads: 8
[2023-07-01 11:20:53] [config] data-weighting: ""
[2023-07-01 11:20:53] [config] data-weighting-type: sentence
[2023-07-01 11:20:53] [config] dec-cell: gru
[2023-07-01 11:20:53] [config] dec-cell-base-depth: 2
[2023-07-01 11:20:53] [config] dec-cell-high-depth: 1
[2023-07-01 11:20:53] [config] dec-depth: 2
[2023-07-01 11:20:53] [config] devices:
[2023-07-01 11:20:53] [config]   - 0
[2023-07-01 11:20:53] [config] dim-emb: 512
[2023-07-01 11:20:53] [config] dim-rnn: 1024
[2023-07-01 11:20:53] [config] dim-vocabs:
[2023-07-01 11:20:53] [config]   - 16384
[2023-07-01 11:20:53] [config]   - 16384
[2023-07-01 11:20:53] [config] disp-first: 0
[2023-07-01 11:20:53] [config] disp-freq: 1000u
[2023-07-01 11:20:53] [config] disp-label-counts: true
[2023-07-01 11:20:53] [config] dropout-rnn: 0
[2023-07-01 11:20:53] [config] dropout-src: 0
[2023-07-01 11:20:53] [config] dropout-trg: 0
[2023-07-01 11:20:53] [config] dump-config: ""
[2023-07-01 11:20:53] [config] dynamic-gradient-scaling:
[2023-07-01 11:20:53] [config]   []
[2023-07-01 11:20:53] [config] early-stopping: 10
[2023-07-01 11:20:53] [config] early-stopping-on: first
[2023-07-01 11:20:53] [config] embedding-fix-src: false
[2023-07-01 11:20:53] [config] embedding-fix-trg: false
[2023-07-01 11:20:53] [config] embedding-normalization: false
[2023-07-01 11:20:53] [config] embedding-vectors:
[2023-07-01 11:20:53] [config]   []
[2023-07-01 11:20:53] [config] enc-cell: gru
[2023-07-01 11:20:53] [config] enc-cell-depth: 1
[2023-07-01 11:20:53] [config] enc-depth: 2
[2023-07-01 11:20:53] [config] enc-type: bidirectional
[2023-07-01 11:20:53] [config] english-title-case-every: 0
[2023-07-01 11:20:53] [config] exponential-smoothing: 0.0001
[2023-07-01 11:20:53] [config] factor-weight: 1
[2023-07-01 11:20:53] [config] factors-combine: sum
[2023-07-01 11:20:53] [config] factors-dim-emb: 0
[2023-07-01 11:20:53] [config] gradient-checkpointing: false
[2023-07-01 11:20:53] [config] gradient-norm-average-window: 100
[2023-07-01 11:20:53] [config] guided-alignment: none
[2023-07-01 11:20:53] [config] guided-alignment-cost: mse
[2023-07-01 11:20:53] [config] guided-alignment-weight: 0.1
[2023-07-01 11:20:53] [config] ignore-model-config: false
[2023-07-01 11:20:53] [config] input-types:
[2023-07-01 11:20:53] [config]   []
[2023-07-01 11:20:53] [config] interpolate-env-vars: false
[2023-07-01 11:20:53] [config] keep-best: false
[2023-07-01 11:20:53] [config] label-smoothing: 0.1
[2023-07-01 11:20:53] [config] layer-normalization: false
[2023-07-01 11:20:53] [config] learn-rate: 0.0003
[2023-07-01 11:20:53] [config] lemma-dependency: ""
[2023-07-01 11:20:53] [config] lemma-dim-emb: 0
[2023-07-01 11:20:53] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:20:53] [config] log-level: info
[2023-07-01 11:20:53] [config] log-time-zone: ""
[2023-07-01 11:20:53] [config] logical-epoch:
[2023-07-01 11:20:53] [config]   - 1e
[2023-07-01 11:20:53] [config]   - 0
[2023-07-01 11:20:53] [config] lr-decay: 0
[2023-07-01 11:20:53] [config] lr-decay-freq: 50000
[2023-07-01 11:20:53] [config] lr-decay-inv-sqrt:
[2023-07-01 11:20:53] [config]   - 16000
[2023-07-01 11:20:53] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:20:53] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:20:53] [config] lr-decay-start:
[2023-07-01 11:20:53] [config]   - 10
[2023-07-01 11:20:53] [config]   - 1
[2023-07-01 11:20:53] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:20:53] [config] lr-report: true
[2023-07-01 11:20:53] [config] lr-warmup: 16000
[2023-07-01 11:20:53] [config] lr-warmup-at-reload: false
[2023-07-01 11:20:53] [config] lr-warmup-cycle: false
[2023-07-01 11:20:53] [config] lr-warmup-start-rate: 0
[2023-07-01 11:20:53] [config] max-length: 100
[2023-07-01 11:20:53] [config] max-length-crop: false
[2023-07-01 11:20:53] [config] max-length-factor: 3
[2023-07-01 11:20:53] [config] maxi-batch: 100
[2023-07-01 11:20:53] [config] maxi-batch-sort: trg
[2023-07-01 11:20:53] [config] mini-batch: 1000
[2023-07-01 11:20:53] [config] mini-batch-fit: true
[2023-07-01 11:20:53] [config] mini-batch-fit-step: 10
[2023-07-01 11:20:53] [config] mini-batch-round-up: true
[2023-07-01 11:20:53] [config] mini-batch-track-lr: false
[2023-07-01 11:20:53] [config] mini-batch-warmup: 0
[2023-07-01 11:20:53] [config] mini-batch-words: 0
[2023-07-01 11:20:53] [config] mini-batch-words-ref: 0
[2023-07-01 11:20:53] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:20:53] [config] multi-loss-type: sum
[2023-07-01 11:20:53] [config] n-best: false
[2023-07-01 11:20:53] [config] no-nccl: false
[2023-07-01 11:20:53] [config] no-reload: false
[2023-07-01 11:20:53] [config] no-restore-corpus: false
[2023-07-01 11:20:53] [config] normalize: 1
[2023-07-01 11:20:53] [config] normalize-gradient: false
[2023-07-01 11:20:53] [config] num-devices: 0
[2023-07-01 11:20:53] [config] optimizer: adam
[2023-07-01 11:20:53] [config] optimizer-delay: 1
[2023-07-01 11:20:53] [config] optimizer-params:
[2023-07-01 11:20:53] [config]   - 0.9
[2023-07-01 11:20:53] [config]   - 0.98
[2023-07-01 11:20:53] [config]   - 1e-09
[2023-07-01 11:20:53] [config] output-omit-bias: false
[2023-07-01 11:20:53] [config] overwrite: true
[2023-07-01 11:20:53] [config] precision:
[2023-07-01 11:20:53] [config]   - float32
[2023-07-01 11:20:53] [config]   - float32
[2023-07-01 11:20:53] [config] pretrained-model: ""
[2023-07-01 11:20:53] [config] quantize-biases: false
[2023-07-01 11:20:53] [config] quantize-bits: 0
[2023-07-01 11:20:53] [config] quantize-log-based: false
[2023-07-01 11:20:53] [config] quantize-optimization-steps: 0
[2023-07-01 11:20:53] [config] quiet: false
[2023-07-01 11:20:53] [config] quiet-translation: true
[2023-07-01 11:20:53] [config] relative-paths: false
[2023-07-01 11:20:53] [config] right-left: false
[2023-07-01 11:20:53] [config] save-freq: 10000u
[2023-07-01 11:20:53] [config] seed: 1234
[2023-07-01 11:20:53] [config] sentencepiece-alphas:
[2023-07-01 11:20:53] [config]   []
[2023-07-01 11:20:53] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:20:53] [config] sentencepiece-options: ""
[2023-07-01 11:20:53] [config] sharding: global
[2023-07-01 11:20:53] [config] shuffle: data
[2023-07-01 11:20:53] [config] shuffle-in-ram: false
[2023-07-01 11:20:53] [config] sigterm: save-and-exit
[2023-07-01 11:20:53] [config] skip: false
[2023-07-01 11:20:53] [config] sqlite: ""
[2023-07-01 11:20:53] [config] sqlite-drop: false
[2023-07-01 11:20:53] [config] sync-freq: 200u
[2023-07-01 11:20:53] [config] sync-sgd: true
[2023-07-01 11:20:53] [config] tempdir: /tmp
[2023-07-01 11:20:53] [config] tied-embeddings: false
[2023-07-01 11:20:53] [config] tied-embeddings-all: true
[2023-07-01 11:20:53] [config] tied-embeddings-src: false
[2023-07-01 11:20:53] [config] train-embedder-rank:
[2023-07-01 11:20:53] [config]   []
[2023-07-01 11:20:53] [config] train-sets:
[2023-07-01 11:20:53] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:20:53] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:20:53] [config] transformer-aan-activation: swish
[2023-07-01 11:20:53] [config] transformer-aan-depth: 2
[2023-07-01 11:20:53] [config] transformer-aan-nogate: false
[2023-07-01 11:20:53] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:20:53] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:20:53] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:20:53] [config] transformer-depth-scaling: false
[2023-07-01 11:20:53] [config] transformer-dim-aan: 2048
[2023-07-01 11:20:53] [config] transformer-dim-ffn: 2048
[2023-07-01 11:20:53] [config] transformer-dropout: 0.1
[2023-07-01 11:20:53] [config] transformer-dropout-attention: 0
[2023-07-01 11:20:53] [config] transformer-dropout-ffn: 0
[2023-07-01 11:20:53] [config] transformer-ffn-activation: swish
[2023-07-01 11:20:53] [config] transformer-ffn-depth: 2
[2023-07-01 11:20:53] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:20:53] [config] transformer-heads: 8
[2023-07-01 11:20:53] [config] transformer-no-projection: false
[2023-07-01 11:20:53] [config] transformer-pool: false
[2023-07-01 11:20:53] [config] transformer-postprocess: dan
[2023-07-01 11:20:53] [config] transformer-postprocess-emb: d
[2023-07-01 11:20:53] [config] transformer-postprocess-top: ""
[2023-07-01 11:20:53] [config] transformer-preprocess: ""
[2023-07-01 11:20:53] [config] transformer-tied-layers:
[2023-07-01 11:20:53] [config]   []
[2023-07-01 11:20:53] [config] transformer-train-position-embeddings: false
[2023-07-01 11:20:53] [config] tsv: false
[2023-07-01 11:20:53] [config] tsv-fields: 0
[2023-07-01 11:20:53] [config] type: transformer
[2023-07-01 11:20:53] [config] ulr: false
[2023-07-01 11:20:53] [config] ulr-dim-emb: 0
[2023-07-01 11:20:53] [config] ulr-dropout: 0
[2023-07-01 11:20:53] [config] ulr-keys-vectors: ""
[2023-07-01 11:20:53] [config] ulr-query-vectors: ""
[2023-07-01 11:20:53] [config] ulr-softmax-temperature: 1
[2023-07-01 11:20:53] [config] ulr-trainable-transformation: false
[2023-07-01 11:20:53] [config] unlikelihood-loss: false
[2023-07-01 11:20:53] [config] valid-freq: 50000000
[2023-07-01 11:20:53] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:20:53] [config] valid-max-length: 1000
[2023-07-01 11:20:53] [config] valid-metrics:
[2023-07-01 11:20:53] [config]   - cross-entropy
[2023-07-01 11:20:53] [config]   - translation
[2023-07-01 11:20:53] [config] valid-mini-batch: 64
[2023-07-01 11:20:53] [config] valid-reset-stalled: false
[2023-07-01 11:20:53] [config] valid-script-args:
[2023-07-01 11:20:53] [config]   []
[2023-07-01 11:20:53] [config] valid-script-path: ""
[2023-07-01 11:20:53] [config] valid-sets:
[2023-07-01 11:20:53] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:20:53] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:20:53] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:20:53] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:20:53] [config] vocabs:
[2023-07-01 11:20:53] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:20:53] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:20:53] [config] word-penalty: 0
[2023-07-01 11:20:53] [config] word-scores: false
[2023-07-01 11:20:53] [config] workspace: 2048
[2023-07-01 11:20:53] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:20:53] Using synchronous SGD
[2023-07-01 11:20:53] Synced seed 1234
[2023-07-01 11:20:53] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:20:53] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:20:53] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:20:54] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:20:54] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:20:54] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:20:54] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:20:54] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:20:54] [comm] Using global sharding
[2023-07-01 11:20:54] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:20:54] [training] Using 1 GPUs
[2023-07-01 11:20:54] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:20:54] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:20:55] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:20:55] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:21:02] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:21:02] [valid] No post-processing script given for validating translator
[2023-07-01 11:21:02] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:21:02] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:21:02] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:21:02] [comm] Using global sharding
[2023-07-01 11:21:02] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:21:02] [training] Using 1 GPUs
[2023-07-01 11:21:02] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:21:03] Allocating memory for general optimizer shards
[2023-07-01 11:21:03] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:21:03] Loading Adam parameters
[2023-07-01 11:21:03] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:21:03] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:21:03] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:21:03] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:21:03] [data] Shuffling data
[2023-07-01 11:21:03] [data] Done reading 20,192 sentences
[2023-07-01 11:21:04] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:21:04] Training started
[2023-07-01 11:21:04] Training finished
[2023-07-01 11:21:07] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:21:07] [marian] Running on node20.datos.cluster.uy as process 14268 with command line:
[2023-07-01 11:21:07] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 54 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:21:07] [config] after: 0e
[2023-07-01 11:21:07] [config] after-batches: 0
[2023-07-01 11:21:07] [config] after-epochs: 54
[2023-07-01 11:21:07] [config] all-caps-every: 0
[2023-07-01 11:21:07] [config] allow-unk: false
[2023-07-01 11:21:07] [config] authors: false
[2023-07-01 11:21:07] [config] beam-size: 12
[2023-07-01 11:21:07] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:21:07] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:21:07] [config] bert-masking-fraction: 0.15
[2023-07-01 11:21:07] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:21:07] [config] bert-train-type-embeddings: true
[2023-07-01 11:21:07] [config] bert-type-vocab-size: 2
[2023-07-01 11:21:07] [config] build-info: ""
[2023-07-01 11:21:07] [config] check-gradient-nan: false
[2023-07-01 11:21:07] [config] check-nan: false
[2023-07-01 11:21:07] [config] cite: false
[2023-07-01 11:21:07] [config] clip-norm: 5
[2023-07-01 11:21:07] [config] cost-scaling:
[2023-07-01 11:21:07] [config]   []
[2023-07-01 11:21:07] [config] cost-type: ce-sum
[2023-07-01 11:21:07] [config] cpu-threads: 0
[2023-07-01 11:21:07] [config] data-threads: 8
[2023-07-01 11:21:07] [config] data-weighting: ""
[2023-07-01 11:21:07] [config] data-weighting-type: sentence
[2023-07-01 11:21:07] [config] dec-cell: gru
[2023-07-01 11:21:07] [config] dec-cell-base-depth: 2
[2023-07-01 11:21:07] [config] dec-cell-high-depth: 1
[2023-07-01 11:21:07] [config] dec-depth: 2
[2023-07-01 11:21:07] [config] devices:
[2023-07-01 11:21:07] [config]   - 0
[2023-07-01 11:21:07] [config] dim-emb: 512
[2023-07-01 11:21:07] [config] dim-rnn: 1024
[2023-07-01 11:21:07] [config] dim-vocabs:
[2023-07-01 11:21:07] [config]   - 16384
[2023-07-01 11:21:07] [config]   - 16384
[2023-07-01 11:21:07] [config] disp-first: 0
[2023-07-01 11:21:07] [config] disp-freq: 1000u
[2023-07-01 11:21:07] [config] disp-label-counts: true
[2023-07-01 11:21:07] [config] dropout-rnn: 0
[2023-07-01 11:21:07] [config] dropout-src: 0
[2023-07-01 11:21:07] [config] dropout-trg: 0
[2023-07-01 11:21:07] [config] dump-config: ""
[2023-07-01 11:21:07] [config] dynamic-gradient-scaling:
[2023-07-01 11:21:07] [config]   []
[2023-07-01 11:21:07] [config] early-stopping: 10
[2023-07-01 11:21:07] [config] early-stopping-on: first
[2023-07-01 11:21:07] [config] embedding-fix-src: false
[2023-07-01 11:21:07] [config] embedding-fix-trg: false
[2023-07-01 11:21:07] [config] embedding-normalization: false
[2023-07-01 11:21:07] [config] embedding-vectors:
[2023-07-01 11:21:07] [config]   []
[2023-07-01 11:21:07] [config] enc-cell: gru
[2023-07-01 11:21:07] [config] enc-cell-depth: 1
[2023-07-01 11:21:07] [config] enc-depth: 2
[2023-07-01 11:21:07] [config] enc-type: bidirectional
[2023-07-01 11:21:07] [config] english-title-case-every: 0
[2023-07-01 11:21:07] [config] exponential-smoothing: 0.0001
[2023-07-01 11:21:07] [config] factor-weight: 1
[2023-07-01 11:21:07] [config] factors-combine: sum
[2023-07-01 11:21:07] [config] factors-dim-emb: 0
[2023-07-01 11:21:07] [config] gradient-checkpointing: false
[2023-07-01 11:21:07] [config] gradient-norm-average-window: 100
[2023-07-01 11:21:07] [config] guided-alignment: none
[2023-07-01 11:21:07] [config] guided-alignment-cost: mse
[2023-07-01 11:21:07] [config] guided-alignment-weight: 0.1
[2023-07-01 11:21:07] [config] ignore-model-config: false
[2023-07-01 11:21:07] [config] input-types:
[2023-07-01 11:21:07] [config]   []
[2023-07-01 11:21:07] [config] interpolate-env-vars: false
[2023-07-01 11:21:07] [config] keep-best: false
[2023-07-01 11:21:07] [config] label-smoothing: 0.1
[2023-07-01 11:21:07] [config] layer-normalization: false
[2023-07-01 11:21:07] [config] learn-rate: 0.0003
[2023-07-01 11:21:07] [config] lemma-dependency: ""
[2023-07-01 11:21:07] [config] lemma-dim-emb: 0
[2023-07-01 11:21:07] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:21:07] [config] log-level: info
[2023-07-01 11:21:07] [config] log-time-zone: ""
[2023-07-01 11:21:07] [config] logical-epoch:
[2023-07-01 11:21:07] [config]   - 1e
[2023-07-01 11:21:07] [config]   - 0
[2023-07-01 11:21:07] [config] lr-decay: 0
[2023-07-01 11:21:07] [config] lr-decay-freq: 50000
[2023-07-01 11:21:07] [config] lr-decay-inv-sqrt:
[2023-07-01 11:21:07] [config]   - 16000
[2023-07-01 11:21:07] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:21:07] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:21:07] [config] lr-decay-start:
[2023-07-01 11:21:07] [config]   - 10
[2023-07-01 11:21:07] [config]   - 1
[2023-07-01 11:21:07] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:21:07] [config] lr-report: true
[2023-07-01 11:21:07] [config] lr-warmup: 16000
[2023-07-01 11:21:07] [config] lr-warmup-at-reload: false
[2023-07-01 11:21:07] [config] lr-warmup-cycle: false
[2023-07-01 11:21:07] [config] lr-warmup-start-rate: 0
[2023-07-01 11:21:07] [config] max-length: 100
[2023-07-01 11:21:07] [config] max-length-crop: false
[2023-07-01 11:21:07] [config] max-length-factor: 3
[2023-07-01 11:21:07] [config] maxi-batch: 100
[2023-07-01 11:21:07] [config] maxi-batch-sort: trg
[2023-07-01 11:21:07] [config] mini-batch: 1000
[2023-07-01 11:21:07] [config] mini-batch-fit: true
[2023-07-01 11:21:07] [config] mini-batch-fit-step: 10
[2023-07-01 11:21:07] [config] mini-batch-round-up: true
[2023-07-01 11:21:07] [config] mini-batch-track-lr: false
[2023-07-01 11:21:07] [config] mini-batch-warmup: 0
[2023-07-01 11:21:07] [config] mini-batch-words: 0
[2023-07-01 11:21:07] [config] mini-batch-words-ref: 0
[2023-07-01 11:21:07] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:21:07] [config] multi-loss-type: sum
[2023-07-01 11:21:07] [config] n-best: false
[2023-07-01 11:21:07] [config] no-nccl: false
[2023-07-01 11:21:07] [config] no-reload: false
[2023-07-01 11:21:07] [config] no-restore-corpus: false
[2023-07-01 11:21:07] [config] normalize: 1
[2023-07-01 11:21:07] [config] normalize-gradient: false
[2023-07-01 11:21:07] [config] num-devices: 0
[2023-07-01 11:21:07] [config] optimizer: adam
[2023-07-01 11:21:07] [config] optimizer-delay: 1
[2023-07-01 11:21:07] [config] optimizer-params:
[2023-07-01 11:21:07] [config]   - 0.9
[2023-07-01 11:21:07] [config]   - 0.98
[2023-07-01 11:21:07] [config]   - 1e-09
[2023-07-01 11:21:07] [config] output-omit-bias: false
[2023-07-01 11:21:07] [config] overwrite: true
[2023-07-01 11:21:07] [config] precision:
[2023-07-01 11:21:07] [config]   - float32
[2023-07-01 11:21:07] [config]   - float32
[2023-07-01 11:21:07] [config] pretrained-model: ""
[2023-07-01 11:21:07] [config] quantize-biases: false
[2023-07-01 11:21:07] [config] quantize-bits: 0
[2023-07-01 11:21:07] [config] quantize-log-based: false
[2023-07-01 11:21:07] [config] quantize-optimization-steps: 0
[2023-07-01 11:21:07] [config] quiet: false
[2023-07-01 11:21:07] [config] quiet-translation: true
[2023-07-01 11:21:07] [config] relative-paths: false
[2023-07-01 11:21:07] [config] right-left: false
[2023-07-01 11:21:07] [config] save-freq: 10000u
[2023-07-01 11:21:07] [config] seed: 1234
[2023-07-01 11:21:07] [config] sentencepiece-alphas:
[2023-07-01 11:21:07] [config]   []
[2023-07-01 11:21:07] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:21:07] [config] sentencepiece-options: ""
[2023-07-01 11:21:07] [config] sharding: global
[2023-07-01 11:21:07] [config] shuffle: data
[2023-07-01 11:21:07] [config] shuffle-in-ram: false
[2023-07-01 11:21:07] [config] sigterm: save-and-exit
[2023-07-01 11:21:07] [config] skip: false
[2023-07-01 11:21:07] [config] sqlite: ""
[2023-07-01 11:21:07] [config] sqlite-drop: false
[2023-07-01 11:21:07] [config] sync-freq: 200u
[2023-07-01 11:21:07] [config] sync-sgd: true
[2023-07-01 11:21:07] [config] tempdir: /tmp
[2023-07-01 11:21:07] [config] tied-embeddings: false
[2023-07-01 11:21:07] [config] tied-embeddings-all: true
[2023-07-01 11:21:07] [config] tied-embeddings-src: false
[2023-07-01 11:21:07] [config] train-embedder-rank:
[2023-07-01 11:21:07] [config]   []
[2023-07-01 11:21:07] [config] train-sets:
[2023-07-01 11:21:07] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:21:07] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:21:07] [config] transformer-aan-activation: swish
[2023-07-01 11:21:07] [config] transformer-aan-depth: 2
[2023-07-01 11:21:07] [config] transformer-aan-nogate: false
[2023-07-01 11:21:07] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:21:07] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:21:07] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:21:07] [config] transformer-depth-scaling: false
[2023-07-01 11:21:07] [config] transformer-dim-aan: 2048
[2023-07-01 11:21:07] [config] transformer-dim-ffn: 2048
[2023-07-01 11:21:07] [config] transformer-dropout: 0.1
[2023-07-01 11:21:07] [config] transformer-dropout-attention: 0
[2023-07-01 11:21:07] [config] transformer-dropout-ffn: 0
[2023-07-01 11:21:07] [config] transformer-ffn-activation: swish
[2023-07-01 11:21:07] [config] transformer-ffn-depth: 2
[2023-07-01 11:21:07] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:21:07] [config] transformer-heads: 8
[2023-07-01 11:21:07] [config] transformer-no-projection: false
[2023-07-01 11:21:07] [config] transformer-pool: false
[2023-07-01 11:21:07] [config] transformer-postprocess: dan
[2023-07-01 11:21:07] [config] transformer-postprocess-emb: d
[2023-07-01 11:21:07] [config] transformer-postprocess-top: ""
[2023-07-01 11:21:07] [config] transformer-preprocess: ""
[2023-07-01 11:21:07] [config] transformer-tied-layers:
[2023-07-01 11:21:07] [config]   []
[2023-07-01 11:21:07] [config] transformer-train-position-embeddings: false
[2023-07-01 11:21:07] [config] tsv: false
[2023-07-01 11:21:07] [config] tsv-fields: 0
[2023-07-01 11:21:07] [config] type: transformer
[2023-07-01 11:21:07] [config] ulr: false
[2023-07-01 11:21:07] [config] ulr-dim-emb: 0
[2023-07-01 11:21:07] [config] ulr-dropout: 0
[2023-07-01 11:21:07] [config] ulr-keys-vectors: ""
[2023-07-01 11:21:07] [config] ulr-query-vectors: ""
[2023-07-01 11:21:07] [config] ulr-softmax-temperature: 1
[2023-07-01 11:21:07] [config] ulr-trainable-transformation: false
[2023-07-01 11:21:07] [config] unlikelihood-loss: false
[2023-07-01 11:21:07] [config] valid-freq: 50000000
[2023-07-01 11:21:07] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:21:07] [config] valid-max-length: 1000
[2023-07-01 11:21:07] [config] valid-metrics:
[2023-07-01 11:21:07] [config]   - cross-entropy
[2023-07-01 11:21:07] [config]   - translation
[2023-07-01 11:21:07] [config] valid-mini-batch: 64
[2023-07-01 11:21:07] [config] valid-reset-stalled: false
[2023-07-01 11:21:07] [config] valid-script-args:
[2023-07-01 11:21:07] [config]   []
[2023-07-01 11:21:07] [config] valid-script-path: ""
[2023-07-01 11:21:07] [config] valid-sets:
[2023-07-01 11:21:07] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:21:07] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:21:07] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:21:07] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:21:07] [config] vocabs:
[2023-07-01 11:21:07] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:21:07] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:21:07] [config] word-penalty: 0
[2023-07-01 11:21:07] [config] word-scores: false
[2023-07-01 11:21:07] [config] workspace: 2048
[2023-07-01 11:21:07] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:21:07] Using synchronous SGD
[2023-07-01 11:21:07] Synced seed 1234
[2023-07-01 11:21:07] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:21:07] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:21:07] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:21:07] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:21:07] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:21:07] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:21:08] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:21:08] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:21:08] [comm] Using global sharding
[2023-07-01 11:21:08] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:21:08] [training] Using 1 GPUs
[2023-07-01 11:21:08] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:21:08] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:21:09] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:21:09] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:21:16] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:21:16] [valid] No post-processing script given for validating translator
[2023-07-01 11:21:16] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:21:16] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:21:16] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:21:16] [comm] Using global sharding
[2023-07-01 11:21:16] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:21:16] [training] Using 1 GPUs
[2023-07-01 11:21:16] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:21:17] Allocating memory for general optimizer shards
[2023-07-01 11:21:17] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:21:17] Loading Adam parameters
[2023-07-01 11:21:17] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:21:17] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:21:17] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:21:17] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:21:17] [data] Shuffling data
[2023-07-01 11:21:17] [data] Done reading 20,192 sentences
[2023-07-01 11:21:17] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:21:17] Training started
[2023-07-01 11:21:17] Training finished
[2023-07-01 11:21:20] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:21:20] [marian] Running on node20.datos.cluster.uy as process 14327 with command line:
[2023-07-01 11:21:20] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 55 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:21:21] [config] after: 0e
[2023-07-01 11:21:21] [config] after-batches: 0
[2023-07-01 11:21:21] [config] after-epochs: 55
[2023-07-01 11:21:21] [config] all-caps-every: 0
[2023-07-01 11:21:21] [config] allow-unk: false
[2023-07-01 11:21:21] [config] authors: false
[2023-07-01 11:21:21] [config] beam-size: 12
[2023-07-01 11:21:21] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:21:21] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:21:21] [config] bert-masking-fraction: 0.15
[2023-07-01 11:21:21] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:21:21] [config] bert-train-type-embeddings: true
[2023-07-01 11:21:21] [config] bert-type-vocab-size: 2
[2023-07-01 11:21:21] [config] build-info: ""
[2023-07-01 11:21:21] [config] check-gradient-nan: false
[2023-07-01 11:21:21] [config] check-nan: false
[2023-07-01 11:21:21] [config] cite: false
[2023-07-01 11:21:21] [config] clip-norm: 5
[2023-07-01 11:21:21] [config] cost-scaling:
[2023-07-01 11:21:21] [config]   []
[2023-07-01 11:21:21] [config] cost-type: ce-sum
[2023-07-01 11:21:21] [config] cpu-threads: 0
[2023-07-01 11:21:21] [config] data-threads: 8
[2023-07-01 11:21:21] [config] data-weighting: ""
[2023-07-01 11:21:21] [config] data-weighting-type: sentence
[2023-07-01 11:21:21] [config] dec-cell: gru
[2023-07-01 11:21:21] [config] dec-cell-base-depth: 2
[2023-07-01 11:21:21] [config] dec-cell-high-depth: 1
[2023-07-01 11:21:21] [config] dec-depth: 2
[2023-07-01 11:21:21] [config] devices:
[2023-07-01 11:21:21] [config]   - 0
[2023-07-01 11:21:21] [config] dim-emb: 512
[2023-07-01 11:21:21] [config] dim-rnn: 1024
[2023-07-01 11:21:21] [config] dim-vocabs:
[2023-07-01 11:21:21] [config]   - 16384
[2023-07-01 11:21:21] [config]   - 16384
[2023-07-01 11:21:21] [config] disp-first: 0
[2023-07-01 11:21:21] [config] disp-freq: 1000u
[2023-07-01 11:21:21] [config] disp-label-counts: true
[2023-07-01 11:21:21] [config] dropout-rnn: 0
[2023-07-01 11:21:21] [config] dropout-src: 0
[2023-07-01 11:21:21] [config] dropout-trg: 0
[2023-07-01 11:21:21] [config] dump-config: ""
[2023-07-01 11:21:21] [config] dynamic-gradient-scaling:
[2023-07-01 11:21:21] [config]   []
[2023-07-01 11:21:21] [config] early-stopping: 10
[2023-07-01 11:21:21] [config] early-stopping-on: first
[2023-07-01 11:21:21] [config] embedding-fix-src: false
[2023-07-01 11:21:21] [config] embedding-fix-trg: false
[2023-07-01 11:21:21] [config] embedding-normalization: false
[2023-07-01 11:21:21] [config] embedding-vectors:
[2023-07-01 11:21:21] [config]   []
[2023-07-01 11:21:21] [config] enc-cell: gru
[2023-07-01 11:21:21] [config] enc-cell-depth: 1
[2023-07-01 11:21:21] [config] enc-depth: 2
[2023-07-01 11:21:21] [config] enc-type: bidirectional
[2023-07-01 11:21:21] [config] english-title-case-every: 0
[2023-07-01 11:21:21] [config] exponential-smoothing: 0.0001
[2023-07-01 11:21:21] [config] factor-weight: 1
[2023-07-01 11:21:21] [config] factors-combine: sum
[2023-07-01 11:21:21] [config] factors-dim-emb: 0
[2023-07-01 11:21:21] [config] gradient-checkpointing: false
[2023-07-01 11:21:21] [config] gradient-norm-average-window: 100
[2023-07-01 11:21:21] [config] guided-alignment: none
[2023-07-01 11:21:21] [config] guided-alignment-cost: mse
[2023-07-01 11:21:21] [config] guided-alignment-weight: 0.1
[2023-07-01 11:21:21] [config] ignore-model-config: false
[2023-07-01 11:21:21] [config] input-types:
[2023-07-01 11:21:21] [config]   []
[2023-07-01 11:21:21] [config] interpolate-env-vars: false
[2023-07-01 11:21:21] [config] keep-best: false
[2023-07-01 11:21:21] [config] label-smoothing: 0.1
[2023-07-01 11:21:21] [config] layer-normalization: false
[2023-07-01 11:21:21] [config] learn-rate: 0.0003
[2023-07-01 11:21:21] [config] lemma-dependency: ""
[2023-07-01 11:21:21] [config] lemma-dim-emb: 0
[2023-07-01 11:21:21] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:21:21] [config] log-level: info
[2023-07-01 11:21:21] [config] log-time-zone: ""
[2023-07-01 11:21:21] [config] logical-epoch:
[2023-07-01 11:21:21] [config]   - 1e
[2023-07-01 11:21:21] [config]   - 0
[2023-07-01 11:21:21] [config] lr-decay: 0
[2023-07-01 11:21:21] [config] lr-decay-freq: 50000
[2023-07-01 11:21:21] [config] lr-decay-inv-sqrt:
[2023-07-01 11:21:21] [config]   - 16000
[2023-07-01 11:21:21] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:21:21] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:21:21] [config] lr-decay-start:
[2023-07-01 11:21:21] [config]   - 10
[2023-07-01 11:21:21] [config]   - 1
[2023-07-01 11:21:21] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:21:21] [config] lr-report: true
[2023-07-01 11:21:21] [config] lr-warmup: 16000
[2023-07-01 11:21:21] [config] lr-warmup-at-reload: false
[2023-07-01 11:21:21] [config] lr-warmup-cycle: false
[2023-07-01 11:21:21] [config] lr-warmup-start-rate: 0
[2023-07-01 11:21:21] [config] max-length: 100
[2023-07-01 11:21:21] [config] max-length-crop: false
[2023-07-01 11:21:21] [config] max-length-factor: 3
[2023-07-01 11:21:21] [config] maxi-batch: 100
[2023-07-01 11:21:21] [config] maxi-batch-sort: trg
[2023-07-01 11:21:21] [config] mini-batch: 1000
[2023-07-01 11:21:21] [config] mini-batch-fit: true
[2023-07-01 11:21:21] [config] mini-batch-fit-step: 10
[2023-07-01 11:21:21] [config] mini-batch-round-up: true
[2023-07-01 11:21:21] [config] mini-batch-track-lr: false
[2023-07-01 11:21:21] [config] mini-batch-warmup: 0
[2023-07-01 11:21:21] [config] mini-batch-words: 0
[2023-07-01 11:21:21] [config] mini-batch-words-ref: 0
[2023-07-01 11:21:21] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:21:21] [config] multi-loss-type: sum
[2023-07-01 11:21:21] [config] n-best: false
[2023-07-01 11:21:21] [config] no-nccl: false
[2023-07-01 11:21:21] [config] no-reload: false
[2023-07-01 11:21:21] [config] no-restore-corpus: false
[2023-07-01 11:21:21] [config] normalize: 1
[2023-07-01 11:21:21] [config] normalize-gradient: false
[2023-07-01 11:21:21] [config] num-devices: 0
[2023-07-01 11:21:21] [config] optimizer: adam
[2023-07-01 11:21:21] [config] optimizer-delay: 1
[2023-07-01 11:21:21] [config] optimizer-params:
[2023-07-01 11:21:21] [config]   - 0.9
[2023-07-01 11:21:21] [config]   - 0.98
[2023-07-01 11:21:21] [config]   - 1e-09
[2023-07-01 11:21:21] [config] output-omit-bias: false
[2023-07-01 11:21:21] [config] overwrite: true
[2023-07-01 11:21:21] [config] precision:
[2023-07-01 11:21:21] [config]   - float32
[2023-07-01 11:21:21] [config]   - float32
[2023-07-01 11:21:21] [config] pretrained-model: ""
[2023-07-01 11:21:21] [config] quantize-biases: false
[2023-07-01 11:21:21] [config] quantize-bits: 0
[2023-07-01 11:21:21] [config] quantize-log-based: false
[2023-07-01 11:21:21] [config] quantize-optimization-steps: 0
[2023-07-01 11:21:21] [config] quiet: false
[2023-07-01 11:21:21] [config] quiet-translation: true
[2023-07-01 11:21:21] [config] relative-paths: false
[2023-07-01 11:21:21] [config] right-left: false
[2023-07-01 11:21:21] [config] save-freq: 10000u
[2023-07-01 11:21:21] [config] seed: 1234
[2023-07-01 11:21:21] [config] sentencepiece-alphas:
[2023-07-01 11:21:21] [config]   []
[2023-07-01 11:21:21] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:21:21] [config] sentencepiece-options: ""
[2023-07-01 11:21:21] [config] sharding: global
[2023-07-01 11:21:21] [config] shuffle: data
[2023-07-01 11:21:21] [config] shuffle-in-ram: false
[2023-07-01 11:21:21] [config] sigterm: save-and-exit
[2023-07-01 11:21:21] [config] skip: false
[2023-07-01 11:21:21] [config] sqlite: ""
[2023-07-01 11:21:21] [config] sqlite-drop: false
[2023-07-01 11:21:21] [config] sync-freq: 200u
[2023-07-01 11:21:21] [config] sync-sgd: true
[2023-07-01 11:21:21] [config] tempdir: /tmp
[2023-07-01 11:21:21] [config] tied-embeddings: false
[2023-07-01 11:21:21] [config] tied-embeddings-all: true
[2023-07-01 11:21:21] [config] tied-embeddings-src: false
[2023-07-01 11:21:21] [config] train-embedder-rank:
[2023-07-01 11:21:21] [config]   []
[2023-07-01 11:21:21] [config] train-sets:
[2023-07-01 11:21:21] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:21:21] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:21:21] [config] transformer-aan-activation: swish
[2023-07-01 11:21:21] [config] transformer-aan-depth: 2
[2023-07-01 11:21:21] [config] transformer-aan-nogate: false
[2023-07-01 11:21:21] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:21:21] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:21:21] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:21:21] [config] transformer-depth-scaling: false
[2023-07-01 11:21:21] [config] transformer-dim-aan: 2048
[2023-07-01 11:21:21] [config] transformer-dim-ffn: 2048
[2023-07-01 11:21:21] [config] transformer-dropout: 0.1
[2023-07-01 11:21:21] [config] transformer-dropout-attention: 0
[2023-07-01 11:21:21] [config] transformer-dropout-ffn: 0
[2023-07-01 11:21:21] [config] transformer-ffn-activation: swish
[2023-07-01 11:21:21] [config] transformer-ffn-depth: 2
[2023-07-01 11:21:21] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:21:21] [config] transformer-heads: 8
[2023-07-01 11:21:21] [config] transformer-no-projection: false
[2023-07-01 11:21:21] [config] transformer-pool: false
[2023-07-01 11:21:21] [config] transformer-postprocess: dan
[2023-07-01 11:21:21] [config] transformer-postprocess-emb: d
[2023-07-01 11:21:21] [config] transformer-postprocess-top: ""
[2023-07-01 11:21:21] [config] transformer-preprocess: ""
[2023-07-01 11:21:21] [config] transformer-tied-layers:
[2023-07-01 11:21:21] [config]   []
[2023-07-01 11:21:21] [config] transformer-train-position-embeddings: false
[2023-07-01 11:21:21] [config] tsv: false
[2023-07-01 11:21:21] [config] tsv-fields: 0
[2023-07-01 11:21:21] [config] type: transformer
[2023-07-01 11:21:21] [config] ulr: false
[2023-07-01 11:21:21] [config] ulr-dim-emb: 0
[2023-07-01 11:21:21] [config] ulr-dropout: 0
[2023-07-01 11:21:21] [config] ulr-keys-vectors: ""
[2023-07-01 11:21:21] [config] ulr-query-vectors: ""
[2023-07-01 11:21:21] [config] ulr-softmax-temperature: 1
[2023-07-01 11:21:21] [config] ulr-trainable-transformation: false
[2023-07-01 11:21:21] [config] unlikelihood-loss: false
[2023-07-01 11:21:21] [config] valid-freq: 50000000
[2023-07-01 11:21:21] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:21:21] [config] valid-max-length: 1000
[2023-07-01 11:21:21] [config] valid-metrics:
[2023-07-01 11:21:21] [config]   - cross-entropy
[2023-07-01 11:21:21] [config]   - translation
[2023-07-01 11:21:21] [config] valid-mini-batch: 64
[2023-07-01 11:21:21] [config] valid-reset-stalled: false
[2023-07-01 11:21:21] [config] valid-script-args:
[2023-07-01 11:21:21] [config]   []
[2023-07-01 11:21:21] [config] valid-script-path: ""
[2023-07-01 11:21:21] [config] valid-sets:
[2023-07-01 11:21:21] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:21:21] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:21:21] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:21:21] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:21:21] [config] vocabs:
[2023-07-01 11:21:21] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:21:21] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:21:21] [config] word-penalty: 0
[2023-07-01 11:21:21] [config] word-scores: false
[2023-07-01 11:21:21] [config] workspace: 2048
[2023-07-01 11:21:21] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:21:21] Using synchronous SGD
[2023-07-01 11:21:21] Synced seed 1234
[2023-07-01 11:21:21] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:21:21] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:21:21] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:21:21] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:21:21] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:21:21] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:21:22] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:21:22] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:21:22] [comm] Using global sharding
[2023-07-01 11:21:22] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:21:22] [training] Using 1 GPUs
[2023-07-01 11:21:22] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:21:22] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:21:22] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:21:22] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:21:30] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:21:30] [valid] No post-processing script given for validating translator
[2023-07-01 11:21:30] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:21:30] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:21:30] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:21:30] [comm] Using global sharding
[2023-07-01 11:21:30] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:21:30] [training] Using 1 GPUs
[2023-07-01 11:21:30] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:21:30] Allocating memory for general optimizer shards
[2023-07-01 11:21:30] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:21:30] Loading Adam parameters
[2023-07-01 11:21:30] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:21:30] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:21:30] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:21:30] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:21:30] [data] Shuffling data
[2023-07-01 11:21:30] [data] Done reading 20,192 sentences
[2023-07-01 11:21:30] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:21:30] Training started
[2023-07-01 11:21:30] Training finished
[2023-07-01 11:21:34] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:21:34] [marian] Running on node20.datos.cluster.uy as process 14386 with command line:
[2023-07-01 11:21:34] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 56 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:21:34] [config] after: 0e
[2023-07-01 11:21:34] [config] after-batches: 0
[2023-07-01 11:21:34] [config] after-epochs: 56
[2023-07-01 11:21:34] [config] all-caps-every: 0
[2023-07-01 11:21:34] [config] allow-unk: false
[2023-07-01 11:21:34] [config] authors: false
[2023-07-01 11:21:34] [config] beam-size: 12
[2023-07-01 11:21:34] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:21:34] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:21:34] [config] bert-masking-fraction: 0.15
[2023-07-01 11:21:34] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:21:34] [config] bert-train-type-embeddings: true
[2023-07-01 11:21:34] [config] bert-type-vocab-size: 2
[2023-07-01 11:21:34] [config] build-info: ""
[2023-07-01 11:21:34] [config] check-gradient-nan: false
[2023-07-01 11:21:34] [config] check-nan: false
[2023-07-01 11:21:34] [config] cite: false
[2023-07-01 11:21:34] [config] clip-norm: 5
[2023-07-01 11:21:34] [config] cost-scaling:
[2023-07-01 11:21:34] [config]   []
[2023-07-01 11:21:34] [config] cost-type: ce-sum
[2023-07-01 11:21:34] [config] cpu-threads: 0
[2023-07-01 11:21:34] [config] data-threads: 8
[2023-07-01 11:21:34] [config] data-weighting: ""
[2023-07-01 11:21:34] [config] data-weighting-type: sentence
[2023-07-01 11:21:34] [config] dec-cell: gru
[2023-07-01 11:21:34] [config] dec-cell-base-depth: 2
[2023-07-01 11:21:34] [config] dec-cell-high-depth: 1
[2023-07-01 11:21:34] [config] dec-depth: 2
[2023-07-01 11:21:34] [config] devices:
[2023-07-01 11:21:34] [config]   - 0
[2023-07-01 11:21:34] [config] dim-emb: 512
[2023-07-01 11:21:34] [config] dim-rnn: 1024
[2023-07-01 11:21:34] [config] dim-vocabs:
[2023-07-01 11:21:34] [config]   - 16384
[2023-07-01 11:21:34] [config]   - 16384
[2023-07-01 11:21:34] [config] disp-first: 0
[2023-07-01 11:21:34] [config] disp-freq: 1000u
[2023-07-01 11:21:34] [config] disp-label-counts: true
[2023-07-01 11:21:34] [config] dropout-rnn: 0
[2023-07-01 11:21:34] [config] dropout-src: 0
[2023-07-01 11:21:34] [config] dropout-trg: 0
[2023-07-01 11:21:34] [config] dump-config: ""
[2023-07-01 11:21:34] [config] dynamic-gradient-scaling:
[2023-07-01 11:21:34] [config]   []
[2023-07-01 11:21:34] [config] early-stopping: 10
[2023-07-01 11:21:34] [config] early-stopping-on: first
[2023-07-01 11:21:34] [config] embedding-fix-src: false
[2023-07-01 11:21:34] [config] embedding-fix-trg: false
[2023-07-01 11:21:34] [config] embedding-normalization: false
[2023-07-01 11:21:34] [config] embedding-vectors:
[2023-07-01 11:21:34] [config]   []
[2023-07-01 11:21:34] [config] enc-cell: gru
[2023-07-01 11:21:34] [config] enc-cell-depth: 1
[2023-07-01 11:21:34] [config] enc-depth: 2
[2023-07-01 11:21:34] [config] enc-type: bidirectional
[2023-07-01 11:21:34] [config] english-title-case-every: 0
[2023-07-01 11:21:34] [config] exponential-smoothing: 0.0001
[2023-07-01 11:21:34] [config] factor-weight: 1
[2023-07-01 11:21:34] [config] factors-combine: sum
[2023-07-01 11:21:34] [config] factors-dim-emb: 0
[2023-07-01 11:21:34] [config] gradient-checkpointing: false
[2023-07-01 11:21:34] [config] gradient-norm-average-window: 100
[2023-07-01 11:21:34] [config] guided-alignment: none
[2023-07-01 11:21:34] [config] guided-alignment-cost: mse
[2023-07-01 11:21:34] [config] guided-alignment-weight: 0.1
[2023-07-01 11:21:34] [config] ignore-model-config: false
[2023-07-01 11:21:34] [config] input-types:
[2023-07-01 11:21:34] [config]   []
[2023-07-01 11:21:34] [config] interpolate-env-vars: false
[2023-07-01 11:21:34] [config] keep-best: false
[2023-07-01 11:21:34] [config] label-smoothing: 0.1
[2023-07-01 11:21:34] [config] layer-normalization: false
[2023-07-01 11:21:34] [config] learn-rate: 0.0003
[2023-07-01 11:21:34] [config] lemma-dependency: ""
[2023-07-01 11:21:34] [config] lemma-dim-emb: 0
[2023-07-01 11:21:34] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:21:34] [config] log-level: info
[2023-07-01 11:21:34] [config] log-time-zone: ""
[2023-07-01 11:21:34] [config] logical-epoch:
[2023-07-01 11:21:34] [config]   - 1e
[2023-07-01 11:21:34] [config]   - 0
[2023-07-01 11:21:34] [config] lr-decay: 0
[2023-07-01 11:21:34] [config] lr-decay-freq: 50000
[2023-07-01 11:21:34] [config] lr-decay-inv-sqrt:
[2023-07-01 11:21:34] [config]   - 16000
[2023-07-01 11:21:34] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:21:34] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:21:34] [config] lr-decay-start:
[2023-07-01 11:21:34] [config]   - 10
[2023-07-01 11:21:34] [config]   - 1
[2023-07-01 11:21:34] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:21:34] [config] lr-report: true
[2023-07-01 11:21:34] [config] lr-warmup: 16000
[2023-07-01 11:21:34] [config] lr-warmup-at-reload: false
[2023-07-01 11:21:34] [config] lr-warmup-cycle: false
[2023-07-01 11:21:34] [config] lr-warmup-start-rate: 0
[2023-07-01 11:21:34] [config] max-length: 100
[2023-07-01 11:21:34] [config] max-length-crop: false
[2023-07-01 11:21:34] [config] max-length-factor: 3
[2023-07-01 11:21:34] [config] maxi-batch: 100
[2023-07-01 11:21:34] [config] maxi-batch-sort: trg
[2023-07-01 11:21:34] [config] mini-batch: 1000
[2023-07-01 11:21:34] [config] mini-batch-fit: true
[2023-07-01 11:21:34] [config] mini-batch-fit-step: 10
[2023-07-01 11:21:34] [config] mini-batch-round-up: true
[2023-07-01 11:21:34] [config] mini-batch-track-lr: false
[2023-07-01 11:21:34] [config] mini-batch-warmup: 0
[2023-07-01 11:21:34] [config] mini-batch-words: 0
[2023-07-01 11:21:34] [config] mini-batch-words-ref: 0
[2023-07-01 11:21:34] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:21:34] [config] multi-loss-type: sum
[2023-07-01 11:21:34] [config] n-best: false
[2023-07-01 11:21:34] [config] no-nccl: false
[2023-07-01 11:21:34] [config] no-reload: false
[2023-07-01 11:21:34] [config] no-restore-corpus: false
[2023-07-01 11:21:34] [config] normalize: 1
[2023-07-01 11:21:34] [config] normalize-gradient: false
[2023-07-01 11:21:34] [config] num-devices: 0
[2023-07-01 11:21:34] [config] optimizer: adam
[2023-07-01 11:21:34] [config] optimizer-delay: 1
[2023-07-01 11:21:34] [config] optimizer-params:
[2023-07-01 11:21:34] [config]   - 0.9
[2023-07-01 11:21:34] [config]   - 0.98
[2023-07-01 11:21:34] [config]   - 1e-09
[2023-07-01 11:21:34] [config] output-omit-bias: false
[2023-07-01 11:21:34] [config] overwrite: true
[2023-07-01 11:21:34] [config] precision:
[2023-07-01 11:21:34] [config]   - float32
[2023-07-01 11:21:34] [config]   - float32
[2023-07-01 11:21:34] [config] pretrained-model: ""
[2023-07-01 11:21:34] [config] quantize-biases: false
[2023-07-01 11:21:34] [config] quantize-bits: 0
[2023-07-01 11:21:34] [config] quantize-log-based: false
[2023-07-01 11:21:34] [config] quantize-optimization-steps: 0
[2023-07-01 11:21:34] [config] quiet: false
[2023-07-01 11:21:34] [config] quiet-translation: true
[2023-07-01 11:21:34] [config] relative-paths: false
[2023-07-01 11:21:34] [config] right-left: false
[2023-07-01 11:21:34] [config] save-freq: 10000u
[2023-07-01 11:21:34] [config] seed: 1234
[2023-07-01 11:21:34] [config] sentencepiece-alphas:
[2023-07-01 11:21:34] [config]   []
[2023-07-01 11:21:34] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:21:34] [config] sentencepiece-options: ""
[2023-07-01 11:21:34] [config] sharding: global
[2023-07-01 11:21:34] [config] shuffle: data
[2023-07-01 11:21:34] [config] shuffle-in-ram: false
[2023-07-01 11:21:34] [config] sigterm: save-and-exit
[2023-07-01 11:21:34] [config] skip: false
[2023-07-01 11:21:34] [config] sqlite: ""
[2023-07-01 11:21:34] [config] sqlite-drop: false
[2023-07-01 11:21:34] [config] sync-freq: 200u
[2023-07-01 11:21:34] [config] sync-sgd: true
[2023-07-01 11:21:34] [config] tempdir: /tmp
[2023-07-01 11:21:34] [config] tied-embeddings: false
[2023-07-01 11:21:34] [config] tied-embeddings-all: true
[2023-07-01 11:21:34] [config] tied-embeddings-src: false
[2023-07-01 11:21:34] [config] train-embedder-rank:
[2023-07-01 11:21:34] [config]   []
[2023-07-01 11:21:34] [config] train-sets:
[2023-07-01 11:21:34] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:21:34] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:21:34] [config] transformer-aan-activation: swish
[2023-07-01 11:21:34] [config] transformer-aan-depth: 2
[2023-07-01 11:21:34] [config] transformer-aan-nogate: false
[2023-07-01 11:21:34] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:21:34] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:21:34] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:21:34] [config] transformer-depth-scaling: false
[2023-07-01 11:21:34] [config] transformer-dim-aan: 2048
[2023-07-01 11:21:34] [config] transformer-dim-ffn: 2048
[2023-07-01 11:21:34] [config] transformer-dropout: 0.1
[2023-07-01 11:21:34] [config] transformer-dropout-attention: 0
[2023-07-01 11:21:34] [config] transformer-dropout-ffn: 0
[2023-07-01 11:21:34] [config] transformer-ffn-activation: swish
[2023-07-01 11:21:34] [config] transformer-ffn-depth: 2
[2023-07-01 11:21:34] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:21:34] [config] transformer-heads: 8
[2023-07-01 11:21:34] [config] transformer-no-projection: false
[2023-07-01 11:21:34] [config] transformer-pool: false
[2023-07-01 11:21:34] [config] transformer-postprocess: dan
[2023-07-01 11:21:34] [config] transformer-postprocess-emb: d
[2023-07-01 11:21:34] [config] transformer-postprocess-top: ""
[2023-07-01 11:21:34] [config] transformer-preprocess: ""
[2023-07-01 11:21:34] [config] transformer-tied-layers:
[2023-07-01 11:21:34] [config]   []
[2023-07-01 11:21:34] [config] transformer-train-position-embeddings: false
[2023-07-01 11:21:34] [config] tsv: false
[2023-07-01 11:21:34] [config] tsv-fields: 0
[2023-07-01 11:21:34] [config] type: transformer
[2023-07-01 11:21:34] [config] ulr: false
[2023-07-01 11:21:34] [config] ulr-dim-emb: 0
[2023-07-01 11:21:34] [config] ulr-dropout: 0
[2023-07-01 11:21:34] [config] ulr-keys-vectors: ""
[2023-07-01 11:21:34] [config] ulr-query-vectors: ""
[2023-07-01 11:21:34] [config] ulr-softmax-temperature: 1
[2023-07-01 11:21:34] [config] ulr-trainable-transformation: false
[2023-07-01 11:21:34] [config] unlikelihood-loss: false
[2023-07-01 11:21:34] [config] valid-freq: 50000000
[2023-07-01 11:21:34] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:21:34] [config] valid-max-length: 1000
[2023-07-01 11:21:34] [config] valid-metrics:
[2023-07-01 11:21:34] [config]   - cross-entropy
[2023-07-01 11:21:34] [config]   - translation
[2023-07-01 11:21:34] [config] valid-mini-batch: 64
[2023-07-01 11:21:34] [config] valid-reset-stalled: false
[2023-07-01 11:21:34] [config] valid-script-args:
[2023-07-01 11:21:34] [config]   []
[2023-07-01 11:21:34] [config] valid-script-path: ""
[2023-07-01 11:21:34] [config] valid-sets:
[2023-07-01 11:21:34] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:21:34] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:21:34] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:21:34] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:21:34] [config] vocabs:
[2023-07-01 11:21:34] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:21:34] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:21:34] [config] word-penalty: 0
[2023-07-01 11:21:34] [config] word-scores: false
[2023-07-01 11:21:34] [config] workspace: 2048
[2023-07-01 11:21:34] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:21:34] Using synchronous SGD
[2023-07-01 11:21:35] Synced seed 1234
[2023-07-01 11:21:35] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:21:35] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:21:35] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:21:35] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:21:35] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:21:35] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:21:36] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:21:36] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:21:36] [comm] Using global sharding
[2023-07-01 11:21:36] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:21:36] [training] Using 1 GPUs
[2023-07-01 11:21:36] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:21:36] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:21:36] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:21:36] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:21:43] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:21:44] [valid] No post-processing script given for validating translator
[2023-07-01 11:21:44] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:21:44] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:21:44] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:21:44] [comm] Using global sharding
[2023-07-01 11:21:44] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:21:44] [training] Using 1 GPUs
[2023-07-01 11:21:44] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:21:44] Allocating memory for general optimizer shards
[2023-07-01 11:21:44] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:21:44] Loading Adam parameters
[2023-07-01 11:21:44] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:21:44] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:21:44] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:21:44] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:21:44] [data] Shuffling data
[2023-07-01 11:21:44] [data] Done reading 20,192 sentences
[2023-07-01 11:21:44] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:21:44] Training started
[2023-07-01 11:21:44] Training finished
[2023-07-01 11:21:48] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:21:48] [marian] Running on node20.datos.cluster.uy as process 14444 with command line:
[2023-07-01 11:21:48] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 57 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:21:48] [config] after: 0e
[2023-07-01 11:21:48] [config] after-batches: 0
[2023-07-01 11:21:48] [config] after-epochs: 57
[2023-07-01 11:21:48] [config] all-caps-every: 0
[2023-07-01 11:21:48] [config] allow-unk: false
[2023-07-01 11:21:48] [config] authors: false
[2023-07-01 11:21:48] [config] beam-size: 12
[2023-07-01 11:21:48] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:21:48] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:21:48] [config] bert-masking-fraction: 0.15
[2023-07-01 11:21:48] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:21:48] [config] bert-train-type-embeddings: true
[2023-07-01 11:21:48] [config] bert-type-vocab-size: 2
[2023-07-01 11:21:48] [config] build-info: ""
[2023-07-01 11:21:48] [config] check-gradient-nan: false
[2023-07-01 11:21:48] [config] check-nan: false
[2023-07-01 11:21:48] [config] cite: false
[2023-07-01 11:21:48] [config] clip-norm: 5
[2023-07-01 11:21:48] [config] cost-scaling:
[2023-07-01 11:21:48] [config]   []
[2023-07-01 11:21:48] [config] cost-type: ce-sum
[2023-07-01 11:21:48] [config] cpu-threads: 0
[2023-07-01 11:21:48] [config] data-threads: 8
[2023-07-01 11:21:48] [config] data-weighting: ""
[2023-07-01 11:21:48] [config] data-weighting-type: sentence
[2023-07-01 11:21:48] [config] dec-cell: gru
[2023-07-01 11:21:48] [config] dec-cell-base-depth: 2
[2023-07-01 11:21:48] [config] dec-cell-high-depth: 1
[2023-07-01 11:21:48] [config] dec-depth: 2
[2023-07-01 11:21:48] [config] devices:
[2023-07-01 11:21:48] [config]   - 0
[2023-07-01 11:21:48] [config] dim-emb: 512
[2023-07-01 11:21:48] [config] dim-rnn: 1024
[2023-07-01 11:21:48] [config] dim-vocabs:
[2023-07-01 11:21:48] [config]   - 16384
[2023-07-01 11:21:48] [config]   - 16384
[2023-07-01 11:21:48] [config] disp-first: 0
[2023-07-01 11:21:48] [config] disp-freq: 1000u
[2023-07-01 11:21:48] [config] disp-label-counts: true
[2023-07-01 11:21:48] [config] dropout-rnn: 0
[2023-07-01 11:21:48] [config] dropout-src: 0
[2023-07-01 11:21:48] [config] dropout-trg: 0
[2023-07-01 11:21:48] [config] dump-config: ""
[2023-07-01 11:21:48] [config] dynamic-gradient-scaling:
[2023-07-01 11:21:48] [config]   []
[2023-07-01 11:21:48] [config] early-stopping: 10
[2023-07-01 11:21:48] [config] early-stopping-on: first
[2023-07-01 11:21:48] [config] embedding-fix-src: false
[2023-07-01 11:21:48] [config] embedding-fix-trg: false
[2023-07-01 11:21:48] [config] embedding-normalization: false
[2023-07-01 11:21:48] [config] embedding-vectors:
[2023-07-01 11:21:48] [config]   []
[2023-07-01 11:21:48] [config] enc-cell: gru
[2023-07-01 11:21:48] [config] enc-cell-depth: 1
[2023-07-01 11:21:48] [config] enc-depth: 2
[2023-07-01 11:21:48] [config] enc-type: bidirectional
[2023-07-01 11:21:48] [config] english-title-case-every: 0
[2023-07-01 11:21:48] [config] exponential-smoothing: 0.0001
[2023-07-01 11:21:48] [config] factor-weight: 1
[2023-07-01 11:21:48] [config] factors-combine: sum
[2023-07-01 11:21:48] [config] factors-dim-emb: 0
[2023-07-01 11:21:48] [config] gradient-checkpointing: false
[2023-07-01 11:21:48] [config] gradient-norm-average-window: 100
[2023-07-01 11:21:48] [config] guided-alignment: none
[2023-07-01 11:21:48] [config] guided-alignment-cost: mse
[2023-07-01 11:21:48] [config] guided-alignment-weight: 0.1
[2023-07-01 11:21:48] [config] ignore-model-config: false
[2023-07-01 11:21:48] [config] input-types:
[2023-07-01 11:21:48] [config]   []
[2023-07-01 11:21:48] [config] interpolate-env-vars: false
[2023-07-01 11:21:48] [config] keep-best: false
[2023-07-01 11:21:48] [config] label-smoothing: 0.1
[2023-07-01 11:21:48] [config] layer-normalization: false
[2023-07-01 11:21:48] [config] learn-rate: 0.0003
[2023-07-01 11:21:48] [config] lemma-dependency: ""
[2023-07-01 11:21:48] [config] lemma-dim-emb: 0
[2023-07-01 11:21:48] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:21:48] [config] log-level: info
[2023-07-01 11:21:48] [config] log-time-zone: ""
[2023-07-01 11:21:48] [config] logical-epoch:
[2023-07-01 11:21:48] [config]   - 1e
[2023-07-01 11:21:48] [config]   - 0
[2023-07-01 11:21:48] [config] lr-decay: 0
[2023-07-01 11:21:48] [config] lr-decay-freq: 50000
[2023-07-01 11:21:48] [config] lr-decay-inv-sqrt:
[2023-07-01 11:21:48] [config]   - 16000
[2023-07-01 11:21:48] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:21:48] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:21:48] [config] lr-decay-start:
[2023-07-01 11:21:48] [config]   - 10
[2023-07-01 11:21:48] [config]   - 1
[2023-07-01 11:21:48] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:21:48] [config] lr-report: true
[2023-07-01 11:21:48] [config] lr-warmup: 16000
[2023-07-01 11:21:48] [config] lr-warmup-at-reload: false
[2023-07-01 11:21:48] [config] lr-warmup-cycle: false
[2023-07-01 11:21:48] [config] lr-warmup-start-rate: 0
[2023-07-01 11:21:48] [config] max-length: 100
[2023-07-01 11:21:48] [config] max-length-crop: false
[2023-07-01 11:21:48] [config] max-length-factor: 3
[2023-07-01 11:21:48] [config] maxi-batch: 100
[2023-07-01 11:21:48] [config] maxi-batch-sort: trg
[2023-07-01 11:21:48] [config] mini-batch: 1000
[2023-07-01 11:21:48] [config] mini-batch-fit: true
[2023-07-01 11:21:48] [config] mini-batch-fit-step: 10
[2023-07-01 11:21:48] [config] mini-batch-round-up: true
[2023-07-01 11:21:48] [config] mini-batch-track-lr: false
[2023-07-01 11:21:48] [config] mini-batch-warmup: 0
[2023-07-01 11:21:48] [config] mini-batch-words: 0
[2023-07-01 11:21:48] [config] mini-batch-words-ref: 0
[2023-07-01 11:21:48] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:21:48] [config] multi-loss-type: sum
[2023-07-01 11:21:48] [config] n-best: false
[2023-07-01 11:21:48] [config] no-nccl: false
[2023-07-01 11:21:48] [config] no-reload: false
[2023-07-01 11:21:48] [config] no-restore-corpus: false
[2023-07-01 11:21:48] [config] normalize: 1
[2023-07-01 11:21:48] [config] normalize-gradient: false
[2023-07-01 11:21:48] [config] num-devices: 0
[2023-07-01 11:21:48] [config] optimizer: adam
[2023-07-01 11:21:48] [config] optimizer-delay: 1
[2023-07-01 11:21:48] [config] optimizer-params:
[2023-07-01 11:21:48] [config]   - 0.9
[2023-07-01 11:21:48] [config]   - 0.98
[2023-07-01 11:21:48] [config]   - 1e-09
[2023-07-01 11:21:48] [config] output-omit-bias: false
[2023-07-01 11:21:48] [config] overwrite: true
[2023-07-01 11:21:48] [config] precision:
[2023-07-01 11:21:48] [config]   - float32
[2023-07-01 11:21:48] [config]   - float32
[2023-07-01 11:21:48] [config] pretrained-model: ""
[2023-07-01 11:21:48] [config] quantize-biases: false
[2023-07-01 11:21:48] [config] quantize-bits: 0
[2023-07-01 11:21:48] [config] quantize-log-based: false
[2023-07-01 11:21:48] [config] quantize-optimization-steps: 0
[2023-07-01 11:21:48] [config] quiet: false
[2023-07-01 11:21:48] [config] quiet-translation: true
[2023-07-01 11:21:48] [config] relative-paths: false
[2023-07-01 11:21:48] [config] right-left: false
[2023-07-01 11:21:48] [config] save-freq: 10000u
[2023-07-01 11:21:48] [config] seed: 1234
[2023-07-01 11:21:48] [config] sentencepiece-alphas:
[2023-07-01 11:21:48] [config]   []
[2023-07-01 11:21:48] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:21:48] [config] sentencepiece-options: ""
[2023-07-01 11:21:48] [config] sharding: global
[2023-07-01 11:21:48] [config] shuffle: data
[2023-07-01 11:21:48] [config] shuffle-in-ram: false
[2023-07-01 11:21:48] [config] sigterm: save-and-exit
[2023-07-01 11:21:48] [config] skip: false
[2023-07-01 11:21:48] [config] sqlite: ""
[2023-07-01 11:21:48] [config] sqlite-drop: false
[2023-07-01 11:21:48] [config] sync-freq: 200u
[2023-07-01 11:21:48] [config] sync-sgd: true
[2023-07-01 11:21:48] [config] tempdir: /tmp
[2023-07-01 11:21:48] [config] tied-embeddings: false
[2023-07-01 11:21:48] [config] tied-embeddings-all: true
[2023-07-01 11:21:48] [config] tied-embeddings-src: false
[2023-07-01 11:21:48] [config] train-embedder-rank:
[2023-07-01 11:21:48] [config]   []
[2023-07-01 11:21:48] [config] train-sets:
[2023-07-01 11:21:48] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:21:48] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:21:48] [config] transformer-aan-activation: swish
[2023-07-01 11:21:48] [config] transformer-aan-depth: 2
[2023-07-01 11:21:48] [config] transformer-aan-nogate: false
[2023-07-01 11:21:48] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:21:48] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:21:48] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:21:48] [config] transformer-depth-scaling: false
[2023-07-01 11:21:48] [config] transformer-dim-aan: 2048
[2023-07-01 11:21:48] [config] transformer-dim-ffn: 2048
[2023-07-01 11:21:48] [config] transformer-dropout: 0.1
[2023-07-01 11:21:48] [config] transformer-dropout-attention: 0
[2023-07-01 11:21:48] [config] transformer-dropout-ffn: 0
[2023-07-01 11:21:48] [config] transformer-ffn-activation: swish
[2023-07-01 11:21:48] [config] transformer-ffn-depth: 2
[2023-07-01 11:21:48] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:21:48] [config] transformer-heads: 8
[2023-07-01 11:21:48] [config] transformer-no-projection: false
[2023-07-01 11:21:48] [config] transformer-pool: false
[2023-07-01 11:21:48] [config] transformer-postprocess: dan
[2023-07-01 11:21:48] [config] transformer-postprocess-emb: d
[2023-07-01 11:21:48] [config] transformer-postprocess-top: ""
[2023-07-01 11:21:48] [config] transformer-preprocess: ""
[2023-07-01 11:21:48] [config] transformer-tied-layers:
[2023-07-01 11:21:48] [config]   []
[2023-07-01 11:21:48] [config] transformer-train-position-embeddings: false
[2023-07-01 11:21:48] [config] tsv: false
[2023-07-01 11:21:48] [config] tsv-fields: 0
[2023-07-01 11:21:48] [config] type: transformer
[2023-07-01 11:21:48] [config] ulr: false
[2023-07-01 11:21:48] [config] ulr-dim-emb: 0
[2023-07-01 11:21:48] [config] ulr-dropout: 0
[2023-07-01 11:21:48] [config] ulr-keys-vectors: ""
[2023-07-01 11:21:48] [config] ulr-query-vectors: ""
[2023-07-01 11:21:48] [config] ulr-softmax-temperature: 1
[2023-07-01 11:21:48] [config] ulr-trainable-transformation: false
[2023-07-01 11:21:48] [config] unlikelihood-loss: false
[2023-07-01 11:21:48] [config] valid-freq: 50000000
[2023-07-01 11:21:48] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:21:48] [config] valid-max-length: 1000
[2023-07-01 11:21:48] [config] valid-metrics:
[2023-07-01 11:21:48] [config]   - cross-entropy
[2023-07-01 11:21:48] [config]   - translation
[2023-07-01 11:21:48] [config] valid-mini-batch: 64
[2023-07-01 11:21:48] [config] valid-reset-stalled: false
[2023-07-01 11:21:48] [config] valid-script-args:
[2023-07-01 11:21:48] [config]   []
[2023-07-01 11:21:48] [config] valid-script-path: ""
[2023-07-01 11:21:48] [config] valid-sets:
[2023-07-01 11:21:48] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:21:48] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:21:48] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:21:48] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:21:48] [config] vocabs:
[2023-07-01 11:21:48] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:21:48] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:21:48] [config] word-penalty: 0
[2023-07-01 11:21:48] [config] word-scores: false
[2023-07-01 11:21:48] [config] workspace: 2048
[2023-07-01 11:21:48] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:21:48] Using synchronous SGD
[2023-07-01 11:21:48] Synced seed 1234
[2023-07-01 11:21:48] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:21:48] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:21:48] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:21:48] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:21:48] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:21:48] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:21:49] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:21:49] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:21:49] [comm] Using global sharding
[2023-07-01 11:21:49] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:21:49] [training] Using 1 GPUs
[2023-07-01 11:21:49] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:21:49] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:21:49] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:21:49] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:21:57] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:21:57] [valid] No post-processing script given for validating translator
[2023-07-01 11:21:57] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:21:57] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:21:57] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:21:57] [comm] Using global sharding
[2023-07-01 11:21:57] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:21:57] [training] Using 1 GPUs
[2023-07-01 11:21:57] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:21:58] Allocating memory for general optimizer shards
[2023-07-01 11:21:58] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:21:58] Loading Adam parameters
[2023-07-01 11:21:58] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:21:58] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:21:58] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:21:58] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:21:58] [data] Shuffling data
[2023-07-01 11:21:58] [data] Done reading 20,192 sentences
[2023-07-01 11:21:58] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:21:58] Training started
[2023-07-01 11:21:58] Training finished
[2023-07-01 11:22:01] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:22:01] [marian] Running on node20.datos.cluster.uy as process 14502 with command line:
[2023-07-01 11:22:01] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 58 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:22:01] [config] after: 0e
[2023-07-01 11:22:01] [config] after-batches: 0
[2023-07-01 11:22:01] [config] after-epochs: 58
[2023-07-01 11:22:01] [config] all-caps-every: 0
[2023-07-01 11:22:01] [config] allow-unk: false
[2023-07-01 11:22:01] [config] authors: false
[2023-07-01 11:22:01] [config] beam-size: 12
[2023-07-01 11:22:01] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:22:01] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:22:01] [config] bert-masking-fraction: 0.15
[2023-07-01 11:22:01] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:22:01] [config] bert-train-type-embeddings: true
[2023-07-01 11:22:01] [config] bert-type-vocab-size: 2
[2023-07-01 11:22:01] [config] build-info: ""
[2023-07-01 11:22:01] [config] check-gradient-nan: false
[2023-07-01 11:22:01] [config] check-nan: false
[2023-07-01 11:22:01] [config] cite: false
[2023-07-01 11:22:01] [config] clip-norm: 5
[2023-07-01 11:22:01] [config] cost-scaling:
[2023-07-01 11:22:01] [config]   []
[2023-07-01 11:22:01] [config] cost-type: ce-sum
[2023-07-01 11:22:01] [config] cpu-threads: 0
[2023-07-01 11:22:01] [config] data-threads: 8
[2023-07-01 11:22:01] [config] data-weighting: ""
[2023-07-01 11:22:01] [config] data-weighting-type: sentence
[2023-07-01 11:22:01] [config] dec-cell: gru
[2023-07-01 11:22:01] [config] dec-cell-base-depth: 2
[2023-07-01 11:22:01] [config] dec-cell-high-depth: 1
[2023-07-01 11:22:01] [config] dec-depth: 2
[2023-07-01 11:22:01] [config] devices:
[2023-07-01 11:22:01] [config]   - 0
[2023-07-01 11:22:01] [config] dim-emb: 512
[2023-07-01 11:22:01] [config] dim-rnn: 1024
[2023-07-01 11:22:01] [config] dim-vocabs:
[2023-07-01 11:22:01] [config]   - 16384
[2023-07-01 11:22:01] [config]   - 16384
[2023-07-01 11:22:01] [config] disp-first: 0
[2023-07-01 11:22:01] [config] disp-freq: 1000u
[2023-07-01 11:22:01] [config] disp-label-counts: true
[2023-07-01 11:22:01] [config] dropout-rnn: 0
[2023-07-01 11:22:01] [config] dropout-src: 0
[2023-07-01 11:22:01] [config] dropout-trg: 0
[2023-07-01 11:22:01] [config] dump-config: ""
[2023-07-01 11:22:01] [config] dynamic-gradient-scaling:
[2023-07-01 11:22:01] [config]   []
[2023-07-01 11:22:01] [config] early-stopping: 10
[2023-07-01 11:22:01] [config] early-stopping-on: first
[2023-07-01 11:22:01] [config] embedding-fix-src: false
[2023-07-01 11:22:01] [config] embedding-fix-trg: false
[2023-07-01 11:22:01] [config] embedding-normalization: false
[2023-07-01 11:22:01] [config] embedding-vectors:
[2023-07-01 11:22:01] [config]   []
[2023-07-01 11:22:01] [config] enc-cell: gru
[2023-07-01 11:22:01] [config] enc-cell-depth: 1
[2023-07-01 11:22:01] [config] enc-depth: 2
[2023-07-01 11:22:01] [config] enc-type: bidirectional
[2023-07-01 11:22:01] [config] english-title-case-every: 0
[2023-07-01 11:22:01] [config] exponential-smoothing: 0.0001
[2023-07-01 11:22:01] [config] factor-weight: 1
[2023-07-01 11:22:01] [config] factors-combine: sum
[2023-07-01 11:22:01] [config] factors-dim-emb: 0
[2023-07-01 11:22:01] [config] gradient-checkpointing: false
[2023-07-01 11:22:01] [config] gradient-norm-average-window: 100
[2023-07-01 11:22:01] [config] guided-alignment: none
[2023-07-01 11:22:01] [config] guided-alignment-cost: mse
[2023-07-01 11:22:01] [config] guided-alignment-weight: 0.1
[2023-07-01 11:22:01] [config] ignore-model-config: false
[2023-07-01 11:22:01] [config] input-types:
[2023-07-01 11:22:01] [config]   []
[2023-07-01 11:22:01] [config] interpolate-env-vars: false
[2023-07-01 11:22:01] [config] keep-best: false
[2023-07-01 11:22:01] [config] label-smoothing: 0.1
[2023-07-01 11:22:01] [config] layer-normalization: false
[2023-07-01 11:22:01] [config] learn-rate: 0.0003
[2023-07-01 11:22:01] [config] lemma-dependency: ""
[2023-07-01 11:22:01] [config] lemma-dim-emb: 0
[2023-07-01 11:22:01] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:22:01] [config] log-level: info
[2023-07-01 11:22:01] [config] log-time-zone: ""
[2023-07-01 11:22:01] [config] logical-epoch:
[2023-07-01 11:22:01] [config]   - 1e
[2023-07-01 11:22:01] [config]   - 0
[2023-07-01 11:22:01] [config] lr-decay: 0
[2023-07-01 11:22:01] [config] lr-decay-freq: 50000
[2023-07-01 11:22:01] [config] lr-decay-inv-sqrt:
[2023-07-01 11:22:01] [config]   - 16000
[2023-07-01 11:22:01] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:22:01] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:22:01] [config] lr-decay-start:
[2023-07-01 11:22:01] [config]   - 10
[2023-07-01 11:22:01] [config]   - 1
[2023-07-01 11:22:01] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:22:01] [config] lr-report: true
[2023-07-01 11:22:01] [config] lr-warmup: 16000
[2023-07-01 11:22:01] [config] lr-warmup-at-reload: false
[2023-07-01 11:22:01] [config] lr-warmup-cycle: false
[2023-07-01 11:22:01] [config] lr-warmup-start-rate: 0
[2023-07-01 11:22:01] [config] max-length: 100
[2023-07-01 11:22:01] [config] max-length-crop: false
[2023-07-01 11:22:01] [config] max-length-factor: 3
[2023-07-01 11:22:01] [config] maxi-batch: 100
[2023-07-01 11:22:01] [config] maxi-batch-sort: trg
[2023-07-01 11:22:01] [config] mini-batch: 1000
[2023-07-01 11:22:01] [config] mini-batch-fit: true
[2023-07-01 11:22:01] [config] mini-batch-fit-step: 10
[2023-07-01 11:22:01] [config] mini-batch-round-up: true
[2023-07-01 11:22:01] [config] mini-batch-track-lr: false
[2023-07-01 11:22:01] [config] mini-batch-warmup: 0
[2023-07-01 11:22:01] [config] mini-batch-words: 0
[2023-07-01 11:22:01] [config] mini-batch-words-ref: 0
[2023-07-01 11:22:01] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:22:01] [config] multi-loss-type: sum
[2023-07-01 11:22:01] [config] n-best: false
[2023-07-01 11:22:01] [config] no-nccl: false
[2023-07-01 11:22:01] [config] no-reload: false
[2023-07-01 11:22:01] [config] no-restore-corpus: false
[2023-07-01 11:22:01] [config] normalize: 1
[2023-07-01 11:22:01] [config] normalize-gradient: false
[2023-07-01 11:22:01] [config] num-devices: 0
[2023-07-01 11:22:01] [config] optimizer: adam
[2023-07-01 11:22:01] [config] optimizer-delay: 1
[2023-07-01 11:22:01] [config] optimizer-params:
[2023-07-01 11:22:01] [config]   - 0.9
[2023-07-01 11:22:01] [config]   - 0.98
[2023-07-01 11:22:01] [config]   - 1e-09
[2023-07-01 11:22:01] [config] output-omit-bias: false
[2023-07-01 11:22:01] [config] overwrite: true
[2023-07-01 11:22:01] [config] precision:
[2023-07-01 11:22:01] [config]   - float32
[2023-07-01 11:22:01] [config]   - float32
[2023-07-01 11:22:01] [config] pretrained-model: ""
[2023-07-01 11:22:01] [config] quantize-biases: false
[2023-07-01 11:22:01] [config] quantize-bits: 0
[2023-07-01 11:22:01] [config] quantize-log-based: false
[2023-07-01 11:22:01] [config] quantize-optimization-steps: 0
[2023-07-01 11:22:01] [config] quiet: false
[2023-07-01 11:22:01] [config] quiet-translation: true
[2023-07-01 11:22:01] [config] relative-paths: false
[2023-07-01 11:22:01] [config] right-left: false
[2023-07-01 11:22:01] [config] save-freq: 10000u
[2023-07-01 11:22:01] [config] seed: 1234
[2023-07-01 11:22:01] [config] sentencepiece-alphas:
[2023-07-01 11:22:01] [config]   []
[2023-07-01 11:22:01] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:22:01] [config] sentencepiece-options: ""
[2023-07-01 11:22:01] [config] sharding: global
[2023-07-01 11:22:01] [config] shuffle: data
[2023-07-01 11:22:01] [config] shuffle-in-ram: false
[2023-07-01 11:22:01] [config] sigterm: save-and-exit
[2023-07-01 11:22:01] [config] skip: false
[2023-07-01 11:22:01] [config] sqlite: ""
[2023-07-01 11:22:01] [config] sqlite-drop: false
[2023-07-01 11:22:01] [config] sync-freq: 200u
[2023-07-01 11:22:01] [config] sync-sgd: true
[2023-07-01 11:22:01] [config] tempdir: /tmp
[2023-07-01 11:22:01] [config] tied-embeddings: false
[2023-07-01 11:22:01] [config] tied-embeddings-all: true
[2023-07-01 11:22:01] [config] tied-embeddings-src: false
[2023-07-01 11:22:01] [config] train-embedder-rank:
[2023-07-01 11:22:01] [config]   []
[2023-07-01 11:22:01] [config] train-sets:
[2023-07-01 11:22:01] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:22:01] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:22:01] [config] transformer-aan-activation: swish
[2023-07-01 11:22:01] [config] transformer-aan-depth: 2
[2023-07-01 11:22:01] [config] transformer-aan-nogate: false
[2023-07-01 11:22:01] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:22:01] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:22:01] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:22:01] [config] transformer-depth-scaling: false
[2023-07-01 11:22:01] [config] transformer-dim-aan: 2048
[2023-07-01 11:22:01] [config] transformer-dim-ffn: 2048
[2023-07-01 11:22:01] [config] transformer-dropout: 0.1
[2023-07-01 11:22:01] [config] transformer-dropout-attention: 0
[2023-07-01 11:22:01] [config] transformer-dropout-ffn: 0
[2023-07-01 11:22:01] [config] transformer-ffn-activation: swish
[2023-07-01 11:22:01] [config] transformer-ffn-depth: 2
[2023-07-01 11:22:01] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:22:01] [config] transformer-heads: 8
[2023-07-01 11:22:01] [config] transformer-no-projection: false
[2023-07-01 11:22:01] [config] transformer-pool: false
[2023-07-01 11:22:01] [config] transformer-postprocess: dan
[2023-07-01 11:22:01] [config] transformer-postprocess-emb: d
[2023-07-01 11:22:01] [config] transformer-postprocess-top: ""
[2023-07-01 11:22:01] [config] transformer-preprocess: ""
[2023-07-01 11:22:01] [config] transformer-tied-layers:
[2023-07-01 11:22:01] [config]   []
[2023-07-01 11:22:01] [config] transformer-train-position-embeddings: false
[2023-07-01 11:22:01] [config] tsv: false
[2023-07-01 11:22:01] [config] tsv-fields: 0
[2023-07-01 11:22:01] [config] type: transformer
[2023-07-01 11:22:01] [config] ulr: false
[2023-07-01 11:22:01] [config] ulr-dim-emb: 0
[2023-07-01 11:22:01] [config] ulr-dropout: 0
[2023-07-01 11:22:01] [config] ulr-keys-vectors: ""
[2023-07-01 11:22:01] [config] ulr-query-vectors: ""
[2023-07-01 11:22:01] [config] ulr-softmax-temperature: 1
[2023-07-01 11:22:01] [config] ulr-trainable-transformation: false
[2023-07-01 11:22:01] [config] unlikelihood-loss: false
[2023-07-01 11:22:01] [config] valid-freq: 50000000
[2023-07-01 11:22:01] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:22:01] [config] valid-max-length: 1000
[2023-07-01 11:22:01] [config] valid-metrics:
[2023-07-01 11:22:01] [config]   - cross-entropy
[2023-07-01 11:22:01] [config]   - translation
[2023-07-01 11:22:01] [config] valid-mini-batch: 64
[2023-07-01 11:22:01] [config] valid-reset-stalled: false
[2023-07-01 11:22:01] [config] valid-script-args:
[2023-07-01 11:22:01] [config]   []
[2023-07-01 11:22:01] [config] valid-script-path: ""
[2023-07-01 11:22:01] [config] valid-sets:
[2023-07-01 11:22:01] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:22:01] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:22:01] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:22:01] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:22:01] [config] vocabs:
[2023-07-01 11:22:01] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:22:01] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:22:01] [config] word-penalty: 0
[2023-07-01 11:22:01] [config] word-scores: false
[2023-07-01 11:22:01] [config] workspace: 2048
[2023-07-01 11:22:01] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:22:01] Using synchronous SGD
[2023-07-01 11:22:02] Synced seed 1234
[2023-07-01 11:22:02] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:22:02] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:22:02] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:22:02] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:22:02] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:22:02] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:22:03] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:22:03] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:22:03] [comm] Using global sharding
[2023-07-01 11:22:03] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:22:03] [training] Using 1 GPUs
[2023-07-01 11:22:03] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:22:03] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:22:03] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:22:03] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:22:10] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:22:11] [valid] No post-processing script given for validating translator
[2023-07-01 11:22:11] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:22:11] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:22:11] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:22:11] [comm] Using global sharding
[2023-07-01 11:22:11] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:22:11] [training] Using 1 GPUs
[2023-07-01 11:22:11] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:22:11] Allocating memory for general optimizer shards
[2023-07-01 11:22:11] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:22:11] Loading Adam parameters
[2023-07-01 11:22:11] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:22:11] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:22:11] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:22:11] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:22:11] [data] Shuffling data
[2023-07-01 11:22:11] [data] Done reading 20,192 sentences
[2023-07-01 11:22:11] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:22:11] Training started
[2023-07-01 11:22:11] Training finished
[2023-07-01 11:22:15] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:22:15] [marian] Running on node20.datos.cluster.uy as process 14563 with command line:
[2023-07-01 11:22:15] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 59 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:22:15] [config] after: 0e
[2023-07-01 11:22:15] [config] after-batches: 0
[2023-07-01 11:22:15] [config] after-epochs: 59
[2023-07-01 11:22:15] [config] all-caps-every: 0
[2023-07-01 11:22:15] [config] allow-unk: false
[2023-07-01 11:22:15] [config] authors: false
[2023-07-01 11:22:15] [config] beam-size: 12
[2023-07-01 11:22:15] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:22:15] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:22:15] [config] bert-masking-fraction: 0.15
[2023-07-01 11:22:15] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:22:15] [config] bert-train-type-embeddings: true
[2023-07-01 11:22:15] [config] bert-type-vocab-size: 2
[2023-07-01 11:22:15] [config] build-info: ""
[2023-07-01 11:22:15] [config] check-gradient-nan: false
[2023-07-01 11:22:15] [config] check-nan: false
[2023-07-01 11:22:15] [config] cite: false
[2023-07-01 11:22:15] [config] clip-norm: 5
[2023-07-01 11:22:15] [config] cost-scaling:
[2023-07-01 11:22:15] [config]   []
[2023-07-01 11:22:15] [config] cost-type: ce-sum
[2023-07-01 11:22:15] [config] cpu-threads: 0
[2023-07-01 11:22:15] [config] data-threads: 8
[2023-07-01 11:22:15] [config] data-weighting: ""
[2023-07-01 11:22:15] [config] data-weighting-type: sentence
[2023-07-01 11:22:15] [config] dec-cell: gru
[2023-07-01 11:22:15] [config] dec-cell-base-depth: 2
[2023-07-01 11:22:15] [config] dec-cell-high-depth: 1
[2023-07-01 11:22:15] [config] dec-depth: 2
[2023-07-01 11:22:15] [config] devices:
[2023-07-01 11:22:15] [config]   - 0
[2023-07-01 11:22:15] [config] dim-emb: 512
[2023-07-01 11:22:15] [config] dim-rnn: 1024
[2023-07-01 11:22:15] [config] dim-vocabs:
[2023-07-01 11:22:15] [config]   - 16384
[2023-07-01 11:22:15] [config]   - 16384
[2023-07-01 11:22:15] [config] disp-first: 0
[2023-07-01 11:22:15] [config] disp-freq: 1000u
[2023-07-01 11:22:15] [config] disp-label-counts: true
[2023-07-01 11:22:15] [config] dropout-rnn: 0
[2023-07-01 11:22:15] [config] dropout-src: 0
[2023-07-01 11:22:15] [config] dropout-trg: 0
[2023-07-01 11:22:15] [config] dump-config: ""
[2023-07-01 11:22:15] [config] dynamic-gradient-scaling:
[2023-07-01 11:22:15] [config]   []
[2023-07-01 11:22:15] [config] early-stopping: 10
[2023-07-01 11:22:15] [config] early-stopping-on: first
[2023-07-01 11:22:15] [config] embedding-fix-src: false
[2023-07-01 11:22:15] [config] embedding-fix-trg: false
[2023-07-01 11:22:15] [config] embedding-normalization: false
[2023-07-01 11:22:15] [config] embedding-vectors:
[2023-07-01 11:22:15] [config]   []
[2023-07-01 11:22:15] [config] enc-cell: gru
[2023-07-01 11:22:15] [config] enc-cell-depth: 1
[2023-07-01 11:22:15] [config] enc-depth: 2
[2023-07-01 11:22:15] [config] enc-type: bidirectional
[2023-07-01 11:22:15] [config] english-title-case-every: 0
[2023-07-01 11:22:15] [config] exponential-smoothing: 0.0001
[2023-07-01 11:22:15] [config] factor-weight: 1
[2023-07-01 11:22:15] [config] factors-combine: sum
[2023-07-01 11:22:15] [config] factors-dim-emb: 0
[2023-07-01 11:22:15] [config] gradient-checkpointing: false
[2023-07-01 11:22:15] [config] gradient-norm-average-window: 100
[2023-07-01 11:22:15] [config] guided-alignment: none
[2023-07-01 11:22:15] [config] guided-alignment-cost: mse
[2023-07-01 11:22:15] [config] guided-alignment-weight: 0.1
[2023-07-01 11:22:15] [config] ignore-model-config: false
[2023-07-01 11:22:15] [config] input-types:
[2023-07-01 11:22:15] [config]   []
[2023-07-01 11:22:15] [config] interpolate-env-vars: false
[2023-07-01 11:22:15] [config] keep-best: false
[2023-07-01 11:22:15] [config] label-smoothing: 0.1
[2023-07-01 11:22:15] [config] layer-normalization: false
[2023-07-01 11:22:15] [config] learn-rate: 0.0003
[2023-07-01 11:22:15] [config] lemma-dependency: ""
[2023-07-01 11:22:15] [config] lemma-dim-emb: 0
[2023-07-01 11:22:15] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:22:15] [config] log-level: info
[2023-07-01 11:22:15] [config] log-time-zone: ""
[2023-07-01 11:22:15] [config] logical-epoch:
[2023-07-01 11:22:15] [config]   - 1e
[2023-07-01 11:22:15] [config]   - 0
[2023-07-01 11:22:15] [config] lr-decay: 0
[2023-07-01 11:22:15] [config] lr-decay-freq: 50000
[2023-07-01 11:22:15] [config] lr-decay-inv-sqrt:
[2023-07-01 11:22:15] [config]   - 16000
[2023-07-01 11:22:15] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:22:15] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:22:15] [config] lr-decay-start:
[2023-07-01 11:22:15] [config]   - 10
[2023-07-01 11:22:15] [config]   - 1
[2023-07-01 11:22:15] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:22:15] [config] lr-report: true
[2023-07-01 11:22:15] [config] lr-warmup: 16000
[2023-07-01 11:22:15] [config] lr-warmup-at-reload: false
[2023-07-01 11:22:15] [config] lr-warmup-cycle: false
[2023-07-01 11:22:15] [config] lr-warmup-start-rate: 0
[2023-07-01 11:22:15] [config] max-length: 100
[2023-07-01 11:22:15] [config] max-length-crop: false
[2023-07-01 11:22:15] [config] max-length-factor: 3
[2023-07-01 11:22:15] [config] maxi-batch: 100
[2023-07-01 11:22:15] [config] maxi-batch-sort: trg
[2023-07-01 11:22:15] [config] mini-batch: 1000
[2023-07-01 11:22:15] [config] mini-batch-fit: true
[2023-07-01 11:22:15] [config] mini-batch-fit-step: 10
[2023-07-01 11:22:15] [config] mini-batch-round-up: true
[2023-07-01 11:22:15] [config] mini-batch-track-lr: false
[2023-07-01 11:22:15] [config] mini-batch-warmup: 0
[2023-07-01 11:22:15] [config] mini-batch-words: 0
[2023-07-01 11:22:15] [config] mini-batch-words-ref: 0
[2023-07-01 11:22:15] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:22:15] [config] multi-loss-type: sum
[2023-07-01 11:22:15] [config] n-best: false
[2023-07-01 11:22:15] [config] no-nccl: false
[2023-07-01 11:22:15] [config] no-reload: false
[2023-07-01 11:22:15] [config] no-restore-corpus: false
[2023-07-01 11:22:15] [config] normalize: 1
[2023-07-01 11:22:15] [config] normalize-gradient: false
[2023-07-01 11:22:15] [config] num-devices: 0
[2023-07-01 11:22:15] [config] optimizer: adam
[2023-07-01 11:22:15] [config] optimizer-delay: 1
[2023-07-01 11:22:15] [config] optimizer-params:
[2023-07-01 11:22:15] [config]   - 0.9
[2023-07-01 11:22:15] [config]   - 0.98
[2023-07-01 11:22:15] [config]   - 1e-09
[2023-07-01 11:22:15] [config] output-omit-bias: false
[2023-07-01 11:22:15] [config] overwrite: true
[2023-07-01 11:22:15] [config] precision:
[2023-07-01 11:22:15] [config]   - float32
[2023-07-01 11:22:15] [config]   - float32
[2023-07-01 11:22:15] [config] pretrained-model: ""
[2023-07-01 11:22:15] [config] quantize-biases: false
[2023-07-01 11:22:15] [config] quantize-bits: 0
[2023-07-01 11:22:15] [config] quantize-log-based: false
[2023-07-01 11:22:15] [config] quantize-optimization-steps: 0
[2023-07-01 11:22:15] [config] quiet: false
[2023-07-01 11:22:15] [config] quiet-translation: true
[2023-07-01 11:22:15] [config] relative-paths: false
[2023-07-01 11:22:15] [config] right-left: false
[2023-07-01 11:22:15] [config] save-freq: 10000u
[2023-07-01 11:22:15] [config] seed: 1234
[2023-07-01 11:22:15] [config] sentencepiece-alphas:
[2023-07-01 11:22:15] [config]   []
[2023-07-01 11:22:15] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:22:15] [config] sentencepiece-options: ""
[2023-07-01 11:22:15] [config] sharding: global
[2023-07-01 11:22:15] [config] shuffle: data
[2023-07-01 11:22:15] [config] shuffle-in-ram: false
[2023-07-01 11:22:15] [config] sigterm: save-and-exit
[2023-07-01 11:22:15] [config] skip: false
[2023-07-01 11:22:15] [config] sqlite: ""
[2023-07-01 11:22:15] [config] sqlite-drop: false
[2023-07-01 11:22:15] [config] sync-freq: 200u
[2023-07-01 11:22:15] [config] sync-sgd: true
[2023-07-01 11:22:15] [config] tempdir: /tmp
[2023-07-01 11:22:15] [config] tied-embeddings: false
[2023-07-01 11:22:15] [config] tied-embeddings-all: true
[2023-07-01 11:22:15] [config] tied-embeddings-src: false
[2023-07-01 11:22:15] [config] train-embedder-rank:
[2023-07-01 11:22:15] [config]   []
[2023-07-01 11:22:15] [config] train-sets:
[2023-07-01 11:22:15] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:22:15] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:22:15] [config] transformer-aan-activation: swish
[2023-07-01 11:22:15] [config] transformer-aan-depth: 2
[2023-07-01 11:22:15] [config] transformer-aan-nogate: false
[2023-07-01 11:22:15] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:22:15] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:22:15] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:22:15] [config] transformer-depth-scaling: false
[2023-07-01 11:22:15] [config] transformer-dim-aan: 2048
[2023-07-01 11:22:15] [config] transformer-dim-ffn: 2048
[2023-07-01 11:22:15] [config] transformer-dropout: 0.1
[2023-07-01 11:22:15] [config] transformer-dropout-attention: 0
[2023-07-01 11:22:15] [config] transformer-dropout-ffn: 0
[2023-07-01 11:22:15] [config] transformer-ffn-activation: swish
[2023-07-01 11:22:15] [config] transformer-ffn-depth: 2
[2023-07-01 11:22:15] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:22:15] [config] transformer-heads: 8
[2023-07-01 11:22:15] [config] transformer-no-projection: false
[2023-07-01 11:22:15] [config] transformer-pool: false
[2023-07-01 11:22:15] [config] transformer-postprocess: dan
[2023-07-01 11:22:15] [config] transformer-postprocess-emb: d
[2023-07-01 11:22:15] [config] transformer-postprocess-top: ""
[2023-07-01 11:22:15] [config] transformer-preprocess: ""
[2023-07-01 11:22:15] [config] transformer-tied-layers:
[2023-07-01 11:22:15] [config]   []
[2023-07-01 11:22:15] [config] transformer-train-position-embeddings: false
[2023-07-01 11:22:15] [config] tsv: false
[2023-07-01 11:22:15] [config] tsv-fields: 0
[2023-07-01 11:22:15] [config] type: transformer
[2023-07-01 11:22:15] [config] ulr: false
[2023-07-01 11:22:15] [config] ulr-dim-emb: 0
[2023-07-01 11:22:15] [config] ulr-dropout: 0
[2023-07-01 11:22:15] [config] ulr-keys-vectors: ""
[2023-07-01 11:22:15] [config] ulr-query-vectors: ""
[2023-07-01 11:22:15] [config] ulr-softmax-temperature: 1
[2023-07-01 11:22:15] [config] ulr-trainable-transformation: false
[2023-07-01 11:22:15] [config] unlikelihood-loss: false
[2023-07-01 11:22:15] [config] valid-freq: 50000000
[2023-07-01 11:22:15] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:22:15] [config] valid-max-length: 1000
[2023-07-01 11:22:15] [config] valid-metrics:
[2023-07-01 11:22:15] [config]   - cross-entropy
[2023-07-01 11:22:15] [config]   - translation
[2023-07-01 11:22:15] [config] valid-mini-batch: 64
[2023-07-01 11:22:15] [config] valid-reset-stalled: false
[2023-07-01 11:22:15] [config] valid-script-args:
[2023-07-01 11:22:15] [config]   []
[2023-07-01 11:22:15] [config] valid-script-path: ""
[2023-07-01 11:22:15] [config] valid-sets:
[2023-07-01 11:22:15] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:22:15] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:22:15] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:22:15] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:22:15] [config] vocabs:
[2023-07-01 11:22:15] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:22:15] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:22:15] [config] word-penalty: 0
[2023-07-01 11:22:15] [config] word-scores: false
[2023-07-01 11:22:15] [config] workspace: 2048
[2023-07-01 11:22:15] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:22:15] Using synchronous SGD
[2023-07-01 11:22:16] Synced seed 1234
[2023-07-01 11:22:16] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:22:16] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:22:16] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:22:16] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:22:16] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:22:16] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:22:16] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:22:17] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:22:17] [comm] Using global sharding
[2023-07-01 11:22:17] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:22:17] [training] Using 1 GPUs
[2023-07-01 11:22:17] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:22:17] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:22:17] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:22:17] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:22:24] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:22:24] [valid] No post-processing script given for validating translator
[2023-07-01 11:22:24] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:22:24] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:22:24] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:22:24] [comm] Using global sharding
[2023-07-01 11:22:25] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:22:25] [training] Using 1 GPUs
[2023-07-01 11:22:25] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:22:25] Allocating memory for general optimizer shards
[2023-07-01 11:22:25] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:22:25] Loading Adam parameters
[2023-07-01 11:22:25] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:22:25] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:22:25] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:22:25] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:22:25] [data] Shuffling data
[2023-07-01 11:22:25] [data] Done reading 20,192 sentences
[2023-07-01 11:22:25] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:22:25] Training started
[2023-07-01 11:22:25] Training finished
[2023-07-01 11:22:29] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:22:29] [marian] Running on node20.datos.cluster.uy as process 14624 with command line:
[2023-07-01 11:22:29] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 60 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:22:29] [config] after: 0e
[2023-07-01 11:22:29] [config] after-batches: 0
[2023-07-01 11:22:29] [config] after-epochs: 60
[2023-07-01 11:22:29] [config] all-caps-every: 0
[2023-07-01 11:22:29] [config] allow-unk: false
[2023-07-01 11:22:29] [config] authors: false
[2023-07-01 11:22:29] [config] beam-size: 12
[2023-07-01 11:22:29] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:22:29] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:22:29] [config] bert-masking-fraction: 0.15
[2023-07-01 11:22:29] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:22:29] [config] bert-train-type-embeddings: true
[2023-07-01 11:22:29] [config] bert-type-vocab-size: 2
[2023-07-01 11:22:29] [config] build-info: ""
[2023-07-01 11:22:29] [config] check-gradient-nan: false
[2023-07-01 11:22:29] [config] check-nan: false
[2023-07-01 11:22:29] [config] cite: false
[2023-07-01 11:22:29] [config] clip-norm: 5
[2023-07-01 11:22:29] [config] cost-scaling:
[2023-07-01 11:22:29] [config]   []
[2023-07-01 11:22:29] [config] cost-type: ce-sum
[2023-07-01 11:22:29] [config] cpu-threads: 0
[2023-07-01 11:22:29] [config] data-threads: 8
[2023-07-01 11:22:29] [config] data-weighting: ""
[2023-07-01 11:22:29] [config] data-weighting-type: sentence
[2023-07-01 11:22:29] [config] dec-cell: gru
[2023-07-01 11:22:29] [config] dec-cell-base-depth: 2
[2023-07-01 11:22:29] [config] dec-cell-high-depth: 1
[2023-07-01 11:22:29] [config] dec-depth: 2
[2023-07-01 11:22:29] [config] devices:
[2023-07-01 11:22:29] [config]   - 0
[2023-07-01 11:22:29] [config] dim-emb: 512
[2023-07-01 11:22:29] [config] dim-rnn: 1024
[2023-07-01 11:22:29] [config] dim-vocabs:
[2023-07-01 11:22:29] [config]   - 16384
[2023-07-01 11:22:29] [config]   - 16384
[2023-07-01 11:22:29] [config] disp-first: 0
[2023-07-01 11:22:29] [config] disp-freq: 1000u
[2023-07-01 11:22:29] [config] disp-label-counts: true
[2023-07-01 11:22:29] [config] dropout-rnn: 0
[2023-07-01 11:22:29] [config] dropout-src: 0
[2023-07-01 11:22:29] [config] dropout-trg: 0
[2023-07-01 11:22:29] [config] dump-config: ""
[2023-07-01 11:22:29] [config] dynamic-gradient-scaling:
[2023-07-01 11:22:29] [config]   []
[2023-07-01 11:22:29] [config] early-stopping: 10
[2023-07-01 11:22:29] [config] early-stopping-on: first
[2023-07-01 11:22:29] [config] embedding-fix-src: false
[2023-07-01 11:22:29] [config] embedding-fix-trg: false
[2023-07-01 11:22:29] [config] embedding-normalization: false
[2023-07-01 11:22:29] [config] embedding-vectors:
[2023-07-01 11:22:29] [config]   []
[2023-07-01 11:22:29] [config] enc-cell: gru
[2023-07-01 11:22:29] [config] enc-cell-depth: 1
[2023-07-01 11:22:29] [config] enc-depth: 2
[2023-07-01 11:22:29] [config] enc-type: bidirectional
[2023-07-01 11:22:29] [config] english-title-case-every: 0
[2023-07-01 11:22:29] [config] exponential-smoothing: 0.0001
[2023-07-01 11:22:29] [config] factor-weight: 1
[2023-07-01 11:22:29] [config] factors-combine: sum
[2023-07-01 11:22:29] [config] factors-dim-emb: 0
[2023-07-01 11:22:29] [config] gradient-checkpointing: false
[2023-07-01 11:22:29] [config] gradient-norm-average-window: 100
[2023-07-01 11:22:29] [config] guided-alignment: none
[2023-07-01 11:22:29] [config] guided-alignment-cost: mse
[2023-07-01 11:22:29] [config] guided-alignment-weight: 0.1
[2023-07-01 11:22:29] [config] ignore-model-config: false
[2023-07-01 11:22:29] [config] input-types:
[2023-07-01 11:22:29] [config]   []
[2023-07-01 11:22:29] [config] interpolate-env-vars: false
[2023-07-01 11:22:29] [config] keep-best: false
[2023-07-01 11:22:29] [config] label-smoothing: 0.1
[2023-07-01 11:22:29] [config] layer-normalization: false
[2023-07-01 11:22:29] [config] learn-rate: 0.0003
[2023-07-01 11:22:29] [config] lemma-dependency: ""
[2023-07-01 11:22:29] [config] lemma-dim-emb: 0
[2023-07-01 11:22:29] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:22:29] [config] log-level: info
[2023-07-01 11:22:29] [config] log-time-zone: ""
[2023-07-01 11:22:29] [config] logical-epoch:
[2023-07-01 11:22:29] [config]   - 1e
[2023-07-01 11:22:29] [config]   - 0
[2023-07-01 11:22:29] [config] lr-decay: 0
[2023-07-01 11:22:29] [config] lr-decay-freq: 50000
[2023-07-01 11:22:29] [config] lr-decay-inv-sqrt:
[2023-07-01 11:22:29] [config]   - 16000
[2023-07-01 11:22:29] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:22:29] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:22:29] [config] lr-decay-start:
[2023-07-01 11:22:29] [config]   - 10
[2023-07-01 11:22:29] [config]   - 1
[2023-07-01 11:22:29] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:22:29] [config] lr-report: true
[2023-07-01 11:22:29] [config] lr-warmup: 16000
[2023-07-01 11:22:29] [config] lr-warmup-at-reload: false
[2023-07-01 11:22:29] [config] lr-warmup-cycle: false
[2023-07-01 11:22:29] [config] lr-warmup-start-rate: 0
[2023-07-01 11:22:29] [config] max-length: 100
[2023-07-01 11:22:29] [config] max-length-crop: false
[2023-07-01 11:22:29] [config] max-length-factor: 3
[2023-07-01 11:22:29] [config] maxi-batch: 100
[2023-07-01 11:22:29] [config] maxi-batch-sort: trg
[2023-07-01 11:22:29] [config] mini-batch: 1000
[2023-07-01 11:22:29] [config] mini-batch-fit: true
[2023-07-01 11:22:29] [config] mini-batch-fit-step: 10
[2023-07-01 11:22:29] [config] mini-batch-round-up: true
[2023-07-01 11:22:29] [config] mini-batch-track-lr: false
[2023-07-01 11:22:29] [config] mini-batch-warmup: 0
[2023-07-01 11:22:29] [config] mini-batch-words: 0
[2023-07-01 11:22:29] [config] mini-batch-words-ref: 0
[2023-07-01 11:22:29] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:22:29] [config] multi-loss-type: sum
[2023-07-01 11:22:29] [config] n-best: false
[2023-07-01 11:22:29] [config] no-nccl: false
[2023-07-01 11:22:29] [config] no-reload: false
[2023-07-01 11:22:29] [config] no-restore-corpus: false
[2023-07-01 11:22:29] [config] normalize: 1
[2023-07-01 11:22:29] [config] normalize-gradient: false
[2023-07-01 11:22:29] [config] num-devices: 0
[2023-07-01 11:22:29] [config] optimizer: adam
[2023-07-01 11:22:29] [config] optimizer-delay: 1
[2023-07-01 11:22:29] [config] optimizer-params:
[2023-07-01 11:22:29] [config]   - 0.9
[2023-07-01 11:22:29] [config]   - 0.98
[2023-07-01 11:22:29] [config]   - 1e-09
[2023-07-01 11:22:29] [config] output-omit-bias: false
[2023-07-01 11:22:29] [config] overwrite: true
[2023-07-01 11:22:29] [config] precision:
[2023-07-01 11:22:29] [config]   - float32
[2023-07-01 11:22:29] [config]   - float32
[2023-07-01 11:22:29] [config] pretrained-model: ""
[2023-07-01 11:22:29] [config] quantize-biases: false
[2023-07-01 11:22:29] [config] quantize-bits: 0
[2023-07-01 11:22:29] [config] quantize-log-based: false
[2023-07-01 11:22:29] [config] quantize-optimization-steps: 0
[2023-07-01 11:22:29] [config] quiet: false
[2023-07-01 11:22:29] [config] quiet-translation: true
[2023-07-01 11:22:29] [config] relative-paths: false
[2023-07-01 11:22:29] [config] right-left: false
[2023-07-01 11:22:29] [config] save-freq: 10000u
[2023-07-01 11:22:29] [config] seed: 1234
[2023-07-01 11:22:29] [config] sentencepiece-alphas:
[2023-07-01 11:22:29] [config]   []
[2023-07-01 11:22:29] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:22:29] [config] sentencepiece-options: ""
[2023-07-01 11:22:29] [config] sharding: global
[2023-07-01 11:22:29] [config] shuffle: data
[2023-07-01 11:22:29] [config] shuffle-in-ram: false
[2023-07-01 11:22:29] [config] sigterm: save-and-exit
[2023-07-01 11:22:29] [config] skip: false
[2023-07-01 11:22:29] [config] sqlite: ""
[2023-07-01 11:22:29] [config] sqlite-drop: false
[2023-07-01 11:22:29] [config] sync-freq: 200u
[2023-07-01 11:22:29] [config] sync-sgd: true
[2023-07-01 11:22:29] [config] tempdir: /tmp
[2023-07-01 11:22:29] [config] tied-embeddings: false
[2023-07-01 11:22:29] [config] tied-embeddings-all: true
[2023-07-01 11:22:29] [config] tied-embeddings-src: false
[2023-07-01 11:22:29] [config] train-embedder-rank:
[2023-07-01 11:22:29] [config]   []
[2023-07-01 11:22:29] [config] train-sets:
[2023-07-01 11:22:29] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:22:29] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:22:29] [config] transformer-aan-activation: swish
[2023-07-01 11:22:29] [config] transformer-aan-depth: 2
[2023-07-01 11:22:29] [config] transformer-aan-nogate: false
[2023-07-01 11:22:29] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:22:29] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:22:29] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:22:29] [config] transformer-depth-scaling: false
[2023-07-01 11:22:29] [config] transformer-dim-aan: 2048
[2023-07-01 11:22:29] [config] transformer-dim-ffn: 2048
[2023-07-01 11:22:29] [config] transformer-dropout: 0.1
[2023-07-01 11:22:29] [config] transformer-dropout-attention: 0
[2023-07-01 11:22:29] [config] transformer-dropout-ffn: 0
[2023-07-01 11:22:29] [config] transformer-ffn-activation: swish
[2023-07-01 11:22:29] [config] transformer-ffn-depth: 2
[2023-07-01 11:22:29] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:22:29] [config] transformer-heads: 8
[2023-07-01 11:22:29] [config] transformer-no-projection: false
[2023-07-01 11:22:29] [config] transformer-pool: false
[2023-07-01 11:22:29] [config] transformer-postprocess: dan
[2023-07-01 11:22:29] [config] transformer-postprocess-emb: d
[2023-07-01 11:22:29] [config] transformer-postprocess-top: ""
[2023-07-01 11:22:29] [config] transformer-preprocess: ""
[2023-07-01 11:22:29] [config] transformer-tied-layers:
[2023-07-01 11:22:29] [config]   []
[2023-07-01 11:22:29] [config] transformer-train-position-embeddings: false
[2023-07-01 11:22:29] [config] tsv: false
[2023-07-01 11:22:29] [config] tsv-fields: 0
[2023-07-01 11:22:29] [config] type: transformer
[2023-07-01 11:22:29] [config] ulr: false
[2023-07-01 11:22:29] [config] ulr-dim-emb: 0
[2023-07-01 11:22:29] [config] ulr-dropout: 0
[2023-07-01 11:22:29] [config] ulr-keys-vectors: ""
[2023-07-01 11:22:29] [config] ulr-query-vectors: ""
[2023-07-01 11:22:29] [config] ulr-softmax-temperature: 1
[2023-07-01 11:22:29] [config] ulr-trainable-transformation: false
[2023-07-01 11:22:29] [config] unlikelihood-loss: false
[2023-07-01 11:22:29] [config] valid-freq: 50000000
[2023-07-01 11:22:29] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:22:29] [config] valid-max-length: 1000
[2023-07-01 11:22:29] [config] valid-metrics:
[2023-07-01 11:22:29] [config]   - cross-entropy
[2023-07-01 11:22:29] [config]   - translation
[2023-07-01 11:22:29] [config] valid-mini-batch: 64
[2023-07-01 11:22:29] [config] valid-reset-stalled: false
[2023-07-01 11:22:29] [config] valid-script-args:
[2023-07-01 11:22:29] [config]   []
[2023-07-01 11:22:29] [config] valid-script-path: ""
[2023-07-01 11:22:29] [config] valid-sets:
[2023-07-01 11:22:29] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:22:29] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:22:29] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:22:29] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:22:29] [config] vocabs:
[2023-07-01 11:22:29] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:22:29] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:22:29] [config] word-penalty: 0
[2023-07-01 11:22:29] [config] word-scores: false
[2023-07-01 11:22:29] [config] workspace: 2048
[2023-07-01 11:22:29] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:22:29] Using synchronous SGD
[2023-07-01 11:22:30] Synced seed 1234
[2023-07-01 11:22:30] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:22:30] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:22:30] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:22:30] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:22:30] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:22:30] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:22:30] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:22:31] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:22:31] [comm] Using global sharding
[2023-07-01 11:22:31] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:22:31] [training] Using 1 GPUs
[2023-07-01 11:22:31] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:22:31] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:22:31] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:22:31] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:22:38] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:22:38] [valid] No post-processing script given for validating translator
[2023-07-01 11:22:38] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:22:38] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:22:38] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:22:38] [comm] Using global sharding
[2023-07-01 11:22:39] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:22:39] [training] Using 1 GPUs
[2023-07-01 11:22:39] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:22:39] Allocating memory for general optimizer shards
[2023-07-01 11:22:39] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:22:39] Loading Adam parameters
[2023-07-01 11:22:39] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:22:39] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:22:39] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:22:39] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:22:39] [data] Shuffling data
[2023-07-01 11:22:39] [data] Done reading 20,192 sentences
[2023-07-01 11:22:39] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:22:39] Training started
[2023-07-01 11:22:39] Training finished
[2023-07-01 11:22:43] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:22:43] [marian] Running on node20.datos.cluster.uy as process 14682 with command line:
[2023-07-01 11:22:43] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 61 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:22:43] [config] after: 0e
[2023-07-01 11:22:43] [config] after-batches: 0
[2023-07-01 11:22:43] [config] after-epochs: 61
[2023-07-01 11:22:43] [config] all-caps-every: 0
[2023-07-01 11:22:43] [config] allow-unk: false
[2023-07-01 11:22:43] [config] authors: false
[2023-07-01 11:22:43] [config] beam-size: 12
[2023-07-01 11:22:43] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:22:43] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:22:43] [config] bert-masking-fraction: 0.15
[2023-07-01 11:22:43] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:22:43] [config] bert-train-type-embeddings: true
[2023-07-01 11:22:43] [config] bert-type-vocab-size: 2
[2023-07-01 11:22:43] [config] build-info: ""
[2023-07-01 11:22:43] [config] check-gradient-nan: false
[2023-07-01 11:22:43] [config] check-nan: false
[2023-07-01 11:22:43] [config] cite: false
[2023-07-01 11:22:43] [config] clip-norm: 5
[2023-07-01 11:22:43] [config] cost-scaling:
[2023-07-01 11:22:43] [config]   []
[2023-07-01 11:22:43] [config] cost-type: ce-sum
[2023-07-01 11:22:43] [config] cpu-threads: 0
[2023-07-01 11:22:43] [config] data-threads: 8
[2023-07-01 11:22:43] [config] data-weighting: ""
[2023-07-01 11:22:43] [config] data-weighting-type: sentence
[2023-07-01 11:22:43] [config] dec-cell: gru
[2023-07-01 11:22:43] [config] dec-cell-base-depth: 2
[2023-07-01 11:22:43] [config] dec-cell-high-depth: 1
[2023-07-01 11:22:43] [config] dec-depth: 2
[2023-07-01 11:22:43] [config] devices:
[2023-07-01 11:22:43] [config]   - 0
[2023-07-01 11:22:43] [config] dim-emb: 512
[2023-07-01 11:22:43] [config] dim-rnn: 1024
[2023-07-01 11:22:43] [config] dim-vocabs:
[2023-07-01 11:22:43] [config]   - 16384
[2023-07-01 11:22:43] [config]   - 16384
[2023-07-01 11:22:43] [config] disp-first: 0
[2023-07-01 11:22:43] [config] disp-freq: 1000u
[2023-07-01 11:22:43] [config] disp-label-counts: true
[2023-07-01 11:22:43] [config] dropout-rnn: 0
[2023-07-01 11:22:43] [config] dropout-src: 0
[2023-07-01 11:22:43] [config] dropout-trg: 0
[2023-07-01 11:22:43] [config] dump-config: ""
[2023-07-01 11:22:43] [config] dynamic-gradient-scaling:
[2023-07-01 11:22:43] [config]   []
[2023-07-01 11:22:43] [config] early-stopping: 10
[2023-07-01 11:22:43] [config] early-stopping-on: first
[2023-07-01 11:22:43] [config] embedding-fix-src: false
[2023-07-01 11:22:43] [config] embedding-fix-trg: false
[2023-07-01 11:22:43] [config] embedding-normalization: false
[2023-07-01 11:22:43] [config] embedding-vectors:
[2023-07-01 11:22:43] [config]   []
[2023-07-01 11:22:43] [config] enc-cell: gru
[2023-07-01 11:22:43] [config] enc-cell-depth: 1
[2023-07-01 11:22:43] [config] enc-depth: 2
[2023-07-01 11:22:43] [config] enc-type: bidirectional
[2023-07-01 11:22:43] [config] english-title-case-every: 0
[2023-07-01 11:22:43] [config] exponential-smoothing: 0.0001
[2023-07-01 11:22:43] [config] factor-weight: 1
[2023-07-01 11:22:43] [config] factors-combine: sum
[2023-07-01 11:22:43] [config] factors-dim-emb: 0
[2023-07-01 11:22:43] [config] gradient-checkpointing: false
[2023-07-01 11:22:43] [config] gradient-norm-average-window: 100
[2023-07-01 11:22:43] [config] guided-alignment: none
[2023-07-01 11:22:43] [config] guided-alignment-cost: mse
[2023-07-01 11:22:43] [config] guided-alignment-weight: 0.1
[2023-07-01 11:22:43] [config] ignore-model-config: false
[2023-07-01 11:22:43] [config] input-types:
[2023-07-01 11:22:43] [config]   []
[2023-07-01 11:22:43] [config] interpolate-env-vars: false
[2023-07-01 11:22:43] [config] keep-best: false
[2023-07-01 11:22:43] [config] label-smoothing: 0.1
[2023-07-01 11:22:43] [config] layer-normalization: false
[2023-07-01 11:22:43] [config] learn-rate: 0.0003
[2023-07-01 11:22:43] [config] lemma-dependency: ""
[2023-07-01 11:22:43] [config] lemma-dim-emb: 0
[2023-07-01 11:22:43] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:22:43] [config] log-level: info
[2023-07-01 11:22:43] [config] log-time-zone: ""
[2023-07-01 11:22:43] [config] logical-epoch:
[2023-07-01 11:22:43] [config]   - 1e
[2023-07-01 11:22:43] [config]   - 0
[2023-07-01 11:22:43] [config] lr-decay: 0
[2023-07-01 11:22:43] [config] lr-decay-freq: 50000
[2023-07-01 11:22:43] [config] lr-decay-inv-sqrt:
[2023-07-01 11:22:43] [config]   - 16000
[2023-07-01 11:22:43] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:22:43] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:22:43] [config] lr-decay-start:
[2023-07-01 11:22:43] [config]   - 10
[2023-07-01 11:22:43] [config]   - 1
[2023-07-01 11:22:43] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:22:43] [config] lr-report: true
[2023-07-01 11:22:43] [config] lr-warmup: 16000
[2023-07-01 11:22:43] [config] lr-warmup-at-reload: false
[2023-07-01 11:22:43] [config] lr-warmup-cycle: false
[2023-07-01 11:22:43] [config] lr-warmup-start-rate: 0
[2023-07-01 11:22:43] [config] max-length: 100
[2023-07-01 11:22:43] [config] max-length-crop: false
[2023-07-01 11:22:43] [config] max-length-factor: 3
[2023-07-01 11:22:43] [config] maxi-batch: 100
[2023-07-01 11:22:43] [config] maxi-batch-sort: trg
[2023-07-01 11:22:43] [config] mini-batch: 1000
[2023-07-01 11:22:43] [config] mini-batch-fit: true
[2023-07-01 11:22:43] [config] mini-batch-fit-step: 10
[2023-07-01 11:22:43] [config] mini-batch-round-up: true
[2023-07-01 11:22:43] [config] mini-batch-track-lr: false
[2023-07-01 11:22:43] [config] mini-batch-warmup: 0
[2023-07-01 11:22:43] [config] mini-batch-words: 0
[2023-07-01 11:22:43] [config] mini-batch-words-ref: 0
[2023-07-01 11:22:43] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:22:43] [config] multi-loss-type: sum
[2023-07-01 11:22:43] [config] n-best: false
[2023-07-01 11:22:43] [config] no-nccl: false
[2023-07-01 11:22:43] [config] no-reload: false
[2023-07-01 11:22:43] [config] no-restore-corpus: false
[2023-07-01 11:22:43] [config] normalize: 1
[2023-07-01 11:22:43] [config] normalize-gradient: false
[2023-07-01 11:22:43] [config] num-devices: 0
[2023-07-01 11:22:43] [config] optimizer: adam
[2023-07-01 11:22:43] [config] optimizer-delay: 1
[2023-07-01 11:22:43] [config] optimizer-params:
[2023-07-01 11:22:43] [config]   - 0.9
[2023-07-01 11:22:43] [config]   - 0.98
[2023-07-01 11:22:43] [config]   - 1e-09
[2023-07-01 11:22:43] [config] output-omit-bias: false
[2023-07-01 11:22:43] [config] overwrite: true
[2023-07-01 11:22:43] [config] precision:
[2023-07-01 11:22:43] [config]   - float32
[2023-07-01 11:22:43] [config]   - float32
[2023-07-01 11:22:43] [config] pretrained-model: ""
[2023-07-01 11:22:43] [config] quantize-biases: false
[2023-07-01 11:22:43] [config] quantize-bits: 0
[2023-07-01 11:22:43] [config] quantize-log-based: false
[2023-07-01 11:22:43] [config] quantize-optimization-steps: 0
[2023-07-01 11:22:43] [config] quiet: false
[2023-07-01 11:22:43] [config] quiet-translation: true
[2023-07-01 11:22:43] [config] relative-paths: false
[2023-07-01 11:22:43] [config] right-left: false
[2023-07-01 11:22:43] [config] save-freq: 10000u
[2023-07-01 11:22:43] [config] seed: 1234
[2023-07-01 11:22:43] [config] sentencepiece-alphas:
[2023-07-01 11:22:43] [config]   []
[2023-07-01 11:22:43] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:22:43] [config] sentencepiece-options: ""
[2023-07-01 11:22:43] [config] sharding: global
[2023-07-01 11:22:43] [config] shuffle: data
[2023-07-01 11:22:43] [config] shuffle-in-ram: false
[2023-07-01 11:22:43] [config] sigterm: save-and-exit
[2023-07-01 11:22:43] [config] skip: false
[2023-07-01 11:22:43] [config] sqlite: ""
[2023-07-01 11:22:43] [config] sqlite-drop: false
[2023-07-01 11:22:43] [config] sync-freq: 200u
[2023-07-01 11:22:43] [config] sync-sgd: true
[2023-07-01 11:22:43] [config] tempdir: /tmp
[2023-07-01 11:22:43] [config] tied-embeddings: false
[2023-07-01 11:22:43] [config] tied-embeddings-all: true
[2023-07-01 11:22:43] [config] tied-embeddings-src: false
[2023-07-01 11:22:43] [config] train-embedder-rank:
[2023-07-01 11:22:43] [config]   []
[2023-07-01 11:22:43] [config] train-sets:
[2023-07-01 11:22:43] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:22:43] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:22:43] [config] transformer-aan-activation: swish
[2023-07-01 11:22:43] [config] transformer-aan-depth: 2
[2023-07-01 11:22:43] [config] transformer-aan-nogate: false
[2023-07-01 11:22:43] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:22:43] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:22:43] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:22:43] [config] transformer-depth-scaling: false
[2023-07-01 11:22:43] [config] transformer-dim-aan: 2048
[2023-07-01 11:22:43] [config] transformer-dim-ffn: 2048
[2023-07-01 11:22:43] [config] transformer-dropout: 0.1
[2023-07-01 11:22:43] [config] transformer-dropout-attention: 0
[2023-07-01 11:22:43] [config] transformer-dropout-ffn: 0
[2023-07-01 11:22:43] [config] transformer-ffn-activation: swish
[2023-07-01 11:22:43] [config] transformer-ffn-depth: 2
[2023-07-01 11:22:43] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:22:43] [config] transformer-heads: 8
[2023-07-01 11:22:43] [config] transformer-no-projection: false
[2023-07-01 11:22:43] [config] transformer-pool: false
[2023-07-01 11:22:43] [config] transformer-postprocess: dan
[2023-07-01 11:22:43] [config] transformer-postprocess-emb: d
[2023-07-01 11:22:43] [config] transformer-postprocess-top: ""
[2023-07-01 11:22:43] [config] transformer-preprocess: ""
[2023-07-01 11:22:43] [config] transformer-tied-layers:
[2023-07-01 11:22:43] [config]   []
[2023-07-01 11:22:43] [config] transformer-train-position-embeddings: false
[2023-07-01 11:22:43] [config] tsv: false
[2023-07-01 11:22:43] [config] tsv-fields: 0
[2023-07-01 11:22:43] [config] type: transformer
[2023-07-01 11:22:43] [config] ulr: false
[2023-07-01 11:22:43] [config] ulr-dim-emb: 0
[2023-07-01 11:22:43] [config] ulr-dropout: 0
[2023-07-01 11:22:43] [config] ulr-keys-vectors: ""
[2023-07-01 11:22:43] [config] ulr-query-vectors: ""
[2023-07-01 11:22:43] [config] ulr-softmax-temperature: 1
[2023-07-01 11:22:43] [config] ulr-trainable-transformation: false
[2023-07-01 11:22:43] [config] unlikelihood-loss: false
[2023-07-01 11:22:43] [config] valid-freq: 50000000
[2023-07-01 11:22:43] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:22:43] [config] valid-max-length: 1000
[2023-07-01 11:22:43] [config] valid-metrics:
[2023-07-01 11:22:43] [config]   - cross-entropy
[2023-07-01 11:22:43] [config]   - translation
[2023-07-01 11:22:43] [config] valid-mini-batch: 64
[2023-07-01 11:22:43] [config] valid-reset-stalled: false
[2023-07-01 11:22:43] [config] valid-script-args:
[2023-07-01 11:22:43] [config]   []
[2023-07-01 11:22:43] [config] valid-script-path: ""
[2023-07-01 11:22:43] [config] valid-sets:
[2023-07-01 11:22:43] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:22:43] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:22:43] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:22:43] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:22:43] [config] vocabs:
[2023-07-01 11:22:43] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:22:43] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:22:43] [config] word-penalty: 0
[2023-07-01 11:22:43] [config] word-scores: false
[2023-07-01 11:22:43] [config] workspace: 2048
[2023-07-01 11:22:43] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:22:43] Using synchronous SGD
[2023-07-01 11:22:43] Synced seed 1234
[2023-07-01 11:22:43] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:22:43] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:22:43] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:22:43] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:22:43] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:22:43] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:22:44] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:22:44] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:22:44] [comm] Using global sharding
[2023-07-01 11:22:44] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:22:44] [training] Using 1 GPUs
[2023-07-01 11:22:44] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:22:44] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:22:44] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:22:44] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:22:52] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:22:52] [valid] No post-processing script given for validating translator
[2023-07-01 11:22:52] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:22:52] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:22:52] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:22:52] [comm] Using global sharding
[2023-07-01 11:22:52] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:22:52] [training] Using 1 GPUs
[2023-07-01 11:22:52] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:22:52] Allocating memory for general optimizer shards
[2023-07-01 11:22:52] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:22:53] Loading Adam parameters
[2023-07-01 11:22:53] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:22:53] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:22:53] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:22:53] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:22:53] [data] Shuffling data
[2023-07-01 11:22:53] [data] Done reading 20,192 sentences
[2023-07-01 11:22:53] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:22:53] Training started
[2023-07-01 11:22:53] Training finished
[2023-07-01 11:22:56] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:22:56] [marian] Running on node20.datos.cluster.uy as process 14739 with command line:
[2023-07-01 11:22:56] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 62 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:22:56] [config] after: 0e
[2023-07-01 11:22:56] [config] after-batches: 0
[2023-07-01 11:22:56] [config] after-epochs: 62
[2023-07-01 11:22:56] [config] all-caps-every: 0
[2023-07-01 11:22:56] [config] allow-unk: false
[2023-07-01 11:22:56] [config] authors: false
[2023-07-01 11:22:56] [config] beam-size: 12
[2023-07-01 11:22:56] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:22:56] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:22:56] [config] bert-masking-fraction: 0.15
[2023-07-01 11:22:56] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:22:56] [config] bert-train-type-embeddings: true
[2023-07-01 11:22:56] [config] bert-type-vocab-size: 2
[2023-07-01 11:22:56] [config] build-info: ""
[2023-07-01 11:22:56] [config] check-gradient-nan: false
[2023-07-01 11:22:56] [config] check-nan: false
[2023-07-01 11:22:56] [config] cite: false
[2023-07-01 11:22:56] [config] clip-norm: 5
[2023-07-01 11:22:56] [config] cost-scaling:
[2023-07-01 11:22:56] [config]   []
[2023-07-01 11:22:56] [config] cost-type: ce-sum
[2023-07-01 11:22:56] [config] cpu-threads: 0
[2023-07-01 11:22:56] [config] data-threads: 8
[2023-07-01 11:22:56] [config] data-weighting: ""
[2023-07-01 11:22:56] [config] data-weighting-type: sentence
[2023-07-01 11:22:56] [config] dec-cell: gru
[2023-07-01 11:22:56] [config] dec-cell-base-depth: 2
[2023-07-01 11:22:56] [config] dec-cell-high-depth: 1
[2023-07-01 11:22:56] [config] dec-depth: 2
[2023-07-01 11:22:56] [config] devices:
[2023-07-01 11:22:56] [config]   - 0
[2023-07-01 11:22:56] [config] dim-emb: 512
[2023-07-01 11:22:56] [config] dim-rnn: 1024
[2023-07-01 11:22:56] [config] dim-vocabs:
[2023-07-01 11:22:56] [config]   - 16384
[2023-07-01 11:22:56] [config]   - 16384
[2023-07-01 11:22:56] [config] disp-first: 0
[2023-07-01 11:22:56] [config] disp-freq: 1000u
[2023-07-01 11:22:56] [config] disp-label-counts: true
[2023-07-01 11:22:56] [config] dropout-rnn: 0
[2023-07-01 11:22:56] [config] dropout-src: 0
[2023-07-01 11:22:56] [config] dropout-trg: 0
[2023-07-01 11:22:56] [config] dump-config: ""
[2023-07-01 11:22:56] [config] dynamic-gradient-scaling:
[2023-07-01 11:22:56] [config]   []
[2023-07-01 11:22:56] [config] early-stopping: 10
[2023-07-01 11:22:56] [config] early-stopping-on: first
[2023-07-01 11:22:56] [config] embedding-fix-src: false
[2023-07-01 11:22:56] [config] embedding-fix-trg: false
[2023-07-01 11:22:56] [config] embedding-normalization: false
[2023-07-01 11:22:56] [config] embedding-vectors:
[2023-07-01 11:22:56] [config]   []
[2023-07-01 11:22:56] [config] enc-cell: gru
[2023-07-01 11:22:56] [config] enc-cell-depth: 1
[2023-07-01 11:22:56] [config] enc-depth: 2
[2023-07-01 11:22:56] [config] enc-type: bidirectional
[2023-07-01 11:22:56] [config] english-title-case-every: 0
[2023-07-01 11:22:56] [config] exponential-smoothing: 0.0001
[2023-07-01 11:22:56] [config] factor-weight: 1
[2023-07-01 11:22:56] [config] factors-combine: sum
[2023-07-01 11:22:56] [config] factors-dim-emb: 0
[2023-07-01 11:22:56] [config] gradient-checkpointing: false
[2023-07-01 11:22:56] [config] gradient-norm-average-window: 100
[2023-07-01 11:22:56] [config] guided-alignment: none
[2023-07-01 11:22:56] [config] guided-alignment-cost: mse
[2023-07-01 11:22:56] [config] guided-alignment-weight: 0.1
[2023-07-01 11:22:56] [config] ignore-model-config: false
[2023-07-01 11:22:56] [config] input-types:
[2023-07-01 11:22:56] [config]   []
[2023-07-01 11:22:56] [config] interpolate-env-vars: false
[2023-07-01 11:22:56] [config] keep-best: false
[2023-07-01 11:22:56] [config] label-smoothing: 0.1
[2023-07-01 11:22:56] [config] layer-normalization: false
[2023-07-01 11:22:56] [config] learn-rate: 0.0003
[2023-07-01 11:22:56] [config] lemma-dependency: ""
[2023-07-01 11:22:56] [config] lemma-dim-emb: 0
[2023-07-01 11:22:56] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:22:56] [config] log-level: info
[2023-07-01 11:22:56] [config] log-time-zone: ""
[2023-07-01 11:22:56] [config] logical-epoch:
[2023-07-01 11:22:56] [config]   - 1e
[2023-07-01 11:22:56] [config]   - 0
[2023-07-01 11:22:56] [config] lr-decay: 0
[2023-07-01 11:22:56] [config] lr-decay-freq: 50000
[2023-07-01 11:22:56] [config] lr-decay-inv-sqrt:
[2023-07-01 11:22:56] [config]   - 16000
[2023-07-01 11:22:56] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:22:56] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:22:56] [config] lr-decay-start:
[2023-07-01 11:22:56] [config]   - 10
[2023-07-01 11:22:56] [config]   - 1
[2023-07-01 11:22:56] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:22:56] [config] lr-report: true
[2023-07-01 11:22:56] [config] lr-warmup: 16000
[2023-07-01 11:22:56] [config] lr-warmup-at-reload: false
[2023-07-01 11:22:56] [config] lr-warmup-cycle: false
[2023-07-01 11:22:56] [config] lr-warmup-start-rate: 0
[2023-07-01 11:22:56] [config] max-length: 100
[2023-07-01 11:22:56] [config] max-length-crop: false
[2023-07-01 11:22:56] [config] max-length-factor: 3
[2023-07-01 11:22:56] [config] maxi-batch: 100
[2023-07-01 11:22:56] [config] maxi-batch-sort: trg
[2023-07-01 11:22:56] [config] mini-batch: 1000
[2023-07-01 11:22:56] [config] mini-batch-fit: true
[2023-07-01 11:22:56] [config] mini-batch-fit-step: 10
[2023-07-01 11:22:56] [config] mini-batch-round-up: true
[2023-07-01 11:22:56] [config] mini-batch-track-lr: false
[2023-07-01 11:22:56] [config] mini-batch-warmup: 0
[2023-07-01 11:22:56] [config] mini-batch-words: 0
[2023-07-01 11:22:56] [config] mini-batch-words-ref: 0
[2023-07-01 11:22:56] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:22:56] [config] multi-loss-type: sum
[2023-07-01 11:22:56] [config] n-best: false
[2023-07-01 11:22:56] [config] no-nccl: false
[2023-07-01 11:22:56] [config] no-reload: false
[2023-07-01 11:22:56] [config] no-restore-corpus: false
[2023-07-01 11:22:56] [config] normalize: 1
[2023-07-01 11:22:56] [config] normalize-gradient: false
[2023-07-01 11:22:56] [config] num-devices: 0
[2023-07-01 11:22:56] [config] optimizer: adam
[2023-07-01 11:22:56] [config] optimizer-delay: 1
[2023-07-01 11:22:56] [config] optimizer-params:
[2023-07-01 11:22:56] [config]   - 0.9
[2023-07-01 11:22:56] [config]   - 0.98
[2023-07-01 11:22:56] [config]   - 1e-09
[2023-07-01 11:22:56] [config] output-omit-bias: false
[2023-07-01 11:22:56] [config] overwrite: true
[2023-07-01 11:22:56] [config] precision:
[2023-07-01 11:22:56] [config]   - float32
[2023-07-01 11:22:56] [config]   - float32
[2023-07-01 11:22:56] [config] pretrained-model: ""
[2023-07-01 11:22:56] [config] quantize-biases: false
[2023-07-01 11:22:56] [config] quantize-bits: 0
[2023-07-01 11:22:56] [config] quantize-log-based: false
[2023-07-01 11:22:56] [config] quantize-optimization-steps: 0
[2023-07-01 11:22:56] [config] quiet: false
[2023-07-01 11:22:56] [config] quiet-translation: true
[2023-07-01 11:22:56] [config] relative-paths: false
[2023-07-01 11:22:56] [config] right-left: false
[2023-07-01 11:22:56] [config] save-freq: 10000u
[2023-07-01 11:22:56] [config] seed: 1234
[2023-07-01 11:22:56] [config] sentencepiece-alphas:
[2023-07-01 11:22:56] [config]   []
[2023-07-01 11:22:56] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:22:56] [config] sentencepiece-options: ""
[2023-07-01 11:22:56] [config] sharding: global
[2023-07-01 11:22:56] [config] shuffle: data
[2023-07-01 11:22:56] [config] shuffle-in-ram: false
[2023-07-01 11:22:56] [config] sigterm: save-and-exit
[2023-07-01 11:22:56] [config] skip: false
[2023-07-01 11:22:56] [config] sqlite: ""
[2023-07-01 11:22:56] [config] sqlite-drop: false
[2023-07-01 11:22:56] [config] sync-freq: 200u
[2023-07-01 11:22:56] [config] sync-sgd: true
[2023-07-01 11:22:56] [config] tempdir: /tmp
[2023-07-01 11:22:56] [config] tied-embeddings: false
[2023-07-01 11:22:56] [config] tied-embeddings-all: true
[2023-07-01 11:22:56] [config] tied-embeddings-src: false
[2023-07-01 11:22:56] [config] train-embedder-rank:
[2023-07-01 11:22:56] [config]   []
[2023-07-01 11:22:56] [config] train-sets:
[2023-07-01 11:22:56] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:22:56] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:22:56] [config] transformer-aan-activation: swish
[2023-07-01 11:22:56] [config] transformer-aan-depth: 2
[2023-07-01 11:22:56] [config] transformer-aan-nogate: false
[2023-07-01 11:22:56] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:22:56] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:22:56] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:22:56] [config] transformer-depth-scaling: false
[2023-07-01 11:22:56] [config] transformer-dim-aan: 2048
[2023-07-01 11:22:56] [config] transformer-dim-ffn: 2048
[2023-07-01 11:22:56] [config] transformer-dropout: 0.1
[2023-07-01 11:22:56] [config] transformer-dropout-attention: 0
[2023-07-01 11:22:56] [config] transformer-dropout-ffn: 0
[2023-07-01 11:22:56] [config] transformer-ffn-activation: swish
[2023-07-01 11:22:56] [config] transformer-ffn-depth: 2
[2023-07-01 11:22:56] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:22:56] [config] transformer-heads: 8
[2023-07-01 11:22:56] [config] transformer-no-projection: false
[2023-07-01 11:22:56] [config] transformer-pool: false
[2023-07-01 11:22:56] [config] transformer-postprocess: dan
[2023-07-01 11:22:56] [config] transformer-postprocess-emb: d
[2023-07-01 11:22:56] [config] transformer-postprocess-top: ""
[2023-07-01 11:22:56] [config] transformer-preprocess: ""
[2023-07-01 11:22:56] [config] transformer-tied-layers:
[2023-07-01 11:22:56] [config]   []
[2023-07-01 11:22:56] [config] transformer-train-position-embeddings: false
[2023-07-01 11:22:56] [config] tsv: false
[2023-07-01 11:22:56] [config] tsv-fields: 0
[2023-07-01 11:22:56] [config] type: transformer
[2023-07-01 11:22:56] [config] ulr: false
[2023-07-01 11:22:56] [config] ulr-dim-emb: 0
[2023-07-01 11:22:56] [config] ulr-dropout: 0
[2023-07-01 11:22:56] [config] ulr-keys-vectors: ""
[2023-07-01 11:22:56] [config] ulr-query-vectors: ""
[2023-07-01 11:22:56] [config] ulr-softmax-temperature: 1
[2023-07-01 11:22:56] [config] ulr-trainable-transformation: false
[2023-07-01 11:22:56] [config] unlikelihood-loss: false
[2023-07-01 11:22:56] [config] valid-freq: 50000000
[2023-07-01 11:22:56] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:22:56] [config] valid-max-length: 1000
[2023-07-01 11:22:56] [config] valid-metrics:
[2023-07-01 11:22:56] [config]   - cross-entropy
[2023-07-01 11:22:56] [config]   - translation
[2023-07-01 11:22:56] [config] valid-mini-batch: 64
[2023-07-01 11:22:56] [config] valid-reset-stalled: false
[2023-07-01 11:22:56] [config] valid-script-args:
[2023-07-01 11:22:56] [config]   []
[2023-07-01 11:22:56] [config] valid-script-path: ""
[2023-07-01 11:22:56] [config] valid-sets:
[2023-07-01 11:22:56] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:22:56] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:22:56] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:22:56] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:22:56] [config] vocabs:
[2023-07-01 11:22:56] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:22:56] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:22:56] [config] word-penalty: 0
[2023-07-01 11:22:56] [config] word-scores: false
[2023-07-01 11:22:56] [config] workspace: 2048
[2023-07-01 11:22:56] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:22:56] Using synchronous SGD
[2023-07-01 11:22:56] Synced seed 1234
[2023-07-01 11:22:56] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:22:57] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:22:57] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:22:57] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:22:57] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:22:57] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:22:57] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:22:57] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:22:57] [comm] Using global sharding
[2023-07-01 11:22:57] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:22:57] [training] Using 1 GPUs
[2023-07-01 11:22:57] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:22:57] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:22:58] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:22:58] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:23:05] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:23:05] [valid] No post-processing script given for validating translator
[2023-07-01 11:23:05] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:23:05] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:23:05] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:23:05] [comm] Using global sharding
[2023-07-01 11:23:05] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:23:05] [training] Using 1 GPUs
[2023-07-01 11:23:05] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:23:06] Allocating memory for general optimizer shards
[2023-07-01 11:23:06] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:23:06] Loading Adam parameters
[2023-07-01 11:23:06] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:23:06] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:23:06] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:23:06] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:23:06] [data] Shuffling data
[2023-07-01 11:23:06] [data] Done reading 20,192 sentences
[2023-07-01 11:23:06] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:23:06] Training started
[2023-07-01 11:23:06] Training finished
[2023-07-01 11:23:10] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:23:10] [marian] Running on node20.datos.cluster.uy as process 14797 with command line:
[2023-07-01 11:23:10] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 63 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:23:10] [config] after: 0e
[2023-07-01 11:23:10] [config] after-batches: 0
[2023-07-01 11:23:10] [config] after-epochs: 63
[2023-07-01 11:23:10] [config] all-caps-every: 0
[2023-07-01 11:23:10] [config] allow-unk: false
[2023-07-01 11:23:10] [config] authors: false
[2023-07-01 11:23:10] [config] beam-size: 12
[2023-07-01 11:23:10] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:23:10] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:23:10] [config] bert-masking-fraction: 0.15
[2023-07-01 11:23:10] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:23:10] [config] bert-train-type-embeddings: true
[2023-07-01 11:23:10] [config] bert-type-vocab-size: 2
[2023-07-01 11:23:10] [config] build-info: ""
[2023-07-01 11:23:10] [config] check-gradient-nan: false
[2023-07-01 11:23:10] [config] check-nan: false
[2023-07-01 11:23:10] [config] cite: false
[2023-07-01 11:23:10] [config] clip-norm: 5
[2023-07-01 11:23:10] [config] cost-scaling:
[2023-07-01 11:23:10] [config]   []
[2023-07-01 11:23:10] [config] cost-type: ce-sum
[2023-07-01 11:23:10] [config] cpu-threads: 0
[2023-07-01 11:23:10] [config] data-threads: 8
[2023-07-01 11:23:10] [config] data-weighting: ""
[2023-07-01 11:23:10] [config] data-weighting-type: sentence
[2023-07-01 11:23:10] [config] dec-cell: gru
[2023-07-01 11:23:10] [config] dec-cell-base-depth: 2
[2023-07-01 11:23:10] [config] dec-cell-high-depth: 1
[2023-07-01 11:23:10] [config] dec-depth: 2
[2023-07-01 11:23:10] [config] devices:
[2023-07-01 11:23:10] [config]   - 0
[2023-07-01 11:23:10] [config] dim-emb: 512
[2023-07-01 11:23:10] [config] dim-rnn: 1024
[2023-07-01 11:23:10] [config] dim-vocabs:
[2023-07-01 11:23:10] [config]   - 16384
[2023-07-01 11:23:10] [config]   - 16384
[2023-07-01 11:23:10] [config] disp-first: 0
[2023-07-01 11:23:10] [config] disp-freq: 1000u
[2023-07-01 11:23:10] [config] disp-label-counts: true
[2023-07-01 11:23:10] [config] dropout-rnn: 0
[2023-07-01 11:23:10] [config] dropout-src: 0
[2023-07-01 11:23:10] [config] dropout-trg: 0
[2023-07-01 11:23:10] [config] dump-config: ""
[2023-07-01 11:23:10] [config] dynamic-gradient-scaling:
[2023-07-01 11:23:10] [config]   []
[2023-07-01 11:23:10] [config] early-stopping: 10
[2023-07-01 11:23:10] [config] early-stopping-on: first
[2023-07-01 11:23:10] [config] embedding-fix-src: false
[2023-07-01 11:23:10] [config] embedding-fix-trg: false
[2023-07-01 11:23:10] [config] embedding-normalization: false
[2023-07-01 11:23:10] [config] embedding-vectors:
[2023-07-01 11:23:10] [config]   []
[2023-07-01 11:23:10] [config] enc-cell: gru
[2023-07-01 11:23:10] [config] enc-cell-depth: 1
[2023-07-01 11:23:10] [config] enc-depth: 2
[2023-07-01 11:23:10] [config] enc-type: bidirectional
[2023-07-01 11:23:10] [config] english-title-case-every: 0
[2023-07-01 11:23:10] [config] exponential-smoothing: 0.0001
[2023-07-01 11:23:10] [config] factor-weight: 1
[2023-07-01 11:23:10] [config] factors-combine: sum
[2023-07-01 11:23:10] [config] factors-dim-emb: 0
[2023-07-01 11:23:10] [config] gradient-checkpointing: false
[2023-07-01 11:23:10] [config] gradient-norm-average-window: 100
[2023-07-01 11:23:10] [config] guided-alignment: none
[2023-07-01 11:23:10] [config] guided-alignment-cost: mse
[2023-07-01 11:23:10] [config] guided-alignment-weight: 0.1
[2023-07-01 11:23:10] [config] ignore-model-config: false
[2023-07-01 11:23:10] [config] input-types:
[2023-07-01 11:23:10] [config]   []
[2023-07-01 11:23:10] [config] interpolate-env-vars: false
[2023-07-01 11:23:10] [config] keep-best: false
[2023-07-01 11:23:10] [config] label-smoothing: 0.1
[2023-07-01 11:23:10] [config] layer-normalization: false
[2023-07-01 11:23:10] [config] learn-rate: 0.0003
[2023-07-01 11:23:10] [config] lemma-dependency: ""
[2023-07-01 11:23:10] [config] lemma-dim-emb: 0
[2023-07-01 11:23:10] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:23:10] [config] log-level: info
[2023-07-01 11:23:10] [config] log-time-zone: ""
[2023-07-01 11:23:10] [config] logical-epoch:
[2023-07-01 11:23:10] [config]   - 1e
[2023-07-01 11:23:10] [config]   - 0
[2023-07-01 11:23:10] [config] lr-decay: 0
[2023-07-01 11:23:10] [config] lr-decay-freq: 50000
[2023-07-01 11:23:10] [config] lr-decay-inv-sqrt:
[2023-07-01 11:23:10] [config]   - 16000
[2023-07-01 11:23:10] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:23:10] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:23:10] [config] lr-decay-start:
[2023-07-01 11:23:10] [config]   - 10
[2023-07-01 11:23:10] [config]   - 1
[2023-07-01 11:23:10] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:23:10] [config] lr-report: true
[2023-07-01 11:23:10] [config] lr-warmup: 16000
[2023-07-01 11:23:10] [config] lr-warmup-at-reload: false
[2023-07-01 11:23:10] [config] lr-warmup-cycle: false
[2023-07-01 11:23:10] [config] lr-warmup-start-rate: 0
[2023-07-01 11:23:10] [config] max-length: 100
[2023-07-01 11:23:10] [config] max-length-crop: false
[2023-07-01 11:23:10] [config] max-length-factor: 3
[2023-07-01 11:23:10] [config] maxi-batch: 100
[2023-07-01 11:23:10] [config] maxi-batch-sort: trg
[2023-07-01 11:23:10] [config] mini-batch: 1000
[2023-07-01 11:23:10] [config] mini-batch-fit: true
[2023-07-01 11:23:10] [config] mini-batch-fit-step: 10
[2023-07-01 11:23:10] [config] mini-batch-round-up: true
[2023-07-01 11:23:10] [config] mini-batch-track-lr: false
[2023-07-01 11:23:10] [config] mini-batch-warmup: 0
[2023-07-01 11:23:10] [config] mini-batch-words: 0
[2023-07-01 11:23:10] [config] mini-batch-words-ref: 0
[2023-07-01 11:23:10] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:23:10] [config] multi-loss-type: sum
[2023-07-01 11:23:10] [config] n-best: false
[2023-07-01 11:23:10] [config] no-nccl: false
[2023-07-01 11:23:10] [config] no-reload: false
[2023-07-01 11:23:10] [config] no-restore-corpus: false
[2023-07-01 11:23:10] [config] normalize: 1
[2023-07-01 11:23:10] [config] normalize-gradient: false
[2023-07-01 11:23:10] [config] num-devices: 0
[2023-07-01 11:23:10] [config] optimizer: adam
[2023-07-01 11:23:10] [config] optimizer-delay: 1
[2023-07-01 11:23:10] [config] optimizer-params:
[2023-07-01 11:23:10] [config]   - 0.9
[2023-07-01 11:23:10] [config]   - 0.98
[2023-07-01 11:23:10] [config]   - 1e-09
[2023-07-01 11:23:10] [config] output-omit-bias: false
[2023-07-01 11:23:10] [config] overwrite: true
[2023-07-01 11:23:10] [config] precision:
[2023-07-01 11:23:10] [config]   - float32
[2023-07-01 11:23:10] [config]   - float32
[2023-07-01 11:23:10] [config] pretrained-model: ""
[2023-07-01 11:23:10] [config] quantize-biases: false
[2023-07-01 11:23:10] [config] quantize-bits: 0
[2023-07-01 11:23:10] [config] quantize-log-based: false
[2023-07-01 11:23:10] [config] quantize-optimization-steps: 0
[2023-07-01 11:23:10] [config] quiet: false
[2023-07-01 11:23:10] [config] quiet-translation: true
[2023-07-01 11:23:10] [config] relative-paths: false
[2023-07-01 11:23:10] [config] right-left: false
[2023-07-01 11:23:10] [config] save-freq: 10000u
[2023-07-01 11:23:10] [config] seed: 1234
[2023-07-01 11:23:10] [config] sentencepiece-alphas:
[2023-07-01 11:23:10] [config]   []
[2023-07-01 11:23:10] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:23:10] [config] sentencepiece-options: ""
[2023-07-01 11:23:10] [config] sharding: global
[2023-07-01 11:23:10] [config] shuffle: data
[2023-07-01 11:23:10] [config] shuffle-in-ram: false
[2023-07-01 11:23:10] [config] sigterm: save-and-exit
[2023-07-01 11:23:10] [config] skip: false
[2023-07-01 11:23:10] [config] sqlite: ""
[2023-07-01 11:23:10] [config] sqlite-drop: false
[2023-07-01 11:23:10] [config] sync-freq: 200u
[2023-07-01 11:23:10] [config] sync-sgd: true
[2023-07-01 11:23:10] [config] tempdir: /tmp
[2023-07-01 11:23:10] [config] tied-embeddings: false
[2023-07-01 11:23:10] [config] tied-embeddings-all: true
[2023-07-01 11:23:10] [config] tied-embeddings-src: false
[2023-07-01 11:23:10] [config] train-embedder-rank:
[2023-07-01 11:23:10] [config]   []
[2023-07-01 11:23:10] [config] train-sets:
[2023-07-01 11:23:10] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:23:10] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:23:10] [config] transformer-aan-activation: swish
[2023-07-01 11:23:10] [config] transformer-aan-depth: 2
[2023-07-01 11:23:10] [config] transformer-aan-nogate: false
[2023-07-01 11:23:10] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:23:10] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:23:10] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:23:10] [config] transformer-depth-scaling: false
[2023-07-01 11:23:10] [config] transformer-dim-aan: 2048
[2023-07-01 11:23:10] [config] transformer-dim-ffn: 2048
[2023-07-01 11:23:10] [config] transformer-dropout: 0.1
[2023-07-01 11:23:10] [config] transformer-dropout-attention: 0
[2023-07-01 11:23:10] [config] transformer-dropout-ffn: 0
[2023-07-01 11:23:10] [config] transformer-ffn-activation: swish
[2023-07-01 11:23:10] [config] transformer-ffn-depth: 2
[2023-07-01 11:23:10] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:23:10] [config] transformer-heads: 8
[2023-07-01 11:23:10] [config] transformer-no-projection: false
[2023-07-01 11:23:10] [config] transformer-pool: false
[2023-07-01 11:23:10] [config] transformer-postprocess: dan
[2023-07-01 11:23:10] [config] transformer-postprocess-emb: d
[2023-07-01 11:23:10] [config] transformer-postprocess-top: ""
[2023-07-01 11:23:10] [config] transformer-preprocess: ""
[2023-07-01 11:23:10] [config] transformer-tied-layers:
[2023-07-01 11:23:10] [config]   []
[2023-07-01 11:23:10] [config] transformer-train-position-embeddings: false
[2023-07-01 11:23:10] [config] tsv: false
[2023-07-01 11:23:10] [config] tsv-fields: 0
[2023-07-01 11:23:10] [config] type: transformer
[2023-07-01 11:23:10] [config] ulr: false
[2023-07-01 11:23:10] [config] ulr-dim-emb: 0
[2023-07-01 11:23:10] [config] ulr-dropout: 0
[2023-07-01 11:23:10] [config] ulr-keys-vectors: ""
[2023-07-01 11:23:10] [config] ulr-query-vectors: ""
[2023-07-01 11:23:10] [config] ulr-softmax-temperature: 1
[2023-07-01 11:23:10] [config] ulr-trainable-transformation: false
[2023-07-01 11:23:10] [config] unlikelihood-loss: false
[2023-07-01 11:23:10] [config] valid-freq: 50000000
[2023-07-01 11:23:10] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:23:10] [config] valid-max-length: 1000
[2023-07-01 11:23:10] [config] valid-metrics:
[2023-07-01 11:23:10] [config]   - cross-entropy
[2023-07-01 11:23:10] [config]   - translation
[2023-07-01 11:23:10] [config] valid-mini-batch: 64
[2023-07-01 11:23:10] [config] valid-reset-stalled: false
[2023-07-01 11:23:10] [config] valid-script-args:
[2023-07-01 11:23:10] [config]   []
[2023-07-01 11:23:10] [config] valid-script-path: ""
[2023-07-01 11:23:10] [config] valid-sets:
[2023-07-01 11:23:10] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:23:10] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:23:10] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:23:10] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:23:10] [config] vocabs:
[2023-07-01 11:23:10] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:23:10] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:23:10] [config] word-penalty: 0
[2023-07-01 11:23:10] [config] word-scores: false
[2023-07-01 11:23:10] [config] workspace: 2048
[2023-07-01 11:23:10] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:23:10] Using synchronous SGD
[2023-07-01 11:23:10] Synced seed 1234
[2023-07-01 11:23:10] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:23:10] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:23:10] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:23:10] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:23:10] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:23:10] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:23:11] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:23:11] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:23:11] [comm] Using global sharding
[2023-07-01 11:23:11] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:23:11] [training] Using 1 GPUs
[2023-07-01 11:23:11] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:23:11] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:23:11] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:23:11] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:23:19] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:23:19] [valid] No post-processing script given for validating translator
[2023-07-01 11:23:19] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:23:19] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:23:19] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:23:19] [comm] Using global sharding
[2023-07-01 11:23:19] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:23:19] [training] Using 1 GPUs
[2023-07-01 11:23:19] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:23:20] Allocating memory for general optimizer shards
[2023-07-01 11:23:20] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:23:20] Loading Adam parameters
[2023-07-01 11:23:20] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:23:20] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:23:20] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:23:20] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:23:20] [data] Shuffling data
[2023-07-01 11:23:20] [data] Done reading 20,192 sentences
[2023-07-01 11:23:20] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:23:20] Training started
[2023-07-01 11:23:20] Training finished
[2023-07-01 11:23:23] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:23:23] [marian] Running on node20.datos.cluster.uy as process 14856 with command line:
[2023-07-01 11:23:23] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 64 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:23:23] [config] after: 0e
[2023-07-01 11:23:23] [config] after-batches: 0
[2023-07-01 11:23:23] [config] after-epochs: 64
[2023-07-01 11:23:23] [config] all-caps-every: 0
[2023-07-01 11:23:23] [config] allow-unk: false
[2023-07-01 11:23:23] [config] authors: false
[2023-07-01 11:23:23] [config] beam-size: 12
[2023-07-01 11:23:23] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:23:23] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:23:23] [config] bert-masking-fraction: 0.15
[2023-07-01 11:23:23] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:23:23] [config] bert-train-type-embeddings: true
[2023-07-01 11:23:23] [config] bert-type-vocab-size: 2
[2023-07-01 11:23:23] [config] build-info: ""
[2023-07-01 11:23:23] [config] check-gradient-nan: false
[2023-07-01 11:23:23] [config] check-nan: false
[2023-07-01 11:23:23] [config] cite: false
[2023-07-01 11:23:23] [config] clip-norm: 5
[2023-07-01 11:23:23] [config] cost-scaling:
[2023-07-01 11:23:23] [config]   []
[2023-07-01 11:23:23] [config] cost-type: ce-sum
[2023-07-01 11:23:23] [config] cpu-threads: 0
[2023-07-01 11:23:23] [config] data-threads: 8
[2023-07-01 11:23:23] [config] data-weighting: ""
[2023-07-01 11:23:23] [config] data-weighting-type: sentence
[2023-07-01 11:23:23] [config] dec-cell: gru
[2023-07-01 11:23:23] [config] dec-cell-base-depth: 2
[2023-07-01 11:23:23] [config] dec-cell-high-depth: 1
[2023-07-01 11:23:23] [config] dec-depth: 2
[2023-07-01 11:23:23] [config] devices:
[2023-07-01 11:23:23] [config]   - 0
[2023-07-01 11:23:23] [config] dim-emb: 512
[2023-07-01 11:23:23] [config] dim-rnn: 1024
[2023-07-01 11:23:23] [config] dim-vocabs:
[2023-07-01 11:23:23] [config]   - 16384
[2023-07-01 11:23:23] [config]   - 16384
[2023-07-01 11:23:23] [config] disp-first: 0
[2023-07-01 11:23:23] [config] disp-freq: 1000u
[2023-07-01 11:23:23] [config] disp-label-counts: true
[2023-07-01 11:23:23] [config] dropout-rnn: 0
[2023-07-01 11:23:23] [config] dropout-src: 0
[2023-07-01 11:23:23] [config] dropout-trg: 0
[2023-07-01 11:23:23] [config] dump-config: ""
[2023-07-01 11:23:23] [config] dynamic-gradient-scaling:
[2023-07-01 11:23:23] [config]   []
[2023-07-01 11:23:23] [config] early-stopping: 10
[2023-07-01 11:23:23] [config] early-stopping-on: first
[2023-07-01 11:23:23] [config] embedding-fix-src: false
[2023-07-01 11:23:23] [config] embedding-fix-trg: false
[2023-07-01 11:23:23] [config] embedding-normalization: false
[2023-07-01 11:23:23] [config] embedding-vectors:
[2023-07-01 11:23:23] [config]   []
[2023-07-01 11:23:23] [config] enc-cell: gru
[2023-07-01 11:23:23] [config] enc-cell-depth: 1
[2023-07-01 11:23:23] [config] enc-depth: 2
[2023-07-01 11:23:23] [config] enc-type: bidirectional
[2023-07-01 11:23:23] [config] english-title-case-every: 0
[2023-07-01 11:23:23] [config] exponential-smoothing: 0.0001
[2023-07-01 11:23:23] [config] factor-weight: 1
[2023-07-01 11:23:23] [config] factors-combine: sum
[2023-07-01 11:23:23] [config] factors-dim-emb: 0
[2023-07-01 11:23:23] [config] gradient-checkpointing: false
[2023-07-01 11:23:23] [config] gradient-norm-average-window: 100
[2023-07-01 11:23:23] [config] guided-alignment: none
[2023-07-01 11:23:23] [config] guided-alignment-cost: mse
[2023-07-01 11:23:23] [config] guided-alignment-weight: 0.1
[2023-07-01 11:23:23] [config] ignore-model-config: false
[2023-07-01 11:23:23] [config] input-types:
[2023-07-01 11:23:23] [config]   []
[2023-07-01 11:23:23] [config] interpolate-env-vars: false
[2023-07-01 11:23:23] [config] keep-best: false
[2023-07-01 11:23:23] [config] label-smoothing: 0.1
[2023-07-01 11:23:23] [config] layer-normalization: false
[2023-07-01 11:23:23] [config] learn-rate: 0.0003
[2023-07-01 11:23:23] [config] lemma-dependency: ""
[2023-07-01 11:23:23] [config] lemma-dim-emb: 0
[2023-07-01 11:23:23] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:23:23] [config] log-level: info
[2023-07-01 11:23:23] [config] log-time-zone: ""
[2023-07-01 11:23:23] [config] logical-epoch:
[2023-07-01 11:23:23] [config]   - 1e
[2023-07-01 11:23:23] [config]   - 0
[2023-07-01 11:23:23] [config] lr-decay: 0
[2023-07-01 11:23:23] [config] lr-decay-freq: 50000
[2023-07-01 11:23:23] [config] lr-decay-inv-sqrt:
[2023-07-01 11:23:23] [config]   - 16000
[2023-07-01 11:23:23] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:23:23] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:23:23] [config] lr-decay-start:
[2023-07-01 11:23:23] [config]   - 10
[2023-07-01 11:23:23] [config]   - 1
[2023-07-01 11:23:23] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:23:23] [config] lr-report: true
[2023-07-01 11:23:23] [config] lr-warmup: 16000
[2023-07-01 11:23:23] [config] lr-warmup-at-reload: false
[2023-07-01 11:23:23] [config] lr-warmup-cycle: false
[2023-07-01 11:23:23] [config] lr-warmup-start-rate: 0
[2023-07-01 11:23:23] [config] max-length: 100
[2023-07-01 11:23:23] [config] max-length-crop: false
[2023-07-01 11:23:23] [config] max-length-factor: 3
[2023-07-01 11:23:23] [config] maxi-batch: 100
[2023-07-01 11:23:23] [config] maxi-batch-sort: trg
[2023-07-01 11:23:23] [config] mini-batch: 1000
[2023-07-01 11:23:23] [config] mini-batch-fit: true
[2023-07-01 11:23:23] [config] mini-batch-fit-step: 10
[2023-07-01 11:23:23] [config] mini-batch-round-up: true
[2023-07-01 11:23:23] [config] mini-batch-track-lr: false
[2023-07-01 11:23:23] [config] mini-batch-warmup: 0
[2023-07-01 11:23:23] [config] mini-batch-words: 0
[2023-07-01 11:23:23] [config] mini-batch-words-ref: 0
[2023-07-01 11:23:23] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:23:23] [config] multi-loss-type: sum
[2023-07-01 11:23:23] [config] n-best: false
[2023-07-01 11:23:23] [config] no-nccl: false
[2023-07-01 11:23:23] [config] no-reload: false
[2023-07-01 11:23:23] [config] no-restore-corpus: false
[2023-07-01 11:23:23] [config] normalize: 1
[2023-07-01 11:23:23] [config] normalize-gradient: false
[2023-07-01 11:23:23] [config] num-devices: 0
[2023-07-01 11:23:23] [config] optimizer: adam
[2023-07-01 11:23:23] [config] optimizer-delay: 1
[2023-07-01 11:23:23] [config] optimizer-params:
[2023-07-01 11:23:23] [config]   - 0.9
[2023-07-01 11:23:23] [config]   - 0.98
[2023-07-01 11:23:23] [config]   - 1e-09
[2023-07-01 11:23:23] [config] output-omit-bias: false
[2023-07-01 11:23:23] [config] overwrite: true
[2023-07-01 11:23:23] [config] precision:
[2023-07-01 11:23:23] [config]   - float32
[2023-07-01 11:23:23] [config]   - float32
[2023-07-01 11:23:23] [config] pretrained-model: ""
[2023-07-01 11:23:23] [config] quantize-biases: false
[2023-07-01 11:23:23] [config] quantize-bits: 0
[2023-07-01 11:23:23] [config] quantize-log-based: false
[2023-07-01 11:23:23] [config] quantize-optimization-steps: 0
[2023-07-01 11:23:23] [config] quiet: false
[2023-07-01 11:23:23] [config] quiet-translation: true
[2023-07-01 11:23:23] [config] relative-paths: false
[2023-07-01 11:23:23] [config] right-left: false
[2023-07-01 11:23:23] [config] save-freq: 10000u
[2023-07-01 11:23:23] [config] seed: 1234
[2023-07-01 11:23:23] [config] sentencepiece-alphas:
[2023-07-01 11:23:23] [config]   []
[2023-07-01 11:23:23] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:23:23] [config] sentencepiece-options: ""
[2023-07-01 11:23:23] [config] sharding: global
[2023-07-01 11:23:23] [config] shuffle: data
[2023-07-01 11:23:23] [config] shuffle-in-ram: false
[2023-07-01 11:23:23] [config] sigterm: save-and-exit
[2023-07-01 11:23:23] [config] skip: false
[2023-07-01 11:23:23] [config] sqlite: ""
[2023-07-01 11:23:23] [config] sqlite-drop: false
[2023-07-01 11:23:23] [config] sync-freq: 200u
[2023-07-01 11:23:23] [config] sync-sgd: true
[2023-07-01 11:23:23] [config] tempdir: /tmp
[2023-07-01 11:23:23] [config] tied-embeddings: false
[2023-07-01 11:23:23] [config] tied-embeddings-all: true
[2023-07-01 11:23:23] [config] tied-embeddings-src: false
[2023-07-01 11:23:23] [config] train-embedder-rank:
[2023-07-01 11:23:23] [config]   []
[2023-07-01 11:23:23] [config] train-sets:
[2023-07-01 11:23:23] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:23:23] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:23:23] [config] transformer-aan-activation: swish
[2023-07-01 11:23:23] [config] transformer-aan-depth: 2
[2023-07-01 11:23:23] [config] transformer-aan-nogate: false
[2023-07-01 11:23:23] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:23:23] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:23:23] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:23:23] [config] transformer-depth-scaling: false
[2023-07-01 11:23:23] [config] transformer-dim-aan: 2048
[2023-07-01 11:23:23] [config] transformer-dim-ffn: 2048
[2023-07-01 11:23:23] [config] transformer-dropout: 0.1
[2023-07-01 11:23:23] [config] transformer-dropout-attention: 0
[2023-07-01 11:23:23] [config] transformer-dropout-ffn: 0
[2023-07-01 11:23:23] [config] transformer-ffn-activation: swish
[2023-07-01 11:23:23] [config] transformer-ffn-depth: 2
[2023-07-01 11:23:23] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:23:23] [config] transformer-heads: 8
[2023-07-01 11:23:23] [config] transformer-no-projection: false
[2023-07-01 11:23:23] [config] transformer-pool: false
[2023-07-01 11:23:23] [config] transformer-postprocess: dan
[2023-07-01 11:23:23] [config] transformer-postprocess-emb: d
[2023-07-01 11:23:23] [config] transformer-postprocess-top: ""
[2023-07-01 11:23:23] [config] transformer-preprocess: ""
[2023-07-01 11:23:23] [config] transformer-tied-layers:
[2023-07-01 11:23:23] [config]   []
[2023-07-01 11:23:23] [config] transformer-train-position-embeddings: false
[2023-07-01 11:23:23] [config] tsv: false
[2023-07-01 11:23:23] [config] tsv-fields: 0
[2023-07-01 11:23:23] [config] type: transformer
[2023-07-01 11:23:23] [config] ulr: false
[2023-07-01 11:23:23] [config] ulr-dim-emb: 0
[2023-07-01 11:23:23] [config] ulr-dropout: 0
[2023-07-01 11:23:23] [config] ulr-keys-vectors: ""
[2023-07-01 11:23:23] [config] ulr-query-vectors: ""
[2023-07-01 11:23:23] [config] ulr-softmax-temperature: 1
[2023-07-01 11:23:23] [config] ulr-trainable-transformation: false
[2023-07-01 11:23:23] [config] unlikelihood-loss: false
[2023-07-01 11:23:23] [config] valid-freq: 50000000
[2023-07-01 11:23:23] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:23:23] [config] valid-max-length: 1000
[2023-07-01 11:23:23] [config] valid-metrics:
[2023-07-01 11:23:23] [config]   - cross-entropy
[2023-07-01 11:23:23] [config]   - translation
[2023-07-01 11:23:23] [config] valid-mini-batch: 64
[2023-07-01 11:23:23] [config] valid-reset-stalled: false
[2023-07-01 11:23:23] [config] valid-script-args:
[2023-07-01 11:23:23] [config]   []
[2023-07-01 11:23:23] [config] valid-script-path: ""
[2023-07-01 11:23:23] [config] valid-sets:
[2023-07-01 11:23:23] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:23:23] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:23:23] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:23:23] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:23:23] [config] vocabs:
[2023-07-01 11:23:23] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:23:23] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:23:23] [config] word-penalty: 0
[2023-07-01 11:23:23] [config] word-scores: false
[2023-07-01 11:23:23] [config] workspace: 2048
[2023-07-01 11:23:23] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:23:23] Using synchronous SGD
[2023-07-01 11:23:24] Synced seed 1234
[2023-07-01 11:23:24] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:23:24] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:23:24] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:23:24] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:23:24] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:23:24] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:23:24] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:23:24] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:23:24] [comm] Using global sharding
[2023-07-01 11:23:25] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:23:25] [training] Using 1 GPUs
[2023-07-01 11:23:25] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:23:25] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:23:25] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:23:25] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:23:32] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:23:32] [valid] No post-processing script given for validating translator
[2023-07-01 11:23:32] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:23:32] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:23:32] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:23:32] [comm] Using global sharding
[2023-07-01 11:23:32] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:23:32] [training] Using 1 GPUs
[2023-07-01 11:23:32] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:23:33] Allocating memory for general optimizer shards
[2023-07-01 11:23:33] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:23:33] Loading Adam parameters
[2023-07-01 11:23:33] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:23:33] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:23:33] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:23:33] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:23:33] [data] Shuffling data
[2023-07-01 11:23:33] [data] Done reading 20,192 sentences
[2023-07-01 11:23:33] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:23:33] Training started
[2023-07-01 11:23:33] Training finished
[2023-07-01 11:23:37] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:23:37] [marian] Running on node20.datos.cluster.uy as process 14917 with command line:
[2023-07-01 11:23:37] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 65 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:23:37] [config] after: 0e
[2023-07-01 11:23:37] [config] after-batches: 0
[2023-07-01 11:23:37] [config] after-epochs: 65
[2023-07-01 11:23:37] [config] all-caps-every: 0
[2023-07-01 11:23:37] [config] allow-unk: false
[2023-07-01 11:23:37] [config] authors: false
[2023-07-01 11:23:37] [config] beam-size: 12
[2023-07-01 11:23:37] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:23:37] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:23:37] [config] bert-masking-fraction: 0.15
[2023-07-01 11:23:37] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:23:37] [config] bert-train-type-embeddings: true
[2023-07-01 11:23:37] [config] bert-type-vocab-size: 2
[2023-07-01 11:23:37] [config] build-info: ""
[2023-07-01 11:23:37] [config] check-gradient-nan: false
[2023-07-01 11:23:37] [config] check-nan: false
[2023-07-01 11:23:37] [config] cite: false
[2023-07-01 11:23:37] [config] clip-norm: 5
[2023-07-01 11:23:37] [config] cost-scaling:
[2023-07-01 11:23:37] [config]   []
[2023-07-01 11:23:37] [config] cost-type: ce-sum
[2023-07-01 11:23:37] [config] cpu-threads: 0
[2023-07-01 11:23:37] [config] data-threads: 8
[2023-07-01 11:23:37] [config] data-weighting: ""
[2023-07-01 11:23:37] [config] data-weighting-type: sentence
[2023-07-01 11:23:37] [config] dec-cell: gru
[2023-07-01 11:23:37] [config] dec-cell-base-depth: 2
[2023-07-01 11:23:37] [config] dec-cell-high-depth: 1
[2023-07-01 11:23:37] [config] dec-depth: 2
[2023-07-01 11:23:37] [config] devices:
[2023-07-01 11:23:37] [config]   - 0
[2023-07-01 11:23:37] [config] dim-emb: 512
[2023-07-01 11:23:37] [config] dim-rnn: 1024
[2023-07-01 11:23:37] [config] dim-vocabs:
[2023-07-01 11:23:37] [config]   - 16384
[2023-07-01 11:23:37] [config]   - 16384
[2023-07-01 11:23:37] [config] disp-first: 0
[2023-07-01 11:23:37] [config] disp-freq: 1000u
[2023-07-01 11:23:37] [config] disp-label-counts: true
[2023-07-01 11:23:37] [config] dropout-rnn: 0
[2023-07-01 11:23:37] [config] dropout-src: 0
[2023-07-01 11:23:37] [config] dropout-trg: 0
[2023-07-01 11:23:37] [config] dump-config: ""
[2023-07-01 11:23:37] [config] dynamic-gradient-scaling:
[2023-07-01 11:23:37] [config]   []
[2023-07-01 11:23:37] [config] early-stopping: 10
[2023-07-01 11:23:37] [config] early-stopping-on: first
[2023-07-01 11:23:37] [config] embedding-fix-src: false
[2023-07-01 11:23:37] [config] embedding-fix-trg: false
[2023-07-01 11:23:37] [config] embedding-normalization: false
[2023-07-01 11:23:37] [config] embedding-vectors:
[2023-07-01 11:23:37] [config]   []
[2023-07-01 11:23:37] [config] enc-cell: gru
[2023-07-01 11:23:37] [config] enc-cell-depth: 1
[2023-07-01 11:23:37] [config] enc-depth: 2
[2023-07-01 11:23:37] [config] enc-type: bidirectional
[2023-07-01 11:23:37] [config] english-title-case-every: 0
[2023-07-01 11:23:37] [config] exponential-smoothing: 0.0001
[2023-07-01 11:23:37] [config] factor-weight: 1
[2023-07-01 11:23:37] [config] factors-combine: sum
[2023-07-01 11:23:37] [config] factors-dim-emb: 0
[2023-07-01 11:23:37] [config] gradient-checkpointing: false
[2023-07-01 11:23:37] [config] gradient-norm-average-window: 100
[2023-07-01 11:23:37] [config] guided-alignment: none
[2023-07-01 11:23:37] [config] guided-alignment-cost: mse
[2023-07-01 11:23:37] [config] guided-alignment-weight: 0.1
[2023-07-01 11:23:37] [config] ignore-model-config: false
[2023-07-01 11:23:37] [config] input-types:
[2023-07-01 11:23:37] [config]   []
[2023-07-01 11:23:37] [config] interpolate-env-vars: false
[2023-07-01 11:23:37] [config] keep-best: false
[2023-07-01 11:23:37] [config] label-smoothing: 0.1
[2023-07-01 11:23:37] [config] layer-normalization: false
[2023-07-01 11:23:37] [config] learn-rate: 0.0003
[2023-07-01 11:23:37] [config] lemma-dependency: ""
[2023-07-01 11:23:37] [config] lemma-dim-emb: 0
[2023-07-01 11:23:37] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:23:37] [config] log-level: info
[2023-07-01 11:23:37] [config] log-time-zone: ""
[2023-07-01 11:23:37] [config] logical-epoch:
[2023-07-01 11:23:37] [config]   - 1e
[2023-07-01 11:23:37] [config]   - 0
[2023-07-01 11:23:37] [config] lr-decay: 0
[2023-07-01 11:23:37] [config] lr-decay-freq: 50000
[2023-07-01 11:23:37] [config] lr-decay-inv-sqrt:
[2023-07-01 11:23:37] [config]   - 16000
[2023-07-01 11:23:37] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:23:37] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:23:37] [config] lr-decay-start:
[2023-07-01 11:23:37] [config]   - 10
[2023-07-01 11:23:37] [config]   - 1
[2023-07-01 11:23:37] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:23:37] [config] lr-report: true
[2023-07-01 11:23:37] [config] lr-warmup: 16000
[2023-07-01 11:23:37] [config] lr-warmup-at-reload: false
[2023-07-01 11:23:37] [config] lr-warmup-cycle: false
[2023-07-01 11:23:37] [config] lr-warmup-start-rate: 0
[2023-07-01 11:23:37] [config] max-length: 100
[2023-07-01 11:23:37] [config] max-length-crop: false
[2023-07-01 11:23:37] [config] max-length-factor: 3
[2023-07-01 11:23:37] [config] maxi-batch: 100
[2023-07-01 11:23:37] [config] maxi-batch-sort: trg
[2023-07-01 11:23:37] [config] mini-batch: 1000
[2023-07-01 11:23:37] [config] mini-batch-fit: true
[2023-07-01 11:23:37] [config] mini-batch-fit-step: 10
[2023-07-01 11:23:37] [config] mini-batch-round-up: true
[2023-07-01 11:23:37] [config] mini-batch-track-lr: false
[2023-07-01 11:23:37] [config] mini-batch-warmup: 0
[2023-07-01 11:23:37] [config] mini-batch-words: 0
[2023-07-01 11:23:37] [config] mini-batch-words-ref: 0
[2023-07-01 11:23:37] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:23:37] [config] multi-loss-type: sum
[2023-07-01 11:23:37] [config] n-best: false
[2023-07-01 11:23:37] [config] no-nccl: false
[2023-07-01 11:23:37] [config] no-reload: false
[2023-07-01 11:23:37] [config] no-restore-corpus: false
[2023-07-01 11:23:37] [config] normalize: 1
[2023-07-01 11:23:37] [config] normalize-gradient: false
[2023-07-01 11:23:37] [config] num-devices: 0
[2023-07-01 11:23:37] [config] optimizer: adam
[2023-07-01 11:23:37] [config] optimizer-delay: 1
[2023-07-01 11:23:37] [config] optimizer-params:
[2023-07-01 11:23:37] [config]   - 0.9
[2023-07-01 11:23:37] [config]   - 0.98
[2023-07-01 11:23:37] [config]   - 1e-09
[2023-07-01 11:23:37] [config] output-omit-bias: false
[2023-07-01 11:23:37] [config] overwrite: true
[2023-07-01 11:23:37] [config] precision:
[2023-07-01 11:23:37] [config]   - float32
[2023-07-01 11:23:37] [config]   - float32
[2023-07-01 11:23:37] [config] pretrained-model: ""
[2023-07-01 11:23:37] [config] quantize-biases: false
[2023-07-01 11:23:37] [config] quantize-bits: 0
[2023-07-01 11:23:37] [config] quantize-log-based: false
[2023-07-01 11:23:37] [config] quantize-optimization-steps: 0
[2023-07-01 11:23:37] [config] quiet: false
[2023-07-01 11:23:37] [config] quiet-translation: true
[2023-07-01 11:23:37] [config] relative-paths: false
[2023-07-01 11:23:37] [config] right-left: false
[2023-07-01 11:23:37] [config] save-freq: 10000u
[2023-07-01 11:23:37] [config] seed: 1234
[2023-07-01 11:23:37] [config] sentencepiece-alphas:
[2023-07-01 11:23:37] [config]   []
[2023-07-01 11:23:37] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:23:37] [config] sentencepiece-options: ""
[2023-07-01 11:23:37] [config] sharding: global
[2023-07-01 11:23:37] [config] shuffle: data
[2023-07-01 11:23:37] [config] shuffle-in-ram: false
[2023-07-01 11:23:37] [config] sigterm: save-and-exit
[2023-07-01 11:23:37] [config] skip: false
[2023-07-01 11:23:37] [config] sqlite: ""
[2023-07-01 11:23:37] [config] sqlite-drop: false
[2023-07-01 11:23:37] [config] sync-freq: 200u
[2023-07-01 11:23:37] [config] sync-sgd: true
[2023-07-01 11:23:37] [config] tempdir: /tmp
[2023-07-01 11:23:37] [config] tied-embeddings: false
[2023-07-01 11:23:37] [config] tied-embeddings-all: true
[2023-07-01 11:23:37] [config] tied-embeddings-src: false
[2023-07-01 11:23:37] [config] train-embedder-rank:
[2023-07-01 11:23:37] [config]   []
[2023-07-01 11:23:37] [config] train-sets:
[2023-07-01 11:23:37] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:23:37] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:23:37] [config] transformer-aan-activation: swish
[2023-07-01 11:23:37] [config] transformer-aan-depth: 2
[2023-07-01 11:23:37] [config] transformer-aan-nogate: false
[2023-07-01 11:23:37] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:23:37] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:23:37] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:23:37] [config] transformer-depth-scaling: false
[2023-07-01 11:23:37] [config] transformer-dim-aan: 2048
[2023-07-01 11:23:37] [config] transformer-dim-ffn: 2048
[2023-07-01 11:23:37] [config] transformer-dropout: 0.1
[2023-07-01 11:23:37] [config] transformer-dropout-attention: 0
[2023-07-01 11:23:37] [config] transformer-dropout-ffn: 0
[2023-07-01 11:23:37] [config] transformer-ffn-activation: swish
[2023-07-01 11:23:37] [config] transformer-ffn-depth: 2
[2023-07-01 11:23:37] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:23:37] [config] transformer-heads: 8
[2023-07-01 11:23:37] [config] transformer-no-projection: false
[2023-07-01 11:23:37] [config] transformer-pool: false
[2023-07-01 11:23:37] [config] transformer-postprocess: dan
[2023-07-01 11:23:37] [config] transformer-postprocess-emb: d
[2023-07-01 11:23:37] [config] transformer-postprocess-top: ""
[2023-07-01 11:23:37] [config] transformer-preprocess: ""
[2023-07-01 11:23:37] [config] transformer-tied-layers:
[2023-07-01 11:23:37] [config]   []
[2023-07-01 11:23:37] [config] transformer-train-position-embeddings: false
[2023-07-01 11:23:37] [config] tsv: false
[2023-07-01 11:23:37] [config] tsv-fields: 0
[2023-07-01 11:23:37] [config] type: transformer
[2023-07-01 11:23:37] [config] ulr: false
[2023-07-01 11:23:37] [config] ulr-dim-emb: 0
[2023-07-01 11:23:37] [config] ulr-dropout: 0
[2023-07-01 11:23:37] [config] ulr-keys-vectors: ""
[2023-07-01 11:23:37] [config] ulr-query-vectors: ""
[2023-07-01 11:23:37] [config] ulr-softmax-temperature: 1
[2023-07-01 11:23:37] [config] ulr-trainable-transformation: false
[2023-07-01 11:23:37] [config] unlikelihood-loss: false
[2023-07-01 11:23:37] [config] valid-freq: 50000000
[2023-07-01 11:23:37] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:23:37] [config] valid-max-length: 1000
[2023-07-01 11:23:37] [config] valid-metrics:
[2023-07-01 11:23:37] [config]   - cross-entropy
[2023-07-01 11:23:37] [config]   - translation
[2023-07-01 11:23:37] [config] valid-mini-batch: 64
[2023-07-01 11:23:37] [config] valid-reset-stalled: false
[2023-07-01 11:23:37] [config] valid-script-args:
[2023-07-01 11:23:37] [config]   []
[2023-07-01 11:23:37] [config] valid-script-path: ""
[2023-07-01 11:23:37] [config] valid-sets:
[2023-07-01 11:23:37] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:23:37] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:23:37] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:23:37] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:23:37] [config] vocabs:
[2023-07-01 11:23:37] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:23:37] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:23:37] [config] word-penalty: 0
[2023-07-01 11:23:37] [config] word-scores: false
[2023-07-01 11:23:37] [config] workspace: 2048
[2023-07-01 11:23:37] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:23:37] Using synchronous SGD
[2023-07-01 11:23:37] Synced seed 1234
[2023-07-01 11:23:37] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:23:37] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:23:37] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:23:37] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:23:37] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:23:37] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:23:38] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:23:38] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:23:38] [comm] Using global sharding
[2023-07-01 11:23:38] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:23:38] [training] Using 1 GPUs
[2023-07-01 11:23:38] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:23:38] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:23:38] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:23:38] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:23:46] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:23:46] [valid] No post-processing script given for validating translator
[2023-07-01 11:23:46] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:23:46] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:23:46] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:23:46] [comm] Using global sharding
[2023-07-01 11:23:46] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:23:46] [training] Using 1 GPUs
[2023-07-01 11:23:46] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:23:46] Allocating memory for general optimizer shards
[2023-07-01 11:23:46] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:23:46] Loading Adam parameters
[2023-07-01 11:23:46] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:23:46] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:23:46] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:23:46] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:23:46] [data] Shuffling data
[2023-07-01 11:23:46] [data] Done reading 20,192 sentences
[2023-07-01 11:23:46] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:23:46] Training started
[2023-07-01 11:23:46] Training finished
[2023-07-01 11:23:50] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:23:50] [marian] Running on node20.datos.cluster.uy as process 14974 with command line:
[2023-07-01 11:23:50] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 66 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:23:50] [config] after: 0e
[2023-07-01 11:23:50] [config] after-batches: 0
[2023-07-01 11:23:50] [config] after-epochs: 66
[2023-07-01 11:23:50] [config] all-caps-every: 0
[2023-07-01 11:23:50] [config] allow-unk: false
[2023-07-01 11:23:50] [config] authors: false
[2023-07-01 11:23:50] [config] beam-size: 12
[2023-07-01 11:23:50] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:23:50] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:23:50] [config] bert-masking-fraction: 0.15
[2023-07-01 11:23:50] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:23:50] [config] bert-train-type-embeddings: true
[2023-07-01 11:23:50] [config] bert-type-vocab-size: 2
[2023-07-01 11:23:50] [config] build-info: ""
[2023-07-01 11:23:50] [config] check-gradient-nan: false
[2023-07-01 11:23:50] [config] check-nan: false
[2023-07-01 11:23:50] [config] cite: false
[2023-07-01 11:23:50] [config] clip-norm: 5
[2023-07-01 11:23:50] [config] cost-scaling:
[2023-07-01 11:23:50] [config]   []
[2023-07-01 11:23:50] [config] cost-type: ce-sum
[2023-07-01 11:23:50] [config] cpu-threads: 0
[2023-07-01 11:23:50] [config] data-threads: 8
[2023-07-01 11:23:50] [config] data-weighting: ""
[2023-07-01 11:23:50] [config] data-weighting-type: sentence
[2023-07-01 11:23:50] [config] dec-cell: gru
[2023-07-01 11:23:50] [config] dec-cell-base-depth: 2
[2023-07-01 11:23:50] [config] dec-cell-high-depth: 1
[2023-07-01 11:23:50] [config] dec-depth: 2
[2023-07-01 11:23:50] [config] devices:
[2023-07-01 11:23:50] [config]   - 0
[2023-07-01 11:23:50] [config] dim-emb: 512
[2023-07-01 11:23:50] [config] dim-rnn: 1024
[2023-07-01 11:23:50] [config] dim-vocabs:
[2023-07-01 11:23:50] [config]   - 16384
[2023-07-01 11:23:50] [config]   - 16384
[2023-07-01 11:23:50] [config] disp-first: 0
[2023-07-01 11:23:50] [config] disp-freq: 1000u
[2023-07-01 11:23:50] [config] disp-label-counts: true
[2023-07-01 11:23:50] [config] dropout-rnn: 0
[2023-07-01 11:23:50] [config] dropout-src: 0
[2023-07-01 11:23:50] [config] dropout-trg: 0
[2023-07-01 11:23:50] [config] dump-config: ""
[2023-07-01 11:23:50] [config] dynamic-gradient-scaling:
[2023-07-01 11:23:50] [config]   []
[2023-07-01 11:23:50] [config] early-stopping: 10
[2023-07-01 11:23:50] [config] early-stopping-on: first
[2023-07-01 11:23:50] [config] embedding-fix-src: false
[2023-07-01 11:23:50] [config] embedding-fix-trg: false
[2023-07-01 11:23:50] [config] embedding-normalization: false
[2023-07-01 11:23:50] [config] embedding-vectors:
[2023-07-01 11:23:50] [config]   []
[2023-07-01 11:23:50] [config] enc-cell: gru
[2023-07-01 11:23:50] [config] enc-cell-depth: 1
[2023-07-01 11:23:50] [config] enc-depth: 2
[2023-07-01 11:23:50] [config] enc-type: bidirectional
[2023-07-01 11:23:50] [config] english-title-case-every: 0
[2023-07-01 11:23:50] [config] exponential-smoothing: 0.0001
[2023-07-01 11:23:50] [config] factor-weight: 1
[2023-07-01 11:23:50] [config] factors-combine: sum
[2023-07-01 11:23:50] [config] factors-dim-emb: 0
[2023-07-01 11:23:50] [config] gradient-checkpointing: false
[2023-07-01 11:23:50] [config] gradient-norm-average-window: 100
[2023-07-01 11:23:50] [config] guided-alignment: none
[2023-07-01 11:23:50] [config] guided-alignment-cost: mse
[2023-07-01 11:23:50] [config] guided-alignment-weight: 0.1
[2023-07-01 11:23:50] [config] ignore-model-config: false
[2023-07-01 11:23:50] [config] input-types:
[2023-07-01 11:23:50] [config]   []
[2023-07-01 11:23:50] [config] interpolate-env-vars: false
[2023-07-01 11:23:50] [config] keep-best: false
[2023-07-01 11:23:50] [config] label-smoothing: 0.1
[2023-07-01 11:23:50] [config] layer-normalization: false
[2023-07-01 11:23:50] [config] learn-rate: 0.0003
[2023-07-01 11:23:50] [config] lemma-dependency: ""
[2023-07-01 11:23:50] [config] lemma-dim-emb: 0
[2023-07-01 11:23:50] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:23:50] [config] log-level: info
[2023-07-01 11:23:50] [config] log-time-zone: ""
[2023-07-01 11:23:50] [config] logical-epoch:
[2023-07-01 11:23:50] [config]   - 1e
[2023-07-01 11:23:50] [config]   - 0
[2023-07-01 11:23:50] [config] lr-decay: 0
[2023-07-01 11:23:50] [config] lr-decay-freq: 50000
[2023-07-01 11:23:50] [config] lr-decay-inv-sqrt:
[2023-07-01 11:23:50] [config]   - 16000
[2023-07-01 11:23:50] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:23:50] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:23:50] [config] lr-decay-start:
[2023-07-01 11:23:50] [config]   - 10
[2023-07-01 11:23:50] [config]   - 1
[2023-07-01 11:23:50] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:23:50] [config] lr-report: true
[2023-07-01 11:23:50] [config] lr-warmup: 16000
[2023-07-01 11:23:50] [config] lr-warmup-at-reload: false
[2023-07-01 11:23:50] [config] lr-warmup-cycle: false
[2023-07-01 11:23:50] [config] lr-warmup-start-rate: 0
[2023-07-01 11:23:50] [config] max-length: 100
[2023-07-01 11:23:50] [config] max-length-crop: false
[2023-07-01 11:23:50] [config] max-length-factor: 3
[2023-07-01 11:23:50] [config] maxi-batch: 100
[2023-07-01 11:23:50] [config] maxi-batch-sort: trg
[2023-07-01 11:23:50] [config] mini-batch: 1000
[2023-07-01 11:23:50] [config] mini-batch-fit: true
[2023-07-01 11:23:50] [config] mini-batch-fit-step: 10
[2023-07-01 11:23:50] [config] mini-batch-round-up: true
[2023-07-01 11:23:50] [config] mini-batch-track-lr: false
[2023-07-01 11:23:50] [config] mini-batch-warmup: 0
[2023-07-01 11:23:50] [config] mini-batch-words: 0
[2023-07-01 11:23:50] [config] mini-batch-words-ref: 0
[2023-07-01 11:23:50] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:23:50] [config] multi-loss-type: sum
[2023-07-01 11:23:50] [config] n-best: false
[2023-07-01 11:23:50] [config] no-nccl: false
[2023-07-01 11:23:50] [config] no-reload: false
[2023-07-01 11:23:50] [config] no-restore-corpus: false
[2023-07-01 11:23:50] [config] normalize: 1
[2023-07-01 11:23:50] [config] normalize-gradient: false
[2023-07-01 11:23:50] [config] num-devices: 0
[2023-07-01 11:23:50] [config] optimizer: adam
[2023-07-01 11:23:50] [config] optimizer-delay: 1
[2023-07-01 11:23:50] [config] optimizer-params:
[2023-07-01 11:23:50] [config]   - 0.9
[2023-07-01 11:23:50] [config]   - 0.98
[2023-07-01 11:23:50] [config]   - 1e-09
[2023-07-01 11:23:50] [config] output-omit-bias: false
[2023-07-01 11:23:50] [config] overwrite: true
[2023-07-01 11:23:50] [config] precision:
[2023-07-01 11:23:50] [config]   - float32
[2023-07-01 11:23:50] [config]   - float32
[2023-07-01 11:23:50] [config] pretrained-model: ""
[2023-07-01 11:23:50] [config] quantize-biases: false
[2023-07-01 11:23:50] [config] quantize-bits: 0
[2023-07-01 11:23:50] [config] quantize-log-based: false
[2023-07-01 11:23:50] [config] quantize-optimization-steps: 0
[2023-07-01 11:23:50] [config] quiet: false
[2023-07-01 11:23:50] [config] quiet-translation: true
[2023-07-01 11:23:50] [config] relative-paths: false
[2023-07-01 11:23:50] [config] right-left: false
[2023-07-01 11:23:50] [config] save-freq: 10000u
[2023-07-01 11:23:50] [config] seed: 1234
[2023-07-01 11:23:50] [config] sentencepiece-alphas:
[2023-07-01 11:23:50] [config]   []
[2023-07-01 11:23:50] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:23:50] [config] sentencepiece-options: ""
[2023-07-01 11:23:50] [config] sharding: global
[2023-07-01 11:23:50] [config] shuffle: data
[2023-07-01 11:23:50] [config] shuffle-in-ram: false
[2023-07-01 11:23:50] [config] sigterm: save-and-exit
[2023-07-01 11:23:50] [config] skip: false
[2023-07-01 11:23:50] [config] sqlite: ""
[2023-07-01 11:23:50] [config] sqlite-drop: false
[2023-07-01 11:23:50] [config] sync-freq: 200u
[2023-07-01 11:23:50] [config] sync-sgd: true
[2023-07-01 11:23:50] [config] tempdir: /tmp
[2023-07-01 11:23:50] [config] tied-embeddings: false
[2023-07-01 11:23:50] [config] tied-embeddings-all: true
[2023-07-01 11:23:50] [config] tied-embeddings-src: false
[2023-07-01 11:23:50] [config] train-embedder-rank:
[2023-07-01 11:23:50] [config]   []
[2023-07-01 11:23:50] [config] train-sets:
[2023-07-01 11:23:50] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:23:50] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:23:50] [config] transformer-aan-activation: swish
[2023-07-01 11:23:50] [config] transformer-aan-depth: 2
[2023-07-01 11:23:50] [config] transformer-aan-nogate: false
[2023-07-01 11:23:50] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:23:50] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:23:50] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:23:50] [config] transformer-depth-scaling: false
[2023-07-01 11:23:50] [config] transformer-dim-aan: 2048
[2023-07-01 11:23:50] [config] transformer-dim-ffn: 2048
[2023-07-01 11:23:50] [config] transformer-dropout: 0.1
[2023-07-01 11:23:50] [config] transformer-dropout-attention: 0
[2023-07-01 11:23:50] [config] transformer-dropout-ffn: 0
[2023-07-01 11:23:50] [config] transformer-ffn-activation: swish
[2023-07-01 11:23:50] [config] transformer-ffn-depth: 2
[2023-07-01 11:23:50] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:23:50] [config] transformer-heads: 8
[2023-07-01 11:23:50] [config] transformer-no-projection: false
[2023-07-01 11:23:50] [config] transformer-pool: false
[2023-07-01 11:23:50] [config] transformer-postprocess: dan
[2023-07-01 11:23:50] [config] transformer-postprocess-emb: d
[2023-07-01 11:23:50] [config] transformer-postprocess-top: ""
[2023-07-01 11:23:50] [config] transformer-preprocess: ""
[2023-07-01 11:23:50] [config] transformer-tied-layers:
[2023-07-01 11:23:50] [config]   []
[2023-07-01 11:23:50] [config] transformer-train-position-embeddings: false
[2023-07-01 11:23:50] [config] tsv: false
[2023-07-01 11:23:50] [config] tsv-fields: 0
[2023-07-01 11:23:50] [config] type: transformer
[2023-07-01 11:23:50] [config] ulr: false
[2023-07-01 11:23:50] [config] ulr-dim-emb: 0
[2023-07-01 11:23:50] [config] ulr-dropout: 0
[2023-07-01 11:23:50] [config] ulr-keys-vectors: ""
[2023-07-01 11:23:50] [config] ulr-query-vectors: ""
[2023-07-01 11:23:50] [config] ulr-softmax-temperature: 1
[2023-07-01 11:23:50] [config] ulr-trainable-transformation: false
[2023-07-01 11:23:50] [config] unlikelihood-loss: false
[2023-07-01 11:23:50] [config] valid-freq: 50000000
[2023-07-01 11:23:50] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:23:50] [config] valid-max-length: 1000
[2023-07-01 11:23:50] [config] valid-metrics:
[2023-07-01 11:23:50] [config]   - cross-entropy
[2023-07-01 11:23:50] [config]   - translation
[2023-07-01 11:23:50] [config] valid-mini-batch: 64
[2023-07-01 11:23:50] [config] valid-reset-stalled: false
[2023-07-01 11:23:50] [config] valid-script-args:
[2023-07-01 11:23:50] [config]   []
[2023-07-01 11:23:50] [config] valid-script-path: ""
[2023-07-01 11:23:50] [config] valid-sets:
[2023-07-01 11:23:50] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:23:50] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:23:50] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:23:50] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:23:50] [config] vocabs:
[2023-07-01 11:23:50] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:23:50] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:23:50] [config] word-penalty: 0
[2023-07-01 11:23:50] [config] word-scores: false
[2023-07-01 11:23:50] [config] workspace: 2048
[2023-07-01 11:23:50] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:23:50] Using synchronous SGD
[2023-07-01 11:23:50] Synced seed 1234
[2023-07-01 11:23:50] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:23:51] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:23:51] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:23:51] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:23:51] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:23:51] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:23:51] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:23:51] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:23:51] [comm] Using global sharding
[2023-07-01 11:23:51] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:23:51] [training] Using 1 GPUs
[2023-07-01 11:23:51] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:23:51] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:23:52] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:23:52] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:23:59] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:23:59] [valid] No post-processing script given for validating translator
[2023-07-01 11:23:59] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:23:59] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:23:59] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:23:59] [comm] Using global sharding
[2023-07-01 11:23:59] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:23:59] [training] Using 1 GPUs
[2023-07-01 11:23:59] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:24:00] Allocating memory for general optimizer shards
[2023-07-01 11:24:00] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:24:00] Loading Adam parameters
[2023-07-01 11:24:00] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:24:00] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:24:00] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:24:00] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:24:00] [data] Shuffling data
[2023-07-01 11:24:00] [data] Done reading 20,192 sentences
[2023-07-01 11:24:00] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:24:00] Training started
[2023-07-01 11:24:00] Training finished
[2023-07-01 11:24:04] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:24:04] [marian] Running on node20.datos.cluster.uy as process 15032 with command line:
[2023-07-01 11:24:04] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 67 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:24:04] [config] after: 0e
[2023-07-01 11:24:04] [config] after-batches: 0
[2023-07-01 11:24:04] [config] after-epochs: 67
[2023-07-01 11:24:04] [config] all-caps-every: 0
[2023-07-01 11:24:04] [config] allow-unk: false
[2023-07-01 11:24:04] [config] authors: false
[2023-07-01 11:24:04] [config] beam-size: 12
[2023-07-01 11:24:04] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:24:04] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:24:04] [config] bert-masking-fraction: 0.15
[2023-07-01 11:24:04] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:24:04] [config] bert-train-type-embeddings: true
[2023-07-01 11:24:04] [config] bert-type-vocab-size: 2
[2023-07-01 11:24:04] [config] build-info: ""
[2023-07-01 11:24:04] [config] check-gradient-nan: false
[2023-07-01 11:24:04] [config] check-nan: false
[2023-07-01 11:24:04] [config] cite: false
[2023-07-01 11:24:04] [config] clip-norm: 5
[2023-07-01 11:24:04] [config] cost-scaling:
[2023-07-01 11:24:04] [config]   []
[2023-07-01 11:24:04] [config] cost-type: ce-sum
[2023-07-01 11:24:04] [config] cpu-threads: 0
[2023-07-01 11:24:04] [config] data-threads: 8
[2023-07-01 11:24:04] [config] data-weighting: ""
[2023-07-01 11:24:04] [config] data-weighting-type: sentence
[2023-07-01 11:24:04] [config] dec-cell: gru
[2023-07-01 11:24:04] [config] dec-cell-base-depth: 2
[2023-07-01 11:24:04] [config] dec-cell-high-depth: 1
[2023-07-01 11:24:04] [config] dec-depth: 2
[2023-07-01 11:24:04] [config] devices:
[2023-07-01 11:24:04] [config]   - 0
[2023-07-01 11:24:04] [config] dim-emb: 512
[2023-07-01 11:24:04] [config] dim-rnn: 1024
[2023-07-01 11:24:04] [config] dim-vocabs:
[2023-07-01 11:24:04] [config]   - 16384
[2023-07-01 11:24:04] [config]   - 16384
[2023-07-01 11:24:04] [config] disp-first: 0
[2023-07-01 11:24:04] [config] disp-freq: 1000u
[2023-07-01 11:24:04] [config] disp-label-counts: true
[2023-07-01 11:24:04] [config] dropout-rnn: 0
[2023-07-01 11:24:04] [config] dropout-src: 0
[2023-07-01 11:24:04] [config] dropout-trg: 0
[2023-07-01 11:24:04] [config] dump-config: ""
[2023-07-01 11:24:04] [config] dynamic-gradient-scaling:
[2023-07-01 11:24:04] [config]   []
[2023-07-01 11:24:04] [config] early-stopping: 10
[2023-07-01 11:24:04] [config] early-stopping-on: first
[2023-07-01 11:24:04] [config] embedding-fix-src: false
[2023-07-01 11:24:04] [config] embedding-fix-trg: false
[2023-07-01 11:24:04] [config] embedding-normalization: false
[2023-07-01 11:24:04] [config] embedding-vectors:
[2023-07-01 11:24:04] [config]   []
[2023-07-01 11:24:04] [config] enc-cell: gru
[2023-07-01 11:24:04] [config] enc-cell-depth: 1
[2023-07-01 11:24:04] [config] enc-depth: 2
[2023-07-01 11:24:04] [config] enc-type: bidirectional
[2023-07-01 11:24:04] [config] english-title-case-every: 0
[2023-07-01 11:24:04] [config] exponential-smoothing: 0.0001
[2023-07-01 11:24:04] [config] factor-weight: 1
[2023-07-01 11:24:04] [config] factors-combine: sum
[2023-07-01 11:24:04] [config] factors-dim-emb: 0
[2023-07-01 11:24:04] [config] gradient-checkpointing: false
[2023-07-01 11:24:04] [config] gradient-norm-average-window: 100
[2023-07-01 11:24:04] [config] guided-alignment: none
[2023-07-01 11:24:04] [config] guided-alignment-cost: mse
[2023-07-01 11:24:04] [config] guided-alignment-weight: 0.1
[2023-07-01 11:24:04] [config] ignore-model-config: false
[2023-07-01 11:24:04] [config] input-types:
[2023-07-01 11:24:04] [config]   []
[2023-07-01 11:24:04] [config] interpolate-env-vars: false
[2023-07-01 11:24:04] [config] keep-best: false
[2023-07-01 11:24:04] [config] label-smoothing: 0.1
[2023-07-01 11:24:04] [config] layer-normalization: false
[2023-07-01 11:24:04] [config] learn-rate: 0.0003
[2023-07-01 11:24:04] [config] lemma-dependency: ""
[2023-07-01 11:24:04] [config] lemma-dim-emb: 0
[2023-07-01 11:24:04] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:24:04] [config] log-level: info
[2023-07-01 11:24:04] [config] log-time-zone: ""
[2023-07-01 11:24:04] [config] logical-epoch:
[2023-07-01 11:24:04] [config]   - 1e
[2023-07-01 11:24:04] [config]   - 0
[2023-07-01 11:24:04] [config] lr-decay: 0
[2023-07-01 11:24:04] [config] lr-decay-freq: 50000
[2023-07-01 11:24:04] [config] lr-decay-inv-sqrt:
[2023-07-01 11:24:04] [config]   - 16000
[2023-07-01 11:24:04] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:24:04] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:24:04] [config] lr-decay-start:
[2023-07-01 11:24:04] [config]   - 10
[2023-07-01 11:24:04] [config]   - 1
[2023-07-01 11:24:04] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:24:04] [config] lr-report: true
[2023-07-01 11:24:04] [config] lr-warmup: 16000
[2023-07-01 11:24:04] [config] lr-warmup-at-reload: false
[2023-07-01 11:24:04] [config] lr-warmup-cycle: false
[2023-07-01 11:24:04] [config] lr-warmup-start-rate: 0
[2023-07-01 11:24:04] [config] max-length: 100
[2023-07-01 11:24:04] [config] max-length-crop: false
[2023-07-01 11:24:04] [config] max-length-factor: 3
[2023-07-01 11:24:04] [config] maxi-batch: 100
[2023-07-01 11:24:04] [config] maxi-batch-sort: trg
[2023-07-01 11:24:04] [config] mini-batch: 1000
[2023-07-01 11:24:04] [config] mini-batch-fit: true
[2023-07-01 11:24:04] [config] mini-batch-fit-step: 10
[2023-07-01 11:24:04] [config] mini-batch-round-up: true
[2023-07-01 11:24:04] [config] mini-batch-track-lr: false
[2023-07-01 11:24:04] [config] mini-batch-warmup: 0
[2023-07-01 11:24:04] [config] mini-batch-words: 0
[2023-07-01 11:24:04] [config] mini-batch-words-ref: 0
[2023-07-01 11:24:04] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:24:04] [config] multi-loss-type: sum
[2023-07-01 11:24:04] [config] n-best: false
[2023-07-01 11:24:04] [config] no-nccl: false
[2023-07-01 11:24:04] [config] no-reload: false
[2023-07-01 11:24:04] [config] no-restore-corpus: false
[2023-07-01 11:24:04] [config] normalize: 1
[2023-07-01 11:24:04] [config] normalize-gradient: false
[2023-07-01 11:24:04] [config] num-devices: 0
[2023-07-01 11:24:04] [config] optimizer: adam
[2023-07-01 11:24:04] [config] optimizer-delay: 1
[2023-07-01 11:24:04] [config] optimizer-params:
[2023-07-01 11:24:04] [config]   - 0.9
[2023-07-01 11:24:04] [config]   - 0.98
[2023-07-01 11:24:04] [config]   - 1e-09
[2023-07-01 11:24:04] [config] output-omit-bias: false
[2023-07-01 11:24:04] [config] overwrite: true
[2023-07-01 11:24:04] [config] precision:
[2023-07-01 11:24:04] [config]   - float32
[2023-07-01 11:24:04] [config]   - float32
[2023-07-01 11:24:04] [config] pretrained-model: ""
[2023-07-01 11:24:04] [config] quantize-biases: false
[2023-07-01 11:24:04] [config] quantize-bits: 0
[2023-07-01 11:24:04] [config] quantize-log-based: false
[2023-07-01 11:24:04] [config] quantize-optimization-steps: 0
[2023-07-01 11:24:04] [config] quiet: false
[2023-07-01 11:24:04] [config] quiet-translation: true
[2023-07-01 11:24:04] [config] relative-paths: false
[2023-07-01 11:24:04] [config] right-left: false
[2023-07-01 11:24:04] [config] save-freq: 10000u
[2023-07-01 11:24:04] [config] seed: 1234
[2023-07-01 11:24:04] [config] sentencepiece-alphas:
[2023-07-01 11:24:04] [config]   []
[2023-07-01 11:24:04] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:24:04] [config] sentencepiece-options: ""
[2023-07-01 11:24:04] [config] sharding: global
[2023-07-01 11:24:04] [config] shuffle: data
[2023-07-01 11:24:04] [config] shuffle-in-ram: false
[2023-07-01 11:24:04] [config] sigterm: save-and-exit
[2023-07-01 11:24:04] [config] skip: false
[2023-07-01 11:24:04] [config] sqlite: ""
[2023-07-01 11:24:04] [config] sqlite-drop: false
[2023-07-01 11:24:04] [config] sync-freq: 200u
[2023-07-01 11:24:04] [config] sync-sgd: true
[2023-07-01 11:24:04] [config] tempdir: /tmp
[2023-07-01 11:24:04] [config] tied-embeddings: false
[2023-07-01 11:24:04] [config] tied-embeddings-all: true
[2023-07-01 11:24:04] [config] tied-embeddings-src: false
[2023-07-01 11:24:04] [config] train-embedder-rank:
[2023-07-01 11:24:04] [config]   []
[2023-07-01 11:24:04] [config] train-sets:
[2023-07-01 11:24:04] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:24:04] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:24:04] [config] transformer-aan-activation: swish
[2023-07-01 11:24:04] [config] transformer-aan-depth: 2
[2023-07-01 11:24:04] [config] transformer-aan-nogate: false
[2023-07-01 11:24:04] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:24:04] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:24:04] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:24:04] [config] transformer-depth-scaling: false
[2023-07-01 11:24:04] [config] transformer-dim-aan: 2048
[2023-07-01 11:24:04] [config] transformer-dim-ffn: 2048
[2023-07-01 11:24:04] [config] transformer-dropout: 0.1
[2023-07-01 11:24:04] [config] transformer-dropout-attention: 0
[2023-07-01 11:24:04] [config] transformer-dropout-ffn: 0
[2023-07-01 11:24:04] [config] transformer-ffn-activation: swish
[2023-07-01 11:24:04] [config] transformer-ffn-depth: 2
[2023-07-01 11:24:04] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:24:04] [config] transformer-heads: 8
[2023-07-01 11:24:04] [config] transformer-no-projection: false
[2023-07-01 11:24:04] [config] transformer-pool: false
[2023-07-01 11:24:04] [config] transformer-postprocess: dan
[2023-07-01 11:24:04] [config] transformer-postprocess-emb: d
[2023-07-01 11:24:04] [config] transformer-postprocess-top: ""
[2023-07-01 11:24:04] [config] transformer-preprocess: ""
[2023-07-01 11:24:04] [config] transformer-tied-layers:
[2023-07-01 11:24:04] [config]   []
[2023-07-01 11:24:04] [config] transformer-train-position-embeddings: false
[2023-07-01 11:24:04] [config] tsv: false
[2023-07-01 11:24:04] [config] tsv-fields: 0
[2023-07-01 11:24:04] [config] type: transformer
[2023-07-01 11:24:04] [config] ulr: false
[2023-07-01 11:24:04] [config] ulr-dim-emb: 0
[2023-07-01 11:24:04] [config] ulr-dropout: 0
[2023-07-01 11:24:04] [config] ulr-keys-vectors: ""
[2023-07-01 11:24:04] [config] ulr-query-vectors: ""
[2023-07-01 11:24:04] [config] ulr-softmax-temperature: 1
[2023-07-01 11:24:04] [config] ulr-trainable-transformation: false
[2023-07-01 11:24:04] [config] unlikelihood-loss: false
[2023-07-01 11:24:04] [config] valid-freq: 50000000
[2023-07-01 11:24:04] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:24:04] [config] valid-max-length: 1000
[2023-07-01 11:24:04] [config] valid-metrics:
[2023-07-01 11:24:04] [config]   - cross-entropy
[2023-07-01 11:24:04] [config]   - translation
[2023-07-01 11:24:04] [config] valid-mini-batch: 64
[2023-07-01 11:24:04] [config] valid-reset-stalled: false
[2023-07-01 11:24:04] [config] valid-script-args:
[2023-07-01 11:24:04] [config]   []
[2023-07-01 11:24:04] [config] valid-script-path: ""
[2023-07-01 11:24:04] [config] valid-sets:
[2023-07-01 11:24:04] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:24:04] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:24:04] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:24:04] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:24:04] [config] vocabs:
[2023-07-01 11:24:04] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:24:04] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:24:04] [config] word-penalty: 0
[2023-07-01 11:24:04] [config] word-scores: false
[2023-07-01 11:24:04] [config] workspace: 2048
[2023-07-01 11:24:04] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:24:04] Using synchronous SGD
[2023-07-01 11:24:04] Synced seed 1234
[2023-07-01 11:24:04] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:24:04] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:24:04] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:24:04] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:24:04] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:24:04] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:24:05] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:24:05] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:24:05] [comm] Using global sharding
[2023-07-01 11:24:05] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:24:05] [training] Using 1 GPUs
[2023-07-01 11:24:05] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:24:05] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:24:05] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:24:05] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:24:13] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:24:13] [valid] No post-processing script given for validating translator
[2023-07-01 11:24:13] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:24:13] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:24:13] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:24:13] [comm] Using global sharding
[2023-07-01 11:24:13] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:24:13] [training] Using 1 GPUs
[2023-07-01 11:24:13] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:24:14] Allocating memory for general optimizer shards
[2023-07-01 11:24:14] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:24:14] Loading Adam parameters
[2023-07-01 11:24:14] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:24:14] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:24:14] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:24:14] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:24:14] [data] Shuffling data
[2023-07-01 11:24:14] [data] Done reading 20,192 sentences
[2023-07-01 11:24:14] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:24:14] Training started
[2023-07-01 11:24:14] Training finished
[2023-07-01 11:24:18] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:24:18] [marian] Running on node20.datos.cluster.uy as process 15091 with command line:
[2023-07-01 11:24:18] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 68 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:24:18] [config] after: 0e
[2023-07-01 11:24:18] [config] after-batches: 0
[2023-07-01 11:24:18] [config] after-epochs: 68
[2023-07-01 11:24:18] [config] all-caps-every: 0
[2023-07-01 11:24:18] [config] allow-unk: false
[2023-07-01 11:24:18] [config] authors: false
[2023-07-01 11:24:18] [config] beam-size: 12
[2023-07-01 11:24:18] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:24:18] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:24:18] [config] bert-masking-fraction: 0.15
[2023-07-01 11:24:18] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:24:18] [config] bert-train-type-embeddings: true
[2023-07-01 11:24:18] [config] bert-type-vocab-size: 2
[2023-07-01 11:24:18] [config] build-info: ""
[2023-07-01 11:24:18] [config] check-gradient-nan: false
[2023-07-01 11:24:18] [config] check-nan: false
[2023-07-01 11:24:18] [config] cite: false
[2023-07-01 11:24:18] [config] clip-norm: 5
[2023-07-01 11:24:18] [config] cost-scaling:
[2023-07-01 11:24:18] [config]   []
[2023-07-01 11:24:18] [config] cost-type: ce-sum
[2023-07-01 11:24:18] [config] cpu-threads: 0
[2023-07-01 11:24:18] [config] data-threads: 8
[2023-07-01 11:24:18] [config] data-weighting: ""
[2023-07-01 11:24:18] [config] data-weighting-type: sentence
[2023-07-01 11:24:18] [config] dec-cell: gru
[2023-07-01 11:24:18] [config] dec-cell-base-depth: 2
[2023-07-01 11:24:18] [config] dec-cell-high-depth: 1
[2023-07-01 11:24:18] [config] dec-depth: 2
[2023-07-01 11:24:18] [config] devices:
[2023-07-01 11:24:18] [config]   - 0
[2023-07-01 11:24:18] [config] dim-emb: 512
[2023-07-01 11:24:18] [config] dim-rnn: 1024
[2023-07-01 11:24:18] [config] dim-vocabs:
[2023-07-01 11:24:18] [config]   - 16384
[2023-07-01 11:24:18] [config]   - 16384
[2023-07-01 11:24:18] [config] disp-first: 0
[2023-07-01 11:24:18] [config] disp-freq: 1000u
[2023-07-01 11:24:18] [config] disp-label-counts: true
[2023-07-01 11:24:18] [config] dropout-rnn: 0
[2023-07-01 11:24:18] [config] dropout-src: 0
[2023-07-01 11:24:18] [config] dropout-trg: 0
[2023-07-01 11:24:18] [config] dump-config: ""
[2023-07-01 11:24:18] [config] dynamic-gradient-scaling:
[2023-07-01 11:24:18] [config]   []
[2023-07-01 11:24:18] [config] early-stopping: 10
[2023-07-01 11:24:18] [config] early-stopping-on: first
[2023-07-01 11:24:18] [config] embedding-fix-src: false
[2023-07-01 11:24:18] [config] embedding-fix-trg: false
[2023-07-01 11:24:18] [config] embedding-normalization: false
[2023-07-01 11:24:18] [config] embedding-vectors:
[2023-07-01 11:24:18] [config]   []
[2023-07-01 11:24:18] [config] enc-cell: gru
[2023-07-01 11:24:18] [config] enc-cell-depth: 1
[2023-07-01 11:24:18] [config] enc-depth: 2
[2023-07-01 11:24:18] [config] enc-type: bidirectional
[2023-07-01 11:24:18] [config] english-title-case-every: 0
[2023-07-01 11:24:18] [config] exponential-smoothing: 0.0001
[2023-07-01 11:24:18] [config] factor-weight: 1
[2023-07-01 11:24:18] [config] factors-combine: sum
[2023-07-01 11:24:18] [config] factors-dim-emb: 0
[2023-07-01 11:24:18] [config] gradient-checkpointing: false
[2023-07-01 11:24:18] [config] gradient-norm-average-window: 100
[2023-07-01 11:24:18] [config] guided-alignment: none
[2023-07-01 11:24:18] [config] guided-alignment-cost: mse
[2023-07-01 11:24:18] [config] guided-alignment-weight: 0.1
[2023-07-01 11:24:18] [config] ignore-model-config: false
[2023-07-01 11:24:18] [config] input-types:
[2023-07-01 11:24:18] [config]   []
[2023-07-01 11:24:18] [config] interpolate-env-vars: false
[2023-07-01 11:24:18] [config] keep-best: false
[2023-07-01 11:24:18] [config] label-smoothing: 0.1
[2023-07-01 11:24:18] [config] layer-normalization: false
[2023-07-01 11:24:18] [config] learn-rate: 0.0003
[2023-07-01 11:24:18] [config] lemma-dependency: ""
[2023-07-01 11:24:18] [config] lemma-dim-emb: 0
[2023-07-01 11:24:18] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:24:18] [config] log-level: info
[2023-07-01 11:24:18] [config] log-time-zone: ""
[2023-07-01 11:24:18] [config] logical-epoch:
[2023-07-01 11:24:18] [config]   - 1e
[2023-07-01 11:24:18] [config]   - 0
[2023-07-01 11:24:18] [config] lr-decay: 0
[2023-07-01 11:24:18] [config] lr-decay-freq: 50000
[2023-07-01 11:24:18] [config] lr-decay-inv-sqrt:
[2023-07-01 11:24:18] [config]   - 16000
[2023-07-01 11:24:18] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:24:18] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:24:18] [config] lr-decay-start:
[2023-07-01 11:24:18] [config]   - 10
[2023-07-01 11:24:18] [config]   - 1
[2023-07-01 11:24:18] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:24:18] [config] lr-report: true
[2023-07-01 11:24:18] [config] lr-warmup: 16000
[2023-07-01 11:24:18] [config] lr-warmup-at-reload: false
[2023-07-01 11:24:18] [config] lr-warmup-cycle: false
[2023-07-01 11:24:18] [config] lr-warmup-start-rate: 0
[2023-07-01 11:24:18] [config] max-length: 100
[2023-07-01 11:24:18] [config] max-length-crop: false
[2023-07-01 11:24:18] [config] max-length-factor: 3
[2023-07-01 11:24:18] [config] maxi-batch: 100
[2023-07-01 11:24:18] [config] maxi-batch-sort: trg
[2023-07-01 11:24:18] [config] mini-batch: 1000
[2023-07-01 11:24:18] [config] mini-batch-fit: true
[2023-07-01 11:24:18] [config] mini-batch-fit-step: 10
[2023-07-01 11:24:18] [config] mini-batch-round-up: true
[2023-07-01 11:24:18] [config] mini-batch-track-lr: false
[2023-07-01 11:24:18] [config] mini-batch-warmup: 0
[2023-07-01 11:24:18] [config] mini-batch-words: 0
[2023-07-01 11:24:18] [config] mini-batch-words-ref: 0
[2023-07-01 11:24:18] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:24:18] [config] multi-loss-type: sum
[2023-07-01 11:24:18] [config] n-best: false
[2023-07-01 11:24:18] [config] no-nccl: false
[2023-07-01 11:24:18] [config] no-reload: false
[2023-07-01 11:24:18] [config] no-restore-corpus: false
[2023-07-01 11:24:18] [config] normalize: 1
[2023-07-01 11:24:18] [config] normalize-gradient: false
[2023-07-01 11:24:18] [config] num-devices: 0
[2023-07-01 11:24:18] [config] optimizer: adam
[2023-07-01 11:24:18] [config] optimizer-delay: 1
[2023-07-01 11:24:18] [config] optimizer-params:
[2023-07-01 11:24:18] [config]   - 0.9
[2023-07-01 11:24:18] [config]   - 0.98
[2023-07-01 11:24:18] [config]   - 1e-09
[2023-07-01 11:24:18] [config] output-omit-bias: false
[2023-07-01 11:24:18] [config] overwrite: true
[2023-07-01 11:24:18] [config] precision:
[2023-07-01 11:24:18] [config]   - float32
[2023-07-01 11:24:18] [config]   - float32
[2023-07-01 11:24:18] [config] pretrained-model: ""
[2023-07-01 11:24:18] [config] quantize-biases: false
[2023-07-01 11:24:18] [config] quantize-bits: 0
[2023-07-01 11:24:18] [config] quantize-log-based: false
[2023-07-01 11:24:18] [config] quantize-optimization-steps: 0
[2023-07-01 11:24:18] [config] quiet: false
[2023-07-01 11:24:18] [config] quiet-translation: true
[2023-07-01 11:24:18] [config] relative-paths: false
[2023-07-01 11:24:18] [config] right-left: false
[2023-07-01 11:24:18] [config] save-freq: 10000u
[2023-07-01 11:24:18] [config] seed: 1234
[2023-07-01 11:24:18] [config] sentencepiece-alphas:
[2023-07-01 11:24:18] [config]   []
[2023-07-01 11:24:18] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:24:18] [config] sentencepiece-options: ""
[2023-07-01 11:24:18] [config] sharding: global
[2023-07-01 11:24:18] [config] shuffle: data
[2023-07-01 11:24:18] [config] shuffle-in-ram: false
[2023-07-01 11:24:18] [config] sigterm: save-and-exit
[2023-07-01 11:24:18] [config] skip: false
[2023-07-01 11:24:18] [config] sqlite: ""
[2023-07-01 11:24:18] [config] sqlite-drop: false
[2023-07-01 11:24:18] [config] sync-freq: 200u
[2023-07-01 11:24:18] [config] sync-sgd: true
[2023-07-01 11:24:18] [config] tempdir: /tmp
[2023-07-01 11:24:18] [config] tied-embeddings: false
[2023-07-01 11:24:18] [config] tied-embeddings-all: true
[2023-07-01 11:24:18] [config] tied-embeddings-src: false
[2023-07-01 11:24:18] [config] train-embedder-rank:
[2023-07-01 11:24:18] [config]   []
[2023-07-01 11:24:18] [config] train-sets:
[2023-07-01 11:24:18] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:24:18] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:24:18] [config] transformer-aan-activation: swish
[2023-07-01 11:24:18] [config] transformer-aan-depth: 2
[2023-07-01 11:24:18] [config] transformer-aan-nogate: false
[2023-07-01 11:24:18] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:24:18] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:24:18] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:24:18] [config] transformer-depth-scaling: false
[2023-07-01 11:24:18] [config] transformer-dim-aan: 2048
[2023-07-01 11:24:18] [config] transformer-dim-ffn: 2048
[2023-07-01 11:24:18] [config] transformer-dropout: 0.1
[2023-07-01 11:24:18] [config] transformer-dropout-attention: 0
[2023-07-01 11:24:18] [config] transformer-dropout-ffn: 0
[2023-07-01 11:24:18] [config] transformer-ffn-activation: swish
[2023-07-01 11:24:18] [config] transformer-ffn-depth: 2
[2023-07-01 11:24:18] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:24:18] [config] transformer-heads: 8
[2023-07-01 11:24:18] [config] transformer-no-projection: false
[2023-07-01 11:24:18] [config] transformer-pool: false
[2023-07-01 11:24:18] [config] transformer-postprocess: dan
[2023-07-01 11:24:18] [config] transformer-postprocess-emb: d
[2023-07-01 11:24:18] [config] transformer-postprocess-top: ""
[2023-07-01 11:24:18] [config] transformer-preprocess: ""
[2023-07-01 11:24:18] [config] transformer-tied-layers:
[2023-07-01 11:24:18] [config]   []
[2023-07-01 11:24:18] [config] transformer-train-position-embeddings: false
[2023-07-01 11:24:18] [config] tsv: false
[2023-07-01 11:24:18] [config] tsv-fields: 0
[2023-07-01 11:24:18] [config] type: transformer
[2023-07-01 11:24:18] [config] ulr: false
[2023-07-01 11:24:18] [config] ulr-dim-emb: 0
[2023-07-01 11:24:18] [config] ulr-dropout: 0
[2023-07-01 11:24:18] [config] ulr-keys-vectors: ""
[2023-07-01 11:24:18] [config] ulr-query-vectors: ""
[2023-07-01 11:24:18] [config] ulr-softmax-temperature: 1
[2023-07-01 11:24:18] [config] ulr-trainable-transformation: false
[2023-07-01 11:24:18] [config] unlikelihood-loss: false
[2023-07-01 11:24:18] [config] valid-freq: 50000000
[2023-07-01 11:24:18] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:24:18] [config] valid-max-length: 1000
[2023-07-01 11:24:18] [config] valid-metrics:
[2023-07-01 11:24:18] [config]   - cross-entropy
[2023-07-01 11:24:18] [config]   - translation
[2023-07-01 11:24:18] [config] valid-mini-batch: 64
[2023-07-01 11:24:18] [config] valid-reset-stalled: false
[2023-07-01 11:24:18] [config] valid-script-args:
[2023-07-01 11:24:18] [config]   []
[2023-07-01 11:24:18] [config] valid-script-path: ""
[2023-07-01 11:24:18] [config] valid-sets:
[2023-07-01 11:24:18] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:24:18] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:24:18] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:24:18] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:24:18] [config] vocabs:
[2023-07-01 11:24:18] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:24:18] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:24:18] [config] word-penalty: 0
[2023-07-01 11:24:18] [config] word-scores: false
[2023-07-01 11:24:18] [config] workspace: 2048
[2023-07-01 11:24:18] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:24:18] Using synchronous SGD
[2023-07-01 11:24:18] Synced seed 1234
[2023-07-01 11:24:18] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:24:18] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:24:18] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:24:18] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:24:18] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:24:18] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:24:19] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:24:19] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:24:19] [comm] Using global sharding
[2023-07-01 11:24:19] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:24:19] [training] Using 1 GPUs
[2023-07-01 11:24:19] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:24:19] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:24:19] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:24:19] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:24:27] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:24:27] [valid] No post-processing script given for validating translator
[2023-07-01 11:24:27] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:24:27] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:24:27] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:24:27] [comm] Using global sharding
[2023-07-01 11:24:27] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:24:27] [training] Using 1 GPUs
[2023-07-01 11:24:27] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:24:28] Allocating memory for general optimizer shards
[2023-07-01 11:24:28] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:24:28] Loading Adam parameters
[2023-07-01 11:24:28] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:24:28] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:24:28] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:24:28] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:24:28] [data] Shuffling data
[2023-07-01 11:24:28] [data] Done reading 20,192 sentences
[2023-07-01 11:24:28] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:24:28] Training started
[2023-07-01 11:24:28] Training finished
[2023-07-01 11:24:31] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:24:31] [marian] Running on node20.datos.cluster.uy as process 15149 with command line:
[2023-07-01 11:24:31] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 69 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:24:31] [config] after: 0e
[2023-07-01 11:24:31] [config] after-batches: 0
[2023-07-01 11:24:31] [config] after-epochs: 69
[2023-07-01 11:24:31] [config] all-caps-every: 0
[2023-07-01 11:24:31] [config] allow-unk: false
[2023-07-01 11:24:31] [config] authors: false
[2023-07-01 11:24:31] [config] beam-size: 12
[2023-07-01 11:24:31] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:24:31] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:24:31] [config] bert-masking-fraction: 0.15
[2023-07-01 11:24:31] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:24:31] [config] bert-train-type-embeddings: true
[2023-07-01 11:24:31] [config] bert-type-vocab-size: 2
[2023-07-01 11:24:31] [config] build-info: ""
[2023-07-01 11:24:31] [config] check-gradient-nan: false
[2023-07-01 11:24:31] [config] check-nan: false
[2023-07-01 11:24:31] [config] cite: false
[2023-07-01 11:24:31] [config] clip-norm: 5
[2023-07-01 11:24:31] [config] cost-scaling:
[2023-07-01 11:24:31] [config]   []
[2023-07-01 11:24:31] [config] cost-type: ce-sum
[2023-07-01 11:24:31] [config] cpu-threads: 0
[2023-07-01 11:24:31] [config] data-threads: 8
[2023-07-01 11:24:31] [config] data-weighting: ""
[2023-07-01 11:24:31] [config] data-weighting-type: sentence
[2023-07-01 11:24:31] [config] dec-cell: gru
[2023-07-01 11:24:31] [config] dec-cell-base-depth: 2
[2023-07-01 11:24:31] [config] dec-cell-high-depth: 1
[2023-07-01 11:24:31] [config] dec-depth: 2
[2023-07-01 11:24:31] [config] devices:
[2023-07-01 11:24:31] [config]   - 0
[2023-07-01 11:24:31] [config] dim-emb: 512
[2023-07-01 11:24:31] [config] dim-rnn: 1024
[2023-07-01 11:24:31] [config] dim-vocabs:
[2023-07-01 11:24:31] [config]   - 16384
[2023-07-01 11:24:31] [config]   - 16384
[2023-07-01 11:24:31] [config] disp-first: 0
[2023-07-01 11:24:31] [config] disp-freq: 1000u
[2023-07-01 11:24:31] [config] disp-label-counts: true
[2023-07-01 11:24:31] [config] dropout-rnn: 0
[2023-07-01 11:24:31] [config] dropout-src: 0
[2023-07-01 11:24:31] [config] dropout-trg: 0
[2023-07-01 11:24:31] [config] dump-config: ""
[2023-07-01 11:24:31] [config] dynamic-gradient-scaling:
[2023-07-01 11:24:31] [config]   []
[2023-07-01 11:24:31] [config] early-stopping: 10
[2023-07-01 11:24:31] [config] early-stopping-on: first
[2023-07-01 11:24:31] [config] embedding-fix-src: false
[2023-07-01 11:24:31] [config] embedding-fix-trg: false
[2023-07-01 11:24:31] [config] embedding-normalization: false
[2023-07-01 11:24:31] [config] embedding-vectors:
[2023-07-01 11:24:31] [config]   []
[2023-07-01 11:24:31] [config] enc-cell: gru
[2023-07-01 11:24:31] [config] enc-cell-depth: 1
[2023-07-01 11:24:31] [config] enc-depth: 2
[2023-07-01 11:24:31] [config] enc-type: bidirectional
[2023-07-01 11:24:31] [config] english-title-case-every: 0
[2023-07-01 11:24:31] [config] exponential-smoothing: 0.0001
[2023-07-01 11:24:31] [config] factor-weight: 1
[2023-07-01 11:24:31] [config] factors-combine: sum
[2023-07-01 11:24:31] [config] factors-dim-emb: 0
[2023-07-01 11:24:31] [config] gradient-checkpointing: false
[2023-07-01 11:24:31] [config] gradient-norm-average-window: 100
[2023-07-01 11:24:31] [config] guided-alignment: none
[2023-07-01 11:24:31] [config] guided-alignment-cost: mse
[2023-07-01 11:24:31] [config] guided-alignment-weight: 0.1
[2023-07-01 11:24:31] [config] ignore-model-config: false
[2023-07-01 11:24:31] [config] input-types:
[2023-07-01 11:24:31] [config]   []
[2023-07-01 11:24:31] [config] interpolate-env-vars: false
[2023-07-01 11:24:31] [config] keep-best: false
[2023-07-01 11:24:31] [config] label-smoothing: 0.1
[2023-07-01 11:24:31] [config] layer-normalization: false
[2023-07-01 11:24:31] [config] learn-rate: 0.0003
[2023-07-01 11:24:31] [config] lemma-dependency: ""
[2023-07-01 11:24:31] [config] lemma-dim-emb: 0
[2023-07-01 11:24:31] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:24:31] [config] log-level: info
[2023-07-01 11:24:31] [config] log-time-zone: ""
[2023-07-01 11:24:31] [config] logical-epoch:
[2023-07-01 11:24:31] [config]   - 1e
[2023-07-01 11:24:31] [config]   - 0
[2023-07-01 11:24:31] [config] lr-decay: 0
[2023-07-01 11:24:31] [config] lr-decay-freq: 50000
[2023-07-01 11:24:31] [config] lr-decay-inv-sqrt:
[2023-07-01 11:24:31] [config]   - 16000
[2023-07-01 11:24:31] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:24:31] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:24:31] [config] lr-decay-start:
[2023-07-01 11:24:31] [config]   - 10
[2023-07-01 11:24:31] [config]   - 1
[2023-07-01 11:24:31] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:24:31] [config] lr-report: true
[2023-07-01 11:24:31] [config] lr-warmup: 16000
[2023-07-01 11:24:31] [config] lr-warmup-at-reload: false
[2023-07-01 11:24:31] [config] lr-warmup-cycle: false
[2023-07-01 11:24:31] [config] lr-warmup-start-rate: 0
[2023-07-01 11:24:31] [config] max-length: 100
[2023-07-01 11:24:31] [config] max-length-crop: false
[2023-07-01 11:24:31] [config] max-length-factor: 3
[2023-07-01 11:24:31] [config] maxi-batch: 100
[2023-07-01 11:24:31] [config] maxi-batch-sort: trg
[2023-07-01 11:24:31] [config] mini-batch: 1000
[2023-07-01 11:24:31] [config] mini-batch-fit: true
[2023-07-01 11:24:31] [config] mini-batch-fit-step: 10
[2023-07-01 11:24:31] [config] mini-batch-round-up: true
[2023-07-01 11:24:31] [config] mini-batch-track-lr: false
[2023-07-01 11:24:31] [config] mini-batch-warmup: 0
[2023-07-01 11:24:31] [config] mini-batch-words: 0
[2023-07-01 11:24:31] [config] mini-batch-words-ref: 0
[2023-07-01 11:24:31] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:24:31] [config] multi-loss-type: sum
[2023-07-01 11:24:31] [config] n-best: false
[2023-07-01 11:24:31] [config] no-nccl: false
[2023-07-01 11:24:31] [config] no-reload: false
[2023-07-01 11:24:31] [config] no-restore-corpus: false
[2023-07-01 11:24:31] [config] normalize: 1
[2023-07-01 11:24:31] [config] normalize-gradient: false
[2023-07-01 11:24:31] [config] num-devices: 0
[2023-07-01 11:24:31] [config] optimizer: adam
[2023-07-01 11:24:31] [config] optimizer-delay: 1
[2023-07-01 11:24:31] [config] optimizer-params:
[2023-07-01 11:24:31] [config]   - 0.9
[2023-07-01 11:24:31] [config]   - 0.98
[2023-07-01 11:24:31] [config]   - 1e-09
[2023-07-01 11:24:31] [config] output-omit-bias: false
[2023-07-01 11:24:31] [config] overwrite: true
[2023-07-01 11:24:31] [config] precision:
[2023-07-01 11:24:31] [config]   - float32
[2023-07-01 11:24:31] [config]   - float32
[2023-07-01 11:24:31] [config] pretrained-model: ""
[2023-07-01 11:24:31] [config] quantize-biases: false
[2023-07-01 11:24:31] [config] quantize-bits: 0
[2023-07-01 11:24:31] [config] quantize-log-based: false
[2023-07-01 11:24:31] [config] quantize-optimization-steps: 0
[2023-07-01 11:24:31] [config] quiet: false
[2023-07-01 11:24:31] [config] quiet-translation: true
[2023-07-01 11:24:31] [config] relative-paths: false
[2023-07-01 11:24:31] [config] right-left: false
[2023-07-01 11:24:31] [config] save-freq: 10000u
[2023-07-01 11:24:31] [config] seed: 1234
[2023-07-01 11:24:31] [config] sentencepiece-alphas:
[2023-07-01 11:24:31] [config]   []
[2023-07-01 11:24:31] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:24:31] [config] sentencepiece-options: ""
[2023-07-01 11:24:31] [config] sharding: global
[2023-07-01 11:24:31] [config] shuffle: data
[2023-07-01 11:24:31] [config] shuffle-in-ram: false
[2023-07-01 11:24:31] [config] sigterm: save-and-exit
[2023-07-01 11:24:31] [config] skip: false
[2023-07-01 11:24:31] [config] sqlite: ""
[2023-07-01 11:24:31] [config] sqlite-drop: false
[2023-07-01 11:24:31] [config] sync-freq: 200u
[2023-07-01 11:24:31] [config] sync-sgd: true
[2023-07-01 11:24:31] [config] tempdir: /tmp
[2023-07-01 11:24:31] [config] tied-embeddings: false
[2023-07-01 11:24:31] [config] tied-embeddings-all: true
[2023-07-01 11:24:31] [config] tied-embeddings-src: false
[2023-07-01 11:24:31] [config] train-embedder-rank:
[2023-07-01 11:24:31] [config]   []
[2023-07-01 11:24:31] [config] train-sets:
[2023-07-01 11:24:31] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:24:31] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:24:31] [config] transformer-aan-activation: swish
[2023-07-01 11:24:31] [config] transformer-aan-depth: 2
[2023-07-01 11:24:31] [config] transformer-aan-nogate: false
[2023-07-01 11:24:31] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:24:31] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:24:31] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:24:31] [config] transformer-depth-scaling: false
[2023-07-01 11:24:31] [config] transformer-dim-aan: 2048
[2023-07-01 11:24:31] [config] transformer-dim-ffn: 2048
[2023-07-01 11:24:31] [config] transformer-dropout: 0.1
[2023-07-01 11:24:31] [config] transformer-dropout-attention: 0
[2023-07-01 11:24:31] [config] transformer-dropout-ffn: 0
[2023-07-01 11:24:31] [config] transformer-ffn-activation: swish
[2023-07-01 11:24:31] [config] transformer-ffn-depth: 2
[2023-07-01 11:24:31] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:24:31] [config] transformer-heads: 8
[2023-07-01 11:24:31] [config] transformer-no-projection: false
[2023-07-01 11:24:31] [config] transformer-pool: false
[2023-07-01 11:24:31] [config] transformer-postprocess: dan
[2023-07-01 11:24:31] [config] transformer-postprocess-emb: d
[2023-07-01 11:24:31] [config] transformer-postprocess-top: ""
[2023-07-01 11:24:31] [config] transformer-preprocess: ""
[2023-07-01 11:24:31] [config] transformer-tied-layers:
[2023-07-01 11:24:31] [config]   []
[2023-07-01 11:24:31] [config] transformer-train-position-embeddings: false
[2023-07-01 11:24:31] [config] tsv: false
[2023-07-01 11:24:31] [config] tsv-fields: 0
[2023-07-01 11:24:31] [config] type: transformer
[2023-07-01 11:24:31] [config] ulr: false
[2023-07-01 11:24:31] [config] ulr-dim-emb: 0
[2023-07-01 11:24:31] [config] ulr-dropout: 0
[2023-07-01 11:24:31] [config] ulr-keys-vectors: ""
[2023-07-01 11:24:31] [config] ulr-query-vectors: ""
[2023-07-01 11:24:31] [config] ulr-softmax-temperature: 1
[2023-07-01 11:24:31] [config] ulr-trainable-transformation: false
[2023-07-01 11:24:31] [config] unlikelihood-loss: false
[2023-07-01 11:24:31] [config] valid-freq: 50000000
[2023-07-01 11:24:31] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:24:31] [config] valid-max-length: 1000
[2023-07-01 11:24:31] [config] valid-metrics:
[2023-07-01 11:24:31] [config]   - cross-entropy
[2023-07-01 11:24:31] [config]   - translation
[2023-07-01 11:24:31] [config] valid-mini-batch: 64
[2023-07-01 11:24:31] [config] valid-reset-stalled: false
[2023-07-01 11:24:31] [config] valid-script-args:
[2023-07-01 11:24:31] [config]   []
[2023-07-01 11:24:31] [config] valid-script-path: ""
[2023-07-01 11:24:31] [config] valid-sets:
[2023-07-01 11:24:31] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:24:31] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:24:31] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:24:31] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:24:31] [config] vocabs:
[2023-07-01 11:24:31] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:24:31] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:24:31] [config] word-penalty: 0
[2023-07-01 11:24:31] [config] word-scores: false
[2023-07-01 11:24:31] [config] workspace: 2048
[2023-07-01 11:24:31] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:24:31] Using synchronous SGD
[2023-07-01 11:24:32] Synced seed 1234
[2023-07-01 11:24:32] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:24:32] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:24:32] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:24:32] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:24:32] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:24:32] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:24:32] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:24:32] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:24:32] [comm] Using global sharding
[2023-07-01 11:24:32] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:24:32] [training] Using 1 GPUs
[2023-07-01 11:24:32] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:24:32] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:24:33] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:24:33] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:24:40] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:24:40] [valid] No post-processing script given for validating translator
[2023-07-01 11:24:40] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:24:40] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:24:41] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:24:41] [comm] Using global sharding
[2023-07-01 11:24:41] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:24:41] [training] Using 1 GPUs
[2023-07-01 11:24:41] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:24:41] Allocating memory for general optimizer shards
[2023-07-01 11:24:41] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:24:41] Loading Adam parameters
[2023-07-01 11:24:41] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:24:41] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:24:41] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:24:41] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:24:41] [data] Shuffling data
[2023-07-01 11:24:41] [data] Done reading 20,192 sentences
[2023-07-01 11:24:41] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:24:41] Training started
[2023-07-01 11:24:41] Training finished
[2023-07-01 11:24:45] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:24:45] [marian] Running on node20.datos.cluster.uy as process 15207 with command line:
[2023-07-01 11:24:45] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 70 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:24:45] [config] after: 0e
[2023-07-01 11:24:45] [config] after-batches: 0
[2023-07-01 11:24:45] [config] after-epochs: 70
[2023-07-01 11:24:45] [config] all-caps-every: 0
[2023-07-01 11:24:45] [config] allow-unk: false
[2023-07-01 11:24:45] [config] authors: false
[2023-07-01 11:24:45] [config] beam-size: 12
[2023-07-01 11:24:45] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:24:45] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:24:45] [config] bert-masking-fraction: 0.15
[2023-07-01 11:24:45] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:24:45] [config] bert-train-type-embeddings: true
[2023-07-01 11:24:45] [config] bert-type-vocab-size: 2
[2023-07-01 11:24:45] [config] build-info: ""
[2023-07-01 11:24:45] [config] check-gradient-nan: false
[2023-07-01 11:24:45] [config] check-nan: false
[2023-07-01 11:24:45] [config] cite: false
[2023-07-01 11:24:45] [config] clip-norm: 5
[2023-07-01 11:24:45] [config] cost-scaling:
[2023-07-01 11:24:45] [config]   []
[2023-07-01 11:24:45] [config] cost-type: ce-sum
[2023-07-01 11:24:45] [config] cpu-threads: 0
[2023-07-01 11:24:45] [config] data-threads: 8
[2023-07-01 11:24:45] [config] data-weighting: ""
[2023-07-01 11:24:45] [config] data-weighting-type: sentence
[2023-07-01 11:24:45] [config] dec-cell: gru
[2023-07-01 11:24:45] [config] dec-cell-base-depth: 2
[2023-07-01 11:24:45] [config] dec-cell-high-depth: 1
[2023-07-01 11:24:45] [config] dec-depth: 2
[2023-07-01 11:24:45] [config] devices:
[2023-07-01 11:24:45] [config]   - 0
[2023-07-01 11:24:45] [config] dim-emb: 512
[2023-07-01 11:24:45] [config] dim-rnn: 1024
[2023-07-01 11:24:45] [config] dim-vocabs:
[2023-07-01 11:24:45] [config]   - 16384
[2023-07-01 11:24:45] [config]   - 16384
[2023-07-01 11:24:45] [config] disp-first: 0
[2023-07-01 11:24:45] [config] disp-freq: 1000u
[2023-07-01 11:24:45] [config] disp-label-counts: true
[2023-07-01 11:24:45] [config] dropout-rnn: 0
[2023-07-01 11:24:45] [config] dropout-src: 0
[2023-07-01 11:24:45] [config] dropout-trg: 0
[2023-07-01 11:24:45] [config] dump-config: ""
[2023-07-01 11:24:45] [config] dynamic-gradient-scaling:
[2023-07-01 11:24:45] [config]   []
[2023-07-01 11:24:45] [config] early-stopping: 10
[2023-07-01 11:24:45] [config] early-stopping-on: first
[2023-07-01 11:24:45] [config] embedding-fix-src: false
[2023-07-01 11:24:45] [config] embedding-fix-trg: false
[2023-07-01 11:24:45] [config] embedding-normalization: false
[2023-07-01 11:24:45] [config] embedding-vectors:
[2023-07-01 11:24:45] [config]   []
[2023-07-01 11:24:45] [config] enc-cell: gru
[2023-07-01 11:24:45] [config] enc-cell-depth: 1
[2023-07-01 11:24:45] [config] enc-depth: 2
[2023-07-01 11:24:45] [config] enc-type: bidirectional
[2023-07-01 11:24:45] [config] english-title-case-every: 0
[2023-07-01 11:24:45] [config] exponential-smoothing: 0.0001
[2023-07-01 11:24:45] [config] factor-weight: 1
[2023-07-01 11:24:45] [config] factors-combine: sum
[2023-07-01 11:24:45] [config] factors-dim-emb: 0
[2023-07-01 11:24:45] [config] gradient-checkpointing: false
[2023-07-01 11:24:45] [config] gradient-norm-average-window: 100
[2023-07-01 11:24:45] [config] guided-alignment: none
[2023-07-01 11:24:45] [config] guided-alignment-cost: mse
[2023-07-01 11:24:45] [config] guided-alignment-weight: 0.1
[2023-07-01 11:24:45] [config] ignore-model-config: false
[2023-07-01 11:24:45] [config] input-types:
[2023-07-01 11:24:45] [config]   []
[2023-07-01 11:24:45] [config] interpolate-env-vars: false
[2023-07-01 11:24:45] [config] keep-best: false
[2023-07-01 11:24:45] [config] label-smoothing: 0.1
[2023-07-01 11:24:45] [config] layer-normalization: false
[2023-07-01 11:24:45] [config] learn-rate: 0.0003
[2023-07-01 11:24:45] [config] lemma-dependency: ""
[2023-07-01 11:24:45] [config] lemma-dim-emb: 0
[2023-07-01 11:24:45] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:24:45] [config] log-level: info
[2023-07-01 11:24:45] [config] log-time-zone: ""
[2023-07-01 11:24:45] [config] logical-epoch:
[2023-07-01 11:24:45] [config]   - 1e
[2023-07-01 11:24:45] [config]   - 0
[2023-07-01 11:24:45] [config] lr-decay: 0
[2023-07-01 11:24:45] [config] lr-decay-freq: 50000
[2023-07-01 11:24:45] [config] lr-decay-inv-sqrt:
[2023-07-01 11:24:45] [config]   - 16000
[2023-07-01 11:24:45] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:24:45] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:24:45] [config] lr-decay-start:
[2023-07-01 11:24:45] [config]   - 10
[2023-07-01 11:24:45] [config]   - 1
[2023-07-01 11:24:45] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:24:45] [config] lr-report: true
[2023-07-01 11:24:45] [config] lr-warmup: 16000
[2023-07-01 11:24:45] [config] lr-warmup-at-reload: false
[2023-07-01 11:24:45] [config] lr-warmup-cycle: false
[2023-07-01 11:24:45] [config] lr-warmup-start-rate: 0
[2023-07-01 11:24:45] [config] max-length: 100
[2023-07-01 11:24:45] [config] max-length-crop: false
[2023-07-01 11:24:45] [config] max-length-factor: 3
[2023-07-01 11:24:45] [config] maxi-batch: 100
[2023-07-01 11:24:45] [config] maxi-batch-sort: trg
[2023-07-01 11:24:45] [config] mini-batch: 1000
[2023-07-01 11:24:45] [config] mini-batch-fit: true
[2023-07-01 11:24:45] [config] mini-batch-fit-step: 10
[2023-07-01 11:24:45] [config] mini-batch-round-up: true
[2023-07-01 11:24:45] [config] mini-batch-track-lr: false
[2023-07-01 11:24:45] [config] mini-batch-warmup: 0
[2023-07-01 11:24:45] [config] mini-batch-words: 0
[2023-07-01 11:24:45] [config] mini-batch-words-ref: 0
[2023-07-01 11:24:45] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:24:45] [config] multi-loss-type: sum
[2023-07-01 11:24:45] [config] n-best: false
[2023-07-01 11:24:45] [config] no-nccl: false
[2023-07-01 11:24:45] [config] no-reload: false
[2023-07-01 11:24:45] [config] no-restore-corpus: false
[2023-07-01 11:24:45] [config] normalize: 1
[2023-07-01 11:24:45] [config] normalize-gradient: false
[2023-07-01 11:24:45] [config] num-devices: 0
[2023-07-01 11:24:45] [config] optimizer: adam
[2023-07-01 11:24:45] [config] optimizer-delay: 1
[2023-07-01 11:24:45] [config] optimizer-params:
[2023-07-01 11:24:45] [config]   - 0.9
[2023-07-01 11:24:45] [config]   - 0.98
[2023-07-01 11:24:45] [config]   - 1e-09
[2023-07-01 11:24:45] [config] output-omit-bias: false
[2023-07-01 11:24:45] [config] overwrite: true
[2023-07-01 11:24:45] [config] precision:
[2023-07-01 11:24:45] [config]   - float32
[2023-07-01 11:24:45] [config]   - float32
[2023-07-01 11:24:45] [config] pretrained-model: ""
[2023-07-01 11:24:45] [config] quantize-biases: false
[2023-07-01 11:24:45] [config] quantize-bits: 0
[2023-07-01 11:24:45] [config] quantize-log-based: false
[2023-07-01 11:24:45] [config] quantize-optimization-steps: 0
[2023-07-01 11:24:45] [config] quiet: false
[2023-07-01 11:24:45] [config] quiet-translation: true
[2023-07-01 11:24:45] [config] relative-paths: false
[2023-07-01 11:24:45] [config] right-left: false
[2023-07-01 11:24:45] [config] save-freq: 10000u
[2023-07-01 11:24:45] [config] seed: 1234
[2023-07-01 11:24:45] [config] sentencepiece-alphas:
[2023-07-01 11:24:45] [config]   []
[2023-07-01 11:24:45] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:24:45] [config] sentencepiece-options: ""
[2023-07-01 11:24:45] [config] sharding: global
[2023-07-01 11:24:45] [config] shuffle: data
[2023-07-01 11:24:45] [config] shuffle-in-ram: false
[2023-07-01 11:24:45] [config] sigterm: save-and-exit
[2023-07-01 11:24:45] [config] skip: false
[2023-07-01 11:24:45] [config] sqlite: ""
[2023-07-01 11:24:45] [config] sqlite-drop: false
[2023-07-01 11:24:45] [config] sync-freq: 200u
[2023-07-01 11:24:45] [config] sync-sgd: true
[2023-07-01 11:24:45] [config] tempdir: /tmp
[2023-07-01 11:24:45] [config] tied-embeddings: false
[2023-07-01 11:24:45] [config] tied-embeddings-all: true
[2023-07-01 11:24:45] [config] tied-embeddings-src: false
[2023-07-01 11:24:45] [config] train-embedder-rank:
[2023-07-01 11:24:45] [config]   []
[2023-07-01 11:24:45] [config] train-sets:
[2023-07-01 11:24:45] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:24:45] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:24:45] [config] transformer-aan-activation: swish
[2023-07-01 11:24:45] [config] transformer-aan-depth: 2
[2023-07-01 11:24:45] [config] transformer-aan-nogate: false
[2023-07-01 11:24:45] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:24:45] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:24:45] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:24:45] [config] transformer-depth-scaling: false
[2023-07-01 11:24:45] [config] transformer-dim-aan: 2048
[2023-07-01 11:24:45] [config] transformer-dim-ffn: 2048
[2023-07-01 11:24:45] [config] transformer-dropout: 0.1
[2023-07-01 11:24:45] [config] transformer-dropout-attention: 0
[2023-07-01 11:24:45] [config] transformer-dropout-ffn: 0
[2023-07-01 11:24:45] [config] transformer-ffn-activation: swish
[2023-07-01 11:24:45] [config] transformer-ffn-depth: 2
[2023-07-01 11:24:45] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:24:45] [config] transformer-heads: 8
[2023-07-01 11:24:45] [config] transformer-no-projection: false
[2023-07-01 11:24:45] [config] transformer-pool: false
[2023-07-01 11:24:45] [config] transformer-postprocess: dan
[2023-07-01 11:24:45] [config] transformer-postprocess-emb: d
[2023-07-01 11:24:45] [config] transformer-postprocess-top: ""
[2023-07-01 11:24:45] [config] transformer-preprocess: ""
[2023-07-01 11:24:45] [config] transformer-tied-layers:
[2023-07-01 11:24:45] [config]   []
[2023-07-01 11:24:45] [config] transformer-train-position-embeddings: false
[2023-07-01 11:24:45] [config] tsv: false
[2023-07-01 11:24:45] [config] tsv-fields: 0
[2023-07-01 11:24:45] [config] type: transformer
[2023-07-01 11:24:45] [config] ulr: false
[2023-07-01 11:24:45] [config] ulr-dim-emb: 0
[2023-07-01 11:24:45] [config] ulr-dropout: 0
[2023-07-01 11:24:45] [config] ulr-keys-vectors: ""
[2023-07-01 11:24:45] [config] ulr-query-vectors: ""
[2023-07-01 11:24:45] [config] ulr-softmax-temperature: 1
[2023-07-01 11:24:45] [config] ulr-trainable-transformation: false
[2023-07-01 11:24:45] [config] unlikelihood-loss: false
[2023-07-01 11:24:45] [config] valid-freq: 50000000
[2023-07-01 11:24:45] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:24:45] [config] valid-max-length: 1000
[2023-07-01 11:24:45] [config] valid-metrics:
[2023-07-01 11:24:45] [config]   - cross-entropy
[2023-07-01 11:24:45] [config]   - translation
[2023-07-01 11:24:45] [config] valid-mini-batch: 64
[2023-07-01 11:24:45] [config] valid-reset-stalled: false
[2023-07-01 11:24:45] [config] valid-script-args:
[2023-07-01 11:24:45] [config]   []
[2023-07-01 11:24:45] [config] valid-script-path: ""
[2023-07-01 11:24:45] [config] valid-sets:
[2023-07-01 11:24:45] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:24:45] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:24:45] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:24:45] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:24:45] [config] vocabs:
[2023-07-01 11:24:45] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:24:45] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:24:45] [config] word-penalty: 0
[2023-07-01 11:24:45] [config] word-scores: false
[2023-07-01 11:24:45] [config] workspace: 2048
[2023-07-01 11:24:45] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:24:45] Using synchronous SGD
[2023-07-01 11:24:45] Synced seed 1234
[2023-07-01 11:24:45] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:24:45] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:24:45] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:24:45] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:24:45] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:24:45] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:24:46] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:24:46] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:24:46] [comm] Using global sharding
[2023-07-01 11:24:46] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:24:46] [training] Using 1 GPUs
[2023-07-01 11:24:46] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:24:46] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:24:46] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:24:47] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:24:54] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:24:54] [valid] No post-processing script given for validating translator
[2023-07-01 11:24:54] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:24:54] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:24:54] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:24:54] [comm] Using global sharding
[2023-07-01 11:24:54] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:24:54] [training] Using 1 GPUs
[2023-07-01 11:24:54] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:24:55] Allocating memory for general optimizer shards
[2023-07-01 11:24:55] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:24:55] Loading Adam parameters
[2023-07-01 11:24:55] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:24:55] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:24:55] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:24:55] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:24:55] [data] Shuffling data
[2023-07-01 11:24:55] [data] Done reading 20,192 sentences
[2023-07-01 11:24:55] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:24:55] Training started
[2023-07-01 11:24:55] Training finished
[2023-07-01 11:24:59] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:24:59] [marian] Running on node20.datos.cluster.uy as process 15268 with command line:
[2023-07-01 11:24:59] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 71 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:24:59] [config] after: 0e
[2023-07-01 11:24:59] [config] after-batches: 0
[2023-07-01 11:24:59] [config] after-epochs: 71
[2023-07-01 11:24:59] [config] all-caps-every: 0
[2023-07-01 11:24:59] [config] allow-unk: false
[2023-07-01 11:24:59] [config] authors: false
[2023-07-01 11:24:59] [config] beam-size: 12
[2023-07-01 11:24:59] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:24:59] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:24:59] [config] bert-masking-fraction: 0.15
[2023-07-01 11:24:59] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:24:59] [config] bert-train-type-embeddings: true
[2023-07-01 11:24:59] [config] bert-type-vocab-size: 2
[2023-07-01 11:24:59] [config] build-info: ""
[2023-07-01 11:24:59] [config] check-gradient-nan: false
[2023-07-01 11:24:59] [config] check-nan: false
[2023-07-01 11:24:59] [config] cite: false
[2023-07-01 11:24:59] [config] clip-norm: 5
[2023-07-01 11:24:59] [config] cost-scaling:
[2023-07-01 11:24:59] [config]   []
[2023-07-01 11:24:59] [config] cost-type: ce-sum
[2023-07-01 11:24:59] [config] cpu-threads: 0
[2023-07-01 11:24:59] [config] data-threads: 8
[2023-07-01 11:24:59] [config] data-weighting: ""
[2023-07-01 11:24:59] [config] data-weighting-type: sentence
[2023-07-01 11:24:59] [config] dec-cell: gru
[2023-07-01 11:24:59] [config] dec-cell-base-depth: 2
[2023-07-01 11:24:59] [config] dec-cell-high-depth: 1
[2023-07-01 11:24:59] [config] dec-depth: 2
[2023-07-01 11:24:59] [config] devices:
[2023-07-01 11:24:59] [config]   - 0
[2023-07-01 11:24:59] [config] dim-emb: 512
[2023-07-01 11:24:59] [config] dim-rnn: 1024
[2023-07-01 11:24:59] [config] dim-vocabs:
[2023-07-01 11:24:59] [config]   - 16384
[2023-07-01 11:24:59] [config]   - 16384
[2023-07-01 11:24:59] [config] disp-first: 0
[2023-07-01 11:24:59] [config] disp-freq: 1000u
[2023-07-01 11:24:59] [config] disp-label-counts: true
[2023-07-01 11:24:59] [config] dropout-rnn: 0
[2023-07-01 11:24:59] [config] dropout-src: 0
[2023-07-01 11:24:59] [config] dropout-trg: 0
[2023-07-01 11:24:59] [config] dump-config: ""
[2023-07-01 11:24:59] [config] dynamic-gradient-scaling:
[2023-07-01 11:24:59] [config]   []
[2023-07-01 11:24:59] [config] early-stopping: 10
[2023-07-01 11:24:59] [config] early-stopping-on: first
[2023-07-01 11:24:59] [config] embedding-fix-src: false
[2023-07-01 11:24:59] [config] embedding-fix-trg: false
[2023-07-01 11:24:59] [config] embedding-normalization: false
[2023-07-01 11:24:59] [config] embedding-vectors:
[2023-07-01 11:24:59] [config]   []
[2023-07-01 11:24:59] [config] enc-cell: gru
[2023-07-01 11:24:59] [config] enc-cell-depth: 1
[2023-07-01 11:24:59] [config] enc-depth: 2
[2023-07-01 11:24:59] [config] enc-type: bidirectional
[2023-07-01 11:24:59] [config] english-title-case-every: 0
[2023-07-01 11:24:59] [config] exponential-smoothing: 0.0001
[2023-07-01 11:24:59] [config] factor-weight: 1
[2023-07-01 11:24:59] [config] factors-combine: sum
[2023-07-01 11:24:59] [config] factors-dim-emb: 0
[2023-07-01 11:24:59] [config] gradient-checkpointing: false
[2023-07-01 11:24:59] [config] gradient-norm-average-window: 100
[2023-07-01 11:24:59] [config] guided-alignment: none
[2023-07-01 11:24:59] [config] guided-alignment-cost: mse
[2023-07-01 11:24:59] [config] guided-alignment-weight: 0.1
[2023-07-01 11:24:59] [config] ignore-model-config: false
[2023-07-01 11:24:59] [config] input-types:
[2023-07-01 11:24:59] [config]   []
[2023-07-01 11:24:59] [config] interpolate-env-vars: false
[2023-07-01 11:24:59] [config] keep-best: false
[2023-07-01 11:24:59] [config] label-smoothing: 0.1
[2023-07-01 11:24:59] [config] layer-normalization: false
[2023-07-01 11:24:59] [config] learn-rate: 0.0003
[2023-07-01 11:24:59] [config] lemma-dependency: ""
[2023-07-01 11:24:59] [config] lemma-dim-emb: 0
[2023-07-01 11:24:59] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:24:59] [config] log-level: info
[2023-07-01 11:24:59] [config] log-time-zone: ""
[2023-07-01 11:24:59] [config] logical-epoch:
[2023-07-01 11:24:59] [config]   - 1e
[2023-07-01 11:24:59] [config]   - 0
[2023-07-01 11:24:59] [config] lr-decay: 0
[2023-07-01 11:24:59] [config] lr-decay-freq: 50000
[2023-07-01 11:24:59] [config] lr-decay-inv-sqrt:
[2023-07-01 11:24:59] [config]   - 16000
[2023-07-01 11:24:59] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:24:59] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:24:59] [config] lr-decay-start:
[2023-07-01 11:24:59] [config]   - 10
[2023-07-01 11:24:59] [config]   - 1
[2023-07-01 11:24:59] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:24:59] [config] lr-report: true
[2023-07-01 11:24:59] [config] lr-warmup: 16000
[2023-07-01 11:24:59] [config] lr-warmup-at-reload: false
[2023-07-01 11:24:59] [config] lr-warmup-cycle: false
[2023-07-01 11:24:59] [config] lr-warmup-start-rate: 0
[2023-07-01 11:24:59] [config] max-length: 100
[2023-07-01 11:24:59] [config] max-length-crop: false
[2023-07-01 11:24:59] [config] max-length-factor: 3
[2023-07-01 11:24:59] [config] maxi-batch: 100
[2023-07-01 11:24:59] [config] maxi-batch-sort: trg
[2023-07-01 11:24:59] [config] mini-batch: 1000
[2023-07-01 11:24:59] [config] mini-batch-fit: true
[2023-07-01 11:24:59] [config] mini-batch-fit-step: 10
[2023-07-01 11:24:59] [config] mini-batch-round-up: true
[2023-07-01 11:24:59] [config] mini-batch-track-lr: false
[2023-07-01 11:24:59] [config] mini-batch-warmup: 0
[2023-07-01 11:24:59] [config] mini-batch-words: 0
[2023-07-01 11:24:59] [config] mini-batch-words-ref: 0
[2023-07-01 11:24:59] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:24:59] [config] multi-loss-type: sum
[2023-07-01 11:24:59] [config] n-best: false
[2023-07-01 11:24:59] [config] no-nccl: false
[2023-07-01 11:24:59] [config] no-reload: false
[2023-07-01 11:24:59] [config] no-restore-corpus: false
[2023-07-01 11:24:59] [config] normalize: 1
[2023-07-01 11:24:59] [config] normalize-gradient: false
[2023-07-01 11:24:59] [config] num-devices: 0
[2023-07-01 11:24:59] [config] optimizer: adam
[2023-07-01 11:24:59] [config] optimizer-delay: 1
[2023-07-01 11:24:59] [config] optimizer-params:
[2023-07-01 11:24:59] [config]   - 0.9
[2023-07-01 11:24:59] [config]   - 0.98
[2023-07-01 11:24:59] [config]   - 1e-09
[2023-07-01 11:24:59] [config] output-omit-bias: false
[2023-07-01 11:24:59] [config] overwrite: true
[2023-07-01 11:24:59] [config] precision:
[2023-07-01 11:24:59] [config]   - float32
[2023-07-01 11:24:59] [config]   - float32
[2023-07-01 11:24:59] [config] pretrained-model: ""
[2023-07-01 11:24:59] [config] quantize-biases: false
[2023-07-01 11:24:59] [config] quantize-bits: 0
[2023-07-01 11:24:59] [config] quantize-log-based: false
[2023-07-01 11:24:59] [config] quantize-optimization-steps: 0
[2023-07-01 11:24:59] [config] quiet: false
[2023-07-01 11:24:59] [config] quiet-translation: true
[2023-07-01 11:24:59] [config] relative-paths: false
[2023-07-01 11:24:59] [config] right-left: false
[2023-07-01 11:24:59] [config] save-freq: 10000u
[2023-07-01 11:24:59] [config] seed: 1234
[2023-07-01 11:24:59] [config] sentencepiece-alphas:
[2023-07-01 11:24:59] [config]   []
[2023-07-01 11:24:59] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:24:59] [config] sentencepiece-options: ""
[2023-07-01 11:24:59] [config] sharding: global
[2023-07-01 11:24:59] [config] shuffle: data
[2023-07-01 11:24:59] [config] shuffle-in-ram: false
[2023-07-01 11:24:59] [config] sigterm: save-and-exit
[2023-07-01 11:24:59] [config] skip: false
[2023-07-01 11:24:59] [config] sqlite: ""
[2023-07-01 11:24:59] [config] sqlite-drop: false
[2023-07-01 11:24:59] [config] sync-freq: 200u
[2023-07-01 11:24:59] [config] sync-sgd: true
[2023-07-01 11:24:59] [config] tempdir: /tmp
[2023-07-01 11:24:59] [config] tied-embeddings: false
[2023-07-01 11:24:59] [config] tied-embeddings-all: true
[2023-07-01 11:24:59] [config] tied-embeddings-src: false
[2023-07-01 11:24:59] [config] train-embedder-rank:
[2023-07-01 11:24:59] [config]   []
[2023-07-01 11:24:59] [config] train-sets:
[2023-07-01 11:24:59] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:24:59] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:24:59] [config] transformer-aan-activation: swish
[2023-07-01 11:24:59] [config] transformer-aan-depth: 2
[2023-07-01 11:24:59] [config] transformer-aan-nogate: false
[2023-07-01 11:24:59] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:24:59] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:24:59] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:24:59] [config] transformer-depth-scaling: false
[2023-07-01 11:24:59] [config] transformer-dim-aan: 2048
[2023-07-01 11:24:59] [config] transformer-dim-ffn: 2048
[2023-07-01 11:24:59] [config] transformer-dropout: 0.1
[2023-07-01 11:24:59] [config] transformer-dropout-attention: 0
[2023-07-01 11:24:59] [config] transformer-dropout-ffn: 0
[2023-07-01 11:24:59] [config] transformer-ffn-activation: swish
[2023-07-01 11:24:59] [config] transformer-ffn-depth: 2
[2023-07-01 11:24:59] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:24:59] [config] transformer-heads: 8
[2023-07-01 11:24:59] [config] transformer-no-projection: false
[2023-07-01 11:24:59] [config] transformer-pool: false
[2023-07-01 11:24:59] [config] transformer-postprocess: dan
[2023-07-01 11:24:59] [config] transformer-postprocess-emb: d
[2023-07-01 11:24:59] [config] transformer-postprocess-top: ""
[2023-07-01 11:24:59] [config] transformer-preprocess: ""
[2023-07-01 11:24:59] [config] transformer-tied-layers:
[2023-07-01 11:24:59] [config]   []
[2023-07-01 11:24:59] [config] transformer-train-position-embeddings: false
[2023-07-01 11:24:59] [config] tsv: false
[2023-07-01 11:24:59] [config] tsv-fields: 0
[2023-07-01 11:24:59] [config] type: transformer
[2023-07-01 11:24:59] [config] ulr: false
[2023-07-01 11:24:59] [config] ulr-dim-emb: 0
[2023-07-01 11:24:59] [config] ulr-dropout: 0
[2023-07-01 11:24:59] [config] ulr-keys-vectors: ""
[2023-07-01 11:24:59] [config] ulr-query-vectors: ""
[2023-07-01 11:24:59] [config] ulr-softmax-temperature: 1
[2023-07-01 11:24:59] [config] ulr-trainable-transformation: false
[2023-07-01 11:24:59] [config] unlikelihood-loss: false
[2023-07-01 11:24:59] [config] valid-freq: 50000000
[2023-07-01 11:24:59] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:24:59] [config] valid-max-length: 1000
[2023-07-01 11:24:59] [config] valid-metrics:
[2023-07-01 11:24:59] [config]   - cross-entropy
[2023-07-01 11:24:59] [config]   - translation
[2023-07-01 11:24:59] [config] valid-mini-batch: 64
[2023-07-01 11:24:59] [config] valid-reset-stalled: false
[2023-07-01 11:24:59] [config] valid-script-args:
[2023-07-01 11:24:59] [config]   []
[2023-07-01 11:24:59] [config] valid-script-path: ""
[2023-07-01 11:24:59] [config] valid-sets:
[2023-07-01 11:24:59] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:24:59] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:24:59] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:24:59] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:24:59] [config] vocabs:
[2023-07-01 11:24:59] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:24:59] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:24:59] [config] word-penalty: 0
[2023-07-01 11:24:59] [config] word-scores: false
[2023-07-01 11:24:59] [config] workspace: 2048
[2023-07-01 11:24:59] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:24:59] Using synchronous SGD
[2023-07-01 11:24:59] Synced seed 1234
[2023-07-01 11:24:59] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:24:59] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:24:59] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:24:59] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:24:59] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:24:59] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:25:00] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:25:00] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:25:00] [comm] Using global sharding
[2023-07-01 11:25:00] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:25:00] [training] Using 1 GPUs
[2023-07-01 11:25:00] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:25:00] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:25:00] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:25:00] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:25:08] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:25:08] [valid] No post-processing script given for validating translator
[2023-07-01 11:25:08] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:25:08] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:25:08] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:25:08] [comm] Using global sharding
[2023-07-01 11:25:08] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:25:08] [training] Using 1 GPUs
[2023-07-01 11:25:08] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:25:08] Allocating memory for general optimizer shards
[2023-07-01 11:25:08] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:25:08] Loading Adam parameters
[2023-07-01 11:25:08] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:25:08] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:25:08] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:25:08] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:25:08] [data] Shuffling data
[2023-07-01 11:25:08] [data] Done reading 20,192 sentences
[2023-07-01 11:25:09] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:25:09] Training started
[2023-07-01 11:25:09] Training finished
[2023-07-01 11:25:12] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:25:12] [marian] Running on node20.datos.cluster.uy as process 15328 with command line:
[2023-07-01 11:25:12] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 72 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:25:12] [config] after: 0e
[2023-07-01 11:25:12] [config] after-batches: 0
[2023-07-01 11:25:12] [config] after-epochs: 72
[2023-07-01 11:25:12] [config] all-caps-every: 0
[2023-07-01 11:25:12] [config] allow-unk: false
[2023-07-01 11:25:12] [config] authors: false
[2023-07-01 11:25:12] [config] beam-size: 12
[2023-07-01 11:25:12] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:25:12] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:25:12] [config] bert-masking-fraction: 0.15
[2023-07-01 11:25:12] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:25:12] [config] bert-train-type-embeddings: true
[2023-07-01 11:25:12] [config] bert-type-vocab-size: 2
[2023-07-01 11:25:12] [config] build-info: ""
[2023-07-01 11:25:12] [config] check-gradient-nan: false
[2023-07-01 11:25:12] [config] check-nan: false
[2023-07-01 11:25:12] [config] cite: false
[2023-07-01 11:25:12] [config] clip-norm: 5
[2023-07-01 11:25:12] [config] cost-scaling:
[2023-07-01 11:25:12] [config]   []
[2023-07-01 11:25:12] [config] cost-type: ce-sum
[2023-07-01 11:25:12] [config] cpu-threads: 0
[2023-07-01 11:25:12] [config] data-threads: 8
[2023-07-01 11:25:12] [config] data-weighting: ""
[2023-07-01 11:25:12] [config] data-weighting-type: sentence
[2023-07-01 11:25:12] [config] dec-cell: gru
[2023-07-01 11:25:12] [config] dec-cell-base-depth: 2
[2023-07-01 11:25:12] [config] dec-cell-high-depth: 1
[2023-07-01 11:25:12] [config] dec-depth: 2
[2023-07-01 11:25:12] [config] devices:
[2023-07-01 11:25:12] [config]   - 0
[2023-07-01 11:25:12] [config] dim-emb: 512
[2023-07-01 11:25:12] [config] dim-rnn: 1024
[2023-07-01 11:25:12] [config] dim-vocabs:
[2023-07-01 11:25:12] [config]   - 16384
[2023-07-01 11:25:12] [config]   - 16384
[2023-07-01 11:25:12] [config] disp-first: 0
[2023-07-01 11:25:12] [config] disp-freq: 1000u
[2023-07-01 11:25:12] [config] disp-label-counts: true
[2023-07-01 11:25:12] [config] dropout-rnn: 0
[2023-07-01 11:25:12] [config] dropout-src: 0
[2023-07-01 11:25:12] [config] dropout-trg: 0
[2023-07-01 11:25:12] [config] dump-config: ""
[2023-07-01 11:25:12] [config] dynamic-gradient-scaling:
[2023-07-01 11:25:12] [config]   []
[2023-07-01 11:25:12] [config] early-stopping: 10
[2023-07-01 11:25:12] [config] early-stopping-on: first
[2023-07-01 11:25:12] [config] embedding-fix-src: false
[2023-07-01 11:25:12] [config] embedding-fix-trg: false
[2023-07-01 11:25:12] [config] embedding-normalization: false
[2023-07-01 11:25:12] [config] embedding-vectors:
[2023-07-01 11:25:12] [config]   []
[2023-07-01 11:25:12] [config] enc-cell: gru
[2023-07-01 11:25:12] [config] enc-cell-depth: 1
[2023-07-01 11:25:12] [config] enc-depth: 2
[2023-07-01 11:25:12] [config] enc-type: bidirectional
[2023-07-01 11:25:12] [config] english-title-case-every: 0
[2023-07-01 11:25:12] [config] exponential-smoothing: 0.0001
[2023-07-01 11:25:12] [config] factor-weight: 1
[2023-07-01 11:25:12] [config] factors-combine: sum
[2023-07-01 11:25:12] [config] factors-dim-emb: 0
[2023-07-01 11:25:12] [config] gradient-checkpointing: false
[2023-07-01 11:25:12] [config] gradient-norm-average-window: 100
[2023-07-01 11:25:12] [config] guided-alignment: none
[2023-07-01 11:25:12] [config] guided-alignment-cost: mse
[2023-07-01 11:25:12] [config] guided-alignment-weight: 0.1
[2023-07-01 11:25:12] [config] ignore-model-config: false
[2023-07-01 11:25:12] [config] input-types:
[2023-07-01 11:25:12] [config]   []
[2023-07-01 11:25:12] [config] interpolate-env-vars: false
[2023-07-01 11:25:12] [config] keep-best: false
[2023-07-01 11:25:12] [config] label-smoothing: 0.1
[2023-07-01 11:25:12] [config] layer-normalization: false
[2023-07-01 11:25:12] [config] learn-rate: 0.0003
[2023-07-01 11:25:12] [config] lemma-dependency: ""
[2023-07-01 11:25:12] [config] lemma-dim-emb: 0
[2023-07-01 11:25:12] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:25:12] [config] log-level: info
[2023-07-01 11:25:12] [config] log-time-zone: ""
[2023-07-01 11:25:12] [config] logical-epoch:
[2023-07-01 11:25:12] [config]   - 1e
[2023-07-01 11:25:12] [config]   - 0
[2023-07-01 11:25:12] [config] lr-decay: 0
[2023-07-01 11:25:12] [config] lr-decay-freq: 50000
[2023-07-01 11:25:12] [config] lr-decay-inv-sqrt:
[2023-07-01 11:25:12] [config]   - 16000
[2023-07-01 11:25:12] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:25:12] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:25:12] [config] lr-decay-start:
[2023-07-01 11:25:12] [config]   - 10
[2023-07-01 11:25:12] [config]   - 1
[2023-07-01 11:25:12] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:25:12] [config] lr-report: true
[2023-07-01 11:25:12] [config] lr-warmup: 16000
[2023-07-01 11:25:12] [config] lr-warmup-at-reload: false
[2023-07-01 11:25:12] [config] lr-warmup-cycle: false
[2023-07-01 11:25:12] [config] lr-warmup-start-rate: 0
[2023-07-01 11:25:12] [config] max-length: 100
[2023-07-01 11:25:12] [config] max-length-crop: false
[2023-07-01 11:25:12] [config] max-length-factor: 3
[2023-07-01 11:25:12] [config] maxi-batch: 100
[2023-07-01 11:25:12] [config] maxi-batch-sort: trg
[2023-07-01 11:25:12] [config] mini-batch: 1000
[2023-07-01 11:25:12] [config] mini-batch-fit: true
[2023-07-01 11:25:12] [config] mini-batch-fit-step: 10
[2023-07-01 11:25:12] [config] mini-batch-round-up: true
[2023-07-01 11:25:12] [config] mini-batch-track-lr: false
[2023-07-01 11:25:12] [config] mini-batch-warmup: 0
[2023-07-01 11:25:12] [config] mini-batch-words: 0
[2023-07-01 11:25:12] [config] mini-batch-words-ref: 0
[2023-07-01 11:25:12] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:25:12] [config] multi-loss-type: sum
[2023-07-01 11:25:12] [config] n-best: false
[2023-07-01 11:25:12] [config] no-nccl: false
[2023-07-01 11:25:12] [config] no-reload: false
[2023-07-01 11:25:12] [config] no-restore-corpus: false
[2023-07-01 11:25:12] [config] normalize: 1
[2023-07-01 11:25:12] [config] normalize-gradient: false
[2023-07-01 11:25:12] [config] num-devices: 0
[2023-07-01 11:25:12] [config] optimizer: adam
[2023-07-01 11:25:12] [config] optimizer-delay: 1
[2023-07-01 11:25:12] [config] optimizer-params:
[2023-07-01 11:25:12] [config]   - 0.9
[2023-07-01 11:25:12] [config]   - 0.98
[2023-07-01 11:25:12] [config]   - 1e-09
[2023-07-01 11:25:12] [config] output-omit-bias: false
[2023-07-01 11:25:12] [config] overwrite: true
[2023-07-01 11:25:12] [config] precision:
[2023-07-01 11:25:12] [config]   - float32
[2023-07-01 11:25:12] [config]   - float32
[2023-07-01 11:25:12] [config] pretrained-model: ""
[2023-07-01 11:25:12] [config] quantize-biases: false
[2023-07-01 11:25:12] [config] quantize-bits: 0
[2023-07-01 11:25:12] [config] quantize-log-based: false
[2023-07-01 11:25:12] [config] quantize-optimization-steps: 0
[2023-07-01 11:25:12] [config] quiet: false
[2023-07-01 11:25:12] [config] quiet-translation: true
[2023-07-01 11:25:12] [config] relative-paths: false
[2023-07-01 11:25:12] [config] right-left: false
[2023-07-01 11:25:12] [config] save-freq: 10000u
[2023-07-01 11:25:12] [config] seed: 1234
[2023-07-01 11:25:12] [config] sentencepiece-alphas:
[2023-07-01 11:25:12] [config]   []
[2023-07-01 11:25:12] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:25:12] [config] sentencepiece-options: ""
[2023-07-01 11:25:12] [config] sharding: global
[2023-07-01 11:25:12] [config] shuffle: data
[2023-07-01 11:25:12] [config] shuffle-in-ram: false
[2023-07-01 11:25:12] [config] sigterm: save-and-exit
[2023-07-01 11:25:12] [config] skip: false
[2023-07-01 11:25:12] [config] sqlite: ""
[2023-07-01 11:25:12] [config] sqlite-drop: false
[2023-07-01 11:25:12] [config] sync-freq: 200u
[2023-07-01 11:25:12] [config] sync-sgd: true
[2023-07-01 11:25:12] [config] tempdir: /tmp
[2023-07-01 11:25:12] [config] tied-embeddings: false
[2023-07-01 11:25:12] [config] tied-embeddings-all: true
[2023-07-01 11:25:12] [config] tied-embeddings-src: false
[2023-07-01 11:25:12] [config] train-embedder-rank:
[2023-07-01 11:25:12] [config]   []
[2023-07-01 11:25:12] [config] train-sets:
[2023-07-01 11:25:12] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:25:12] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:25:12] [config] transformer-aan-activation: swish
[2023-07-01 11:25:12] [config] transformer-aan-depth: 2
[2023-07-01 11:25:12] [config] transformer-aan-nogate: false
[2023-07-01 11:25:12] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:25:12] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:25:12] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:25:12] [config] transformer-depth-scaling: false
[2023-07-01 11:25:12] [config] transformer-dim-aan: 2048
[2023-07-01 11:25:12] [config] transformer-dim-ffn: 2048
[2023-07-01 11:25:12] [config] transformer-dropout: 0.1
[2023-07-01 11:25:12] [config] transformer-dropout-attention: 0
[2023-07-01 11:25:12] [config] transformer-dropout-ffn: 0
[2023-07-01 11:25:12] [config] transformer-ffn-activation: swish
[2023-07-01 11:25:12] [config] transformer-ffn-depth: 2
[2023-07-01 11:25:12] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:25:12] [config] transformer-heads: 8
[2023-07-01 11:25:12] [config] transformer-no-projection: false
[2023-07-01 11:25:12] [config] transformer-pool: false
[2023-07-01 11:25:12] [config] transformer-postprocess: dan
[2023-07-01 11:25:12] [config] transformer-postprocess-emb: d
[2023-07-01 11:25:12] [config] transformer-postprocess-top: ""
[2023-07-01 11:25:12] [config] transformer-preprocess: ""
[2023-07-01 11:25:12] [config] transformer-tied-layers:
[2023-07-01 11:25:12] [config]   []
[2023-07-01 11:25:12] [config] transformer-train-position-embeddings: false
[2023-07-01 11:25:12] [config] tsv: false
[2023-07-01 11:25:12] [config] tsv-fields: 0
[2023-07-01 11:25:12] [config] type: transformer
[2023-07-01 11:25:12] [config] ulr: false
[2023-07-01 11:25:12] [config] ulr-dim-emb: 0
[2023-07-01 11:25:12] [config] ulr-dropout: 0
[2023-07-01 11:25:12] [config] ulr-keys-vectors: ""
[2023-07-01 11:25:12] [config] ulr-query-vectors: ""
[2023-07-01 11:25:12] [config] ulr-softmax-temperature: 1
[2023-07-01 11:25:12] [config] ulr-trainable-transformation: false
[2023-07-01 11:25:12] [config] unlikelihood-loss: false
[2023-07-01 11:25:12] [config] valid-freq: 50000000
[2023-07-01 11:25:12] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:25:12] [config] valid-max-length: 1000
[2023-07-01 11:25:12] [config] valid-metrics:
[2023-07-01 11:25:12] [config]   - cross-entropy
[2023-07-01 11:25:12] [config]   - translation
[2023-07-01 11:25:12] [config] valid-mini-batch: 64
[2023-07-01 11:25:12] [config] valid-reset-stalled: false
[2023-07-01 11:25:12] [config] valid-script-args:
[2023-07-01 11:25:12] [config]   []
[2023-07-01 11:25:12] [config] valid-script-path: ""
[2023-07-01 11:25:12] [config] valid-sets:
[2023-07-01 11:25:12] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:25:12] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:25:12] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:25:12] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:25:12] [config] vocabs:
[2023-07-01 11:25:12] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:25:12] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:25:12] [config] word-penalty: 0
[2023-07-01 11:25:12] [config] word-scores: false
[2023-07-01 11:25:12] [config] workspace: 2048
[2023-07-01 11:25:12] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:25:12] Using synchronous SGD
[2023-07-01 11:25:12] Synced seed 1234
[2023-07-01 11:25:12] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:25:12] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:25:12] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:25:12] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:25:12] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:25:12] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:25:13] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:25:13] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:25:13] [comm] Using global sharding
[2023-07-01 11:25:13] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:25:13] [training] Using 1 GPUs
[2023-07-01 11:25:13] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:25:13] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:25:14] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:25:14] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:25:21] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:25:21] [valid] No post-processing script given for validating translator
[2023-07-01 11:25:21] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:25:21] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:25:21] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:25:21] [comm] Using global sharding
[2023-07-01 11:25:21] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:25:21] [training] Using 1 GPUs
[2023-07-01 11:25:21] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:25:22] Allocating memory for general optimizer shards
[2023-07-01 11:25:22] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:25:22] Loading Adam parameters
[2023-07-01 11:25:22] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:25:22] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:25:22] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:25:22] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:25:22] [data] Shuffling data
[2023-07-01 11:25:22] [data] Done reading 20,192 sentences
[2023-07-01 11:25:22] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:25:22] Training started
[2023-07-01 11:25:22] Training finished
[2023-07-01 11:25:26] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:25:26] [marian] Running on node20.datos.cluster.uy as process 15392 with command line:
[2023-07-01 11:25:26] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 73 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:25:26] [config] after: 0e
[2023-07-01 11:25:26] [config] after-batches: 0
[2023-07-01 11:25:26] [config] after-epochs: 73
[2023-07-01 11:25:26] [config] all-caps-every: 0
[2023-07-01 11:25:26] [config] allow-unk: false
[2023-07-01 11:25:26] [config] authors: false
[2023-07-01 11:25:26] [config] beam-size: 12
[2023-07-01 11:25:26] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:25:26] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:25:26] [config] bert-masking-fraction: 0.15
[2023-07-01 11:25:26] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:25:26] [config] bert-train-type-embeddings: true
[2023-07-01 11:25:26] [config] bert-type-vocab-size: 2
[2023-07-01 11:25:26] [config] build-info: ""
[2023-07-01 11:25:26] [config] check-gradient-nan: false
[2023-07-01 11:25:26] [config] check-nan: false
[2023-07-01 11:25:26] [config] cite: false
[2023-07-01 11:25:26] [config] clip-norm: 5
[2023-07-01 11:25:26] [config] cost-scaling:
[2023-07-01 11:25:26] [config]   []
[2023-07-01 11:25:26] [config] cost-type: ce-sum
[2023-07-01 11:25:26] [config] cpu-threads: 0
[2023-07-01 11:25:26] [config] data-threads: 8
[2023-07-01 11:25:26] [config] data-weighting: ""
[2023-07-01 11:25:26] [config] data-weighting-type: sentence
[2023-07-01 11:25:26] [config] dec-cell: gru
[2023-07-01 11:25:26] [config] dec-cell-base-depth: 2
[2023-07-01 11:25:26] [config] dec-cell-high-depth: 1
[2023-07-01 11:25:26] [config] dec-depth: 2
[2023-07-01 11:25:26] [config] devices:
[2023-07-01 11:25:26] [config]   - 0
[2023-07-01 11:25:26] [config] dim-emb: 512
[2023-07-01 11:25:26] [config] dim-rnn: 1024
[2023-07-01 11:25:26] [config] dim-vocabs:
[2023-07-01 11:25:26] [config]   - 16384
[2023-07-01 11:25:26] [config]   - 16384
[2023-07-01 11:25:26] [config] disp-first: 0
[2023-07-01 11:25:26] [config] disp-freq: 1000u
[2023-07-01 11:25:26] [config] disp-label-counts: true
[2023-07-01 11:25:26] [config] dropout-rnn: 0
[2023-07-01 11:25:26] [config] dropout-src: 0
[2023-07-01 11:25:26] [config] dropout-trg: 0
[2023-07-01 11:25:26] [config] dump-config: ""
[2023-07-01 11:25:26] [config] dynamic-gradient-scaling:
[2023-07-01 11:25:26] [config]   []
[2023-07-01 11:25:26] [config] early-stopping: 10
[2023-07-01 11:25:26] [config] early-stopping-on: first
[2023-07-01 11:25:26] [config] embedding-fix-src: false
[2023-07-01 11:25:26] [config] embedding-fix-trg: false
[2023-07-01 11:25:26] [config] embedding-normalization: false
[2023-07-01 11:25:26] [config] embedding-vectors:
[2023-07-01 11:25:26] [config]   []
[2023-07-01 11:25:26] [config] enc-cell: gru
[2023-07-01 11:25:26] [config] enc-cell-depth: 1
[2023-07-01 11:25:26] [config] enc-depth: 2
[2023-07-01 11:25:26] [config] enc-type: bidirectional
[2023-07-01 11:25:26] [config] english-title-case-every: 0
[2023-07-01 11:25:26] [config] exponential-smoothing: 0.0001
[2023-07-01 11:25:26] [config] factor-weight: 1
[2023-07-01 11:25:26] [config] factors-combine: sum
[2023-07-01 11:25:26] [config] factors-dim-emb: 0
[2023-07-01 11:25:26] [config] gradient-checkpointing: false
[2023-07-01 11:25:26] [config] gradient-norm-average-window: 100
[2023-07-01 11:25:26] [config] guided-alignment: none
[2023-07-01 11:25:26] [config] guided-alignment-cost: mse
[2023-07-01 11:25:26] [config] guided-alignment-weight: 0.1
[2023-07-01 11:25:26] [config] ignore-model-config: false
[2023-07-01 11:25:26] [config] input-types:
[2023-07-01 11:25:26] [config]   []
[2023-07-01 11:25:26] [config] interpolate-env-vars: false
[2023-07-01 11:25:26] [config] keep-best: false
[2023-07-01 11:25:26] [config] label-smoothing: 0.1
[2023-07-01 11:25:26] [config] layer-normalization: false
[2023-07-01 11:25:26] [config] learn-rate: 0.0003
[2023-07-01 11:25:26] [config] lemma-dependency: ""
[2023-07-01 11:25:26] [config] lemma-dim-emb: 0
[2023-07-01 11:25:26] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:25:26] [config] log-level: info
[2023-07-01 11:25:26] [config] log-time-zone: ""
[2023-07-01 11:25:26] [config] logical-epoch:
[2023-07-01 11:25:26] [config]   - 1e
[2023-07-01 11:25:26] [config]   - 0
[2023-07-01 11:25:26] [config] lr-decay: 0
[2023-07-01 11:25:26] [config] lr-decay-freq: 50000
[2023-07-01 11:25:26] [config] lr-decay-inv-sqrt:
[2023-07-01 11:25:26] [config]   - 16000
[2023-07-01 11:25:26] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:25:26] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:25:26] [config] lr-decay-start:
[2023-07-01 11:25:26] [config]   - 10
[2023-07-01 11:25:26] [config]   - 1
[2023-07-01 11:25:26] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:25:26] [config] lr-report: true
[2023-07-01 11:25:26] [config] lr-warmup: 16000
[2023-07-01 11:25:26] [config] lr-warmup-at-reload: false
[2023-07-01 11:25:26] [config] lr-warmup-cycle: false
[2023-07-01 11:25:26] [config] lr-warmup-start-rate: 0
[2023-07-01 11:25:26] [config] max-length: 100
[2023-07-01 11:25:26] [config] max-length-crop: false
[2023-07-01 11:25:26] [config] max-length-factor: 3
[2023-07-01 11:25:26] [config] maxi-batch: 100
[2023-07-01 11:25:26] [config] maxi-batch-sort: trg
[2023-07-01 11:25:26] [config] mini-batch: 1000
[2023-07-01 11:25:26] [config] mini-batch-fit: true
[2023-07-01 11:25:26] [config] mini-batch-fit-step: 10
[2023-07-01 11:25:26] [config] mini-batch-round-up: true
[2023-07-01 11:25:26] [config] mini-batch-track-lr: false
[2023-07-01 11:25:26] [config] mini-batch-warmup: 0
[2023-07-01 11:25:26] [config] mini-batch-words: 0
[2023-07-01 11:25:26] [config] mini-batch-words-ref: 0
[2023-07-01 11:25:26] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:25:26] [config] multi-loss-type: sum
[2023-07-01 11:25:26] [config] n-best: false
[2023-07-01 11:25:26] [config] no-nccl: false
[2023-07-01 11:25:26] [config] no-reload: false
[2023-07-01 11:25:26] [config] no-restore-corpus: false
[2023-07-01 11:25:26] [config] normalize: 1
[2023-07-01 11:25:26] [config] normalize-gradient: false
[2023-07-01 11:25:26] [config] num-devices: 0
[2023-07-01 11:25:26] [config] optimizer: adam
[2023-07-01 11:25:26] [config] optimizer-delay: 1
[2023-07-01 11:25:26] [config] optimizer-params:
[2023-07-01 11:25:26] [config]   - 0.9
[2023-07-01 11:25:26] [config]   - 0.98
[2023-07-01 11:25:26] [config]   - 1e-09
[2023-07-01 11:25:26] [config] output-omit-bias: false
[2023-07-01 11:25:26] [config] overwrite: true
[2023-07-01 11:25:26] [config] precision:
[2023-07-01 11:25:26] [config]   - float32
[2023-07-01 11:25:26] [config]   - float32
[2023-07-01 11:25:26] [config] pretrained-model: ""
[2023-07-01 11:25:26] [config] quantize-biases: false
[2023-07-01 11:25:26] [config] quantize-bits: 0
[2023-07-01 11:25:26] [config] quantize-log-based: false
[2023-07-01 11:25:26] [config] quantize-optimization-steps: 0
[2023-07-01 11:25:26] [config] quiet: false
[2023-07-01 11:25:26] [config] quiet-translation: true
[2023-07-01 11:25:26] [config] relative-paths: false
[2023-07-01 11:25:26] [config] right-left: false
[2023-07-01 11:25:26] [config] save-freq: 10000u
[2023-07-01 11:25:26] [config] seed: 1234
[2023-07-01 11:25:26] [config] sentencepiece-alphas:
[2023-07-01 11:25:26] [config]   []
[2023-07-01 11:25:26] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:25:26] [config] sentencepiece-options: ""
[2023-07-01 11:25:26] [config] sharding: global
[2023-07-01 11:25:26] [config] shuffle: data
[2023-07-01 11:25:26] [config] shuffle-in-ram: false
[2023-07-01 11:25:26] [config] sigterm: save-and-exit
[2023-07-01 11:25:26] [config] skip: false
[2023-07-01 11:25:26] [config] sqlite: ""
[2023-07-01 11:25:26] [config] sqlite-drop: false
[2023-07-01 11:25:26] [config] sync-freq: 200u
[2023-07-01 11:25:26] [config] sync-sgd: true
[2023-07-01 11:25:26] [config] tempdir: /tmp
[2023-07-01 11:25:26] [config] tied-embeddings: false
[2023-07-01 11:25:26] [config] tied-embeddings-all: true
[2023-07-01 11:25:26] [config] tied-embeddings-src: false
[2023-07-01 11:25:26] [config] train-embedder-rank:
[2023-07-01 11:25:26] [config]   []
[2023-07-01 11:25:26] [config] train-sets:
[2023-07-01 11:25:26] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:25:26] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:25:26] [config] transformer-aan-activation: swish
[2023-07-01 11:25:26] [config] transformer-aan-depth: 2
[2023-07-01 11:25:26] [config] transformer-aan-nogate: false
[2023-07-01 11:25:26] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:25:26] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:25:26] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:25:26] [config] transformer-depth-scaling: false
[2023-07-01 11:25:26] [config] transformer-dim-aan: 2048
[2023-07-01 11:25:26] [config] transformer-dim-ffn: 2048
[2023-07-01 11:25:26] [config] transformer-dropout: 0.1
[2023-07-01 11:25:26] [config] transformer-dropout-attention: 0
[2023-07-01 11:25:26] [config] transformer-dropout-ffn: 0
[2023-07-01 11:25:26] [config] transformer-ffn-activation: swish
[2023-07-01 11:25:26] [config] transformer-ffn-depth: 2
[2023-07-01 11:25:26] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:25:26] [config] transformer-heads: 8
[2023-07-01 11:25:26] [config] transformer-no-projection: false
[2023-07-01 11:25:26] [config] transformer-pool: false
[2023-07-01 11:25:26] [config] transformer-postprocess: dan
[2023-07-01 11:25:26] [config] transformer-postprocess-emb: d
[2023-07-01 11:25:26] [config] transformer-postprocess-top: ""
[2023-07-01 11:25:26] [config] transformer-preprocess: ""
[2023-07-01 11:25:26] [config] transformer-tied-layers:
[2023-07-01 11:25:26] [config]   []
[2023-07-01 11:25:26] [config] transformer-train-position-embeddings: false
[2023-07-01 11:25:26] [config] tsv: false
[2023-07-01 11:25:26] [config] tsv-fields: 0
[2023-07-01 11:25:26] [config] type: transformer
[2023-07-01 11:25:26] [config] ulr: false
[2023-07-01 11:25:26] [config] ulr-dim-emb: 0
[2023-07-01 11:25:26] [config] ulr-dropout: 0
[2023-07-01 11:25:26] [config] ulr-keys-vectors: ""
[2023-07-01 11:25:26] [config] ulr-query-vectors: ""
[2023-07-01 11:25:26] [config] ulr-softmax-temperature: 1
[2023-07-01 11:25:26] [config] ulr-trainable-transformation: false
[2023-07-01 11:25:26] [config] unlikelihood-loss: false
[2023-07-01 11:25:26] [config] valid-freq: 50000000
[2023-07-01 11:25:26] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:25:26] [config] valid-max-length: 1000
[2023-07-01 11:25:26] [config] valid-metrics:
[2023-07-01 11:25:26] [config]   - cross-entropy
[2023-07-01 11:25:26] [config]   - translation
[2023-07-01 11:25:26] [config] valid-mini-batch: 64
[2023-07-01 11:25:26] [config] valid-reset-stalled: false
[2023-07-01 11:25:26] [config] valid-script-args:
[2023-07-01 11:25:26] [config]   []
[2023-07-01 11:25:26] [config] valid-script-path: ""
[2023-07-01 11:25:26] [config] valid-sets:
[2023-07-01 11:25:26] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:25:26] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:25:26] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:25:26] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:25:26] [config] vocabs:
[2023-07-01 11:25:26] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:25:26] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:25:26] [config] word-penalty: 0
[2023-07-01 11:25:26] [config] word-scores: false
[2023-07-01 11:25:26] [config] workspace: 2048
[2023-07-01 11:25:26] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:25:26] Using synchronous SGD
[2023-07-01 11:25:26] Synced seed 1234
[2023-07-01 11:25:26] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:25:26] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:25:26] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:25:26] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:25:26] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:25:26] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:25:27] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:25:27] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:25:27] [comm] Using global sharding
[2023-07-01 11:25:27] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:25:27] [training] Using 1 GPUs
[2023-07-01 11:25:27] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:25:27] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:25:27] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:25:27] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:25:35] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:25:35] [valid] No post-processing script given for validating translator
[2023-07-01 11:25:35] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:25:35] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:25:35] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:25:35] [comm] Using global sharding
[2023-07-01 11:25:35] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:25:35] [training] Using 1 GPUs
[2023-07-01 11:25:35] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:25:36] Allocating memory for general optimizer shards
[2023-07-01 11:25:36] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:25:36] Loading Adam parameters
[2023-07-01 11:25:36] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:25:36] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:25:36] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:25:36] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:25:36] [data] Shuffling data
[2023-07-01 11:25:36] [data] Done reading 20,192 sentences
[2023-07-01 11:25:36] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:25:36] Training started
[2023-07-01 11:25:36] Training finished
[2023-07-01 11:25:40] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:25:40] [marian] Running on node20.datos.cluster.uy as process 15450 with command line:
[2023-07-01 11:25:40] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 74 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:25:40] [config] after: 0e
[2023-07-01 11:25:40] [config] after-batches: 0
[2023-07-01 11:25:40] [config] after-epochs: 74
[2023-07-01 11:25:40] [config] all-caps-every: 0
[2023-07-01 11:25:40] [config] allow-unk: false
[2023-07-01 11:25:40] [config] authors: false
[2023-07-01 11:25:40] [config] beam-size: 12
[2023-07-01 11:25:40] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:25:40] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:25:40] [config] bert-masking-fraction: 0.15
[2023-07-01 11:25:40] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:25:40] [config] bert-train-type-embeddings: true
[2023-07-01 11:25:40] [config] bert-type-vocab-size: 2
[2023-07-01 11:25:40] [config] build-info: ""
[2023-07-01 11:25:40] [config] check-gradient-nan: false
[2023-07-01 11:25:40] [config] check-nan: false
[2023-07-01 11:25:40] [config] cite: false
[2023-07-01 11:25:40] [config] clip-norm: 5
[2023-07-01 11:25:40] [config] cost-scaling:
[2023-07-01 11:25:40] [config]   []
[2023-07-01 11:25:40] [config] cost-type: ce-sum
[2023-07-01 11:25:40] [config] cpu-threads: 0
[2023-07-01 11:25:40] [config] data-threads: 8
[2023-07-01 11:25:40] [config] data-weighting: ""
[2023-07-01 11:25:40] [config] data-weighting-type: sentence
[2023-07-01 11:25:40] [config] dec-cell: gru
[2023-07-01 11:25:40] [config] dec-cell-base-depth: 2
[2023-07-01 11:25:40] [config] dec-cell-high-depth: 1
[2023-07-01 11:25:40] [config] dec-depth: 2
[2023-07-01 11:25:40] [config] devices:
[2023-07-01 11:25:40] [config]   - 0
[2023-07-01 11:25:40] [config] dim-emb: 512
[2023-07-01 11:25:40] [config] dim-rnn: 1024
[2023-07-01 11:25:40] [config] dim-vocabs:
[2023-07-01 11:25:40] [config]   - 16384
[2023-07-01 11:25:40] [config]   - 16384
[2023-07-01 11:25:40] [config] disp-first: 0
[2023-07-01 11:25:40] [config] disp-freq: 1000u
[2023-07-01 11:25:40] [config] disp-label-counts: true
[2023-07-01 11:25:40] [config] dropout-rnn: 0
[2023-07-01 11:25:40] [config] dropout-src: 0
[2023-07-01 11:25:40] [config] dropout-trg: 0
[2023-07-01 11:25:40] [config] dump-config: ""
[2023-07-01 11:25:40] [config] dynamic-gradient-scaling:
[2023-07-01 11:25:40] [config]   []
[2023-07-01 11:25:40] [config] early-stopping: 10
[2023-07-01 11:25:40] [config] early-stopping-on: first
[2023-07-01 11:25:40] [config] embedding-fix-src: false
[2023-07-01 11:25:40] [config] embedding-fix-trg: false
[2023-07-01 11:25:40] [config] embedding-normalization: false
[2023-07-01 11:25:40] [config] embedding-vectors:
[2023-07-01 11:25:40] [config]   []
[2023-07-01 11:25:40] [config] enc-cell: gru
[2023-07-01 11:25:40] [config] enc-cell-depth: 1
[2023-07-01 11:25:40] [config] enc-depth: 2
[2023-07-01 11:25:40] [config] enc-type: bidirectional
[2023-07-01 11:25:40] [config] english-title-case-every: 0
[2023-07-01 11:25:40] [config] exponential-smoothing: 0.0001
[2023-07-01 11:25:40] [config] factor-weight: 1
[2023-07-01 11:25:40] [config] factors-combine: sum
[2023-07-01 11:25:40] [config] factors-dim-emb: 0
[2023-07-01 11:25:40] [config] gradient-checkpointing: false
[2023-07-01 11:25:40] [config] gradient-norm-average-window: 100
[2023-07-01 11:25:40] [config] guided-alignment: none
[2023-07-01 11:25:40] [config] guided-alignment-cost: mse
[2023-07-01 11:25:40] [config] guided-alignment-weight: 0.1
[2023-07-01 11:25:40] [config] ignore-model-config: false
[2023-07-01 11:25:40] [config] input-types:
[2023-07-01 11:25:40] [config]   []
[2023-07-01 11:25:40] [config] interpolate-env-vars: false
[2023-07-01 11:25:40] [config] keep-best: false
[2023-07-01 11:25:40] [config] label-smoothing: 0.1
[2023-07-01 11:25:40] [config] layer-normalization: false
[2023-07-01 11:25:40] [config] learn-rate: 0.0003
[2023-07-01 11:25:40] [config] lemma-dependency: ""
[2023-07-01 11:25:40] [config] lemma-dim-emb: 0
[2023-07-01 11:25:40] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:25:40] [config] log-level: info
[2023-07-01 11:25:40] [config] log-time-zone: ""
[2023-07-01 11:25:40] [config] logical-epoch:
[2023-07-01 11:25:40] [config]   - 1e
[2023-07-01 11:25:40] [config]   - 0
[2023-07-01 11:25:40] [config] lr-decay: 0
[2023-07-01 11:25:40] [config] lr-decay-freq: 50000
[2023-07-01 11:25:40] [config] lr-decay-inv-sqrt:
[2023-07-01 11:25:40] [config]   - 16000
[2023-07-01 11:25:40] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:25:40] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:25:40] [config] lr-decay-start:
[2023-07-01 11:25:40] [config]   - 10
[2023-07-01 11:25:40] [config]   - 1
[2023-07-01 11:25:40] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:25:40] [config] lr-report: true
[2023-07-01 11:25:40] [config] lr-warmup: 16000
[2023-07-01 11:25:40] [config] lr-warmup-at-reload: false
[2023-07-01 11:25:40] [config] lr-warmup-cycle: false
[2023-07-01 11:25:40] [config] lr-warmup-start-rate: 0
[2023-07-01 11:25:40] [config] max-length: 100
[2023-07-01 11:25:40] [config] max-length-crop: false
[2023-07-01 11:25:40] [config] max-length-factor: 3
[2023-07-01 11:25:40] [config] maxi-batch: 100
[2023-07-01 11:25:40] [config] maxi-batch-sort: trg
[2023-07-01 11:25:40] [config] mini-batch: 1000
[2023-07-01 11:25:40] [config] mini-batch-fit: true
[2023-07-01 11:25:40] [config] mini-batch-fit-step: 10
[2023-07-01 11:25:40] [config] mini-batch-round-up: true
[2023-07-01 11:25:40] [config] mini-batch-track-lr: false
[2023-07-01 11:25:40] [config] mini-batch-warmup: 0
[2023-07-01 11:25:40] [config] mini-batch-words: 0
[2023-07-01 11:25:40] [config] mini-batch-words-ref: 0
[2023-07-01 11:25:40] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:25:40] [config] multi-loss-type: sum
[2023-07-01 11:25:40] [config] n-best: false
[2023-07-01 11:25:40] [config] no-nccl: false
[2023-07-01 11:25:40] [config] no-reload: false
[2023-07-01 11:25:40] [config] no-restore-corpus: false
[2023-07-01 11:25:40] [config] normalize: 1
[2023-07-01 11:25:40] [config] normalize-gradient: false
[2023-07-01 11:25:40] [config] num-devices: 0
[2023-07-01 11:25:40] [config] optimizer: adam
[2023-07-01 11:25:40] [config] optimizer-delay: 1
[2023-07-01 11:25:40] [config] optimizer-params:
[2023-07-01 11:25:40] [config]   - 0.9
[2023-07-01 11:25:40] [config]   - 0.98
[2023-07-01 11:25:40] [config]   - 1e-09
[2023-07-01 11:25:40] [config] output-omit-bias: false
[2023-07-01 11:25:40] [config] overwrite: true
[2023-07-01 11:25:40] [config] precision:
[2023-07-01 11:25:40] [config]   - float32
[2023-07-01 11:25:40] [config]   - float32
[2023-07-01 11:25:40] [config] pretrained-model: ""
[2023-07-01 11:25:40] [config] quantize-biases: false
[2023-07-01 11:25:40] [config] quantize-bits: 0
[2023-07-01 11:25:40] [config] quantize-log-based: false
[2023-07-01 11:25:40] [config] quantize-optimization-steps: 0
[2023-07-01 11:25:40] [config] quiet: false
[2023-07-01 11:25:40] [config] quiet-translation: true
[2023-07-01 11:25:40] [config] relative-paths: false
[2023-07-01 11:25:40] [config] right-left: false
[2023-07-01 11:25:40] [config] save-freq: 10000u
[2023-07-01 11:25:40] [config] seed: 1234
[2023-07-01 11:25:40] [config] sentencepiece-alphas:
[2023-07-01 11:25:40] [config]   []
[2023-07-01 11:25:40] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:25:40] [config] sentencepiece-options: ""
[2023-07-01 11:25:40] [config] sharding: global
[2023-07-01 11:25:40] [config] shuffle: data
[2023-07-01 11:25:40] [config] shuffle-in-ram: false
[2023-07-01 11:25:40] [config] sigterm: save-and-exit
[2023-07-01 11:25:40] [config] skip: false
[2023-07-01 11:25:40] [config] sqlite: ""
[2023-07-01 11:25:40] [config] sqlite-drop: false
[2023-07-01 11:25:40] [config] sync-freq: 200u
[2023-07-01 11:25:40] [config] sync-sgd: true
[2023-07-01 11:25:40] [config] tempdir: /tmp
[2023-07-01 11:25:40] [config] tied-embeddings: false
[2023-07-01 11:25:40] [config] tied-embeddings-all: true
[2023-07-01 11:25:40] [config] tied-embeddings-src: false
[2023-07-01 11:25:40] [config] train-embedder-rank:
[2023-07-01 11:25:40] [config]   []
[2023-07-01 11:25:40] [config] train-sets:
[2023-07-01 11:25:40] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:25:40] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:25:40] [config] transformer-aan-activation: swish
[2023-07-01 11:25:40] [config] transformer-aan-depth: 2
[2023-07-01 11:25:40] [config] transformer-aan-nogate: false
[2023-07-01 11:25:40] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:25:40] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:25:40] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:25:40] [config] transformer-depth-scaling: false
[2023-07-01 11:25:40] [config] transformer-dim-aan: 2048
[2023-07-01 11:25:40] [config] transformer-dim-ffn: 2048
[2023-07-01 11:25:40] [config] transformer-dropout: 0.1
[2023-07-01 11:25:40] [config] transformer-dropout-attention: 0
[2023-07-01 11:25:40] [config] transformer-dropout-ffn: 0
[2023-07-01 11:25:40] [config] transformer-ffn-activation: swish
[2023-07-01 11:25:40] [config] transformer-ffn-depth: 2
[2023-07-01 11:25:40] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:25:40] [config] transformer-heads: 8
[2023-07-01 11:25:40] [config] transformer-no-projection: false
[2023-07-01 11:25:40] [config] transformer-pool: false
[2023-07-01 11:25:40] [config] transformer-postprocess: dan
[2023-07-01 11:25:40] [config] transformer-postprocess-emb: d
[2023-07-01 11:25:40] [config] transformer-postprocess-top: ""
[2023-07-01 11:25:40] [config] transformer-preprocess: ""
[2023-07-01 11:25:40] [config] transformer-tied-layers:
[2023-07-01 11:25:40] [config]   []
[2023-07-01 11:25:40] [config] transformer-train-position-embeddings: false
[2023-07-01 11:25:40] [config] tsv: false
[2023-07-01 11:25:40] [config] tsv-fields: 0
[2023-07-01 11:25:40] [config] type: transformer
[2023-07-01 11:25:40] [config] ulr: false
[2023-07-01 11:25:40] [config] ulr-dim-emb: 0
[2023-07-01 11:25:40] [config] ulr-dropout: 0
[2023-07-01 11:25:40] [config] ulr-keys-vectors: ""
[2023-07-01 11:25:40] [config] ulr-query-vectors: ""
[2023-07-01 11:25:40] [config] ulr-softmax-temperature: 1
[2023-07-01 11:25:40] [config] ulr-trainable-transformation: false
[2023-07-01 11:25:40] [config] unlikelihood-loss: false
[2023-07-01 11:25:40] [config] valid-freq: 50000000
[2023-07-01 11:25:40] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:25:40] [config] valid-max-length: 1000
[2023-07-01 11:25:40] [config] valid-metrics:
[2023-07-01 11:25:40] [config]   - cross-entropy
[2023-07-01 11:25:40] [config]   - translation
[2023-07-01 11:25:40] [config] valid-mini-batch: 64
[2023-07-01 11:25:40] [config] valid-reset-stalled: false
[2023-07-01 11:25:40] [config] valid-script-args:
[2023-07-01 11:25:40] [config]   []
[2023-07-01 11:25:40] [config] valid-script-path: ""
[2023-07-01 11:25:40] [config] valid-sets:
[2023-07-01 11:25:40] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:25:40] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:25:40] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:25:40] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:25:40] [config] vocabs:
[2023-07-01 11:25:40] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:25:40] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:25:40] [config] word-penalty: 0
[2023-07-01 11:25:40] [config] word-scores: false
[2023-07-01 11:25:40] [config] workspace: 2048
[2023-07-01 11:25:40] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:25:40] Using synchronous SGD
[2023-07-01 11:25:40] Synced seed 1234
[2023-07-01 11:25:40] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:25:40] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:25:40] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:25:40] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:25:40] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:25:40] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:25:41] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:25:41] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:25:41] [comm] Using global sharding
[2023-07-01 11:25:41] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:25:41] [training] Using 1 GPUs
[2023-07-01 11:25:41] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:25:41] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:25:41] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:25:41] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:25:49] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:25:49] [valid] No post-processing script given for validating translator
[2023-07-01 11:25:49] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:25:49] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:25:49] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:25:49] [comm] Using global sharding
[2023-07-01 11:25:49] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:25:49] [training] Using 1 GPUs
[2023-07-01 11:25:49] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:25:49] Allocating memory for general optimizer shards
[2023-07-01 11:25:49] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:25:49] Loading Adam parameters
[2023-07-01 11:25:49] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:25:50] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:25:50] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:25:50] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:25:50] [data] Shuffling data
[2023-07-01 11:25:50] [data] Done reading 20,192 sentences
[2023-07-01 11:25:50] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:25:50] Training started
[2023-07-01 11:25:50] Training finished
[2023-07-01 11:25:53] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:25:53] [marian] Running on node20.datos.cluster.uy as process 15508 with command line:
[2023-07-01 11:25:53] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 75 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:25:53] [config] after: 0e
[2023-07-01 11:25:53] [config] after-batches: 0
[2023-07-01 11:25:53] [config] after-epochs: 75
[2023-07-01 11:25:53] [config] all-caps-every: 0
[2023-07-01 11:25:53] [config] allow-unk: false
[2023-07-01 11:25:53] [config] authors: false
[2023-07-01 11:25:53] [config] beam-size: 12
[2023-07-01 11:25:53] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:25:53] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:25:53] [config] bert-masking-fraction: 0.15
[2023-07-01 11:25:53] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:25:53] [config] bert-train-type-embeddings: true
[2023-07-01 11:25:53] [config] bert-type-vocab-size: 2
[2023-07-01 11:25:53] [config] build-info: ""
[2023-07-01 11:25:53] [config] check-gradient-nan: false
[2023-07-01 11:25:53] [config] check-nan: false
[2023-07-01 11:25:53] [config] cite: false
[2023-07-01 11:25:53] [config] clip-norm: 5
[2023-07-01 11:25:53] [config] cost-scaling:
[2023-07-01 11:25:53] [config]   []
[2023-07-01 11:25:53] [config] cost-type: ce-sum
[2023-07-01 11:25:53] [config] cpu-threads: 0
[2023-07-01 11:25:53] [config] data-threads: 8
[2023-07-01 11:25:53] [config] data-weighting: ""
[2023-07-01 11:25:53] [config] data-weighting-type: sentence
[2023-07-01 11:25:53] [config] dec-cell: gru
[2023-07-01 11:25:53] [config] dec-cell-base-depth: 2
[2023-07-01 11:25:53] [config] dec-cell-high-depth: 1
[2023-07-01 11:25:53] [config] dec-depth: 2
[2023-07-01 11:25:53] [config] devices:
[2023-07-01 11:25:53] [config]   - 0
[2023-07-01 11:25:53] [config] dim-emb: 512
[2023-07-01 11:25:53] [config] dim-rnn: 1024
[2023-07-01 11:25:53] [config] dim-vocabs:
[2023-07-01 11:25:53] [config]   - 16384
[2023-07-01 11:25:53] [config]   - 16384
[2023-07-01 11:25:53] [config] disp-first: 0
[2023-07-01 11:25:53] [config] disp-freq: 1000u
[2023-07-01 11:25:53] [config] disp-label-counts: true
[2023-07-01 11:25:53] [config] dropout-rnn: 0
[2023-07-01 11:25:53] [config] dropout-src: 0
[2023-07-01 11:25:53] [config] dropout-trg: 0
[2023-07-01 11:25:53] [config] dump-config: ""
[2023-07-01 11:25:53] [config] dynamic-gradient-scaling:
[2023-07-01 11:25:53] [config]   []
[2023-07-01 11:25:53] [config] early-stopping: 10
[2023-07-01 11:25:53] [config] early-stopping-on: first
[2023-07-01 11:25:53] [config] embedding-fix-src: false
[2023-07-01 11:25:53] [config] embedding-fix-trg: false
[2023-07-01 11:25:53] [config] embedding-normalization: false
[2023-07-01 11:25:53] [config] embedding-vectors:
[2023-07-01 11:25:53] [config]   []
[2023-07-01 11:25:53] [config] enc-cell: gru
[2023-07-01 11:25:53] [config] enc-cell-depth: 1
[2023-07-01 11:25:53] [config] enc-depth: 2
[2023-07-01 11:25:53] [config] enc-type: bidirectional
[2023-07-01 11:25:53] [config] english-title-case-every: 0
[2023-07-01 11:25:53] [config] exponential-smoothing: 0.0001
[2023-07-01 11:25:53] [config] factor-weight: 1
[2023-07-01 11:25:53] [config] factors-combine: sum
[2023-07-01 11:25:53] [config] factors-dim-emb: 0
[2023-07-01 11:25:53] [config] gradient-checkpointing: false
[2023-07-01 11:25:53] [config] gradient-norm-average-window: 100
[2023-07-01 11:25:53] [config] guided-alignment: none
[2023-07-01 11:25:53] [config] guided-alignment-cost: mse
[2023-07-01 11:25:53] [config] guided-alignment-weight: 0.1
[2023-07-01 11:25:53] [config] ignore-model-config: false
[2023-07-01 11:25:53] [config] input-types:
[2023-07-01 11:25:53] [config]   []
[2023-07-01 11:25:53] [config] interpolate-env-vars: false
[2023-07-01 11:25:53] [config] keep-best: false
[2023-07-01 11:25:53] [config] label-smoothing: 0.1
[2023-07-01 11:25:53] [config] layer-normalization: false
[2023-07-01 11:25:53] [config] learn-rate: 0.0003
[2023-07-01 11:25:53] [config] lemma-dependency: ""
[2023-07-01 11:25:53] [config] lemma-dim-emb: 0
[2023-07-01 11:25:53] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:25:53] [config] log-level: info
[2023-07-01 11:25:53] [config] log-time-zone: ""
[2023-07-01 11:25:53] [config] logical-epoch:
[2023-07-01 11:25:53] [config]   - 1e
[2023-07-01 11:25:53] [config]   - 0
[2023-07-01 11:25:53] [config] lr-decay: 0
[2023-07-01 11:25:53] [config] lr-decay-freq: 50000
[2023-07-01 11:25:53] [config] lr-decay-inv-sqrt:
[2023-07-01 11:25:53] [config]   - 16000
[2023-07-01 11:25:53] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:25:53] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:25:53] [config] lr-decay-start:
[2023-07-01 11:25:53] [config]   - 10
[2023-07-01 11:25:53] [config]   - 1
[2023-07-01 11:25:53] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:25:53] [config] lr-report: true
[2023-07-01 11:25:53] [config] lr-warmup: 16000
[2023-07-01 11:25:53] [config] lr-warmup-at-reload: false
[2023-07-01 11:25:53] [config] lr-warmup-cycle: false
[2023-07-01 11:25:53] [config] lr-warmup-start-rate: 0
[2023-07-01 11:25:53] [config] max-length: 100
[2023-07-01 11:25:53] [config] max-length-crop: false
[2023-07-01 11:25:53] [config] max-length-factor: 3
[2023-07-01 11:25:53] [config] maxi-batch: 100
[2023-07-01 11:25:53] [config] maxi-batch-sort: trg
[2023-07-01 11:25:53] [config] mini-batch: 1000
[2023-07-01 11:25:53] [config] mini-batch-fit: true
[2023-07-01 11:25:53] [config] mini-batch-fit-step: 10
[2023-07-01 11:25:53] [config] mini-batch-round-up: true
[2023-07-01 11:25:53] [config] mini-batch-track-lr: false
[2023-07-01 11:25:53] [config] mini-batch-warmup: 0
[2023-07-01 11:25:53] [config] mini-batch-words: 0
[2023-07-01 11:25:53] [config] mini-batch-words-ref: 0
[2023-07-01 11:25:53] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:25:53] [config] multi-loss-type: sum
[2023-07-01 11:25:53] [config] n-best: false
[2023-07-01 11:25:53] [config] no-nccl: false
[2023-07-01 11:25:53] [config] no-reload: false
[2023-07-01 11:25:53] [config] no-restore-corpus: false
[2023-07-01 11:25:53] [config] normalize: 1
[2023-07-01 11:25:53] [config] normalize-gradient: false
[2023-07-01 11:25:53] [config] num-devices: 0
[2023-07-01 11:25:53] [config] optimizer: adam
[2023-07-01 11:25:53] [config] optimizer-delay: 1
[2023-07-01 11:25:53] [config] optimizer-params:
[2023-07-01 11:25:53] [config]   - 0.9
[2023-07-01 11:25:53] [config]   - 0.98
[2023-07-01 11:25:53] [config]   - 1e-09
[2023-07-01 11:25:53] [config] output-omit-bias: false
[2023-07-01 11:25:53] [config] overwrite: true
[2023-07-01 11:25:53] [config] precision:
[2023-07-01 11:25:53] [config]   - float32
[2023-07-01 11:25:53] [config]   - float32
[2023-07-01 11:25:53] [config] pretrained-model: ""
[2023-07-01 11:25:53] [config] quantize-biases: false
[2023-07-01 11:25:53] [config] quantize-bits: 0
[2023-07-01 11:25:53] [config] quantize-log-based: false
[2023-07-01 11:25:53] [config] quantize-optimization-steps: 0
[2023-07-01 11:25:53] [config] quiet: false
[2023-07-01 11:25:53] [config] quiet-translation: true
[2023-07-01 11:25:53] [config] relative-paths: false
[2023-07-01 11:25:53] [config] right-left: false
[2023-07-01 11:25:53] [config] save-freq: 10000u
[2023-07-01 11:25:53] [config] seed: 1234
[2023-07-01 11:25:53] [config] sentencepiece-alphas:
[2023-07-01 11:25:53] [config]   []
[2023-07-01 11:25:53] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:25:53] [config] sentencepiece-options: ""
[2023-07-01 11:25:53] [config] sharding: global
[2023-07-01 11:25:53] [config] shuffle: data
[2023-07-01 11:25:53] [config] shuffle-in-ram: false
[2023-07-01 11:25:53] [config] sigterm: save-and-exit
[2023-07-01 11:25:53] [config] skip: false
[2023-07-01 11:25:53] [config] sqlite: ""
[2023-07-01 11:25:53] [config] sqlite-drop: false
[2023-07-01 11:25:53] [config] sync-freq: 200u
[2023-07-01 11:25:53] [config] sync-sgd: true
[2023-07-01 11:25:53] [config] tempdir: /tmp
[2023-07-01 11:25:53] [config] tied-embeddings: false
[2023-07-01 11:25:53] [config] tied-embeddings-all: true
[2023-07-01 11:25:53] [config] tied-embeddings-src: false
[2023-07-01 11:25:53] [config] train-embedder-rank:
[2023-07-01 11:25:53] [config]   []
[2023-07-01 11:25:53] [config] train-sets:
[2023-07-01 11:25:53] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:25:53] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:25:53] [config] transformer-aan-activation: swish
[2023-07-01 11:25:53] [config] transformer-aan-depth: 2
[2023-07-01 11:25:53] [config] transformer-aan-nogate: false
[2023-07-01 11:25:53] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:25:53] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:25:53] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:25:53] [config] transformer-depth-scaling: false
[2023-07-01 11:25:53] [config] transformer-dim-aan: 2048
[2023-07-01 11:25:53] [config] transformer-dim-ffn: 2048
[2023-07-01 11:25:53] [config] transformer-dropout: 0.1
[2023-07-01 11:25:53] [config] transformer-dropout-attention: 0
[2023-07-01 11:25:53] [config] transformer-dropout-ffn: 0
[2023-07-01 11:25:53] [config] transformer-ffn-activation: swish
[2023-07-01 11:25:53] [config] transformer-ffn-depth: 2
[2023-07-01 11:25:53] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:25:53] [config] transformer-heads: 8
[2023-07-01 11:25:53] [config] transformer-no-projection: false
[2023-07-01 11:25:53] [config] transformer-pool: false
[2023-07-01 11:25:53] [config] transformer-postprocess: dan
[2023-07-01 11:25:53] [config] transformer-postprocess-emb: d
[2023-07-01 11:25:53] [config] transformer-postprocess-top: ""
[2023-07-01 11:25:53] [config] transformer-preprocess: ""
[2023-07-01 11:25:53] [config] transformer-tied-layers:
[2023-07-01 11:25:53] [config]   []
[2023-07-01 11:25:53] [config] transformer-train-position-embeddings: false
[2023-07-01 11:25:53] [config] tsv: false
[2023-07-01 11:25:53] [config] tsv-fields: 0
[2023-07-01 11:25:53] [config] type: transformer
[2023-07-01 11:25:53] [config] ulr: false
[2023-07-01 11:25:53] [config] ulr-dim-emb: 0
[2023-07-01 11:25:53] [config] ulr-dropout: 0
[2023-07-01 11:25:53] [config] ulr-keys-vectors: ""
[2023-07-01 11:25:53] [config] ulr-query-vectors: ""
[2023-07-01 11:25:53] [config] ulr-softmax-temperature: 1
[2023-07-01 11:25:53] [config] ulr-trainable-transformation: false
[2023-07-01 11:25:53] [config] unlikelihood-loss: false
[2023-07-01 11:25:53] [config] valid-freq: 50000000
[2023-07-01 11:25:53] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:25:53] [config] valid-max-length: 1000
[2023-07-01 11:25:53] [config] valid-metrics:
[2023-07-01 11:25:53] [config]   - cross-entropy
[2023-07-01 11:25:53] [config]   - translation
[2023-07-01 11:25:53] [config] valid-mini-batch: 64
[2023-07-01 11:25:53] [config] valid-reset-stalled: false
[2023-07-01 11:25:53] [config] valid-script-args:
[2023-07-01 11:25:53] [config]   []
[2023-07-01 11:25:53] [config] valid-script-path: ""
[2023-07-01 11:25:53] [config] valid-sets:
[2023-07-01 11:25:53] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:25:53] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:25:53] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:25:53] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:25:53] [config] vocabs:
[2023-07-01 11:25:53] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:25:53] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:25:53] [config] word-penalty: 0
[2023-07-01 11:25:53] [config] word-scores: false
[2023-07-01 11:25:53] [config] workspace: 2048
[2023-07-01 11:25:53] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:25:53] Using synchronous SGD
[2023-07-01 11:25:54] Synced seed 1234
[2023-07-01 11:25:54] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:25:54] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:25:54] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:25:54] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:25:54] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:25:54] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:25:54] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:25:55] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:25:55] [comm] Using global sharding
[2023-07-01 11:25:55] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:25:55] [training] Using 1 GPUs
[2023-07-01 11:25:55] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:25:55] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:25:55] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:25:55] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:26:02] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:26:02] [valid] No post-processing script given for validating translator
[2023-07-01 11:26:03] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:26:03] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:26:03] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:26:03] [comm] Using global sharding
[2023-07-01 11:26:03] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:26:03] [training] Using 1 GPUs
[2023-07-01 11:26:03] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:26:03] Allocating memory for general optimizer shards
[2023-07-01 11:26:03] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:26:03] Loading Adam parameters
[2023-07-01 11:26:03] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:26:03] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:26:03] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:26:03] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:26:03] [data] Shuffling data
[2023-07-01 11:26:03] [data] Done reading 20,192 sentences
[2023-07-01 11:26:03] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:26:03] Training started
[2023-07-01 11:26:03] Training finished
[2023-07-01 11:26:07] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:26:07] [marian] Running on node20.datos.cluster.uy as process 15569 with command line:
[2023-07-01 11:26:07] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 76 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:26:07] [config] after: 0e
[2023-07-01 11:26:07] [config] after-batches: 0
[2023-07-01 11:26:07] [config] after-epochs: 76
[2023-07-01 11:26:07] [config] all-caps-every: 0
[2023-07-01 11:26:07] [config] allow-unk: false
[2023-07-01 11:26:07] [config] authors: false
[2023-07-01 11:26:07] [config] beam-size: 12
[2023-07-01 11:26:07] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:26:07] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:26:07] [config] bert-masking-fraction: 0.15
[2023-07-01 11:26:07] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:26:07] [config] bert-train-type-embeddings: true
[2023-07-01 11:26:07] [config] bert-type-vocab-size: 2
[2023-07-01 11:26:07] [config] build-info: ""
[2023-07-01 11:26:07] [config] check-gradient-nan: false
[2023-07-01 11:26:07] [config] check-nan: false
[2023-07-01 11:26:07] [config] cite: false
[2023-07-01 11:26:07] [config] clip-norm: 5
[2023-07-01 11:26:07] [config] cost-scaling:
[2023-07-01 11:26:07] [config]   []
[2023-07-01 11:26:07] [config] cost-type: ce-sum
[2023-07-01 11:26:07] [config] cpu-threads: 0
[2023-07-01 11:26:07] [config] data-threads: 8
[2023-07-01 11:26:07] [config] data-weighting: ""
[2023-07-01 11:26:07] [config] data-weighting-type: sentence
[2023-07-01 11:26:07] [config] dec-cell: gru
[2023-07-01 11:26:07] [config] dec-cell-base-depth: 2
[2023-07-01 11:26:07] [config] dec-cell-high-depth: 1
[2023-07-01 11:26:07] [config] dec-depth: 2
[2023-07-01 11:26:07] [config] devices:
[2023-07-01 11:26:07] [config]   - 0
[2023-07-01 11:26:07] [config] dim-emb: 512
[2023-07-01 11:26:07] [config] dim-rnn: 1024
[2023-07-01 11:26:07] [config] dim-vocabs:
[2023-07-01 11:26:07] [config]   - 16384
[2023-07-01 11:26:07] [config]   - 16384
[2023-07-01 11:26:07] [config] disp-first: 0
[2023-07-01 11:26:07] [config] disp-freq: 1000u
[2023-07-01 11:26:07] [config] disp-label-counts: true
[2023-07-01 11:26:07] [config] dropout-rnn: 0
[2023-07-01 11:26:07] [config] dropout-src: 0
[2023-07-01 11:26:07] [config] dropout-trg: 0
[2023-07-01 11:26:07] [config] dump-config: ""
[2023-07-01 11:26:07] [config] dynamic-gradient-scaling:
[2023-07-01 11:26:07] [config]   []
[2023-07-01 11:26:07] [config] early-stopping: 10
[2023-07-01 11:26:07] [config] early-stopping-on: first
[2023-07-01 11:26:07] [config] embedding-fix-src: false
[2023-07-01 11:26:07] [config] embedding-fix-trg: false
[2023-07-01 11:26:07] [config] embedding-normalization: false
[2023-07-01 11:26:07] [config] embedding-vectors:
[2023-07-01 11:26:07] [config]   []
[2023-07-01 11:26:07] [config] enc-cell: gru
[2023-07-01 11:26:07] [config] enc-cell-depth: 1
[2023-07-01 11:26:07] [config] enc-depth: 2
[2023-07-01 11:26:07] [config] enc-type: bidirectional
[2023-07-01 11:26:07] [config] english-title-case-every: 0
[2023-07-01 11:26:07] [config] exponential-smoothing: 0.0001
[2023-07-01 11:26:07] [config] factor-weight: 1
[2023-07-01 11:26:07] [config] factors-combine: sum
[2023-07-01 11:26:07] [config] factors-dim-emb: 0
[2023-07-01 11:26:07] [config] gradient-checkpointing: false
[2023-07-01 11:26:07] [config] gradient-norm-average-window: 100
[2023-07-01 11:26:07] [config] guided-alignment: none
[2023-07-01 11:26:07] [config] guided-alignment-cost: mse
[2023-07-01 11:26:07] [config] guided-alignment-weight: 0.1
[2023-07-01 11:26:07] [config] ignore-model-config: false
[2023-07-01 11:26:07] [config] input-types:
[2023-07-01 11:26:07] [config]   []
[2023-07-01 11:26:07] [config] interpolate-env-vars: false
[2023-07-01 11:26:07] [config] keep-best: false
[2023-07-01 11:26:07] [config] label-smoothing: 0.1
[2023-07-01 11:26:07] [config] layer-normalization: false
[2023-07-01 11:26:07] [config] learn-rate: 0.0003
[2023-07-01 11:26:07] [config] lemma-dependency: ""
[2023-07-01 11:26:07] [config] lemma-dim-emb: 0
[2023-07-01 11:26:07] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:26:07] [config] log-level: info
[2023-07-01 11:26:07] [config] log-time-zone: ""
[2023-07-01 11:26:07] [config] logical-epoch:
[2023-07-01 11:26:07] [config]   - 1e
[2023-07-01 11:26:07] [config]   - 0
[2023-07-01 11:26:07] [config] lr-decay: 0
[2023-07-01 11:26:07] [config] lr-decay-freq: 50000
[2023-07-01 11:26:07] [config] lr-decay-inv-sqrt:
[2023-07-01 11:26:07] [config]   - 16000
[2023-07-01 11:26:07] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:26:07] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:26:07] [config] lr-decay-start:
[2023-07-01 11:26:07] [config]   - 10
[2023-07-01 11:26:07] [config]   - 1
[2023-07-01 11:26:07] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:26:07] [config] lr-report: true
[2023-07-01 11:26:07] [config] lr-warmup: 16000
[2023-07-01 11:26:07] [config] lr-warmup-at-reload: false
[2023-07-01 11:26:07] [config] lr-warmup-cycle: false
[2023-07-01 11:26:07] [config] lr-warmup-start-rate: 0
[2023-07-01 11:26:07] [config] max-length: 100
[2023-07-01 11:26:07] [config] max-length-crop: false
[2023-07-01 11:26:07] [config] max-length-factor: 3
[2023-07-01 11:26:07] [config] maxi-batch: 100
[2023-07-01 11:26:07] [config] maxi-batch-sort: trg
[2023-07-01 11:26:07] [config] mini-batch: 1000
[2023-07-01 11:26:07] [config] mini-batch-fit: true
[2023-07-01 11:26:07] [config] mini-batch-fit-step: 10
[2023-07-01 11:26:07] [config] mini-batch-round-up: true
[2023-07-01 11:26:07] [config] mini-batch-track-lr: false
[2023-07-01 11:26:07] [config] mini-batch-warmup: 0
[2023-07-01 11:26:07] [config] mini-batch-words: 0
[2023-07-01 11:26:07] [config] mini-batch-words-ref: 0
[2023-07-01 11:26:07] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:26:07] [config] multi-loss-type: sum
[2023-07-01 11:26:07] [config] n-best: false
[2023-07-01 11:26:07] [config] no-nccl: false
[2023-07-01 11:26:07] [config] no-reload: false
[2023-07-01 11:26:07] [config] no-restore-corpus: false
[2023-07-01 11:26:07] [config] normalize: 1
[2023-07-01 11:26:07] [config] normalize-gradient: false
[2023-07-01 11:26:07] [config] num-devices: 0
[2023-07-01 11:26:07] [config] optimizer: adam
[2023-07-01 11:26:07] [config] optimizer-delay: 1
[2023-07-01 11:26:07] [config] optimizer-params:
[2023-07-01 11:26:07] [config]   - 0.9
[2023-07-01 11:26:07] [config]   - 0.98
[2023-07-01 11:26:07] [config]   - 1e-09
[2023-07-01 11:26:07] [config] output-omit-bias: false
[2023-07-01 11:26:07] [config] overwrite: true
[2023-07-01 11:26:07] [config] precision:
[2023-07-01 11:26:07] [config]   - float32
[2023-07-01 11:26:07] [config]   - float32
[2023-07-01 11:26:07] [config] pretrained-model: ""
[2023-07-01 11:26:07] [config] quantize-biases: false
[2023-07-01 11:26:07] [config] quantize-bits: 0
[2023-07-01 11:26:07] [config] quantize-log-based: false
[2023-07-01 11:26:07] [config] quantize-optimization-steps: 0
[2023-07-01 11:26:07] [config] quiet: false
[2023-07-01 11:26:07] [config] quiet-translation: true
[2023-07-01 11:26:07] [config] relative-paths: false
[2023-07-01 11:26:07] [config] right-left: false
[2023-07-01 11:26:07] [config] save-freq: 10000u
[2023-07-01 11:26:07] [config] seed: 1234
[2023-07-01 11:26:07] [config] sentencepiece-alphas:
[2023-07-01 11:26:07] [config]   []
[2023-07-01 11:26:07] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:26:07] [config] sentencepiece-options: ""
[2023-07-01 11:26:07] [config] sharding: global
[2023-07-01 11:26:07] [config] shuffle: data
[2023-07-01 11:26:07] [config] shuffle-in-ram: false
[2023-07-01 11:26:07] [config] sigterm: save-and-exit
[2023-07-01 11:26:07] [config] skip: false
[2023-07-01 11:26:07] [config] sqlite: ""
[2023-07-01 11:26:07] [config] sqlite-drop: false
[2023-07-01 11:26:07] [config] sync-freq: 200u
[2023-07-01 11:26:07] [config] sync-sgd: true
[2023-07-01 11:26:07] [config] tempdir: /tmp
[2023-07-01 11:26:07] [config] tied-embeddings: false
[2023-07-01 11:26:07] [config] tied-embeddings-all: true
[2023-07-01 11:26:07] [config] tied-embeddings-src: false
[2023-07-01 11:26:07] [config] train-embedder-rank:
[2023-07-01 11:26:07] [config]   []
[2023-07-01 11:26:07] [config] train-sets:
[2023-07-01 11:26:07] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:26:07] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:26:07] [config] transformer-aan-activation: swish
[2023-07-01 11:26:07] [config] transformer-aan-depth: 2
[2023-07-01 11:26:07] [config] transformer-aan-nogate: false
[2023-07-01 11:26:07] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:26:07] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:26:07] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:26:07] [config] transformer-depth-scaling: false
[2023-07-01 11:26:07] [config] transformer-dim-aan: 2048
[2023-07-01 11:26:07] [config] transformer-dim-ffn: 2048
[2023-07-01 11:26:07] [config] transformer-dropout: 0.1
[2023-07-01 11:26:07] [config] transformer-dropout-attention: 0
[2023-07-01 11:26:07] [config] transformer-dropout-ffn: 0
[2023-07-01 11:26:07] [config] transformer-ffn-activation: swish
[2023-07-01 11:26:07] [config] transformer-ffn-depth: 2
[2023-07-01 11:26:07] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:26:07] [config] transformer-heads: 8
[2023-07-01 11:26:07] [config] transformer-no-projection: false
[2023-07-01 11:26:07] [config] transformer-pool: false
[2023-07-01 11:26:07] [config] transformer-postprocess: dan
[2023-07-01 11:26:07] [config] transformer-postprocess-emb: d
[2023-07-01 11:26:07] [config] transformer-postprocess-top: ""
[2023-07-01 11:26:07] [config] transformer-preprocess: ""
[2023-07-01 11:26:07] [config] transformer-tied-layers:
[2023-07-01 11:26:07] [config]   []
[2023-07-01 11:26:07] [config] transformer-train-position-embeddings: false
[2023-07-01 11:26:07] [config] tsv: false
[2023-07-01 11:26:07] [config] tsv-fields: 0
[2023-07-01 11:26:07] [config] type: transformer
[2023-07-01 11:26:07] [config] ulr: false
[2023-07-01 11:26:07] [config] ulr-dim-emb: 0
[2023-07-01 11:26:07] [config] ulr-dropout: 0
[2023-07-01 11:26:07] [config] ulr-keys-vectors: ""
[2023-07-01 11:26:07] [config] ulr-query-vectors: ""
[2023-07-01 11:26:07] [config] ulr-softmax-temperature: 1
[2023-07-01 11:26:07] [config] ulr-trainable-transformation: false
[2023-07-01 11:26:07] [config] unlikelihood-loss: false
[2023-07-01 11:26:07] [config] valid-freq: 50000000
[2023-07-01 11:26:07] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:26:07] [config] valid-max-length: 1000
[2023-07-01 11:26:07] [config] valid-metrics:
[2023-07-01 11:26:07] [config]   - cross-entropy
[2023-07-01 11:26:07] [config]   - translation
[2023-07-01 11:26:07] [config] valid-mini-batch: 64
[2023-07-01 11:26:07] [config] valid-reset-stalled: false
[2023-07-01 11:26:07] [config] valid-script-args:
[2023-07-01 11:26:07] [config]   []
[2023-07-01 11:26:07] [config] valid-script-path: ""
[2023-07-01 11:26:07] [config] valid-sets:
[2023-07-01 11:26:07] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:26:07] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:26:07] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:26:07] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:26:07] [config] vocabs:
[2023-07-01 11:26:07] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:26:07] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:26:07] [config] word-penalty: 0
[2023-07-01 11:26:07] [config] word-scores: false
[2023-07-01 11:26:07] [config] workspace: 2048
[2023-07-01 11:26:07] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:26:07] Using synchronous SGD
[2023-07-01 11:26:07] Synced seed 1234
[2023-07-01 11:26:07] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:26:07] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:26:07] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:26:07] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:26:07] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:26:07] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:26:08] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:26:08] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:26:08] [comm] Using global sharding
[2023-07-01 11:26:08] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:26:08] [training] Using 1 GPUs
[2023-07-01 11:26:08] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:26:08] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:26:08] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:26:08] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:26:16] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:26:16] [valid] No post-processing script given for validating translator
[2023-07-01 11:26:16] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:26:16] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:26:16] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:26:16] [comm] Using global sharding
[2023-07-01 11:26:16] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:26:16] [training] Using 1 GPUs
[2023-07-01 11:26:16] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:26:16] Allocating memory for general optimizer shards
[2023-07-01 11:26:16] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:26:17] Loading Adam parameters
[2023-07-01 11:26:17] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:26:17] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:26:17] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:26:17] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:26:17] [data] Shuffling data
[2023-07-01 11:26:17] [data] Done reading 20,192 sentences
[2023-07-01 11:26:17] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:26:17] Training started
[2023-07-01 11:26:17] Training finished
[2023-07-01 11:26:20] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:26:20] [marian] Running on node20.datos.cluster.uy as process 15627 with command line:
[2023-07-01 11:26:20] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 77 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:26:20] [config] after: 0e
[2023-07-01 11:26:20] [config] after-batches: 0
[2023-07-01 11:26:20] [config] after-epochs: 77
[2023-07-01 11:26:20] [config] all-caps-every: 0
[2023-07-01 11:26:20] [config] allow-unk: false
[2023-07-01 11:26:20] [config] authors: false
[2023-07-01 11:26:20] [config] beam-size: 12
[2023-07-01 11:26:20] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:26:20] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:26:20] [config] bert-masking-fraction: 0.15
[2023-07-01 11:26:20] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:26:20] [config] bert-train-type-embeddings: true
[2023-07-01 11:26:20] [config] bert-type-vocab-size: 2
[2023-07-01 11:26:20] [config] build-info: ""
[2023-07-01 11:26:20] [config] check-gradient-nan: false
[2023-07-01 11:26:20] [config] check-nan: false
[2023-07-01 11:26:20] [config] cite: false
[2023-07-01 11:26:20] [config] clip-norm: 5
[2023-07-01 11:26:20] [config] cost-scaling:
[2023-07-01 11:26:20] [config]   []
[2023-07-01 11:26:20] [config] cost-type: ce-sum
[2023-07-01 11:26:20] [config] cpu-threads: 0
[2023-07-01 11:26:20] [config] data-threads: 8
[2023-07-01 11:26:20] [config] data-weighting: ""
[2023-07-01 11:26:20] [config] data-weighting-type: sentence
[2023-07-01 11:26:20] [config] dec-cell: gru
[2023-07-01 11:26:20] [config] dec-cell-base-depth: 2
[2023-07-01 11:26:20] [config] dec-cell-high-depth: 1
[2023-07-01 11:26:20] [config] dec-depth: 2
[2023-07-01 11:26:20] [config] devices:
[2023-07-01 11:26:20] [config]   - 0
[2023-07-01 11:26:20] [config] dim-emb: 512
[2023-07-01 11:26:20] [config] dim-rnn: 1024
[2023-07-01 11:26:20] [config] dim-vocabs:
[2023-07-01 11:26:20] [config]   - 16384
[2023-07-01 11:26:20] [config]   - 16384
[2023-07-01 11:26:20] [config] disp-first: 0
[2023-07-01 11:26:20] [config] disp-freq: 1000u
[2023-07-01 11:26:20] [config] disp-label-counts: true
[2023-07-01 11:26:20] [config] dropout-rnn: 0
[2023-07-01 11:26:20] [config] dropout-src: 0
[2023-07-01 11:26:20] [config] dropout-trg: 0
[2023-07-01 11:26:20] [config] dump-config: ""
[2023-07-01 11:26:20] [config] dynamic-gradient-scaling:
[2023-07-01 11:26:20] [config]   []
[2023-07-01 11:26:20] [config] early-stopping: 10
[2023-07-01 11:26:20] [config] early-stopping-on: first
[2023-07-01 11:26:20] [config] embedding-fix-src: false
[2023-07-01 11:26:20] [config] embedding-fix-trg: false
[2023-07-01 11:26:20] [config] embedding-normalization: false
[2023-07-01 11:26:20] [config] embedding-vectors:
[2023-07-01 11:26:20] [config]   []
[2023-07-01 11:26:20] [config] enc-cell: gru
[2023-07-01 11:26:20] [config] enc-cell-depth: 1
[2023-07-01 11:26:20] [config] enc-depth: 2
[2023-07-01 11:26:20] [config] enc-type: bidirectional
[2023-07-01 11:26:20] [config] english-title-case-every: 0
[2023-07-01 11:26:20] [config] exponential-smoothing: 0.0001
[2023-07-01 11:26:20] [config] factor-weight: 1
[2023-07-01 11:26:20] [config] factors-combine: sum
[2023-07-01 11:26:20] [config] factors-dim-emb: 0
[2023-07-01 11:26:20] [config] gradient-checkpointing: false
[2023-07-01 11:26:20] [config] gradient-norm-average-window: 100
[2023-07-01 11:26:20] [config] guided-alignment: none
[2023-07-01 11:26:20] [config] guided-alignment-cost: mse
[2023-07-01 11:26:20] [config] guided-alignment-weight: 0.1
[2023-07-01 11:26:20] [config] ignore-model-config: false
[2023-07-01 11:26:20] [config] input-types:
[2023-07-01 11:26:20] [config]   []
[2023-07-01 11:26:20] [config] interpolate-env-vars: false
[2023-07-01 11:26:20] [config] keep-best: false
[2023-07-01 11:26:20] [config] label-smoothing: 0.1
[2023-07-01 11:26:20] [config] layer-normalization: false
[2023-07-01 11:26:20] [config] learn-rate: 0.0003
[2023-07-01 11:26:20] [config] lemma-dependency: ""
[2023-07-01 11:26:20] [config] lemma-dim-emb: 0
[2023-07-01 11:26:20] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:26:20] [config] log-level: info
[2023-07-01 11:26:20] [config] log-time-zone: ""
[2023-07-01 11:26:20] [config] logical-epoch:
[2023-07-01 11:26:20] [config]   - 1e
[2023-07-01 11:26:20] [config]   - 0
[2023-07-01 11:26:20] [config] lr-decay: 0
[2023-07-01 11:26:20] [config] lr-decay-freq: 50000
[2023-07-01 11:26:20] [config] lr-decay-inv-sqrt:
[2023-07-01 11:26:20] [config]   - 16000
[2023-07-01 11:26:20] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:26:20] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:26:20] [config] lr-decay-start:
[2023-07-01 11:26:20] [config]   - 10
[2023-07-01 11:26:20] [config]   - 1
[2023-07-01 11:26:20] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:26:20] [config] lr-report: true
[2023-07-01 11:26:20] [config] lr-warmup: 16000
[2023-07-01 11:26:20] [config] lr-warmup-at-reload: false
[2023-07-01 11:26:20] [config] lr-warmup-cycle: false
[2023-07-01 11:26:20] [config] lr-warmup-start-rate: 0
[2023-07-01 11:26:20] [config] max-length: 100
[2023-07-01 11:26:20] [config] max-length-crop: false
[2023-07-01 11:26:20] [config] max-length-factor: 3
[2023-07-01 11:26:20] [config] maxi-batch: 100
[2023-07-01 11:26:20] [config] maxi-batch-sort: trg
[2023-07-01 11:26:20] [config] mini-batch: 1000
[2023-07-01 11:26:20] [config] mini-batch-fit: true
[2023-07-01 11:26:20] [config] mini-batch-fit-step: 10
[2023-07-01 11:26:20] [config] mini-batch-round-up: true
[2023-07-01 11:26:20] [config] mini-batch-track-lr: false
[2023-07-01 11:26:20] [config] mini-batch-warmup: 0
[2023-07-01 11:26:20] [config] mini-batch-words: 0
[2023-07-01 11:26:20] [config] mini-batch-words-ref: 0
[2023-07-01 11:26:20] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:26:20] [config] multi-loss-type: sum
[2023-07-01 11:26:20] [config] n-best: false
[2023-07-01 11:26:20] [config] no-nccl: false
[2023-07-01 11:26:20] [config] no-reload: false
[2023-07-01 11:26:20] [config] no-restore-corpus: false
[2023-07-01 11:26:20] [config] normalize: 1
[2023-07-01 11:26:20] [config] normalize-gradient: false
[2023-07-01 11:26:20] [config] num-devices: 0
[2023-07-01 11:26:20] [config] optimizer: adam
[2023-07-01 11:26:20] [config] optimizer-delay: 1
[2023-07-01 11:26:20] [config] optimizer-params:
[2023-07-01 11:26:20] [config]   - 0.9
[2023-07-01 11:26:20] [config]   - 0.98
[2023-07-01 11:26:20] [config]   - 1e-09
[2023-07-01 11:26:20] [config] output-omit-bias: false
[2023-07-01 11:26:20] [config] overwrite: true
[2023-07-01 11:26:20] [config] precision:
[2023-07-01 11:26:20] [config]   - float32
[2023-07-01 11:26:20] [config]   - float32
[2023-07-01 11:26:20] [config] pretrained-model: ""
[2023-07-01 11:26:20] [config] quantize-biases: false
[2023-07-01 11:26:20] [config] quantize-bits: 0
[2023-07-01 11:26:20] [config] quantize-log-based: false
[2023-07-01 11:26:20] [config] quantize-optimization-steps: 0
[2023-07-01 11:26:20] [config] quiet: false
[2023-07-01 11:26:20] [config] quiet-translation: true
[2023-07-01 11:26:20] [config] relative-paths: false
[2023-07-01 11:26:20] [config] right-left: false
[2023-07-01 11:26:20] [config] save-freq: 10000u
[2023-07-01 11:26:20] [config] seed: 1234
[2023-07-01 11:26:20] [config] sentencepiece-alphas:
[2023-07-01 11:26:20] [config]   []
[2023-07-01 11:26:20] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:26:20] [config] sentencepiece-options: ""
[2023-07-01 11:26:20] [config] sharding: global
[2023-07-01 11:26:20] [config] shuffle: data
[2023-07-01 11:26:20] [config] shuffle-in-ram: false
[2023-07-01 11:26:20] [config] sigterm: save-and-exit
[2023-07-01 11:26:20] [config] skip: false
[2023-07-01 11:26:20] [config] sqlite: ""
[2023-07-01 11:26:20] [config] sqlite-drop: false
[2023-07-01 11:26:20] [config] sync-freq: 200u
[2023-07-01 11:26:20] [config] sync-sgd: true
[2023-07-01 11:26:20] [config] tempdir: /tmp
[2023-07-01 11:26:20] [config] tied-embeddings: false
[2023-07-01 11:26:20] [config] tied-embeddings-all: true
[2023-07-01 11:26:20] [config] tied-embeddings-src: false
[2023-07-01 11:26:20] [config] train-embedder-rank:
[2023-07-01 11:26:20] [config]   []
[2023-07-01 11:26:20] [config] train-sets:
[2023-07-01 11:26:20] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:26:20] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:26:20] [config] transformer-aan-activation: swish
[2023-07-01 11:26:20] [config] transformer-aan-depth: 2
[2023-07-01 11:26:20] [config] transformer-aan-nogate: false
[2023-07-01 11:26:20] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:26:20] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:26:20] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:26:20] [config] transformer-depth-scaling: false
[2023-07-01 11:26:20] [config] transformer-dim-aan: 2048
[2023-07-01 11:26:20] [config] transformer-dim-ffn: 2048
[2023-07-01 11:26:20] [config] transformer-dropout: 0.1
[2023-07-01 11:26:20] [config] transformer-dropout-attention: 0
[2023-07-01 11:26:20] [config] transformer-dropout-ffn: 0
[2023-07-01 11:26:20] [config] transformer-ffn-activation: swish
[2023-07-01 11:26:20] [config] transformer-ffn-depth: 2
[2023-07-01 11:26:20] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:26:20] [config] transformer-heads: 8
[2023-07-01 11:26:20] [config] transformer-no-projection: false
[2023-07-01 11:26:20] [config] transformer-pool: false
[2023-07-01 11:26:20] [config] transformer-postprocess: dan
[2023-07-01 11:26:20] [config] transformer-postprocess-emb: d
[2023-07-01 11:26:20] [config] transformer-postprocess-top: ""
[2023-07-01 11:26:20] [config] transformer-preprocess: ""
[2023-07-01 11:26:20] [config] transformer-tied-layers:
[2023-07-01 11:26:20] [config]   []
[2023-07-01 11:26:20] [config] transformer-train-position-embeddings: false
[2023-07-01 11:26:20] [config] tsv: false
[2023-07-01 11:26:20] [config] tsv-fields: 0
[2023-07-01 11:26:20] [config] type: transformer
[2023-07-01 11:26:20] [config] ulr: false
[2023-07-01 11:26:20] [config] ulr-dim-emb: 0
[2023-07-01 11:26:20] [config] ulr-dropout: 0
[2023-07-01 11:26:20] [config] ulr-keys-vectors: ""
[2023-07-01 11:26:20] [config] ulr-query-vectors: ""
[2023-07-01 11:26:20] [config] ulr-softmax-temperature: 1
[2023-07-01 11:26:20] [config] ulr-trainable-transformation: false
[2023-07-01 11:26:20] [config] unlikelihood-loss: false
[2023-07-01 11:26:20] [config] valid-freq: 50000000
[2023-07-01 11:26:20] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:26:20] [config] valid-max-length: 1000
[2023-07-01 11:26:20] [config] valid-metrics:
[2023-07-01 11:26:20] [config]   - cross-entropy
[2023-07-01 11:26:20] [config]   - translation
[2023-07-01 11:26:20] [config] valid-mini-batch: 64
[2023-07-01 11:26:20] [config] valid-reset-stalled: false
[2023-07-01 11:26:20] [config] valid-script-args:
[2023-07-01 11:26:20] [config]   []
[2023-07-01 11:26:20] [config] valid-script-path: ""
[2023-07-01 11:26:20] [config] valid-sets:
[2023-07-01 11:26:20] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:26:20] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:26:20] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:26:20] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:26:20] [config] vocabs:
[2023-07-01 11:26:20] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:26:20] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:26:20] [config] word-penalty: 0
[2023-07-01 11:26:20] [config] word-scores: false
[2023-07-01 11:26:20] [config] workspace: 2048
[2023-07-01 11:26:20] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:26:20] Using synchronous SGD
[2023-07-01 11:26:20] Synced seed 1234
[2023-07-01 11:26:20] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:26:20] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:26:20] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:26:20] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:26:20] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:26:20] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:26:21] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:26:21] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:26:21] [comm] Using global sharding
[2023-07-01 11:26:21] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:26:21] [training] Using 1 GPUs
[2023-07-01 11:26:21] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:26:21] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:26:22] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:26:22] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:26:29] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:26:29] [valid] No post-processing script given for validating translator
[2023-07-01 11:26:29] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:26:29] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:26:29] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:26:29] [comm] Using global sharding
[2023-07-01 11:26:29] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:26:29] [training] Using 1 GPUs
[2023-07-01 11:26:29] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:26:30] Allocating memory for general optimizer shards
[2023-07-01 11:26:30] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:26:30] Loading Adam parameters
[2023-07-01 11:26:30] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:26:30] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:26:30] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:26:30] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:26:30] [data] Shuffling data
[2023-07-01 11:26:30] [data] Done reading 20,192 sentences
[2023-07-01 11:26:30] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:26:30] Training started
[2023-07-01 11:26:30] Training finished
[2023-07-01 11:26:34] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:26:34] [marian] Running on node20.datos.cluster.uy as process 15685 with command line:
[2023-07-01 11:26:34] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 78 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:26:34] [config] after: 0e
[2023-07-01 11:26:34] [config] after-batches: 0
[2023-07-01 11:26:34] [config] after-epochs: 78
[2023-07-01 11:26:34] [config] all-caps-every: 0
[2023-07-01 11:26:34] [config] allow-unk: false
[2023-07-01 11:26:34] [config] authors: false
[2023-07-01 11:26:34] [config] beam-size: 12
[2023-07-01 11:26:34] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:26:34] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:26:34] [config] bert-masking-fraction: 0.15
[2023-07-01 11:26:34] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:26:34] [config] bert-train-type-embeddings: true
[2023-07-01 11:26:34] [config] bert-type-vocab-size: 2
[2023-07-01 11:26:34] [config] build-info: ""
[2023-07-01 11:26:34] [config] check-gradient-nan: false
[2023-07-01 11:26:34] [config] check-nan: false
[2023-07-01 11:26:34] [config] cite: false
[2023-07-01 11:26:34] [config] clip-norm: 5
[2023-07-01 11:26:34] [config] cost-scaling:
[2023-07-01 11:26:34] [config]   []
[2023-07-01 11:26:34] [config] cost-type: ce-sum
[2023-07-01 11:26:34] [config] cpu-threads: 0
[2023-07-01 11:26:34] [config] data-threads: 8
[2023-07-01 11:26:34] [config] data-weighting: ""
[2023-07-01 11:26:34] [config] data-weighting-type: sentence
[2023-07-01 11:26:34] [config] dec-cell: gru
[2023-07-01 11:26:34] [config] dec-cell-base-depth: 2
[2023-07-01 11:26:34] [config] dec-cell-high-depth: 1
[2023-07-01 11:26:34] [config] dec-depth: 2
[2023-07-01 11:26:34] [config] devices:
[2023-07-01 11:26:34] [config]   - 0
[2023-07-01 11:26:34] [config] dim-emb: 512
[2023-07-01 11:26:34] [config] dim-rnn: 1024
[2023-07-01 11:26:34] [config] dim-vocabs:
[2023-07-01 11:26:34] [config]   - 16384
[2023-07-01 11:26:34] [config]   - 16384
[2023-07-01 11:26:34] [config] disp-first: 0
[2023-07-01 11:26:34] [config] disp-freq: 1000u
[2023-07-01 11:26:34] [config] disp-label-counts: true
[2023-07-01 11:26:34] [config] dropout-rnn: 0
[2023-07-01 11:26:34] [config] dropout-src: 0
[2023-07-01 11:26:34] [config] dropout-trg: 0
[2023-07-01 11:26:34] [config] dump-config: ""
[2023-07-01 11:26:34] [config] dynamic-gradient-scaling:
[2023-07-01 11:26:34] [config]   []
[2023-07-01 11:26:34] [config] early-stopping: 10
[2023-07-01 11:26:34] [config] early-stopping-on: first
[2023-07-01 11:26:34] [config] embedding-fix-src: false
[2023-07-01 11:26:34] [config] embedding-fix-trg: false
[2023-07-01 11:26:34] [config] embedding-normalization: false
[2023-07-01 11:26:34] [config] embedding-vectors:
[2023-07-01 11:26:34] [config]   []
[2023-07-01 11:26:34] [config] enc-cell: gru
[2023-07-01 11:26:34] [config] enc-cell-depth: 1
[2023-07-01 11:26:34] [config] enc-depth: 2
[2023-07-01 11:26:34] [config] enc-type: bidirectional
[2023-07-01 11:26:34] [config] english-title-case-every: 0
[2023-07-01 11:26:34] [config] exponential-smoothing: 0.0001
[2023-07-01 11:26:34] [config] factor-weight: 1
[2023-07-01 11:26:34] [config] factors-combine: sum
[2023-07-01 11:26:34] [config] factors-dim-emb: 0
[2023-07-01 11:26:34] [config] gradient-checkpointing: false
[2023-07-01 11:26:34] [config] gradient-norm-average-window: 100
[2023-07-01 11:26:34] [config] guided-alignment: none
[2023-07-01 11:26:34] [config] guided-alignment-cost: mse
[2023-07-01 11:26:34] [config] guided-alignment-weight: 0.1
[2023-07-01 11:26:34] [config] ignore-model-config: false
[2023-07-01 11:26:34] [config] input-types:
[2023-07-01 11:26:34] [config]   []
[2023-07-01 11:26:34] [config] interpolate-env-vars: false
[2023-07-01 11:26:34] [config] keep-best: false
[2023-07-01 11:26:34] [config] label-smoothing: 0.1
[2023-07-01 11:26:34] [config] layer-normalization: false
[2023-07-01 11:26:34] [config] learn-rate: 0.0003
[2023-07-01 11:26:34] [config] lemma-dependency: ""
[2023-07-01 11:26:34] [config] lemma-dim-emb: 0
[2023-07-01 11:26:34] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:26:34] [config] log-level: info
[2023-07-01 11:26:34] [config] log-time-zone: ""
[2023-07-01 11:26:34] [config] logical-epoch:
[2023-07-01 11:26:34] [config]   - 1e
[2023-07-01 11:26:34] [config]   - 0
[2023-07-01 11:26:34] [config] lr-decay: 0
[2023-07-01 11:26:34] [config] lr-decay-freq: 50000
[2023-07-01 11:26:34] [config] lr-decay-inv-sqrt:
[2023-07-01 11:26:34] [config]   - 16000
[2023-07-01 11:26:34] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:26:34] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:26:34] [config] lr-decay-start:
[2023-07-01 11:26:34] [config]   - 10
[2023-07-01 11:26:34] [config]   - 1
[2023-07-01 11:26:34] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:26:34] [config] lr-report: true
[2023-07-01 11:26:34] [config] lr-warmup: 16000
[2023-07-01 11:26:34] [config] lr-warmup-at-reload: false
[2023-07-01 11:26:34] [config] lr-warmup-cycle: false
[2023-07-01 11:26:34] [config] lr-warmup-start-rate: 0
[2023-07-01 11:26:34] [config] max-length: 100
[2023-07-01 11:26:34] [config] max-length-crop: false
[2023-07-01 11:26:34] [config] max-length-factor: 3
[2023-07-01 11:26:34] [config] maxi-batch: 100
[2023-07-01 11:26:34] [config] maxi-batch-sort: trg
[2023-07-01 11:26:34] [config] mini-batch: 1000
[2023-07-01 11:26:34] [config] mini-batch-fit: true
[2023-07-01 11:26:34] [config] mini-batch-fit-step: 10
[2023-07-01 11:26:34] [config] mini-batch-round-up: true
[2023-07-01 11:26:34] [config] mini-batch-track-lr: false
[2023-07-01 11:26:34] [config] mini-batch-warmup: 0
[2023-07-01 11:26:34] [config] mini-batch-words: 0
[2023-07-01 11:26:34] [config] mini-batch-words-ref: 0
[2023-07-01 11:26:34] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:26:34] [config] multi-loss-type: sum
[2023-07-01 11:26:34] [config] n-best: false
[2023-07-01 11:26:34] [config] no-nccl: false
[2023-07-01 11:26:34] [config] no-reload: false
[2023-07-01 11:26:34] [config] no-restore-corpus: false
[2023-07-01 11:26:34] [config] normalize: 1
[2023-07-01 11:26:34] [config] normalize-gradient: false
[2023-07-01 11:26:34] [config] num-devices: 0
[2023-07-01 11:26:34] [config] optimizer: adam
[2023-07-01 11:26:34] [config] optimizer-delay: 1
[2023-07-01 11:26:34] [config] optimizer-params:
[2023-07-01 11:26:34] [config]   - 0.9
[2023-07-01 11:26:34] [config]   - 0.98
[2023-07-01 11:26:34] [config]   - 1e-09
[2023-07-01 11:26:34] [config] output-omit-bias: false
[2023-07-01 11:26:34] [config] overwrite: true
[2023-07-01 11:26:34] [config] precision:
[2023-07-01 11:26:34] [config]   - float32
[2023-07-01 11:26:34] [config]   - float32
[2023-07-01 11:26:34] [config] pretrained-model: ""
[2023-07-01 11:26:34] [config] quantize-biases: false
[2023-07-01 11:26:34] [config] quantize-bits: 0
[2023-07-01 11:26:34] [config] quantize-log-based: false
[2023-07-01 11:26:34] [config] quantize-optimization-steps: 0
[2023-07-01 11:26:34] [config] quiet: false
[2023-07-01 11:26:34] [config] quiet-translation: true
[2023-07-01 11:26:34] [config] relative-paths: false
[2023-07-01 11:26:34] [config] right-left: false
[2023-07-01 11:26:34] [config] save-freq: 10000u
[2023-07-01 11:26:34] [config] seed: 1234
[2023-07-01 11:26:34] [config] sentencepiece-alphas:
[2023-07-01 11:26:34] [config]   []
[2023-07-01 11:26:34] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:26:34] [config] sentencepiece-options: ""
[2023-07-01 11:26:34] [config] sharding: global
[2023-07-01 11:26:34] [config] shuffle: data
[2023-07-01 11:26:34] [config] shuffle-in-ram: false
[2023-07-01 11:26:34] [config] sigterm: save-and-exit
[2023-07-01 11:26:34] [config] skip: false
[2023-07-01 11:26:34] [config] sqlite: ""
[2023-07-01 11:26:34] [config] sqlite-drop: false
[2023-07-01 11:26:34] [config] sync-freq: 200u
[2023-07-01 11:26:34] [config] sync-sgd: true
[2023-07-01 11:26:34] [config] tempdir: /tmp
[2023-07-01 11:26:34] [config] tied-embeddings: false
[2023-07-01 11:26:34] [config] tied-embeddings-all: true
[2023-07-01 11:26:34] [config] tied-embeddings-src: false
[2023-07-01 11:26:34] [config] train-embedder-rank:
[2023-07-01 11:26:34] [config]   []
[2023-07-01 11:26:34] [config] train-sets:
[2023-07-01 11:26:34] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:26:34] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:26:34] [config] transformer-aan-activation: swish
[2023-07-01 11:26:34] [config] transformer-aan-depth: 2
[2023-07-01 11:26:34] [config] transformer-aan-nogate: false
[2023-07-01 11:26:34] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:26:34] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:26:34] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:26:34] [config] transformer-depth-scaling: false
[2023-07-01 11:26:34] [config] transformer-dim-aan: 2048
[2023-07-01 11:26:34] [config] transformer-dim-ffn: 2048
[2023-07-01 11:26:34] [config] transformer-dropout: 0.1
[2023-07-01 11:26:34] [config] transformer-dropout-attention: 0
[2023-07-01 11:26:34] [config] transformer-dropout-ffn: 0
[2023-07-01 11:26:34] [config] transformer-ffn-activation: swish
[2023-07-01 11:26:34] [config] transformer-ffn-depth: 2
[2023-07-01 11:26:34] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:26:34] [config] transformer-heads: 8
[2023-07-01 11:26:34] [config] transformer-no-projection: false
[2023-07-01 11:26:34] [config] transformer-pool: false
[2023-07-01 11:26:34] [config] transformer-postprocess: dan
[2023-07-01 11:26:34] [config] transformer-postprocess-emb: d
[2023-07-01 11:26:34] [config] transformer-postprocess-top: ""
[2023-07-01 11:26:34] [config] transformer-preprocess: ""
[2023-07-01 11:26:34] [config] transformer-tied-layers:
[2023-07-01 11:26:34] [config]   []
[2023-07-01 11:26:34] [config] transformer-train-position-embeddings: false
[2023-07-01 11:26:34] [config] tsv: false
[2023-07-01 11:26:34] [config] tsv-fields: 0
[2023-07-01 11:26:34] [config] type: transformer
[2023-07-01 11:26:34] [config] ulr: false
[2023-07-01 11:26:34] [config] ulr-dim-emb: 0
[2023-07-01 11:26:34] [config] ulr-dropout: 0
[2023-07-01 11:26:34] [config] ulr-keys-vectors: ""
[2023-07-01 11:26:34] [config] ulr-query-vectors: ""
[2023-07-01 11:26:34] [config] ulr-softmax-temperature: 1
[2023-07-01 11:26:34] [config] ulr-trainable-transformation: false
[2023-07-01 11:26:34] [config] unlikelihood-loss: false
[2023-07-01 11:26:34] [config] valid-freq: 50000000
[2023-07-01 11:26:34] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:26:34] [config] valid-max-length: 1000
[2023-07-01 11:26:34] [config] valid-metrics:
[2023-07-01 11:26:34] [config]   - cross-entropy
[2023-07-01 11:26:34] [config]   - translation
[2023-07-01 11:26:34] [config] valid-mini-batch: 64
[2023-07-01 11:26:34] [config] valid-reset-stalled: false
[2023-07-01 11:26:34] [config] valid-script-args:
[2023-07-01 11:26:34] [config]   []
[2023-07-01 11:26:34] [config] valid-script-path: ""
[2023-07-01 11:26:34] [config] valid-sets:
[2023-07-01 11:26:34] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:26:34] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:26:34] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:26:34] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:26:34] [config] vocabs:
[2023-07-01 11:26:34] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:26:34] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:26:34] [config] word-penalty: 0
[2023-07-01 11:26:34] [config] word-scores: false
[2023-07-01 11:26:34] [config] workspace: 2048
[2023-07-01 11:26:34] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:26:34] Using synchronous SGD
[2023-07-01 11:26:34] Synced seed 1234
[2023-07-01 11:26:34] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:26:34] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:26:34] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:26:34] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:26:34] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:26:34] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:26:35] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:26:35] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:26:35] [comm] Using global sharding
[2023-07-01 11:26:35] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:26:35] [training] Using 1 GPUs
[2023-07-01 11:26:35] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:26:35] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:26:35] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:26:35] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:26:43] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:26:43] [valid] No post-processing script given for validating translator
[2023-07-01 11:26:43] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:26:43] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:26:43] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:26:43] [comm] Using global sharding
[2023-07-01 11:26:43] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:26:43] [training] Using 1 GPUs
[2023-07-01 11:26:43] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:26:43] Allocating memory for general optimizer shards
[2023-07-01 11:26:43] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:26:43] Loading Adam parameters
[2023-07-01 11:26:44] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:26:44] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:26:44] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:26:44] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:26:44] [data] Shuffling data
[2023-07-01 11:26:44] [data] Done reading 20,192 sentences
[2023-07-01 11:26:44] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:26:44] Training started
[2023-07-01 11:26:44] Training finished
[2023-07-01 11:26:47] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:26:47] [marian] Running on node20.datos.cluster.uy as process 15743 with command line:
[2023-07-01 11:26:47] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 79 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:26:47] [config] after: 0e
[2023-07-01 11:26:47] [config] after-batches: 0
[2023-07-01 11:26:47] [config] after-epochs: 79
[2023-07-01 11:26:47] [config] all-caps-every: 0
[2023-07-01 11:26:47] [config] allow-unk: false
[2023-07-01 11:26:47] [config] authors: false
[2023-07-01 11:26:47] [config] beam-size: 12
[2023-07-01 11:26:47] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:26:47] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:26:47] [config] bert-masking-fraction: 0.15
[2023-07-01 11:26:47] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:26:47] [config] bert-train-type-embeddings: true
[2023-07-01 11:26:47] [config] bert-type-vocab-size: 2
[2023-07-01 11:26:47] [config] build-info: ""
[2023-07-01 11:26:47] [config] check-gradient-nan: false
[2023-07-01 11:26:47] [config] check-nan: false
[2023-07-01 11:26:47] [config] cite: false
[2023-07-01 11:26:47] [config] clip-norm: 5
[2023-07-01 11:26:47] [config] cost-scaling:
[2023-07-01 11:26:47] [config]   []
[2023-07-01 11:26:47] [config] cost-type: ce-sum
[2023-07-01 11:26:47] [config] cpu-threads: 0
[2023-07-01 11:26:47] [config] data-threads: 8
[2023-07-01 11:26:47] [config] data-weighting: ""
[2023-07-01 11:26:47] [config] data-weighting-type: sentence
[2023-07-01 11:26:47] [config] dec-cell: gru
[2023-07-01 11:26:47] [config] dec-cell-base-depth: 2
[2023-07-01 11:26:47] [config] dec-cell-high-depth: 1
[2023-07-01 11:26:47] [config] dec-depth: 2
[2023-07-01 11:26:47] [config] devices:
[2023-07-01 11:26:47] [config]   - 0
[2023-07-01 11:26:47] [config] dim-emb: 512
[2023-07-01 11:26:47] [config] dim-rnn: 1024
[2023-07-01 11:26:47] [config] dim-vocabs:
[2023-07-01 11:26:47] [config]   - 16384
[2023-07-01 11:26:47] [config]   - 16384
[2023-07-01 11:26:47] [config] disp-first: 0
[2023-07-01 11:26:47] [config] disp-freq: 1000u
[2023-07-01 11:26:47] [config] disp-label-counts: true
[2023-07-01 11:26:47] [config] dropout-rnn: 0
[2023-07-01 11:26:47] [config] dropout-src: 0
[2023-07-01 11:26:47] [config] dropout-trg: 0
[2023-07-01 11:26:47] [config] dump-config: ""
[2023-07-01 11:26:47] [config] dynamic-gradient-scaling:
[2023-07-01 11:26:47] [config]   []
[2023-07-01 11:26:47] [config] early-stopping: 10
[2023-07-01 11:26:47] [config] early-stopping-on: first
[2023-07-01 11:26:47] [config] embedding-fix-src: false
[2023-07-01 11:26:47] [config] embedding-fix-trg: false
[2023-07-01 11:26:47] [config] embedding-normalization: false
[2023-07-01 11:26:47] [config] embedding-vectors:
[2023-07-01 11:26:47] [config]   []
[2023-07-01 11:26:47] [config] enc-cell: gru
[2023-07-01 11:26:47] [config] enc-cell-depth: 1
[2023-07-01 11:26:47] [config] enc-depth: 2
[2023-07-01 11:26:47] [config] enc-type: bidirectional
[2023-07-01 11:26:47] [config] english-title-case-every: 0
[2023-07-01 11:26:47] [config] exponential-smoothing: 0.0001
[2023-07-01 11:26:47] [config] factor-weight: 1
[2023-07-01 11:26:47] [config] factors-combine: sum
[2023-07-01 11:26:47] [config] factors-dim-emb: 0
[2023-07-01 11:26:47] [config] gradient-checkpointing: false
[2023-07-01 11:26:47] [config] gradient-norm-average-window: 100
[2023-07-01 11:26:47] [config] guided-alignment: none
[2023-07-01 11:26:47] [config] guided-alignment-cost: mse
[2023-07-01 11:26:47] [config] guided-alignment-weight: 0.1
[2023-07-01 11:26:47] [config] ignore-model-config: false
[2023-07-01 11:26:47] [config] input-types:
[2023-07-01 11:26:47] [config]   []
[2023-07-01 11:26:47] [config] interpolate-env-vars: false
[2023-07-01 11:26:47] [config] keep-best: false
[2023-07-01 11:26:47] [config] label-smoothing: 0.1
[2023-07-01 11:26:47] [config] layer-normalization: false
[2023-07-01 11:26:47] [config] learn-rate: 0.0003
[2023-07-01 11:26:47] [config] lemma-dependency: ""
[2023-07-01 11:26:47] [config] lemma-dim-emb: 0
[2023-07-01 11:26:47] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:26:47] [config] log-level: info
[2023-07-01 11:26:47] [config] log-time-zone: ""
[2023-07-01 11:26:47] [config] logical-epoch:
[2023-07-01 11:26:47] [config]   - 1e
[2023-07-01 11:26:47] [config]   - 0
[2023-07-01 11:26:47] [config] lr-decay: 0
[2023-07-01 11:26:47] [config] lr-decay-freq: 50000
[2023-07-01 11:26:47] [config] lr-decay-inv-sqrt:
[2023-07-01 11:26:47] [config]   - 16000
[2023-07-01 11:26:47] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:26:47] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:26:47] [config] lr-decay-start:
[2023-07-01 11:26:47] [config]   - 10
[2023-07-01 11:26:47] [config]   - 1
[2023-07-01 11:26:47] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:26:47] [config] lr-report: true
[2023-07-01 11:26:47] [config] lr-warmup: 16000
[2023-07-01 11:26:47] [config] lr-warmup-at-reload: false
[2023-07-01 11:26:47] [config] lr-warmup-cycle: false
[2023-07-01 11:26:47] [config] lr-warmup-start-rate: 0
[2023-07-01 11:26:47] [config] max-length: 100
[2023-07-01 11:26:47] [config] max-length-crop: false
[2023-07-01 11:26:47] [config] max-length-factor: 3
[2023-07-01 11:26:47] [config] maxi-batch: 100
[2023-07-01 11:26:47] [config] maxi-batch-sort: trg
[2023-07-01 11:26:47] [config] mini-batch: 1000
[2023-07-01 11:26:47] [config] mini-batch-fit: true
[2023-07-01 11:26:47] [config] mini-batch-fit-step: 10
[2023-07-01 11:26:47] [config] mini-batch-round-up: true
[2023-07-01 11:26:47] [config] mini-batch-track-lr: false
[2023-07-01 11:26:47] [config] mini-batch-warmup: 0
[2023-07-01 11:26:47] [config] mini-batch-words: 0
[2023-07-01 11:26:47] [config] mini-batch-words-ref: 0
[2023-07-01 11:26:47] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:26:47] [config] multi-loss-type: sum
[2023-07-01 11:26:47] [config] n-best: false
[2023-07-01 11:26:47] [config] no-nccl: false
[2023-07-01 11:26:47] [config] no-reload: false
[2023-07-01 11:26:47] [config] no-restore-corpus: false
[2023-07-01 11:26:47] [config] normalize: 1
[2023-07-01 11:26:47] [config] normalize-gradient: false
[2023-07-01 11:26:47] [config] num-devices: 0
[2023-07-01 11:26:47] [config] optimizer: adam
[2023-07-01 11:26:47] [config] optimizer-delay: 1
[2023-07-01 11:26:47] [config] optimizer-params:
[2023-07-01 11:26:47] [config]   - 0.9
[2023-07-01 11:26:47] [config]   - 0.98
[2023-07-01 11:26:47] [config]   - 1e-09
[2023-07-01 11:26:47] [config] output-omit-bias: false
[2023-07-01 11:26:47] [config] overwrite: true
[2023-07-01 11:26:47] [config] precision:
[2023-07-01 11:26:47] [config]   - float32
[2023-07-01 11:26:47] [config]   - float32
[2023-07-01 11:26:47] [config] pretrained-model: ""
[2023-07-01 11:26:47] [config] quantize-biases: false
[2023-07-01 11:26:47] [config] quantize-bits: 0
[2023-07-01 11:26:47] [config] quantize-log-based: false
[2023-07-01 11:26:47] [config] quantize-optimization-steps: 0
[2023-07-01 11:26:47] [config] quiet: false
[2023-07-01 11:26:47] [config] quiet-translation: true
[2023-07-01 11:26:47] [config] relative-paths: false
[2023-07-01 11:26:47] [config] right-left: false
[2023-07-01 11:26:47] [config] save-freq: 10000u
[2023-07-01 11:26:47] [config] seed: 1234
[2023-07-01 11:26:47] [config] sentencepiece-alphas:
[2023-07-01 11:26:47] [config]   []
[2023-07-01 11:26:47] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:26:47] [config] sentencepiece-options: ""
[2023-07-01 11:26:47] [config] sharding: global
[2023-07-01 11:26:47] [config] shuffle: data
[2023-07-01 11:26:47] [config] shuffle-in-ram: false
[2023-07-01 11:26:47] [config] sigterm: save-and-exit
[2023-07-01 11:26:47] [config] skip: false
[2023-07-01 11:26:47] [config] sqlite: ""
[2023-07-01 11:26:47] [config] sqlite-drop: false
[2023-07-01 11:26:47] [config] sync-freq: 200u
[2023-07-01 11:26:47] [config] sync-sgd: true
[2023-07-01 11:26:47] [config] tempdir: /tmp
[2023-07-01 11:26:47] [config] tied-embeddings: false
[2023-07-01 11:26:47] [config] tied-embeddings-all: true
[2023-07-01 11:26:47] [config] tied-embeddings-src: false
[2023-07-01 11:26:47] [config] train-embedder-rank:
[2023-07-01 11:26:47] [config]   []
[2023-07-01 11:26:47] [config] train-sets:
[2023-07-01 11:26:47] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:26:47] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:26:47] [config] transformer-aan-activation: swish
[2023-07-01 11:26:47] [config] transformer-aan-depth: 2
[2023-07-01 11:26:47] [config] transformer-aan-nogate: false
[2023-07-01 11:26:47] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:26:47] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:26:47] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:26:47] [config] transformer-depth-scaling: false
[2023-07-01 11:26:47] [config] transformer-dim-aan: 2048
[2023-07-01 11:26:47] [config] transformer-dim-ffn: 2048
[2023-07-01 11:26:47] [config] transformer-dropout: 0.1
[2023-07-01 11:26:47] [config] transformer-dropout-attention: 0
[2023-07-01 11:26:47] [config] transformer-dropout-ffn: 0
[2023-07-01 11:26:47] [config] transformer-ffn-activation: swish
[2023-07-01 11:26:47] [config] transformer-ffn-depth: 2
[2023-07-01 11:26:47] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:26:47] [config] transformer-heads: 8
[2023-07-01 11:26:47] [config] transformer-no-projection: false
[2023-07-01 11:26:47] [config] transformer-pool: false
[2023-07-01 11:26:47] [config] transformer-postprocess: dan
[2023-07-01 11:26:47] [config] transformer-postprocess-emb: d
[2023-07-01 11:26:47] [config] transformer-postprocess-top: ""
[2023-07-01 11:26:47] [config] transformer-preprocess: ""
[2023-07-01 11:26:47] [config] transformer-tied-layers:
[2023-07-01 11:26:47] [config]   []
[2023-07-01 11:26:47] [config] transformer-train-position-embeddings: false
[2023-07-01 11:26:47] [config] tsv: false
[2023-07-01 11:26:47] [config] tsv-fields: 0
[2023-07-01 11:26:47] [config] type: transformer
[2023-07-01 11:26:47] [config] ulr: false
[2023-07-01 11:26:47] [config] ulr-dim-emb: 0
[2023-07-01 11:26:47] [config] ulr-dropout: 0
[2023-07-01 11:26:47] [config] ulr-keys-vectors: ""
[2023-07-01 11:26:47] [config] ulr-query-vectors: ""
[2023-07-01 11:26:47] [config] ulr-softmax-temperature: 1
[2023-07-01 11:26:47] [config] ulr-trainable-transformation: false
[2023-07-01 11:26:47] [config] unlikelihood-loss: false
[2023-07-01 11:26:47] [config] valid-freq: 50000000
[2023-07-01 11:26:47] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:26:47] [config] valid-max-length: 1000
[2023-07-01 11:26:47] [config] valid-metrics:
[2023-07-01 11:26:47] [config]   - cross-entropy
[2023-07-01 11:26:47] [config]   - translation
[2023-07-01 11:26:47] [config] valid-mini-batch: 64
[2023-07-01 11:26:47] [config] valid-reset-stalled: false
[2023-07-01 11:26:47] [config] valid-script-args:
[2023-07-01 11:26:47] [config]   []
[2023-07-01 11:26:47] [config] valid-script-path: ""
[2023-07-01 11:26:47] [config] valid-sets:
[2023-07-01 11:26:47] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:26:47] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:26:47] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:26:47] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:26:47] [config] vocabs:
[2023-07-01 11:26:47] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:26:47] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:26:47] [config] word-penalty: 0
[2023-07-01 11:26:47] [config] word-scores: false
[2023-07-01 11:26:47] [config] workspace: 2048
[2023-07-01 11:26:47] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:26:47] Using synchronous SGD
[2023-07-01 11:26:47] Synced seed 1234
[2023-07-01 11:26:47] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:26:47] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:26:47] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:26:47] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:26:47] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:26:47] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:26:48] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:26:48] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:26:48] [comm] Using global sharding
[2023-07-01 11:26:48] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:26:48] [training] Using 1 GPUs
[2023-07-01 11:26:48] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:26:48] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:26:49] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:26:49] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:26:56] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:26:56] [valid] No post-processing script given for validating translator
[2023-07-01 11:26:56] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:26:56] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:26:56] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:26:56] [comm] Using global sharding
[2023-07-01 11:26:56] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:26:56] [training] Using 1 GPUs
[2023-07-01 11:26:56] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:26:57] Allocating memory for general optimizer shards
[2023-07-01 11:26:57] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:26:57] Loading Adam parameters
[2023-07-01 11:26:57] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:26:57] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:26:57] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:26:57] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:26:57] [data] Shuffling data
[2023-07-01 11:26:57] [data] Done reading 20,192 sentences
[2023-07-01 11:26:57] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:26:57] Training started
[2023-07-01 11:26:57] Training finished
[2023-07-01 11:27:00] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:27:00] [marian] Running on node20.datos.cluster.uy as process 15801 with command line:
[2023-07-01 11:27:00] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 80 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:27:00] [config] after: 0e
[2023-07-01 11:27:00] [config] after-batches: 0
[2023-07-01 11:27:00] [config] after-epochs: 80
[2023-07-01 11:27:00] [config] all-caps-every: 0
[2023-07-01 11:27:00] [config] allow-unk: false
[2023-07-01 11:27:00] [config] authors: false
[2023-07-01 11:27:00] [config] beam-size: 12
[2023-07-01 11:27:00] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:27:00] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:27:00] [config] bert-masking-fraction: 0.15
[2023-07-01 11:27:00] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:27:00] [config] bert-train-type-embeddings: true
[2023-07-01 11:27:00] [config] bert-type-vocab-size: 2
[2023-07-01 11:27:00] [config] build-info: ""
[2023-07-01 11:27:00] [config] check-gradient-nan: false
[2023-07-01 11:27:00] [config] check-nan: false
[2023-07-01 11:27:00] [config] cite: false
[2023-07-01 11:27:00] [config] clip-norm: 5
[2023-07-01 11:27:00] [config] cost-scaling:
[2023-07-01 11:27:00] [config]   []
[2023-07-01 11:27:00] [config] cost-type: ce-sum
[2023-07-01 11:27:00] [config] cpu-threads: 0
[2023-07-01 11:27:00] [config] data-threads: 8
[2023-07-01 11:27:00] [config] data-weighting: ""
[2023-07-01 11:27:00] [config] data-weighting-type: sentence
[2023-07-01 11:27:00] [config] dec-cell: gru
[2023-07-01 11:27:00] [config] dec-cell-base-depth: 2
[2023-07-01 11:27:00] [config] dec-cell-high-depth: 1
[2023-07-01 11:27:00] [config] dec-depth: 2
[2023-07-01 11:27:00] [config] devices:
[2023-07-01 11:27:00] [config]   - 0
[2023-07-01 11:27:00] [config] dim-emb: 512
[2023-07-01 11:27:00] [config] dim-rnn: 1024
[2023-07-01 11:27:00] [config] dim-vocabs:
[2023-07-01 11:27:00] [config]   - 16384
[2023-07-01 11:27:00] [config]   - 16384
[2023-07-01 11:27:00] [config] disp-first: 0
[2023-07-01 11:27:00] [config] disp-freq: 1000u
[2023-07-01 11:27:00] [config] disp-label-counts: true
[2023-07-01 11:27:00] [config] dropout-rnn: 0
[2023-07-01 11:27:00] [config] dropout-src: 0
[2023-07-01 11:27:00] [config] dropout-trg: 0
[2023-07-01 11:27:00] [config] dump-config: ""
[2023-07-01 11:27:00] [config] dynamic-gradient-scaling:
[2023-07-01 11:27:00] [config]   []
[2023-07-01 11:27:00] [config] early-stopping: 10
[2023-07-01 11:27:00] [config] early-stopping-on: first
[2023-07-01 11:27:00] [config] embedding-fix-src: false
[2023-07-01 11:27:00] [config] embedding-fix-trg: false
[2023-07-01 11:27:00] [config] embedding-normalization: false
[2023-07-01 11:27:00] [config] embedding-vectors:
[2023-07-01 11:27:00] [config]   []
[2023-07-01 11:27:00] [config] enc-cell: gru
[2023-07-01 11:27:00] [config] enc-cell-depth: 1
[2023-07-01 11:27:00] [config] enc-depth: 2
[2023-07-01 11:27:00] [config] enc-type: bidirectional
[2023-07-01 11:27:00] [config] english-title-case-every: 0
[2023-07-01 11:27:00] [config] exponential-smoothing: 0.0001
[2023-07-01 11:27:00] [config] factor-weight: 1
[2023-07-01 11:27:00] [config] factors-combine: sum
[2023-07-01 11:27:00] [config] factors-dim-emb: 0
[2023-07-01 11:27:00] [config] gradient-checkpointing: false
[2023-07-01 11:27:00] [config] gradient-norm-average-window: 100
[2023-07-01 11:27:00] [config] guided-alignment: none
[2023-07-01 11:27:00] [config] guided-alignment-cost: mse
[2023-07-01 11:27:00] [config] guided-alignment-weight: 0.1
[2023-07-01 11:27:00] [config] ignore-model-config: false
[2023-07-01 11:27:00] [config] input-types:
[2023-07-01 11:27:00] [config]   []
[2023-07-01 11:27:00] [config] interpolate-env-vars: false
[2023-07-01 11:27:00] [config] keep-best: false
[2023-07-01 11:27:00] [config] label-smoothing: 0.1
[2023-07-01 11:27:00] [config] layer-normalization: false
[2023-07-01 11:27:00] [config] learn-rate: 0.0003
[2023-07-01 11:27:00] [config] lemma-dependency: ""
[2023-07-01 11:27:00] [config] lemma-dim-emb: 0
[2023-07-01 11:27:00] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:27:00] [config] log-level: info
[2023-07-01 11:27:00] [config] log-time-zone: ""
[2023-07-01 11:27:00] [config] logical-epoch:
[2023-07-01 11:27:00] [config]   - 1e
[2023-07-01 11:27:00] [config]   - 0
[2023-07-01 11:27:00] [config] lr-decay: 0
[2023-07-01 11:27:00] [config] lr-decay-freq: 50000
[2023-07-01 11:27:00] [config] lr-decay-inv-sqrt:
[2023-07-01 11:27:00] [config]   - 16000
[2023-07-01 11:27:00] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:27:00] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:27:00] [config] lr-decay-start:
[2023-07-01 11:27:00] [config]   - 10
[2023-07-01 11:27:00] [config]   - 1
[2023-07-01 11:27:00] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:27:00] [config] lr-report: true
[2023-07-01 11:27:00] [config] lr-warmup: 16000
[2023-07-01 11:27:00] [config] lr-warmup-at-reload: false
[2023-07-01 11:27:00] [config] lr-warmup-cycle: false
[2023-07-01 11:27:00] [config] lr-warmup-start-rate: 0
[2023-07-01 11:27:00] [config] max-length: 100
[2023-07-01 11:27:00] [config] max-length-crop: false
[2023-07-01 11:27:00] [config] max-length-factor: 3
[2023-07-01 11:27:00] [config] maxi-batch: 100
[2023-07-01 11:27:00] [config] maxi-batch-sort: trg
[2023-07-01 11:27:00] [config] mini-batch: 1000
[2023-07-01 11:27:00] [config] mini-batch-fit: true
[2023-07-01 11:27:00] [config] mini-batch-fit-step: 10
[2023-07-01 11:27:00] [config] mini-batch-round-up: true
[2023-07-01 11:27:00] [config] mini-batch-track-lr: false
[2023-07-01 11:27:00] [config] mini-batch-warmup: 0
[2023-07-01 11:27:00] [config] mini-batch-words: 0
[2023-07-01 11:27:00] [config] mini-batch-words-ref: 0
[2023-07-01 11:27:00] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:27:00] [config] multi-loss-type: sum
[2023-07-01 11:27:00] [config] n-best: false
[2023-07-01 11:27:00] [config] no-nccl: false
[2023-07-01 11:27:00] [config] no-reload: false
[2023-07-01 11:27:00] [config] no-restore-corpus: false
[2023-07-01 11:27:00] [config] normalize: 1
[2023-07-01 11:27:00] [config] normalize-gradient: false
[2023-07-01 11:27:00] [config] num-devices: 0
[2023-07-01 11:27:00] [config] optimizer: adam
[2023-07-01 11:27:00] [config] optimizer-delay: 1
[2023-07-01 11:27:00] [config] optimizer-params:
[2023-07-01 11:27:00] [config]   - 0.9
[2023-07-01 11:27:00] [config]   - 0.98
[2023-07-01 11:27:00] [config]   - 1e-09
[2023-07-01 11:27:00] [config] output-omit-bias: false
[2023-07-01 11:27:00] [config] overwrite: true
[2023-07-01 11:27:00] [config] precision:
[2023-07-01 11:27:00] [config]   - float32
[2023-07-01 11:27:00] [config]   - float32
[2023-07-01 11:27:00] [config] pretrained-model: ""
[2023-07-01 11:27:00] [config] quantize-biases: false
[2023-07-01 11:27:00] [config] quantize-bits: 0
[2023-07-01 11:27:00] [config] quantize-log-based: false
[2023-07-01 11:27:00] [config] quantize-optimization-steps: 0
[2023-07-01 11:27:00] [config] quiet: false
[2023-07-01 11:27:00] [config] quiet-translation: true
[2023-07-01 11:27:00] [config] relative-paths: false
[2023-07-01 11:27:00] [config] right-left: false
[2023-07-01 11:27:00] [config] save-freq: 10000u
[2023-07-01 11:27:00] [config] seed: 1234
[2023-07-01 11:27:00] [config] sentencepiece-alphas:
[2023-07-01 11:27:00] [config]   []
[2023-07-01 11:27:00] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:27:00] [config] sentencepiece-options: ""
[2023-07-01 11:27:00] [config] sharding: global
[2023-07-01 11:27:00] [config] shuffle: data
[2023-07-01 11:27:00] [config] shuffle-in-ram: false
[2023-07-01 11:27:00] [config] sigterm: save-and-exit
[2023-07-01 11:27:00] [config] skip: false
[2023-07-01 11:27:00] [config] sqlite: ""
[2023-07-01 11:27:00] [config] sqlite-drop: false
[2023-07-01 11:27:00] [config] sync-freq: 200u
[2023-07-01 11:27:00] [config] sync-sgd: true
[2023-07-01 11:27:00] [config] tempdir: /tmp
[2023-07-01 11:27:00] [config] tied-embeddings: false
[2023-07-01 11:27:00] [config] tied-embeddings-all: true
[2023-07-01 11:27:00] [config] tied-embeddings-src: false
[2023-07-01 11:27:00] [config] train-embedder-rank:
[2023-07-01 11:27:00] [config]   []
[2023-07-01 11:27:00] [config] train-sets:
[2023-07-01 11:27:00] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:27:00] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:27:00] [config] transformer-aan-activation: swish
[2023-07-01 11:27:00] [config] transformer-aan-depth: 2
[2023-07-01 11:27:00] [config] transformer-aan-nogate: false
[2023-07-01 11:27:00] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:27:00] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:27:00] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:27:00] [config] transformer-depth-scaling: false
[2023-07-01 11:27:00] [config] transformer-dim-aan: 2048
[2023-07-01 11:27:00] [config] transformer-dim-ffn: 2048
[2023-07-01 11:27:00] [config] transformer-dropout: 0.1
[2023-07-01 11:27:00] [config] transformer-dropout-attention: 0
[2023-07-01 11:27:00] [config] transformer-dropout-ffn: 0
[2023-07-01 11:27:00] [config] transformer-ffn-activation: swish
[2023-07-01 11:27:00] [config] transformer-ffn-depth: 2
[2023-07-01 11:27:00] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:27:00] [config] transformer-heads: 8
[2023-07-01 11:27:00] [config] transformer-no-projection: false
[2023-07-01 11:27:00] [config] transformer-pool: false
[2023-07-01 11:27:00] [config] transformer-postprocess: dan
[2023-07-01 11:27:00] [config] transformer-postprocess-emb: d
[2023-07-01 11:27:00] [config] transformer-postprocess-top: ""
[2023-07-01 11:27:00] [config] transformer-preprocess: ""
[2023-07-01 11:27:00] [config] transformer-tied-layers:
[2023-07-01 11:27:00] [config]   []
[2023-07-01 11:27:00] [config] transformer-train-position-embeddings: false
[2023-07-01 11:27:00] [config] tsv: false
[2023-07-01 11:27:00] [config] tsv-fields: 0
[2023-07-01 11:27:00] [config] type: transformer
[2023-07-01 11:27:00] [config] ulr: false
[2023-07-01 11:27:00] [config] ulr-dim-emb: 0
[2023-07-01 11:27:00] [config] ulr-dropout: 0
[2023-07-01 11:27:00] [config] ulr-keys-vectors: ""
[2023-07-01 11:27:00] [config] ulr-query-vectors: ""
[2023-07-01 11:27:00] [config] ulr-softmax-temperature: 1
[2023-07-01 11:27:00] [config] ulr-trainable-transformation: false
[2023-07-01 11:27:00] [config] unlikelihood-loss: false
[2023-07-01 11:27:00] [config] valid-freq: 50000000
[2023-07-01 11:27:00] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:27:00] [config] valid-max-length: 1000
[2023-07-01 11:27:00] [config] valid-metrics:
[2023-07-01 11:27:00] [config]   - cross-entropy
[2023-07-01 11:27:00] [config]   - translation
[2023-07-01 11:27:00] [config] valid-mini-batch: 64
[2023-07-01 11:27:00] [config] valid-reset-stalled: false
[2023-07-01 11:27:00] [config] valid-script-args:
[2023-07-01 11:27:00] [config]   []
[2023-07-01 11:27:00] [config] valid-script-path: ""
[2023-07-01 11:27:00] [config] valid-sets:
[2023-07-01 11:27:00] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:27:00] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:27:00] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:27:00] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:27:00] [config] vocabs:
[2023-07-01 11:27:00] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:27:00] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:27:00] [config] word-penalty: 0
[2023-07-01 11:27:00] [config] word-scores: false
[2023-07-01 11:27:00] [config] workspace: 2048
[2023-07-01 11:27:00] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:27:00] Using synchronous SGD
[2023-07-01 11:27:01] Synced seed 1234
[2023-07-01 11:27:01] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:27:01] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:27:01] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:27:01] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:27:01] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:27:01] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:27:01] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:27:02] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:27:02] [comm] Using global sharding
[2023-07-01 11:27:02] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:27:02] [training] Using 1 GPUs
[2023-07-01 11:27:02] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:27:02] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:27:02] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:27:02] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:27:09] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:27:09] [valid] No post-processing script given for validating translator
[2023-07-01 11:27:10] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:27:10] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:27:10] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:27:10] [comm] Using global sharding
[2023-07-01 11:27:10] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:27:10] [training] Using 1 GPUs
[2023-07-01 11:27:10] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:27:10] Allocating memory for general optimizer shards
[2023-07-01 11:27:10] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:27:10] Loading Adam parameters
[2023-07-01 11:27:10] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:27:10] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:27:10] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:27:10] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:27:10] [data] Shuffling data
[2023-07-01 11:27:10] [data] Done reading 20,192 sentences
[2023-07-01 11:27:10] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:27:10] Training started
[2023-07-01 11:27:10] Training finished
[2023-07-01 11:27:14] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:27:14] [marian] Running on node20.datos.cluster.uy as process 15861 with command line:
[2023-07-01 11:27:14] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 81 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:27:14] [config] after: 0e
[2023-07-01 11:27:14] [config] after-batches: 0
[2023-07-01 11:27:14] [config] after-epochs: 81
[2023-07-01 11:27:14] [config] all-caps-every: 0
[2023-07-01 11:27:14] [config] allow-unk: false
[2023-07-01 11:27:14] [config] authors: false
[2023-07-01 11:27:14] [config] beam-size: 12
[2023-07-01 11:27:14] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:27:14] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:27:14] [config] bert-masking-fraction: 0.15
[2023-07-01 11:27:14] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:27:14] [config] bert-train-type-embeddings: true
[2023-07-01 11:27:14] [config] bert-type-vocab-size: 2
[2023-07-01 11:27:14] [config] build-info: ""
[2023-07-01 11:27:14] [config] check-gradient-nan: false
[2023-07-01 11:27:14] [config] check-nan: false
[2023-07-01 11:27:14] [config] cite: false
[2023-07-01 11:27:14] [config] clip-norm: 5
[2023-07-01 11:27:14] [config] cost-scaling:
[2023-07-01 11:27:14] [config]   []
[2023-07-01 11:27:14] [config] cost-type: ce-sum
[2023-07-01 11:27:14] [config] cpu-threads: 0
[2023-07-01 11:27:14] [config] data-threads: 8
[2023-07-01 11:27:14] [config] data-weighting: ""
[2023-07-01 11:27:14] [config] data-weighting-type: sentence
[2023-07-01 11:27:14] [config] dec-cell: gru
[2023-07-01 11:27:14] [config] dec-cell-base-depth: 2
[2023-07-01 11:27:14] [config] dec-cell-high-depth: 1
[2023-07-01 11:27:14] [config] dec-depth: 2
[2023-07-01 11:27:14] [config] devices:
[2023-07-01 11:27:14] [config]   - 0
[2023-07-01 11:27:14] [config] dim-emb: 512
[2023-07-01 11:27:14] [config] dim-rnn: 1024
[2023-07-01 11:27:14] [config] dim-vocabs:
[2023-07-01 11:27:14] [config]   - 16384
[2023-07-01 11:27:14] [config]   - 16384
[2023-07-01 11:27:14] [config] disp-first: 0
[2023-07-01 11:27:14] [config] disp-freq: 1000u
[2023-07-01 11:27:14] [config] disp-label-counts: true
[2023-07-01 11:27:14] [config] dropout-rnn: 0
[2023-07-01 11:27:14] [config] dropout-src: 0
[2023-07-01 11:27:14] [config] dropout-trg: 0
[2023-07-01 11:27:14] [config] dump-config: ""
[2023-07-01 11:27:14] [config] dynamic-gradient-scaling:
[2023-07-01 11:27:14] [config]   []
[2023-07-01 11:27:14] [config] early-stopping: 10
[2023-07-01 11:27:14] [config] early-stopping-on: first
[2023-07-01 11:27:14] [config] embedding-fix-src: false
[2023-07-01 11:27:14] [config] embedding-fix-trg: false
[2023-07-01 11:27:14] [config] embedding-normalization: false
[2023-07-01 11:27:14] [config] embedding-vectors:
[2023-07-01 11:27:14] [config]   []
[2023-07-01 11:27:14] [config] enc-cell: gru
[2023-07-01 11:27:14] [config] enc-cell-depth: 1
[2023-07-01 11:27:14] [config] enc-depth: 2
[2023-07-01 11:27:14] [config] enc-type: bidirectional
[2023-07-01 11:27:14] [config] english-title-case-every: 0
[2023-07-01 11:27:14] [config] exponential-smoothing: 0.0001
[2023-07-01 11:27:14] [config] factor-weight: 1
[2023-07-01 11:27:14] [config] factors-combine: sum
[2023-07-01 11:27:14] [config] factors-dim-emb: 0
[2023-07-01 11:27:14] [config] gradient-checkpointing: false
[2023-07-01 11:27:14] [config] gradient-norm-average-window: 100
[2023-07-01 11:27:14] [config] guided-alignment: none
[2023-07-01 11:27:14] [config] guided-alignment-cost: mse
[2023-07-01 11:27:14] [config] guided-alignment-weight: 0.1
[2023-07-01 11:27:14] [config] ignore-model-config: false
[2023-07-01 11:27:14] [config] input-types:
[2023-07-01 11:27:14] [config]   []
[2023-07-01 11:27:14] [config] interpolate-env-vars: false
[2023-07-01 11:27:14] [config] keep-best: false
[2023-07-01 11:27:14] [config] label-smoothing: 0.1
[2023-07-01 11:27:14] [config] layer-normalization: false
[2023-07-01 11:27:14] [config] learn-rate: 0.0003
[2023-07-01 11:27:14] [config] lemma-dependency: ""
[2023-07-01 11:27:14] [config] lemma-dim-emb: 0
[2023-07-01 11:27:14] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:27:14] [config] log-level: info
[2023-07-01 11:27:14] [config] log-time-zone: ""
[2023-07-01 11:27:14] [config] logical-epoch:
[2023-07-01 11:27:14] [config]   - 1e
[2023-07-01 11:27:14] [config]   - 0
[2023-07-01 11:27:14] [config] lr-decay: 0
[2023-07-01 11:27:14] [config] lr-decay-freq: 50000
[2023-07-01 11:27:14] [config] lr-decay-inv-sqrt:
[2023-07-01 11:27:14] [config]   - 16000
[2023-07-01 11:27:14] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:27:14] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:27:14] [config] lr-decay-start:
[2023-07-01 11:27:14] [config]   - 10
[2023-07-01 11:27:14] [config]   - 1
[2023-07-01 11:27:14] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:27:14] [config] lr-report: true
[2023-07-01 11:27:14] [config] lr-warmup: 16000
[2023-07-01 11:27:14] [config] lr-warmup-at-reload: false
[2023-07-01 11:27:14] [config] lr-warmup-cycle: false
[2023-07-01 11:27:14] [config] lr-warmup-start-rate: 0
[2023-07-01 11:27:14] [config] max-length: 100
[2023-07-01 11:27:14] [config] max-length-crop: false
[2023-07-01 11:27:14] [config] max-length-factor: 3
[2023-07-01 11:27:14] [config] maxi-batch: 100
[2023-07-01 11:27:14] [config] maxi-batch-sort: trg
[2023-07-01 11:27:14] [config] mini-batch: 1000
[2023-07-01 11:27:14] [config] mini-batch-fit: true
[2023-07-01 11:27:14] [config] mini-batch-fit-step: 10
[2023-07-01 11:27:14] [config] mini-batch-round-up: true
[2023-07-01 11:27:14] [config] mini-batch-track-lr: false
[2023-07-01 11:27:14] [config] mini-batch-warmup: 0
[2023-07-01 11:27:14] [config] mini-batch-words: 0
[2023-07-01 11:27:14] [config] mini-batch-words-ref: 0
[2023-07-01 11:27:14] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:27:14] [config] multi-loss-type: sum
[2023-07-01 11:27:14] [config] n-best: false
[2023-07-01 11:27:14] [config] no-nccl: false
[2023-07-01 11:27:14] [config] no-reload: false
[2023-07-01 11:27:14] [config] no-restore-corpus: false
[2023-07-01 11:27:14] [config] normalize: 1
[2023-07-01 11:27:14] [config] normalize-gradient: false
[2023-07-01 11:27:14] [config] num-devices: 0
[2023-07-01 11:27:14] [config] optimizer: adam
[2023-07-01 11:27:14] [config] optimizer-delay: 1
[2023-07-01 11:27:14] [config] optimizer-params:
[2023-07-01 11:27:14] [config]   - 0.9
[2023-07-01 11:27:14] [config]   - 0.98
[2023-07-01 11:27:14] [config]   - 1e-09
[2023-07-01 11:27:14] [config] output-omit-bias: false
[2023-07-01 11:27:14] [config] overwrite: true
[2023-07-01 11:27:14] [config] precision:
[2023-07-01 11:27:14] [config]   - float32
[2023-07-01 11:27:14] [config]   - float32
[2023-07-01 11:27:14] [config] pretrained-model: ""
[2023-07-01 11:27:14] [config] quantize-biases: false
[2023-07-01 11:27:14] [config] quantize-bits: 0
[2023-07-01 11:27:14] [config] quantize-log-based: false
[2023-07-01 11:27:14] [config] quantize-optimization-steps: 0
[2023-07-01 11:27:14] [config] quiet: false
[2023-07-01 11:27:14] [config] quiet-translation: true
[2023-07-01 11:27:14] [config] relative-paths: false
[2023-07-01 11:27:14] [config] right-left: false
[2023-07-01 11:27:14] [config] save-freq: 10000u
[2023-07-01 11:27:14] [config] seed: 1234
[2023-07-01 11:27:14] [config] sentencepiece-alphas:
[2023-07-01 11:27:14] [config]   []
[2023-07-01 11:27:14] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:27:14] [config] sentencepiece-options: ""
[2023-07-01 11:27:14] [config] sharding: global
[2023-07-01 11:27:14] [config] shuffle: data
[2023-07-01 11:27:14] [config] shuffle-in-ram: false
[2023-07-01 11:27:14] [config] sigterm: save-and-exit
[2023-07-01 11:27:14] [config] skip: false
[2023-07-01 11:27:14] [config] sqlite: ""
[2023-07-01 11:27:14] [config] sqlite-drop: false
[2023-07-01 11:27:14] [config] sync-freq: 200u
[2023-07-01 11:27:14] [config] sync-sgd: true
[2023-07-01 11:27:14] [config] tempdir: /tmp
[2023-07-01 11:27:14] [config] tied-embeddings: false
[2023-07-01 11:27:14] [config] tied-embeddings-all: true
[2023-07-01 11:27:14] [config] tied-embeddings-src: false
[2023-07-01 11:27:14] [config] train-embedder-rank:
[2023-07-01 11:27:14] [config]   []
[2023-07-01 11:27:14] [config] train-sets:
[2023-07-01 11:27:14] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:27:14] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:27:14] [config] transformer-aan-activation: swish
[2023-07-01 11:27:14] [config] transformer-aan-depth: 2
[2023-07-01 11:27:14] [config] transformer-aan-nogate: false
[2023-07-01 11:27:14] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:27:14] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:27:14] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:27:14] [config] transformer-depth-scaling: false
[2023-07-01 11:27:14] [config] transformer-dim-aan: 2048
[2023-07-01 11:27:14] [config] transformer-dim-ffn: 2048
[2023-07-01 11:27:14] [config] transformer-dropout: 0.1
[2023-07-01 11:27:14] [config] transformer-dropout-attention: 0
[2023-07-01 11:27:14] [config] transformer-dropout-ffn: 0
[2023-07-01 11:27:14] [config] transformer-ffn-activation: swish
[2023-07-01 11:27:14] [config] transformer-ffn-depth: 2
[2023-07-01 11:27:14] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:27:14] [config] transformer-heads: 8
[2023-07-01 11:27:14] [config] transformer-no-projection: false
[2023-07-01 11:27:14] [config] transformer-pool: false
[2023-07-01 11:27:14] [config] transformer-postprocess: dan
[2023-07-01 11:27:14] [config] transformer-postprocess-emb: d
[2023-07-01 11:27:14] [config] transformer-postprocess-top: ""
[2023-07-01 11:27:14] [config] transformer-preprocess: ""
[2023-07-01 11:27:14] [config] transformer-tied-layers:
[2023-07-01 11:27:14] [config]   []
[2023-07-01 11:27:14] [config] transformer-train-position-embeddings: false
[2023-07-01 11:27:14] [config] tsv: false
[2023-07-01 11:27:14] [config] tsv-fields: 0
[2023-07-01 11:27:14] [config] type: transformer
[2023-07-01 11:27:14] [config] ulr: false
[2023-07-01 11:27:14] [config] ulr-dim-emb: 0
[2023-07-01 11:27:14] [config] ulr-dropout: 0
[2023-07-01 11:27:14] [config] ulr-keys-vectors: ""
[2023-07-01 11:27:14] [config] ulr-query-vectors: ""
[2023-07-01 11:27:14] [config] ulr-softmax-temperature: 1
[2023-07-01 11:27:14] [config] ulr-trainable-transformation: false
[2023-07-01 11:27:14] [config] unlikelihood-loss: false
[2023-07-01 11:27:14] [config] valid-freq: 50000000
[2023-07-01 11:27:14] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:27:14] [config] valid-max-length: 1000
[2023-07-01 11:27:14] [config] valid-metrics:
[2023-07-01 11:27:14] [config]   - cross-entropy
[2023-07-01 11:27:14] [config]   - translation
[2023-07-01 11:27:14] [config] valid-mini-batch: 64
[2023-07-01 11:27:14] [config] valid-reset-stalled: false
[2023-07-01 11:27:14] [config] valid-script-args:
[2023-07-01 11:27:14] [config]   []
[2023-07-01 11:27:14] [config] valid-script-path: ""
[2023-07-01 11:27:14] [config] valid-sets:
[2023-07-01 11:27:14] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:27:14] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:27:14] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:27:14] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:27:14] [config] vocabs:
[2023-07-01 11:27:14] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:27:14] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:27:14] [config] word-penalty: 0
[2023-07-01 11:27:14] [config] word-scores: false
[2023-07-01 11:27:14] [config] workspace: 2048
[2023-07-01 11:27:14] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:27:14] Using synchronous SGD
[2023-07-01 11:27:14] Synced seed 1234
[2023-07-01 11:27:14] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:27:14] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:27:14] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:27:14] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:27:14] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:27:14] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:27:15] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:27:15] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:27:15] [comm] Using global sharding
[2023-07-01 11:27:15] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:27:15] [training] Using 1 GPUs
[2023-07-01 11:27:15] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:27:15] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:27:16] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:27:16] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:27:23] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:27:23] [valid] No post-processing script given for validating translator
[2023-07-01 11:27:23] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:27:23] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:27:23] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:27:23] [comm] Using global sharding
[2023-07-01 11:27:23] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:27:23] [training] Using 1 GPUs
[2023-07-01 11:27:23] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:27:24] Allocating memory for general optimizer shards
[2023-07-01 11:27:24] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:27:24] Loading Adam parameters
[2023-07-01 11:27:24] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:27:24] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:27:24] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:27:24] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:27:24] [data] Shuffling data
[2023-07-01 11:27:24] [data] Done reading 20,192 sentences
[2023-07-01 11:27:24] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:27:24] Training started
[2023-07-01 11:27:24] Training finished
[2023-07-01 11:27:28] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:27:28] [marian] Running on node20.datos.cluster.uy as process 15921 with command line:
[2023-07-01 11:27:28] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 82 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:27:28] [config] after: 0e
[2023-07-01 11:27:28] [config] after-batches: 0
[2023-07-01 11:27:28] [config] after-epochs: 82
[2023-07-01 11:27:28] [config] all-caps-every: 0
[2023-07-01 11:27:28] [config] allow-unk: false
[2023-07-01 11:27:28] [config] authors: false
[2023-07-01 11:27:28] [config] beam-size: 12
[2023-07-01 11:27:28] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:27:28] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:27:28] [config] bert-masking-fraction: 0.15
[2023-07-01 11:27:28] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:27:28] [config] bert-train-type-embeddings: true
[2023-07-01 11:27:28] [config] bert-type-vocab-size: 2
[2023-07-01 11:27:28] [config] build-info: ""
[2023-07-01 11:27:28] [config] check-gradient-nan: false
[2023-07-01 11:27:28] [config] check-nan: false
[2023-07-01 11:27:28] [config] cite: false
[2023-07-01 11:27:28] [config] clip-norm: 5
[2023-07-01 11:27:28] [config] cost-scaling:
[2023-07-01 11:27:28] [config]   []
[2023-07-01 11:27:28] [config] cost-type: ce-sum
[2023-07-01 11:27:28] [config] cpu-threads: 0
[2023-07-01 11:27:28] [config] data-threads: 8
[2023-07-01 11:27:28] [config] data-weighting: ""
[2023-07-01 11:27:28] [config] data-weighting-type: sentence
[2023-07-01 11:27:28] [config] dec-cell: gru
[2023-07-01 11:27:28] [config] dec-cell-base-depth: 2
[2023-07-01 11:27:28] [config] dec-cell-high-depth: 1
[2023-07-01 11:27:28] [config] dec-depth: 2
[2023-07-01 11:27:28] [config] devices:
[2023-07-01 11:27:28] [config]   - 0
[2023-07-01 11:27:28] [config] dim-emb: 512
[2023-07-01 11:27:28] [config] dim-rnn: 1024
[2023-07-01 11:27:28] [config] dim-vocabs:
[2023-07-01 11:27:28] [config]   - 16384
[2023-07-01 11:27:28] [config]   - 16384
[2023-07-01 11:27:28] [config] disp-first: 0
[2023-07-01 11:27:28] [config] disp-freq: 1000u
[2023-07-01 11:27:28] [config] disp-label-counts: true
[2023-07-01 11:27:28] [config] dropout-rnn: 0
[2023-07-01 11:27:28] [config] dropout-src: 0
[2023-07-01 11:27:28] [config] dropout-trg: 0
[2023-07-01 11:27:28] [config] dump-config: ""
[2023-07-01 11:27:28] [config] dynamic-gradient-scaling:
[2023-07-01 11:27:28] [config]   []
[2023-07-01 11:27:28] [config] early-stopping: 10
[2023-07-01 11:27:28] [config] early-stopping-on: first
[2023-07-01 11:27:28] [config] embedding-fix-src: false
[2023-07-01 11:27:28] [config] embedding-fix-trg: false
[2023-07-01 11:27:28] [config] embedding-normalization: false
[2023-07-01 11:27:28] [config] embedding-vectors:
[2023-07-01 11:27:28] [config]   []
[2023-07-01 11:27:28] [config] enc-cell: gru
[2023-07-01 11:27:28] [config] enc-cell-depth: 1
[2023-07-01 11:27:28] [config] enc-depth: 2
[2023-07-01 11:27:28] [config] enc-type: bidirectional
[2023-07-01 11:27:28] [config] english-title-case-every: 0
[2023-07-01 11:27:28] [config] exponential-smoothing: 0.0001
[2023-07-01 11:27:28] [config] factor-weight: 1
[2023-07-01 11:27:28] [config] factors-combine: sum
[2023-07-01 11:27:28] [config] factors-dim-emb: 0
[2023-07-01 11:27:28] [config] gradient-checkpointing: false
[2023-07-01 11:27:28] [config] gradient-norm-average-window: 100
[2023-07-01 11:27:28] [config] guided-alignment: none
[2023-07-01 11:27:28] [config] guided-alignment-cost: mse
[2023-07-01 11:27:28] [config] guided-alignment-weight: 0.1
[2023-07-01 11:27:28] [config] ignore-model-config: false
[2023-07-01 11:27:28] [config] input-types:
[2023-07-01 11:27:28] [config]   []
[2023-07-01 11:27:28] [config] interpolate-env-vars: false
[2023-07-01 11:27:28] [config] keep-best: false
[2023-07-01 11:27:28] [config] label-smoothing: 0.1
[2023-07-01 11:27:28] [config] layer-normalization: false
[2023-07-01 11:27:28] [config] learn-rate: 0.0003
[2023-07-01 11:27:28] [config] lemma-dependency: ""
[2023-07-01 11:27:28] [config] lemma-dim-emb: 0
[2023-07-01 11:27:28] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:27:28] [config] log-level: info
[2023-07-01 11:27:28] [config] log-time-zone: ""
[2023-07-01 11:27:28] [config] logical-epoch:
[2023-07-01 11:27:28] [config]   - 1e
[2023-07-01 11:27:28] [config]   - 0
[2023-07-01 11:27:28] [config] lr-decay: 0
[2023-07-01 11:27:28] [config] lr-decay-freq: 50000
[2023-07-01 11:27:28] [config] lr-decay-inv-sqrt:
[2023-07-01 11:27:28] [config]   - 16000
[2023-07-01 11:27:28] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:27:28] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:27:28] [config] lr-decay-start:
[2023-07-01 11:27:28] [config]   - 10
[2023-07-01 11:27:28] [config]   - 1
[2023-07-01 11:27:28] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:27:28] [config] lr-report: true
[2023-07-01 11:27:28] [config] lr-warmup: 16000
[2023-07-01 11:27:28] [config] lr-warmup-at-reload: false
[2023-07-01 11:27:28] [config] lr-warmup-cycle: false
[2023-07-01 11:27:28] [config] lr-warmup-start-rate: 0
[2023-07-01 11:27:28] [config] max-length: 100
[2023-07-01 11:27:28] [config] max-length-crop: false
[2023-07-01 11:27:28] [config] max-length-factor: 3
[2023-07-01 11:27:28] [config] maxi-batch: 100
[2023-07-01 11:27:28] [config] maxi-batch-sort: trg
[2023-07-01 11:27:28] [config] mini-batch: 1000
[2023-07-01 11:27:28] [config] mini-batch-fit: true
[2023-07-01 11:27:28] [config] mini-batch-fit-step: 10
[2023-07-01 11:27:28] [config] mini-batch-round-up: true
[2023-07-01 11:27:28] [config] mini-batch-track-lr: false
[2023-07-01 11:27:28] [config] mini-batch-warmup: 0
[2023-07-01 11:27:28] [config] mini-batch-words: 0
[2023-07-01 11:27:28] [config] mini-batch-words-ref: 0
[2023-07-01 11:27:28] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:27:28] [config] multi-loss-type: sum
[2023-07-01 11:27:28] [config] n-best: false
[2023-07-01 11:27:28] [config] no-nccl: false
[2023-07-01 11:27:28] [config] no-reload: false
[2023-07-01 11:27:28] [config] no-restore-corpus: false
[2023-07-01 11:27:28] [config] normalize: 1
[2023-07-01 11:27:28] [config] normalize-gradient: false
[2023-07-01 11:27:28] [config] num-devices: 0
[2023-07-01 11:27:28] [config] optimizer: adam
[2023-07-01 11:27:28] [config] optimizer-delay: 1
[2023-07-01 11:27:28] [config] optimizer-params:
[2023-07-01 11:27:28] [config]   - 0.9
[2023-07-01 11:27:28] [config]   - 0.98
[2023-07-01 11:27:28] [config]   - 1e-09
[2023-07-01 11:27:28] [config] output-omit-bias: false
[2023-07-01 11:27:28] [config] overwrite: true
[2023-07-01 11:27:28] [config] precision:
[2023-07-01 11:27:28] [config]   - float32
[2023-07-01 11:27:28] [config]   - float32
[2023-07-01 11:27:28] [config] pretrained-model: ""
[2023-07-01 11:27:28] [config] quantize-biases: false
[2023-07-01 11:27:28] [config] quantize-bits: 0
[2023-07-01 11:27:28] [config] quantize-log-based: false
[2023-07-01 11:27:28] [config] quantize-optimization-steps: 0
[2023-07-01 11:27:28] [config] quiet: false
[2023-07-01 11:27:28] [config] quiet-translation: true
[2023-07-01 11:27:28] [config] relative-paths: false
[2023-07-01 11:27:28] [config] right-left: false
[2023-07-01 11:27:28] [config] save-freq: 10000u
[2023-07-01 11:27:28] [config] seed: 1234
[2023-07-01 11:27:28] [config] sentencepiece-alphas:
[2023-07-01 11:27:28] [config]   []
[2023-07-01 11:27:28] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:27:28] [config] sentencepiece-options: ""
[2023-07-01 11:27:28] [config] sharding: global
[2023-07-01 11:27:28] [config] shuffle: data
[2023-07-01 11:27:28] [config] shuffle-in-ram: false
[2023-07-01 11:27:28] [config] sigterm: save-and-exit
[2023-07-01 11:27:28] [config] skip: false
[2023-07-01 11:27:28] [config] sqlite: ""
[2023-07-01 11:27:28] [config] sqlite-drop: false
[2023-07-01 11:27:28] [config] sync-freq: 200u
[2023-07-01 11:27:28] [config] sync-sgd: true
[2023-07-01 11:27:28] [config] tempdir: /tmp
[2023-07-01 11:27:28] [config] tied-embeddings: false
[2023-07-01 11:27:28] [config] tied-embeddings-all: true
[2023-07-01 11:27:28] [config] tied-embeddings-src: false
[2023-07-01 11:27:28] [config] train-embedder-rank:
[2023-07-01 11:27:28] [config]   []
[2023-07-01 11:27:28] [config] train-sets:
[2023-07-01 11:27:28] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:27:28] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:27:28] [config] transformer-aan-activation: swish
[2023-07-01 11:27:28] [config] transformer-aan-depth: 2
[2023-07-01 11:27:28] [config] transformer-aan-nogate: false
[2023-07-01 11:27:28] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:27:28] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:27:28] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:27:28] [config] transformer-depth-scaling: false
[2023-07-01 11:27:28] [config] transformer-dim-aan: 2048
[2023-07-01 11:27:28] [config] transformer-dim-ffn: 2048
[2023-07-01 11:27:28] [config] transformer-dropout: 0.1
[2023-07-01 11:27:28] [config] transformer-dropout-attention: 0
[2023-07-01 11:27:28] [config] transformer-dropout-ffn: 0
[2023-07-01 11:27:28] [config] transformer-ffn-activation: swish
[2023-07-01 11:27:28] [config] transformer-ffn-depth: 2
[2023-07-01 11:27:28] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:27:28] [config] transformer-heads: 8
[2023-07-01 11:27:28] [config] transformer-no-projection: false
[2023-07-01 11:27:28] [config] transformer-pool: false
[2023-07-01 11:27:28] [config] transformer-postprocess: dan
[2023-07-01 11:27:28] [config] transformer-postprocess-emb: d
[2023-07-01 11:27:28] [config] transformer-postprocess-top: ""
[2023-07-01 11:27:28] [config] transformer-preprocess: ""
[2023-07-01 11:27:28] [config] transformer-tied-layers:
[2023-07-01 11:27:28] [config]   []
[2023-07-01 11:27:28] [config] transformer-train-position-embeddings: false
[2023-07-01 11:27:28] [config] tsv: false
[2023-07-01 11:27:28] [config] tsv-fields: 0
[2023-07-01 11:27:28] [config] type: transformer
[2023-07-01 11:27:28] [config] ulr: false
[2023-07-01 11:27:28] [config] ulr-dim-emb: 0
[2023-07-01 11:27:28] [config] ulr-dropout: 0
[2023-07-01 11:27:28] [config] ulr-keys-vectors: ""
[2023-07-01 11:27:28] [config] ulr-query-vectors: ""
[2023-07-01 11:27:28] [config] ulr-softmax-temperature: 1
[2023-07-01 11:27:28] [config] ulr-trainable-transformation: false
[2023-07-01 11:27:28] [config] unlikelihood-loss: false
[2023-07-01 11:27:28] [config] valid-freq: 50000000
[2023-07-01 11:27:28] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:27:28] [config] valid-max-length: 1000
[2023-07-01 11:27:28] [config] valid-metrics:
[2023-07-01 11:27:28] [config]   - cross-entropy
[2023-07-01 11:27:28] [config]   - translation
[2023-07-01 11:27:28] [config] valid-mini-batch: 64
[2023-07-01 11:27:28] [config] valid-reset-stalled: false
[2023-07-01 11:27:28] [config] valid-script-args:
[2023-07-01 11:27:28] [config]   []
[2023-07-01 11:27:28] [config] valid-script-path: ""
[2023-07-01 11:27:28] [config] valid-sets:
[2023-07-01 11:27:28] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:27:28] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:27:28] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:27:28] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:27:28] [config] vocabs:
[2023-07-01 11:27:28] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:27:28] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:27:28] [config] word-penalty: 0
[2023-07-01 11:27:28] [config] word-scores: false
[2023-07-01 11:27:28] [config] workspace: 2048
[2023-07-01 11:27:28] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:27:28] Using synchronous SGD
[2023-07-01 11:27:28] Synced seed 1234
[2023-07-01 11:27:28] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:27:28] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:27:28] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:27:28] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:27:28] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:27:28] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:27:29] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:27:29] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:27:29] [comm] Using global sharding
[2023-07-01 11:27:29] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:27:29] [training] Using 1 GPUs
[2023-07-01 11:27:29] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:27:29] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:27:29] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:27:29] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:27:37] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:27:37] [valid] No post-processing script given for validating translator
[2023-07-01 11:27:37] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:27:37] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:27:37] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:27:37] [comm] Using global sharding
[2023-07-01 11:27:37] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:27:37] [training] Using 1 GPUs
[2023-07-01 11:27:37] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:27:37] Allocating memory for general optimizer shards
[2023-07-01 11:27:37] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:27:37] Loading Adam parameters
[2023-07-01 11:27:37] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:27:38] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:27:38] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:27:38] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:27:38] [data] Shuffling data
[2023-07-01 11:27:38] [data] Done reading 20,192 sentences
[2023-07-01 11:27:38] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:27:38] Training started
[2023-07-01 11:27:38] Training finished
[2023-07-01 11:27:41] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:27:41] [marian] Running on node20.datos.cluster.uy as process 15979 with command line:
[2023-07-01 11:27:41] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 83 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:27:41] [config] after: 0e
[2023-07-01 11:27:41] [config] after-batches: 0
[2023-07-01 11:27:41] [config] after-epochs: 83
[2023-07-01 11:27:41] [config] all-caps-every: 0
[2023-07-01 11:27:41] [config] allow-unk: false
[2023-07-01 11:27:41] [config] authors: false
[2023-07-01 11:27:41] [config] beam-size: 12
[2023-07-01 11:27:41] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:27:41] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:27:41] [config] bert-masking-fraction: 0.15
[2023-07-01 11:27:41] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:27:41] [config] bert-train-type-embeddings: true
[2023-07-01 11:27:41] [config] bert-type-vocab-size: 2
[2023-07-01 11:27:41] [config] build-info: ""
[2023-07-01 11:27:41] [config] check-gradient-nan: false
[2023-07-01 11:27:41] [config] check-nan: false
[2023-07-01 11:27:41] [config] cite: false
[2023-07-01 11:27:41] [config] clip-norm: 5
[2023-07-01 11:27:41] [config] cost-scaling:
[2023-07-01 11:27:41] [config]   []
[2023-07-01 11:27:41] [config] cost-type: ce-sum
[2023-07-01 11:27:41] [config] cpu-threads: 0
[2023-07-01 11:27:41] [config] data-threads: 8
[2023-07-01 11:27:41] [config] data-weighting: ""
[2023-07-01 11:27:41] [config] data-weighting-type: sentence
[2023-07-01 11:27:41] [config] dec-cell: gru
[2023-07-01 11:27:41] [config] dec-cell-base-depth: 2
[2023-07-01 11:27:41] [config] dec-cell-high-depth: 1
[2023-07-01 11:27:41] [config] dec-depth: 2
[2023-07-01 11:27:41] [config] devices:
[2023-07-01 11:27:41] [config]   - 0
[2023-07-01 11:27:41] [config] dim-emb: 512
[2023-07-01 11:27:41] [config] dim-rnn: 1024
[2023-07-01 11:27:41] [config] dim-vocabs:
[2023-07-01 11:27:41] [config]   - 16384
[2023-07-01 11:27:41] [config]   - 16384
[2023-07-01 11:27:41] [config] disp-first: 0
[2023-07-01 11:27:41] [config] disp-freq: 1000u
[2023-07-01 11:27:41] [config] disp-label-counts: true
[2023-07-01 11:27:41] [config] dropout-rnn: 0
[2023-07-01 11:27:41] [config] dropout-src: 0
[2023-07-01 11:27:41] [config] dropout-trg: 0
[2023-07-01 11:27:41] [config] dump-config: ""
[2023-07-01 11:27:41] [config] dynamic-gradient-scaling:
[2023-07-01 11:27:41] [config]   []
[2023-07-01 11:27:41] [config] early-stopping: 10
[2023-07-01 11:27:41] [config] early-stopping-on: first
[2023-07-01 11:27:41] [config] embedding-fix-src: false
[2023-07-01 11:27:41] [config] embedding-fix-trg: false
[2023-07-01 11:27:41] [config] embedding-normalization: false
[2023-07-01 11:27:41] [config] embedding-vectors:
[2023-07-01 11:27:41] [config]   []
[2023-07-01 11:27:41] [config] enc-cell: gru
[2023-07-01 11:27:41] [config] enc-cell-depth: 1
[2023-07-01 11:27:41] [config] enc-depth: 2
[2023-07-01 11:27:41] [config] enc-type: bidirectional
[2023-07-01 11:27:41] [config] english-title-case-every: 0
[2023-07-01 11:27:41] [config] exponential-smoothing: 0.0001
[2023-07-01 11:27:41] [config] factor-weight: 1
[2023-07-01 11:27:41] [config] factors-combine: sum
[2023-07-01 11:27:41] [config] factors-dim-emb: 0
[2023-07-01 11:27:41] [config] gradient-checkpointing: false
[2023-07-01 11:27:41] [config] gradient-norm-average-window: 100
[2023-07-01 11:27:41] [config] guided-alignment: none
[2023-07-01 11:27:41] [config] guided-alignment-cost: mse
[2023-07-01 11:27:41] [config] guided-alignment-weight: 0.1
[2023-07-01 11:27:41] [config] ignore-model-config: false
[2023-07-01 11:27:41] [config] input-types:
[2023-07-01 11:27:41] [config]   []
[2023-07-01 11:27:41] [config] interpolate-env-vars: false
[2023-07-01 11:27:41] [config] keep-best: false
[2023-07-01 11:27:41] [config] label-smoothing: 0.1
[2023-07-01 11:27:41] [config] layer-normalization: false
[2023-07-01 11:27:41] [config] learn-rate: 0.0003
[2023-07-01 11:27:41] [config] lemma-dependency: ""
[2023-07-01 11:27:41] [config] lemma-dim-emb: 0
[2023-07-01 11:27:41] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:27:41] [config] log-level: info
[2023-07-01 11:27:41] [config] log-time-zone: ""
[2023-07-01 11:27:41] [config] logical-epoch:
[2023-07-01 11:27:41] [config]   - 1e
[2023-07-01 11:27:41] [config]   - 0
[2023-07-01 11:27:41] [config] lr-decay: 0
[2023-07-01 11:27:41] [config] lr-decay-freq: 50000
[2023-07-01 11:27:41] [config] lr-decay-inv-sqrt:
[2023-07-01 11:27:41] [config]   - 16000
[2023-07-01 11:27:41] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:27:41] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:27:41] [config] lr-decay-start:
[2023-07-01 11:27:41] [config]   - 10
[2023-07-01 11:27:41] [config]   - 1
[2023-07-01 11:27:41] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:27:41] [config] lr-report: true
[2023-07-01 11:27:41] [config] lr-warmup: 16000
[2023-07-01 11:27:41] [config] lr-warmup-at-reload: false
[2023-07-01 11:27:41] [config] lr-warmup-cycle: false
[2023-07-01 11:27:41] [config] lr-warmup-start-rate: 0
[2023-07-01 11:27:41] [config] max-length: 100
[2023-07-01 11:27:41] [config] max-length-crop: false
[2023-07-01 11:27:41] [config] max-length-factor: 3
[2023-07-01 11:27:41] [config] maxi-batch: 100
[2023-07-01 11:27:41] [config] maxi-batch-sort: trg
[2023-07-01 11:27:41] [config] mini-batch: 1000
[2023-07-01 11:27:41] [config] mini-batch-fit: true
[2023-07-01 11:27:41] [config] mini-batch-fit-step: 10
[2023-07-01 11:27:41] [config] mini-batch-round-up: true
[2023-07-01 11:27:41] [config] mini-batch-track-lr: false
[2023-07-01 11:27:41] [config] mini-batch-warmup: 0
[2023-07-01 11:27:41] [config] mini-batch-words: 0
[2023-07-01 11:27:41] [config] mini-batch-words-ref: 0
[2023-07-01 11:27:41] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:27:41] [config] multi-loss-type: sum
[2023-07-01 11:27:41] [config] n-best: false
[2023-07-01 11:27:41] [config] no-nccl: false
[2023-07-01 11:27:41] [config] no-reload: false
[2023-07-01 11:27:41] [config] no-restore-corpus: false
[2023-07-01 11:27:41] [config] normalize: 1
[2023-07-01 11:27:41] [config] normalize-gradient: false
[2023-07-01 11:27:41] [config] num-devices: 0
[2023-07-01 11:27:41] [config] optimizer: adam
[2023-07-01 11:27:41] [config] optimizer-delay: 1
[2023-07-01 11:27:41] [config] optimizer-params:
[2023-07-01 11:27:41] [config]   - 0.9
[2023-07-01 11:27:41] [config]   - 0.98
[2023-07-01 11:27:41] [config]   - 1e-09
[2023-07-01 11:27:41] [config] output-omit-bias: false
[2023-07-01 11:27:41] [config] overwrite: true
[2023-07-01 11:27:41] [config] precision:
[2023-07-01 11:27:41] [config]   - float32
[2023-07-01 11:27:41] [config]   - float32
[2023-07-01 11:27:41] [config] pretrained-model: ""
[2023-07-01 11:27:41] [config] quantize-biases: false
[2023-07-01 11:27:41] [config] quantize-bits: 0
[2023-07-01 11:27:41] [config] quantize-log-based: false
[2023-07-01 11:27:41] [config] quantize-optimization-steps: 0
[2023-07-01 11:27:41] [config] quiet: false
[2023-07-01 11:27:41] [config] quiet-translation: true
[2023-07-01 11:27:41] [config] relative-paths: false
[2023-07-01 11:27:41] [config] right-left: false
[2023-07-01 11:27:41] [config] save-freq: 10000u
[2023-07-01 11:27:41] [config] seed: 1234
[2023-07-01 11:27:41] [config] sentencepiece-alphas:
[2023-07-01 11:27:41] [config]   []
[2023-07-01 11:27:41] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:27:41] [config] sentencepiece-options: ""
[2023-07-01 11:27:41] [config] sharding: global
[2023-07-01 11:27:41] [config] shuffle: data
[2023-07-01 11:27:41] [config] shuffle-in-ram: false
[2023-07-01 11:27:41] [config] sigterm: save-and-exit
[2023-07-01 11:27:41] [config] skip: false
[2023-07-01 11:27:41] [config] sqlite: ""
[2023-07-01 11:27:41] [config] sqlite-drop: false
[2023-07-01 11:27:41] [config] sync-freq: 200u
[2023-07-01 11:27:41] [config] sync-sgd: true
[2023-07-01 11:27:41] [config] tempdir: /tmp
[2023-07-01 11:27:41] [config] tied-embeddings: false
[2023-07-01 11:27:41] [config] tied-embeddings-all: true
[2023-07-01 11:27:41] [config] tied-embeddings-src: false
[2023-07-01 11:27:41] [config] train-embedder-rank:
[2023-07-01 11:27:41] [config]   []
[2023-07-01 11:27:41] [config] train-sets:
[2023-07-01 11:27:41] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:27:41] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:27:41] [config] transformer-aan-activation: swish
[2023-07-01 11:27:41] [config] transformer-aan-depth: 2
[2023-07-01 11:27:41] [config] transformer-aan-nogate: false
[2023-07-01 11:27:41] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:27:41] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:27:41] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:27:41] [config] transformer-depth-scaling: false
[2023-07-01 11:27:41] [config] transformer-dim-aan: 2048
[2023-07-01 11:27:41] [config] transformer-dim-ffn: 2048
[2023-07-01 11:27:41] [config] transformer-dropout: 0.1
[2023-07-01 11:27:41] [config] transformer-dropout-attention: 0
[2023-07-01 11:27:41] [config] transformer-dropout-ffn: 0
[2023-07-01 11:27:41] [config] transformer-ffn-activation: swish
[2023-07-01 11:27:41] [config] transformer-ffn-depth: 2
[2023-07-01 11:27:41] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:27:41] [config] transformer-heads: 8
[2023-07-01 11:27:41] [config] transformer-no-projection: false
[2023-07-01 11:27:41] [config] transformer-pool: false
[2023-07-01 11:27:41] [config] transformer-postprocess: dan
[2023-07-01 11:27:41] [config] transformer-postprocess-emb: d
[2023-07-01 11:27:41] [config] transformer-postprocess-top: ""
[2023-07-01 11:27:41] [config] transformer-preprocess: ""
[2023-07-01 11:27:41] [config] transformer-tied-layers:
[2023-07-01 11:27:41] [config]   []
[2023-07-01 11:27:41] [config] transformer-train-position-embeddings: false
[2023-07-01 11:27:41] [config] tsv: false
[2023-07-01 11:27:41] [config] tsv-fields: 0
[2023-07-01 11:27:41] [config] type: transformer
[2023-07-01 11:27:41] [config] ulr: false
[2023-07-01 11:27:41] [config] ulr-dim-emb: 0
[2023-07-01 11:27:41] [config] ulr-dropout: 0
[2023-07-01 11:27:41] [config] ulr-keys-vectors: ""
[2023-07-01 11:27:41] [config] ulr-query-vectors: ""
[2023-07-01 11:27:41] [config] ulr-softmax-temperature: 1
[2023-07-01 11:27:41] [config] ulr-trainable-transformation: false
[2023-07-01 11:27:41] [config] unlikelihood-loss: false
[2023-07-01 11:27:41] [config] valid-freq: 50000000
[2023-07-01 11:27:41] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:27:41] [config] valid-max-length: 1000
[2023-07-01 11:27:41] [config] valid-metrics:
[2023-07-01 11:27:41] [config]   - cross-entropy
[2023-07-01 11:27:41] [config]   - translation
[2023-07-01 11:27:41] [config] valid-mini-batch: 64
[2023-07-01 11:27:41] [config] valid-reset-stalled: false
[2023-07-01 11:27:41] [config] valid-script-args:
[2023-07-01 11:27:41] [config]   []
[2023-07-01 11:27:41] [config] valid-script-path: ""
[2023-07-01 11:27:41] [config] valid-sets:
[2023-07-01 11:27:41] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:27:41] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:27:41] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:27:41] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:27:41] [config] vocabs:
[2023-07-01 11:27:41] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:27:41] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:27:41] [config] word-penalty: 0
[2023-07-01 11:27:41] [config] word-scores: false
[2023-07-01 11:27:41] [config] workspace: 2048
[2023-07-01 11:27:41] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:27:41] Using synchronous SGD
[2023-07-01 11:27:42] Synced seed 1234
[2023-07-01 11:27:42] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:27:42] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:27:42] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:27:42] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:27:42] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:27:42] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:27:42] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:27:42] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:27:42] [comm] Using global sharding
[2023-07-01 11:27:43] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:27:43] [training] Using 1 GPUs
[2023-07-01 11:27:43] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:27:43] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:27:43] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:27:43] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:27:50] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:27:51] [valid] No post-processing script given for validating translator
[2023-07-01 11:27:51] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:27:51] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:27:51] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:27:51] [comm] Using global sharding
[2023-07-01 11:27:51] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:27:51] [training] Using 1 GPUs
[2023-07-01 11:27:51] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:27:51] Allocating memory for general optimizer shards
[2023-07-01 11:27:51] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:27:51] Loading Adam parameters
[2023-07-01 11:27:51] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:27:51] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:27:51] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:27:51] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:27:51] [data] Shuffling data
[2023-07-01 11:27:51] [data] Done reading 20,192 sentences
[2023-07-01 11:27:51] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:27:51] Training started
[2023-07-01 11:27:51] Training finished
[2023-07-01 11:27:55] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:27:55] [marian] Running on node20.datos.cluster.uy as process 16037 with command line:
[2023-07-01 11:27:55] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 84 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:27:55] [config] after: 0e
[2023-07-01 11:27:55] [config] after-batches: 0
[2023-07-01 11:27:55] [config] after-epochs: 84
[2023-07-01 11:27:55] [config] all-caps-every: 0
[2023-07-01 11:27:55] [config] allow-unk: false
[2023-07-01 11:27:55] [config] authors: false
[2023-07-01 11:27:55] [config] beam-size: 12
[2023-07-01 11:27:55] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:27:55] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:27:55] [config] bert-masking-fraction: 0.15
[2023-07-01 11:27:55] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:27:55] [config] bert-train-type-embeddings: true
[2023-07-01 11:27:55] [config] bert-type-vocab-size: 2
[2023-07-01 11:27:55] [config] build-info: ""
[2023-07-01 11:27:55] [config] check-gradient-nan: false
[2023-07-01 11:27:55] [config] check-nan: false
[2023-07-01 11:27:55] [config] cite: false
[2023-07-01 11:27:55] [config] clip-norm: 5
[2023-07-01 11:27:55] [config] cost-scaling:
[2023-07-01 11:27:55] [config]   []
[2023-07-01 11:27:55] [config] cost-type: ce-sum
[2023-07-01 11:27:55] [config] cpu-threads: 0
[2023-07-01 11:27:55] [config] data-threads: 8
[2023-07-01 11:27:55] [config] data-weighting: ""
[2023-07-01 11:27:55] [config] data-weighting-type: sentence
[2023-07-01 11:27:55] [config] dec-cell: gru
[2023-07-01 11:27:55] [config] dec-cell-base-depth: 2
[2023-07-01 11:27:55] [config] dec-cell-high-depth: 1
[2023-07-01 11:27:55] [config] dec-depth: 2
[2023-07-01 11:27:55] [config] devices:
[2023-07-01 11:27:55] [config]   - 0
[2023-07-01 11:27:55] [config] dim-emb: 512
[2023-07-01 11:27:55] [config] dim-rnn: 1024
[2023-07-01 11:27:55] [config] dim-vocabs:
[2023-07-01 11:27:55] [config]   - 16384
[2023-07-01 11:27:55] [config]   - 16384
[2023-07-01 11:27:55] [config] disp-first: 0
[2023-07-01 11:27:55] [config] disp-freq: 1000u
[2023-07-01 11:27:55] [config] disp-label-counts: true
[2023-07-01 11:27:55] [config] dropout-rnn: 0
[2023-07-01 11:27:55] [config] dropout-src: 0
[2023-07-01 11:27:55] [config] dropout-trg: 0
[2023-07-01 11:27:55] [config] dump-config: ""
[2023-07-01 11:27:55] [config] dynamic-gradient-scaling:
[2023-07-01 11:27:55] [config]   []
[2023-07-01 11:27:55] [config] early-stopping: 10
[2023-07-01 11:27:55] [config] early-stopping-on: first
[2023-07-01 11:27:55] [config] embedding-fix-src: false
[2023-07-01 11:27:55] [config] embedding-fix-trg: false
[2023-07-01 11:27:55] [config] embedding-normalization: false
[2023-07-01 11:27:55] [config] embedding-vectors:
[2023-07-01 11:27:55] [config]   []
[2023-07-01 11:27:55] [config] enc-cell: gru
[2023-07-01 11:27:55] [config] enc-cell-depth: 1
[2023-07-01 11:27:55] [config] enc-depth: 2
[2023-07-01 11:27:55] [config] enc-type: bidirectional
[2023-07-01 11:27:55] [config] english-title-case-every: 0
[2023-07-01 11:27:55] [config] exponential-smoothing: 0.0001
[2023-07-01 11:27:55] [config] factor-weight: 1
[2023-07-01 11:27:55] [config] factors-combine: sum
[2023-07-01 11:27:55] [config] factors-dim-emb: 0
[2023-07-01 11:27:55] [config] gradient-checkpointing: false
[2023-07-01 11:27:55] [config] gradient-norm-average-window: 100
[2023-07-01 11:27:55] [config] guided-alignment: none
[2023-07-01 11:27:55] [config] guided-alignment-cost: mse
[2023-07-01 11:27:55] [config] guided-alignment-weight: 0.1
[2023-07-01 11:27:55] [config] ignore-model-config: false
[2023-07-01 11:27:55] [config] input-types:
[2023-07-01 11:27:55] [config]   []
[2023-07-01 11:27:55] [config] interpolate-env-vars: false
[2023-07-01 11:27:55] [config] keep-best: false
[2023-07-01 11:27:55] [config] label-smoothing: 0.1
[2023-07-01 11:27:55] [config] layer-normalization: false
[2023-07-01 11:27:55] [config] learn-rate: 0.0003
[2023-07-01 11:27:55] [config] lemma-dependency: ""
[2023-07-01 11:27:55] [config] lemma-dim-emb: 0
[2023-07-01 11:27:55] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:27:55] [config] log-level: info
[2023-07-01 11:27:55] [config] log-time-zone: ""
[2023-07-01 11:27:55] [config] logical-epoch:
[2023-07-01 11:27:55] [config]   - 1e
[2023-07-01 11:27:55] [config]   - 0
[2023-07-01 11:27:55] [config] lr-decay: 0
[2023-07-01 11:27:55] [config] lr-decay-freq: 50000
[2023-07-01 11:27:55] [config] lr-decay-inv-sqrt:
[2023-07-01 11:27:55] [config]   - 16000
[2023-07-01 11:27:55] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:27:55] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:27:55] [config] lr-decay-start:
[2023-07-01 11:27:55] [config]   - 10
[2023-07-01 11:27:55] [config]   - 1
[2023-07-01 11:27:55] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:27:55] [config] lr-report: true
[2023-07-01 11:27:55] [config] lr-warmup: 16000
[2023-07-01 11:27:55] [config] lr-warmup-at-reload: false
[2023-07-01 11:27:55] [config] lr-warmup-cycle: false
[2023-07-01 11:27:55] [config] lr-warmup-start-rate: 0
[2023-07-01 11:27:55] [config] max-length: 100
[2023-07-01 11:27:55] [config] max-length-crop: false
[2023-07-01 11:27:55] [config] max-length-factor: 3
[2023-07-01 11:27:55] [config] maxi-batch: 100
[2023-07-01 11:27:55] [config] maxi-batch-sort: trg
[2023-07-01 11:27:55] [config] mini-batch: 1000
[2023-07-01 11:27:55] [config] mini-batch-fit: true
[2023-07-01 11:27:55] [config] mini-batch-fit-step: 10
[2023-07-01 11:27:55] [config] mini-batch-round-up: true
[2023-07-01 11:27:55] [config] mini-batch-track-lr: false
[2023-07-01 11:27:55] [config] mini-batch-warmup: 0
[2023-07-01 11:27:55] [config] mini-batch-words: 0
[2023-07-01 11:27:55] [config] mini-batch-words-ref: 0
[2023-07-01 11:27:55] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:27:55] [config] multi-loss-type: sum
[2023-07-01 11:27:55] [config] n-best: false
[2023-07-01 11:27:55] [config] no-nccl: false
[2023-07-01 11:27:55] [config] no-reload: false
[2023-07-01 11:27:55] [config] no-restore-corpus: false
[2023-07-01 11:27:55] [config] normalize: 1
[2023-07-01 11:27:55] [config] normalize-gradient: false
[2023-07-01 11:27:55] [config] num-devices: 0
[2023-07-01 11:27:55] [config] optimizer: adam
[2023-07-01 11:27:55] [config] optimizer-delay: 1
[2023-07-01 11:27:55] [config] optimizer-params:
[2023-07-01 11:27:55] [config]   - 0.9
[2023-07-01 11:27:55] [config]   - 0.98
[2023-07-01 11:27:55] [config]   - 1e-09
[2023-07-01 11:27:55] [config] output-omit-bias: false
[2023-07-01 11:27:55] [config] overwrite: true
[2023-07-01 11:27:55] [config] precision:
[2023-07-01 11:27:55] [config]   - float32
[2023-07-01 11:27:55] [config]   - float32
[2023-07-01 11:27:55] [config] pretrained-model: ""
[2023-07-01 11:27:55] [config] quantize-biases: false
[2023-07-01 11:27:55] [config] quantize-bits: 0
[2023-07-01 11:27:55] [config] quantize-log-based: false
[2023-07-01 11:27:55] [config] quantize-optimization-steps: 0
[2023-07-01 11:27:55] [config] quiet: false
[2023-07-01 11:27:55] [config] quiet-translation: true
[2023-07-01 11:27:55] [config] relative-paths: false
[2023-07-01 11:27:55] [config] right-left: false
[2023-07-01 11:27:55] [config] save-freq: 10000u
[2023-07-01 11:27:55] [config] seed: 1234
[2023-07-01 11:27:55] [config] sentencepiece-alphas:
[2023-07-01 11:27:55] [config]   []
[2023-07-01 11:27:55] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:27:55] [config] sentencepiece-options: ""
[2023-07-01 11:27:55] [config] sharding: global
[2023-07-01 11:27:55] [config] shuffle: data
[2023-07-01 11:27:55] [config] shuffle-in-ram: false
[2023-07-01 11:27:55] [config] sigterm: save-and-exit
[2023-07-01 11:27:55] [config] skip: false
[2023-07-01 11:27:55] [config] sqlite: ""
[2023-07-01 11:27:55] [config] sqlite-drop: false
[2023-07-01 11:27:55] [config] sync-freq: 200u
[2023-07-01 11:27:55] [config] sync-sgd: true
[2023-07-01 11:27:55] [config] tempdir: /tmp
[2023-07-01 11:27:55] [config] tied-embeddings: false
[2023-07-01 11:27:55] [config] tied-embeddings-all: true
[2023-07-01 11:27:55] [config] tied-embeddings-src: false
[2023-07-01 11:27:55] [config] train-embedder-rank:
[2023-07-01 11:27:55] [config]   []
[2023-07-01 11:27:55] [config] train-sets:
[2023-07-01 11:27:55] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:27:55] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:27:55] [config] transformer-aan-activation: swish
[2023-07-01 11:27:55] [config] transformer-aan-depth: 2
[2023-07-01 11:27:55] [config] transformer-aan-nogate: false
[2023-07-01 11:27:55] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:27:55] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:27:55] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:27:55] [config] transformer-depth-scaling: false
[2023-07-01 11:27:55] [config] transformer-dim-aan: 2048
[2023-07-01 11:27:55] [config] transformer-dim-ffn: 2048
[2023-07-01 11:27:55] [config] transformer-dropout: 0.1
[2023-07-01 11:27:55] [config] transformer-dropout-attention: 0
[2023-07-01 11:27:55] [config] transformer-dropout-ffn: 0
[2023-07-01 11:27:55] [config] transformer-ffn-activation: swish
[2023-07-01 11:27:55] [config] transformer-ffn-depth: 2
[2023-07-01 11:27:55] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:27:55] [config] transformer-heads: 8
[2023-07-01 11:27:55] [config] transformer-no-projection: false
[2023-07-01 11:27:55] [config] transformer-pool: false
[2023-07-01 11:27:55] [config] transformer-postprocess: dan
[2023-07-01 11:27:55] [config] transformer-postprocess-emb: d
[2023-07-01 11:27:55] [config] transformer-postprocess-top: ""
[2023-07-01 11:27:55] [config] transformer-preprocess: ""
[2023-07-01 11:27:55] [config] transformer-tied-layers:
[2023-07-01 11:27:55] [config]   []
[2023-07-01 11:27:55] [config] transformer-train-position-embeddings: false
[2023-07-01 11:27:55] [config] tsv: false
[2023-07-01 11:27:55] [config] tsv-fields: 0
[2023-07-01 11:27:55] [config] type: transformer
[2023-07-01 11:27:55] [config] ulr: false
[2023-07-01 11:27:55] [config] ulr-dim-emb: 0
[2023-07-01 11:27:55] [config] ulr-dropout: 0
[2023-07-01 11:27:55] [config] ulr-keys-vectors: ""
[2023-07-01 11:27:55] [config] ulr-query-vectors: ""
[2023-07-01 11:27:55] [config] ulr-softmax-temperature: 1
[2023-07-01 11:27:55] [config] ulr-trainable-transformation: false
[2023-07-01 11:27:55] [config] unlikelihood-loss: false
[2023-07-01 11:27:55] [config] valid-freq: 50000000
[2023-07-01 11:27:55] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:27:55] [config] valid-max-length: 1000
[2023-07-01 11:27:55] [config] valid-metrics:
[2023-07-01 11:27:55] [config]   - cross-entropy
[2023-07-01 11:27:55] [config]   - translation
[2023-07-01 11:27:55] [config] valid-mini-batch: 64
[2023-07-01 11:27:55] [config] valid-reset-stalled: false
[2023-07-01 11:27:55] [config] valid-script-args:
[2023-07-01 11:27:55] [config]   []
[2023-07-01 11:27:55] [config] valid-script-path: ""
[2023-07-01 11:27:55] [config] valid-sets:
[2023-07-01 11:27:55] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:27:55] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:27:55] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:27:55] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:27:55] [config] vocabs:
[2023-07-01 11:27:55] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:27:55] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:27:55] [config] word-penalty: 0
[2023-07-01 11:27:55] [config] word-scores: false
[2023-07-01 11:27:55] [config] workspace: 2048
[2023-07-01 11:27:55] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:27:55] Using synchronous SGD
[2023-07-01 11:27:55] Synced seed 1234
[2023-07-01 11:27:55] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:27:55] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:27:55] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:27:56] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:27:56] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:27:56] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:27:56] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:27:56] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:27:56] [comm] Using global sharding
[2023-07-01 11:27:56] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:27:56] [training] Using 1 GPUs
[2023-07-01 11:27:56] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:27:56] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:27:57] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:27:57] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:28:04] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:28:04] [valid] No post-processing script given for validating translator
[2023-07-01 11:28:04] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:28:04] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:28:04] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:28:04] [comm] Using global sharding
[2023-07-01 11:28:04] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:28:04] [training] Using 1 GPUs
[2023-07-01 11:28:04] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:28:05] Allocating memory for general optimizer shards
[2023-07-01 11:28:05] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:28:05] Loading Adam parameters
[2023-07-01 11:28:05] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:28:05] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:28:05] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:28:05] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:28:05] [data] Shuffling data
[2023-07-01 11:28:05] [data] Done reading 20,192 sentences
[2023-07-01 11:28:05] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:28:05] Training started
[2023-07-01 11:28:05] Training finished
[2023-07-01 11:28:09] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:28:09] [marian] Running on node20.datos.cluster.uy as process 16095 with command line:
[2023-07-01 11:28:09] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 85 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:28:09] [config] after: 0e
[2023-07-01 11:28:09] [config] after-batches: 0
[2023-07-01 11:28:09] [config] after-epochs: 85
[2023-07-01 11:28:09] [config] all-caps-every: 0
[2023-07-01 11:28:09] [config] allow-unk: false
[2023-07-01 11:28:09] [config] authors: false
[2023-07-01 11:28:09] [config] beam-size: 12
[2023-07-01 11:28:09] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:28:09] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:28:09] [config] bert-masking-fraction: 0.15
[2023-07-01 11:28:09] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:28:09] [config] bert-train-type-embeddings: true
[2023-07-01 11:28:09] [config] bert-type-vocab-size: 2
[2023-07-01 11:28:09] [config] build-info: ""
[2023-07-01 11:28:09] [config] check-gradient-nan: false
[2023-07-01 11:28:09] [config] check-nan: false
[2023-07-01 11:28:09] [config] cite: false
[2023-07-01 11:28:09] [config] clip-norm: 5
[2023-07-01 11:28:09] [config] cost-scaling:
[2023-07-01 11:28:09] [config]   []
[2023-07-01 11:28:09] [config] cost-type: ce-sum
[2023-07-01 11:28:09] [config] cpu-threads: 0
[2023-07-01 11:28:09] [config] data-threads: 8
[2023-07-01 11:28:09] [config] data-weighting: ""
[2023-07-01 11:28:09] [config] data-weighting-type: sentence
[2023-07-01 11:28:09] [config] dec-cell: gru
[2023-07-01 11:28:09] [config] dec-cell-base-depth: 2
[2023-07-01 11:28:09] [config] dec-cell-high-depth: 1
[2023-07-01 11:28:09] [config] dec-depth: 2
[2023-07-01 11:28:09] [config] devices:
[2023-07-01 11:28:09] [config]   - 0
[2023-07-01 11:28:09] [config] dim-emb: 512
[2023-07-01 11:28:09] [config] dim-rnn: 1024
[2023-07-01 11:28:09] [config] dim-vocabs:
[2023-07-01 11:28:09] [config]   - 16384
[2023-07-01 11:28:09] [config]   - 16384
[2023-07-01 11:28:09] [config] disp-first: 0
[2023-07-01 11:28:09] [config] disp-freq: 1000u
[2023-07-01 11:28:09] [config] disp-label-counts: true
[2023-07-01 11:28:09] [config] dropout-rnn: 0
[2023-07-01 11:28:09] [config] dropout-src: 0
[2023-07-01 11:28:09] [config] dropout-trg: 0
[2023-07-01 11:28:09] [config] dump-config: ""
[2023-07-01 11:28:09] [config] dynamic-gradient-scaling:
[2023-07-01 11:28:09] [config]   []
[2023-07-01 11:28:09] [config] early-stopping: 10
[2023-07-01 11:28:09] [config] early-stopping-on: first
[2023-07-01 11:28:09] [config] embedding-fix-src: false
[2023-07-01 11:28:09] [config] embedding-fix-trg: false
[2023-07-01 11:28:09] [config] embedding-normalization: false
[2023-07-01 11:28:09] [config] embedding-vectors:
[2023-07-01 11:28:09] [config]   []
[2023-07-01 11:28:09] [config] enc-cell: gru
[2023-07-01 11:28:09] [config] enc-cell-depth: 1
[2023-07-01 11:28:09] [config] enc-depth: 2
[2023-07-01 11:28:09] [config] enc-type: bidirectional
[2023-07-01 11:28:09] [config] english-title-case-every: 0
[2023-07-01 11:28:09] [config] exponential-smoothing: 0.0001
[2023-07-01 11:28:09] [config] factor-weight: 1
[2023-07-01 11:28:09] [config] factors-combine: sum
[2023-07-01 11:28:09] [config] factors-dim-emb: 0
[2023-07-01 11:28:09] [config] gradient-checkpointing: false
[2023-07-01 11:28:09] [config] gradient-norm-average-window: 100
[2023-07-01 11:28:09] [config] guided-alignment: none
[2023-07-01 11:28:09] [config] guided-alignment-cost: mse
[2023-07-01 11:28:09] [config] guided-alignment-weight: 0.1
[2023-07-01 11:28:09] [config] ignore-model-config: false
[2023-07-01 11:28:09] [config] input-types:
[2023-07-01 11:28:09] [config]   []
[2023-07-01 11:28:09] [config] interpolate-env-vars: false
[2023-07-01 11:28:09] [config] keep-best: false
[2023-07-01 11:28:09] [config] label-smoothing: 0.1
[2023-07-01 11:28:09] [config] layer-normalization: false
[2023-07-01 11:28:09] [config] learn-rate: 0.0003
[2023-07-01 11:28:09] [config] lemma-dependency: ""
[2023-07-01 11:28:09] [config] lemma-dim-emb: 0
[2023-07-01 11:28:09] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:28:09] [config] log-level: info
[2023-07-01 11:28:09] [config] log-time-zone: ""
[2023-07-01 11:28:09] [config] logical-epoch:
[2023-07-01 11:28:09] [config]   - 1e
[2023-07-01 11:28:09] [config]   - 0
[2023-07-01 11:28:09] [config] lr-decay: 0
[2023-07-01 11:28:09] [config] lr-decay-freq: 50000
[2023-07-01 11:28:09] [config] lr-decay-inv-sqrt:
[2023-07-01 11:28:09] [config]   - 16000
[2023-07-01 11:28:09] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:28:09] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:28:09] [config] lr-decay-start:
[2023-07-01 11:28:09] [config]   - 10
[2023-07-01 11:28:09] [config]   - 1
[2023-07-01 11:28:09] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:28:09] [config] lr-report: true
[2023-07-01 11:28:09] [config] lr-warmup: 16000
[2023-07-01 11:28:09] [config] lr-warmup-at-reload: false
[2023-07-01 11:28:09] [config] lr-warmup-cycle: false
[2023-07-01 11:28:09] [config] lr-warmup-start-rate: 0
[2023-07-01 11:28:09] [config] max-length: 100
[2023-07-01 11:28:09] [config] max-length-crop: false
[2023-07-01 11:28:09] [config] max-length-factor: 3
[2023-07-01 11:28:09] [config] maxi-batch: 100
[2023-07-01 11:28:09] [config] maxi-batch-sort: trg
[2023-07-01 11:28:09] [config] mini-batch: 1000
[2023-07-01 11:28:09] [config] mini-batch-fit: true
[2023-07-01 11:28:09] [config] mini-batch-fit-step: 10
[2023-07-01 11:28:09] [config] mini-batch-round-up: true
[2023-07-01 11:28:09] [config] mini-batch-track-lr: false
[2023-07-01 11:28:09] [config] mini-batch-warmup: 0
[2023-07-01 11:28:09] [config] mini-batch-words: 0
[2023-07-01 11:28:09] [config] mini-batch-words-ref: 0
[2023-07-01 11:28:09] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:28:09] [config] multi-loss-type: sum
[2023-07-01 11:28:09] [config] n-best: false
[2023-07-01 11:28:09] [config] no-nccl: false
[2023-07-01 11:28:09] [config] no-reload: false
[2023-07-01 11:28:09] [config] no-restore-corpus: false
[2023-07-01 11:28:09] [config] normalize: 1
[2023-07-01 11:28:09] [config] normalize-gradient: false
[2023-07-01 11:28:09] [config] num-devices: 0
[2023-07-01 11:28:09] [config] optimizer: adam
[2023-07-01 11:28:09] [config] optimizer-delay: 1
[2023-07-01 11:28:09] [config] optimizer-params:
[2023-07-01 11:28:09] [config]   - 0.9
[2023-07-01 11:28:09] [config]   - 0.98
[2023-07-01 11:28:09] [config]   - 1e-09
[2023-07-01 11:28:09] [config] output-omit-bias: false
[2023-07-01 11:28:09] [config] overwrite: true
[2023-07-01 11:28:09] [config] precision:
[2023-07-01 11:28:09] [config]   - float32
[2023-07-01 11:28:09] [config]   - float32
[2023-07-01 11:28:09] [config] pretrained-model: ""
[2023-07-01 11:28:09] [config] quantize-biases: false
[2023-07-01 11:28:09] [config] quantize-bits: 0
[2023-07-01 11:28:09] [config] quantize-log-based: false
[2023-07-01 11:28:09] [config] quantize-optimization-steps: 0
[2023-07-01 11:28:09] [config] quiet: false
[2023-07-01 11:28:09] [config] quiet-translation: true
[2023-07-01 11:28:09] [config] relative-paths: false
[2023-07-01 11:28:09] [config] right-left: false
[2023-07-01 11:28:09] [config] save-freq: 10000u
[2023-07-01 11:28:09] [config] seed: 1234
[2023-07-01 11:28:09] [config] sentencepiece-alphas:
[2023-07-01 11:28:09] [config]   []
[2023-07-01 11:28:09] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:28:09] [config] sentencepiece-options: ""
[2023-07-01 11:28:09] [config] sharding: global
[2023-07-01 11:28:09] [config] shuffle: data
[2023-07-01 11:28:09] [config] shuffle-in-ram: false
[2023-07-01 11:28:09] [config] sigterm: save-and-exit
[2023-07-01 11:28:09] [config] skip: false
[2023-07-01 11:28:09] [config] sqlite: ""
[2023-07-01 11:28:09] [config] sqlite-drop: false
[2023-07-01 11:28:09] [config] sync-freq: 200u
[2023-07-01 11:28:09] [config] sync-sgd: true
[2023-07-01 11:28:09] [config] tempdir: /tmp
[2023-07-01 11:28:09] [config] tied-embeddings: false
[2023-07-01 11:28:09] [config] tied-embeddings-all: true
[2023-07-01 11:28:09] [config] tied-embeddings-src: false
[2023-07-01 11:28:09] [config] train-embedder-rank:
[2023-07-01 11:28:09] [config]   []
[2023-07-01 11:28:09] [config] train-sets:
[2023-07-01 11:28:09] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:28:09] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:28:09] [config] transformer-aan-activation: swish
[2023-07-01 11:28:09] [config] transformer-aan-depth: 2
[2023-07-01 11:28:09] [config] transformer-aan-nogate: false
[2023-07-01 11:28:09] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:28:09] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:28:09] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:28:09] [config] transformer-depth-scaling: false
[2023-07-01 11:28:09] [config] transformer-dim-aan: 2048
[2023-07-01 11:28:09] [config] transformer-dim-ffn: 2048
[2023-07-01 11:28:09] [config] transformer-dropout: 0.1
[2023-07-01 11:28:09] [config] transformer-dropout-attention: 0
[2023-07-01 11:28:09] [config] transformer-dropout-ffn: 0
[2023-07-01 11:28:09] [config] transformer-ffn-activation: swish
[2023-07-01 11:28:09] [config] transformer-ffn-depth: 2
[2023-07-01 11:28:09] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:28:09] [config] transformer-heads: 8
[2023-07-01 11:28:09] [config] transformer-no-projection: false
[2023-07-01 11:28:09] [config] transformer-pool: false
[2023-07-01 11:28:09] [config] transformer-postprocess: dan
[2023-07-01 11:28:09] [config] transformer-postprocess-emb: d
[2023-07-01 11:28:09] [config] transformer-postprocess-top: ""
[2023-07-01 11:28:09] [config] transformer-preprocess: ""
[2023-07-01 11:28:09] [config] transformer-tied-layers:
[2023-07-01 11:28:09] [config]   []
[2023-07-01 11:28:09] [config] transformer-train-position-embeddings: false
[2023-07-01 11:28:09] [config] tsv: false
[2023-07-01 11:28:09] [config] tsv-fields: 0
[2023-07-01 11:28:09] [config] type: transformer
[2023-07-01 11:28:09] [config] ulr: false
[2023-07-01 11:28:09] [config] ulr-dim-emb: 0
[2023-07-01 11:28:09] [config] ulr-dropout: 0
[2023-07-01 11:28:09] [config] ulr-keys-vectors: ""
[2023-07-01 11:28:09] [config] ulr-query-vectors: ""
[2023-07-01 11:28:09] [config] ulr-softmax-temperature: 1
[2023-07-01 11:28:09] [config] ulr-trainable-transformation: false
[2023-07-01 11:28:09] [config] unlikelihood-loss: false
[2023-07-01 11:28:09] [config] valid-freq: 50000000
[2023-07-01 11:28:09] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:28:09] [config] valid-max-length: 1000
[2023-07-01 11:28:09] [config] valid-metrics:
[2023-07-01 11:28:09] [config]   - cross-entropy
[2023-07-01 11:28:09] [config]   - translation
[2023-07-01 11:28:09] [config] valid-mini-batch: 64
[2023-07-01 11:28:09] [config] valid-reset-stalled: false
[2023-07-01 11:28:09] [config] valid-script-args:
[2023-07-01 11:28:09] [config]   []
[2023-07-01 11:28:09] [config] valid-script-path: ""
[2023-07-01 11:28:09] [config] valid-sets:
[2023-07-01 11:28:09] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:28:09] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:28:09] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:28:09] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:28:09] [config] vocabs:
[2023-07-01 11:28:09] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:28:09] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:28:09] [config] word-penalty: 0
[2023-07-01 11:28:09] [config] word-scores: false
[2023-07-01 11:28:09] [config] workspace: 2048
[2023-07-01 11:28:09] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:28:09] Using synchronous SGD
[2023-07-01 11:28:09] Synced seed 1234
[2023-07-01 11:28:09] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:28:09] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:28:09] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:28:09] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:28:09] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:28:09] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:28:10] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:28:10] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:28:10] [comm] Using global sharding
[2023-07-01 11:28:10] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:28:10] [training] Using 1 GPUs
[2023-07-01 11:28:10] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:28:10] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:28:10] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:28:10] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:28:18] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:28:18] [valid] No post-processing script given for validating translator
[2023-07-01 11:28:18] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:28:18] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:28:18] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:28:18] [comm] Using global sharding
[2023-07-01 11:28:18] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:28:18] [training] Using 1 GPUs
[2023-07-01 11:28:18] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:28:18] Allocating memory for general optimizer shards
[2023-07-01 11:28:18] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:28:19] Loading Adam parameters
[2023-07-01 11:28:19] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:28:19] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:28:19] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:28:19] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:28:19] [data] Shuffling data
[2023-07-01 11:28:19] [data] Done reading 20,192 sentences
[2023-07-01 11:28:19] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:28:19] Training started
[2023-07-01 11:28:19] Training finished
[2023-07-01 11:28:22] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:28:22] [marian] Running on node20.datos.cluster.uy as process 16154 with command line:
[2023-07-01 11:28:22] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 86 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:28:22] [config] after: 0e
[2023-07-01 11:28:22] [config] after-batches: 0
[2023-07-01 11:28:22] [config] after-epochs: 86
[2023-07-01 11:28:22] [config] all-caps-every: 0
[2023-07-01 11:28:22] [config] allow-unk: false
[2023-07-01 11:28:22] [config] authors: false
[2023-07-01 11:28:22] [config] beam-size: 12
[2023-07-01 11:28:22] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:28:22] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:28:22] [config] bert-masking-fraction: 0.15
[2023-07-01 11:28:22] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:28:22] [config] bert-train-type-embeddings: true
[2023-07-01 11:28:22] [config] bert-type-vocab-size: 2
[2023-07-01 11:28:22] [config] build-info: ""
[2023-07-01 11:28:22] [config] check-gradient-nan: false
[2023-07-01 11:28:22] [config] check-nan: false
[2023-07-01 11:28:22] [config] cite: false
[2023-07-01 11:28:22] [config] clip-norm: 5
[2023-07-01 11:28:22] [config] cost-scaling:
[2023-07-01 11:28:22] [config]   []
[2023-07-01 11:28:22] [config] cost-type: ce-sum
[2023-07-01 11:28:22] [config] cpu-threads: 0
[2023-07-01 11:28:22] [config] data-threads: 8
[2023-07-01 11:28:22] [config] data-weighting: ""
[2023-07-01 11:28:22] [config] data-weighting-type: sentence
[2023-07-01 11:28:22] [config] dec-cell: gru
[2023-07-01 11:28:22] [config] dec-cell-base-depth: 2
[2023-07-01 11:28:22] [config] dec-cell-high-depth: 1
[2023-07-01 11:28:22] [config] dec-depth: 2
[2023-07-01 11:28:22] [config] devices:
[2023-07-01 11:28:22] [config]   - 0
[2023-07-01 11:28:22] [config] dim-emb: 512
[2023-07-01 11:28:22] [config] dim-rnn: 1024
[2023-07-01 11:28:22] [config] dim-vocabs:
[2023-07-01 11:28:22] [config]   - 16384
[2023-07-01 11:28:22] [config]   - 16384
[2023-07-01 11:28:22] [config] disp-first: 0
[2023-07-01 11:28:22] [config] disp-freq: 1000u
[2023-07-01 11:28:22] [config] disp-label-counts: true
[2023-07-01 11:28:22] [config] dropout-rnn: 0
[2023-07-01 11:28:22] [config] dropout-src: 0
[2023-07-01 11:28:22] [config] dropout-trg: 0
[2023-07-01 11:28:22] [config] dump-config: ""
[2023-07-01 11:28:22] [config] dynamic-gradient-scaling:
[2023-07-01 11:28:22] [config]   []
[2023-07-01 11:28:22] [config] early-stopping: 10
[2023-07-01 11:28:22] [config] early-stopping-on: first
[2023-07-01 11:28:22] [config] embedding-fix-src: false
[2023-07-01 11:28:22] [config] embedding-fix-trg: false
[2023-07-01 11:28:22] [config] embedding-normalization: false
[2023-07-01 11:28:22] [config] embedding-vectors:
[2023-07-01 11:28:22] [config]   []
[2023-07-01 11:28:22] [config] enc-cell: gru
[2023-07-01 11:28:22] [config] enc-cell-depth: 1
[2023-07-01 11:28:22] [config] enc-depth: 2
[2023-07-01 11:28:22] [config] enc-type: bidirectional
[2023-07-01 11:28:22] [config] english-title-case-every: 0
[2023-07-01 11:28:22] [config] exponential-smoothing: 0.0001
[2023-07-01 11:28:22] [config] factor-weight: 1
[2023-07-01 11:28:22] [config] factors-combine: sum
[2023-07-01 11:28:22] [config] factors-dim-emb: 0
[2023-07-01 11:28:22] [config] gradient-checkpointing: false
[2023-07-01 11:28:22] [config] gradient-norm-average-window: 100
[2023-07-01 11:28:22] [config] guided-alignment: none
[2023-07-01 11:28:22] [config] guided-alignment-cost: mse
[2023-07-01 11:28:22] [config] guided-alignment-weight: 0.1
[2023-07-01 11:28:22] [config] ignore-model-config: false
[2023-07-01 11:28:22] [config] input-types:
[2023-07-01 11:28:22] [config]   []
[2023-07-01 11:28:22] [config] interpolate-env-vars: false
[2023-07-01 11:28:22] [config] keep-best: false
[2023-07-01 11:28:22] [config] label-smoothing: 0.1
[2023-07-01 11:28:22] [config] layer-normalization: false
[2023-07-01 11:28:22] [config] learn-rate: 0.0003
[2023-07-01 11:28:22] [config] lemma-dependency: ""
[2023-07-01 11:28:22] [config] lemma-dim-emb: 0
[2023-07-01 11:28:22] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:28:22] [config] log-level: info
[2023-07-01 11:28:22] [config] log-time-zone: ""
[2023-07-01 11:28:22] [config] logical-epoch:
[2023-07-01 11:28:22] [config]   - 1e
[2023-07-01 11:28:22] [config]   - 0
[2023-07-01 11:28:22] [config] lr-decay: 0
[2023-07-01 11:28:22] [config] lr-decay-freq: 50000
[2023-07-01 11:28:22] [config] lr-decay-inv-sqrt:
[2023-07-01 11:28:22] [config]   - 16000
[2023-07-01 11:28:22] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:28:22] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:28:22] [config] lr-decay-start:
[2023-07-01 11:28:22] [config]   - 10
[2023-07-01 11:28:22] [config]   - 1
[2023-07-01 11:28:22] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:28:22] [config] lr-report: true
[2023-07-01 11:28:22] [config] lr-warmup: 16000
[2023-07-01 11:28:22] [config] lr-warmup-at-reload: false
[2023-07-01 11:28:22] [config] lr-warmup-cycle: false
[2023-07-01 11:28:22] [config] lr-warmup-start-rate: 0
[2023-07-01 11:28:22] [config] max-length: 100
[2023-07-01 11:28:22] [config] max-length-crop: false
[2023-07-01 11:28:22] [config] max-length-factor: 3
[2023-07-01 11:28:22] [config] maxi-batch: 100
[2023-07-01 11:28:22] [config] maxi-batch-sort: trg
[2023-07-01 11:28:22] [config] mini-batch: 1000
[2023-07-01 11:28:22] [config] mini-batch-fit: true
[2023-07-01 11:28:22] [config] mini-batch-fit-step: 10
[2023-07-01 11:28:22] [config] mini-batch-round-up: true
[2023-07-01 11:28:22] [config] mini-batch-track-lr: false
[2023-07-01 11:28:22] [config] mini-batch-warmup: 0
[2023-07-01 11:28:22] [config] mini-batch-words: 0
[2023-07-01 11:28:22] [config] mini-batch-words-ref: 0
[2023-07-01 11:28:22] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:28:22] [config] multi-loss-type: sum
[2023-07-01 11:28:22] [config] n-best: false
[2023-07-01 11:28:22] [config] no-nccl: false
[2023-07-01 11:28:22] [config] no-reload: false
[2023-07-01 11:28:22] [config] no-restore-corpus: false
[2023-07-01 11:28:22] [config] normalize: 1
[2023-07-01 11:28:22] [config] normalize-gradient: false
[2023-07-01 11:28:22] [config] num-devices: 0
[2023-07-01 11:28:22] [config] optimizer: adam
[2023-07-01 11:28:22] [config] optimizer-delay: 1
[2023-07-01 11:28:22] [config] optimizer-params:
[2023-07-01 11:28:22] [config]   - 0.9
[2023-07-01 11:28:22] [config]   - 0.98
[2023-07-01 11:28:22] [config]   - 1e-09
[2023-07-01 11:28:22] [config] output-omit-bias: false
[2023-07-01 11:28:22] [config] overwrite: true
[2023-07-01 11:28:22] [config] precision:
[2023-07-01 11:28:22] [config]   - float32
[2023-07-01 11:28:22] [config]   - float32
[2023-07-01 11:28:22] [config] pretrained-model: ""
[2023-07-01 11:28:22] [config] quantize-biases: false
[2023-07-01 11:28:22] [config] quantize-bits: 0
[2023-07-01 11:28:22] [config] quantize-log-based: false
[2023-07-01 11:28:22] [config] quantize-optimization-steps: 0
[2023-07-01 11:28:22] [config] quiet: false
[2023-07-01 11:28:22] [config] quiet-translation: true
[2023-07-01 11:28:22] [config] relative-paths: false
[2023-07-01 11:28:22] [config] right-left: false
[2023-07-01 11:28:22] [config] save-freq: 10000u
[2023-07-01 11:28:22] [config] seed: 1234
[2023-07-01 11:28:22] [config] sentencepiece-alphas:
[2023-07-01 11:28:22] [config]   []
[2023-07-01 11:28:22] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:28:22] [config] sentencepiece-options: ""
[2023-07-01 11:28:22] [config] sharding: global
[2023-07-01 11:28:22] [config] shuffle: data
[2023-07-01 11:28:22] [config] shuffle-in-ram: false
[2023-07-01 11:28:22] [config] sigterm: save-and-exit
[2023-07-01 11:28:22] [config] skip: false
[2023-07-01 11:28:22] [config] sqlite: ""
[2023-07-01 11:28:22] [config] sqlite-drop: false
[2023-07-01 11:28:22] [config] sync-freq: 200u
[2023-07-01 11:28:22] [config] sync-sgd: true
[2023-07-01 11:28:22] [config] tempdir: /tmp
[2023-07-01 11:28:22] [config] tied-embeddings: false
[2023-07-01 11:28:22] [config] tied-embeddings-all: true
[2023-07-01 11:28:22] [config] tied-embeddings-src: false
[2023-07-01 11:28:22] [config] train-embedder-rank:
[2023-07-01 11:28:22] [config]   []
[2023-07-01 11:28:22] [config] train-sets:
[2023-07-01 11:28:22] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:28:22] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:28:22] [config] transformer-aan-activation: swish
[2023-07-01 11:28:22] [config] transformer-aan-depth: 2
[2023-07-01 11:28:22] [config] transformer-aan-nogate: false
[2023-07-01 11:28:22] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:28:22] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:28:22] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:28:22] [config] transformer-depth-scaling: false
[2023-07-01 11:28:22] [config] transformer-dim-aan: 2048
[2023-07-01 11:28:22] [config] transformer-dim-ffn: 2048
[2023-07-01 11:28:22] [config] transformer-dropout: 0.1
[2023-07-01 11:28:22] [config] transformer-dropout-attention: 0
[2023-07-01 11:28:22] [config] transformer-dropout-ffn: 0
[2023-07-01 11:28:22] [config] transformer-ffn-activation: swish
[2023-07-01 11:28:22] [config] transformer-ffn-depth: 2
[2023-07-01 11:28:22] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:28:22] [config] transformer-heads: 8
[2023-07-01 11:28:22] [config] transformer-no-projection: false
[2023-07-01 11:28:22] [config] transformer-pool: false
[2023-07-01 11:28:22] [config] transformer-postprocess: dan
[2023-07-01 11:28:22] [config] transformer-postprocess-emb: d
[2023-07-01 11:28:22] [config] transformer-postprocess-top: ""
[2023-07-01 11:28:22] [config] transformer-preprocess: ""
[2023-07-01 11:28:22] [config] transformer-tied-layers:
[2023-07-01 11:28:22] [config]   []
[2023-07-01 11:28:22] [config] transformer-train-position-embeddings: false
[2023-07-01 11:28:22] [config] tsv: false
[2023-07-01 11:28:22] [config] tsv-fields: 0
[2023-07-01 11:28:22] [config] type: transformer
[2023-07-01 11:28:22] [config] ulr: false
[2023-07-01 11:28:22] [config] ulr-dim-emb: 0
[2023-07-01 11:28:22] [config] ulr-dropout: 0
[2023-07-01 11:28:22] [config] ulr-keys-vectors: ""
[2023-07-01 11:28:22] [config] ulr-query-vectors: ""
[2023-07-01 11:28:22] [config] ulr-softmax-temperature: 1
[2023-07-01 11:28:22] [config] ulr-trainable-transformation: false
[2023-07-01 11:28:22] [config] unlikelihood-loss: false
[2023-07-01 11:28:22] [config] valid-freq: 50000000
[2023-07-01 11:28:22] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:28:22] [config] valid-max-length: 1000
[2023-07-01 11:28:22] [config] valid-metrics:
[2023-07-01 11:28:22] [config]   - cross-entropy
[2023-07-01 11:28:22] [config]   - translation
[2023-07-01 11:28:22] [config] valid-mini-batch: 64
[2023-07-01 11:28:22] [config] valid-reset-stalled: false
[2023-07-01 11:28:22] [config] valid-script-args:
[2023-07-01 11:28:22] [config]   []
[2023-07-01 11:28:22] [config] valid-script-path: ""
[2023-07-01 11:28:22] [config] valid-sets:
[2023-07-01 11:28:22] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:28:22] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:28:22] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:28:22] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:28:22] [config] vocabs:
[2023-07-01 11:28:22] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:28:22] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:28:22] [config] word-penalty: 0
[2023-07-01 11:28:22] [config] word-scores: false
[2023-07-01 11:28:22] [config] workspace: 2048
[2023-07-01 11:28:22] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:28:22] Using synchronous SGD
[2023-07-01 11:28:23] Synced seed 1234
[2023-07-01 11:28:23] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:28:23] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:28:23] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:28:23] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:28:23] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:28:23] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:28:23] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:28:23] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:28:23] [comm] Using global sharding
[2023-07-01 11:28:23] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:28:23] [training] Using 1 GPUs
[2023-07-01 11:28:23] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:28:23] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:28:24] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:28:24] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:28:31] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:28:31] [valid] No post-processing script given for validating translator
[2023-07-01 11:28:31] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:28:31] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:28:31] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:28:31] [comm] Using global sharding
[2023-07-01 11:28:31] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:28:31] [training] Using 1 GPUs
[2023-07-01 11:28:31] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:28:32] Allocating memory for general optimizer shards
[2023-07-01 11:28:32] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:28:32] Loading Adam parameters
[2023-07-01 11:28:32] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:28:32] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:28:32] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:28:32] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:28:32] [data] Shuffling data
[2023-07-01 11:28:32] [data] Done reading 20,192 sentences
[2023-07-01 11:28:32] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:28:32] Training started
[2023-07-01 11:28:32] Training finished
[2023-07-01 11:28:36] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:28:36] [marian] Running on node20.datos.cluster.uy as process 16216 with command line:
[2023-07-01 11:28:36] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 87 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:28:36] [config] after: 0e
[2023-07-01 11:28:36] [config] after-batches: 0
[2023-07-01 11:28:36] [config] after-epochs: 87
[2023-07-01 11:28:36] [config] all-caps-every: 0
[2023-07-01 11:28:36] [config] allow-unk: false
[2023-07-01 11:28:36] [config] authors: false
[2023-07-01 11:28:36] [config] beam-size: 12
[2023-07-01 11:28:36] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:28:36] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:28:36] [config] bert-masking-fraction: 0.15
[2023-07-01 11:28:36] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:28:36] [config] bert-train-type-embeddings: true
[2023-07-01 11:28:36] [config] bert-type-vocab-size: 2
[2023-07-01 11:28:36] [config] build-info: ""
[2023-07-01 11:28:36] [config] check-gradient-nan: false
[2023-07-01 11:28:36] [config] check-nan: false
[2023-07-01 11:28:36] [config] cite: false
[2023-07-01 11:28:36] [config] clip-norm: 5
[2023-07-01 11:28:36] [config] cost-scaling:
[2023-07-01 11:28:36] [config]   []
[2023-07-01 11:28:36] [config] cost-type: ce-sum
[2023-07-01 11:28:36] [config] cpu-threads: 0
[2023-07-01 11:28:36] [config] data-threads: 8
[2023-07-01 11:28:36] [config] data-weighting: ""
[2023-07-01 11:28:36] [config] data-weighting-type: sentence
[2023-07-01 11:28:36] [config] dec-cell: gru
[2023-07-01 11:28:36] [config] dec-cell-base-depth: 2
[2023-07-01 11:28:36] [config] dec-cell-high-depth: 1
[2023-07-01 11:28:36] [config] dec-depth: 2
[2023-07-01 11:28:36] [config] devices:
[2023-07-01 11:28:36] [config]   - 0
[2023-07-01 11:28:36] [config] dim-emb: 512
[2023-07-01 11:28:36] [config] dim-rnn: 1024
[2023-07-01 11:28:36] [config] dim-vocabs:
[2023-07-01 11:28:36] [config]   - 16384
[2023-07-01 11:28:36] [config]   - 16384
[2023-07-01 11:28:36] [config] disp-first: 0
[2023-07-01 11:28:36] [config] disp-freq: 1000u
[2023-07-01 11:28:36] [config] disp-label-counts: true
[2023-07-01 11:28:36] [config] dropout-rnn: 0
[2023-07-01 11:28:36] [config] dropout-src: 0
[2023-07-01 11:28:36] [config] dropout-trg: 0
[2023-07-01 11:28:36] [config] dump-config: ""
[2023-07-01 11:28:36] [config] dynamic-gradient-scaling:
[2023-07-01 11:28:36] [config]   []
[2023-07-01 11:28:36] [config] early-stopping: 10
[2023-07-01 11:28:36] [config] early-stopping-on: first
[2023-07-01 11:28:36] [config] embedding-fix-src: false
[2023-07-01 11:28:36] [config] embedding-fix-trg: false
[2023-07-01 11:28:36] [config] embedding-normalization: false
[2023-07-01 11:28:36] [config] embedding-vectors:
[2023-07-01 11:28:36] [config]   []
[2023-07-01 11:28:36] [config] enc-cell: gru
[2023-07-01 11:28:36] [config] enc-cell-depth: 1
[2023-07-01 11:28:36] [config] enc-depth: 2
[2023-07-01 11:28:36] [config] enc-type: bidirectional
[2023-07-01 11:28:36] [config] english-title-case-every: 0
[2023-07-01 11:28:36] [config] exponential-smoothing: 0.0001
[2023-07-01 11:28:36] [config] factor-weight: 1
[2023-07-01 11:28:36] [config] factors-combine: sum
[2023-07-01 11:28:36] [config] factors-dim-emb: 0
[2023-07-01 11:28:36] [config] gradient-checkpointing: false
[2023-07-01 11:28:36] [config] gradient-norm-average-window: 100
[2023-07-01 11:28:36] [config] guided-alignment: none
[2023-07-01 11:28:36] [config] guided-alignment-cost: mse
[2023-07-01 11:28:36] [config] guided-alignment-weight: 0.1
[2023-07-01 11:28:36] [config] ignore-model-config: false
[2023-07-01 11:28:36] [config] input-types:
[2023-07-01 11:28:36] [config]   []
[2023-07-01 11:28:36] [config] interpolate-env-vars: false
[2023-07-01 11:28:36] [config] keep-best: false
[2023-07-01 11:28:36] [config] label-smoothing: 0.1
[2023-07-01 11:28:36] [config] layer-normalization: false
[2023-07-01 11:28:36] [config] learn-rate: 0.0003
[2023-07-01 11:28:36] [config] lemma-dependency: ""
[2023-07-01 11:28:36] [config] lemma-dim-emb: 0
[2023-07-01 11:28:36] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:28:36] [config] log-level: info
[2023-07-01 11:28:36] [config] log-time-zone: ""
[2023-07-01 11:28:36] [config] logical-epoch:
[2023-07-01 11:28:36] [config]   - 1e
[2023-07-01 11:28:36] [config]   - 0
[2023-07-01 11:28:36] [config] lr-decay: 0
[2023-07-01 11:28:36] [config] lr-decay-freq: 50000
[2023-07-01 11:28:36] [config] lr-decay-inv-sqrt:
[2023-07-01 11:28:36] [config]   - 16000
[2023-07-01 11:28:36] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:28:36] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:28:36] [config] lr-decay-start:
[2023-07-01 11:28:36] [config]   - 10
[2023-07-01 11:28:36] [config]   - 1
[2023-07-01 11:28:36] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:28:36] [config] lr-report: true
[2023-07-01 11:28:36] [config] lr-warmup: 16000
[2023-07-01 11:28:36] [config] lr-warmup-at-reload: false
[2023-07-01 11:28:36] [config] lr-warmup-cycle: false
[2023-07-01 11:28:36] [config] lr-warmup-start-rate: 0
[2023-07-01 11:28:36] [config] max-length: 100
[2023-07-01 11:28:36] [config] max-length-crop: false
[2023-07-01 11:28:36] [config] max-length-factor: 3
[2023-07-01 11:28:36] [config] maxi-batch: 100
[2023-07-01 11:28:36] [config] maxi-batch-sort: trg
[2023-07-01 11:28:36] [config] mini-batch: 1000
[2023-07-01 11:28:36] [config] mini-batch-fit: true
[2023-07-01 11:28:36] [config] mini-batch-fit-step: 10
[2023-07-01 11:28:36] [config] mini-batch-round-up: true
[2023-07-01 11:28:36] [config] mini-batch-track-lr: false
[2023-07-01 11:28:36] [config] mini-batch-warmup: 0
[2023-07-01 11:28:36] [config] mini-batch-words: 0
[2023-07-01 11:28:36] [config] mini-batch-words-ref: 0
[2023-07-01 11:28:36] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:28:36] [config] multi-loss-type: sum
[2023-07-01 11:28:36] [config] n-best: false
[2023-07-01 11:28:36] [config] no-nccl: false
[2023-07-01 11:28:36] [config] no-reload: false
[2023-07-01 11:28:36] [config] no-restore-corpus: false
[2023-07-01 11:28:36] [config] normalize: 1
[2023-07-01 11:28:36] [config] normalize-gradient: false
[2023-07-01 11:28:36] [config] num-devices: 0
[2023-07-01 11:28:36] [config] optimizer: adam
[2023-07-01 11:28:36] [config] optimizer-delay: 1
[2023-07-01 11:28:36] [config] optimizer-params:
[2023-07-01 11:28:36] [config]   - 0.9
[2023-07-01 11:28:36] [config]   - 0.98
[2023-07-01 11:28:36] [config]   - 1e-09
[2023-07-01 11:28:36] [config] output-omit-bias: false
[2023-07-01 11:28:36] [config] overwrite: true
[2023-07-01 11:28:36] [config] precision:
[2023-07-01 11:28:36] [config]   - float32
[2023-07-01 11:28:36] [config]   - float32
[2023-07-01 11:28:36] [config] pretrained-model: ""
[2023-07-01 11:28:36] [config] quantize-biases: false
[2023-07-01 11:28:36] [config] quantize-bits: 0
[2023-07-01 11:28:36] [config] quantize-log-based: false
[2023-07-01 11:28:36] [config] quantize-optimization-steps: 0
[2023-07-01 11:28:36] [config] quiet: false
[2023-07-01 11:28:36] [config] quiet-translation: true
[2023-07-01 11:28:36] [config] relative-paths: false
[2023-07-01 11:28:36] [config] right-left: false
[2023-07-01 11:28:36] [config] save-freq: 10000u
[2023-07-01 11:28:36] [config] seed: 1234
[2023-07-01 11:28:36] [config] sentencepiece-alphas:
[2023-07-01 11:28:36] [config]   []
[2023-07-01 11:28:36] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:28:36] [config] sentencepiece-options: ""
[2023-07-01 11:28:36] [config] sharding: global
[2023-07-01 11:28:36] [config] shuffle: data
[2023-07-01 11:28:36] [config] shuffle-in-ram: false
[2023-07-01 11:28:36] [config] sigterm: save-and-exit
[2023-07-01 11:28:36] [config] skip: false
[2023-07-01 11:28:36] [config] sqlite: ""
[2023-07-01 11:28:36] [config] sqlite-drop: false
[2023-07-01 11:28:36] [config] sync-freq: 200u
[2023-07-01 11:28:36] [config] sync-sgd: true
[2023-07-01 11:28:36] [config] tempdir: /tmp
[2023-07-01 11:28:36] [config] tied-embeddings: false
[2023-07-01 11:28:36] [config] tied-embeddings-all: true
[2023-07-01 11:28:36] [config] tied-embeddings-src: false
[2023-07-01 11:28:36] [config] train-embedder-rank:
[2023-07-01 11:28:36] [config]   []
[2023-07-01 11:28:36] [config] train-sets:
[2023-07-01 11:28:36] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:28:36] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:28:36] [config] transformer-aan-activation: swish
[2023-07-01 11:28:36] [config] transformer-aan-depth: 2
[2023-07-01 11:28:36] [config] transformer-aan-nogate: false
[2023-07-01 11:28:36] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:28:36] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:28:36] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:28:36] [config] transformer-depth-scaling: false
[2023-07-01 11:28:36] [config] transformer-dim-aan: 2048
[2023-07-01 11:28:36] [config] transformer-dim-ffn: 2048
[2023-07-01 11:28:36] [config] transformer-dropout: 0.1
[2023-07-01 11:28:36] [config] transformer-dropout-attention: 0
[2023-07-01 11:28:36] [config] transformer-dropout-ffn: 0
[2023-07-01 11:28:36] [config] transformer-ffn-activation: swish
[2023-07-01 11:28:36] [config] transformer-ffn-depth: 2
[2023-07-01 11:28:36] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:28:36] [config] transformer-heads: 8
[2023-07-01 11:28:36] [config] transformer-no-projection: false
[2023-07-01 11:28:36] [config] transformer-pool: false
[2023-07-01 11:28:36] [config] transformer-postprocess: dan
[2023-07-01 11:28:36] [config] transformer-postprocess-emb: d
[2023-07-01 11:28:36] [config] transformer-postprocess-top: ""
[2023-07-01 11:28:36] [config] transformer-preprocess: ""
[2023-07-01 11:28:36] [config] transformer-tied-layers:
[2023-07-01 11:28:36] [config]   []
[2023-07-01 11:28:36] [config] transformer-train-position-embeddings: false
[2023-07-01 11:28:36] [config] tsv: false
[2023-07-01 11:28:36] [config] tsv-fields: 0
[2023-07-01 11:28:36] [config] type: transformer
[2023-07-01 11:28:36] [config] ulr: false
[2023-07-01 11:28:36] [config] ulr-dim-emb: 0
[2023-07-01 11:28:36] [config] ulr-dropout: 0
[2023-07-01 11:28:36] [config] ulr-keys-vectors: ""
[2023-07-01 11:28:36] [config] ulr-query-vectors: ""
[2023-07-01 11:28:36] [config] ulr-softmax-temperature: 1
[2023-07-01 11:28:36] [config] ulr-trainable-transformation: false
[2023-07-01 11:28:36] [config] unlikelihood-loss: false
[2023-07-01 11:28:36] [config] valid-freq: 50000000
[2023-07-01 11:28:36] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:28:36] [config] valid-max-length: 1000
[2023-07-01 11:28:36] [config] valid-metrics:
[2023-07-01 11:28:36] [config]   - cross-entropy
[2023-07-01 11:28:36] [config]   - translation
[2023-07-01 11:28:36] [config] valid-mini-batch: 64
[2023-07-01 11:28:36] [config] valid-reset-stalled: false
[2023-07-01 11:28:36] [config] valid-script-args:
[2023-07-01 11:28:36] [config]   []
[2023-07-01 11:28:36] [config] valid-script-path: ""
[2023-07-01 11:28:36] [config] valid-sets:
[2023-07-01 11:28:36] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:28:36] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:28:36] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:28:36] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:28:36] [config] vocabs:
[2023-07-01 11:28:36] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:28:36] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:28:36] [config] word-penalty: 0
[2023-07-01 11:28:36] [config] word-scores: false
[2023-07-01 11:28:36] [config] workspace: 2048
[2023-07-01 11:28:36] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:28:36] Using synchronous SGD
[2023-07-01 11:28:36] Synced seed 1234
[2023-07-01 11:28:36] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:28:36] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:28:36] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:28:36] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:28:36] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:28:36] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:28:37] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:28:37] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:28:37] [comm] Using global sharding
[2023-07-01 11:28:37] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:28:37] [training] Using 1 GPUs
[2023-07-01 11:28:37] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:28:37] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:28:37] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:28:37] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:28:45] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:28:45] [valid] No post-processing script given for validating translator
[2023-07-01 11:28:45] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:28:45] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:28:45] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:28:45] [comm] Using global sharding
[2023-07-01 11:28:45] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:28:45] [training] Using 1 GPUs
[2023-07-01 11:28:45] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:28:45] Allocating memory for general optimizer shards
[2023-07-01 11:28:45] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:28:45] Loading Adam parameters
[2023-07-01 11:28:45] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:28:45] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:28:46] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:28:46] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:28:46] [data] Shuffling data
[2023-07-01 11:28:46] [data] Done reading 20,192 sentences
[2023-07-01 11:28:46] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:28:46] Training started
[2023-07-01 11:28:46] Training finished
[2023-07-01 11:28:49] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:28:49] [marian] Running on node20.datos.cluster.uy as process 16274 with command line:
[2023-07-01 11:28:49] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 88 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:28:49] [config] after: 0e
[2023-07-01 11:28:49] [config] after-batches: 0
[2023-07-01 11:28:49] [config] after-epochs: 88
[2023-07-01 11:28:49] [config] all-caps-every: 0
[2023-07-01 11:28:49] [config] allow-unk: false
[2023-07-01 11:28:49] [config] authors: false
[2023-07-01 11:28:49] [config] beam-size: 12
[2023-07-01 11:28:49] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:28:49] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:28:49] [config] bert-masking-fraction: 0.15
[2023-07-01 11:28:49] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:28:49] [config] bert-train-type-embeddings: true
[2023-07-01 11:28:49] [config] bert-type-vocab-size: 2
[2023-07-01 11:28:49] [config] build-info: ""
[2023-07-01 11:28:49] [config] check-gradient-nan: false
[2023-07-01 11:28:49] [config] check-nan: false
[2023-07-01 11:28:49] [config] cite: false
[2023-07-01 11:28:49] [config] clip-norm: 5
[2023-07-01 11:28:49] [config] cost-scaling:
[2023-07-01 11:28:49] [config]   []
[2023-07-01 11:28:49] [config] cost-type: ce-sum
[2023-07-01 11:28:49] [config] cpu-threads: 0
[2023-07-01 11:28:49] [config] data-threads: 8
[2023-07-01 11:28:49] [config] data-weighting: ""
[2023-07-01 11:28:49] [config] data-weighting-type: sentence
[2023-07-01 11:28:49] [config] dec-cell: gru
[2023-07-01 11:28:49] [config] dec-cell-base-depth: 2
[2023-07-01 11:28:49] [config] dec-cell-high-depth: 1
[2023-07-01 11:28:49] [config] dec-depth: 2
[2023-07-01 11:28:49] [config] devices:
[2023-07-01 11:28:49] [config]   - 0
[2023-07-01 11:28:49] [config] dim-emb: 512
[2023-07-01 11:28:49] [config] dim-rnn: 1024
[2023-07-01 11:28:49] [config] dim-vocabs:
[2023-07-01 11:28:49] [config]   - 16384
[2023-07-01 11:28:49] [config]   - 16384
[2023-07-01 11:28:49] [config] disp-first: 0
[2023-07-01 11:28:49] [config] disp-freq: 1000u
[2023-07-01 11:28:49] [config] disp-label-counts: true
[2023-07-01 11:28:49] [config] dropout-rnn: 0
[2023-07-01 11:28:49] [config] dropout-src: 0
[2023-07-01 11:28:49] [config] dropout-trg: 0
[2023-07-01 11:28:49] [config] dump-config: ""
[2023-07-01 11:28:49] [config] dynamic-gradient-scaling:
[2023-07-01 11:28:49] [config]   []
[2023-07-01 11:28:49] [config] early-stopping: 10
[2023-07-01 11:28:49] [config] early-stopping-on: first
[2023-07-01 11:28:49] [config] embedding-fix-src: false
[2023-07-01 11:28:49] [config] embedding-fix-trg: false
[2023-07-01 11:28:49] [config] embedding-normalization: false
[2023-07-01 11:28:49] [config] embedding-vectors:
[2023-07-01 11:28:49] [config]   []
[2023-07-01 11:28:49] [config] enc-cell: gru
[2023-07-01 11:28:49] [config] enc-cell-depth: 1
[2023-07-01 11:28:49] [config] enc-depth: 2
[2023-07-01 11:28:49] [config] enc-type: bidirectional
[2023-07-01 11:28:49] [config] english-title-case-every: 0
[2023-07-01 11:28:49] [config] exponential-smoothing: 0.0001
[2023-07-01 11:28:49] [config] factor-weight: 1
[2023-07-01 11:28:49] [config] factors-combine: sum
[2023-07-01 11:28:49] [config] factors-dim-emb: 0
[2023-07-01 11:28:49] [config] gradient-checkpointing: false
[2023-07-01 11:28:49] [config] gradient-norm-average-window: 100
[2023-07-01 11:28:49] [config] guided-alignment: none
[2023-07-01 11:28:49] [config] guided-alignment-cost: mse
[2023-07-01 11:28:49] [config] guided-alignment-weight: 0.1
[2023-07-01 11:28:49] [config] ignore-model-config: false
[2023-07-01 11:28:49] [config] input-types:
[2023-07-01 11:28:49] [config]   []
[2023-07-01 11:28:49] [config] interpolate-env-vars: false
[2023-07-01 11:28:49] [config] keep-best: false
[2023-07-01 11:28:49] [config] label-smoothing: 0.1
[2023-07-01 11:28:49] [config] layer-normalization: false
[2023-07-01 11:28:49] [config] learn-rate: 0.0003
[2023-07-01 11:28:49] [config] lemma-dependency: ""
[2023-07-01 11:28:49] [config] lemma-dim-emb: 0
[2023-07-01 11:28:49] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:28:49] [config] log-level: info
[2023-07-01 11:28:49] [config] log-time-zone: ""
[2023-07-01 11:28:49] [config] logical-epoch:
[2023-07-01 11:28:49] [config]   - 1e
[2023-07-01 11:28:49] [config]   - 0
[2023-07-01 11:28:49] [config] lr-decay: 0
[2023-07-01 11:28:49] [config] lr-decay-freq: 50000
[2023-07-01 11:28:49] [config] lr-decay-inv-sqrt:
[2023-07-01 11:28:49] [config]   - 16000
[2023-07-01 11:28:49] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:28:49] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:28:49] [config] lr-decay-start:
[2023-07-01 11:28:49] [config]   - 10
[2023-07-01 11:28:49] [config]   - 1
[2023-07-01 11:28:49] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:28:49] [config] lr-report: true
[2023-07-01 11:28:49] [config] lr-warmup: 16000
[2023-07-01 11:28:49] [config] lr-warmup-at-reload: false
[2023-07-01 11:28:49] [config] lr-warmup-cycle: false
[2023-07-01 11:28:49] [config] lr-warmup-start-rate: 0
[2023-07-01 11:28:49] [config] max-length: 100
[2023-07-01 11:28:49] [config] max-length-crop: false
[2023-07-01 11:28:49] [config] max-length-factor: 3
[2023-07-01 11:28:49] [config] maxi-batch: 100
[2023-07-01 11:28:49] [config] maxi-batch-sort: trg
[2023-07-01 11:28:49] [config] mini-batch: 1000
[2023-07-01 11:28:49] [config] mini-batch-fit: true
[2023-07-01 11:28:49] [config] mini-batch-fit-step: 10
[2023-07-01 11:28:49] [config] mini-batch-round-up: true
[2023-07-01 11:28:49] [config] mini-batch-track-lr: false
[2023-07-01 11:28:49] [config] mini-batch-warmup: 0
[2023-07-01 11:28:49] [config] mini-batch-words: 0
[2023-07-01 11:28:49] [config] mini-batch-words-ref: 0
[2023-07-01 11:28:49] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:28:49] [config] multi-loss-type: sum
[2023-07-01 11:28:49] [config] n-best: false
[2023-07-01 11:28:49] [config] no-nccl: false
[2023-07-01 11:28:49] [config] no-reload: false
[2023-07-01 11:28:49] [config] no-restore-corpus: false
[2023-07-01 11:28:49] [config] normalize: 1
[2023-07-01 11:28:49] [config] normalize-gradient: false
[2023-07-01 11:28:49] [config] num-devices: 0
[2023-07-01 11:28:49] [config] optimizer: adam
[2023-07-01 11:28:49] [config] optimizer-delay: 1
[2023-07-01 11:28:49] [config] optimizer-params:
[2023-07-01 11:28:49] [config]   - 0.9
[2023-07-01 11:28:49] [config]   - 0.98
[2023-07-01 11:28:49] [config]   - 1e-09
[2023-07-01 11:28:49] [config] output-omit-bias: false
[2023-07-01 11:28:49] [config] overwrite: true
[2023-07-01 11:28:49] [config] precision:
[2023-07-01 11:28:49] [config]   - float32
[2023-07-01 11:28:49] [config]   - float32
[2023-07-01 11:28:49] [config] pretrained-model: ""
[2023-07-01 11:28:49] [config] quantize-biases: false
[2023-07-01 11:28:49] [config] quantize-bits: 0
[2023-07-01 11:28:49] [config] quantize-log-based: false
[2023-07-01 11:28:49] [config] quantize-optimization-steps: 0
[2023-07-01 11:28:49] [config] quiet: false
[2023-07-01 11:28:49] [config] quiet-translation: true
[2023-07-01 11:28:49] [config] relative-paths: false
[2023-07-01 11:28:49] [config] right-left: false
[2023-07-01 11:28:49] [config] save-freq: 10000u
[2023-07-01 11:28:49] [config] seed: 1234
[2023-07-01 11:28:49] [config] sentencepiece-alphas:
[2023-07-01 11:28:49] [config]   []
[2023-07-01 11:28:49] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:28:49] [config] sentencepiece-options: ""
[2023-07-01 11:28:49] [config] sharding: global
[2023-07-01 11:28:49] [config] shuffle: data
[2023-07-01 11:28:49] [config] shuffle-in-ram: false
[2023-07-01 11:28:49] [config] sigterm: save-and-exit
[2023-07-01 11:28:49] [config] skip: false
[2023-07-01 11:28:49] [config] sqlite: ""
[2023-07-01 11:28:49] [config] sqlite-drop: false
[2023-07-01 11:28:49] [config] sync-freq: 200u
[2023-07-01 11:28:49] [config] sync-sgd: true
[2023-07-01 11:28:49] [config] tempdir: /tmp
[2023-07-01 11:28:49] [config] tied-embeddings: false
[2023-07-01 11:28:49] [config] tied-embeddings-all: true
[2023-07-01 11:28:49] [config] tied-embeddings-src: false
[2023-07-01 11:28:49] [config] train-embedder-rank:
[2023-07-01 11:28:49] [config]   []
[2023-07-01 11:28:49] [config] train-sets:
[2023-07-01 11:28:49] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:28:49] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:28:49] [config] transformer-aan-activation: swish
[2023-07-01 11:28:49] [config] transformer-aan-depth: 2
[2023-07-01 11:28:49] [config] transformer-aan-nogate: false
[2023-07-01 11:28:49] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:28:49] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:28:49] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:28:49] [config] transformer-depth-scaling: false
[2023-07-01 11:28:49] [config] transformer-dim-aan: 2048
[2023-07-01 11:28:49] [config] transformer-dim-ffn: 2048
[2023-07-01 11:28:49] [config] transformer-dropout: 0.1
[2023-07-01 11:28:49] [config] transformer-dropout-attention: 0
[2023-07-01 11:28:49] [config] transformer-dropout-ffn: 0
[2023-07-01 11:28:49] [config] transformer-ffn-activation: swish
[2023-07-01 11:28:49] [config] transformer-ffn-depth: 2
[2023-07-01 11:28:49] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:28:49] [config] transformer-heads: 8
[2023-07-01 11:28:49] [config] transformer-no-projection: false
[2023-07-01 11:28:49] [config] transformer-pool: false
[2023-07-01 11:28:49] [config] transformer-postprocess: dan
[2023-07-01 11:28:49] [config] transformer-postprocess-emb: d
[2023-07-01 11:28:49] [config] transformer-postprocess-top: ""
[2023-07-01 11:28:49] [config] transformer-preprocess: ""
[2023-07-01 11:28:49] [config] transformer-tied-layers:
[2023-07-01 11:28:49] [config]   []
[2023-07-01 11:28:49] [config] transformer-train-position-embeddings: false
[2023-07-01 11:28:49] [config] tsv: false
[2023-07-01 11:28:49] [config] tsv-fields: 0
[2023-07-01 11:28:49] [config] type: transformer
[2023-07-01 11:28:49] [config] ulr: false
[2023-07-01 11:28:49] [config] ulr-dim-emb: 0
[2023-07-01 11:28:49] [config] ulr-dropout: 0
[2023-07-01 11:28:49] [config] ulr-keys-vectors: ""
[2023-07-01 11:28:49] [config] ulr-query-vectors: ""
[2023-07-01 11:28:49] [config] ulr-softmax-temperature: 1
[2023-07-01 11:28:49] [config] ulr-trainable-transformation: false
[2023-07-01 11:28:49] [config] unlikelihood-loss: false
[2023-07-01 11:28:49] [config] valid-freq: 50000000
[2023-07-01 11:28:49] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:28:49] [config] valid-max-length: 1000
[2023-07-01 11:28:49] [config] valid-metrics:
[2023-07-01 11:28:49] [config]   - cross-entropy
[2023-07-01 11:28:49] [config]   - translation
[2023-07-01 11:28:49] [config] valid-mini-batch: 64
[2023-07-01 11:28:49] [config] valid-reset-stalled: false
[2023-07-01 11:28:49] [config] valid-script-args:
[2023-07-01 11:28:49] [config]   []
[2023-07-01 11:28:49] [config] valid-script-path: ""
[2023-07-01 11:28:49] [config] valid-sets:
[2023-07-01 11:28:49] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:28:49] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:28:49] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:28:49] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:28:49] [config] vocabs:
[2023-07-01 11:28:49] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:28:49] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:28:49] [config] word-penalty: 0
[2023-07-01 11:28:49] [config] word-scores: false
[2023-07-01 11:28:49] [config] workspace: 2048
[2023-07-01 11:28:49] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:28:49] Using synchronous SGD
[2023-07-01 11:28:50] Synced seed 1234
[2023-07-01 11:28:50] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:28:50] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:28:50] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:28:50] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:28:50] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:28:50] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:28:51] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:28:51] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:28:51] [comm] Using global sharding
[2023-07-01 11:28:51] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:28:51] [training] Using 1 GPUs
[2023-07-01 11:28:51] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:28:51] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:28:51] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:28:51] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:28:58] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:28:58] [valid] No post-processing script given for validating translator
[2023-07-01 11:28:58] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:28:58] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:28:58] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:28:58] [comm] Using global sharding
[2023-07-01 11:28:59] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:28:59] [training] Using 1 GPUs
[2023-07-01 11:28:59] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:28:59] Allocating memory for general optimizer shards
[2023-07-01 11:28:59] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:28:59] Loading Adam parameters
[2023-07-01 11:28:59] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:28:59] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:28:59] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:28:59] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:28:59] [data] Shuffling data
[2023-07-01 11:28:59] [data] Done reading 20,192 sentences
[2023-07-01 11:28:59] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:28:59] Training started
[2023-07-01 11:28:59] Training finished
[2023-07-01 11:29:03] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:29:03] [marian] Running on node20.datos.cluster.uy as process 16333 with command line:
[2023-07-01 11:29:03] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 89 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:29:03] [config] after: 0e
[2023-07-01 11:29:03] [config] after-batches: 0
[2023-07-01 11:29:03] [config] after-epochs: 89
[2023-07-01 11:29:03] [config] all-caps-every: 0
[2023-07-01 11:29:03] [config] allow-unk: false
[2023-07-01 11:29:03] [config] authors: false
[2023-07-01 11:29:03] [config] beam-size: 12
[2023-07-01 11:29:03] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:29:03] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:29:03] [config] bert-masking-fraction: 0.15
[2023-07-01 11:29:03] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:29:03] [config] bert-train-type-embeddings: true
[2023-07-01 11:29:03] [config] bert-type-vocab-size: 2
[2023-07-01 11:29:03] [config] build-info: ""
[2023-07-01 11:29:03] [config] check-gradient-nan: false
[2023-07-01 11:29:03] [config] check-nan: false
[2023-07-01 11:29:03] [config] cite: false
[2023-07-01 11:29:03] [config] clip-norm: 5
[2023-07-01 11:29:03] [config] cost-scaling:
[2023-07-01 11:29:03] [config]   []
[2023-07-01 11:29:03] [config] cost-type: ce-sum
[2023-07-01 11:29:03] [config] cpu-threads: 0
[2023-07-01 11:29:03] [config] data-threads: 8
[2023-07-01 11:29:03] [config] data-weighting: ""
[2023-07-01 11:29:03] [config] data-weighting-type: sentence
[2023-07-01 11:29:03] [config] dec-cell: gru
[2023-07-01 11:29:03] [config] dec-cell-base-depth: 2
[2023-07-01 11:29:03] [config] dec-cell-high-depth: 1
[2023-07-01 11:29:03] [config] dec-depth: 2
[2023-07-01 11:29:03] [config] devices:
[2023-07-01 11:29:03] [config]   - 0
[2023-07-01 11:29:03] [config] dim-emb: 512
[2023-07-01 11:29:03] [config] dim-rnn: 1024
[2023-07-01 11:29:03] [config] dim-vocabs:
[2023-07-01 11:29:03] [config]   - 16384
[2023-07-01 11:29:03] [config]   - 16384
[2023-07-01 11:29:03] [config] disp-first: 0
[2023-07-01 11:29:03] [config] disp-freq: 1000u
[2023-07-01 11:29:03] [config] disp-label-counts: true
[2023-07-01 11:29:03] [config] dropout-rnn: 0
[2023-07-01 11:29:03] [config] dropout-src: 0
[2023-07-01 11:29:03] [config] dropout-trg: 0
[2023-07-01 11:29:03] [config] dump-config: ""
[2023-07-01 11:29:03] [config] dynamic-gradient-scaling:
[2023-07-01 11:29:03] [config]   []
[2023-07-01 11:29:03] [config] early-stopping: 10
[2023-07-01 11:29:03] [config] early-stopping-on: first
[2023-07-01 11:29:03] [config] embedding-fix-src: false
[2023-07-01 11:29:03] [config] embedding-fix-trg: false
[2023-07-01 11:29:03] [config] embedding-normalization: false
[2023-07-01 11:29:03] [config] embedding-vectors:
[2023-07-01 11:29:03] [config]   []
[2023-07-01 11:29:03] [config] enc-cell: gru
[2023-07-01 11:29:03] [config] enc-cell-depth: 1
[2023-07-01 11:29:03] [config] enc-depth: 2
[2023-07-01 11:29:03] [config] enc-type: bidirectional
[2023-07-01 11:29:03] [config] english-title-case-every: 0
[2023-07-01 11:29:03] [config] exponential-smoothing: 0.0001
[2023-07-01 11:29:03] [config] factor-weight: 1
[2023-07-01 11:29:03] [config] factors-combine: sum
[2023-07-01 11:29:03] [config] factors-dim-emb: 0
[2023-07-01 11:29:03] [config] gradient-checkpointing: false
[2023-07-01 11:29:03] [config] gradient-norm-average-window: 100
[2023-07-01 11:29:03] [config] guided-alignment: none
[2023-07-01 11:29:03] [config] guided-alignment-cost: mse
[2023-07-01 11:29:03] [config] guided-alignment-weight: 0.1
[2023-07-01 11:29:03] [config] ignore-model-config: false
[2023-07-01 11:29:03] [config] input-types:
[2023-07-01 11:29:03] [config]   []
[2023-07-01 11:29:03] [config] interpolate-env-vars: false
[2023-07-01 11:29:03] [config] keep-best: false
[2023-07-01 11:29:03] [config] label-smoothing: 0.1
[2023-07-01 11:29:03] [config] layer-normalization: false
[2023-07-01 11:29:03] [config] learn-rate: 0.0003
[2023-07-01 11:29:03] [config] lemma-dependency: ""
[2023-07-01 11:29:03] [config] lemma-dim-emb: 0
[2023-07-01 11:29:03] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:29:03] [config] log-level: info
[2023-07-01 11:29:03] [config] log-time-zone: ""
[2023-07-01 11:29:03] [config] logical-epoch:
[2023-07-01 11:29:03] [config]   - 1e
[2023-07-01 11:29:03] [config]   - 0
[2023-07-01 11:29:03] [config] lr-decay: 0
[2023-07-01 11:29:03] [config] lr-decay-freq: 50000
[2023-07-01 11:29:03] [config] lr-decay-inv-sqrt:
[2023-07-01 11:29:03] [config]   - 16000
[2023-07-01 11:29:03] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:29:03] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:29:03] [config] lr-decay-start:
[2023-07-01 11:29:03] [config]   - 10
[2023-07-01 11:29:03] [config]   - 1
[2023-07-01 11:29:03] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:29:03] [config] lr-report: true
[2023-07-01 11:29:03] [config] lr-warmup: 16000
[2023-07-01 11:29:03] [config] lr-warmup-at-reload: false
[2023-07-01 11:29:03] [config] lr-warmup-cycle: false
[2023-07-01 11:29:03] [config] lr-warmup-start-rate: 0
[2023-07-01 11:29:03] [config] max-length: 100
[2023-07-01 11:29:03] [config] max-length-crop: false
[2023-07-01 11:29:03] [config] max-length-factor: 3
[2023-07-01 11:29:03] [config] maxi-batch: 100
[2023-07-01 11:29:03] [config] maxi-batch-sort: trg
[2023-07-01 11:29:03] [config] mini-batch: 1000
[2023-07-01 11:29:03] [config] mini-batch-fit: true
[2023-07-01 11:29:03] [config] mini-batch-fit-step: 10
[2023-07-01 11:29:03] [config] mini-batch-round-up: true
[2023-07-01 11:29:03] [config] mini-batch-track-lr: false
[2023-07-01 11:29:03] [config] mini-batch-warmup: 0
[2023-07-01 11:29:03] [config] mini-batch-words: 0
[2023-07-01 11:29:03] [config] mini-batch-words-ref: 0
[2023-07-01 11:29:03] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:29:03] [config] multi-loss-type: sum
[2023-07-01 11:29:03] [config] n-best: false
[2023-07-01 11:29:03] [config] no-nccl: false
[2023-07-01 11:29:03] [config] no-reload: false
[2023-07-01 11:29:03] [config] no-restore-corpus: false
[2023-07-01 11:29:03] [config] normalize: 1
[2023-07-01 11:29:03] [config] normalize-gradient: false
[2023-07-01 11:29:03] [config] num-devices: 0
[2023-07-01 11:29:03] [config] optimizer: adam
[2023-07-01 11:29:03] [config] optimizer-delay: 1
[2023-07-01 11:29:03] [config] optimizer-params:
[2023-07-01 11:29:03] [config]   - 0.9
[2023-07-01 11:29:03] [config]   - 0.98
[2023-07-01 11:29:03] [config]   - 1e-09
[2023-07-01 11:29:03] [config] output-omit-bias: false
[2023-07-01 11:29:03] [config] overwrite: true
[2023-07-01 11:29:03] [config] precision:
[2023-07-01 11:29:03] [config]   - float32
[2023-07-01 11:29:03] [config]   - float32
[2023-07-01 11:29:03] [config] pretrained-model: ""
[2023-07-01 11:29:03] [config] quantize-biases: false
[2023-07-01 11:29:03] [config] quantize-bits: 0
[2023-07-01 11:29:03] [config] quantize-log-based: false
[2023-07-01 11:29:03] [config] quantize-optimization-steps: 0
[2023-07-01 11:29:03] [config] quiet: false
[2023-07-01 11:29:03] [config] quiet-translation: true
[2023-07-01 11:29:03] [config] relative-paths: false
[2023-07-01 11:29:03] [config] right-left: false
[2023-07-01 11:29:03] [config] save-freq: 10000u
[2023-07-01 11:29:03] [config] seed: 1234
[2023-07-01 11:29:03] [config] sentencepiece-alphas:
[2023-07-01 11:29:03] [config]   []
[2023-07-01 11:29:03] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:29:03] [config] sentencepiece-options: ""
[2023-07-01 11:29:03] [config] sharding: global
[2023-07-01 11:29:03] [config] shuffle: data
[2023-07-01 11:29:03] [config] shuffle-in-ram: false
[2023-07-01 11:29:03] [config] sigterm: save-and-exit
[2023-07-01 11:29:03] [config] skip: false
[2023-07-01 11:29:03] [config] sqlite: ""
[2023-07-01 11:29:03] [config] sqlite-drop: false
[2023-07-01 11:29:03] [config] sync-freq: 200u
[2023-07-01 11:29:03] [config] sync-sgd: true
[2023-07-01 11:29:03] [config] tempdir: /tmp
[2023-07-01 11:29:03] [config] tied-embeddings: false
[2023-07-01 11:29:03] [config] tied-embeddings-all: true
[2023-07-01 11:29:03] [config] tied-embeddings-src: false
[2023-07-01 11:29:03] [config] train-embedder-rank:
[2023-07-01 11:29:03] [config]   []
[2023-07-01 11:29:03] [config] train-sets:
[2023-07-01 11:29:03] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:29:03] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:29:03] [config] transformer-aan-activation: swish
[2023-07-01 11:29:03] [config] transformer-aan-depth: 2
[2023-07-01 11:29:03] [config] transformer-aan-nogate: false
[2023-07-01 11:29:03] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:29:03] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:29:03] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:29:03] [config] transformer-depth-scaling: false
[2023-07-01 11:29:03] [config] transformer-dim-aan: 2048
[2023-07-01 11:29:03] [config] transformer-dim-ffn: 2048
[2023-07-01 11:29:03] [config] transformer-dropout: 0.1
[2023-07-01 11:29:03] [config] transformer-dropout-attention: 0
[2023-07-01 11:29:03] [config] transformer-dropout-ffn: 0
[2023-07-01 11:29:03] [config] transformer-ffn-activation: swish
[2023-07-01 11:29:03] [config] transformer-ffn-depth: 2
[2023-07-01 11:29:03] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:29:03] [config] transformer-heads: 8
[2023-07-01 11:29:03] [config] transformer-no-projection: false
[2023-07-01 11:29:03] [config] transformer-pool: false
[2023-07-01 11:29:03] [config] transformer-postprocess: dan
[2023-07-01 11:29:03] [config] transformer-postprocess-emb: d
[2023-07-01 11:29:03] [config] transformer-postprocess-top: ""
[2023-07-01 11:29:03] [config] transformer-preprocess: ""
[2023-07-01 11:29:03] [config] transformer-tied-layers:
[2023-07-01 11:29:03] [config]   []
[2023-07-01 11:29:03] [config] transformer-train-position-embeddings: false
[2023-07-01 11:29:03] [config] tsv: false
[2023-07-01 11:29:03] [config] tsv-fields: 0
[2023-07-01 11:29:03] [config] type: transformer
[2023-07-01 11:29:03] [config] ulr: false
[2023-07-01 11:29:03] [config] ulr-dim-emb: 0
[2023-07-01 11:29:03] [config] ulr-dropout: 0
[2023-07-01 11:29:03] [config] ulr-keys-vectors: ""
[2023-07-01 11:29:03] [config] ulr-query-vectors: ""
[2023-07-01 11:29:03] [config] ulr-softmax-temperature: 1
[2023-07-01 11:29:03] [config] ulr-trainable-transformation: false
[2023-07-01 11:29:03] [config] unlikelihood-loss: false
[2023-07-01 11:29:03] [config] valid-freq: 50000000
[2023-07-01 11:29:03] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:29:03] [config] valid-max-length: 1000
[2023-07-01 11:29:03] [config] valid-metrics:
[2023-07-01 11:29:03] [config]   - cross-entropy
[2023-07-01 11:29:03] [config]   - translation
[2023-07-01 11:29:03] [config] valid-mini-batch: 64
[2023-07-01 11:29:03] [config] valid-reset-stalled: false
[2023-07-01 11:29:03] [config] valid-script-args:
[2023-07-01 11:29:03] [config]   []
[2023-07-01 11:29:03] [config] valid-script-path: ""
[2023-07-01 11:29:03] [config] valid-sets:
[2023-07-01 11:29:03] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:29:03] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:29:03] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:29:03] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:29:03] [config] vocabs:
[2023-07-01 11:29:03] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:29:03] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:29:03] [config] word-penalty: 0
[2023-07-01 11:29:03] [config] word-scores: false
[2023-07-01 11:29:03] [config] workspace: 2048
[2023-07-01 11:29:03] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:29:03] Using synchronous SGD
[2023-07-01 11:29:03] Synced seed 1234
[2023-07-01 11:29:03] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:29:03] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:29:03] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:29:03] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:29:03] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:29:03] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:29:04] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:29:04] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:29:04] [comm] Using global sharding
[2023-07-01 11:29:04] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:29:04] [training] Using 1 GPUs
[2023-07-01 11:29:04] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:29:04] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:29:04] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:29:04] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:29:12] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:29:12] [valid] No post-processing script given for validating translator
[2023-07-01 11:29:12] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:29:12] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:29:12] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:29:12] [comm] Using global sharding
[2023-07-01 11:29:12] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:29:12] [training] Using 1 GPUs
[2023-07-01 11:29:12] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:29:12] Allocating memory for general optimizer shards
[2023-07-01 11:29:12] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:29:13] Loading Adam parameters
[2023-07-01 11:29:13] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:29:13] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:29:13] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:29:13] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:29:13] [data] Shuffling data
[2023-07-01 11:29:13] [data] Done reading 20,192 sentences
[2023-07-01 11:29:13] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:29:13] Training started
[2023-07-01 11:29:13] Training finished
[2023-07-01 11:29:16] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:29:16] [marian] Running on node20.datos.cluster.uy as process 16391 with command line:
[2023-07-01 11:29:16] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 90 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:29:16] [config] after: 0e
[2023-07-01 11:29:16] [config] after-batches: 0
[2023-07-01 11:29:16] [config] after-epochs: 90
[2023-07-01 11:29:16] [config] all-caps-every: 0
[2023-07-01 11:29:16] [config] allow-unk: false
[2023-07-01 11:29:16] [config] authors: false
[2023-07-01 11:29:16] [config] beam-size: 12
[2023-07-01 11:29:16] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:29:16] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:29:16] [config] bert-masking-fraction: 0.15
[2023-07-01 11:29:16] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:29:16] [config] bert-train-type-embeddings: true
[2023-07-01 11:29:16] [config] bert-type-vocab-size: 2
[2023-07-01 11:29:16] [config] build-info: ""
[2023-07-01 11:29:16] [config] check-gradient-nan: false
[2023-07-01 11:29:16] [config] check-nan: false
[2023-07-01 11:29:16] [config] cite: false
[2023-07-01 11:29:16] [config] clip-norm: 5
[2023-07-01 11:29:16] [config] cost-scaling:
[2023-07-01 11:29:16] [config]   []
[2023-07-01 11:29:16] [config] cost-type: ce-sum
[2023-07-01 11:29:16] [config] cpu-threads: 0
[2023-07-01 11:29:16] [config] data-threads: 8
[2023-07-01 11:29:16] [config] data-weighting: ""
[2023-07-01 11:29:16] [config] data-weighting-type: sentence
[2023-07-01 11:29:16] [config] dec-cell: gru
[2023-07-01 11:29:16] [config] dec-cell-base-depth: 2
[2023-07-01 11:29:16] [config] dec-cell-high-depth: 1
[2023-07-01 11:29:16] [config] dec-depth: 2
[2023-07-01 11:29:16] [config] devices:
[2023-07-01 11:29:16] [config]   - 0
[2023-07-01 11:29:16] [config] dim-emb: 512
[2023-07-01 11:29:16] [config] dim-rnn: 1024
[2023-07-01 11:29:16] [config] dim-vocabs:
[2023-07-01 11:29:16] [config]   - 16384
[2023-07-01 11:29:16] [config]   - 16384
[2023-07-01 11:29:16] [config] disp-first: 0
[2023-07-01 11:29:16] [config] disp-freq: 1000u
[2023-07-01 11:29:16] [config] disp-label-counts: true
[2023-07-01 11:29:16] [config] dropout-rnn: 0
[2023-07-01 11:29:16] [config] dropout-src: 0
[2023-07-01 11:29:16] [config] dropout-trg: 0
[2023-07-01 11:29:16] [config] dump-config: ""
[2023-07-01 11:29:16] [config] dynamic-gradient-scaling:
[2023-07-01 11:29:16] [config]   []
[2023-07-01 11:29:16] [config] early-stopping: 10
[2023-07-01 11:29:16] [config] early-stopping-on: first
[2023-07-01 11:29:16] [config] embedding-fix-src: false
[2023-07-01 11:29:16] [config] embedding-fix-trg: false
[2023-07-01 11:29:16] [config] embedding-normalization: false
[2023-07-01 11:29:16] [config] embedding-vectors:
[2023-07-01 11:29:16] [config]   []
[2023-07-01 11:29:16] [config] enc-cell: gru
[2023-07-01 11:29:16] [config] enc-cell-depth: 1
[2023-07-01 11:29:16] [config] enc-depth: 2
[2023-07-01 11:29:16] [config] enc-type: bidirectional
[2023-07-01 11:29:16] [config] english-title-case-every: 0
[2023-07-01 11:29:16] [config] exponential-smoothing: 0.0001
[2023-07-01 11:29:16] [config] factor-weight: 1
[2023-07-01 11:29:16] [config] factors-combine: sum
[2023-07-01 11:29:16] [config] factors-dim-emb: 0
[2023-07-01 11:29:16] [config] gradient-checkpointing: false
[2023-07-01 11:29:16] [config] gradient-norm-average-window: 100
[2023-07-01 11:29:16] [config] guided-alignment: none
[2023-07-01 11:29:16] [config] guided-alignment-cost: mse
[2023-07-01 11:29:16] [config] guided-alignment-weight: 0.1
[2023-07-01 11:29:16] [config] ignore-model-config: false
[2023-07-01 11:29:16] [config] input-types:
[2023-07-01 11:29:16] [config]   []
[2023-07-01 11:29:16] [config] interpolate-env-vars: false
[2023-07-01 11:29:16] [config] keep-best: false
[2023-07-01 11:29:16] [config] label-smoothing: 0.1
[2023-07-01 11:29:16] [config] layer-normalization: false
[2023-07-01 11:29:16] [config] learn-rate: 0.0003
[2023-07-01 11:29:16] [config] lemma-dependency: ""
[2023-07-01 11:29:16] [config] lemma-dim-emb: 0
[2023-07-01 11:29:16] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:29:16] [config] log-level: info
[2023-07-01 11:29:16] [config] log-time-zone: ""
[2023-07-01 11:29:16] [config] logical-epoch:
[2023-07-01 11:29:16] [config]   - 1e
[2023-07-01 11:29:16] [config]   - 0
[2023-07-01 11:29:16] [config] lr-decay: 0
[2023-07-01 11:29:16] [config] lr-decay-freq: 50000
[2023-07-01 11:29:16] [config] lr-decay-inv-sqrt:
[2023-07-01 11:29:16] [config]   - 16000
[2023-07-01 11:29:16] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:29:16] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:29:16] [config] lr-decay-start:
[2023-07-01 11:29:16] [config]   - 10
[2023-07-01 11:29:16] [config]   - 1
[2023-07-01 11:29:16] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:29:16] [config] lr-report: true
[2023-07-01 11:29:16] [config] lr-warmup: 16000
[2023-07-01 11:29:16] [config] lr-warmup-at-reload: false
[2023-07-01 11:29:16] [config] lr-warmup-cycle: false
[2023-07-01 11:29:16] [config] lr-warmup-start-rate: 0
[2023-07-01 11:29:16] [config] max-length: 100
[2023-07-01 11:29:16] [config] max-length-crop: false
[2023-07-01 11:29:16] [config] max-length-factor: 3
[2023-07-01 11:29:16] [config] maxi-batch: 100
[2023-07-01 11:29:16] [config] maxi-batch-sort: trg
[2023-07-01 11:29:16] [config] mini-batch: 1000
[2023-07-01 11:29:16] [config] mini-batch-fit: true
[2023-07-01 11:29:16] [config] mini-batch-fit-step: 10
[2023-07-01 11:29:16] [config] mini-batch-round-up: true
[2023-07-01 11:29:16] [config] mini-batch-track-lr: false
[2023-07-01 11:29:16] [config] mini-batch-warmup: 0
[2023-07-01 11:29:16] [config] mini-batch-words: 0
[2023-07-01 11:29:16] [config] mini-batch-words-ref: 0
[2023-07-01 11:29:16] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:29:16] [config] multi-loss-type: sum
[2023-07-01 11:29:16] [config] n-best: false
[2023-07-01 11:29:16] [config] no-nccl: false
[2023-07-01 11:29:16] [config] no-reload: false
[2023-07-01 11:29:16] [config] no-restore-corpus: false
[2023-07-01 11:29:16] [config] normalize: 1
[2023-07-01 11:29:16] [config] normalize-gradient: false
[2023-07-01 11:29:16] [config] num-devices: 0
[2023-07-01 11:29:16] [config] optimizer: adam
[2023-07-01 11:29:16] [config] optimizer-delay: 1
[2023-07-01 11:29:16] [config] optimizer-params:
[2023-07-01 11:29:16] [config]   - 0.9
[2023-07-01 11:29:16] [config]   - 0.98
[2023-07-01 11:29:16] [config]   - 1e-09
[2023-07-01 11:29:16] [config] output-omit-bias: false
[2023-07-01 11:29:16] [config] overwrite: true
[2023-07-01 11:29:16] [config] precision:
[2023-07-01 11:29:16] [config]   - float32
[2023-07-01 11:29:16] [config]   - float32
[2023-07-01 11:29:16] [config] pretrained-model: ""
[2023-07-01 11:29:16] [config] quantize-biases: false
[2023-07-01 11:29:16] [config] quantize-bits: 0
[2023-07-01 11:29:16] [config] quantize-log-based: false
[2023-07-01 11:29:16] [config] quantize-optimization-steps: 0
[2023-07-01 11:29:16] [config] quiet: false
[2023-07-01 11:29:16] [config] quiet-translation: true
[2023-07-01 11:29:16] [config] relative-paths: false
[2023-07-01 11:29:16] [config] right-left: false
[2023-07-01 11:29:16] [config] save-freq: 10000u
[2023-07-01 11:29:16] [config] seed: 1234
[2023-07-01 11:29:16] [config] sentencepiece-alphas:
[2023-07-01 11:29:16] [config]   []
[2023-07-01 11:29:16] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:29:16] [config] sentencepiece-options: ""
[2023-07-01 11:29:16] [config] sharding: global
[2023-07-01 11:29:16] [config] shuffle: data
[2023-07-01 11:29:16] [config] shuffle-in-ram: false
[2023-07-01 11:29:16] [config] sigterm: save-and-exit
[2023-07-01 11:29:16] [config] skip: false
[2023-07-01 11:29:16] [config] sqlite: ""
[2023-07-01 11:29:16] [config] sqlite-drop: false
[2023-07-01 11:29:16] [config] sync-freq: 200u
[2023-07-01 11:29:16] [config] sync-sgd: true
[2023-07-01 11:29:16] [config] tempdir: /tmp
[2023-07-01 11:29:16] [config] tied-embeddings: false
[2023-07-01 11:29:16] [config] tied-embeddings-all: true
[2023-07-01 11:29:16] [config] tied-embeddings-src: false
[2023-07-01 11:29:16] [config] train-embedder-rank:
[2023-07-01 11:29:16] [config]   []
[2023-07-01 11:29:16] [config] train-sets:
[2023-07-01 11:29:16] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:29:16] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:29:16] [config] transformer-aan-activation: swish
[2023-07-01 11:29:16] [config] transformer-aan-depth: 2
[2023-07-01 11:29:16] [config] transformer-aan-nogate: false
[2023-07-01 11:29:16] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:29:16] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:29:16] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:29:16] [config] transformer-depth-scaling: false
[2023-07-01 11:29:16] [config] transformer-dim-aan: 2048
[2023-07-01 11:29:16] [config] transformer-dim-ffn: 2048
[2023-07-01 11:29:16] [config] transformer-dropout: 0.1
[2023-07-01 11:29:16] [config] transformer-dropout-attention: 0
[2023-07-01 11:29:16] [config] transformer-dropout-ffn: 0
[2023-07-01 11:29:16] [config] transformer-ffn-activation: swish
[2023-07-01 11:29:16] [config] transformer-ffn-depth: 2
[2023-07-01 11:29:16] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:29:16] [config] transformer-heads: 8
[2023-07-01 11:29:16] [config] transformer-no-projection: false
[2023-07-01 11:29:16] [config] transformer-pool: false
[2023-07-01 11:29:16] [config] transformer-postprocess: dan
[2023-07-01 11:29:16] [config] transformer-postprocess-emb: d
[2023-07-01 11:29:16] [config] transformer-postprocess-top: ""
[2023-07-01 11:29:16] [config] transformer-preprocess: ""
[2023-07-01 11:29:16] [config] transformer-tied-layers:
[2023-07-01 11:29:16] [config]   []
[2023-07-01 11:29:16] [config] transformer-train-position-embeddings: false
[2023-07-01 11:29:16] [config] tsv: false
[2023-07-01 11:29:16] [config] tsv-fields: 0
[2023-07-01 11:29:16] [config] type: transformer
[2023-07-01 11:29:16] [config] ulr: false
[2023-07-01 11:29:16] [config] ulr-dim-emb: 0
[2023-07-01 11:29:16] [config] ulr-dropout: 0
[2023-07-01 11:29:16] [config] ulr-keys-vectors: ""
[2023-07-01 11:29:16] [config] ulr-query-vectors: ""
[2023-07-01 11:29:16] [config] ulr-softmax-temperature: 1
[2023-07-01 11:29:16] [config] ulr-trainable-transformation: false
[2023-07-01 11:29:16] [config] unlikelihood-loss: false
[2023-07-01 11:29:16] [config] valid-freq: 50000000
[2023-07-01 11:29:16] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:29:16] [config] valid-max-length: 1000
[2023-07-01 11:29:16] [config] valid-metrics:
[2023-07-01 11:29:16] [config]   - cross-entropy
[2023-07-01 11:29:16] [config]   - translation
[2023-07-01 11:29:16] [config] valid-mini-batch: 64
[2023-07-01 11:29:16] [config] valid-reset-stalled: false
[2023-07-01 11:29:16] [config] valid-script-args:
[2023-07-01 11:29:16] [config]   []
[2023-07-01 11:29:16] [config] valid-script-path: ""
[2023-07-01 11:29:16] [config] valid-sets:
[2023-07-01 11:29:16] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:29:16] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:29:16] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:29:16] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:29:16] [config] vocabs:
[2023-07-01 11:29:16] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:29:16] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:29:16] [config] word-penalty: 0
[2023-07-01 11:29:16] [config] word-scores: false
[2023-07-01 11:29:16] [config] workspace: 2048
[2023-07-01 11:29:16] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:29:16] Using synchronous SGD
[2023-07-01 11:29:17] Synced seed 1234
[2023-07-01 11:29:17] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:29:17] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:29:17] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:29:17] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:29:17] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:29:17] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:29:17] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:29:17] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:29:17] [comm] Using global sharding
[2023-07-01 11:29:17] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:29:17] [training] Using 1 GPUs
[2023-07-01 11:29:17] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:29:17] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:29:18] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:29:18] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:29:25] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:29:25] [valid] No post-processing script given for validating translator
[2023-07-01 11:29:25] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:29:25] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:29:25] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:29:25] [comm] Using global sharding
[2023-07-01 11:29:25] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:29:25] [training] Using 1 GPUs
[2023-07-01 11:29:25] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:29:26] Allocating memory for general optimizer shards
[2023-07-01 11:29:26] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:29:26] Loading Adam parameters
[2023-07-01 11:29:26] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:29:26] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:29:26] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:29:26] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:29:26] [data] Shuffling data
[2023-07-01 11:29:26] [data] Done reading 20,192 sentences
[2023-07-01 11:29:26] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:29:26] Training started
[2023-07-01 11:29:26] Training finished
[2023-07-01 11:29:30] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:29:30] [marian] Running on node20.datos.cluster.uy as process 16449 with command line:
[2023-07-01 11:29:30] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 91 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:29:30] [config] after: 0e
[2023-07-01 11:29:30] [config] after-batches: 0
[2023-07-01 11:29:30] [config] after-epochs: 91
[2023-07-01 11:29:30] [config] all-caps-every: 0
[2023-07-01 11:29:30] [config] allow-unk: false
[2023-07-01 11:29:30] [config] authors: false
[2023-07-01 11:29:30] [config] beam-size: 12
[2023-07-01 11:29:30] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:29:30] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:29:30] [config] bert-masking-fraction: 0.15
[2023-07-01 11:29:30] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:29:30] [config] bert-train-type-embeddings: true
[2023-07-01 11:29:30] [config] bert-type-vocab-size: 2
[2023-07-01 11:29:30] [config] build-info: ""
[2023-07-01 11:29:30] [config] check-gradient-nan: false
[2023-07-01 11:29:30] [config] check-nan: false
[2023-07-01 11:29:30] [config] cite: false
[2023-07-01 11:29:30] [config] clip-norm: 5
[2023-07-01 11:29:30] [config] cost-scaling:
[2023-07-01 11:29:30] [config]   []
[2023-07-01 11:29:30] [config] cost-type: ce-sum
[2023-07-01 11:29:30] [config] cpu-threads: 0
[2023-07-01 11:29:30] [config] data-threads: 8
[2023-07-01 11:29:30] [config] data-weighting: ""
[2023-07-01 11:29:30] [config] data-weighting-type: sentence
[2023-07-01 11:29:30] [config] dec-cell: gru
[2023-07-01 11:29:30] [config] dec-cell-base-depth: 2
[2023-07-01 11:29:30] [config] dec-cell-high-depth: 1
[2023-07-01 11:29:30] [config] dec-depth: 2
[2023-07-01 11:29:30] [config] devices:
[2023-07-01 11:29:30] [config]   - 0
[2023-07-01 11:29:30] [config] dim-emb: 512
[2023-07-01 11:29:30] [config] dim-rnn: 1024
[2023-07-01 11:29:30] [config] dim-vocabs:
[2023-07-01 11:29:30] [config]   - 16384
[2023-07-01 11:29:30] [config]   - 16384
[2023-07-01 11:29:30] [config] disp-first: 0
[2023-07-01 11:29:30] [config] disp-freq: 1000u
[2023-07-01 11:29:30] [config] disp-label-counts: true
[2023-07-01 11:29:30] [config] dropout-rnn: 0
[2023-07-01 11:29:30] [config] dropout-src: 0
[2023-07-01 11:29:30] [config] dropout-trg: 0
[2023-07-01 11:29:30] [config] dump-config: ""
[2023-07-01 11:29:30] [config] dynamic-gradient-scaling:
[2023-07-01 11:29:30] [config]   []
[2023-07-01 11:29:30] [config] early-stopping: 10
[2023-07-01 11:29:30] [config] early-stopping-on: first
[2023-07-01 11:29:30] [config] embedding-fix-src: false
[2023-07-01 11:29:30] [config] embedding-fix-trg: false
[2023-07-01 11:29:30] [config] embedding-normalization: false
[2023-07-01 11:29:30] [config] embedding-vectors:
[2023-07-01 11:29:30] [config]   []
[2023-07-01 11:29:30] [config] enc-cell: gru
[2023-07-01 11:29:30] [config] enc-cell-depth: 1
[2023-07-01 11:29:30] [config] enc-depth: 2
[2023-07-01 11:29:30] [config] enc-type: bidirectional
[2023-07-01 11:29:30] [config] english-title-case-every: 0
[2023-07-01 11:29:30] [config] exponential-smoothing: 0.0001
[2023-07-01 11:29:30] [config] factor-weight: 1
[2023-07-01 11:29:30] [config] factors-combine: sum
[2023-07-01 11:29:30] [config] factors-dim-emb: 0
[2023-07-01 11:29:30] [config] gradient-checkpointing: false
[2023-07-01 11:29:30] [config] gradient-norm-average-window: 100
[2023-07-01 11:29:30] [config] guided-alignment: none
[2023-07-01 11:29:30] [config] guided-alignment-cost: mse
[2023-07-01 11:29:30] [config] guided-alignment-weight: 0.1
[2023-07-01 11:29:30] [config] ignore-model-config: false
[2023-07-01 11:29:30] [config] input-types:
[2023-07-01 11:29:30] [config]   []
[2023-07-01 11:29:30] [config] interpolate-env-vars: false
[2023-07-01 11:29:30] [config] keep-best: false
[2023-07-01 11:29:30] [config] label-smoothing: 0.1
[2023-07-01 11:29:30] [config] layer-normalization: false
[2023-07-01 11:29:30] [config] learn-rate: 0.0003
[2023-07-01 11:29:30] [config] lemma-dependency: ""
[2023-07-01 11:29:30] [config] lemma-dim-emb: 0
[2023-07-01 11:29:30] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:29:30] [config] log-level: info
[2023-07-01 11:29:30] [config] log-time-zone: ""
[2023-07-01 11:29:30] [config] logical-epoch:
[2023-07-01 11:29:30] [config]   - 1e
[2023-07-01 11:29:30] [config]   - 0
[2023-07-01 11:29:30] [config] lr-decay: 0
[2023-07-01 11:29:30] [config] lr-decay-freq: 50000
[2023-07-01 11:29:30] [config] lr-decay-inv-sqrt:
[2023-07-01 11:29:30] [config]   - 16000
[2023-07-01 11:29:30] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:29:30] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:29:30] [config] lr-decay-start:
[2023-07-01 11:29:30] [config]   - 10
[2023-07-01 11:29:30] [config]   - 1
[2023-07-01 11:29:30] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:29:30] [config] lr-report: true
[2023-07-01 11:29:30] [config] lr-warmup: 16000
[2023-07-01 11:29:30] [config] lr-warmup-at-reload: false
[2023-07-01 11:29:30] [config] lr-warmup-cycle: false
[2023-07-01 11:29:30] [config] lr-warmup-start-rate: 0
[2023-07-01 11:29:30] [config] max-length: 100
[2023-07-01 11:29:30] [config] max-length-crop: false
[2023-07-01 11:29:30] [config] max-length-factor: 3
[2023-07-01 11:29:30] [config] maxi-batch: 100
[2023-07-01 11:29:30] [config] maxi-batch-sort: trg
[2023-07-01 11:29:30] [config] mini-batch: 1000
[2023-07-01 11:29:30] [config] mini-batch-fit: true
[2023-07-01 11:29:30] [config] mini-batch-fit-step: 10
[2023-07-01 11:29:30] [config] mini-batch-round-up: true
[2023-07-01 11:29:30] [config] mini-batch-track-lr: false
[2023-07-01 11:29:30] [config] mini-batch-warmup: 0
[2023-07-01 11:29:30] [config] mini-batch-words: 0
[2023-07-01 11:29:30] [config] mini-batch-words-ref: 0
[2023-07-01 11:29:30] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:29:30] [config] multi-loss-type: sum
[2023-07-01 11:29:30] [config] n-best: false
[2023-07-01 11:29:30] [config] no-nccl: false
[2023-07-01 11:29:30] [config] no-reload: false
[2023-07-01 11:29:30] [config] no-restore-corpus: false
[2023-07-01 11:29:30] [config] normalize: 1
[2023-07-01 11:29:30] [config] normalize-gradient: false
[2023-07-01 11:29:30] [config] num-devices: 0
[2023-07-01 11:29:30] [config] optimizer: adam
[2023-07-01 11:29:30] [config] optimizer-delay: 1
[2023-07-01 11:29:30] [config] optimizer-params:
[2023-07-01 11:29:30] [config]   - 0.9
[2023-07-01 11:29:30] [config]   - 0.98
[2023-07-01 11:29:30] [config]   - 1e-09
[2023-07-01 11:29:30] [config] output-omit-bias: false
[2023-07-01 11:29:30] [config] overwrite: true
[2023-07-01 11:29:30] [config] precision:
[2023-07-01 11:29:30] [config]   - float32
[2023-07-01 11:29:30] [config]   - float32
[2023-07-01 11:29:30] [config] pretrained-model: ""
[2023-07-01 11:29:30] [config] quantize-biases: false
[2023-07-01 11:29:30] [config] quantize-bits: 0
[2023-07-01 11:29:30] [config] quantize-log-based: false
[2023-07-01 11:29:30] [config] quantize-optimization-steps: 0
[2023-07-01 11:29:30] [config] quiet: false
[2023-07-01 11:29:30] [config] quiet-translation: true
[2023-07-01 11:29:30] [config] relative-paths: false
[2023-07-01 11:29:30] [config] right-left: false
[2023-07-01 11:29:30] [config] save-freq: 10000u
[2023-07-01 11:29:30] [config] seed: 1234
[2023-07-01 11:29:30] [config] sentencepiece-alphas:
[2023-07-01 11:29:30] [config]   []
[2023-07-01 11:29:30] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:29:30] [config] sentencepiece-options: ""
[2023-07-01 11:29:30] [config] sharding: global
[2023-07-01 11:29:30] [config] shuffle: data
[2023-07-01 11:29:30] [config] shuffle-in-ram: false
[2023-07-01 11:29:30] [config] sigterm: save-and-exit
[2023-07-01 11:29:30] [config] skip: false
[2023-07-01 11:29:30] [config] sqlite: ""
[2023-07-01 11:29:30] [config] sqlite-drop: false
[2023-07-01 11:29:30] [config] sync-freq: 200u
[2023-07-01 11:29:30] [config] sync-sgd: true
[2023-07-01 11:29:30] [config] tempdir: /tmp
[2023-07-01 11:29:30] [config] tied-embeddings: false
[2023-07-01 11:29:30] [config] tied-embeddings-all: true
[2023-07-01 11:29:30] [config] tied-embeddings-src: false
[2023-07-01 11:29:30] [config] train-embedder-rank:
[2023-07-01 11:29:30] [config]   []
[2023-07-01 11:29:30] [config] train-sets:
[2023-07-01 11:29:30] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:29:30] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:29:30] [config] transformer-aan-activation: swish
[2023-07-01 11:29:30] [config] transformer-aan-depth: 2
[2023-07-01 11:29:30] [config] transformer-aan-nogate: false
[2023-07-01 11:29:30] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:29:30] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:29:30] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:29:30] [config] transformer-depth-scaling: false
[2023-07-01 11:29:30] [config] transformer-dim-aan: 2048
[2023-07-01 11:29:30] [config] transformer-dim-ffn: 2048
[2023-07-01 11:29:30] [config] transformer-dropout: 0.1
[2023-07-01 11:29:30] [config] transformer-dropout-attention: 0
[2023-07-01 11:29:30] [config] transformer-dropout-ffn: 0
[2023-07-01 11:29:30] [config] transformer-ffn-activation: swish
[2023-07-01 11:29:30] [config] transformer-ffn-depth: 2
[2023-07-01 11:29:30] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:29:30] [config] transformer-heads: 8
[2023-07-01 11:29:30] [config] transformer-no-projection: false
[2023-07-01 11:29:30] [config] transformer-pool: false
[2023-07-01 11:29:30] [config] transformer-postprocess: dan
[2023-07-01 11:29:30] [config] transformer-postprocess-emb: d
[2023-07-01 11:29:30] [config] transformer-postprocess-top: ""
[2023-07-01 11:29:30] [config] transformer-preprocess: ""
[2023-07-01 11:29:30] [config] transformer-tied-layers:
[2023-07-01 11:29:30] [config]   []
[2023-07-01 11:29:30] [config] transformer-train-position-embeddings: false
[2023-07-01 11:29:30] [config] tsv: false
[2023-07-01 11:29:30] [config] tsv-fields: 0
[2023-07-01 11:29:30] [config] type: transformer
[2023-07-01 11:29:30] [config] ulr: false
[2023-07-01 11:29:30] [config] ulr-dim-emb: 0
[2023-07-01 11:29:30] [config] ulr-dropout: 0
[2023-07-01 11:29:30] [config] ulr-keys-vectors: ""
[2023-07-01 11:29:30] [config] ulr-query-vectors: ""
[2023-07-01 11:29:30] [config] ulr-softmax-temperature: 1
[2023-07-01 11:29:30] [config] ulr-trainable-transformation: false
[2023-07-01 11:29:30] [config] unlikelihood-loss: false
[2023-07-01 11:29:30] [config] valid-freq: 50000000
[2023-07-01 11:29:30] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:29:30] [config] valid-max-length: 1000
[2023-07-01 11:29:30] [config] valid-metrics:
[2023-07-01 11:29:30] [config]   - cross-entropy
[2023-07-01 11:29:30] [config]   - translation
[2023-07-01 11:29:30] [config] valid-mini-batch: 64
[2023-07-01 11:29:30] [config] valid-reset-stalled: false
[2023-07-01 11:29:30] [config] valid-script-args:
[2023-07-01 11:29:30] [config]   []
[2023-07-01 11:29:30] [config] valid-script-path: ""
[2023-07-01 11:29:30] [config] valid-sets:
[2023-07-01 11:29:30] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:29:30] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:29:30] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:29:30] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:29:30] [config] vocabs:
[2023-07-01 11:29:30] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:29:30] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:29:30] [config] word-penalty: 0
[2023-07-01 11:29:30] [config] word-scores: false
[2023-07-01 11:29:30] [config] workspace: 2048
[2023-07-01 11:29:30] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:29:30] Using synchronous SGD
[2023-07-01 11:29:30] Synced seed 1234
[2023-07-01 11:29:30] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:29:30] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:29:30] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:29:30] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:29:30] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:29:30] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:29:31] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:29:31] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:29:31] [comm] Using global sharding
[2023-07-01 11:29:31] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:29:31] [training] Using 1 GPUs
[2023-07-01 11:29:31] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:29:31] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:29:31] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:29:31] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:29:39] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:29:39] [valid] No post-processing script given for validating translator
[2023-07-01 11:29:39] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:29:39] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:29:39] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:29:39] [comm] Using global sharding
[2023-07-01 11:29:39] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:29:39] [training] Using 1 GPUs
[2023-07-01 11:29:39] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:29:40] Allocating memory for general optimizer shards
[2023-07-01 11:29:40] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:29:40] Loading Adam parameters
[2023-07-01 11:29:40] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:29:40] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:29:40] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:29:40] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:29:40] [data] Shuffling data
[2023-07-01 11:29:40] [data] Done reading 20,192 sentences
[2023-07-01 11:29:40] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:29:40] Training started
[2023-07-01 11:29:40] Training finished
[2023-07-01 11:29:44] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:29:44] [marian] Running on node20.datos.cluster.uy as process 16508 with command line:
[2023-07-01 11:29:44] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 92 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:29:44] [config] after: 0e
[2023-07-01 11:29:44] [config] after-batches: 0
[2023-07-01 11:29:44] [config] after-epochs: 92
[2023-07-01 11:29:44] [config] all-caps-every: 0
[2023-07-01 11:29:44] [config] allow-unk: false
[2023-07-01 11:29:44] [config] authors: false
[2023-07-01 11:29:44] [config] beam-size: 12
[2023-07-01 11:29:44] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:29:44] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:29:44] [config] bert-masking-fraction: 0.15
[2023-07-01 11:29:44] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:29:44] [config] bert-train-type-embeddings: true
[2023-07-01 11:29:44] [config] bert-type-vocab-size: 2
[2023-07-01 11:29:44] [config] build-info: ""
[2023-07-01 11:29:44] [config] check-gradient-nan: false
[2023-07-01 11:29:44] [config] check-nan: false
[2023-07-01 11:29:44] [config] cite: false
[2023-07-01 11:29:44] [config] clip-norm: 5
[2023-07-01 11:29:44] [config] cost-scaling:
[2023-07-01 11:29:44] [config]   []
[2023-07-01 11:29:44] [config] cost-type: ce-sum
[2023-07-01 11:29:44] [config] cpu-threads: 0
[2023-07-01 11:29:44] [config] data-threads: 8
[2023-07-01 11:29:44] [config] data-weighting: ""
[2023-07-01 11:29:44] [config] data-weighting-type: sentence
[2023-07-01 11:29:44] [config] dec-cell: gru
[2023-07-01 11:29:44] [config] dec-cell-base-depth: 2
[2023-07-01 11:29:44] [config] dec-cell-high-depth: 1
[2023-07-01 11:29:44] [config] dec-depth: 2
[2023-07-01 11:29:44] [config] devices:
[2023-07-01 11:29:44] [config]   - 0
[2023-07-01 11:29:44] [config] dim-emb: 512
[2023-07-01 11:29:44] [config] dim-rnn: 1024
[2023-07-01 11:29:44] [config] dim-vocabs:
[2023-07-01 11:29:44] [config]   - 16384
[2023-07-01 11:29:44] [config]   - 16384
[2023-07-01 11:29:44] [config] disp-first: 0
[2023-07-01 11:29:44] [config] disp-freq: 1000u
[2023-07-01 11:29:44] [config] disp-label-counts: true
[2023-07-01 11:29:44] [config] dropout-rnn: 0
[2023-07-01 11:29:44] [config] dropout-src: 0
[2023-07-01 11:29:44] [config] dropout-trg: 0
[2023-07-01 11:29:44] [config] dump-config: ""
[2023-07-01 11:29:44] [config] dynamic-gradient-scaling:
[2023-07-01 11:29:44] [config]   []
[2023-07-01 11:29:44] [config] early-stopping: 10
[2023-07-01 11:29:44] [config] early-stopping-on: first
[2023-07-01 11:29:44] [config] embedding-fix-src: false
[2023-07-01 11:29:44] [config] embedding-fix-trg: false
[2023-07-01 11:29:44] [config] embedding-normalization: false
[2023-07-01 11:29:44] [config] embedding-vectors:
[2023-07-01 11:29:44] [config]   []
[2023-07-01 11:29:44] [config] enc-cell: gru
[2023-07-01 11:29:44] [config] enc-cell-depth: 1
[2023-07-01 11:29:44] [config] enc-depth: 2
[2023-07-01 11:29:44] [config] enc-type: bidirectional
[2023-07-01 11:29:44] [config] english-title-case-every: 0
[2023-07-01 11:29:44] [config] exponential-smoothing: 0.0001
[2023-07-01 11:29:44] [config] factor-weight: 1
[2023-07-01 11:29:44] [config] factors-combine: sum
[2023-07-01 11:29:44] [config] factors-dim-emb: 0
[2023-07-01 11:29:44] [config] gradient-checkpointing: false
[2023-07-01 11:29:44] [config] gradient-norm-average-window: 100
[2023-07-01 11:29:44] [config] guided-alignment: none
[2023-07-01 11:29:44] [config] guided-alignment-cost: mse
[2023-07-01 11:29:44] [config] guided-alignment-weight: 0.1
[2023-07-01 11:29:44] [config] ignore-model-config: false
[2023-07-01 11:29:44] [config] input-types:
[2023-07-01 11:29:44] [config]   []
[2023-07-01 11:29:44] [config] interpolate-env-vars: false
[2023-07-01 11:29:44] [config] keep-best: false
[2023-07-01 11:29:44] [config] label-smoothing: 0.1
[2023-07-01 11:29:44] [config] layer-normalization: false
[2023-07-01 11:29:44] [config] learn-rate: 0.0003
[2023-07-01 11:29:44] [config] lemma-dependency: ""
[2023-07-01 11:29:44] [config] lemma-dim-emb: 0
[2023-07-01 11:29:44] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:29:44] [config] log-level: info
[2023-07-01 11:29:44] [config] log-time-zone: ""
[2023-07-01 11:29:44] [config] logical-epoch:
[2023-07-01 11:29:44] [config]   - 1e
[2023-07-01 11:29:44] [config]   - 0
[2023-07-01 11:29:44] [config] lr-decay: 0
[2023-07-01 11:29:44] [config] lr-decay-freq: 50000
[2023-07-01 11:29:44] [config] lr-decay-inv-sqrt:
[2023-07-01 11:29:44] [config]   - 16000
[2023-07-01 11:29:44] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:29:44] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:29:44] [config] lr-decay-start:
[2023-07-01 11:29:44] [config]   - 10
[2023-07-01 11:29:44] [config]   - 1
[2023-07-01 11:29:44] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:29:44] [config] lr-report: true
[2023-07-01 11:29:44] [config] lr-warmup: 16000
[2023-07-01 11:29:44] [config] lr-warmup-at-reload: false
[2023-07-01 11:29:44] [config] lr-warmup-cycle: false
[2023-07-01 11:29:44] [config] lr-warmup-start-rate: 0
[2023-07-01 11:29:44] [config] max-length: 100
[2023-07-01 11:29:44] [config] max-length-crop: false
[2023-07-01 11:29:44] [config] max-length-factor: 3
[2023-07-01 11:29:44] [config] maxi-batch: 100
[2023-07-01 11:29:44] [config] maxi-batch-sort: trg
[2023-07-01 11:29:44] [config] mini-batch: 1000
[2023-07-01 11:29:44] [config] mini-batch-fit: true
[2023-07-01 11:29:44] [config] mini-batch-fit-step: 10
[2023-07-01 11:29:44] [config] mini-batch-round-up: true
[2023-07-01 11:29:44] [config] mini-batch-track-lr: false
[2023-07-01 11:29:44] [config] mini-batch-warmup: 0
[2023-07-01 11:29:44] [config] mini-batch-words: 0
[2023-07-01 11:29:44] [config] mini-batch-words-ref: 0
[2023-07-01 11:29:44] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:29:44] [config] multi-loss-type: sum
[2023-07-01 11:29:44] [config] n-best: false
[2023-07-01 11:29:44] [config] no-nccl: false
[2023-07-01 11:29:44] [config] no-reload: false
[2023-07-01 11:29:44] [config] no-restore-corpus: false
[2023-07-01 11:29:44] [config] normalize: 1
[2023-07-01 11:29:44] [config] normalize-gradient: false
[2023-07-01 11:29:44] [config] num-devices: 0
[2023-07-01 11:29:44] [config] optimizer: adam
[2023-07-01 11:29:44] [config] optimizer-delay: 1
[2023-07-01 11:29:44] [config] optimizer-params:
[2023-07-01 11:29:44] [config]   - 0.9
[2023-07-01 11:29:44] [config]   - 0.98
[2023-07-01 11:29:44] [config]   - 1e-09
[2023-07-01 11:29:44] [config] output-omit-bias: false
[2023-07-01 11:29:44] [config] overwrite: true
[2023-07-01 11:29:44] [config] precision:
[2023-07-01 11:29:44] [config]   - float32
[2023-07-01 11:29:44] [config]   - float32
[2023-07-01 11:29:44] [config] pretrained-model: ""
[2023-07-01 11:29:44] [config] quantize-biases: false
[2023-07-01 11:29:44] [config] quantize-bits: 0
[2023-07-01 11:29:44] [config] quantize-log-based: false
[2023-07-01 11:29:44] [config] quantize-optimization-steps: 0
[2023-07-01 11:29:44] [config] quiet: false
[2023-07-01 11:29:44] [config] quiet-translation: true
[2023-07-01 11:29:44] [config] relative-paths: false
[2023-07-01 11:29:44] [config] right-left: false
[2023-07-01 11:29:44] [config] save-freq: 10000u
[2023-07-01 11:29:44] [config] seed: 1234
[2023-07-01 11:29:44] [config] sentencepiece-alphas:
[2023-07-01 11:29:44] [config]   []
[2023-07-01 11:29:44] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:29:44] [config] sentencepiece-options: ""
[2023-07-01 11:29:44] [config] sharding: global
[2023-07-01 11:29:44] [config] shuffle: data
[2023-07-01 11:29:44] [config] shuffle-in-ram: false
[2023-07-01 11:29:44] [config] sigterm: save-and-exit
[2023-07-01 11:29:44] [config] skip: false
[2023-07-01 11:29:44] [config] sqlite: ""
[2023-07-01 11:29:44] [config] sqlite-drop: false
[2023-07-01 11:29:44] [config] sync-freq: 200u
[2023-07-01 11:29:44] [config] sync-sgd: true
[2023-07-01 11:29:44] [config] tempdir: /tmp
[2023-07-01 11:29:44] [config] tied-embeddings: false
[2023-07-01 11:29:44] [config] tied-embeddings-all: true
[2023-07-01 11:29:44] [config] tied-embeddings-src: false
[2023-07-01 11:29:44] [config] train-embedder-rank:
[2023-07-01 11:29:44] [config]   []
[2023-07-01 11:29:44] [config] train-sets:
[2023-07-01 11:29:44] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:29:44] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:29:44] [config] transformer-aan-activation: swish
[2023-07-01 11:29:44] [config] transformer-aan-depth: 2
[2023-07-01 11:29:44] [config] transformer-aan-nogate: false
[2023-07-01 11:29:44] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:29:44] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:29:44] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:29:44] [config] transformer-depth-scaling: false
[2023-07-01 11:29:44] [config] transformer-dim-aan: 2048
[2023-07-01 11:29:44] [config] transformer-dim-ffn: 2048
[2023-07-01 11:29:44] [config] transformer-dropout: 0.1
[2023-07-01 11:29:44] [config] transformer-dropout-attention: 0
[2023-07-01 11:29:44] [config] transformer-dropout-ffn: 0
[2023-07-01 11:29:44] [config] transformer-ffn-activation: swish
[2023-07-01 11:29:44] [config] transformer-ffn-depth: 2
[2023-07-01 11:29:44] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:29:44] [config] transformer-heads: 8
[2023-07-01 11:29:44] [config] transformer-no-projection: false
[2023-07-01 11:29:44] [config] transformer-pool: false
[2023-07-01 11:29:44] [config] transformer-postprocess: dan
[2023-07-01 11:29:44] [config] transformer-postprocess-emb: d
[2023-07-01 11:29:44] [config] transformer-postprocess-top: ""
[2023-07-01 11:29:44] [config] transformer-preprocess: ""
[2023-07-01 11:29:44] [config] transformer-tied-layers:
[2023-07-01 11:29:44] [config]   []
[2023-07-01 11:29:44] [config] transformer-train-position-embeddings: false
[2023-07-01 11:29:44] [config] tsv: false
[2023-07-01 11:29:44] [config] tsv-fields: 0
[2023-07-01 11:29:44] [config] type: transformer
[2023-07-01 11:29:44] [config] ulr: false
[2023-07-01 11:29:44] [config] ulr-dim-emb: 0
[2023-07-01 11:29:44] [config] ulr-dropout: 0
[2023-07-01 11:29:44] [config] ulr-keys-vectors: ""
[2023-07-01 11:29:44] [config] ulr-query-vectors: ""
[2023-07-01 11:29:44] [config] ulr-softmax-temperature: 1
[2023-07-01 11:29:44] [config] ulr-trainable-transformation: false
[2023-07-01 11:29:44] [config] unlikelihood-loss: false
[2023-07-01 11:29:44] [config] valid-freq: 50000000
[2023-07-01 11:29:44] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:29:44] [config] valid-max-length: 1000
[2023-07-01 11:29:44] [config] valid-metrics:
[2023-07-01 11:29:44] [config]   - cross-entropy
[2023-07-01 11:29:44] [config]   - translation
[2023-07-01 11:29:44] [config] valid-mini-batch: 64
[2023-07-01 11:29:44] [config] valid-reset-stalled: false
[2023-07-01 11:29:44] [config] valid-script-args:
[2023-07-01 11:29:44] [config]   []
[2023-07-01 11:29:44] [config] valid-script-path: ""
[2023-07-01 11:29:44] [config] valid-sets:
[2023-07-01 11:29:44] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:29:44] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:29:44] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:29:44] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:29:44] [config] vocabs:
[2023-07-01 11:29:44] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:29:44] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:29:44] [config] word-penalty: 0
[2023-07-01 11:29:44] [config] word-scores: false
[2023-07-01 11:29:44] [config] workspace: 2048
[2023-07-01 11:29:44] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:29:44] Using synchronous SGD
[2023-07-01 11:29:44] Synced seed 1234
[2023-07-01 11:29:44] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:29:44] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:29:44] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:29:44] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:29:44] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:29:44] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:29:45] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:29:45] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:29:45] [comm] Using global sharding
[2023-07-01 11:29:45] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:29:45] [training] Using 1 GPUs
[2023-07-01 11:29:45] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:29:45] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:29:45] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:29:45] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:29:53] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:29:53] [valid] No post-processing script given for validating translator
[2023-07-01 11:29:53] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:29:53] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:29:53] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:29:53] [comm] Using global sharding
[2023-07-01 11:29:53] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:29:53] [training] Using 1 GPUs
[2023-07-01 11:29:53] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:29:53] Allocating memory for general optimizer shards
[2023-07-01 11:29:53] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:29:53] Loading Adam parameters
[2023-07-01 11:29:53] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:29:53] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:29:53] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:29:53] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:29:53] [data] Shuffling data
[2023-07-01 11:29:53] [data] Done reading 20,192 sentences
[2023-07-01 11:29:53] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:29:53] Training started
[2023-07-01 11:29:53] Training finished
[2023-07-01 11:29:57] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:29:57] [marian] Running on node20.datos.cluster.uy as process 16570 with command line:
[2023-07-01 11:29:57] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 93 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:29:57] [config] after: 0e
[2023-07-01 11:29:57] [config] after-batches: 0
[2023-07-01 11:29:57] [config] after-epochs: 93
[2023-07-01 11:29:57] [config] all-caps-every: 0
[2023-07-01 11:29:57] [config] allow-unk: false
[2023-07-01 11:29:57] [config] authors: false
[2023-07-01 11:29:57] [config] beam-size: 12
[2023-07-01 11:29:57] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:29:57] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:29:57] [config] bert-masking-fraction: 0.15
[2023-07-01 11:29:57] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:29:57] [config] bert-train-type-embeddings: true
[2023-07-01 11:29:57] [config] bert-type-vocab-size: 2
[2023-07-01 11:29:57] [config] build-info: ""
[2023-07-01 11:29:57] [config] check-gradient-nan: false
[2023-07-01 11:29:57] [config] check-nan: false
[2023-07-01 11:29:57] [config] cite: false
[2023-07-01 11:29:57] [config] clip-norm: 5
[2023-07-01 11:29:57] [config] cost-scaling:
[2023-07-01 11:29:57] [config]   []
[2023-07-01 11:29:57] [config] cost-type: ce-sum
[2023-07-01 11:29:57] [config] cpu-threads: 0
[2023-07-01 11:29:57] [config] data-threads: 8
[2023-07-01 11:29:57] [config] data-weighting: ""
[2023-07-01 11:29:57] [config] data-weighting-type: sentence
[2023-07-01 11:29:57] [config] dec-cell: gru
[2023-07-01 11:29:57] [config] dec-cell-base-depth: 2
[2023-07-01 11:29:57] [config] dec-cell-high-depth: 1
[2023-07-01 11:29:57] [config] dec-depth: 2
[2023-07-01 11:29:57] [config] devices:
[2023-07-01 11:29:57] [config]   - 0
[2023-07-01 11:29:57] [config] dim-emb: 512
[2023-07-01 11:29:57] [config] dim-rnn: 1024
[2023-07-01 11:29:57] [config] dim-vocabs:
[2023-07-01 11:29:57] [config]   - 16384
[2023-07-01 11:29:57] [config]   - 16384
[2023-07-01 11:29:57] [config] disp-first: 0
[2023-07-01 11:29:57] [config] disp-freq: 1000u
[2023-07-01 11:29:57] [config] disp-label-counts: true
[2023-07-01 11:29:57] [config] dropout-rnn: 0
[2023-07-01 11:29:57] [config] dropout-src: 0
[2023-07-01 11:29:57] [config] dropout-trg: 0
[2023-07-01 11:29:57] [config] dump-config: ""
[2023-07-01 11:29:57] [config] dynamic-gradient-scaling:
[2023-07-01 11:29:57] [config]   []
[2023-07-01 11:29:57] [config] early-stopping: 10
[2023-07-01 11:29:57] [config] early-stopping-on: first
[2023-07-01 11:29:57] [config] embedding-fix-src: false
[2023-07-01 11:29:57] [config] embedding-fix-trg: false
[2023-07-01 11:29:57] [config] embedding-normalization: false
[2023-07-01 11:29:57] [config] embedding-vectors:
[2023-07-01 11:29:57] [config]   []
[2023-07-01 11:29:57] [config] enc-cell: gru
[2023-07-01 11:29:57] [config] enc-cell-depth: 1
[2023-07-01 11:29:57] [config] enc-depth: 2
[2023-07-01 11:29:57] [config] enc-type: bidirectional
[2023-07-01 11:29:57] [config] english-title-case-every: 0
[2023-07-01 11:29:57] [config] exponential-smoothing: 0.0001
[2023-07-01 11:29:57] [config] factor-weight: 1
[2023-07-01 11:29:57] [config] factors-combine: sum
[2023-07-01 11:29:57] [config] factors-dim-emb: 0
[2023-07-01 11:29:57] [config] gradient-checkpointing: false
[2023-07-01 11:29:57] [config] gradient-norm-average-window: 100
[2023-07-01 11:29:57] [config] guided-alignment: none
[2023-07-01 11:29:57] [config] guided-alignment-cost: mse
[2023-07-01 11:29:57] [config] guided-alignment-weight: 0.1
[2023-07-01 11:29:57] [config] ignore-model-config: false
[2023-07-01 11:29:57] [config] input-types:
[2023-07-01 11:29:57] [config]   []
[2023-07-01 11:29:57] [config] interpolate-env-vars: false
[2023-07-01 11:29:57] [config] keep-best: false
[2023-07-01 11:29:57] [config] label-smoothing: 0.1
[2023-07-01 11:29:57] [config] layer-normalization: false
[2023-07-01 11:29:57] [config] learn-rate: 0.0003
[2023-07-01 11:29:57] [config] lemma-dependency: ""
[2023-07-01 11:29:57] [config] lemma-dim-emb: 0
[2023-07-01 11:29:57] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:29:57] [config] log-level: info
[2023-07-01 11:29:57] [config] log-time-zone: ""
[2023-07-01 11:29:57] [config] logical-epoch:
[2023-07-01 11:29:57] [config]   - 1e
[2023-07-01 11:29:57] [config]   - 0
[2023-07-01 11:29:57] [config] lr-decay: 0
[2023-07-01 11:29:57] [config] lr-decay-freq: 50000
[2023-07-01 11:29:57] [config] lr-decay-inv-sqrt:
[2023-07-01 11:29:57] [config]   - 16000
[2023-07-01 11:29:57] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:29:57] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:29:57] [config] lr-decay-start:
[2023-07-01 11:29:57] [config]   - 10
[2023-07-01 11:29:57] [config]   - 1
[2023-07-01 11:29:57] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:29:57] [config] lr-report: true
[2023-07-01 11:29:57] [config] lr-warmup: 16000
[2023-07-01 11:29:57] [config] lr-warmup-at-reload: false
[2023-07-01 11:29:57] [config] lr-warmup-cycle: false
[2023-07-01 11:29:57] [config] lr-warmup-start-rate: 0
[2023-07-01 11:29:57] [config] max-length: 100
[2023-07-01 11:29:57] [config] max-length-crop: false
[2023-07-01 11:29:57] [config] max-length-factor: 3
[2023-07-01 11:29:57] [config] maxi-batch: 100
[2023-07-01 11:29:57] [config] maxi-batch-sort: trg
[2023-07-01 11:29:57] [config] mini-batch: 1000
[2023-07-01 11:29:57] [config] mini-batch-fit: true
[2023-07-01 11:29:57] [config] mini-batch-fit-step: 10
[2023-07-01 11:29:57] [config] mini-batch-round-up: true
[2023-07-01 11:29:57] [config] mini-batch-track-lr: false
[2023-07-01 11:29:57] [config] mini-batch-warmup: 0
[2023-07-01 11:29:57] [config] mini-batch-words: 0
[2023-07-01 11:29:57] [config] mini-batch-words-ref: 0
[2023-07-01 11:29:57] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:29:57] [config] multi-loss-type: sum
[2023-07-01 11:29:57] [config] n-best: false
[2023-07-01 11:29:57] [config] no-nccl: false
[2023-07-01 11:29:57] [config] no-reload: false
[2023-07-01 11:29:57] [config] no-restore-corpus: false
[2023-07-01 11:29:57] [config] normalize: 1
[2023-07-01 11:29:57] [config] normalize-gradient: false
[2023-07-01 11:29:57] [config] num-devices: 0
[2023-07-01 11:29:57] [config] optimizer: adam
[2023-07-01 11:29:57] [config] optimizer-delay: 1
[2023-07-01 11:29:57] [config] optimizer-params:
[2023-07-01 11:29:57] [config]   - 0.9
[2023-07-01 11:29:57] [config]   - 0.98
[2023-07-01 11:29:57] [config]   - 1e-09
[2023-07-01 11:29:57] [config] output-omit-bias: false
[2023-07-01 11:29:57] [config] overwrite: true
[2023-07-01 11:29:57] [config] precision:
[2023-07-01 11:29:57] [config]   - float32
[2023-07-01 11:29:57] [config]   - float32
[2023-07-01 11:29:57] [config] pretrained-model: ""
[2023-07-01 11:29:57] [config] quantize-biases: false
[2023-07-01 11:29:57] [config] quantize-bits: 0
[2023-07-01 11:29:57] [config] quantize-log-based: false
[2023-07-01 11:29:57] [config] quantize-optimization-steps: 0
[2023-07-01 11:29:57] [config] quiet: false
[2023-07-01 11:29:57] [config] quiet-translation: true
[2023-07-01 11:29:57] [config] relative-paths: false
[2023-07-01 11:29:57] [config] right-left: false
[2023-07-01 11:29:57] [config] save-freq: 10000u
[2023-07-01 11:29:57] [config] seed: 1234
[2023-07-01 11:29:57] [config] sentencepiece-alphas:
[2023-07-01 11:29:57] [config]   []
[2023-07-01 11:29:57] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:29:57] [config] sentencepiece-options: ""
[2023-07-01 11:29:57] [config] sharding: global
[2023-07-01 11:29:57] [config] shuffle: data
[2023-07-01 11:29:57] [config] shuffle-in-ram: false
[2023-07-01 11:29:57] [config] sigterm: save-and-exit
[2023-07-01 11:29:57] [config] skip: false
[2023-07-01 11:29:57] [config] sqlite: ""
[2023-07-01 11:29:57] [config] sqlite-drop: false
[2023-07-01 11:29:57] [config] sync-freq: 200u
[2023-07-01 11:29:57] [config] sync-sgd: true
[2023-07-01 11:29:57] [config] tempdir: /tmp
[2023-07-01 11:29:57] [config] tied-embeddings: false
[2023-07-01 11:29:57] [config] tied-embeddings-all: true
[2023-07-01 11:29:57] [config] tied-embeddings-src: false
[2023-07-01 11:29:57] [config] train-embedder-rank:
[2023-07-01 11:29:57] [config]   []
[2023-07-01 11:29:57] [config] train-sets:
[2023-07-01 11:29:57] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:29:57] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:29:57] [config] transformer-aan-activation: swish
[2023-07-01 11:29:57] [config] transformer-aan-depth: 2
[2023-07-01 11:29:57] [config] transformer-aan-nogate: false
[2023-07-01 11:29:57] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:29:57] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:29:57] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:29:57] [config] transformer-depth-scaling: false
[2023-07-01 11:29:57] [config] transformer-dim-aan: 2048
[2023-07-01 11:29:57] [config] transformer-dim-ffn: 2048
[2023-07-01 11:29:57] [config] transformer-dropout: 0.1
[2023-07-01 11:29:57] [config] transformer-dropout-attention: 0
[2023-07-01 11:29:57] [config] transformer-dropout-ffn: 0
[2023-07-01 11:29:57] [config] transformer-ffn-activation: swish
[2023-07-01 11:29:57] [config] transformer-ffn-depth: 2
[2023-07-01 11:29:57] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:29:57] [config] transformer-heads: 8
[2023-07-01 11:29:57] [config] transformer-no-projection: false
[2023-07-01 11:29:57] [config] transformer-pool: false
[2023-07-01 11:29:57] [config] transformer-postprocess: dan
[2023-07-01 11:29:57] [config] transformer-postprocess-emb: d
[2023-07-01 11:29:57] [config] transformer-postprocess-top: ""
[2023-07-01 11:29:57] [config] transformer-preprocess: ""
[2023-07-01 11:29:57] [config] transformer-tied-layers:
[2023-07-01 11:29:57] [config]   []
[2023-07-01 11:29:57] [config] transformer-train-position-embeddings: false
[2023-07-01 11:29:57] [config] tsv: false
[2023-07-01 11:29:57] [config] tsv-fields: 0
[2023-07-01 11:29:57] [config] type: transformer
[2023-07-01 11:29:57] [config] ulr: false
[2023-07-01 11:29:57] [config] ulr-dim-emb: 0
[2023-07-01 11:29:57] [config] ulr-dropout: 0
[2023-07-01 11:29:57] [config] ulr-keys-vectors: ""
[2023-07-01 11:29:57] [config] ulr-query-vectors: ""
[2023-07-01 11:29:57] [config] ulr-softmax-temperature: 1
[2023-07-01 11:29:57] [config] ulr-trainable-transformation: false
[2023-07-01 11:29:57] [config] unlikelihood-loss: false
[2023-07-01 11:29:57] [config] valid-freq: 50000000
[2023-07-01 11:29:57] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:29:57] [config] valid-max-length: 1000
[2023-07-01 11:29:57] [config] valid-metrics:
[2023-07-01 11:29:57] [config]   - cross-entropy
[2023-07-01 11:29:57] [config]   - translation
[2023-07-01 11:29:57] [config] valid-mini-batch: 64
[2023-07-01 11:29:57] [config] valid-reset-stalled: false
[2023-07-01 11:29:57] [config] valid-script-args:
[2023-07-01 11:29:57] [config]   []
[2023-07-01 11:29:57] [config] valid-script-path: ""
[2023-07-01 11:29:57] [config] valid-sets:
[2023-07-01 11:29:57] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:29:57] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:29:57] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:29:57] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:29:57] [config] vocabs:
[2023-07-01 11:29:57] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:29:57] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:29:57] [config] word-penalty: 0
[2023-07-01 11:29:57] [config] word-scores: false
[2023-07-01 11:29:57] [config] workspace: 2048
[2023-07-01 11:29:57] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:29:57] Using synchronous SGD
[2023-07-01 11:29:57] Synced seed 1234
[2023-07-01 11:29:57] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:29:57] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:29:57] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:29:57] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:29:57] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:29:57] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:29:58] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:29:58] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:29:58] [comm] Using global sharding
[2023-07-01 11:29:58] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:29:58] [training] Using 1 GPUs
[2023-07-01 11:29:58] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:29:58] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:29:59] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:29:59] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:30:06] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:30:06] [valid] No post-processing script given for validating translator
[2023-07-01 11:30:06] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:30:06] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:30:06] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:30:06] [comm] Using global sharding
[2023-07-01 11:30:06] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:30:06] [training] Using 1 GPUs
[2023-07-01 11:30:06] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:30:07] Allocating memory for general optimizer shards
[2023-07-01 11:30:07] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:30:07] Loading Adam parameters
[2023-07-01 11:30:07] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:30:07] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:30:07] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:30:07] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:30:07] [data] Shuffling data
[2023-07-01 11:30:07] [data] Done reading 20,192 sentences
[2023-07-01 11:30:07] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:30:07] Training started
[2023-07-01 11:30:07] Training finished
[2023-07-01 11:30:11] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:30:11] [marian] Running on node20.datos.cluster.uy as process 16629 with command line:
[2023-07-01 11:30:11] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 94 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:30:11] [config] after: 0e
[2023-07-01 11:30:11] [config] after-batches: 0
[2023-07-01 11:30:11] [config] after-epochs: 94
[2023-07-01 11:30:11] [config] all-caps-every: 0
[2023-07-01 11:30:11] [config] allow-unk: false
[2023-07-01 11:30:11] [config] authors: false
[2023-07-01 11:30:11] [config] beam-size: 12
[2023-07-01 11:30:11] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:30:11] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:30:11] [config] bert-masking-fraction: 0.15
[2023-07-01 11:30:11] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:30:11] [config] bert-train-type-embeddings: true
[2023-07-01 11:30:11] [config] bert-type-vocab-size: 2
[2023-07-01 11:30:11] [config] build-info: ""
[2023-07-01 11:30:11] [config] check-gradient-nan: false
[2023-07-01 11:30:11] [config] check-nan: false
[2023-07-01 11:30:11] [config] cite: false
[2023-07-01 11:30:11] [config] clip-norm: 5
[2023-07-01 11:30:11] [config] cost-scaling:
[2023-07-01 11:30:11] [config]   []
[2023-07-01 11:30:11] [config] cost-type: ce-sum
[2023-07-01 11:30:11] [config] cpu-threads: 0
[2023-07-01 11:30:11] [config] data-threads: 8
[2023-07-01 11:30:11] [config] data-weighting: ""
[2023-07-01 11:30:11] [config] data-weighting-type: sentence
[2023-07-01 11:30:11] [config] dec-cell: gru
[2023-07-01 11:30:11] [config] dec-cell-base-depth: 2
[2023-07-01 11:30:11] [config] dec-cell-high-depth: 1
[2023-07-01 11:30:11] [config] dec-depth: 2
[2023-07-01 11:30:11] [config] devices:
[2023-07-01 11:30:11] [config]   - 0
[2023-07-01 11:30:11] [config] dim-emb: 512
[2023-07-01 11:30:11] [config] dim-rnn: 1024
[2023-07-01 11:30:11] [config] dim-vocabs:
[2023-07-01 11:30:11] [config]   - 16384
[2023-07-01 11:30:11] [config]   - 16384
[2023-07-01 11:30:11] [config] disp-first: 0
[2023-07-01 11:30:11] [config] disp-freq: 1000u
[2023-07-01 11:30:11] [config] disp-label-counts: true
[2023-07-01 11:30:11] [config] dropout-rnn: 0
[2023-07-01 11:30:11] [config] dropout-src: 0
[2023-07-01 11:30:11] [config] dropout-trg: 0
[2023-07-01 11:30:11] [config] dump-config: ""
[2023-07-01 11:30:11] [config] dynamic-gradient-scaling:
[2023-07-01 11:30:11] [config]   []
[2023-07-01 11:30:11] [config] early-stopping: 10
[2023-07-01 11:30:11] [config] early-stopping-on: first
[2023-07-01 11:30:11] [config] embedding-fix-src: false
[2023-07-01 11:30:11] [config] embedding-fix-trg: false
[2023-07-01 11:30:11] [config] embedding-normalization: false
[2023-07-01 11:30:11] [config] embedding-vectors:
[2023-07-01 11:30:11] [config]   []
[2023-07-01 11:30:11] [config] enc-cell: gru
[2023-07-01 11:30:11] [config] enc-cell-depth: 1
[2023-07-01 11:30:11] [config] enc-depth: 2
[2023-07-01 11:30:11] [config] enc-type: bidirectional
[2023-07-01 11:30:11] [config] english-title-case-every: 0
[2023-07-01 11:30:11] [config] exponential-smoothing: 0.0001
[2023-07-01 11:30:11] [config] factor-weight: 1
[2023-07-01 11:30:11] [config] factors-combine: sum
[2023-07-01 11:30:11] [config] factors-dim-emb: 0
[2023-07-01 11:30:11] [config] gradient-checkpointing: false
[2023-07-01 11:30:11] [config] gradient-norm-average-window: 100
[2023-07-01 11:30:11] [config] guided-alignment: none
[2023-07-01 11:30:11] [config] guided-alignment-cost: mse
[2023-07-01 11:30:11] [config] guided-alignment-weight: 0.1
[2023-07-01 11:30:11] [config] ignore-model-config: false
[2023-07-01 11:30:11] [config] input-types:
[2023-07-01 11:30:11] [config]   []
[2023-07-01 11:30:11] [config] interpolate-env-vars: false
[2023-07-01 11:30:11] [config] keep-best: false
[2023-07-01 11:30:11] [config] label-smoothing: 0.1
[2023-07-01 11:30:11] [config] layer-normalization: false
[2023-07-01 11:30:11] [config] learn-rate: 0.0003
[2023-07-01 11:30:11] [config] lemma-dependency: ""
[2023-07-01 11:30:11] [config] lemma-dim-emb: 0
[2023-07-01 11:30:11] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:30:11] [config] log-level: info
[2023-07-01 11:30:11] [config] log-time-zone: ""
[2023-07-01 11:30:11] [config] logical-epoch:
[2023-07-01 11:30:11] [config]   - 1e
[2023-07-01 11:30:11] [config]   - 0
[2023-07-01 11:30:11] [config] lr-decay: 0
[2023-07-01 11:30:11] [config] lr-decay-freq: 50000
[2023-07-01 11:30:11] [config] lr-decay-inv-sqrt:
[2023-07-01 11:30:11] [config]   - 16000
[2023-07-01 11:30:11] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:30:11] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:30:11] [config] lr-decay-start:
[2023-07-01 11:30:11] [config]   - 10
[2023-07-01 11:30:11] [config]   - 1
[2023-07-01 11:30:11] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:30:11] [config] lr-report: true
[2023-07-01 11:30:11] [config] lr-warmup: 16000
[2023-07-01 11:30:11] [config] lr-warmup-at-reload: false
[2023-07-01 11:30:11] [config] lr-warmup-cycle: false
[2023-07-01 11:30:11] [config] lr-warmup-start-rate: 0
[2023-07-01 11:30:11] [config] max-length: 100
[2023-07-01 11:30:11] [config] max-length-crop: false
[2023-07-01 11:30:11] [config] max-length-factor: 3
[2023-07-01 11:30:11] [config] maxi-batch: 100
[2023-07-01 11:30:11] [config] maxi-batch-sort: trg
[2023-07-01 11:30:11] [config] mini-batch: 1000
[2023-07-01 11:30:11] [config] mini-batch-fit: true
[2023-07-01 11:30:11] [config] mini-batch-fit-step: 10
[2023-07-01 11:30:11] [config] mini-batch-round-up: true
[2023-07-01 11:30:11] [config] mini-batch-track-lr: false
[2023-07-01 11:30:11] [config] mini-batch-warmup: 0
[2023-07-01 11:30:11] [config] mini-batch-words: 0
[2023-07-01 11:30:11] [config] mini-batch-words-ref: 0
[2023-07-01 11:30:11] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:30:11] [config] multi-loss-type: sum
[2023-07-01 11:30:11] [config] n-best: false
[2023-07-01 11:30:11] [config] no-nccl: false
[2023-07-01 11:30:11] [config] no-reload: false
[2023-07-01 11:30:11] [config] no-restore-corpus: false
[2023-07-01 11:30:11] [config] normalize: 1
[2023-07-01 11:30:11] [config] normalize-gradient: false
[2023-07-01 11:30:11] [config] num-devices: 0
[2023-07-01 11:30:11] [config] optimizer: adam
[2023-07-01 11:30:11] [config] optimizer-delay: 1
[2023-07-01 11:30:11] [config] optimizer-params:
[2023-07-01 11:30:11] [config]   - 0.9
[2023-07-01 11:30:11] [config]   - 0.98
[2023-07-01 11:30:11] [config]   - 1e-09
[2023-07-01 11:30:11] [config] output-omit-bias: false
[2023-07-01 11:30:11] [config] overwrite: true
[2023-07-01 11:30:11] [config] precision:
[2023-07-01 11:30:11] [config]   - float32
[2023-07-01 11:30:11] [config]   - float32
[2023-07-01 11:30:11] [config] pretrained-model: ""
[2023-07-01 11:30:11] [config] quantize-biases: false
[2023-07-01 11:30:11] [config] quantize-bits: 0
[2023-07-01 11:30:11] [config] quantize-log-based: false
[2023-07-01 11:30:11] [config] quantize-optimization-steps: 0
[2023-07-01 11:30:11] [config] quiet: false
[2023-07-01 11:30:11] [config] quiet-translation: true
[2023-07-01 11:30:11] [config] relative-paths: false
[2023-07-01 11:30:11] [config] right-left: false
[2023-07-01 11:30:11] [config] save-freq: 10000u
[2023-07-01 11:30:11] [config] seed: 1234
[2023-07-01 11:30:11] [config] sentencepiece-alphas:
[2023-07-01 11:30:11] [config]   []
[2023-07-01 11:30:11] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:30:11] [config] sentencepiece-options: ""
[2023-07-01 11:30:11] [config] sharding: global
[2023-07-01 11:30:11] [config] shuffle: data
[2023-07-01 11:30:11] [config] shuffle-in-ram: false
[2023-07-01 11:30:11] [config] sigterm: save-and-exit
[2023-07-01 11:30:11] [config] skip: false
[2023-07-01 11:30:11] [config] sqlite: ""
[2023-07-01 11:30:11] [config] sqlite-drop: false
[2023-07-01 11:30:11] [config] sync-freq: 200u
[2023-07-01 11:30:11] [config] sync-sgd: true
[2023-07-01 11:30:11] [config] tempdir: /tmp
[2023-07-01 11:30:11] [config] tied-embeddings: false
[2023-07-01 11:30:11] [config] tied-embeddings-all: true
[2023-07-01 11:30:11] [config] tied-embeddings-src: false
[2023-07-01 11:30:11] [config] train-embedder-rank:
[2023-07-01 11:30:11] [config]   []
[2023-07-01 11:30:11] [config] train-sets:
[2023-07-01 11:30:11] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:30:11] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:30:11] [config] transformer-aan-activation: swish
[2023-07-01 11:30:11] [config] transformer-aan-depth: 2
[2023-07-01 11:30:11] [config] transformer-aan-nogate: false
[2023-07-01 11:30:11] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:30:11] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:30:11] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:30:11] [config] transformer-depth-scaling: false
[2023-07-01 11:30:11] [config] transformer-dim-aan: 2048
[2023-07-01 11:30:11] [config] transformer-dim-ffn: 2048
[2023-07-01 11:30:11] [config] transformer-dropout: 0.1
[2023-07-01 11:30:11] [config] transformer-dropout-attention: 0
[2023-07-01 11:30:11] [config] transformer-dropout-ffn: 0
[2023-07-01 11:30:11] [config] transformer-ffn-activation: swish
[2023-07-01 11:30:11] [config] transformer-ffn-depth: 2
[2023-07-01 11:30:11] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:30:11] [config] transformer-heads: 8
[2023-07-01 11:30:11] [config] transformer-no-projection: false
[2023-07-01 11:30:11] [config] transformer-pool: false
[2023-07-01 11:30:11] [config] transformer-postprocess: dan
[2023-07-01 11:30:11] [config] transformer-postprocess-emb: d
[2023-07-01 11:30:11] [config] transformer-postprocess-top: ""
[2023-07-01 11:30:11] [config] transformer-preprocess: ""
[2023-07-01 11:30:11] [config] transformer-tied-layers:
[2023-07-01 11:30:11] [config]   []
[2023-07-01 11:30:11] [config] transformer-train-position-embeddings: false
[2023-07-01 11:30:11] [config] tsv: false
[2023-07-01 11:30:11] [config] tsv-fields: 0
[2023-07-01 11:30:11] [config] type: transformer
[2023-07-01 11:30:11] [config] ulr: false
[2023-07-01 11:30:11] [config] ulr-dim-emb: 0
[2023-07-01 11:30:11] [config] ulr-dropout: 0
[2023-07-01 11:30:11] [config] ulr-keys-vectors: ""
[2023-07-01 11:30:11] [config] ulr-query-vectors: ""
[2023-07-01 11:30:11] [config] ulr-softmax-temperature: 1
[2023-07-01 11:30:11] [config] ulr-trainable-transformation: false
[2023-07-01 11:30:11] [config] unlikelihood-loss: false
[2023-07-01 11:30:11] [config] valid-freq: 50000000
[2023-07-01 11:30:11] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:30:11] [config] valid-max-length: 1000
[2023-07-01 11:30:11] [config] valid-metrics:
[2023-07-01 11:30:11] [config]   - cross-entropy
[2023-07-01 11:30:11] [config]   - translation
[2023-07-01 11:30:11] [config] valid-mini-batch: 64
[2023-07-01 11:30:11] [config] valid-reset-stalled: false
[2023-07-01 11:30:11] [config] valid-script-args:
[2023-07-01 11:30:11] [config]   []
[2023-07-01 11:30:11] [config] valid-script-path: ""
[2023-07-01 11:30:11] [config] valid-sets:
[2023-07-01 11:30:11] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:30:11] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:30:11] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:30:11] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:30:11] [config] vocabs:
[2023-07-01 11:30:11] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:30:11] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:30:11] [config] word-penalty: 0
[2023-07-01 11:30:11] [config] word-scores: false
[2023-07-01 11:30:11] [config] workspace: 2048
[2023-07-01 11:30:11] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:30:11] Using synchronous SGD
[2023-07-01 11:30:11] Synced seed 1234
[2023-07-01 11:30:11] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:30:11] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:30:11] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:30:11] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:30:11] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:30:11] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:30:12] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:30:12] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:30:12] [comm] Using global sharding
[2023-07-01 11:30:12] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:30:12] [training] Using 1 GPUs
[2023-07-01 11:30:12] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:30:12] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:30:12] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:30:12] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:30:20] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:30:20] [valid] No post-processing script given for validating translator
[2023-07-01 11:30:20] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:30:20] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:30:20] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:30:20] [comm] Using global sharding
[2023-07-01 11:30:20] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:30:20] [training] Using 1 GPUs
[2023-07-01 11:30:20] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:30:20] Allocating memory for general optimizer shards
[2023-07-01 11:30:20] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:30:20] Loading Adam parameters
[2023-07-01 11:30:20] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:30:21] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:30:21] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:30:21] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:30:21] [data] Shuffling data
[2023-07-01 11:30:21] [data] Done reading 20,192 sentences
[2023-07-01 11:30:21] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:30:21] Training started
[2023-07-01 11:30:21] Training finished
[2023-07-01 11:30:24] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:30:24] [marian] Running on node20.datos.cluster.uy as process 16686 with command line:
[2023-07-01 11:30:24] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 95 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:30:24] [config] after: 0e
[2023-07-01 11:30:24] [config] after-batches: 0
[2023-07-01 11:30:24] [config] after-epochs: 95
[2023-07-01 11:30:24] [config] all-caps-every: 0
[2023-07-01 11:30:24] [config] allow-unk: false
[2023-07-01 11:30:24] [config] authors: false
[2023-07-01 11:30:24] [config] beam-size: 12
[2023-07-01 11:30:24] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:30:24] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:30:24] [config] bert-masking-fraction: 0.15
[2023-07-01 11:30:24] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:30:24] [config] bert-train-type-embeddings: true
[2023-07-01 11:30:24] [config] bert-type-vocab-size: 2
[2023-07-01 11:30:24] [config] build-info: ""
[2023-07-01 11:30:24] [config] check-gradient-nan: false
[2023-07-01 11:30:24] [config] check-nan: false
[2023-07-01 11:30:24] [config] cite: false
[2023-07-01 11:30:24] [config] clip-norm: 5
[2023-07-01 11:30:24] [config] cost-scaling:
[2023-07-01 11:30:24] [config]   []
[2023-07-01 11:30:24] [config] cost-type: ce-sum
[2023-07-01 11:30:24] [config] cpu-threads: 0
[2023-07-01 11:30:24] [config] data-threads: 8
[2023-07-01 11:30:24] [config] data-weighting: ""
[2023-07-01 11:30:24] [config] data-weighting-type: sentence
[2023-07-01 11:30:24] [config] dec-cell: gru
[2023-07-01 11:30:24] [config] dec-cell-base-depth: 2
[2023-07-01 11:30:24] [config] dec-cell-high-depth: 1
[2023-07-01 11:30:24] [config] dec-depth: 2
[2023-07-01 11:30:24] [config] devices:
[2023-07-01 11:30:24] [config]   - 0
[2023-07-01 11:30:24] [config] dim-emb: 512
[2023-07-01 11:30:24] [config] dim-rnn: 1024
[2023-07-01 11:30:24] [config] dim-vocabs:
[2023-07-01 11:30:24] [config]   - 16384
[2023-07-01 11:30:24] [config]   - 16384
[2023-07-01 11:30:24] [config] disp-first: 0
[2023-07-01 11:30:24] [config] disp-freq: 1000u
[2023-07-01 11:30:24] [config] disp-label-counts: true
[2023-07-01 11:30:24] [config] dropout-rnn: 0
[2023-07-01 11:30:24] [config] dropout-src: 0
[2023-07-01 11:30:24] [config] dropout-trg: 0
[2023-07-01 11:30:24] [config] dump-config: ""
[2023-07-01 11:30:24] [config] dynamic-gradient-scaling:
[2023-07-01 11:30:24] [config]   []
[2023-07-01 11:30:24] [config] early-stopping: 10
[2023-07-01 11:30:24] [config] early-stopping-on: first
[2023-07-01 11:30:24] [config] embedding-fix-src: false
[2023-07-01 11:30:24] [config] embedding-fix-trg: false
[2023-07-01 11:30:24] [config] embedding-normalization: false
[2023-07-01 11:30:24] [config] embedding-vectors:
[2023-07-01 11:30:24] [config]   []
[2023-07-01 11:30:24] [config] enc-cell: gru
[2023-07-01 11:30:24] [config] enc-cell-depth: 1
[2023-07-01 11:30:24] [config] enc-depth: 2
[2023-07-01 11:30:24] [config] enc-type: bidirectional
[2023-07-01 11:30:24] [config] english-title-case-every: 0
[2023-07-01 11:30:24] [config] exponential-smoothing: 0.0001
[2023-07-01 11:30:24] [config] factor-weight: 1
[2023-07-01 11:30:24] [config] factors-combine: sum
[2023-07-01 11:30:24] [config] factors-dim-emb: 0
[2023-07-01 11:30:24] [config] gradient-checkpointing: false
[2023-07-01 11:30:24] [config] gradient-norm-average-window: 100
[2023-07-01 11:30:24] [config] guided-alignment: none
[2023-07-01 11:30:24] [config] guided-alignment-cost: mse
[2023-07-01 11:30:24] [config] guided-alignment-weight: 0.1
[2023-07-01 11:30:24] [config] ignore-model-config: false
[2023-07-01 11:30:24] [config] input-types:
[2023-07-01 11:30:24] [config]   []
[2023-07-01 11:30:24] [config] interpolate-env-vars: false
[2023-07-01 11:30:24] [config] keep-best: false
[2023-07-01 11:30:24] [config] label-smoothing: 0.1
[2023-07-01 11:30:24] [config] layer-normalization: false
[2023-07-01 11:30:24] [config] learn-rate: 0.0003
[2023-07-01 11:30:24] [config] lemma-dependency: ""
[2023-07-01 11:30:24] [config] lemma-dim-emb: 0
[2023-07-01 11:30:24] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:30:24] [config] log-level: info
[2023-07-01 11:30:24] [config] log-time-zone: ""
[2023-07-01 11:30:24] [config] logical-epoch:
[2023-07-01 11:30:24] [config]   - 1e
[2023-07-01 11:30:24] [config]   - 0
[2023-07-01 11:30:24] [config] lr-decay: 0
[2023-07-01 11:30:24] [config] lr-decay-freq: 50000
[2023-07-01 11:30:24] [config] lr-decay-inv-sqrt:
[2023-07-01 11:30:24] [config]   - 16000
[2023-07-01 11:30:24] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:30:24] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:30:24] [config] lr-decay-start:
[2023-07-01 11:30:24] [config]   - 10
[2023-07-01 11:30:24] [config]   - 1
[2023-07-01 11:30:24] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:30:24] [config] lr-report: true
[2023-07-01 11:30:24] [config] lr-warmup: 16000
[2023-07-01 11:30:24] [config] lr-warmup-at-reload: false
[2023-07-01 11:30:24] [config] lr-warmup-cycle: false
[2023-07-01 11:30:24] [config] lr-warmup-start-rate: 0
[2023-07-01 11:30:24] [config] max-length: 100
[2023-07-01 11:30:24] [config] max-length-crop: false
[2023-07-01 11:30:24] [config] max-length-factor: 3
[2023-07-01 11:30:24] [config] maxi-batch: 100
[2023-07-01 11:30:24] [config] maxi-batch-sort: trg
[2023-07-01 11:30:24] [config] mini-batch: 1000
[2023-07-01 11:30:24] [config] mini-batch-fit: true
[2023-07-01 11:30:24] [config] mini-batch-fit-step: 10
[2023-07-01 11:30:24] [config] mini-batch-round-up: true
[2023-07-01 11:30:24] [config] mini-batch-track-lr: false
[2023-07-01 11:30:24] [config] mini-batch-warmup: 0
[2023-07-01 11:30:24] [config] mini-batch-words: 0
[2023-07-01 11:30:24] [config] mini-batch-words-ref: 0
[2023-07-01 11:30:24] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:30:24] [config] multi-loss-type: sum
[2023-07-01 11:30:24] [config] n-best: false
[2023-07-01 11:30:24] [config] no-nccl: false
[2023-07-01 11:30:24] [config] no-reload: false
[2023-07-01 11:30:24] [config] no-restore-corpus: false
[2023-07-01 11:30:24] [config] normalize: 1
[2023-07-01 11:30:24] [config] normalize-gradient: false
[2023-07-01 11:30:24] [config] num-devices: 0
[2023-07-01 11:30:24] [config] optimizer: adam
[2023-07-01 11:30:24] [config] optimizer-delay: 1
[2023-07-01 11:30:24] [config] optimizer-params:
[2023-07-01 11:30:24] [config]   - 0.9
[2023-07-01 11:30:24] [config]   - 0.98
[2023-07-01 11:30:24] [config]   - 1e-09
[2023-07-01 11:30:24] [config] output-omit-bias: false
[2023-07-01 11:30:24] [config] overwrite: true
[2023-07-01 11:30:24] [config] precision:
[2023-07-01 11:30:24] [config]   - float32
[2023-07-01 11:30:24] [config]   - float32
[2023-07-01 11:30:24] [config] pretrained-model: ""
[2023-07-01 11:30:24] [config] quantize-biases: false
[2023-07-01 11:30:24] [config] quantize-bits: 0
[2023-07-01 11:30:24] [config] quantize-log-based: false
[2023-07-01 11:30:24] [config] quantize-optimization-steps: 0
[2023-07-01 11:30:24] [config] quiet: false
[2023-07-01 11:30:24] [config] quiet-translation: true
[2023-07-01 11:30:24] [config] relative-paths: false
[2023-07-01 11:30:24] [config] right-left: false
[2023-07-01 11:30:24] [config] save-freq: 10000u
[2023-07-01 11:30:24] [config] seed: 1234
[2023-07-01 11:30:24] [config] sentencepiece-alphas:
[2023-07-01 11:30:24] [config]   []
[2023-07-01 11:30:24] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:30:24] [config] sentencepiece-options: ""
[2023-07-01 11:30:24] [config] sharding: global
[2023-07-01 11:30:24] [config] shuffle: data
[2023-07-01 11:30:24] [config] shuffle-in-ram: false
[2023-07-01 11:30:24] [config] sigterm: save-and-exit
[2023-07-01 11:30:24] [config] skip: false
[2023-07-01 11:30:24] [config] sqlite: ""
[2023-07-01 11:30:24] [config] sqlite-drop: false
[2023-07-01 11:30:24] [config] sync-freq: 200u
[2023-07-01 11:30:24] [config] sync-sgd: true
[2023-07-01 11:30:24] [config] tempdir: /tmp
[2023-07-01 11:30:24] [config] tied-embeddings: false
[2023-07-01 11:30:24] [config] tied-embeddings-all: true
[2023-07-01 11:30:24] [config] tied-embeddings-src: false
[2023-07-01 11:30:24] [config] train-embedder-rank:
[2023-07-01 11:30:24] [config]   []
[2023-07-01 11:30:24] [config] train-sets:
[2023-07-01 11:30:24] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:30:24] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:30:24] [config] transformer-aan-activation: swish
[2023-07-01 11:30:24] [config] transformer-aan-depth: 2
[2023-07-01 11:30:24] [config] transformer-aan-nogate: false
[2023-07-01 11:30:24] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:30:24] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:30:24] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:30:24] [config] transformer-depth-scaling: false
[2023-07-01 11:30:24] [config] transformer-dim-aan: 2048
[2023-07-01 11:30:24] [config] transformer-dim-ffn: 2048
[2023-07-01 11:30:24] [config] transformer-dropout: 0.1
[2023-07-01 11:30:24] [config] transformer-dropout-attention: 0
[2023-07-01 11:30:24] [config] transformer-dropout-ffn: 0
[2023-07-01 11:30:24] [config] transformer-ffn-activation: swish
[2023-07-01 11:30:24] [config] transformer-ffn-depth: 2
[2023-07-01 11:30:24] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:30:24] [config] transformer-heads: 8
[2023-07-01 11:30:24] [config] transformer-no-projection: false
[2023-07-01 11:30:24] [config] transformer-pool: false
[2023-07-01 11:30:24] [config] transformer-postprocess: dan
[2023-07-01 11:30:24] [config] transformer-postprocess-emb: d
[2023-07-01 11:30:24] [config] transformer-postprocess-top: ""
[2023-07-01 11:30:24] [config] transformer-preprocess: ""
[2023-07-01 11:30:24] [config] transformer-tied-layers:
[2023-07-01 11:30:24] [config]   []
[2023-07-01 11:30:24] [config] transformer-train-position-embeddings: false
[2023-07-01 11:30:24] [config] tsv: false
[2023-07-01 11:30:24] [config] tsv-fields: 0
[2023-07-01 11:30:24] [config] type: transformer
[2023-07-01 11:30:24] [config] ulr: false
[2023-07-01 11:30:24] [config] ulr-dim-emb: 0
[2023-07-01 11:30:24] [config] ulr-dropout: 0
[2023-07-01 11:30:24] [config] ulr-keys-vectors: ""
[2023-07-01 11:30:24] [config] ulr-query-vectors: ""
[2023-07-01 11:30:24] [config] ulr-softmax-temperature: 1
[2023-07-01 11:30:24] [config] ulr-trainable-transformation: false
[2023-07-01 11:30:24] [config] unlikelihood-loss: false
[2023-07-01 11:30:24] [config] valid-freq: 50000000
[2023-07-01 11:30:24] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:30:24] [config] valid-max-length: 1000
[2023-07-01 11:30:24] [config] valid-metrics:
[2023-07-01 11:30:24] [config]   - cross-entropy
[2023-07-01 11:30:24] [config]   - translation
[2023-07-01 11:30:24] [config] valid-mini-batch: 64
[2023-07-01 11:30:24] [config] valid-reset-stalled: false
[2023-07-01 11:30:24] [config] valid-script-args:
[2023-07-01 11:30:24] [config]   []
[2023-07-01 11:30:24] [config] valid-script-path: ""
[2023-07-01 11:30:24] [config] valid-sets:
[2023-07-01 11:30:24] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:30:24] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:30:24] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:30:24] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:30:24] [config] vocabs:
[2023-07-01 11:30:24] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:30:24] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:30:24] [config] word-penalty: 0
[2023-07-01 11:30:24] [config] word-scores: false
[2023-07-01 11:30:24] [config] workspace: 2048
[2023-07-01 11:30:24] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:30:24] Using synchronous SGD
[2023-07-01 11:30:24] Synced seed 1234
[2023-07-01 11:30:24] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:30:24] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:30:24] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:30:24] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:30:24] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:30:24] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:30:25] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:30:25] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:30:25] [comm] Using global sharding
[2023-07-01 11:30:25] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:30:25] [training] Using 1 GPUs
[2023-07-01 11:30:25] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:30:25] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:30:26] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:30:26] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:30:33] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:30:33] [valid] No post-processing script given for validating translator
[2023-07-01 11:30:33] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:30:33] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:30:33] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:30:33] [comm] Using global sharding
[2023-07-01 11:30:33] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:30:33] [training] Using 1 GPUs
[2023-07-01 11:30:33] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:30:34] Allocating memory for general optimizer shards
[2023-07-01 11:30:34] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:30:34] Loading Adam parameters
[2023-07-01 11:30:34] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:30:34] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:30:34] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:30:34] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:30:34] [data] Shuffling data
[2023-07-01 11:30:34] [data] Done reading 20,192 sentences
[2023-07-01 11:30:34] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:30:34] Training started
[2023-07-01 11:30:34] Training finished
[2023-07-01 11:30:38] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:30:38] [marian] Running on node20.datos.cluster.uy as process 16744 with command line:
[2023-07-01 11:30:38] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 96 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:30:38] [config] after: 0e
[2023-07-01 11:30:38] [config] after-batches: 0
[2023-07-01 11:30:38] [config] after-epochs: 96
[2023-07-01 11:30:38] [config] all-caps-every: 0
[2023-07-01 11:30:38] [config] allow-unk: false
[2023-07-01 11:30:38] [config] authors: false
[2023-07-01 11:30:38] [config] beam-size: 12
[2023-07-01 11:30:38] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:30:38] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:30:38] [config] bert-masking-fraction: 0.15
[2023-07-01 11:30:38] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:30:38] [config] bert-train-type-embeddings: true
[2023-07-01 11:30:38] [config] bert-type-vocab-size: 2
[2023-07-01 11:30:38] [config] build-info: ""
[2023-07-01 11:30:38] [config] check-gradient-nan: false
[2023-07-01 11:30:38] [config] check-nan: false
[2023-07-01 11:30:38] [config] cite: false
[2023-07-01 11:30:38] [config] clip-norm: 5
[2023-07-01 11:30:38] [config] cost-scaling:
[2023-07-01 11:30:38] [config]   []
[2023-07-01 11:30:38] [config] cost-type: ce-sum
[2023-07-01 11:30:38] [config] cpu-threads: 0
[2023-07-01 11:30:38] [config] data-threads: 8
[2023-07-01 11:30:38] [config] data-weighting: ""
[2023-07-01 11:30:38] [config] data-weighting-type: sentence
[2023-07-01 11:30:38] [config] dec-cell: gru
[2023-07-01 11:30:38] [config] dec-cell-base-depth: 2
[2023-07-01 11:30:38] [config] dec-cell-high-depth: 1
[2023-07-01 11:30:38] [config] dec-depth: 2
[2023-07-01 11:30:38] [config] devices:
[2023-07-01 11:30:38] [config]   - 0
[2023-07-01 11:30:38] [config] dim-emb: 512
[2023-07-01 11:30:38] [config] dim-rnn: 1024
[2023-07-01 11:30:38] [config] dim-vocabs:
[2023-07-01 11:30:38] [config]   - 16384
[2023-07-01 11:30:38] [config]   - 16384
[2023-07-01 11:30:38] [config] disp-first: 0
[2023-07-01 11:30:38] [config] disp-freq: 1000u
[2023-07-01 11:30:38] [config] disp-label-counts: true
[2023-07-01 11:30:38] [config] dropout-rnn: 0
[2023-07-01 11:30:38] [config] dropout-src: 0
[2023-07-01 11:30:38] [config] dropout-trg: 0
[2023-07-01 11:30:38] [config] dump-config: ""
[2023-07-01 11:30:38] [config] dynamic-gradient-scaling:
[2023-07-01 11:30:38] [config]   []
[2023-07-01 11:30:38] [config] early-stopping: 10
[2023-07-01 11:30:38] [config] early-stopping-on: first
[2023-07-01 11:30:38] [config] embedding-fix-src: false
[2023-07-01 11:30:38] [config] embedding-fix-trg: false
[2023-07-01 11:30:38] [config] embedding-normalization: false
[2023-07-01 11:30:38] [config] embedding-vectors:
[2023-07-01 11:30:38] [config]   []
[2023-07-01 11:30:38] [config] enc-cell: gru
[2023-07-01 11:30:38] [config] enc-cell-depth: 1
[2023-07-01 11:30:38] [config] enc-depth: 2
[2023-07-01 11:30:38] [config] enc-type: bidirectional
[2023-07-01 11:30:38] [config] english-title-case-every: 0
[2023-07-01 11:30:38] [config] exponential-smoothing: 0.0001
[2023-07-01 11:30:38] [config] factor-weight: 1
[2023-07-01 11:30:38] [config] factors-combine: sum
[2023-07-01 11:30:38] [config] factors-dim-emb: 0
[2023-07-01 11:30:38] [config] gradient-checkpointing: false
[2023-07-01 11:30:38] [config] gradient-norm-average-window: 100
[2023-07-01 11:30:38] [config] guided-alignment: none
[2023-07-01 11:30:38] [config] guided-alignment-cost: mse
[2023-07-01 11:30:38] [config] guided-alignment-weight: 0.1
[2023-07-01 11:30:38] [config] ignore-model-config: false
[2023-07-01 11:30:38] [config] input-types:
[2023-07-01 11:30:38] [config]   []
[2023-07-01 11:30:38] [config] interpolate-env-vars: false
[2023-07-01 11:30:38] [config] keep-best: false
[2023-07-01 11:30:38] [config] label-smoothing: 0.1
[2023-07-01 11:30:38] [config] layer-normalization: false
[2023-07-01 11:30:38] [config] learn-rate: 0.0003
[2023-07-01 11:30:38] [config] lemma-dependency: ""
[2023-07-01 11:30:38] [config] lemma-dim-emb: 0
[2023-07-01 11:30:38] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:30:38] [config] log-level: info
[2023-07-01 11:30:38] [config] log-time-zone: ""
[2023-07-01 11:30:38] [config] logical-epoch:
[2023-07-01 11:30:38] [config]   - 1e
[2023-07-01 11:30:38] [config]   - 0
[2023-07-01 11:30:38] [config] lr-decay: 0
[2023-07-01 11:30:38] [config] lr-decay-freq: 50000
[2023-07-01 11:30:38] [config] lr-decay-inv-sqrt:
[2023-07-01 11:30:38] [config]   - 16000
[2023-07-01 11:30:38] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:30:38] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:30:38] [config] lr-decay-start:
[2023-07-01 11:30:38] [config]   - 10
[2023-07-01 11:30:38] [config]   - 1
[2023-07-01 11:30:38] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:30:38] [config] lr-report: true
[2023-07-01 11:30:38] [config] lr-warmup: 16000
[2023-07-01 11:30:38] [config] lr-warmup-at-reload: false
[2023-07-01 11:30:38] [config] lr-warmup-cycle: false
[2023-07-01 11:30:38] [config] lr-warmup-start-rate: 0
[2023-07-01 11:30:38] [config] max-length: 100
[2023-07-01 11:30:38] [config] max-length-crop: false
[2023-07-01 11:30:38] [config] max-length-factor: 3
[2023-07-01 11:30:38] [config] maxi-batch: 100
[2023-07-01 11:30:38] [config] maxi-batch-sort: trg
[2023-07-01 11:30:38] [config] mini-batch: 1000
[2023-07-01 11:30:38] [config] mini-batch-fit: true
[2023-07-01 11:30:38] [config] mini-batch-fit-step: 10
[2023-07-01 11:30:38] [config] mini-batch-round-up: true
[2023-07-01 11:30:38] [config] mini-batch-track-lr: false
[2023-07-01 11:30:38] [config] mini-batch-warmup: 0
[2023-07-01 11:30:38] [config] mini-batch-words: 0
[2023-07-01 11:30:38] [config] mini-batch-words-ref: 0
[2023-07-01 11:30:38] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:30:38] [config] multi-loss-type: sum
[2023-07-01 11:30:38] [config] n-best: false
[2023-07-01 11:30:38] [config] no-nccl: false
[2023-07-01 11:30:38] [config] no-reload: false
[2023-07-01 11:30:38] [config] no-restore-corpus: false
[2023-07-01 11:30:38] [config] normalize: 1
[2023-07-01 11:30:38] [config] normalize-gradient: false
[2023-07-01 11:30:38] [config] num-devices: 0
[2023-07-01 11:30:38] [config] optimizer: adam
[2023-07-01 11:30:38] [config] optimizer-delay: 1
[2023-07-01 11:30:38] [config] optimizer-params:
[2023-07-01 11:30:38] [config]   - 0.9
[2023-07-01 11:30:38] [config]   - 0.98
[2023-07-01 11:30:38] [config]   - 1e-09
[2023-07-01 11:30:38] [config] output-omit-bias: false
[2023-07-01 11:30:38] [config] overwrite: true
[2023-07-01 11:30:38] [config] precision:
[2023-07-01 11:30:38] [config]   - float32
[2023-07-01 11:30:38] [config]   - float32
[2023-07-01 11:30:38] [config] pretrained-model: ""
[2023-07-01 11:30:38] [config] quantize-biases: false
[2023-07-01 11:30:38] [config] quantize-bits: 0
[2023-07-01 11:30:38] [config] quantize-log-based: false
[2023-07-01 11:30:38] [config] quantize-optimization-steps: 0
[2023-07-01 11:30:38] [config] quiet: false
[2023-07-01 11:30:38] [config] quiet-translation: true
[2023-07-01 11:30:38] [config] relative-paths: false
[2023-07-01 11:30:38] [config] right-left: false
[2023-07-01 11:30:38] [config] save-freq: 10000u
[2023-07-01 11:30:38] [config] seed: 1234
[2023-07-01 11:30:38] [config] sentencepiece-alphas:
[2023-07-01 11:30:38] [config]   []
[2023-07-01 11:30:38] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:30:38] [config] sentencepiece-options: ""
[2023-07-01 11:30:38] [config] sharding: global
[2023-07-01 11:30:38] [config] shuffle: data
[2023-07-01 11:30:38] [config] shuffle-in-ram: false
[2023-07-01 11:30:38] [config] sigterm: save-and-exit
[2023-07-01 11:30:38] [config] skip: false
[2023-07-01 11:30:38] [config] sqlite: ""
[2023-07-01 11:30:38] [config] sqlite-drop: false
[2023-07-01 11:30:38] [config] sync-freq: 200u
[2023-07-01 11:30:38] [config] sync-sgd: true
[2023-07-01 11:30:38] [config] tempdir: /tmp
[2023-07-01 11:30:38] [config] tied-embeddings: false
[2023-07-01 11:30:38] [config] tied-embeddings-all: true
[2023-07-01 11:30:38] [config] tied-embeddings-src: false
[2023-07-01 11:30:38] [config] train-embedder-rank:
[2023-07-01 11:30:38] [config]   []
[2023-07-01 11:30:38] [config] train-sets:
[2023-07-01 11:30:38] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:30:38] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:30:38] [config] transformer-aan-activation: swish
[2023-07-01 11:30:38] [config] transformer-aan-depth: 2
[2023-07-01 11:30:38] [config] transformer-aan-nogate: false
[2023-07-01 11:30:38] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:30:38] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:30:38] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:30:38] [config] transformer-depth-scaling: false
[2023-07-01 11:30:38] [config] transformer-dim-aan: 2048
[2023-07-01 11:30:38] [config] transformer-dim-ffn: 2048
[2023-07-01 11:30:38] [config] transformer-dropout: 0.1
[2023-07-01 11:30:38] [config] transformer-dropout-attention: 0
[2023-07-01 11:30:38] [config] transformer-dropout-ffn: 0
[2023-07-01 11:30:38] [config] transformer-ffn-activation: swish
[2023-07-01 11:30:38] [config] transformer-ffn-depth: 2
[2023-07-01 11:30:38] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:30:38] [config] transformer-heads: 8
[2023-07-01 11:30:38] [config] transformer-no-projection: false
[2023-07-01 11:30:38] [config] transformer-pool: false
[2023-07-01 11:30:38] [config] transformer-postprocess: dan
[2023-07-01 11:30:38] [config] transformer-postprocess-emb: d
[2023-07-01 11:30:38] [config] transformer-postprocess-top: ""
[2023-07-01 11:30:38] [config] transformer-preprocess: ""
[2023-07-01 11:30:38] [config] transformer-tied-layers:
[2023-07-01 11:30:38] [config]   []
[2023-07-01 11:30:38] [config] transformer-train-position-embeddings: false
[2023-07-01 11:30:38] [config] tsv: false
[2023-07-01 11:30:38] [config] tsv-fields: 0
[2023-07-01 11:30:38] [config] type: transformer
[2023-07-01 11:30:38] [config] ulr: false
[2023-07-01 11:30:38] [config] ulr-dim-emb: 0
[2023-07-01 11:30:38] [config] ulr-dropout: 0
[2023-07-01 11:30:38] [config] ulr-keys-vectors: ""
[2023-07-01 11:30:38] [config] ulr-query-vectors: ""
[2023-07-01 11:30:38] [config] ulr-softmax-temperature: 1
[2023-07-01 11:30:38] [config] ulr-trainable-transformation: false
[2023-07-01 11:30:38] [config] unlikelihood-loss: false
[2023-07-01 11:30:38] [config] valid-freq: 50000000
[2023-07-01 11:30:38] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:30:38] [config] valid-max-length: 1000
[2023-07-01 11:30:38] [config] valid-metrics:
[2023-07-01 11:30:38] [config]   - cross-entropy
[2023-07-01 11:30:38] [config]   - translation
[2023-07-01 11:30:38] [config] valid-mini-batch: 64
[2023-07-01 11:30:38] [config] valid-reset-stalled: false
[2023-07-01 11:30:38] [config] valid-script-args:
[2023-07-01 11:30:38] [config]   []
[2023-07-01 11:30:38] [config] valid-script-path: ""
[2023-07-01 11:30:38] [config] valid-sets:
[2023-07-01 11:30:38] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:30:38] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:30:38] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:30:38] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:30:38] [config] vocabs:
[2023-07-01 11:30:38] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:30:38] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:30:38] [config] word-penalty: 0
[2023-07-01 11:30:38] [config] word-scores: false
[2023-07-01 11:30:38] [config] workspace: 2048
[2023-07-01 11:30:38] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:30:38] Using synchronous SGD
[2023-07-01 11:30:38] Synced seed 1234
[2023-07-01 11:30:38] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:30:38] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:30:38] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:30:38] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:30:38] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:30:38] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:30:39] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:30:39] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:30:39] [comm] Using global sharding
[2023-07-01 11:30:39] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:30:39] [training] Using 1 GPUs
[2023-07-01 11:30:39] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:30:39] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:30:39] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:30:39] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:30:47] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:30:47] [valid] No post-processing script given for validating translator
[2023-07-01 11:30:47] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:30:47] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:30:47] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:30:47] [comm] Using global sharding
[2023-07-01 11:30:47] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:30:47] [training] Using 1 GPUs
[2023-07-01 11:30:47] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:30:47] Allocating memory for general optimizer shards
[2023-07-01 11:30:47] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:30:47] Loading Adam parameters
[2023-07-01 11:30:47] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:30:47] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:30:47] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:30:47] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:30:47] [data] Shuffling data
[2023-07-01 11:30:47] [data] Done reading 20,192 sentences
[2023-07-01 11:30:47] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:30:47] Training started
[2023-07-01 11:30:47] Training finished
[2023-07-01 11:30:51] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:30:51] [marian] Running on node20.datos.cluster.uy as process 16802 with command line:
[2023-07-01 11:30:51] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 97 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:30:51] [config] after: 0e
[2023-07-01 11:30:51] [config] after-batches: 0
[2023-07-01 11:30:51] [config] after-epochs: 97
[2023-07-01 11:30:51] [config] all-caps-every: 0
[2023-07-01 11:30:51] [config] allow-unk: false
[2023-07-01 11:30:51] [config] authors: false
[2023-07-01 11:30:51] [config] beam-size: 12
[2023-07-01 11:30:51] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:30:51] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:30:51] [config] bert-masking-fraction: 0.15
[2023-07-01 11:30:51] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:30:51] [config] bert-train-type-embeddings: true
[2023-07-01 11:30:51] [config] bert-type-vocab-size: 2
[2023-07-01 11:30:51] [config] build-info: ""
[2023-07-01 11:30:51] [config] check-gradient-nan: false
[2023-07-01 11:30:51] [config] check-nan: false
[2023-07-01 11:30:51] [config] cite: false
[2023-07-01 11:30:51] [config] clip-norm: 5
[2023-07-01 11:30:51] [config] cost-scaling:
[2023-07-01 11:30:51] [config]   []
[2023-07-01 11:30:51] [config] cost-type: ce-sum
[2023-07-01 11:30:51] [config] cpu-threads: 0
[2023-07-01 11:30:51] [config] data-threads: 8
[2023-07-01 11:30:51] [config] data-weighting: ""
[2023-07-01 11:30:51] [config] data-weighting-type: sentence
[2023-07-01 11:30:51] [config] dec-cell: gru
[2023-07-01 11:30:51] [config] dec-cell-base-depth: 2
[2023-07-01 11:30:51] [config] dec-cell-high-depth: 1
[2023-07-01 11:30:51] [config] dec-depth: 2
[2023-07-01 11:30:51] [config] devices:
[2023-07-01 11:30:51] [config]   - 0
[2023-07-01 11:30:51] [config] dim-emb: 512
[2023-07-01 11:30:51] [config] dim-rnn: 1024
[2023-07-01 11:30:51] [config] dim-vocabs:
[2023-07-01 11:30:51] [config]   - 16384
[2023-07-01 11:30:51] [config]   - 16384
[2023-07-01 11:30:51] [config] disp-first: 0
[2023-07-01 11:30:51] [config] disp-freq: 1000u
[2023-07-01 11:30:51] [config] disp-label-counts: true
[2023-07-01 11:30:51] [config] dropout-rnn: 0
[2023-07-01 11:30:51] [config] dropout-src: 0
[2023-07-01 11:30:51] [config] dropout-trg: 0
[2023-07-01 11:30:51] [config] dump-config: ""
[2023-07-01 11:30:51] [config] dynamic-gradient-scaling:
[2023-07-01 11:30:51] [config]   []
[2023-07-01 11:30:51] [config] early-stopping: 10
[2023-07-01 11:30:51] [config] early-stopping-on: first
[2023-07-01 11:30:51] [config] embedding-fix-src: false
[2023-07-01 11:30:51] [config] embedding-fix-trg: false
[2023-07-01 11:30:51] [config] embedding-normalization: false
[2023-07-01 11:30:51] [config] embedding-vectors:
[2023-07-01 11:30:51] [config]   []
[2023-07-01 11:30:51] [config] enc-cell: gru
[2023-07-01 11:30:51] [config] enc-cell-depth: 1
[2023-07-01 11:30:51] [config] enc-depth: 2
[2023-07-01 11:30:51] [config] enc-type: bidirectional
[2023-07-01 11:30:51] [config] english-title-case-every: 0
[2023-07-01 11:30:51] [config] exponential-smoothing: 0.0001
[2023-07-01 11:30:51] [config] factor-weight: 1
[2023-07-01 11:30:51] [config] factors-combine: sum
[2023-07-01 11:30:51] [config] factors-dim-emb: 0
[2023-07-01 11:30:51] [config] gradient-checkpointing: false
[2023-07-01 11:30:51] [config] gradient-norm-average-window: 100
[2023-07-01 11:30:51] [config] guided-alignment: none
[2023-07-01 11:30:51] [config] guided-alignment-cost: mse
[2023-07-01 11:30:51] [config] guided-alignment-weight: 0.1
[2023-07-01 11:30:51] [config] ignore-model-config: false
[2023-07-01 11:30:51] [config] input-types:
[2023-07-01 11:30:51] [config]   []
[2023-07-01 11:30:51] [config] interpolate-env-vars: false
[2023-07-01 11:30:51] [config] keep-best: false
[2023-07-01 11:30:51] [config] label-smoothing: 0.1
[2023-07-01 11:30:51] [config] layer-normalization: false
[2023-07-01 11:30:51] [config] learn-rate: 0.0003
[2023-07-01 11:30:51] [config] lemma-dependency: ""
[2023-07-01 11:30:51] [config] lemma-dim-emb: 0
[2023-07-01 11:30:51] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:30:51] [config] log-level: info
[2023-07-01 11:30:51] [config] log-time-zone: ""
[2023-07-01 11:30:51] [config] logical-epoch:
[2023-07-01 11:30:51] [config]   - 1e
[2023-07-01 11:30:51] [config]   - 0
[2023-07-01 11:30:51] [config] lr-decay: 0
[2023-07-01 11:30:51] [config] lr-decay-freq: 50000
[2023-07-01 11:30:51] [config] lr-decay-inv-sqrt:
[2023-07-01 11:30:51] [config]   - 16000
[2023-07-01 11:30:51] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:30:51] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:30:51] [config] lr-decay-start:
[2023-07-01 11:30:51] [config]   - 10
[2023-07-01 11:30:51] [config]   - 1
[2023-07-01 11:30:51] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:30:51] [config] lr-report: true
[2023-07-01 11:30:51] [config] lr-warmup: 16000
[2023-07-01 11:30:51] [config] lr-warmup-at-reload: false
[2023-07-01 11:30:51] [config] lr-warmup-cycle: false
[2023-07-01 11:30:51] [config] lr-warmup-start-rate: 0
[2023-07-01 11:30:51] [config] max-length: 100
[2023-07-01 11:30:51] [config] max-length-crop: false
[2023-07-01 11:30:51] [config] max-length-factor: 3
[2023-07-01 11:30:51] [config] maxi-batch: 100
[2023-07-01 11:30:51] [config] maxi-batch-sort: trg
[2023-07-01 11:30:51] [config] mini-batch: 1000
[2023-07-01 11:30:51] [config] mini-batch-fit: true
[2023-07-01 11:30:51] [config] mini-batch-fit-step: 10
[2023-07-01 11:30:51] [config] mini-batch-round-up: true
[2023-07-01 11:30:51] [config] mini-batch-track-lr: false
[2023-07-01 11:30:51] [config] mini-batch-warmup: 0
[2023-07-01 11:30:51] [config] mini-batch-words: 0
[2023-07-01 11:30:51] [config] mini-batch-words-ref: 0
[2023-07-01 11:30:51] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:30:51] [config] multi-loss-type: sum
[2023-07-01 11:30:51] [config] n-best: false
[2023-07-01 11:30:51] [config] no-nccl: false
[2023-07-01 11:30:51] [config] no-reload: false
[2023-07-01 11:30:51] [config] no-restore-corpus: false
[2023-07-01 11:30:51] [config] normalize: 1
[2023-07-01 11:30:51] [config] normalize-gradient: false
[2023-07-01 11:30:51] [config] num-devices: 0
[2023-07-01 11:30:51] [config] optimizer: adam
[2023-07-01 11:30:51] [config] optimizer-delay: 1
[2023-07-01 11:30:51] [config] optimizer-params:
[2023-07-01 11:30:51] [config]   - 0.9
[2023-07-01 11:30:51] [config]   - 0.98
[2023-07-01 11:30:51] [config]   - 1e-09
[2023-07-01 11:30:51] [config] output-omit-bias: false
[2023-07-01 11:30:51] [config] overwrite: true
[2023-07-01 11:30:51] [config] precision:
[2023-07-01 11:30:51] [config]   - float32
[2023-07-01 11:30:51] [config]   - float32
[2023-07-01 11:30:51] [config] pretrained-model: ""
[2023-07-01 11:30:51] [config] quantize-biases: false
[2023-07-01 11:30:51] [config] quantize-bits: 0
[2023-07-01 11:30:51] [config] quantize-log-based: false
[2023-07-01 11:30:51] [config] quantize-optimization-steps: 0
[2023-07-01 11:30:51] [config] quiet: false
[2023-07-01 11:30:51] [config] quiet-translation: true
[2023-07-01 11:30:51] [config] relative-paths: false
[2023-07-01 11:30:51] [config] right-left: false
[2023-07-01 11:30:51] [config] save-freq: 10000u
[2023-07-01 11:30:51] [config] seed: 1234
[2023-07-01 11:30:51] [config] sentencepiece-alphas:
[2023-07-01 11:30:51] [config]   []
[2023-07-01 11:30:51] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:30:51] [config] sentencepiece-options: ""
[2023-07-01 11:30:51] [config] sharding: global
[2023-07-01 11:30:51] [config] shuffle: data
[2023-07-01 11:30:51] [config] shuffle-in-ram: false
[2023-07-01 11:30:51] [config] sigterm: save-and-exit
[2023-07-01 11:30:51] [config] skip: false
[2023-07-01 11:30:51] [config] sqlite: ""
[2023-07-01 11:30:51] [config] sqlite-drop: false
[2023-07-01 11:30:51] [config] sync-freq: 200u
[2023-07-01 11:30:51] [config] sync-sgd: true
[2023-07-01 11:30:51] [config] tempdir: /tmp
[2023-07-01 11:30:51] [config] tied-embeddings: false
[2023-07-01 11:30:51] [config] tied-embeddings-all: true
[2023-07-01 11:30:51] [config] tied-embeddings-src: false
[2023-07-01 11:30:51] [config] train-embedder-rank:
[2023-07-01 11:30:51] [config]   []
[2023-07-01 11:30:51] [config] train-sets:
[2023-07-01 11:30:51] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:30:51] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:30:51] [config] transformer-aan-activation: swish
[2023-07-01 11:30:51] [config] transformer-aan-depth: 2
[2023-07-01 11:30:51] [config] transformer-aan-nogate: false
[2023-07-01 11:30:51] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:30:51] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:30:51] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:30:51] [config] transformer-depth-scaling: false
[2023-07-01 11:30:51] [config] transformer-dim-aan: 2048
[2023-07-01 11:30:51] [config] transformer-dim-ffn: 2048
[2023-07-01 11:30:51] [config] transformer-dropout: 0.1
[2023-07-01 11:30:51] [config] transformer-dropout-attention: 0
[2023-07-01 11:30:51] [config] transformer-dropout-ffn: 0
[2023-07-01 11:30:51] [config] transformer-ffn-activation: swish
[2023-07-01 11:30:51] [config] transformer-ffn-depth: 2
[2023-07-01 11:30:51] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:30:51] [config] transformer-heads: 8
[2023-07-01 11:30:51] [config] transformer-no-projection: false
[2023-07-01 11:30:51] [config] transformer-pool: false
[2023-07-01 11:30:51] [config] transformer-postprocess: dan
[2023-07-01 11:30:51] [config] transformer-postprocess-emb: d
[2023-07-01 11:30:51] [config] transformer-postprocess-top: ""
[2023-07-01 11:30:51] [config] transformer-preprocess: ""
[2023-07-01 11:30:51] [config] transformer-tied-layers:
[2023-07-01 11:30:51] [config]   []
[2023-07-01 11:30:51] [config] transformer-train-position-embeddings: false
[2023-07-01 11:30:51] [config] tsv: false
[2023-07-01 11:30:51] [config] tsv-fields: 0
[2023-07-01 11:30:51] [config] type: transformer
[2023-07-01 11:30:51] [config] ulr: false
[2023-07-01 11:30:51] [config] ulr-dim-emb: 0
[2023-07-01 11:30:51] [config] ulr-dropout: 0
[2023-07-01 11:30:51] [config] ulr-keys-vectors: ""
[2023-07-01 11:30:51] [config] ulr-query-vectors: ""
[2023-07-01 11:30:51] [config] ulr-softmax-temperature: 1
[2023-07-01 11:30:51] [config] ulr-trainable-transformation: false
[2023-07-01 11:30:51] [config] unlikelihood-loss: false
[2023-07-01 11:30:51] [config] valid-freq: 50000000
[2023-07-01 11:30:51] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:30:51] [config] valid-max-length: 1000
[2023-07-01 11:30:51] [config] valid-metrics:
[2023-07-01 11:30:51] [config]   - cross-entropy
[2023-07-01 11:30:51] [config]   - translation
[2023-07-01 11:30:51] [config] valid-mini-batch: 64
[2023-07-01 11:30:51] [config] valid-reset-stalled: false
[2023-07-01 11:30:51] [config] valid-script-args:
[2023-07-01 11:30:51] [config]   []
[2023-07-01 11:30:51] [config] valid-script-path: ""
[2023-07-01 11:30:51] [config] valid-sets:
[2023-07-01 11:30:51] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:30:51] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:30:51] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:30:51] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:30:51] [config] vocabs:
[2023-07-01 11:30:51] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:30:51] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:30:51] [config] word-penalty: 0
[2023-07-01 11:30:51] [config] word-scores: false
[2023-07-01 11:30:51] [config] workspace: 2048
[2023-07-01 11:30:51] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:30:51] Using synchronous SGD
[2023-07-01 11:30:52] Synced seed 1234
[2023-07-01 11:30:52] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:30:52] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:30:52] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:30:52] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:30:52] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:30:52] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:30:52] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:30:52] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:30:52] [comm] Using global sharding
[2023-07-01 11:30:53] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:30:53] [training] Using 1 GPUs
[2023-07-01 11:30:53] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:30:53] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:30:53] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:30:53] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:31:00] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:31:00] [valid] No post-processing script given for validating translator
[2023-07-01 11:31:00] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:31:00] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:31:00] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:31:00] [comm] Using global sharding
[2023-07-01 11:31:00] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:31:00] [training] Using 1 GPUs
[2023-07-01 11:31:00] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:31:01] Allocating memory for general optimizer shards
[2023-07-01 11:31:01] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:31:01] Loading Adam parameters
[2023-07-01 11:31:01] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:31:01] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:31:01] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:31:01] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:31:01] [data] Shuffling data
[2023-07-01 11:31:01] [data] Done reading 20,192 sentences
[2023-07-01 11:31:01] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:31:01] Training started
[2023-07-01 11:31:01] Training finished
[2023-07-01 11:31:05] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:31:05] [marian] Running on node20.datos.cluster.uy as process 16863 with command line:
[2023-07-01 11:31:05] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 98 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:31:05] [config] after: 0e
[2023-07-01 11:31:05] [config] after-batches: 0
[2023-07-01 11:31:05] [config] after-epochs: 98
[2023-07-01 11:31:05] [config] all-caps-every: 0
[2023-07-01 11:31:05] [config] allow-unk: false
[2023-07-01 11:31:05] [config] authors: false
[2023-07-01 11:31:05] [config] beam-size: 12
[2023-07-01 11:31:05] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:31:05] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:31:05] [config] bert-masking-fraction: 0.15
[2023-07-01 11:31:05] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:31:05] [config] bert-train-type-embeddings: true
[2023-07-01 11:31:05] [config] bert-type-vocab-size: 2
[2023-07-01 11:31:05] [config] build-info: ""
[2023-07-01 11:31:05] [config] check-gradient-nan: false
[2023-07-01 11:31:05] [config] check-nan: false
[2023-07-01 11:31:05] [config] cite: false
[2023-07-01 11:31:05] [config] clip-norm: 5
[2023-07-01 11:31:05] [config] cost-scaling:
[2023-07-01 11:31:05] [config]   []
[2023-07-01 11:31:05] [config] cost-type: ce-sum
[2023-07-01 11:31:05] [config] cpu-threads: 0
[2023-07-01 11:31:05] [config] data-threads: 8
[2023-07-01 11:31:05] [config] data-weighting: ""
[2023-07-01 11:31:05] [config] data-weighting-type: sentence
[2023-07-01 11:31:05] [config] dec-cell: gru
[2023-07-01 11:31:05] [config] dec-cell-base-depth: 2
[2023-07-01 11:31:05] [config] dec-cell-high-depth: 1
[2023-07-01 11:31:05] [config] dec-depth: 2
[2023-07-01 11:31:05] [config] devices:
[2023-07-01 11:31:05] [config]   - 0
[2023-07-01 11:31:05] [config] dim-emb: 512
[2023-07-01 11:31:05] [config] dim-rnn: 1024
[2023-07-01 11:31:05] [config] dim-vocabs:
[2023-07-01 11:31:05] [config]   - 16384
[2023-07-01 11:31:05] [config]   - 16384
[2023-07-01 11:31:05] [config] disp-first: 0
[2023-07-01 11:31:05] [config] disp-freq: 1000u
[2023-07-01 11:31:05] [config] disp-label-counts: true
[2023-07-01 11:31:05] [config] dropout-rnn: 0
[2023-07-01 11:31:05] [config] dropout-src: 0
[2023-07-01 11:31:05] [config] dropout-trg: 0
[2023-07-01 11:31:05] [config] dump-config: ""
[2023-07-01 11:31:05] [config] dynamic-gradient-scaling:
[2023-07-01 11:31:05] [config]   []
[2023-07-01 11:31:05] [config] early-stopping: 10
[2023-07-01 11:31:05] [config] early-stopping-on: first
[2023-07-01 11:31:05] [config] embedding-fix-src: false
[2023-07-01 11:31:05] [config] embedding-fix-trg: false
[2023-07-01 11:31:05] [config] embedding-normalization: false
[2023-07-01 11:31:05] [config] embedding-vectors:
[2023-07-01 11:31:05] [config]   []
[2023-07-01 11:31:05] [config] enc-cell: gru
[2023-07-01 11:31:05] [config] enc-cell-depth: 1
[2023-07-01 11:31:05] [config] enc-depth: 2
[2023-07-01 11:31:05] [config] enc-type: bidirectional
[2023-07-01 11:31:05] [config] english-title-case-every: 0
[2023-07-01 11:31:05] [config] exponential-smoothing: 0.0001
[2023-07-01 11:31:05] [config] factor-weight: 1
[2023-07-01 11:31:05] [config] factors-combine: sum
[2023-07-01 11:31:05] [config] factors-dim-emb: 0
[2023-07-01 11:31:05] [config] gradient-checkpointing: false
[2023-07-01 11:31:05] [config] gradient-norm-average-window: 100
[2023-07-01 11:31:05] [config] guided-alignment: none
[2023-07-01 11:31:05] [config] guided-alignment-cost: mse
[2023-07-01 11:31:05] [config] guided-alignment-weight: 0.1
[2023-07-01 11:31:05] [config] ignore-model-config: false
[2023-07-01 11:31:05] [config] input-types:
[2023-07-01 11:31:05] [config]   []
[2023-07-01 11:31:05] [config] interpolate-env-vars: false
[2023-07-01 11:31:05] [config] keep-best: false
[2023-07-01 11:31:05] [config] label-smoothing: 0.1
[2023-07-01 11:31:05] [config] layer-normalization: false
[2023-07-01 11:31:05] [config] learn-rate: 0.0003
[2023-07-01 11:31:05] [config] lemma-dependency: ""
[2023-07-01 11:31:05] [config] lemma-dim-emb: 0
[2023-07-01 11:31:05] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:31:05] [config] log-level: info
[2023-07-01 11:31:05] [config] log-time-zone: ""
[2023-07-01 11:31:05] [config] logical-epoch:
[2023-07-01 11:31:05] [config]   - 1e
[2023-07-01 11:31:05] [config]   - 0
[2023-07-01 11:31:05] [config] lr-decay: 0
[2023-07-01 11:31:05] [config] lr-decay-freq: 50000
[2023-07-01 11:31:05] [config] lr-decay-inv-sqrt:
[2023-07-01 11:31:05] [config]   - 16000
[2023-07-01 11:31:05] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:31:05] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:31:05] [config] lr-decay-start:
[2023-07-01 11:31:05] [config]   - 10
[2023-07-01 11:31:05] [config]   - 1
[2023-07-01 11:31:05] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:31:05] [config] lr-report: true
[2023-07-01 11:31:05] [config] lr-warmup: 16000
[2023-07-01 11:31:05] [config] lr-warmup-at-reload: false
[2023-07-01 11:31:05] [config] lr-warmup-cycle: false
[2023-07-01 11:31:05] [config] lr-warmup-start-rate: 0
[2023-07-01 11:31:05] [config] max-length: 100
[2023-07-01 11:31:05] [config] max-length-crop: false
[2023-07-01 11:31:05] [config] max-length-factor: 3
[2023-07-01 11:31:05] [config] maxi-batch: 100
[2023-07-01 11:31:05] [config] maxi-batch-sort: trg
[2023-07-01 11:31:05] [config] mini-batch: 1000
[2023-07-01 11:31:05] [config] mini-batch-fit: true
[2023-07-01 11:31:05] [config] mini-batch-fit-step: 10
[2023-07-01 11:31:05] [config] mini-batch-round-up: true
[2023-07-01 11:31:05] [config] mini-batch-track-lr: false
[2023-07-01 11:31:05] [config] mini-batch-warmup: 0
[2023-07-01 11:31:05] [config] mini-batch-words: 0
[2023-07-01 11:31:05] [config] mini-batch-words-ref: 0
[2023-07-01 11:31:05] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:31:05] [config] multi-loss-type: sum
[2023-07-01 11:31:05] [config] n-best: false
[2023-07-01 11:31:05] [config] no-nccl: false
[2023-07-01 11:31:05] [config] no-reload: false
[2023-07-01 11:31:05] [config] no-restore-corpus: false
[2023-07-01 11:31:05] [config] normalize: 1
[2023-07-01 11:31:05] [config] normalize-gradient: false
[2023-07-01 11:31:05] [config] num-devices: 0
[2023-07-01 11:31:05] [config] optimizer: adam
[2023-07-01 11:31:05] [config] optimizer-delay: 1
[2023-07-01 11:31:05] [config] optimizer-params:
[2023-07-01 11:31:05] [config]   - 0.9
[2023-07-01 11:31:05] [config]   - 0.98
[2023-07-01 11:31:05] [config]   - 1e-09
[2023-07-01 11:31:05] [config] output-omit-bias: false
[2023-07-01 11:31:05] [config] overwrite: true
[2023-07-01 11:31:05] [config] precision:
[2023-07-01 11:31:05] [config]   - float32
[2023-07-01 11:31:05] [config]   - float32
[2023-07-01 11:31:05] [config] pretrained-model: ""
[2023-07-01 11:31:05] [config] quantize-biases: false
[2023-07-01 11:31:05] [config] quantize-bits: 0
[2023-07-01 11:31:05] [config] quantize-log-based: false
[2023-07-01 11:31:05] [config] quantize-optimization-steps: 0
[2023-07-01 11:31:05] [config] quiet: false
[2023-07-01 11:31:05] [config] quiet-translation: true
[2023-07-01 11:31:05] [config] relative-paths: false
[2023-07-01 11:31:05] [config] right-left: false
[2023-07-01 11:31:05] [config] save-freq: 10000u
[2023-07-01 11:31:05] [config] seed: 1234
[2023-07-01 11:31:05] [config] sentencepiece-alphas:
[2023-07-01 11:31:05] [config]   []
[2023-07-01 11:31:05] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:31:05] [config] sentencepiece-options: ""
[2023-07-01 11:31:05] [config] sharding: global
[2023-07-01 11:31:05] [config] shuffle: data
[2023-07-01 11:31:05] [config] shuffle-in-ram: false
[2023-07-01 11:31:05] [config] sigterm: save-and-exit
[2023-07-01 11:31:05] [config] skip: false
[2023-07-01 11:31:05] [config] sqlite: ""
[2023-07-01 11:31:05] [config] sqlite-drop: false
[2023-07-01 11:31:05] [config] sync-freq: 200u
[2023-07-01 11:31:05] [config] sync-sgd: true
[2023-07-01 11:31:05] [config] tempdir: /tmp
[2023-07-01 11:31:05] [config] tied-embeddings: false
[2023-07-01 11:31:05] [config] tied-embeddings-all: true
[2023-07-01 11:31:05] [config] tied-embeddings-src: false
[2023-07-01 11:31:05] [config] train-embedder-rank:
[2023-07-01 11:31:05] [config]   []
[2023-07-01 11:31:05] [config] train-sets:
[2023-07-01 11:31:05] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:31:05] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:31:05] [config] transformer-aan-activation: swish
[2023-07-01 11:31:05] [config] transformer-aan-depth: 2
[2023-07-01 11:31:05] [config] transformer-aan-nogate: false
[2023-07-01 11:31:05] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:31:05] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:31:05] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:31:05] [config] transformer-depth-scaling: false
[2023-07-01 11:31:05] [config] transformer-dim-aan: 2048
[2023-07-01 11:31:05] [config] transformer-dim-ffn: 2048
[2023-07-01 11:31:05] [config] transformer-dropout: 0.1
[2023-07-01 11:31:05] [config] transformer-dropout-attention: 0
[2023-07-01 11:31:05] [config] transformer-dropout-ffn: 0
[2023-07-01 11:31:05] [config] transformer-ffn-activation: swish
[2023-07-01 11:31:05] [config] transformer-ffn-depth: 2
[2023-07-01 11:31:05] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:31:05] [config] transformer-heads: 8
[2023-07-01 11:31:05] [config] transformer-no-projection: false
[2023-07-01 11:31:05] [config] transformer-pool: false
[2023-07-01 11:31:05] [config] transformer-postprocess: dan
[2023-07-01 11:31:05] [config] transformer-postprocess-emb: d
[2023-07-01 11:31:05] [config] transformer-postprocess-top: ""
[2023-07-01 11:31:05] [config] transformer-preprocess: ""
[2023-07-01 11:31:05] [config] transformer-tied-layers:
[2023-07-01 11:31:05] [config]   []
[2023-07-01 11:31:05] [config] transformer-train-position-embeddings: false
[2023-07-01 11:31:05] [config] tsv: false
[2023-07-01 11:31:05] [config] tsv-fields: 0
[2023-07-01 11:31:05] [config] type: transformer
[2023-07-01 11:31:05] [config] ulr: false
[2023-07-01 11:31:05] [config] ulr-dim-emb: 0
[2023-07-01 11:31:05] [config] ulr-dropout: 0
[2023-07-01 11:31:05] [config] ulr-keys-vectors: ""
[2023-07-01 11:31:05] [config] ulr-query-vectors: ""
[2023-07-01 11:31:05] [config] ulr-softmax-temperature: 1
[2023-07-01 11:31:05] [config] ulr-trainable-transformation: false
[2023-07-01 11:31:05] [config] unlikelihood-loss: false
[2023-07-01 11:31:05] [config] valid-freq: 50000000
[2023-07-01 11:31:05] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:31:05] [config] valid-max-length: 1000
[2023-07-01 11:31:05] [config] valid-metrics:
[2023-07-01 11:31:05] [config]   - cross-entropy
[2023-07-01 11:31:05] [config]   - translation
[2023-07-01 11:31:05] [config] valid-mini-batch: 64
[2023-07-01 11:31:05] [config] valid-reset-stalled: false
[2023-07-01 11:31:05] [config] valid-script-args:
[2023-07-01 11:31:05] [config]   []
[2023-07-01 11:31:05] [config] valid-script-path: ""
[2023-07-01 11:31:05] [config] valid-sets:
[2023-07-01 11:31:05] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:31:05] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:31:05] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:31:05] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:31:05] [config] vocabs:
[2023-07-01 11:31:05] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:31:05] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:31:05] [config] word-penalty: 0
[2023-07-01 11:31:05] [config] word-scores: false
[2023-07-01 11:31:05] [config] workspace: 2048
[2023-07-01 11:31:05] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:31:05] Using synchronous SGD
[2023-07-01 11:31:05] Synced seed 1234
[2023-07-01 11:31:05] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:31:05] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:31:05] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:31:05] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:31:05] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:31:05] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:31:06] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:31:06] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:31:06] [comm] Using global sharding
[2023-07-01 11:31:06] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:31:06] [training] Using 1 GPUs
[2023-07-01 11:31:06] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:31:06] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:31:06] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:31:06] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:31:14] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:31:14] [valid] No post-processing script given for validating translator
[2023-07-01 11:31:14] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:31:14] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:31:14] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:31:14] [comm] Using global sharding
[2023-07-01 11:31:14] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:31:14] [training] Using 1 GPUs
[2023-07-01 11:31:14] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:31:14] Allocating memory for general optimizer shards
[2023-07-01 11:31:14] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:31:14] Loading Adam parameters
[2023-07-01 11:31:15] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:31:15] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:31:15] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:31:15] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:31:15] [data] Shuffling data
[2023-07-01 11:31:15] [data] Done reading 20,192 sentences
[2023-07-01 11:31:15] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:31:15] Training started
[2023-07-01 11:31:15] Training finished
[2023-07-01 11:31:19] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:31:19] [marian] Running on node20.datos.cluster.uy as process 16922 with command line:
[2023-07-01 11:31:19] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 99 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:31:19] [config] after: 0e
[2023-07-01 11:31:19] [config] after-batches: 0
[2023-07-01 11:31:19] [config] after-epochs: 99
[2023-07-01 11:31:19] [config] all-caps-every: 0
[2023-07-01 11:31:19] [config] allow-unk: false
[2023-07-01 11:31:19] [config] authors: false
[2023-07-01 11:31:19] [config] beam-size: 12
[2023-07-01 11:31:19] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:31:19] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:31:19] [config] bert-masking-fraction: 0.15
[2023-07-01 11:31:19] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:31:19] [config] bert-train-type-embeddings: true
[2023-07-01 11:31:19] [config] bert-type-vocab-size: 2
[2023-07-01 11:31:19] [config] build-info: ""
[2023-07-01 11:31:19] [config] check-gradient-nan: false
[2023-07-01 11:31:19] [config] check-nan: false
[2023-07-01 11:31:19] [config] cite: false
[2023-07-01 11:31:19] [config] clip-norm: 5
[2023-07-01 11:31:19] [config] cost-scaling:
[2023-07-01 11:31:19] [config]   []
[2023-07-01 11:31:19] [config] cost-type: ce-sum
[2023-07-01 11:31:19] [config] cpu-threads: 0
[2023-07-01 11:31:19] [config] data-threads: 8
[2023-07-01 11:31:19] [config] data-weighting: ""
[2023-07-01 11:31:19] [config] data-weighting-type: sentence
[2023-07-01 11:31:19] [config] dec-cell: gru
[2023-07-01 11:31:19] [config] dec-cell-base-depth: 2
[2023-07-01 11:31:19] [config] dec-cell-high-depth: 1
[2023-07-01 11:31:19] [config] dec-depth: 2
[2023-07-01 11:31:19] [config] devices:
[2023-07-01 11:31:19] [config]   - 0
[2023-07-01 11:31:19] [config] dim-emb: 512
[2023-07-01 11:31:19] [config] dim-rnn: 1024
[2023-07-01 11:31:19] [config] dim-vocabs:
[2023-07-01 11:31:19] [config]   - 16384
[2023-07-01 11:31:19] [config]   - 16384
[2023-07-01 11:31:19] [config] disp-first: 0
[2023-07-01 11:31:19] [config] disp-freq: 1000u
[2023-07-01 11:31:19] [config] disp-label-counts: true
[2023-07-01 11:31:19] [config] dropout-rnn: 0
[2023-07-01 11:31:19] [config] dropout-src: 0
[2023-07-01 11:31:19] [config] dropout-trg: 0
[2023-07-01 11:31:19] [config] dump-config: ""
[2023-07-01 11:31:19] [config] dynamic-gradient-scaling:
[2023-07-01 11:31:19] [config]   []
[2023-07-01 11:31:19] [config] early-stopping: 10
[2023-07-01 11:31:19] [config] early-stopping-on: first
[2023-07-01 11:31:19] [config] embedding-fix-src: false
[2023-07-01 11:31:19] [config] embedding-fix-trg: false
[2023-07-01 11:31:19] [config] embedding-normalization: false
[2023-07-01 11:31:19] [config] embedding-vectors:
[2023-07-01 11:31:19] [config]   []
[2023-07-01 11:31:19] [config] enc-cell: gru
[2023-07-01 11:31:19] [config] enc-cell-depth: 1
[2023-07-01 11:31:19] [config] enc-depth: 2
[2023-07-01 11:31:19] [config] enc-type: bidirectional
[2023-07-01 11:31:19] [config] english-title-case-every: 0
[2023-07-01 11:31:19] [config] exponential-smoothing: 0.0001
[2023-07-01 11:31:19] [config] factor-weight: 1
[2023-07-01 11:31:19] [config] factors-combine: sum
[2023-07-01 11:31:19] [config] factors-dim-emb: 0
[2023-07-01 11:31:19] [config] gradient-checkpointing: false
[2023-07-01 11:31:19] [config] gradient-norm-average-window: 100
[2023-07-01 11:31:19] [config] guided-alignment: none
[2023-07-01 11:31:19] [config] guided-alignment-cost: mse
[2023-07-01 11:31:19] [config] guided-alignment-weight: 0.1
[2023-07-01 11:31:19] [config] ignore-model-config: false
[2023-07-01 11:31:19] [config] input-types:
[2023-07-01 11:31:19] [config]   []
[2023-07-01 11:31:19] [config] interpolate-env-vars: false
[2023-07-01 11:31:19] [config] keep-best: false
[2023-07-01 11:31:19] [config] label-smoothing: 0.1
[2023-07-01 11:31:19] [config] layer-normalization: false
[2023-07-01 11:31:19] [config] learn-rate: 0.0003
[2023-07-01 11:31:19] [config] lemma-dependency: ""
[2023-07-01 11:31:19] [config] lemma-dim-emb: 0
[2023-07-01 11:31:19] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:31:19] [config] log-level: info
[2023-07-01 11:31:19] [config] log-time-zone: ""
[2023-07-01 11:31:19] [config] logical-epoch:
[2023-07-01 11:31:19] [config]   - 1e
[2023-07-01 11:31:19] [config]   - 0
[2023-07-01 11:31:19] [config] lr-decay: 0
[2023-07-01 11:31:19] [config] lr-decay-freq: 50000
[2023-07-01 11:31:19] [config] lr-decay-inv-sqrt:
[2023-07-01 11:31:19] [config]   - 16000
[2023-07-01 11:31:19] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:31:19] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:31:19] [config] lr-decay-start:
[2023-07-01 11:31:19] [config]   - 10
[2023-07-01 11:31:19] [config]   - 1
[2023-07-01 11:31:19] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:31:19] [config] lr-report: true
[2023-07-01 11:31:19] [config] lr-warmup: 16000
[2023-07-01 11:31:19] [config] lr-warmup-at-reload: false
[2023-07-01 11:31:19] [config] lr-warmup-cycle: false
[2023-07-01 11:31:19] [config] lr-warmup-start-rate: 0
[2023-07-01 11:31:19] [config] max-length: 100
[2023-07-01 11:31:19] [config] max-length-crop: false
[2023-07-01 11:31:19] [config] max-length-factor: 3
[2023-07-01 11:31:19] [config] maxi-batch: 100
[2023-07-01 11:31:19] [config] maxi-batch-sort: trg
[2023-07-01 11:31:19] [config] mini-batch: 1000
[2023-07-01 11:31:19] [config] mini-batch-fit: true
[2023-07-01 11:31:19] [config] mini-batch-fit-step: 10
[2023-07-01 11:31:19] [config] mini-batch-round-up: true
[2023-07-01 11:31:19] [config] mini-batch-track-lr: false
[2023-07-01 11:31:19] [config] mini-batch-warmup: 0
[2023-07-01 11:31:19] [config] mini-batch-words: 0
[2023-07-01 11:31:19] [config] mini-batch-words-ref: 0
[2023-07-01 11:31:19] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:31:19] [config] multi-loss-type: sum
[2023-07-01 11:31:19] [config] n-best: false
[2023-07-01 11:31:19] [config] no-nccl: false
[2023-07-01 11:31:19] [config] no-reload: false
[2023-07-01 11:31:19] [config] no-restore-corpus: false
[2023-07-01 11:31:19] [config] normalize: 1
[2023-07-01 11:31:19] [config] normalize-gradient: false
[2023-07-01 11:31:19] [config] num-devices: 0
[2023-07-01 11:31:19] [config] optimizer: adam
[2023-07-01 11:31:19] [config] optimizer-delay: 1
[2023-07-01 11:31:19] [config] optimizer-params:
[2023-07-01 11:31:19] [config]   - 0.9
[2023-07-01 11:31:19] [config]   - 0.98
[2023-07-01 11:31:19] [config]   - 1e-09
[2023-07-01 11:31:19] [config] output-omit-bias: false
[2023-07-01 11:31:19] [config] overwrite: true
[2023-07-01 11:31:19] [config] precision:
[2023-07-01 11:31:19] [config]   - float32
[2023-07-01 11:31:19] [config]   - float32
[2023-07-01 11:31:19] [config] pretrained-model: ""
[2023-07-01 11:31:19] [config] quantize-biases: false
[2023-07-01 11:31:19] [config] quantize-bits: 0
[2023-07-01 11:31:19] [config] quantize-log-based: false
[2023-07-01 11:31:19] [config] quantize-optimization-steps: 0
[2023-07-01 11:31:19] [config] quiet: false
[2023-07-01 11:31:19] [config] quiet-translation: true
[2023-07-01 11:31:19] [config] relative-paths: false
[2023-07-01 11:31:19] [config] right-left: false
[2023-07-01 11:31:19] [config] save-freq: 10000u
[2023-07-01 11:31:19] [config] seed: 1234
[2023-07-01 11:31:19] [config] sentencepiece-alphas:
[2023-07-01 11:31:19] [config]   []
[2023-07-01 11:31:19] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:31:19] [config] sentencepiece-options: ""
[2023-07-01 11:31:19] [config] sharding: global
[2023-07-01 11:31:19] [config] shuffle: data
[2023-07-01 11:31:19] [config] shuffle-in-ram: false
[2023-07-01 11:31:19] [config] sigterm: save-and-exit
[2023-07-01 11:31:19] [config] skip: false
[2023-07-01 11:31:19] [config] sqlite: ""
[2023-07-01 11:31:19] [config] sqlite-drop: false
[2023-07-01 11:31:19] [config] sync-freq: 200u
[2023-07-01 11:31:19] [config] sync-sgd: true
[2023-07-01 11:31:19] [config] tempdir: /tmp
[2023-07-01 11:31:19] [config] tied-embeddings: false
[2023-07-01 11:31:19] [config] tied-embeddings-all: true
[2023-07-01 11:31:19] [config] tied-embeddings-src: false
[2023-07-01 11:31:19] [config] train-embedder-rank:
[2023-07-01 11:31:19] [config]   []
[2023-07-01 11:31:19] [config] train-sets:
[2023-07-01 11:31:19] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:31:19] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:31:19] [config] transformer-aan-activation: swish
[2023-07-01 11:31:19] [config] transformer-aan-depth: 2
[2023-07-01 11:31:19] [config] transformer-aan-nogate: false
[2023-07-01 11:31:19] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:31:19] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:31:19] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:31:19] [config] transformer-depth-scaling: false
[2023-07-01 11:31:19] [config] transformer-dim-aan: 2048
[2023-07-01 11:31:19] [config] transformer-dim-ffn: 2048
[2023-07-01 11:31:19] [config] transformer-dropout: 0.1
[2023-07-01 11:31:19] [config] transformer-dropout-attention: 0
[2023-07-01 11:31:19] [config] transformer-dropout-ffn: 0
[2023-07-01 11:31:19] [config] transformer-ffn-activation: swish
[2023-07-01 11:31:19] [config] transformer-ffn-depth: 2
[2023-07-01 11:31:19] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:31:19] [config] transformer-heads: 8
[2023-07-01 11:31:19] [config] transformer-no-projection: false
[2023-07-01 11:31:19] [config] transformer-pool: false
[2023-07-01 11:31:19] [config] transformer-postprocess: dan
[2023-07-01 11:31:19] [config] transformer-postprocess-emb: d
[2023-07-01 11:31:19] [config] transformer-postprocess-top: ""
[2023-07-01 11:31:19] [config] transformer-preprocess: ""
[2023-07-01 11:31:19] [config] transformer-tied-layers:
[2023-07-01 11:31:19] [config]   []
[2023-07-01 11:31:19] [config] transformer-train-position-embeddings: false
[2023-07-01 11:31:19] [config] tsv: false
[2023-07-01 11:31:19] [config] tsv-fields: 0
[2023-07-01 11:31:19] [config] type: transformer
[2023-07-01 11:31:19] [config] ulr: false
[2023-07-01 11:31:19] [config] ulr-dim-emb: 0
[2023-07-01 11:31:19] [config] ulr-dropout: 0
[2023-07-01 11:31:19] [config] ulr-keys-vectors: ""
[2023-07-01 11:31:19] [config] ulr-query-vectors: ""
[2023-07-01 11:31:19] [config] ulr-softmax-temperature: 1
[2023-07-01 11:31:19] [config] ulr-trainable-transformation: false
[2023-07-01 11:31:19] [config] unlikelihood-loss: false
[2023-07-01 11:31:19] [config] valid-freq: 50000000
[2023-07-01 11:31:19] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:31:19] [config] valid-max-length: 1000
[2023-07-01 11:31:19] [config] valid-metrics:
[2023-07-01 11:31:19] [config]   - cross-entropy
[2023-07-01 11:31:19] [config]   - translation
[2023-07-01 11:31:19] [config] valid-mini-batch: 64
[2023-07-01 11:31:19] [config] valid-reset-stalled: false
[2023-07-01 11:31:19] [config] valid-script-args:
[2023-07-01 11:31:19] [config]   []
[2023-07-01 11:31:19] [config] valid-script-path: ""
[2023-07-01 11:31:19] [config] valid-sets:
[2023-07-01 11:31:19] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:31:19] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:31:19] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:31:19] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:31:19] [config] vocabs:
[2023-07-01 11:31:19] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:31:19] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:31:19] [config] word-penalty: 0
[2023-07-01 11:31:19] [config] word-scores: false
[2023-07-01 11:31:19] [config] workspace: 2048
[2023-07-01 11:31:19] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:31:19] Using synchronous SGD
[2023-07-01 11:31:19] Synced seed 1234
[2023-07-01 11:31:19] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:31:19] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:31:19] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:31:19] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:31:19] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:31:19] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:31:20] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:31:20] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:31:20] [comm] Using global sharding
[2023-07-01 11:31:20] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:31:20] [training] Using 1 GPUs
[2023-07-01 11:31:20] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:31:20] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:31:20] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:31:20] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:31:28] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:31:28] [valid] No post-processing script given for validating translator
[2023-07-01 11:31:28] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:31:28] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:31:28] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:31:28] [comm] Using global sharding
[2023-07-01 11:31:28] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:31:28] [training] Using 1 GPUs
[2023-07-01 11:31:28] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:31:28] Allocating memory for general optimizer shards
[2023-07-01 11:31:28] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:31:28] Loading Adam parameters
[2023-07-01 11:31:28] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:31:28] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:31:28] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:31:28] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:31:28] [data] Shuffling data
[2023-07-01 11:31:29] [data] Done reading 20,192 sentences
[2023-07-01 11:31:29] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:31:29] Training started
[2023-07-01 11:31:29] Training finished
[2023-07-01 11:31:32] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:31:32] [marian] Running on node20.datos.cluster.uy as process 16980 with command line:
[2023-07-01 11:31:32] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 100 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:31:32] [config] after: 0e
[2023-07-01 11:31:32] [config] after-batches: 0
[2023-07-01 11:31:32] [config] after-epochs: 100
[2023-07-01 11:31:32] [config] all-caps-every: 0
[2023-07-01 11:31:32] [config] allow-unk: false
[2023-07-01 11:31:32] [config] authors: false
[2023-07-01 11:31:32] [config] beam-size: 12
[2023-07-01 11:31:32] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:31:32] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:31:32] [config] bert-masking-fraction: 0.15
[2023-07-01 11:31:32] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:31:32] [config] bert-train-type-embeddings: true
[2023-07-01 11:31:32] [config] bert-type-vocab-size: 2
[2023-07-01 11:31:32] [config] build-info: ""
[2023-07-01 11:31:32] [config] check-gradient-nan: false
[2023-07-01 11:31:32] [config] check-nan: false
[2023-07-01 11:31:32] [config] cite: false
[2023-07-01 11:31:32] [config] clip-norm: 5
[2023-07-01 11:31:32] [config] cost-scaling:
[2023-07-01 11:31:32] [config]   []
[2023-07-01 11:31:32] [config] cost-type: ce-sum
[2023-07-01 11:31:32] [config] cpu-threads: 0
[2023-07-01 11:31:32] [config] data-threads: 8
[2023-07-01 11:31:32] [config] data-weighting: ""
[2023-07-01 11:31:32] [config] data-weighting-type: sentence
[2023-07-01 11:31:32] [config] dec-cell: gru
[2023-07-01 11:31:32] [config] dec-cell-base-depth: 2
[2023-07-01 11:31:32] [config] dec-cell-high-depth: 1
[2023-07-01 11:31:32] [config] dec-depth: 2
[2023-07-01 11:31:32] [config] devices:
[2023-07-01 11:31:32] [config]   - 0
[2023-07-01 11:31:32] [config] dim-emb: 512
[2023-07-01 11:31:32] [config] dim-rnn: 1024
[2023-07-01 11:31:32] [config] dim-vocabs:
[2023-07-01 11:31:32] [config]   - 16384
[2023-07-01 11:31:32] [config]   - 16384
[2023-07-01 11:31:32] [config] disp-first: 0
[2023-07-01 11:31:32] [config] disp-freq: 1000u
[2023-07-01 11:31:32] [config] disp-label-counts: true
[2023-07-01 11:31:32] [config] dropout-rnn: 0
[2023-07-01 11:31:32] [config] dropout-src: 0
[2023-07-01 11:31:32] [config] dropout-trg: 0
[2023-07-01 11:31:32] [config] dump-config: ""
[2023-07-01 11:31:32] [config] dynamic-gradient-scaling:
[2023-07-01 11:31:32] [config]   []
[2023-07-01 11:31:32] [config] early-stopping: 10
[2023-07-01 11:31:32] [config] early-stopping-on: first
[2023-07-01 11:31:32] [config] embedding-fix-src: false
[2023-07-01 11:31:32] [config] embedding-fix-trg: false
[2023-07-01 11:31:32] [config] embedding-normalization: false
[2023-07-01 11:31:32] [config] embedding-vectors:
[2023-07-01 11:31:32] [config]   []
[2023-07-01 11:31:32] [config] enc-cell: gru
[2023-07-01 11:31:32] [config] enc-cell-depth: 1
[2023-07-01 11:31:32] [config] enc-depth: 2
[2023-07-01 11:31:32] [config] enc-type: bidirectional
[2023-07-01 11:31:32] [config] english-title-case-every: 0
[2023-07-01 11:31:32] [config] exponential-smoothing: 0.0001
[2023-07-01 11:31:32] [config] factor-weight: 1
[2023-07-01 11:31:32] [config] factors-combine: sum
[2023-07-01 11:31:32] [config] factors-dim-emb: 0
[2023-07-01 11:31:32] [config] gradient-checkpointing: false
[2023-07-01 11:31:32] [config] gradient-norm-average-window: 100
[2023-07-01 11:31:32] [config] guided-alignment: none
[2023-07-01 11:31:32] [config] guided-alignment-cost: mse
[2023-07-01 11:31:32] [config] guided-alignment-weight: 0.1
[2023-07-01 11:31:32] [config] ignore-model-config: false
[2023-07-01 11:31:32] [config] input-types:
[2023-07-01 11:31:32] [config]   []
[2023-07-01 11:31:32] [config] interpolate-env-vars: false
[2023-07-01 11:31:32] [config] keep-best: false
[2023-07-01 11:31:32] [config] label-smoothing: 0.1
[2023-07-01 11:31:32] [config] layer-normalization: false
[2023-07-01 11:31:32] [config] learn-rate: 0.0003
[2023-07-01 11:31:32] [config] lemma-dependency: ""
[2023-07-01 11:31:32] [config] lemma-dim-emb: 0
[2023-07-01 11:31:32] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:31:32] [config] log-level: info
[2023-07-01 11:31:32] [config] log-time-zone: ""
[2023-07-01 11:31:32] [config] logical-epoch:
[2023-07-01 11:31:32] [config]   - 1e
[2023-07-01 11:31:32] [config]   - 0
[2023-07-01 11:31:32] [config] lr-decay: 0
[2023-07-01 11:31:32] [config] lr-decay-freq: 50000
[2023-07-01 11:31:32] [config] lr-decay-inv-sqrt:
[2023-07-01 11:31:32] [config]   - 16000
[2023-07-01 11:31:32] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:31:32] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:31:32] [config] lr-decay-start:
[2023-07-01 11:31:32] [config]   - 10
[2023-07-01 11:31:32] [config]   - 1
[2023-07-01 11:31:32] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:31:32] [config] lr-report: true
[2023-07-01 11:31:32] [config] lr-warmup: 16000
[2023-07-01 11:31:32] [config] lr-warmup-at-reload: false
[2023-07-01 11:31:32] [config] lr-warmup-cycle: false
[2023-07-01 11:31:32] [config] lr-warmup-start-rate: 0
[2023-07-01 11:31:32] [config] max-length: 100
[2023-07-01 11:31:32] [config] max-length-crop: false
[2023-07-01 11:31:32] [config] max-length-factor: 3
[2023-07-01 11:31:32] [config] maxi-batch: 100
[2023-07-01 11:31:32] [config] maxi-batch-sort: trg
[2023-07-01 11:31:32] [config] mini-batch: 1000
[2023-07-01 11:31:32] [config] mini-batch-fit: true
[2023-07-01 11:31:32] [config] mini-batch-fit-step: 10
[2023-07-01 11:31:32] [config] mini-batch-round-up: true
[2023-07-01 11:31:32] [config] mini-batch-track-lr: false
[2023-07-01 11:31:32] [config] mini-batch-warmup: 0
[2023-07-01 11:31:32] [config] mini-batch-words: 0
[2023-07-01 11:31:32] [config] mini-batch-words-ref: 0
[2023-07-01 11:31:32] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:31:32] [config] multi-loss-type: sum
[2023-07-01 11:31:32] [config] n-best: false
[2023-07-01 11:31:32] [config] no-nccl: false
[2023-07-01 11:31:32] [config] no-reload: false
[2023-07-01 11:31:32] [config] no-restore-corpus: false
[2023-07-01 11:31:32] [config] normalize: 1
[2023-07-01 11:31:32] [config] normalize-gradient: false
[2023-07-01 11:31:32] [config] num-devices: 0
[2023-07-01 11:31:32] [config] optimizer: adam
[2023-07-01 11:31:32] [config] optimizer-delay: 1
[2023-07-01 11:31:32] [config] optimizer-params:
[2023-07-01 11:31:32] [config]   - 0.9
[2023-07-01 11:31:32] [config]   - 0.98
[2023-07-01 11:31:32] [config]   - 1e-09
[2023-07-01 11:31:32] [config] output-omit-bias: false
[2023-07-01 11:31:32] [config] overwrite: true
[2023-07-01 11:31:32] [config] precision:
[2023-07-01 11:31:32] [config]   - float32
[2023-07-01 11:31:32] [config]   - float32
[2023-07-01 11:31:32] [config] pretrained-model: ""
[2023-07-01 11:31:32] [config] quantize-biases: false
[2023-07-01 11:31:32] [config] quantize-bits: 0
[2023-07-01 11:31:32] [config] quantize-log-based: false
[2023-07-01 11:31:32] [config] quantize-optimization-steps: 0
[2023-07-01 11:31:32] [config] quiet: false
[2023-07-01 11:31:32] [config] quiet-translation: true
[2023-07-01 11:31:32] [config] relative-paths: false
[2023-07-01 11:31:32] [config] right-left: false
[2023-07-01 11:31:32] [config] save-freq: 10000u
[2023-07-01 11:31:32] [config] seed: 1234
[2023-07-01 11:31:32] [config] sentencepiece-alphas:
[2023-07-01 11:31:32] [config]   []
[2023-07-01 11:31:32] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:31:32] [config] sentencepiece-options: ""
[2023-07-01 11:31:32] [config] sharding: global
[2023-07-01 11:31:32] [config] shuffle: data
[2023-07-01 11:31:32] [config] shuffle-in-ram: false
[2023-07-01 11:31:32] [config] sigterm: save-and-exit
[2023-07-01 11:31:32] [config] skip: false
[2023-07-01 11:31:32] [config] sqlite: ""
[2023-07-01 11:31:32] [config] sqlite-drop: false
[2023-07-01 11:31:32] [config] sync-freq: 200u
[2023-07-01 11:31:32] [config] sync-sgd: true
[2023-07-01 11:31:32] [config] tempdir: /tmp
[2023-07-01 11:31:32] [config] tied-embeddings: false
[2023-07-01 11:31:32] [config] tied-embeddings-all: true
[2023-07-01 11:31:32] [config] tied-embeddings-src: false
[2023-07-01 11:31:32] [config] train-embedder-rank:
[2023-07-01 11:31:32] [config]   []
[2023-07-01 11:31:32] [config] train-sets:
[2023-07-01 11:31:32] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:31:32] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:31:32] [config] transformer-aan-activation: swish
[2023-07-01 11:31:32] [config] transformer-aan-depth: 2
[2023-07-01 11:31:32] [config] transformer-aan-nogate: false
[2023-07-01 11:31:32] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:31:32] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:31:32] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:31:32] [config] transformer-depth-scaling: false
[2023-07-01 11:31:32] [config] transformer-dim-aan: 2048
[2023-07-01 11:31:32] [config] transformer-dim-ffn: 2048
[2023-07-01 11:31:32] [config] transformer-dropout: 0.1
[2023-07-01 11:31:32] [config] transformer-dropout-attention: 0
[2023-07-01 11:31:32] [config] transformer-dropout-ffn: 0
[2023-07-01 11:31:32] [config] transformer-ffn-activation: swish
[2023-07-01 11:31:32] [config] transformer-ffn-depth: 2
[2023-07-01 11:31:32] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:31:32] [config] transformer-heads: 8
[2023-07-01 11:31:32] [config] transformer-no-projection: false
[2023-07-01 11:31:32] [config] transformer-pool: false
[2023-07-01 11:31:32] [config] transformer-postprocess: dan
[2023-07-01 11:31:32] [config] transformer-postprocess-emb: d
[2023-07-01 11:31:32] [config] transformer-postprocess-top: ""
[2023-07-01 11:31:32] [config] transformer-preprocess: ""
[2023-07-01 11:31:32] [config] transformer-tied-layers:
[2023-07-01 11:31:32] [config]   []
[2023-07-01 11:31:32] [config] transformer-train-position-embeddings: false
[2023-07-01 11:31:32] [config] tsv: false
[2023-07-01 11:31:32] [config] tsv-fields: 0
[2023-07-01 11:31:32] [config] type: transformer
[2023-07-01 11:31:32] [config] ulr: false
[2023-07-01 11:31:32] [config] ulr-dim-emb: 0
[2023-07-01 11:31:32] [config] ulr-dropout: 0
[2023-07-01 11:31:32] [config] ulr-keys-vectors: ""
[2023-07-01 11:31:32] [config] ulr-query-vectors: ""
[2023-07-01 11:31:32] [config] ulr-softmax-temperature: 1
[2023-07-01 11:31:32] [config] ulr-trainable-transformation: false
[2023-07-01 11:31:32] [config] unlikelihood-loss: false
[2023-07-01 11:31:32] [config] valid-freq: 50000000
[2023-07-01 11:31:32] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:31:32] [config] valid-max-length: 1000
[2023-07-01 11:31:32] [config] valid-metrics:
[2023-07-01 11:31:32] [config]   - cross-entropy
[2023-07-01 11:31:32] [config]   - translation
[2023-07-01 11:31:32] [config] valid-mini-batch: 64
[2023-07-01 11:31:32] [config] valid-reset-stalled: false
[2023-07-01 11:31:32] [config] valid-script-args:
[2023-07-01 11:31:32] [config]   []
[2023-07-01 11:31:32] [config] valid-script-path: ""
[2023-07-01 11:31:32] [config] valid-sets:
[2023-07-01 11:31:32] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:31:32] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:31:32] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:31:32] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:31:32] [config] vocabs:
[2023-07-01 11:31:32] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:31:32] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:31:32] [config] word-penalty: 0
[2023-07-01 11:31:32] [config] word-scores: false
[2023-07-01 11:31:32] [config] workspace: 2048
[2023-07-01 11:31:32] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:31:32] Using synchronous SGD
[2023-07-01 11:31:32] Synced seed 1234
[2023-07-01 11:31:32] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:31:32] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:31:32] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:31:32] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:31:32] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:31:32] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:31:33] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:31:33] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:31:33] [comm] Using global sharding
[2023-07-01 11:31:33] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:31:33] [training] Using 1 GPUs
[2023-07-01 11:31:33] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:31:33] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:31:34] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:31:34] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:31:41] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:31:41] [valid] No post-processing script given for validating translator
[2023-07-01 11:31:41] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:31:41] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:31:41] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:31:41] [comm] Using global sharding
[2023-07-01 11:31:41] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:31:41] [training] Using 1 GPUs
[2023-07-01 11:31:41] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:31:42] Allocating memory for general optimizer shards
[2023-07-01 11:31:42] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:31:42] Loading Adam parameters
[2023-07-01 11:31:42] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:31:42] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:31:42] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:31:42] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:31:42] [data] Shuffling data
[2023-07-01 11:31:42] [data] Done reading 20,192 sentences
[2023-07-01 11:31:42] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:31:42] Training started
[2023-07-01 11:31:42] Training finished
[2023-07-01 11:31:46] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:31:46] [marian] Running on node20.datos.cluster.uy as process 17038 with command line:
[2023-07-01 11:31:46] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 101 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:31:46] [config] after: 0e
[2023-07-01 11:31:46] [config] after-batches: 0
[2023-07-01 11:31:46] [config] after-epochs: 101
[2023-07-01 11:31:46] [config] all-caps-every: 0
[2023-07-01 11:31:46] [config] allow-unk: false
[2023-07-01 11:31:46] [config] authors: false
[2023-07-01 11:31:46] [config] beam-size: 12
[2023-07-01 11:31:46] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:31:46] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:31:46] [config] bert-masking-fraction: 0.15
[2023-07-01 11:31:46] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:31:46] [config] bert-train-type-embeddings: true
[2023-07-01 11:31:46] [config] bert-type-vocab-size: 2
[2023-07-01 11:31:46] [config] build-info: ""
[2023-07-01 11:31:46] [config] check-gradient-nan: false
[2023-07-01 11:31:46] [config] check-nan: false
[2023-07-01 11:31:46] [config] cite: false
[2023-07-01 11:31:46] [config] clip-norm: 5
[2023-07-01 11:31:46] [config] cost-scaling:
[2023-07-01 11:31:46] [config]   []
[2023-07-01 11:31:46] [config] cost-type: ce-sum
[2023-07-01 11:31:46] [config] cpu-threads: 0
[2023-07-01 11:31:46] [config] data-threads: 8
[2023-07-01 11:31:46] [config] data-weighting: ""
[2023-07-01 11:31:46] [config] data-weighting-type: sentence
[2023-07-01 11:31:46] [config] dec-cell: gru
[2023-07-01 11:31:46] [config] dec-cell-base-depth: 2
[2023-07-01 11:31:46] [config] dec-cell-high-depth: 1
[2023-07-01 11:31:46] [config] dec-depth: 2
[2023-07-01 11:31:46] [config] devices:
[2023-07-01 11:31:46] [config]   - 0
[2023-07-01 11:31:46] [config] dim-emb: 512
[2023-07-01 11:31:46] [config] dim-rnn: 1024
[2023-07-01 11:31:46] [config] dim-vocabs:
[2023-07-01 11:31:46] [config]   - 16384
[2023-07-01 11:31:46] [config]   - 16384
[2023-07-01 11:31:46] [config] disp-first: 0
[2023-07-01 11:31:46] [config] disp-freq: 1000u
[2023-07-01 11:31:46] [config] disp-label-counts: true
[2023-07-01 11:31:46] [config] dropout-rnn: 0
[2023-07-01 11:31:46] [config] dropout-src: 0
[2023-07-01 11:31:46] [config] dropout-trg: 0
[2023-07-01 11:31:46] [config] dump-config: ""
[2023-07-01 11:31:46] [config] dynamic-gradient-scaling:
[2023-07-01 11:31:46] [config]   []
[2023-07-01 11:31:46] [config] early-stopping: 10
[2023-07-01 11:31:46] [config] early-stopping-on: first
[2023-07-01 11:31:46] [config] embedding-fix-src: false
[2023-07-01 11:31:46] [config] embedding-fix-trg: false
[2023-07-01 11:31:46] [config] embedding-normalization: false
[2023-07-01 11:31:46] [config] embedding-vectors:
[2023-07-01 11:31:46] [config]   []
[2023-07-01 11:31:46] [config] enc-cell: gru
[2023-07-01 11:31:46] [config] enc-cell-depth: 1
[2023-07-01 11:31:46] [config] enc-depth: 2
[2023-07-01 11:31:46] [config] enc-type: bidirectional
[2023-07-01 11:31:46] [config] english-title-case-every: 0
[2023-07-01 11:31:46] [config] exponential-smoothing: 0.0001
[2023-07-01 11:31:46] [config] factor-weight: 1
[2023-07-01 11:31:46] [config] factors-combine: sum
[2023-07-01 11:31:46] [config] factors-dim-emb: 0
[2023-07-01 11:31:46] [config] gradient-checkpointing: false
[2023-07-01 11:31:46] [config] gradient-norm-average-window: 100
[2023-07-01 11:31:46] [config] guided-alignment: none
[2023-07-01 11:31:46] [config] guided-alignment-cost: mse
[2023-07-01 11:31:46] [config] guided-alignment-weight: 0.1
[2023-07-01 11:31:46] [config] ignore-model-config: false
[2023-07-01 11:31:46] [config] input-types:
[2023-07-01 11:31:46] [config]   []
[2023-07-01 11:31:46] [config] interpolate-env-vars: false
[2023-07-01 11:31:46] [config] keep-best: false
[2023-07-01 11:31:46] [config] label-smoothing: 0.1
[2023-07-01 11:31:46] [config] layer-normalization: false
[2023-07-01 11:31:46] [config] learn-rate: 0.0003
[2023-07-01 11:31:46] [config] lemma-dependency: ""
[2023-07-01 11:31:46] [config] lemma-dim-emb: 0
[2023-07-01 11:31:46] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:31:46] [config] log-level: info
[2023-07-01 11:31:46] [config] log-time-zone: ""
[2023-07-01 11:31:46] [config] logical-epoch:
[2023-07-01 11:31:46] [config]   - 1e
[2023-07-01 11:31:46] [config]   - 0
[2023-07-01 11:31:46] [config] lr-decay: 0
[2023-07-01 11:31:46] [config] lr-decay-freq: 50000
[2023-07-01 11:31:46] [config] lr-decay-inv-sqrt:
[2023-07-01 11:31:46] [config]   - 16000
[2023-07-01 11:31:46] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:31:46] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:31:46] [config] lr-decay-start:
[2023-07-01 11:31:46] [config]   - 10
[2023-07-01 11:31:46] [config]   - 1
[2023-07-01 11:31:46] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:31:46] [config] lr-report: true
[2023-07-01 11:31:46] [config] lr-warmup: 16000
[2023-07-01 11:31:46] [config] lr-warmup-at-reload: false
[2023-07-01 11:31:46] [config] lr-warmup-cycle: false
[2023-07-01 11:31:46] [config] lr-warmup-start-rate: 0
[2023-07-01 11:31:46] [config] max-length: 100
[2023-07-01 11:31:46] [config] max-length-crop: false
[2023-07-01 11:31:46] [config] max-length-factor: 3
[2023-07-01 11:31:46] [config] maxi-batch: 100
[2023-07-01 11:31:46] [config] maxi-batch-sort: trg
[2023-07-01 11:31:46] [config] mini-batch: 1000
[2023-07-01 11:31:46] [config] mini-batch-fit: true
[2023-07-01 11:31:46] [config] mini-batch-fit-step: 10
[2023-07-01 11:31:46] [config] mini-batch-round-up: true
[2023-07-01 11:31:46] [config] mini-batch-track-lr: false
[2023-07-01 11:31:46] [config] mini-batch-warmup: 0
[2023-07-01 11:31:46] [config] mini-batch-words: 0
[2023-07-01 11:31:46] [config] mini-batch-words-ref: 0
[2023-07-01 11:31:46] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:31:46] [config] multi-loss-type: sum
[2023-07-01 11:31:46] [config] n-best: false
[2023-07-01 11:31:46] [config] no-nccl: false
[2023-07-01 11:31:46] [config] no-reload: false
[2023-07-01 11:31:46] [config] no-restore-corpus: false
[2023-07-01 11:31:46] [config] normalize: 1
[2023-07-01 11:31:46] [config] normalize-gradient: false
[2023-07-01 11:31:46] [config] num-devices: 0
[2023-07-01 11:31:46] [config] optimizer: adam
[2023-07-01 11:31:46] [config] optimizer-delay: 1
[2023-07-01 11:31:46] [config] optimizer-params:
[2023-07-01 11:31:46] [config]   - 0.9
[2023-07-01 11:31:46] [config]   - 0.98
[2023-07-01 11:31:46] [config]   - 1e-09
[2023-07-01 11:31:46] [config] output-omit-bias: false
[2023-07-01 11:31:46] [config] overwrite: true
[2023-07-01 11:31:46] [config] precision:
[2023-07-01 11:31:46] [config]   - float32
[2023-07-01 11:31:46] [config]   - float32
[2023-07-01 11:31:46] [config] pretrained-model: ""
[2023-07-01 11:31:46] [config] quantize-biases: false
[2023-07-01 11:31:46] [config] quantize-bits: 0
[2023-07-01 11:31:46] [config] quantize-log-based: false
[2023-07-01 11:31:46] [config] quantize-optimization-steps: 0
[2023-07-01 11:31:46] [config] quiet: false
[2023-07-01 11:31:46] [config] quiet-translation: true
[2023-07-01 11:31:46] [config] relative-paths: false
[2023-07-01 11:31:46] [config] right-left: false
[2023-07-01 11:31:46] [config] save-freq: 10000u
[2023-07-01 11:31:46] [config] seed: 1234
[2023-07-01 11:31:46] [config] sentencepiece-alphas:
[2023-07-01 11:31:46] [config]   []
[2023-07-01 11:31:46] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:31:46] [config] sentencepiece-options: ""
[2023-07-01 11:31:46] [config] sharding: global
[2023-07-01 11:31:46] [config] shuffle: data
[2023-07-01 11:31:46] [config] shuffle-in-ram: false
[2023-07-01 11:31:46] [config] sigterm: save-and-exit
[2023-07-01 11:31:46] [config] skip: false
[2023-07-01 11:31:46] [config] sqlite: ""
[2023-07-01 11:31:46] [config] sqlite-drop: false
[2023-07-01 11:31:46] [config] sync-freq: 200u
[2023-07-01 11:31:46] [config] sync-sgd: true
[2023-07-01 11:31:46] [config] tempdir: /tmp
[2023-07-01 11:31:46] [config] tied-embeddings: false
[2023-07-01 11:31:46] [config] tied-embeddings-all: true
[2023-07-01 11:31:46] [config] tied-embeddings-src: false
[2023-07-01 11:31:46] [config] train-embedder-rank:
[2023-07-01 11:31:46] [config]   []
[2023-07-01 11:31:46] [config] train-sets:
[2023-07-01 11:31:46] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:31:46] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:31:46] [config] transformer-aan-activation: swish
[2023-07-01 11:31:46] [config] transformer-aan-depth: 2
[2023-07-01 11:31:46] [config] transformer-aan-nogate: false
[2023-07-01 11:31:46] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:31:46] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:31:46] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:31:46] [config] transformer-depth-scaling: false
[2023-07-01 11:31:46] [config] transformer-dim-aan: 2048
[2023-07-01 11:31:46] [config] transformer-dim-ffn: 2048
[2023-07-01 11:31:46] [config] transformer-dropout: 0.1
[2023-07-01 11:31:46] [config] transformer-dropout-attention: 0
[2023-07-01 11:31:46] [config] transformer-dropout-ffn: 0
[2023-07-01 11:31:46] [config] transformer-ffn-activation: swish
[2023-07-01 11:31:46] [config] transformer-ffn-depth: 2
[2023-07-01 11:31:46] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:31:46] [config] transformer-heads: 8
[2023-07-01 11:31:46] [config] transformer-no-projection: false
[2023-07-01 11:31:46] [config] transformer-pool: false
[2023-07-01 11:31:46] [config] transformer-postprocess: dan
[2023-07-01 11:31:46] [config] transformer-postprocess-emb: d
[2023-07-01 11:31:46] [config] transformer-postprocess-top: ""
[2023-07-01 11:31:46] [config] transformer-preprocess: ""
[2023-07-01 11:31:46] [config] transformer-tied-layers:
[2023-07-01 11:31:46] [config]   []
[2023-07-01 11:31:46] [config] transformer-train-position-embeddings: false
[2023-07-01 11:31:46] [config] tsv: false
[2023-07-01 11:31:46] [config] tsv-fields: 0
[2023-07-01 11:31:46] [config] type: transformer
[2023-07-01 11:31:46] [config] ulr: false
[2023-07-01 11:31:46] [config] ulr-dim-emb: 0
[2023-07-01 11:31:46] [config] ulr-dropout: 0
[2023-07-01 11:31:46] [config] ulr-keys-vectors: ""
[2023-07-01 11:31:46] [config] ulr-query-vectors: ""
[2023-07-01 11:31:46] [config] ulr-softmax-temperature: 1
[2023-07-01 11:31:46] [config] ulr-trainable-transformation: false
[2023-07-01 11:31:46] [config] unlikelihood-loss: false
[2023-07-01 11:31:46] [config] valid-freq: 50000000
[2023-07-01 11:31:46] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:31:46] [config] valid-max-length: 1000
[2023-07-01 11:31:46] [config] valid-metrics:
[2023-07-01 11:31:46] [config]   - cross-entropy
[2023-07-01 11:31:46] [config]   - translation
[2023-07-01 11:31:46] [config] valid-mini-batch: 64
[2023-07-01 11:31:46] [config] valid-reset-stalled: false
[2023-07-01 11:31:46] [config] valid-script-args:
[2023-07-01 11:31:46] [config]   []
[2023-07-01 11:31:46] [config] valid-script-path: ""
[2023-07-01 11:31:46] [config] valid-sets:
[2023-07-01 11:31:46] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:31:46] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:31:46] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:31:46] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:31:46] [config] vocabs:
[2023-07-01 11:31:46] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:31:46] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:31:46] [config] word-penalty: 0
[2023-07-01 11:31:46] [config] word-scores: false
[2023-07-01 11:31:46] [config] workspace: 2048
[2023-07-01 11:31:46] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:31:46] Using synchronous SGD
[2023-07-01 11:31:46] Synced seed 1234
[2023-07-01 11:31:46] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:31:46] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:31:46] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:31:46] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:31:46] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:31:46] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:31:47] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:31:47] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:31:47] [comm] Using global sharding
[2023-07-01 11:31:47] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:31:47] [training] Using 1 GPUs
[2023-07-01 11:31:47] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:31:47] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:31:47] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:31:47] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:31:55] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:31:55] [valid] No post-processing script given for validating translator
[2023-07-01 11:31:55] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:31:55] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:31:55] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:31:55] [comm] Using global sharding
[2023-07-01 11:31:55] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:31:55] [training] Using 1 GPUs
[2023-07-01 11:31:55] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:31:55] Allocating memory for general optimizer shards
[2023-07-01 11:31:55] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:31:55] Loading Adam parameters
[2023-07-01 11:31:56] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:31:56] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:31:56] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:31:56] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:31:56] [data] Shuffling data
[2023-07-01 11:31:56] [data] Done reading 20,192 sentences
[2023-07-01 11:31:56] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:31:56] Training started
[2023-07-01 11:31:56] Training finished
[2023-07-01 11:31:59] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:31:59] [marian] Running on node20.datos.cluster.uy as process 17097 with command line:
[2023-07-01 11:31:59] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 102 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:31:59] [config] after: 0e
[2023-07-01 11:31:59] [config] after-batches: 0
[2023-07-01 11:31:59] [config] after-epochs: 102
[2023-07-01 11:31:59] [config] all-caps-every: 0
[2023-07-01 11:31:59] [config] allow-unk: false
[2023-07-01 11:31:59] [config] authors: false
[2023-07-01 11:31:59] [config] beam-size: 12
[2023-07-01 11:31:59] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:31:59] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:31:59] [config] bert-masking-fraction: 0.15
[2023-07-01 11:31:59] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:31:59] [config] bert-train-type-embeddings: true
[2023-07-01 11:31:59] [config] bert-type-vocab-size: 2
[2023-07-01 11:31:59] [config] build-info: ""
[2023-07-01 11:31:59] [config] check-gradient-nan: false
[2023-07-01 11:31:59] [config] check-nan: false
[2023-07-01 11:31:59] [config] cite: false
[2023-07-01 11:31:59] [config] clip-norm: 5
[2023-07-01 11:31:59] [config] cost-scaling:
[2023-07-01 11:31:59] [config]   []
[2023-07-01 11:31:59] [config] cost-type: ce-sum
[2023-07-01 11:31:59] [config] cpu-threads: 0
[2023-07-01 11:31:59] [config] data-threads: 8
[2023-07-01 11:31:59] [config] data-weighting: ""
[2023-07-01 11:31:59] [config] data-weighting-type: sentence
[2023-07-01 11:31:59] [config] dec-cell: gru
[2023-07-01 11:31:59] [config] dec-cell-base-depth: 2
[2023-07-01 11:31:59] [config] dec-cell-high-depth: 1
[2023-07-01 11:31:59] [config] dec-depth: 2
[2023-07-01 11:31:59] [config] devices:
[2023-07-01 11:31:59] [config]   - 0
[2023-07-01 11:31:59] [config] dim-emb: 512
[2023-07-01 11:31:59] [config] dim-rnn: 1024
[2023-07-01 11:31:59] [config] dim-vocabs:
[2023-07-01 11:31:59] [config]   - 16384
[2023-07-01 11:31:59] [config]   - 16384
[2023-07-01 11:31:59] [config] disp-first: 0
[2023-07-01 11:31:59] [config] disp-freq: 1000u
[2023-07-01 11:31:59] [config] disp-label-counts: true
[2023-07-01 11:31:59] [config] dropout-rnn: 0
[2023-07-01 11:31:59] [config] dropout-src: 0
[2023-07-01 11:31:59] [config] dropout-trg: 0
[2023-07-01 11:31:59] [config] dump-config: ""
[2023-07-01 11:31:59] [config] dynamic-gradient-scaling:
[2023-07-01 11:31:59] [config]   []
[2023-07-01 11:31:59] [config] early-stopping: 10
[2023-07-01 11:31:59] [config] early-stopping-on: first
[2023-07-01 11:31:59] [config] embedding-fix-src: false
[2023-07-01 11:31:59] [config] embedding-fix-trg: false
[2023-07-01 11:31:59] [config] embedding-normalization: false
[2023-07-01 11:31:59] [config] embedding-vectors:
[2023-07-01 11:31:59] [config]   []
[2023-07-01 11:31:59] [config] enc-cell: gru
[2023-07-01 11:31:59] [config] enc-cell-depth: 1
[2023-07-01 11:31:59] [config] enc-depth: 2
[2023-07-01 11:31:59] [config] enc-type: bidirectional
[2023-07-01 11:31:59] [config] english-title-case-every: 0
[2023-07-01 11:31:59] [config] exponential-smoothing: 0.0001
[2023-07-01 11:31:59] [config] factor-weight: 1
[2023-07-01 11:31:59] [config] factors-combine: sum
[2023-07-01 11:31:59] [config] factors-dim-emb: 0
[2023-07-01 11:31:59] [config] gradient-checkpointing: false
[2023-07-01 11:31:59] [config] gradient-norm-average-window: 100
[2023-07-01 11:31:59] [config] guided-alignment: none
[2023-07-01 11:31:59] [config] guided-alignment-cost: mse
[2023-07-01 11:31:59] [config] guided-alignment-weight: 0.1
[2023-07-01 11:31:59] [config] ignore-model-config: false
[2023-07-01 11:31:59] [config] input-types:
[2023-07-01 11:31:59] [config]   []
[2023-07-01 11:31:59] [config] interpolate-env-vars: false
[2023-07-01 11:31:59] [config] keep-best: false
[2023-07-01 11:31:59] [config] label-smoothing: 0.1
[2023-07-01 11:31:59] [config] layer-normalization: false
[2023-07-01 11:31:59] [config] learn-rate: 0.0003
[2023-07-01 11:31:59] [config] lemma-dependency: ""
[2023-07-01 11:31:59] [config] lemma-dim-emb: 0
[2023-07-01 11:31:59] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:31:59] [config] log-level: info
[2023-07-01 11:31:59] [config] log-time-zone: ""
[2023-07-01 11:31:59] [config] logical-epoch:
[2023-07-01 11:31:59] [config]   - 1e
[2023-07-01 11:31:59] [config]   - 0
[2023-07-01 11:31:59] [config] lr-decay: 0
[2023-07-01 11:31:59] [config] lr-decay-freq: 50000
[2023-07-01 11:31:59] [config] lr-decay-inv-sqrt:
[2023-07-01 11:31:59] [config]   - 16000
[2023-07-01 11:31:59] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:31:59] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:31:59] [config] lr-decay-start:
[2023-07-01 11:31:59] [config]   - 10
[2023-07-01 11:31:59] [config]   - 1
[2023-07-01 11:31:59] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:31:59] [config] lr-report: true
[2023-07-01 11:31:59] [config] lr-warmup: 16000
[2023-07-01 11:31:59] [config] lr-warmup-at-reload: false
[2023-07-01 11:31:59] [config] lr-warmup-cycle: false
[2023-07-01 11:31:59] [config] lr-warmup-start-rate: 0
[2023-07-01 11:31:59] [config] max-length: 100
[2023-07-01 11:31:59] [config] max-length-crop: false
[2023-07-01 11:31:59] [config] max-length-factor: 3
[2023-07-01 11:31:59] [config] maxi-batch: 100
[2023-07-01 11:31:59] [config] maxi-batch-sort: trg
[2023-07-01 11:31:59] [config] mini-batch: 1000
[2023-07-01 11:31:59] [config] mini-batch-fit: true
[2023-07-01 11:31:59] [config] mini-batch-fit-step: 10
[2023-07-01 11:31:59] [config] mini-batch-round-up: true
[2023-07-01 11:31:59] [config] mini-batch-track-lr: false
[2023-07-01 11:31:59] [config] mini-batch-warmup: 0
[2023-07-01 11:31:59] [config] mini-batch-words: 0
[2023-07-01 11:31:59] [config] mini-batch-words-ref: 0
[2023-07-01 11:31:59] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:31:59] [config] multi-loss-type: sum
[2023-07-01 11:31:59] [config] n-best: false
[2023-07-01 11:31:59] [config] no-nccl: false
[2023-07-01 11:31:59] [config] no-reload: false
[2023-07-01 11:31:59] [config] no-restore-corpus: false
[2023-07-01 11:31:59] [config] normalize: 1
[2023-07-01 11:31:59] [config] normalize-gradient: false
[2023-07-01 11:31:59] [config] num-devices: 0
[2023-07-01 11:31:59] [config] optimizer: adam
[2023-07-01 11:31:59] [config] optimizer-delay: 1
[2023-07-01 11:31:59] [config] optimizer-params:
[2023-07-01 11:31:59] [config]   - 0.9
[2023-07-01 11:31:59] [config]   - 0.98
[2023-07-01 11:31:59] [config]   - 1e-09
[2023-07-01 11:31:59] [config] output-omit-bias: false
[2023-07-01 11:31:59] [config] overwrite: true
[2023-07-01 11:31:59] [config] precision:
[2023-07-01 11:31:59] [config]   - float32
[2023-07-01 11:31:59] [config]   - float32
[2023-07-01 11:31:59] [config] pretrained-model: ""
[2023-07-01 11:31:59] [config] quantize-biases: false
[2023-07-01 11:31:59] [config] quantize-bits: 0
[2023-07-01 11:31:59] [config] quantize-log-based: false
[2023-07-01 11:31:59] [config] quantize-optimization-steps: 0
[2023-07-01 11:31:59] [config] quiet: false
[2023-07-01 11:31:59] [config] quiet-translation: true
[2023-07-01 11:31:59] [config] relative-paths: false
[2023-07-01 11:31:59] [config] right-left: false
[2023-07-01 11:31:59] [config] save-freq: 10000u
[2023-07-01 11:31:59] [config] seed: 1234
[2023-07-01 11:31:59] [config] sentencepiece-alphas:
[2023-07-01 11:31:59] [config]   []
[2023-07-01 11:31:59] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:31:59] [config] sentencepiece-options: ""
[2023-07-01 11:31:59] [config] sharding: global
[2023-07-01 11:31:59] [config] shuffle: data
[2023-07-01 11:31:59] [config] shuffle-in-ram: false
[2023-07-01 11:31:59] [config] sigterm: save-and-exit
[2023-07-01 11:31:59] [config] skip: false
[2023-07-01 11:31:59] [config] sqlite: ""
[2023-07-01 11:31:59] [config] sqlite-drop: false
[2023-07-01 11:31:59] [config] sync-freq: 200u
[2023-07-01 11:31:59] [config] sync-sgd: true
[2023-07-01 11:31:59] [config] tempdir: /tmp
[2023-07-01 11:31:59] [config] tied-embeddings: false
[2023-07-01 11:31:59] [config] tied-embeddings-all: true
[2023-07-01 11:31:59] [config] tied-embeddings-src: false
[2023-07-01 11:31:59] [config] train-embedder-rank:
[2023-07-01 11:31:59] [config]   []
[2023-07-01 11:31:59] [config] train-sets:
[2023-07-01 11:31:59] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:31:59] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:31:59] [config] transformer-aan-activation: swish
[2023-07-01 11:31:59] [config] transformer-aan-depth: 2
[2023-07-01 11:31:59] [config] transformer-aan-nogate: false
[2023-07-01 11:31:59] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:31:59] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:31:59] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:31:59] [config] transformer-depth-scaling: false
[2023-07-01 11:31:59] [config] transformer-dim-aan: 2048
[2023-07-01 11:31:59] [config] transformer-dim-ffn: 2048
[2023-07-01 11:31:59] [config] transformer-dropout: 0.1
[2023-07-01 11:31:59] [config] transformer-dropout-attention: 0
[2023-07-01 11:31:59] [config] transformer-dropout-ffn: 0
[2023-07-01 11:31:59] [config] transformer-ffn-activation: swish
[2023-07-01 11:31:59] [config] transformer-ffn-depth: 2
[2023-07-01 11:31:59] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:31:59] [config] transformer-heads: 8
[2023-07-01 11:31:59] [config] transformer-no-projection: false
[2023-07-01 11:31:59] [config] transformer-pool: false
[2023-07-01 11:31:59] [config] transformer-postprocess: dan
[2023-07-01 11:31:59] [config] transformer-postprocess-emb: d
[2023-07-01 11:31:59] [config] transformer-postprocess-top: ""
[2023-07-01 11:31:59] [config] transformer-preprocess: ""
[2023-07-01 11:31:59] [config] transformer-tied-layers:
[2023-07-01 11:31:59] [config]   []
[2023-07-01 11:31:59] [config] transformer-train-position-embeddings: false
[2023-07-01 11:31:59] [config] tsv: false
[2023-07-01 11:31:59] [config] tsv-fields: 0
[2023-07-01 11:31:59] [config] type: transformer
[2023-07-01 11:31:59] [config] ulr: false
[2023-07-01 11:31:59] [config] ulr-dim-emb: 0
[2023-07-01 11:31:59] [config] ulr-dropout: 0
[2023-07-01 11:31:59] [config] ulr-keys-vectors: ""
[2023-07-01 11:31:59] [config] ulr-query-vectors: ""
[2023-07-01 11:31:59] [config] ulr-softmax-temperature: 1
[2023-07-01 11:31:59] [config] ulr-trainable-transformation: false
[2023-07-01 11:31:59] [config] unlikelihood-loss: false
[2023-07-01 11:31:59] [config] valid-freq: 50000000
[2023-07-01 11:31:59] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:31:59] [config] valid-max-length: 1000
[2023-07-01 11:31:59] [config] valid-metrics:
[2023-07-01 11:31:59] [config]   - cross-entropy
[2023-07-01 11:31:59] [config]   - translation
[2023-07-01 11:31:59] [config] valid-mini-batch: 64
[2023-07-01 11:31:59] [config] valid-reset-stalled: false
[2023-07-01 11:31:59] [config] valid-script-args:
[2023-07-01 11:31:59] [config]   []
[2023-07-01 11:31:59] [config] valid-script-path: ""
[2023-07-01 11:31:59] [config] valid-sets:
[2023-07-01 11:31:59] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:31:59] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:31:59] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:31:59] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:31:59] [config] vocabs:
[2023-07-01 11:31:59] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:31:59] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:31:59] [config] word-penalty: 0
[2023-07-01 11:31:59] [config] word-scores: false
[2023-07-01 11:31:59] [config] workspace: 2048
[2023-07-01 11:31:59] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:31:59] Using synchronous SGD
[2023-07-01 11:32:00] Synced seed 1234
[2023-07-01 11:32:00] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:32:00] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:32:00] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:32:00] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:32:00] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:32:00] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:32:00] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:32:00] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:32:00] [comm] Using global sharding
[2023-07-01 11:32:01] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:32:01] [training] Using 1 GPUs
[2023-07-01 11:32:01] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:32:01] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:32:01] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:32:01] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:32:08] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:32:08] [valid] No post-processing script given for validating translator
[2023-07-01 11:32:08] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:32:08] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:32:08] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:32:08] [comm] Using global sharding
[2023-07-01 11:32:08] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:32:08] [training] Using 1 GPUs
[2023-07-01 11:32:08] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:32:09] Allocating memory for general optimizer shards
[2023-07-01 11:32:09] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:32:09] Loading Adam parameters
[2023-07-01 11:32:09] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:32:09] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:32:09] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:32:09] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:32:09] [data] Shuffling data
[2023-07-01 11:32:09] [data] Done reading 20,192 sentences
[2023-07-01 11:32:09] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:32:09] Training started
[2023-07-01 11:32:09] Training finished
[2023-07-01 11:32:13] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:32:13] [marian] Running on node20.datos.cluster.uy as process 17156 with command line:
[2023-07-01 11:32:13] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 103 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:32:13] [config] after: 0e
[2023-07-01 11:32:13] [config] after-batches: 0
[2023-07-01 11:32:13] [config] after-epochs: 103
[2023-07-01 11:32:13] [config] all-caps-every: 0
[2023-07-01 11:32:13] [config] allow-unk: false
[2023-07-01 11:32:13] [config] authors: false
[2023-07-01 11:32:13] [config] beam-size: 12
[2023-07-01 11:32:13] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:32:13] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:32:13] [config] bert-masking-fraction: 0.15
[2023-07-01 11:32:13] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:32:13] [config] bert-train-type-embeddings: true
[2023-07-01 11:32:13] [config] bert-type-vocab-size: 2
[2023-07-01 11:32:13] [config] build-info: ""
[2023-07-01 11:32:13] [config] check-gradient-nan: false
[2023-07-01 11:32:13] [config] check-nan: false
[2023-07-01 11:32:13] [config] cite: false
[2023-07-01 11:32:13] [config] clip-norm: 5
[2023-07-01 11:32:13] [config] cost-scaling:
[2023-07-01 11:32:13] [config]   []
[2023-07-01 11:32:13] [config] cost-type: ce-sum
[2023-07-01 11:32:13] [config] cpu-threads: 0
[2023-07-01 11:32:13] [config] data-threads: 8
[2023-07-01 11:32:13] [config] data-weighting: ""
[2023-07-01 11:32:13] [config] data-weighting-type: sentence
[2023-07-01 11:32:13] [config] dec-cell: gru
[2023-07-01 11:32:13] [config] dec-cell-base-depth: 2
[2023-07-01 11:32:13] [config] dec-cell-high-depth: 1
[2023-07-01 11:32:13] [config] dec-depth: 2
[2023-07-01 11:32:13] [config] devices:
[2023-07-01 11:32:13] [config]   - 0
[2023-07-01 11:32:13] [config] dim-emb: 512
[2023-07-01 11:32:13] [config] dim-rnn: 1024
[2023-07-01 11:32:13] [config] dim-vocabs:
[2023-07-01 11:32:13] [config]   - 16384
[2023-07-01 11:32:13] [config]   - 16384
[2023-07-01 11:32:13] [config] disp-first: 0
[2023-07-01 11:32:13] [config] disp-freq: 1000u
[2023-07-01 11:32:13] [config] disp-label-counts: true
[2023-07-01 11:32:13] [config] dropout-rnn: 0
[2023-07-01 11:32:13] [config] dropout-src: 0
[2023-07-01 11:32:13] [config] dropout-trg: 0
[2023-07-01 11:32:13] [config] dump-config: ""
[2023-07-01 11:32:13] [config] dynamic-gradient-scaling:
[2023-07-01 11:32:13] [config]   []
[2023-07-01 11:32:13] [config] early-stopping: 10
[2023-07-01 11:32:13] [config] early-stopping-on: first
[2023-07-01 11:32:13] [config] embedding-fix-src: false
[2023-07-01 11:32:13] [config] embedding-fix-trg: false
[2023-07-01 11:32:13] [config] embedding-normalization: false
[2023-07-01 11:32:13] [config] embedding-vectors:
[2023-07-01 11:32:13] [config]   []
[2023-07-01 11:32:13] [config] enc-cell: gru
[2023-07-01 11:32:13] [config] enc-cell-depth: 1
[2023-07-01 11:32:13] [config] enc-depth: 2
[2023-07-01 11:32:13] [config] enc-type: bidirectional
[2023-07-01 11:32:13] [config] english-title-case-every: 0
[2023-07-01 11:32:13] [config] exponential-smoothing: 0.0001
[2023-07-01 11:32:13] [config] factor-weight: 1
[2023-07-01 11:32:13] [config] factors-combine: sum
[2023-07-01 11:32:13] [config] factors-dim-emb: 0
[2023-07-01 11:32:13] [config] gradient-checkpointing: false
[2023-07-01 11:32:13] [config] gradient-norm-average-window: 100
[2023-07-01 11:32:13] [config] guided-alignment: none
[2023-07-01 11:32:13] [config] guided-alignment-cost: mse
[2023-07-01 11:32:13] [config] guided-alignment-weight: 0.1
[2023-07-01 11:32:13] [config] ignore-model-config: false
[2023-07-01 11:32:13] [config] input-types:
[2023-07-01 11:32:13] [config]   []
[2023-07-01 11:32:13] [config] interpolate-env-vars: false
[2023-07-01 11:32:13] [config] keep-best: false
[2023-07-01 11:32:13] [config] label-smoothing: 0.1
[2023-07-01 11:32:13] [config] layer-normalization: false
[2023-07-01 11:32:13] [config] learn-rate: 0.0003
[2023-07-01 11:32:13] [config] lemma-dependency: ""
[2023-07-01 11:32:13] [config] lemma-dim-emb: 0
[2023-07-01 11:32:13] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:32:13] [config] log-level: info
[2023-07-01 11:32:13] [config] log-time-zone: ""
[2023-07-01 11:32:13] [config] logical-epoch:
[2023-07-01 11:32:13] [config]   - 1e
[2023-07-01 11:32:13] [config]   - 0
[2023-07-01 11:32:13] [config] lr-decay: 0
[2023-07-01 11:32:13] [config] lr-decay-freq: 50000
[2023-07-01 11:32:13] [config] lr-decay-inv-sqrt:
[2023-07-01 11:32:13] [config]   - 16000
[2023-07-01 11:32:13] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:32:13] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:32:13] [config] lr-decay-start:
[2023-07-01 11:32:13] [config]   - 10
[2023-07-01 11:32:13] [config]   - 1
[2023-07-01 11:32:13] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:32:13] [config] lr-report: true
[2023-07-01 11:32:13] [config] lr-warmup: 16000
[2023-07-01 11:32:13] [config] lr-warmup-at-reload: false
[2023-07-01 11:32:13] [config] lr-warmup-cycle: false
[2023-07-01 11:32:13] [config] lr-warmup-start-rate: 0
[2023-07-01 11:32:13] [config] max-length: 100
[2023-07-01 11:32:13] [config] max-length-crop: false
[2023-07-01 11:32:13] [config] max-length-factor: 3
[2023-07-01 11:32:13] [config] maxi-batch: 100
[2023-07-01 11:32:13] [config] maxi-batch-sort: trg
[2023-07-01 11:32:13] [config] mini-batch: 1000
[2023-07-01 11:32:13] [config] mini-batch-fit: true
[2023-07-01 11:32:13] [config] mini-batch-fit-step: 10
[2023-07-01 11:32:13] [config] mini-batch-round-up: true
[2023-07-01 11:32:13] [config] mini-batch-track-lr: false
[2023-07-01 11:32:13] [config] mini-batch-warmup: 0
[2023-07-01 11:32:13] [config] mini-batch-words: 0
[2023-07-01 11:32:13] [config] mini-batch-words-ref: 0
[2023-07-01 11:32:13] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:32:13] [config] multi-loss-type: sum
[2023-07-01 11:32:13] [config] n-best: false
[2023-07-01 11:32:13] [config] no-nccl: false
[2023-07-01 11:32:13] [config] no-reload: false
[2023-07-01 11:32:13] [config] no-restore-corpus: false
[2023-07-01 11:32:13] [config] normalize: 1
[2023-07-01 11:32:13] [config] normalize-gradient: false
[2023-07-01 11:32:13] [config] num-devices: 0
[2023-07-01 11:32:13] [config] optimizer: adam
[2023-07-01 11:32:13] [config] optimizer-delay: 1
[2023-07-01 11:32:13] [config] optimizer-params:
[2023-07-01 11:32:13] [config]   - 0.9
[2023-07-01 11:32:13] [config]   - 0.98
[2023-07-01 11:32:13] [config]   - 1e-09
[2023-07-01 11:32:13] [config] output-omit-bias: false
[2023-07-01 11:32:13] [config] overwrite: true
[2023-07-01 11:32:13] [config] precision:
[2023-07-01 11:32:13] [config]   - float32
[2023-07-01 11:32:13] [config]   - float32
[2023-07-01 11:32:13] [config] pretrained-model: ""
[2023-07-01 11:32:13] [config] quantize-biases: false
[2023-07-01 11:32:13] [config] quantize-bits: 0
[2023-07-01 11:32:13] [config] quantize-log-based: false
[2023-07-01 11:32:13] [config] quantize-optimization-steps: 0
[2023-07-01 11:32:13] [config] quiet: false
[2023-07-01 11:32:13] [config] quiet-translation: true
[2023-07-01 11:32:13] [config] relative-paths: false
[2023-07-01 11:32:13] [config] right-left: false
[2023-07-01 11:32:13] [config] save-freq: 10000u
[2023-07-01 11:32:13] [config] seed: 1234
[2023-07-01 11:32:13] [config] sentencepiece-alphas:
[2023-07-01 11:32:13] [config]   []
[2023-07-01 11:32:13] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:32:13] [config] sentencepiece-options: ""
[2023-07-01 11:32:13] [config] sharding: global
[2023-07-01 11:32:13] [config] shuffle: data
[2023-07-01 11:32:13] [config] shuffle-in-ram: false
[2023-07-01 11:32:13] [config] sigterm: save-and-exit
[2023-07-01 11:32:13] [config] skip: false
[2023-07-01 11:32:13] [config] sqlite: ""
[2023-07-01 11:32:13] [config] sqlite-drop: false
[2023-07-01 11:32:13] [config] sync-freq: 200u
[2023-07-01 11:32:13] [config] sync-sgd: true
[2023-07-01 11:32:13] [config] tempdir: /tmp
[2023-07-01 11:32:13] [config] tied-embeddings: false
[2023-07-01 11:32:13] [config] tied-embeddings-all: true
[2023-07-01 11:32:13] [config] tied-embeddings-src: false
[2023-07-01 11:32:13] [config] train-embedder-rank:
[2023-07-01 11:32:13] [config]   []
[2023-07-01 11:32:13] [config] train-sets:
[2023-07-01 11:32:13] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:32:13] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:32:13] [config] transformer-aan-activation: swish
[2023-07-01 11:32:13] [config] transformer-aan-depth: 2
[2023-07-01 11:32:13] [config] transformer-aan-nogate: false
[2023-07-01 11:32:13] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:32:13] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:32:13] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:32:13] [config] transformer-depth-scaling: false
[2023-07-01 11:32:13] [config] transformer-dim-aan: 2048
[2023-07-01 11:32:13] [config] transformer-dim-ffn: 2048
[2023-07-01 11:32:13] [config] transformer-dropout: 0.1
[2023-07-01 11:32:13] [config] transformer-dropout-attention: 0
[2023-07-01 11:32:13] [config] transformer-dropout-ffn: 0
[2023-07-01 11:32:13] [config] transformer-ffn-activation: swish
[2023-07-01 11:32:13] [config] transformer-ffn-depth: 2
[2023-07-01 11:32:13] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:32:13] [config] transformer-heads: 8
[2023-07-01 11:32:13] [config] transformer-no-projection: false
[2023-07-01 11:32:13] [config] transformer-pool: false
[2023-07-01 11:32:13] [config] transformer-postprocess: dan
[2023-07-01 11:32:13] [config] transformer-postprocess-emb: d
[2023-07-01 11:32:13] [config] transformer-postprocess-top: ""
[2023-07-01 11:32:13] [config] transformer-preprocess: ""
[2023-07-01 11:32:13] [config] transformer-tied-layers:
[2023-07-01 11:32:13] [config]   []
[2023-07-01 11:32:13] [config] transformer-train-position-embeddings: false
[2023-07-01 11:32:13] [config] tsv: false
[2023-07-01 11:32:13] [config] tsv-fields: 0
[2023-07-01 11:32:13] [config] type: transformer
[2023-07-01 11:32:13] [config] ulr: false
[2023-07-01 11:32:13] [config] ulr-dim-emb: 0
[2023-07-01 11:32:13] [config] ulr-dropout: 0
[2023-07-01 11:32:13] [config] ulr-keys-vectors: ""
[2023-07-01 11:32:13] [config] ulr-query-vectors: ""
[2023-07-01 11:32:13] [config] ulr-softmax-temperature: 1
[2023-07-01 11:32:13] [config] ulr-trainable-transformation: false
[2023-07-01 11:32:13] [config] unlikelihood-loss: false
[2023-07-01 11:32:13] [config] valid-freq: 50000000
[2023-07-01 11:32:13] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:32:13] [config] valid-max-length: 1000
[2023-07-01 11:32:13] [config] valid-metrics:
[2023-07-01 11:32:13] [config]   - cross-entropy
[2023-07-01 11:32:13] [config]   - translation
[2023-07-01 11:32:13] [config] valid-mini-batch: 64
[2023-07-01 11:32:13] [config] valid-reset-stalled: false
[2023-07-01 11:32:13] [config] valid-script-args:
[2023-07-01 11:32:13] [config]   []
[2023-07-01 11:32:13] [config] valid-script-path: ""
[2023-07-01 11:32:13] [config] valid-sets:
[2023-07-01 11:32:13] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:32:13] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:32:13] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:32:13] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:32:13] [config] vocabs:
[2023-07-01 11:32:13] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:32:13] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:32:13] [config] word-penalty: 0
[2023-07-01 11:32:13] [config] word-scores: false
[2023-07-01 11:32:13] [config] workspace: 2048
[2023-07-01 11:32:13] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:32:13] Using synchronous SGD
[2023-07-01 11:32:13] Synced seed 1234
[2023-07-01 11:32:13] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:32:13] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:32:13] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:32:13] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:32:13] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:32:13] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:32:14] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:32:14] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:32:14] [comm] Using global sharding
[2023-07-01 11:32:14] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:32:14] [training] Using 1 GPUs
[2023-07-01 11:32:14] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:32:14] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:32:14] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:32:14] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:32:22] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:32:22] [valid] No post-processing script given for validating translator
[2023-07-01 11:32:22] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:32:22] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:32:22] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:32:22] [comm] Using global sharding
[2023-07-01 11:32:22] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:32:22] [training] Using 1 GPUs
[2023-07-01 11:32:22] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:32:22] Allocating memory for general optimizer shards
[2023-07-01 11:32:22] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:32:22] Loading Adam parameters
[2023-07-01 11:32:22] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:32:22] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:32:22] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:32:22] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:32:22] [data] Shuffling data
[2023-07-01 11:32:23] [data] Done reading 20,192 sentences
[2023-07-01 11:32:23] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:32:23] Training started
[2023-07-01 11:32:23] Training finished
[2023-07-01 11:32:26] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:32:26] [marian] Running on node20.datos.cluster.uy as process 17217 with command line:
[2023-07-01 11:32:26] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 104 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:32:26] [config] after: 0e
[2023-07-01 11:32:26] [config] after-batches: 0
[2023-07-01 11:32:26] [config] after-epochs: 104
[2023-07-01 11:32:26] [config] all-caps-every: 0
[2023-07-01 11:32:26] [config] allow-unk: false
[2023-07-01 11:32:26] [config] authors: false
[2023-07-01 11:32:26] [config] beam-size: 12
[2023-07-01 11:32:26] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:32:26] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:32:26] [config] bert-masking-fraction: 0.15
[2023-07-01 11:32:26] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:32:26] [config] bert-train-type-embeddings: true
[2023-07-01 11:32:26] [config] bert-type-vocab-size: 2
[2023-07-01 11:32:26] [config] build-info: ""
[2023-07-01 11:32:26] [config] check-gradient-nan: false
[2023-07-01 11:32:26] [config] check-nan: false
[2023-07-01 11:32:26] [config] cite: false
[2023-07-01 11:32:26] [config] clip-norm: 5
[2023-07-01 11:32:26] [config] cost-scaling:
[2023-07-01 11:32:26] [config]   []
[2023-07-01 11:32:26] [config] cost-type: ce-sum
[2023-07-01 11:32:26] [config] cpu-threads: 0
[2023-07-01 11:32:26] [config] data-threads: 8
[2023-07-01 11:32:26] [config] data-weighting: ""
[2023-07-01 11:32:26] [config] data-weighting-type: sentence
[2023-07-01 11:32:26] [config] dec-cell: gru
[2023-07-01 11:32:26] [config] dec-cell-base-depth: 2
[2023-07-01 11:32:26] [config] dec-cell-high-depth: 1
[2023-07-01 11:32:26] [config] dec-depth: 2
[2023-07-01 11:32:26] [config] devices:
[2023-07-01 11:32:26] [config]   - 0
[2023-07-01 11:32:26] [config] dim-emb: 512
[2023-07-01 11:32:26] [config] dim-rnn: 1024
[2023-07-01 11:32:26] [config] dim-vocabs:
[2023-07-01 11:32:26] [config]   - 16384
[2023-07-01 11:32:26] [config]   - 16384
[2023-07-01 11:32:26] [config] disp-first: 0
[2023-07-01 11:32:26] [config] disp-freq: 1000u
[2023-07-01 11:32:26] [config] disp-label-counts: true
[2023-07-01 11:32:26] [config] dropout-rnn: 0
[2023-07-01 11:32:26] [config] dropout-src: 0
[2023-07-01 11:32:26] [config] dropout-trg: 0
[2023-07-01 11:32:26] [config] dump-config: ""
[2023-07-01 11:32:26] [config] dynamic-gradient-scaling:
[2023-07-01 11:32:26] [config]   []
[2023-07-01 11:32:26] [config] early-stopping: 10
[2023-07-01 11:32:26] [config] early-stopping-on: first
[2023-07-01 11:32:26] [config] embedding-fix-src: false
[2023-07-01 11:32:26] [config] embedding-fix-trg: false
[2023-07-01 11:32:26] [config] embedding-normalization: false
[2023-07-01 11:32:26] [config] embedding-vectors:
[2023-07-01 11:32:26] [config]   []
[2023-07-01 11:32:26] [config] enc-cell: gru
[2023-07-01 11:32:26] [config] enc-cell-depth: 1
[2023-07-01 11:32:26] [config] enc-depth: 2
[2023-07-01 11:32:26] [config] enc-type: bidirectional
[2023-07-01 11:32:26] [config] english-title-case-every: 0
[2023-07-01 11:32:26] [config] exponential-smoothing: 0.0001
[2023-07-01 11:32:26] [config] factor-weight: 1
[2023-07-01 11:32:26] [config] factors-combine: sum
[2023-07-01 11:32:26] [config] factors-dim-emb: 0
[2023-07-01 11:32:26] [config] gradient-checkpointing: false
[2023-07-01 11:32:26] [config] gradient-norm-average-window: 100
[2023-07-01 11:32:26] [config] guided-alignment: none
[2023-07-01 11:32:26] [config] guided-alignment-cost: mse
[2023-07-01 11:32:26] [config] guided-alignment-weight: 0.1
[2023-07-01 11:32:26] [config] ignore-model-config: false
[2023-07-01 11:32:26] [config] input-types:
[2023-07-01 11:32:26] [config]   []
[2023-07-01 11:32:26] [config] interpolate-env-vars: false
[2023-07-01 11:32:26] [config] keep-best: false
[2023-07-01 11:32:26] [config] label-smoothing: 0.1
[2023-07-01 11:32:26] [config] layer-normalization: false
[2023-07-01 11:32:26] [config] learn-rate: 0.0003
[2023-07-01 11:32:26] [config] lemma-dependency: ""
[2023-07-01 11:32:26] [config] lemma-dim-emb: 0
[2023-07-01 11:32:26] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:32:26] [config] log-level: info
[2023-07-01 11:32:26] [config] log-time-zone: ""
[2023-07-01 11:32:26] [config] logical-epoch:
[2023-07-01 11:32:26] [config]   - 1e
[2023-07-01 11:32:26] [config]   - 0
[2023-07-01 11:32:26] [config] lr-decay: 0
[2023-07-01 11:32:26] [config] lr-decay-freq: 50000
[2023-07-01 11:32:26] [config] lr-decay-inv-sqrt:
[2023-07-01 11:32:26] [config]   - 16000
[2023-07-01 11:32:26] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:32:26] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:32:26] [config] lr-decay-start:
[2023-07-01 11:32:26] [config]   - 10
[2023-07-01 11:32:26] [config]   - 1
[2023-07-01 11:32:26] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:32:26] [config] lr-report: true
[2023-07-01 11:32:26] [config] lr-warmup: 16000
[2023-07-01 11:32:26] [config] lr-warmup-at-reload: false
[2023-07-01 11:32:26] [config] lr-warmup-cycle: false
[2023-07-01 11:32:26] [config] lr-warmup-start-rate: 0
[2023-07-01 11:32:26] [config] max-length: 100
[2023-07-01 11:32:26] [config] max-length-crop: false
[2023-07-01 11:32:26] [config] max-length-factor: 3
[2023-07-01 11:32:26] [config] maxi-batch: 100
[2023-07-01 11:32:26] [config] maxi-batch-sort: trg
[2023-07-01 11:32:26] [config] mini-batch: 1000
[2023-07-01 11:32:26] [config] mini-batch-fit: true
[2023-07-01 11:32:26] [config] mini-batch-fit-step: 10
[2023-07-01 11:32:26] [config] mini-batch-round-up: true
[2023-07-01 11:32:26] [config] mini-batch-track-lr: false
[2023-07-01 11:32:26] [config] mini-batch-warmup: 0
[2023-07-01 11:32:26] [config] mini-batch-words: 0
[2023-07-01 11:32:26] [config] mini-batch-words-ref: 0
[2023-07-01 11:32:26] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:32:26] [config] multi-loss-type: sum
[2023-07-01 11:32:26] [config] n-best: false
[2023-07-01 11:32:26] [config] no-nccl: false
[2023-07-01 11:32:26] [config] no-reload: false
[2023-07-01 11:32:26] [config] no-restore-corpus: false
[2023-07-01 11:32:26] [config] normalize: 1
[2023-07-01 11:32:26] [config] normalize-gradient: false
[2023-07-01 11:32:26] [config] num-devices: 0
[2023-07-01 11:32:26] [config] optimizer: adam
[2023-07-01 11:32:26] [config] optimizer-delay: 1
[2023-07-01 11:32:26] [config] optimizer-params:
[2023-07-01 11:32:26] [config]   - 0.9
[2023-07-01 11:32:26] [config]   - 0.98
[2023-07-01 11:32:26] [config]   - 1e-09
[2023-07-01 11:32:26] [config] output-omit-bias: false
[2023-07-01 11:32:26] [config] overwrite: true
[2023-07-01 11:32:26] [config] precision:
[2023-07-01 11:32:26] [config]   - float32
[2023-07-01 11:32:26] [config]   - float32
[2023-07-01 11:32:26] [config] pretrained-model: ""
[2023-07-01 11:32:26] [config] quantize-biases: false
[2023-07-01 11:32:26] [config] quantize-bits: 0
[2023-07-01 11:32:26] [config] quantize-log-based: false
[2023-07-01 11:32:26] [config] quantize-optimization-steps: 0
[2023-07-01 11:32:26] [config] quiet: false
[2023-07-01 11:32:26] [config] quiet-translation: true
[2023-07-01 11:32:26] [config] relative-paths: false
[2023-07-01 11:32:26] [config] right-left: false
[2023-07-01 11:32:26] [config] save-freq: 10000u
[2023-07-01 11:32:26] [config] seed: 1234
[2023-07-01 11:32:26] [config] sentencepiece-alphas:
[2023-07-01 11:32:26] [config]   []
[2023-07-01 11:32:26] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:32:26] [config] sentencepiece-options: ""
[2023-07-01 11:32:26] [config] sharding: global
[2023-07-01 11:32:26] [config] shuffle: data
[2023-07-01 11:32:26] [config] shuffle-in-ram: false
[2023-07-01 11:32:26] [config] sigterm: save-and-exit
[2023-07-01 11:32:26] [config] skip: false
[2023-07-01 11:32:26] [config] sqlite: ""
[2023-07-01 11:32:26] [config] sqlite-drop: false
[2023-07-01 11:32:26] [config] sync-freq: 200u
[2023-07-01 11:32:26] [config] sync-sgd: true
[2023-07-01 11:32:26] [config] tempdir: /tmp
[2023-07-01 11:32:26] [config] tied-embeddings: false
[2023-07-01 11:32:26] [config] tied-embeddings-all: true
[2023-07-01 11:32:26] [config] tied-embeddings-src: false
[2023-07-01 11:32:26] [config] train-embedder-rank:
[2023-07-01 11:32:26] [config]   []
[2023-07-01 11:32:26] [config] train-sets:
[2023-07-01 11:32:26] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:32:26] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:32:26] [config] transformer-aan-activation: swish
[2023-07-01 11:32:26] [config] transformer-aan-depth: 2
[2023-07-01 11:32:26] [config] transformer-aan-nogate: false
[2023-07-01 11:32:26] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:32:26] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:32:26] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:32:26] [config] transformer-depth-scaling: false
[2023-07-01 11:32:26] [config] transformer-dim-aan: 2048
[2023-07-01 11:32:26] [config] transformer-dim-ffn: 2048
[2023-07-01 11:32:26] [config] transformer-dropout: 0.1
[2023-07-01 11:32:26] [config] transformer-dropout-attention: 0
[2023-07-01 11:32:26] [config] transformer-dropout-ffn: 0
[2023-07-01 11:32:26] [config] transformer-ffn-activation: swish
[2023-07-01 11:32:26] [config] transformer-ffn-depth: 2
[2023-07-01 11:32:26] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:32:26] [config] transformer-heads: 8
[2023-07-01 11:32:26] [config] transformer-no-projection: false
[2023-07-01 11:32:26] [config] transformer-pool: false
[2023-07-01 11:32:26] [config] transformer-postprocess: dan
[2023-07-01 11:32:26] [config] transformer-postprocess-emb: d
[2023-07-01 11:32:26] [config] transformer-postprocess-top: ""
[2023-07-01 11:32:26] [config] transformer-preprocess: ""
[2023-07-01 11:32:26] [config] transformer-tied-layers:
[2023-07-01 11:32:26] [config]   []
[2023-07-01 11:32:26] [config] transformer-train-position-embeddings: false
[2023-07-01 11:32:26] [config] tsv: false
[2023-07-01 11:32:26] [config] tsv-fields: 0
[2023-07-01 11:32:26] [config] type: transformer
[2023-07-01 11:32:26] [config] ulr: false
[2023-07-01 11:32:26] [config] ulr-dim-emb: 0
[2023-07-01 11:32:26] [config] ulr-dropout: 0
[2023-07-01 11:32:26] [config] ulr-keys-vectors: ""
[2023-07-01 11:32:26] [config] ulr-query-vectors: ""
[2023-07-01 11:32:26] [config] ulr-softmax-temperature: 1
[2023-07-01 11:32:26] [config] ulr-trainable-transformation: false
[2023-07-01 11:32:26] [config] unlikelihood-loss: false
[2023-07-01 11:32:26] [config] valid-freq: 50000000
[2023-07-01 11:32:26] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:32:26] [config] valid-max-length: 1000
[2023-07-01 11:32:26] [config] valid-metrics:
[2023-07-01 11:32:26] [config]   - cross-entropy
[2023-07-01 11:32:26] [config]   - translation
[2023-07-01 11:32:26] [config] valid-mini-batch: 64
[2023-07-01 11:32:26] [config] valid-reset-stalled: false
[2023-07-01 11:32:26] [config] valid-script-args:
[2023-07-01 11:32:26] [config]   []
[2023-07-01 11:32:26] [config] valid-script-path: ""
[2023-07-01 11:32:26] [config] valid-sets:
[2023-07-01 11:32:26] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:32:26] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:32:26] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:32:26] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:32:26] [config] vocabs:
[2023-07-01 11:32:26] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:32:26] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:32:26] [config] word-penalty: 0
[2023-07-01 11:32:26] [config] word-scores: false
[2023-07-01 11:32:26] [config] workspace: 2048
[2023-07-01 11:32:26] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:32:26] Using synchronous SGD
[2023-07-01 11:32:26] Synced seed 1234
[2023-07-01 11:32:26] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:32:26] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:32:26] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:32:26] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:32:26] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:32:26] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:32:27] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:32:27] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:32:27] [comm] Using global sharding
[2023-07-01 11:32:27] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:32:27] [training] Using 1 GPUs
[2023-07-01 11:32:27] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:32:27] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:32:28] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:32:28] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:32:35] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:32:35] [valid] No post-processing script given for validating translator
[2023-07-01 11:32:35] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:32:35] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:32:35] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:32:35] [comm] Using global sharding
[2023-07-01 11:32:35] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:32:35] [training] Using 1 GPUs
[2023-07-01 11:32:35] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:32:36] Allocating memory for general optimizer shards
[2023-07-01 11:32:36] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:32:36] Loading Adam parameters
[2023-07-01 11:32:36] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:32:36] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:32:36] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:32:36] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:32:36] [data] Shuffling data
[2023-07-01 11:32:36] [data] Done reading 20,192 sentences
[2023-07-01 11:32:36] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:32:36] Training started
[2023-07-01 11:32:36] Training finished
[2023-07-01 11:32:39] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:32:39] [marian] Running on node20.datos.cluster.uy as process 17275 with command line:
[2023-07-01 11:32:39] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 105 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:32:39] [config] after: 0e
[2023-07-01 11:32:39] [config] after-batches: 0
[2023-07-01 11:32:39] [config] after-epochs: 105
[2023-07-01 11:32:39] [config] all-caps-every: 0
[2023-07-01 11:32:39] [config] allow-unk: false
[2023-07-01 11:32:39] [config] authors: false
[2023-07-01 11:32:39] [config] beam-size: 12
[2023-07-01 11:32:39] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:32:39] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:32:39] [config] bert-masking-fraction: 0.15
[2023-07-01 11:32:39] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:32:39] [config] bert-train-type-embeddings: true
[2023-07-01 11:32:39] [config] bert-type-vocab-size: 2
[2023-07-01 11:32:39] [config] build-info: ""
[2023-07-01 11:32:39] [config] check-gradient-nan: false
[2023-07-01 11:32:39] [config] check-nan: false
[2023-07-01 11:32:39] [config] cite: false
[2023-07-01 11:32:39] [config] clip-norm: 5
[2023-07-01 11:32:39] [config] cost-scaling:
[2023-07-01 11:32:39] [config]   []
[2023-07-01 11:32:39] [config] cost-type: ce-sum
[2023-07-01 11:32:39] [config] cpu-threads: 0
[2023-07-01 11:32:39] [config] data-threads: 8
[2023-07-01 11:32:39] [config] data-weighting: ""
[2023-07-01 11:32:39] [config] data-weighting-type: sentence
[2023-07-01 11:32:39] [config] dec-cell: gru
[2023-07-01 11:32:39] [config] dec-cell-base-depth: 2
[2023-07-01 11:32:39] [config] dec-cell-high-depth: 1
[2023-07-01 11:32:39] [config] dec-depth: 2
[2023-07-01 11:32:39] [config] devices:
[2023-07-01 11:32:39] [config]   - 0
[2023-07-01 11:32:39] [config] dim-emb: 512
[2023-07-01 11:32:39] [config] dim-rnn: 1024
[2023-07-01 11:32:39] [config] dim-vocabs:
[2023-07-01 11:32:39] [config]   - 16384
[2023-07-01 11:32:39] [config]   - 16384
[2023-07-01 11:32:39] [config] disp-first: 0
[2023-07-01 11:32:39] [config] disp-freq: 1000u
[2023-07-01 11:32:39] [config] disp-label-counts: true
[2023-07-01 11:32:39] [config] dropout-rnn: 0
[2023-07-01 11:32:39] [config] dropout-src: 0
[2023-07-01 11:32:39] [config] dropout-trg: 0
[2023-07-01 11:32:39] [config] dump-config: ""
[2023-07-01 11:32:39] [config] dynamic-gradient-scaling:
[2023-07-01 11:32:39] [config]   []
[2023-07-01 11:32:39] [config] early-stopping: 10
[2023-07-01 11:32:39] [config] early-stopping-on: first
[2023-07-01 11:32:39] [config] embedding-fix-src: false
[2023-07-01 11:32:39] [config] embedding-fix-trg: false
[2023-07-01 11:32:39] [config] embedding-normalization: false
[2023-07-01 11:32:39] [config] embedding-vectors:
[2023-07-01 11:32:39] [config]   []
[2023-07-01 11:32:39] [config] enc-cell: gru
[2023-07-01 11:32:39] [config] enc-cell-depth: 1
[2023-07-01 11:32:39] [config] enc-depth: 2
[2023-07-01 11:32:39] [config] enc-type: bidirectional
[2023-07-01 11:32:39] [config] english-title-case-every: 0
[2023-07-01 11:32:39] [config] exponential-smoothing: 0.0001
[2023-07-01 11:32:39] [config] factor-weight: 1
[2023-07-01 11:32:39] [config] factors-combine: sum
[2023-07-01 11:32:39] [config] factors-dim-emb: 0
[2023-07-01 11:32:39] [config] gradient-checkpointing: false
[2023-07-01 11:32:39] [config] gradient-norm-average-window: 100
[2023-07-01 11:32:39] [config] guided-alignment: none
[2023-07-01 11:32:39] [config] guided-alignment-cost: mse
[2023-07-01 11:32:39] [config] guided-alignment-weight: 0.1
[2023-07-01 11:32:39] [config] ignore-model-config: false
[2023-07-01 11:32:39] [config] input-types:
[2023-07-01 11:32:39] [config]   []
[2023-07-01 11:32:39] [config] interpolate-env-vars: false
[2023-07-01 11:32:39] [config] keep-best: false
[2023-07-01 11:32:39] [config] label-smoothing: 0.1
[2023-07-01 11:32:39] [config] layer-normalization: false
[2023-07-01 11:32:39] [config] learn-rate: 0.0003
[2023-07-01 11:32:39] [config] lemma-dependency: ""
[2023-07-01 11:32:39] [config] lemma-dim-emb: 0
[2023-07-01 11:32:39] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:32:39] [config] log-level: info
[2023-07-01 11:32:39] [config] log-time-zone: ""
[2023-07-01 11:32:39] [config] logical-epoch:
[2023-07-01 11:32:39] [config]   - 1e
[2023-07-01 11:32:39] [config]   - 0
[2023-07-01 11:32:39] [config] lr-decay: 0
[2023-07-01 11:32:39] [config] lr-decay-freq: 50000
[2023-07-01 11:32:39] [config] lr-decay-inv-sqrt:
[2023-07-01 11:32:39] [config]   - 16000
[2023-07-01 11:32:39] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:32:39] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:32:39] [config] lr-decay-start:
[2023-07-01 11:32:39] [config]   - 10
[2023-07-01 11:32:39] [config]   - 1
[2023-07-01 11:32:39] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:32:39] [config] lr-report: true
[2023-07-01 11:32:39] [config] lr-warmup: 16000
[2023-07-01 11:32:39] [config] lr-warmup-at-reload: false
[2023-07-01 11:32:39] [config] lr-warmup-cycle: false
[2023-07-01 11:32:39] [config] lr-warmup-start-rate: 0
[2023-07-01 11:32:39] [config] max-length: 100
[2023-07-01 11:32:39] [config] max-length-crop: false
[2023-07-01 11:32:39] [config] max-length-factor: 3
[2023-07-01 11:32:39] [config] maxi-batch: 100
[2023-07-01 11:32:39] [config] maxi-batch-sort: trg
[2023-07-01 11:32:39] [config] mini-batch: 1000
[2023-07-01 11:32:39] [config] mini-batch-fit: true
[2023-07-01 11:32:39] [config] mini-batch-fit-step: 10
[2023-07-01 11:32:39] [config] mini-batch-round-up: true
[2023-07-01 11:32:39] [config] mini-batch-track-lr: false
[2023-07-01 11:32:39] [config] mini-batch-warmup: 0
[2023-07-01 11:32:39] [config] mini-batch-words: 0
[2023-07-01 11:32:39] [config] mini-batch-words-ref: 0
[2023-07-01 11:32:39] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:32:39] [config] multi-loss-type: sum
[2023-07-01 11:32:39] [config] n-best: false
[2023-07-01 11:32:39] [config] no-nccl: false
[2023-07-01 11:32:39] [config] no-reload: false
[2023-07-01 11:32:39] [config] no-restore-corpus: false
[2023-07-01 11:32:39] [config] normalize: 1
[2023-07-01 11:32:39] [config] normalize-gradient: false
[2023-07-01 11:32:39] [config] num-devices: 0
[2023-07-01 11:32:39] [config] optimizer: adam
[2023-07-01 11:32:39] [config] optimizer-delay: 1
[2023-07-01 11:32:39] [config] optimizer-params:
[2023-07-01 11:32:39] [config]   - 0.9
[2023-07-01 11:32:39] [config]   - 0.98
[2023-07-01 11:32:39] [config]   - 1e-09
[2023-07-01 11:32:39] [config] output-omit-bias: false
[2023-07-01 11:32:39] [config] overwrite: true
[2023-07-01 11:32:39] [config] precision:
[2023-07-01 11:32:39] [config]   - float32
[2023-07-01 11:32:39] [config]   - float32
[2023-07-01 11:32:39] [config] pretrained-model: ""
[2023-07-01 11:32:39] [config] quantize-biases: false
[2023-07-01 11:32:39] [config] quantize-bits: 0
[2023-07-01 11:32:39] [config] quantize-log-based: false
[2023-07-01 11:32:39] [config] quantize-optimization-steps: 0
[2023-07-01 11:32:39] [config] quiet: false
[2023-07-01 11:32:39] [config] quiet-translation: true
[2023-07-01 11:32:39] [config] relative-paths: false
[2023-07-01 11:32:39] [config] right-left: false
[2023-07-01 11:32:39] [config] save-freq: 10000u
[2023-07-01 11:32:39] [config] seed: 1234
[2023-07-01 11:32:39] [config] sentencepiece-alphas:
[2023-07-01 11:32:39] [config]   []
[2023-07-01 11:32:39] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:32:39] [config] sentencepiece-options: ""
[2023-07-01 11:32:39] [config] sharding: global
[2023-07-01 11:32:39] [config] shuffle: data
[2023-07-01 11:32:39] [config] shuffle-in-ram: false
[2023-07-01 11:32:39] [config] sigterm: save-and-exit
[2023-07-01 11:32:39] [config] skip: false
[2023-07-01 11:32:39] [config] sqlite: ""
[2023-07-01 11:32:39] [config] sqlite-drop: false
[2023-07-01 11:32:39] [config] sync-freq: 200u
[2023-07-01 11:32:39] [config] sync-sgd: true
[2023-07-01 11:32:39] [config] tempdir: /tmp
[2023-07-01 11:32:39] [config] tied-embeddings: false
[2023-07-01 11:32:39] [config] tied-embeddings-all: true
[2023-07-01 11:32:39] [config] tied-embeddings-src: false
[2023-07-01 11:32:39] [config] train-embedder-rank:
[2023-07-01 11:32:39] [config]   []
[2023-07-01 11:32:39] [config] train-sets:
[2023-07-01 11:32:39] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:32:39] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:32:39] [config] transformer-aan-activation: swish
[2023-07-01 11:32:39] [config] transformer-aan-depth: 2
[2023-07-01 11:32:39] [config] transformer-aan-nogate: false
[2023-07-01 11:32:39] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:32:39] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:32:39] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:32:39] [config] transformer-depth-scaling: false
[2023-07-01 11:32:39] [config] transformer-dim-aan: 2048
[2023-07-01 11:32:39] [config] transformer-dim-ffn: 2048
[2023-07-01 11:32:39] [config] transformer-dropout: 0.1
[2023-07-01 11:32:39] [config] transformer-dropout-attention: 0
[2023-07-01 11:32:39] [config] transformer-dropout-ffn: 0
[2023-07-01 11:32:39] [config] transformer-ffn-activation: swish
[2023-07-01 11:32:39] [config] transformer-ffn-depth: 2
[2023-07-01 11:32:39] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:32:39] [config] transformer-heads: 8
[2023-07-01 11:32:39] [config] transformer-no-projection: false
[2023-07-01 11:32:39] [config] transformer-pool: false
[2023-07-01 11:32:39] [config] transformer-postprocess: dan
[2023-07-01 11:32:39] [config] transformer-postprocess-emb: d
[2023-07-01 11:32:39] [config] transformer-postprocess-top: ""
[2023-07-01 11:32:39] [config] transformer-preprocess: ""
[2023-07-01 11:32:39] [config] transformer-tied-layers:
[2023-07-01 11:32:39] [config]   []
[2023-07-01 11:32:39] [config] transformer-train-position-embeddings: false
[2023-07-01 11:32:39] [config] tsv: false
[2023-07-01 11:32:39] [config] tsv-fields: 0
[2023-07-01 11:32:39] [config] type: transformer
[2023-07-01 11:32:39] [config] ulr: false
[2023-07-01 11:32:39] [config] ulr-dim-emb: 0
[2023-07-01 11:32:39] [config] ulr-dropout: 0
[2023-07-01 11:32:39] [config] ulr-keys-vectors: ""
[2023-07-01 11:32:39] [config] ulr-query-vectors: ""
[2023-07-01 11:32:39] [config] ulr-softmax-temperature: 1
[2023-07-01 11:32:39] [config] ulr-trainable-transformation: false
[2023-07-01 11:32:39] [config] unlikelihood-loss: false
[2023-07-01 11:32:39] [config] valid-freq: 50000000
[2023-07-01 11:32:39] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:32:39] [config] valid-max-length: 1000
[2023-07-01 11:32:39] [config] valid-metrics:
[2023-07-01 11:32:39] [config]   - cross-entropy
[2023-07-01 11:32:39] [config]   - translation
[2023-07-01 11:32:39] [config] valid-mini-batch: 64
[2023-07-01 11:32:39] [config] valid-reset-stalled: false
[2023-07-01 11:32:39] [config] valid-script-args:
[2023-07-01 11:32:39] [config]   []
[2023-07-01 11:32:39] [config] valid-script-path: ""
[2023-07-01 11:32:39] [config] valid-sets:
[2023-07-01 11:32:39] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:32:39] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:32:39] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:32:39] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:32:39] [config] vocabs:
[2023-07-01 11:32:39] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:32:39] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:32:39] [config] word-penalty: 0
[2023-07-01 11:32:39] [config] word-scores: false
[2023-07-01 11:32:39] [config] workspace: 2048
[2023-07-01 11:32:39] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:32:39] Using synchronous SGD
[2023-07-01 11:32:40] Synced seed 1234
[2023-07-01 11:32:40] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:32:40] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:32:40] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:32:40] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:32:40] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:32:40] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:32:41] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:32:41] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:32:41] [comm] Using global sharding
[2023-07-01 11:32:41] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:32:41] [training] Using 1 GPUs
[2023-07-01 11:32:41] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:32:41] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:32:41] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:32:41] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:32:48] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:32:48] [valid] No post-processing script given for validating translator
[2023-07-01 11:32:49] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:32:49] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:32:49] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:32:49] [comm] Using global sharding
[2023-07-01 11:32:49] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:32:49] [training] Using 1 GPUs
[2023-07-01 11:32:49] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:32:49] Allocating memory for general optimizer shards
[2023-07-01 11:32:49] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:32:49] Loading Adam parameters
[2023-07-01 11:32:49] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:32:49] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:32:49] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:32:49] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:32:49] [data] Shuffling data
[2023-07-01 11:32:49] [data] Done reading 20,192 sentences
[2023-07-01 11:32:49] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:32:49] Training started
[2023-07-01 11:32:49] Training finished
[2023-07-01 11:32:53] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:32:53] [marian] Running on node20.datos.cluster.uy as process 17334 with command line:
[2023-07-01 11:32:53] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 106 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:32:53] [config] after: 0e
[2023-07-01 11:32:53] [config] after-batches: 0
[2023-07-01 11:32:53] [config] after-epochs: 106
[2023-07-01 11:32:53] [config] all-caps-every: 0
[2023-07-01 11:32:53] [config] allow-unk: false
[2023-07-01 11:32:53] [config] authors: false
[2023-07-01 11:32:53] [config] beam-size: 12
[2023-07-01 11:32:53] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:32:53] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:32:53] [config] bert-masking-fraction: 0.15
[2023-07-01 11:32:53] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:32:53] [config] bert-train-type-embeddings: true
[2023-07-01 11:32:53] [config] bert-type-vocab-size: 2
[2023-07-01 11:32:53] [config] build-info: ""
[2023-07-01 11:32:53] [config] check-gradient-nan: false
[2023-07-01 11:32:53] [config] check-nan: false
[2023-07-01 11:32:53] [config] cite: false
[2023-07-01 11:32:53] [config] clip-norm: 5
[2023-07-01 11:32:53] [config] cost-scaling:
[2023-07-01 11:32:53] [config]   []
[2023-07-01 11:32:53] [config] cost-type: ce-sum
[2023-07-01 11:32:53] [config] cpu-threads: 0
[2023-07-01 11:32:53] [config] data-threads: 8
[2023-07-01 11:32:53] [config] data-weighting: ""
[2023-07-01 11:32:53] [config] data-weighting-type: sentence
[2023-07-01 11:32:53] [config] dec-cell: gru
[2023-07-01 11:32:53] [config] dec-cell-base-depth: 2
[2023-07-01 11:32:53] [config] dec-cell-high-depth: 1
[2023-07-01 11:32:53] [config] dec-depth: 2
[2023-07-01 11:32:53] [config] devices:
[2023-07-01 11:32:53] [config]   - 0
[2023-07-01 11:32:53] [config] dim-emb: 512
[2023-07-01 11:32:53] [config] dim-rnn: 1024
[2023-07-01 11:32:53] [config] dim-vocabs:
[2023-07-01 11:32:53] [config]   - 16384
[2023-07-01 11:32:53] [config]   - 16384
[2023-07-01 11:32:53] [config] disp-first: 0
[2023-07-01 11:32:53] [config] disp-freq: 1000u
[2023-07-01 11:32:53] [config] disp-label-counts: true
[2023-07-01 11:32:53] [config] dropout-rnn: 0
[2023-07-01 11:32:53] [config] dropout-src: 0
[2023-07-01 11:32:53] [config] dropout-trg: 0
[2023-07-01 11:32:53] [config] dump-config: ""
[2023-07-01 11:32:53] [config] dynamic-gradient-scaling:
[2023-07-01 11:32:53] [config]   []
[2023-07-01 11:32:53] [config] early-stopping: 10
[2023-07-01 11:32:53] [config] early-stopping-on: first
[2023-07-01 11:32:53] [config] embedding-fix-src: false
[2023-07-01 11:32:53] [config] embedding-fix-trg: false
[2023-07-01 11:32:53] [config] embedding-normalization: false
[2023-07-01 11:32:53] [config] embedding-vectors:
[2023-07-01 11:32:53] [config]   []
[2023-07-01 11:32:53] [config] enc-cell: gru
[2023-07-01 11:32:53] [config] enc-cell-depth: 1
[2023-07-01 11:32:53] [config] enc-depth: 2
[2023-07-01 11:32:53] [config] enc-type: bidirectional
[2023-07-01 11:32:53] [config] english-title-case-every: 0
[2023-07-01 11:32:53] [config] exponential-smoothing: 0.0001
[2023-07-01 11:32:53] [config] factor-weight: 1
[2023-07-01 11:32:53] [config] factors-combine: sum
[2023-07-01 11:32:53] [config] factors-dim-emb: 0
[2023-07-01 11:32:53] [config] gradient-checkpointing: false
[2023-07-01 11:32:53] [config] gradient-norm-average-window: 100
[2023-07-01 11:32:53] [config] guided-alignment: none
[2023-07-01 11:32:53] [config] guided-alignment-cost: mse
[2023-07-01 11:32:53] [config] guided-alignment-weight: 0.1
[2023-07-01 11:32:53] [config] ignore-model-config: false
[2023-07-01 11:32:53] [config] input-types:
[2023-07-01 11:32:53] [config]   []
[2023-07-01 11:32:53] [config] interpolate-env-vars: false
[2023-07-01 11:32:53] [config] keep-best: false
[2023-07-01 11:32:53] [config] label-smoothing: 0.1
[2023-07-01 11:32:53] [config] layer-normalization: false
[2023-07-01 11:32:53] [config] learn-rate: 0.0003
[2023-07-01 11:32:53] [config] lemma-dependency: ""
[2023-07-01 11:32:53] [config] lemma-dim-emb: 0
[2023-07-01 11:32:53] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:32:53] [config] log-level: info
[2023-07-01 11:32:53] [config] log-time-zone: ""
[2023-07-01 11:32:53] [config] logical-epoch:
[2023-07-01 11:32:53] [config]   - 1e
[2023-07-01 11:32:53] [config]   - 0
[2023-07-01 11:32:53] [config] lr-decay: 0
[2023-07-01 11:32:53] [config] lr-decay-freq: 50000
[2023-07-01 11:32:53] [config] lr-decay-inv-sqrt:
[2023-07-01 11:32:53] [config]   - 16000
[2023-07-01 11:32:53] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:32:53] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:32:53] [config] lr-decay-start:
[2023-07-01 11:32:53] [config]   - 10
[2023-07-01 11:32:53] [config]   - 1
[2023-07-01 11:32:53] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:32:53] [config] lr-report: true
[2023-07-01 11:32:53] [config] lr-warmup: 16000
[2023-07-01 11:32:53] [config] lr-warmup-at-reload: false
[2023-07-01 11:32:53] [config] lr-warmup-cycle: false
[2023-07-01 11:32:53] [config] lr-warmup-start-rate: 0
[2023-07-01 11:32:53] [config] max-length: 100
[2023-07-01 11:32:53] [config] max-length-crop: false
[2023-07-01 11:32:53] [config] max-length-factor: 3
[2023-07-01 11:32:53] [config] maxi-batch: 100
[2023-07-01 11:32:53] [config] maxi-batch-sort: trg
[2023-07-01 11:32:53] [config] mini-batch: 1000
[2023-07-01 11:32:53] [config] mini-batch-fit: true
[2023-07-01 11:32:53] [config] mini-batch-fit-step: 10
[2023-07-01 11:32:53] [config] mini-batch-round-up: true
[2023-07-01 11:32:53] [config] mini-batch-track-lr: false
[2023-07-01 11:32:53] [config] mini-batch-warmup: 0
[2023-07-01 11:32:53] [config] mini-batch-words: 0
[2023-07-01 11:32:53] [config] mini-batch-words-ref: 0
[2023-07-01 11:32:53] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:32:53] [config] multi-loss-type: sum
[2023-07-01 11:32:53] [config] n-best: false
[2023-07-01 11:32:53] [config] no-nccl: false
[2023-07-01 11:32:53] [config] no-reload: false
[2023-07-01 11:32:53] [config] no-restore-corpus: false
[2023-07-01 11:32:53] [config] normalize: 1
[2023-07-01 11:32:53] [config] normalize-gradient: false
[2023-07-01 11:32:53] [config] num-devices: 0
[2023-07-01 11:32:53] [config] optimizer: adam
[2023-07-01 11:32:53] [config] optimizer-delay: 1
[2023-07-01 11:32:53] [config] optimizer-params:
[2023-07-01 11:32:53] [config]   - 0.9
[2023-07-01 11:32:53] [config]   - 0.98
[2023-07-01 11:32:53] [config]   - 1e-09
[2023-07-01 11:32:53] [config] output-omit-bias: false
[2023-07-01 11:32:53] [config] overwrite: true
[2023-07-01 11:32:53] [config] precision:
[2023-07-01 11:32:53] [config]   - float32
[2023-07-01 11:32:53] [config]   - float32
[2023-07-01 11:32:53] [config] pretrained-model: ""
[2023-07-01 11:32:53] [config] quantize-biases: false
[2023-07-01 11:32:53] [config] quantize-bits: 0
[2023-07-01 11:32:53] [config] quantize-log-based: false
[2023-07-01 11:32:53] [config] quantize-optimization-steps: 0
[2023-07-01 11:32:53] [config] quiet: false
[2023-07-01 11:32:53] [config] quiet-translation: true
[2023-07-01 11:32:53] [config] relative-paths: false
[2023-07-01 11:32:53] [config] right-left: false
[2023-07-01 11:32:53] [config] save-freq: 10000u
[2023-07-01 11:32:53] [config] seed: 1234
[2023-07-01 11:32:53] [config] sentencepiece-alphas:
[2023-07-01 11:32:53] [config]   []
[2023-07-01 11:32:53] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:32:53] [config] sentencepiece-options: ""
[2023-07-01 11:32:53] [config] sharding: global
[2023-07-01 11:32:53] [config] shuffle: data
[2023-07-01 11:32:53] [config] shuffle-in-ram: false
[2023-07-01 11:32:53] [config] sigterm: save-and-exit
[2023-07-01 11:32:53] [config] skip: false
[2023-07-01 11:32:53] [config] sqlite: ""
[2023-07-01 11:32:53] [config] sqlite-drop: false
[2023-07-01 11:32:53] [config] sync-freq: 200u
[2023-07-01 11:32:53] [config] sync-sgd: true
[2023-07-01 11:32:53] [config] tempdir: /tmp
[2023-07-01 11:32:53] [config] tied-embeddings: false
[2023-07-01 11:32:53] [config] tied-embeddings-all: true
[2023-07-01 11:32:53] [config] tied-embeddings-src: false
[2023-07-01 11:32:53] [config] train-embedder-rank:
[2023-07-01 11:32:53] [config]   []
[2023-07-01 11:32:53] [config] train-sets:
[2023-07-01 11:32:53] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:32:53] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:32:53] [config] transformer-aan-activation: swish
[2023-07-01 11:32:53] [config] transformer-aan-depth: 2
[2023-07-01 11:32:53] [config] transformer-aan-nogate: false
[2023-07-01 11:32:53] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:32:53] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:32:53] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:32:53] [config] transformer-depth-scaling: false
[2023-07-01 11:32:53] [config] transformer-dim-aan: 2048
[2023-07-01 11:32:53] [config] transformer-dim-ffn: 2048
[2023-07-01 11:32:53] [config] transformer-dropout: 0.1
[2023-07-01 11:32:53] [config] transformer-dropout-attention: 0
[2023-07-01 11:32:53] [config] transformer-dropout-ffn: 0
[2023-07-01 11:32:53] [config] transformer-ffn-activation: swish
[2023-07-01 11:32:53] [config] transformer-ffn-depth: 2
[2023-07-01 11:32:53] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:32:53] [config] transformer-heads: 8
[2023-07-01 11:32:53] [config] transformer-no-projection: false
[2023-07-01 11:32:53] [config] transformer-pool: false
[2023-07-01 11:32:53] [config] transformer-postprocess: dan
[2023-07-01 11:32:53] [config] transformer-postprocess-emb: d
[2023-07-01 11:32:53] [config] transformer-postprocess-top: ""
[2023-07-01 11:32:53] [config] transformer-preprocess: ""
[2023-07-01 11:32:53] [config] transformer-tied-layers:
[2023-07-01 11:32:53] [config]   []
[2023-07-01 11:32:53] [config] transformer-train-position-embeddings: false
[2023-07-01 11:32:53] [config] tsv: false
[2023-07-01 11:32:53] [config] tsv-fields: 0
[2023-07-01 11:32:53] [config] type: transformer
[2023-07-01 11:32:53] [config] ulr: false
[2023-07-01 11:32:53] [config] ulr-dim-emb: 0
[2023-07-01 11:32:53] [config] ulr-dropout: 0
[2023-07-01 11:32:53] [config] ulr-keys-vectors: ""
[2023-07-01 11:32:53] [config] ulr-query-vectors: ""
[2023-07-01 11:32:53] [config] ulr-softmax-temperature: 1
[2023-07-01 11:32:53] [config] ulr-trainable-transformation: false
[2023-07-01 11:32:53] [config] unlikelihood-loss: false
[2023-07-01 11:32:53] [config] valid-freq: 50000000
[2023-07-01 11:32:53] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:32:53] [config] valid-max-length: 1000
[2023-07-01 11:32:53] [config] valid-metrics:
[2023-07-01 11:32:53] [config]   - cross-entropy
[2023-07-01 11:32:53] [config]   - translation
[2023-07-01 11:32:53] [config] valid-mini-batch: 64
[2023-07-01 11:32:53] [config] valid-reset-stalled: false
[2023-07-01 11:32:53] [config] valid-script-args:
[2023-07-01 11:32:53] [config]   []
[2023-07-01 11:32:53] [config] valid-script-path: ""
[2023-07-01 11:32:53] [config] valid-sets:
[2023-07-01 11:32:53] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:32:53] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:32:53] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:32:53] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:32:53] [config] vocabs:
[2023-07-01 11:32:53] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:32:53] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:32:53] [config] word-penalty: 0
[2023-07-01 11:32:53] [config] word-scores: false
[2023-07-01 11:32:53] [config] workspace: 2048
[2023-07-01 11:32:53] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:32:53] Using synchronous SGD
[2023-07-01 11:32:54] Synced seed 1234
[2023-07-01 11:32:54] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:32:54] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:32:54] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:32:54] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:32:54] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:32:54] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:32:54] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:32:54] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:32:54] [comm] Using global sharding
[2023-07-01 11:32:54] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:32:54] [training] Using 1 GPUs
[2023-07-01 11:32:54] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:32:54] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:32:55] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:32:55] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:33:02] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:33:02] [valid] No post-processing script given for validating translator
[2023-07-01 11:33:02] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:33:02] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:33:02] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:33:02] [comm] Using global sharding
[2023-07-01 11:33:02] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:33:02] [training] Using 1 GPUs
[2023-07-01 11:33:02] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:33:03] Allocating memory for general optimizer shards
[2023-07-01 11:33:03] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:33:03] Loading Adam parameters
[2023-07-01 11:33:03] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:33:03] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:33:03] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:33:03] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:33:03] [data] Shuffling data
[2023-07-01 11:33:03] [data] Done reading 20,192 sentences
[2023-07-01 11:33:03] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:33:03] Training started
[2023-07-01 11:33:03] Training finished
[2023-07-01 11:33:07] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:33:07] [marian] Running on node20.datos.cluster.uy as process 17393 with command line:
[2023-07-01 11:33:07] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 107 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:33:07] [config] after: 0e
[2023-07-01 11:33:07] [config] after-batches: 0
[2023-07-01 11:33:07] [config] after-epochs: 107
[2023-07-01 11:33:07] [config] all-caps-every: 0
[2023-07-01 11:33:07] [config] allow-unk: false
[2023-07-01 11:33:07] [config] authors: false
[2023-07-01 11:33:07] [config] beam-size: 12
[2023-07-01 11:33:07] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:33:07] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:33:07] [config] bert-masking-fraction: 0.15
[2023-07-01 11:33:07] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:33:07] [config] bert-train-type-embeddings: true
[2023-07-01 11:33:07] [config] bert-type-vocab-size: 2
[2023-07-01 11:33:07] [config] build-info: ""
[2023-07-01 11:33:07] [config] check-gradient-nan: false
[2023-07-01 11:33:07] [config] check-nan: false
[2023-07-01 11:33:07] [config] cite: false
[2023-07-01 11:33:07] [config] clip-norm: 5
[2023-07-01 11:33:07] [config] cost-scaling:
[2023-07-01 11:33:07] [config]   []
[2023-07-01 11:33:07] [config] cost-type: ce-sum
[2023-07-01 11:33:07] [config] cpu-threads: 0
[2023-07-01 11:33:07] [config] data-threads: 8
[2023-07-01 11:33:07] [config] data-weighting: ""
[2023-07-01 11:33:07] [config] data-weighting-type: sentence
[2023-07-01 11:33:07] [config] dec-cell: gru
[2023-07-01 11:33:07] [config] dec-cell-base-depth: 2
[2023-07-01 11:33:07] [config] dec-cell-high-depth: 1
[2023-07-01 11:33:07] [config] dec-depth: 2
[2023-07-01 11:33:07] [config] devices:
[2023-07-01 11:33:07] [config]   - 0
[2023-07-01 11:33:07] [config] dim-emb: 512
[2023-07-01 11:33:07] [config] dim-rnn: 1024
[2023-07-01 11:33:07] [config] dim-vocabs:
[2023-07-01 11:33:07] [config]   - 16384
[2023-07-01 11:33:07] [config]   - 16384
[2023-07-01 11:33:07] [config] disp-first: 0
[2023-07-01 11:33:07] [config] disp-freq: 1000u
[2023-07-01 11:33:07] [config] disp-label-counts: true
[2023-07-01 11:33:07] [config] dropout-rnn: 0
[2023-07-01 11:33:07] [config] dropout-src: 0
[2023-07-01 11:33:07] [config] dropout-trg: 0
[2023-07-01 11:33:07] [config] dump-config: ""
[2023-07-01 11:33:07] [config] dynamic-gradient-scaling:
[2023-07-01 11:33:07] [config]   []
[2023-07-01 11:33:07] [config] early-stopping: 10
[2023-07-01 11:33:07] [config] early-stopping-on: first
[2023-07-01 11:33:07] [config] embedding-fix-src: false
[2023-07-01 11:33:07] [config] embedding-fix-trg: false
[2023-07-01 11:33:07] [config] embedding-normalization: false
[2023-07-01 11:33:07] [config] embedding-vectors:
[2023-07-01 11:33:07] [config]   []
[2023-07-01 11:33:07] [config] enc-cell: gru
[2023-07-01 11:33:07] [config] enc-cell-depth: 1
[2023-07-01 11:33:07] [config] enc-depth: 2
[2023-07-01 11:33:07] [config] enc-type: bidirectional
[2023-07-01 11:33:07] [config] english-title-case-every: 0
[2023-07-01 11:33:07] [config] exponential-smoothing: 0.0001
[2023-07-01 11:33:07] [config] factor-weight: 1
[2023-07-01 11:33:07] [config] factors-combine: sum
[2023-07-01 11:33:07] [config] factors-dim-emb: 0
[2023-07-01 11:33:07] [config] gradient-checkpointing: false
[2023-07-01 11:33:07] [config] gradient-norm-average-window: 100
[2023-07-01 11:33:07] [config] guided-alignment: none
[2023-07-01 11:33:07] [config] guided-alignment-cost: mse
[2023-07-01 11:33:07] [config] guided-alignment-weight: 0.1
[2023-07-01 11:33:07] [config] ignore-model-config: false
[2023-07-01 11:33:07] [config] input-types:
[2023-07-01 11:33:07] [config]   []
[2023-07-01 11:33:07] [config] interpolate-env-vars: false
[2023-07-01 11:33:07] [config] keep-best: false
[2023-07-01 11:33:07] [config] label-smoothing: 0.1
[2023-07-01 11:33:07] [config] layer-normalization: false
[2023-07-01 11:33:07] [config] learn-rate: 0.0003
[2023-07-01 11:33:07] [config] lemma-dependency: ""
[2023-07-01 11:33:07] [config] lemma-dim-emb: 0
[2023-07-01 11:33:07] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:33:07] [config] log-level: info
[2023-07-01 11:33:07] [config] log-time-zone: ""
[2023-07-01 11:33:07] [config] logical-epoch:
[2023-07-01 11:33:07] [config]   - 1e
[2023-07-01 11:33:07] [config]   - 0
[2023-07-01 11:33:07] [config] lr-decay: 0
[2023-07-01 11:33:07] [config] lr-decay-freq: 50000
[2023-07-01 11:33:07] [config] lr-decay-inv-sqrt:
[2023-07-01 11:33:07] [config]   - 16000
[2023-07-01 11:33:07] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:33:07] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:33:07] [config] lr-decay-start:
[2023-07-01 11:33:07] [config]   - 10
[2023-07-01 11:33:07] [config]   - 1
[2023-07-01 11:33:07] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:33:07] [config] lr-report: true
[2023-07-01 11:33:07] [config] lr-warmup: 16000
[2023-07-01 11:33:07] [config] lr-warmup-at-reload: false
[2023-07-01 11:33:07] [config] lr-warmup-cycle: false
[2023-07-01 11:33:07] [config] lr-warmup-start-rate: 0
[2023-07-01 11:33:07] [config] max-length: 100
[2023-07-01 11:33:07] [config] max-length-crop: false
[2023-07-01 11:33:07] [config] max-length-factor: 3
[2023-07-01 11:33:07] [config] maxi-batch: 100
[2023-07-01 11:33:07] [config] maxi-batch-sort: trg
[2023-07-01 11:33:07] [config] mini-batch: 1000
[2023-07-01 11:33:07] [config] mini-batch-fit: true
[2023-07-01 11:33:07] [config] mini-batch-fit-step: 10
[2023-07-01 11:33:07] [config] mini-batch-round-up: true
[2023-07-01 11:33:07] [config] mini-batch-track-lr: false
[2023-07-01 11:33:07] [config] mini-batch-warmup: 0
[2023-07-01 11:33:07] [config] mini-batch-words: 0
[2023-07-01 11:33:07] [config] mini-batch-words-ref: 0
[2023-07-01 11:33:07] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:33:07] [config] multi-loss-type: sum
[2023-07-01 11:33:07] [config] n-best: false
[2023-07-01 11:33:07] [config] no-nccl: false
[2023-07-01 11:33:07] [config] no-reload: false
[2023-07-01 11:33:07] [config] no-restore-corpus: false
[2023-07-01 11:33:07] [config] normalize: 1
[2023-07-01 11:33:07] [config] normalize-gradient: false
[2023-07-01 11:33:07] [config] num-devices: 0
[2023-07-01 11:33:07] [config] optimizer: adam
[2023-07-01 11:33:07] [config] optimizer-delay: 1
[2023-07-01 11:33:07] [config] optimizer-params:
[2023-07-01 11:33:07] [config]   - 0.9
[2023-07-01 11:33:07] [config]   - 0.98
[2023-07-01 11:33:07] [config]   - 1e-09
[2023-07-01 11:33:07] [config] output-omit-bias: false
[2023-07-01 11:33:07] [config] overwrite: true
[2023-07-01 11:33:07] [config] precision:
[2023-07-01 11:33:07] [config]   - float32
[2023-07-01 11:33:07] [config]   - float32
[2023-07-01 11:33:07] [config] pretrained-model: ""
[2023-07-01 11:33:07] [config] quantize-biases: false
[2023-07-01 11:33:07] [config] quantize-bits: 0
[2023-07-01 11:33:07] [config] quantize-log-based: false
[2023-07-01 11:33:07] [config] quantize-optimization-steps: 0
[2023-07-01 11:33:07] [config] quiet: false
[2023-07-01 11:33:07] [config] quiet-translation: true
[2023-07-01 11:33:07] [config] relative-paths: false
[2023-07-01 11:33:07] [config] right-left: false
[2023-07-01 11:33:07] [config] save-freq: 10000u
[2023-07-01 11:33:07] [config] seed: 1234
[2023-07-01 11:33:07] [config] sentencepiece-alphas:
[2023-07-01 11:33:07] [config]   []
[2023-07-01 11:33:07] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:33:07] [config] sentencepiece-options: ""
[2023-07-01 11:33:07] [config] sharding: global
[2023-07-01 11:33:07] [config] shuffle: data
[2023-07-01 11:33:07] [config] shuffle-in-ram: false
[2023-07-01 11:33:07] [config] sigterm: save-and-exit
[2023-07-01 11:33:07] [config] skip: false
[2023-07-01 11:33:07] [config] sqlite: ""
[2023-07-01 11:33:07] [config] sqlite-drop: false
[2023-07-01 11:33:07] [config] sync-freq: 200u
[2023-07-01 11:33:07] [config] sync-sgd: true
[2023-07-01 11:33:07] [config] tempdir: /tmp
[2023-07-01 11:33:07] [config] tied-embeddings: false
[2023-07-01 11:33:07] [config] tied-embeddings-all: true
[2023-07-01 11:33:07] [config] tied-embeddings-src: false
[2023-07-01 11:33:07] [config] train-embedder-rank:
[2023-07-01 11:33:07] [config]   []
[2023-07-01 11:33:07] [config] train-sets:
[2023-07-01 11:33:07] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:33:07] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:33:07] [config] transformer-aan-activation: swish
[2023-07-01 11:33:07] [config] transformer-aan-depth: 2
[2023-07-01 11:33:07] [config] transformer-aan-nogate: false
[2023-07-01 11:33:07] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:33:07] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:33:07] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:33:07] [config] transformer-depth-scaling: false
[2023-07-01 11:33:07] [config] transformer-dim-aan: 2048
[2023-07-01 11:33:07] [config] transformer-dim-ffn: 2048
[2023-07-01 11:33:07] [config] transformer-dropout: 0.1
[2023-07-01 11:33:07] [config] transformer-dropout-attention: 0
[2023-07-01 11:33:07] [config] transformer-dropout-ffn: 0
[2023-07-01 11:33:07] [config] transformer-ffn-activation: swish
[2023-07-01 11:33:07] [config] transformer-ffn-depth: 2
[2023-07-01 11:33:07] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:33:07] [config] transformer-heads: 8
[2023-07-01 11:33:07] [config] transformer-no-projection: false
[2023-07-01 11:33:07] [config] transformer-pool: false
[2023-07-01 11:33:07] [config] transformer-postprocess: dan
[2023-07-01 11:33:07] [config] transformer-postprocess-emb: d
[2023-07-01 11:33:07] [config] transformer-postprocess-top: ""
[2023-07-01 11:33:07] [config] transformer-preprocess: ""
[2023-07-01 11:33:07] [config] transformer-tied-layers:
[2023-07-01 11:33:07] [config]   []
[2023-07-01 11:33:07] [config] transformer-train-position-embeddings: false
[2023-07-01 11:33:07] [config] tsv: false
[2023-07-01 11:33:07] [config] tsv-fields: 0
[2023-07-01 11:33:07] [config] type: transformer
[2023-07-01 11:33:07] [config] ulr: false
[2023-07-01 11:33:07] [config] ulr-dim-emb: 0
[2023-07-01 11:33:07] [config] ulr-dropout: 0
[2023-07-01 11:33:07] [config] ulr-keys-vectors: ""
[2023-07-01 11:33:07] [config] ulr-query-vectors: ""
[2023-07-01 11:33:07] [config] ulr-softmax-temperature: 1
[2023-07-01 11:33:07] [config] ulr-trainable-transformation: false
[2023-07-01 11:33:07] [config] unlikelihood-loss: false
[2023-07-01 11:33:07] [config] valid-freq: 50000000
[2023-07-01 11:33:07] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:33:07] [config] valid-max-length: 1000
[2023-07-01 11:33:07] [config] valid-metrics:
[2023-07-01 11:33:07] [config]   - cross-entropy
[2023-07-01 11:33:07] [config]   - translation
[2023-07-01 11:33:07] [config] valid-mini-batch: 64
[2023-07-01 11:33:07] [config] valid-reset-stalled: false
[2023-07-01 11:33:07] [config] valid-script-args:
[2023-07-01 11:33:07] [config]   []
[2023-07-01 11:33:07] [config] valid-script-path: ""
[2023-07-01 11:33:07] [config] valid-sets:
[2023-07-01 11:33:07] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:33:07] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:33:07] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:33:07] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:33:07] [config] vocabs:
[2023-07-01 11:33:07] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:33:07] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:33:07] [config] word-penalty: 0
[2023-07-01 11:33:07] [config] word-scores: false
[2023-07-01 11:33:07] [config] workspace: 2048
[2023-07-01 11:33:07] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:33:07] Using synchronous SGD
[2023-07-01 11:33:07] Synced seed 1234
[2023-07-01 11:33:07] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:33:07] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:33:07] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:33:07] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:33:07] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:33:07] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:33:08] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:33:08] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:33:08] [comm] Using global sharding
[2023-07-01 11:33:08] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:33:08] [training] Using 1 GPUs
[2023-07-01 11:33:08] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:33:08] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:33:08] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:33:08] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:33:16] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:33:16] [valid] No post-processing script given for validating translator
[2023-07-01 11:33:16] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:33:16] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:33:16] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:33:16] [comm] Using global sharding
[2023-07-01 11:33:16] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:33:16] [training] Using 1 GPUs
[2023-07-01 11:33:16] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:33:16] Allocating memory for general optimizer shards
[2023-07-01 11:33:16] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:33:16] Loading Adam parameters
[2023-07-01 11:33:16] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:33:17] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:33:17] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:33:17] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:33:17] [data] Shuffling data
[2023-07-01 11:33:17] [data] Done reading 20,192 sentences
[2023-07-01 11:33:17] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:33:17] Training started
[2023-07-01 11:33:17] Training finished
[2023-07-01 11:33:20] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:33:20] [marian] Running on node20.datos.cluster.uy as process 17452 with command line:
[2023-07-01 11:33:20] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 108 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:33:20] [config] after: 0e
[2023-07-01 11:33:20] [config] after-batches: 0
[2023-07-01 11:33:20] [config] after-epochs: 108
[2023-07-01 11:33:20] [config] all-caps-every: 0
[2023-07-01 11:33:20] [config] allow-unk: false
[2023-07-01 11:33:20] [config] authors: false
[2023-07-01 11:33:20] [config] beam-size: 12
[2023-07-01 11:33:20] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:33:20] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:33:20] [config] bert-masking-fraction: 0.15
[2023-07-01 11:33:20] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:33:20] [config] bert-train-type-embeddings: true
[2023-07-01 11:33:20] [config] bert-type-vocab-size: 2
[2023-07-01 11:33:20] [config] build-info: ""
[2023-07-01 11:33:20] [config] check-gradient-nan: false
[2023-07-01 11:33:20] [config] check-nan: false
[2023-07-01 11:33:20] [config] cite: false
[2023-07-01 11:33:20] [config] clip-norm: 5
[2023-07-01 11:33:20] [config] cost-scaling:
[2023-07-01 11:33:20] [config]   []
[2023-07-01 11:33:20] [config] cost-type: ce-sum
[2023-07-01 11:33:20] [config] cpu-threads: 0
[2023-07-01 11:33:20] [config] data-threads: 8
[2023-07-01 11:33:20] [config] data-weighting: ""
[2023-07-01 11:33:20] [config] data-weighting-type: sentence
[2023-07-01 11:33:20] [config] dec-cell: gru
[2023-07-01 11:33:20] [config] dec-cell-base-depth: 2
[2023-07-01 11:33:20] [config] dec-cell-high-depth: 1
[2023-07-01 11:33:20] [config] dec-depth: 2
[2023-07-01 11:33:20] [config] devices:
[2023-07-01 11:33:20] [config]   - 0
[2023-07-01 11:33:20] [config] dim-emb: 512
[2023-07-01 11:33:20] [config] dim-rnn: 1024
[2023-07-01 11:33:20] [config] dim-vocabs:
[2023-07-01 11:33:20] [config]   - 16384
[2023-07-01 11:33:20] [config]   - 16384
[2023-07-01 11:33:20] [config] disp-first: 0
[2023-07-01 11:33:20] [config] disp-freq: 1000u
[2023-07-01 11:33:20] [config] disp-label-counts: true
[2023-07-01 11:33:20] [config] dropout-rnn: 0
[2023-07-01 11:33:20] [config] dropout-src: 0
[2023-07-01 11:33:20] [config] dropout-trg: 0
[2023-07-01 11:33:20] [config] dump-config: ""
[2023-07-01 11:33:20] [config] dynamic-gradient-scaling:
[2023-07-01 11:33:20] [config]   []
[2023-07-01 11:33:20] [config] early-stopping: 10
[2023-07-01 11:33:20] [config] early-stopping-on: first
[2023-07-01 11:33:20] [config] embedding-fix-src: false
[2023-07-01 11:33:20] [config] embedding-fix-trg: false
[2023-07-01 11:33:20] [config] embedding-normalization: false
[2023-07-01 11:33:20] [config] embedding-vectors:
[2023-07-01 11:33:20] [config]   []
[2023-07-01 11:33:20] [config] enc-cell: gru
[2023-07-01 11:33:20] [config] enc-cell-depth: 1
[2023-07-01 11:33:20] [config] enc-depth: 2
[2023-07-01 11:33:20] [config] enc-type: bidirectional
[2023-07-01 11:33:20] [config] english-title-case-every: 0
[2023-07-01 11:33:20] [config] exponential-smoothing: 0.0001
[2023-07-01 11:33:20] [config] factor-weight: 1
[2023-07-01 11:33:20] [config] factors-combine: sum
[2023-07-01 11:33:20] [config] factors-dim-emb: 0
[2023-07-01 11:33:20] [config] gradient-checkpointing: false
[2023-07-01 11:33:20] [config] gradient-norm-average-window: 100
[2023-07-01 11:33:20] [config] guided-alignment: none
[2023-07-01 11:33:20] [config] guided-alignment-cost: mse
[2023-07-01 11:33:20] [config] guided-alignment-weight: 0.1
[2023-07-01 11:33:20] [config] ignore-model-config: false
[2023-07-01 11:33:20] [config] input-types:
[2023-07-01 11:33:20] [config]   []
[2023-07-01 11:33:20] [config] interpolate-env-vars: false
[2023-07-01 11:33:20] [config] keep-best: false
[2023-07-01 11:33:20] [config] label-smoothing: 0.1
[2023-07-01 11:33:20] [config] layer-normalization: false
[2023-07-01 11:33:20] [config] learn-rate: 0.0003
[2023-07-01 11:33:20] [config] lemma-dependency: ""
[2023-07-01 11:33:20] [config] lemma-dim-emb: 0
[2023-07-01 11:33:20] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:33:20] [config] log-level: info
[2023-07-01 11:33:20] [config] log-time-zone: ""
[2023-07-01 11:33:20] [config] logical-epoch:
[2023-07-01 11:33:20] [config]   - 1e
[2023-07-01 11:33:20] [config]   - 0
[2023-07-01 11:33:20] [config] lr-decay: 0
[2023-07-01 11:33:20] [config] lr-decay-freq: 50000
[2023-07-01 11:33:20] [config] lr-decay-inv-sqrt:
[2023-07-01 11:33:20] [config]   - 16000
[2023-07-01 11:33:20] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:33:20] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:33:20] [config] lr-decay-start:
[2023-07-01 11:33:20] [config]   - 10
[2023-07-01 11:33:20] [config]   - 1
[2023-07-01 11:33:20] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:33:20] [config] lr-report: true
[2023-07-01 11:33:20] [config] lr-warmup: 16000
[2023-07-01 11:33:20] [config] lr-warmup-at-reload: false
[2023-07-01 11:33:20] [config] lr-warmup-cycle: false
[2023-07-01 11:33:20] [config] lr-warmup-start-rate: 0
[2023-07-01 11:33:20] [config] max-length: 100
[2023-07-01 11:33:20] [config] max-length-crop: false
[2023-07-01 11:33:20] [config] max-length-factor: 3
[2023-07-01 11:33:20] [config] maxi-batch: 100
[2023-07-01 11:33:20] [config] maxi-batch-sort: trg
[2023-07-01 11:33:20] [config] mini-batch: 1000
[2023-07-01 11:33:20] [config] mini-batch-fit: true
[2023-07-01 11:33:20] [config] mini-batch-fit-step: 10
[2023-07-01 11:33:20] [config] mini-batch-round-up: true
[2023-07-01 11:33:20] [config] mini-batch-track-lr: false
[2023-07-01 11:33:20] [config] mini-batch-warmup: 0
[2023-07-01 11:33:20] [config] mini-batch-words: 0
[2023-07-01 11:33:20] [config] mini-batch-words-ref: 0
[2023-07-01 11:33:20] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:33:20] [config] multi-loss-type: sum
[2023-07-01 11:33:20] [config] n-best: false
[2023-07-01 11:33:20] [config] no-nccl: false
[2023-07-01 11:33:20] [config] no-reload: false
[2023-07-01 11:33:20] [config] no-restore-corpus: false
[2023-07-01 11:33:20] [config] normalize: 1
[2023-07-01 11:33:20] [config] normalize-gradient: false
[2023-07-01 11:33:20] [config] num-devices: 0
[2023-07-01 11:33:20] [config] optimizer: adam
[2023-07-01 11:33:20] [config] optimizer-delay: 1
[2023-07-01 11:33:20] [config] optimizer-params:
[2023-07-01 11:33:20] [config]   - 0.9
[2023-07-01 11:33:20] [config]   - 0.98
[2023-07-01 11:33:20] [config]   - 1e-09
[2023-07-01 11:33:20] [config] output-omit-bias: false
[2023-07-01 11:33:20] [config] overwrite: true
[2023-07-01 11:33:20] [config] precision:
[2023-07-01 11:33:20] [config]   - float32
[2023-07-01 11:33:20] [config]   - float32
[2023-07-01 11:33:20] [config] pretrained-model: ""
[2023-07-01 11:33:20] [config] quantize-biases: false
[2023-07-01 11:33:20] [config] quantize-bits: 0
[2023-07-01 11:33:20] [config] quantize-log-based: false
[2023-07-01 11:33:20] [config] quantize-optimization-steps: 0
[2023-07-01 11:33:20] [config] quiet: false
[2023-07-01 11:33:20] [config] quiet-translation: true
[2023-07-01 11:33:20] [config] relative-paths: false
[2023-07-01 11:33:20] [config] right-left: false
[2023-07-01 11:33:20] [config] save-freq: 10000u
[2023-07-01 11:33:20] [config] seed: 1234
[2023-07-01 11:33:20] [config] sentencepiece-alphas:
[2023-07-01 11:33:20] [config]   []
[2023-07-01 11:33:20] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:33:20] [config] sentencepiece-options: ""
[2023-07-01 11:33:20] [config] sharding: global
[2023-07-01 11:33:20] [config] shuffle: data
[2023-07-01 11:33:20] [config] shuffle-in-ram: false
[2023-07-01 11:33:20] [config] sigterm: save-and-exit
[2023-07-01 11:33:20] [config] skip: false
[2023-07-01 11:33:20] [config] sqlite: ""
[2023-07-01 11:33:20] [config] sqlite-drop: false
[2023-07-01 11:33:20] [config] sync-freq: 200u
[2023-07-01 11:33:20] [config] sync-sgd: true
[2023-07-01 11:33:20] [config] tempdir: /tmp
[2023-07-01 11:33:20] [config] tied-embeddings: false
[2023-07-01 11:33:20] [config] tied-embeddings-all: true
[2023-07-01 11:33:20] [config] tied-embeddings-src: false
[2023-07-01 11:33:20] [config] train-embedder-rank:
[2023-07-01 11:33:20] [config]   []
[2023-07-01 11:33:20] [config] train-sets:
[2023-07-01 11:33:20] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:33:20] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:33:20] [config] transformer-aan-activation: swish
[2023-07-01 11:33:20] [config] transformer-aan-depth: 2
[2023-07-01 11:33:20] [config] transformer-aan-nogate: false
[2023-07-01 11:33:20] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:33:20] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:33:20] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:33:20] [config] transformer-depth-scaling: false
[2023-07-01 11:33:20] [config] transformer-dim-aan: 2048
[2023-07-01 11:33:20] [config] transformer-dim-ffn: 2048
[2023-07-01 11:33:20] [config] transformer-dropout: 0.1
[2023-07-01 11:33:20] [config] transformer-dropout-attention: 0
[2023-07-01 11:33:20] [config] transformer-dropout-ffn: 0
[2023-07-01 11:33:20] [config] transformer-ffn-activation: swish
[2023-07-01 11:33:20] [config] transformer-ffn-depth: 2
[2023-07-01 11:33:20] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:33:20] [config] transformer-heads: 8
[2023-07-01 11:33:20] [config] transformer-no-projection: false
[2023-07-01 11:33:20] [config] transformer-pool: false
[2023-07-01 11:33:20] [config] transformer-postprocess: dan
[2023-07-01 11:33:20] [config] transformer-postprocess-emb: d
[2023-07-01 11:33:20] [config] transformer-postprocess-top: ""
[2023-07-01 11:33:20] [config] transformer-preprocess: ""
[2023-07-01 11:33:20] [config] transformer-tied-layers:
[2023-07-01 11:33:20] [config]   []
[2023-07-01 11:33:20] [config] transformer-train-position-embeddings: false
[2023-07-01 11:33:20] [config] tsv: false
[2023-07-01 11:33:20] [config] tsv-fields: 0
[2023-07-01 11:33:20] [config] type: transformer
[2023-07-01 11:33:20] [config] ulr: false
[2023-07-01 11:33:20] [config] ulr-dim-emb: 0
[2023-07-01 11:33:20] [config] ulr-dropout: 0
[2023-07-01 11:33:20] [config] ulr-keys-vectors: ""
[2023-07-01 11:33:20] [config] ulr-query-vectors: ""
[2023-07-01 11:33:20] [config] ulr-softmax-temperature: 1
[2023-07-01 11:33:20] [config] ulr-trainable-transformation: false
[2023-07-01 11:33:20] [config] unlikelihood-loss: false
[2023-07-01 11:33:20] [config] valid-freq: 50000000
[2023-07-01 11:33:20] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:33:20] [config] valid-max-length: 1000
[2023-07-01 11:33:20] [config] valid-metrics:
[2023-07-01 11:33:20] [config]   - cross-entropy
[2023-07-01 11:33:20] [config]   - translation
[2023-07-01 11:33:20] [config] valid-mini-batch: 64
[2023-07-01 11:33:20] [config] valid-reset-stalled: false
[2023-07-01 11:33:20] [config] valid-script-args:
[2023-07-01 11:33:20] [config]   []
[2023-07-01 11:33:20] [config] valid-script-path: ""
[2023-07-01 11:33:20] [config] valid-sets:
[2023-07-01 11:33:20] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:33:20] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:33:20] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:33:20] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:33:20] [config] vocabs:
[2023-07-01 11:33:20] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:33:20] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:33:20] [config] word-penalty: 0
[2023-07-01 11:33:20] [config] word-scores: false
[2023-07-01 11:33:20] [config] workspace: 2048
[2023-07-01 11:33:20] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:33:20] Using synchronous SGD
[2023-07-01 11:33:21] Synced seed 1234
[2023-07-01 11:33:21] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:33:21] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:33:21] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:33:21] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:33:21] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:33:21] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:33:21] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:33:21] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:33:21] [comm] Using global sharding
[2023-07-01 11:33:22] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:33:22] [training] Using 1 GPUs
[2023-07-01 11:33:22] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:33:22] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:33:22] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:33:22] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:33:29] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:33:29] [valid] No post-processing script given for validating translator
[2023-07-01 11:33:29] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:33:29] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:33:29] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:33:29] [comm] Using global sharding
[2023-07-01 11:33:29] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:33:29] [training] Using 1 GPUs
[2023-07-01 11:33:29] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:33:30] Allocating memory for general optimizer shards
[2023-07-01 11:33:30] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:33:30] Loading Adam parameters
[2023-07-01 11:33:30] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:33:30] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:33:30] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:33:30] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:33:30] [data] Shuffling data
[2023-07-01 11:33:30] [data] Done reading 20,192 sentences
[2023-07-01 11:33:30] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:33:30] Training started
[2023-07-01 11:33:30] Training finished
[2023-07-01 11:33:34] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:33:34] [marian] Running on node20.datos.cluster.uy as process 17512 with command line:
[2023-07-01 11:33:34] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 109 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:33:34] [config] after: 0e
[2023-07-01 11:33:34] [config] after-batches: 0
[2023-07-01 11:33:34] [config] after-epochs: 109
[2023-07-01 11:33:34] [config] all-caps-every: 0
[2023-07-01 11:33:34] [config] allow-unk: false
[2023-07-01 11:33:34] [config] authors: false
[2023-07-01 11:33:34] [config] beam-size: 12
[2023-07-01 11:33:34] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:33:34] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:33:34] [config] bert-masking-fraction: 0.15
[2023-07-01 11:33:34] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:33:34] [config] bert-train-type-embeddings: true
[2023-07-01 11:33:34] [config] bert-type-vocab-size: 2
[2023-07-01 11:33:34] [config] build-info: ""
[2023-07-01 11:33:34] [config] check-gradient-nan: false
[2023-07-01 11:33:34] [config] check-nan: false
[2023-07-01 11:33:34] [config] cite: false
[2023-07-01 11:33:34] [config] clip-norm: 5
[2023-07-01 11:33:34] [config] cost-scaling:
[2023-07-01 11:33:34] [config]   []
[2023-07-01 11:33:34] [config] cost-type: ce-sum
[2023-07-01 11:33:34] [config] cpu-threads: 0
[2023-07-01 11:33:34] [config] data-threads: 8
[2023-07-01 11:33:34] [config] data-weighting: ""
[2023-07-01 11:33:34] [config] data-weighting-type: sentence
[2023-07-01 11:33:34] [config] dec-cell: gru
[2023-07-01 11:33:34] [config] dec-cell-base-depth: 2
[2023-07-01 11:33:34] [config] dec-cell-high-depth: 1
[2023-07-01 11:33:34] [config] dec-depth: 2
[2023-07-01 11:33:34] [config] devices:
[2023-07-01 11:33:34] [config]   - 0
[2023-07-01 11:33:34] [config] dim-emb: 512
[2023-07-01 11:33:34] [config] dim-rnn: 1024
[2023-07-01 11:33:34] [config] dim-vocabs:
[2023-07-01 11:33:34] [config]   - 16384
[2023-07-01 11:33:34] [config]   - 16384
[2023-07-01 11:33:34] [config] disp-first: 0
[2023-07-01 11:33:34] [config] disp-freq: 1000u
[2023-07-01 11:33:34] [config] disp-label-counts: true
[2023-07-01 11:33:34] [config] dropout-rnn: 0
[2023-07-01 11:33:34] [config] dropout-src: 0
[2023-07-01 11:33:34] [config] dropout-trg: 0
[2023-07-01 11:33:34] [config] dump-config: ""
[2023-07-01 11:33:34] [config] dynamic-gradient-scaling:
[2023-07-01 11:33:34] [config]   []
[2023-07-01 11:33:34] [config] early-stopping: 10
[2023-07-01 11:33:34] [config] early-stopping-on: first
[2023-07-01 11:33:34] [config] embedding-fix-src: false
[2023-07-01 11:33:34] [config] embedding-fix-trg: false
[2023-07-01 11:33:34] [config] embedding-normalization: false
[2023-07-01 11:33:34] [config] embedding-vectors:
[2023-07-01 11:33:34] [config]   []
[2023-07-01 11:33:34] [config] enc-cell: gru
[2023-07-01 11:33:34] [config] enc-cell-depth: 1
[2023-07-01 11:33:34] [config] enc-depth: 2
[2023-07-01 11:33:34] [config] enc-type: bidirectional
[2023-07-01 11:33:34] [config] english-title-case-every: 0
[2023-07-01 11:33:34] [config] exponential-smoothing: 0.0001
[2023-07-01 11:33:34] [config] factor-weight: 1
[2023-07-01 11:33:34] [config] factors-combine: sum
[2023-07-01 11:33:34] [config] factors-dim-emb: 0
[2023-07-01 11:33:34] [config] gradient-checkpointing: false
[2023-07-01 11:33:34] [config] gradient-norm-average-window: 100
[2023-07-01 11:33:34] [config] guided-alignment: none
[2023-07-01 11:33:34] [config] guided-alignment-cost: mse
[2023-07-01 11:33:34] [config] guided-alignment-weight: 0.1
[2023-07-01 11:33:34] [config] ignore-model-config: false
[2023-07-01 11:33:34] [config] input-types:
[2023-07-01 11:33:34] [config]   []
[2023-07-01 11:33:34] [config] interpolate-env-vars: false
[2023-07-01 11:33:34] [config] keep-best: false
[2023-07-01 11:33:34] [config] label-smoothing: 0.1
[2023-07-01 11:33:34] [config] layer-normalization: false
[2023-07-01 11:33:34] [config] learn-rate: 0.0003
[2023-07-01 11:33:34] [config] lemma-dependency: ""
[2023-07-01 11:33:34] [config] lemma-dim-emb: 0
[2023-07-01 11:33:34] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:33:34] [config] log-level: info
[2023-07-01 11:33:34] [config] log-time-zone: ""
[2023-07-01 11:33:34] [config] logical-epoch:
[2023-07-01 11:33:34] [config]   - 1e
[2023-07-01 11:33:34] [config]   - 0
[2023-07-01 11:33:34] [config] lr-decay: 0
[2023-07-01 11:33:34] [config] lr-decay-freq: 50000
[2023-07-01 11:33:34] [config] lr-decay-inv-sqrt:
[2023-07-01 11:33:34] [config]   - 16000
[2023-07-01 11:33:34] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:33:34] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:33:34] [config] lr-decay-start:
[2023-07-01 11:33:34] [config]   - 10
[2023-07-01 11:33:34] [config]   - 1
[2023-07-01 11:33:34] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:33:34] [config] lr-report: true
[2023-07-01 11:33:34] [config] lr-warmup: 16000
[2023-07-01 11:33:34] [config] lr-warmup-at-reload: false
[2023-07-01 11:33:34] [config] lr-warmup-cycle: false
[2023-07-01 11:33:34] [config] lr-warmup-start-rate: 0
[2023-07-01 11:33:34] [config] max-length: 100
[2023-07-01 11:33:34] [config] max-length-crop: false
[2023-07-01 11:33:34] [config] max-length-factor: 3
[2023-07-01 11:33:34] [config] maxi-batch: 100
[2023-07-01 11:33:34] [config] maxi-batch-sort: trg
[2023-07-01 11:33:34] [config] mini-batch: 1000
[2023-07-01 11:33:34] [config] mini-batch-fit: true
[2023-07-01 11:33:34] [config] mini-batch-fit-step: 10
[2023-07-01 11:33:34] [config] mini-batch-round-up: true
[2023-07-01 11:33:34] [config] mini-batch-track-lr: false
[2023-07-01 11:33:34] [config] mini-batch-warmup: 0
[2023-07-01 11:33:34] [config] mini-batch-words: 0
[2023-07-01 11:33:34] [config] mini-batch-words-ref: 0
[2023-07-01 11:33:34] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:33:34] [config] multi-loss-type: sum
[2023-07-01 11:33:34] [config] n-best: false
[2023-07-01 11:33:34] [config] no-nccl: false
[2023-07-01 11:33:34] [config] no-reload: false
[2023-07-01 11:33:34] [config] no-restore-corpus: false
[2023-07-01 11:33:34] [config] normalize: 1
[2023-07-01 11:33:34] [config] normalize-gradient: false
[2023-07-01 11:33:34] [config] num-devices: 0
[2023-07-01 11:33:34] [config] optimizer: adam
[2023-07-01 11:33:34] [config] optimizer-delay: 1
[2023-07-01 11:33:34] [config] optimizer-params:
[2023-07-01 11:33:34] [config]   - 0.9
[2023-07-01 11:33:34] [config]   - 0.98
[2023-07-01 11:33:34] [config]   - 1e-09
[2023-07-01 11:33:34] [config] output-omit-bias: false
[2023-07-01 11:33:34] [config] overwrite: true
[2023-07-01 11:33:34] [config] precision:
[2023-07-01 11:33:34] [config]   - float32
[2023-07-01 11:33:34] [config]   - float32
[2023-07-01 11:33:34] [config] pretrained-model: ""
[2023-07-01 11:33:34] [config] quantize-biases: false
[2023-07-01 11:33:34] [config] quantize-bits: 0
[2023-07-01 11:33:34] [config] quantize-log-based: false
[2023-07-01 11:33:34] [config] quantize-optimization-steps: 0
[2023-07-01 11:33:34] [config] quiet: false
[2023-07-01 11:33:34] [config] quiet-translation: true
[2023-07-01 11:33:34] [config] relative-paths: false
[2023-07-01 11:33:34] [config] right-left: false
[2023-07-01 11:33:34] [config] save-freq: 10000u
[2023-07-01 11:33:34] [config] seed: 1234
[2023-07-01 11:33:34] [config] sentencepiece-alphas:
[2023-07-01 11:33:34] [config]   []
[2023-07-01 11:33:34] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:33:34] [config] sentencepiece-options: ""
[2023-07-01 11:33:34] [config] sharding: global
[2023-07-01 11:33:34] [config] shuffle: data
[2023-07-01 11:33:34] [config] shuffle-in-ram: false
[2023-07-01 11:33:34] [config] sigterm: save-and-exit
[2023-07-01 11:33:34] [config] skip: false
[2023-07-01 11:33:34] [config] sqlite: ""
[2023-07-01 11:33:34] [config] sqlite-drop: false
[2023-07-01 11:33:34] [config] sync-freq: 200u
[2023-07-01 11:33:34] [config] sync-sgd: true
[2023-07-01 11:33:34] [config] tempdir: /tmp
[2023-07-01 11:33:34] [config] tied-embeddings: false
[2023-07-01 11:33:34] [config] tied-embeddings-all: true
[2023-07-01 11:33:34] [config] tied-embeddings-src: false
[2023-07-01 11:33:34] [config] train-embedder-rank:
[2023-07-01 11:33:34] [config]   []
[2023-07-01 11:33:34] [config] train-sets:
[2023-07-01 11:33:34] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:33:34] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:33:34] [config] transformer-aan-activation: swish
[2023-07-01 11:33:34] [config] transformer-aan-depth: 2
[2023-07-01 11:33:34] [config] transformer-aan-nogate: false
[2023-07-01 11:33:34] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:33:34] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:33:34] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:33:34] [config] transformer-depth-scaling: false
[2023-07-01 11:33:34] [config] transformer-dim-aan: 2048
[2023-07-01 11:33:34] [config] transformer-dim-ffn: 2048
[2023-07-01 11:33:34] [config] transformer-dropout: 0.1
[2023-07-01 11:33:34] [config] transformer-dropout-attention: 0
[2023-07-01 11:33:34] [config] transformer-dropout-ffn: 0
[2023-07-01 11:33:34] [config] transformer-ffn-activation: swish
[2023-07-01 11:33:34] [config] transformer-ffn-depth: 2
[2023-07-01 11:33:34] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:33:34] [config] transformer-heads: 8
[2023-07-01 11:33:34] [config] transformer-no-projection: false
[2023-07-01 11:33:34] [config] transformer-pool: false
[2023-07-01 11:33:34] [config] transformer-postprocess: dan
[2023-07-01 11:33:34] [config] transformer-postprocess-emb: d
[2023-07-01 11:33:34] [config] transformer-postprocess-top: ""
[2023-07-01 11:33:34] [config] transformer-preprocess: ""
[2023-07-01 11:33:34] [config] transformer-tied-layers:
[2023-07-01 11:33:34] [config]   []
[2023-07-01 11:33:34] [config] transformer-train-position-embeddings: false
[2023-07-01 11:33:34] [config] tsv: false
[2023-07-01 11:33:34] [config] tsv-fields: 0
[2023-07-01 11:33:34] [config] type: transformer
[2023-07-01 11:33:34] [config] ulr: false
[2023-07-01 11:33:34] [config] ulr-dim-emb: 0
[2023-07-01 11:33:34] [config] ulr-dropout: 0
[2023-07-01 11:33:34] [config] ulr-keys-vectors: ""
[2023-07-01 11:33:34] [config] ulr-query-vectors: ""
[2023-07-01 11:33:34] [config] ulr-softmax-temperature: 1
[2023-07-01 11:33:34] [config] ulr-trainable-transformation: false
[2023-07-01 11:33:34] [config] unlikelihood-loss: false
[2023-07-01 11:33:34] [config] valid-freq: 50000000
[2023-07-01 11:33:34] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:33:34] [config] valid-max-length: 1000
[2023-07-01 11:33:34] [config] valid-metrics:
[2023-07-01 11:33:34] [config]   - cross-entropy
[2023-07-01 11:33:34] [config]   - translation
[2023-07-01 11:33:34] [config] valid-mini-batch: 64
[2023-07-01 11:33:34] [config] valid-reset-stalled: false
[2023-07-01 11:33:34] [config] valid-script-args:
[2023-07-01 11:33:34] [config]   []
[2023-07-01 11:33:34] [config] valid-script-path: ""
[2023-07-01 11:33:34] [config] valid-sets:
[2023-07-01 11:33:34] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:33:34] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:33:34] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:33:34] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:33:34] [config] vocabs:
[2023-07-01 11:33:34] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:33:34] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:33:34] [config] word-penalty: 0
[2023-07-01 11:33:34] [config] word-scores: false
[2023-07-01 11:33:34] [config] workspace: 2048
[2023-07-01 11:33:34] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:33:34] Using synchronous SGD
[2023-07-01 11:33:34] Synced seed 1234
[2023-07-01 11:33:34] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:33:34] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:33:34] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:33:34] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:33:34] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:33:34] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:33:35] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:33:35] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:33:35] [comm] Using global sharding
[2023-07-01 11:33:35] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:33:35] [training] Using 1 GPUs
[2023-07-01 11:33:35] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:33:35] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:33:35] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:33:35] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:33:43] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:33:43] [valid] No post-processing script given for validating translator
[2023-07-01 11:33:43] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:33:43] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:33:43] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:33:43] [comm] Using global sharding
[2023-07-01 11:33:43] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:33:43] [training] Using 1 GPUs
[2023-07-01 11:33:43] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:33:43] Allocating memory for general optimizer shards
[2023-07-01 11:33:43] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:33:43] Loading Adam parameters
[2023-07-01 11:33:44] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:33:44] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:33:44] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:33:44] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:33:44] [data] Shuffling data
[2023-07-01 11:33:44] [data] Done reading 20,192 sentences
[2023-07-01 11:33:44] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:33:44] Training started
[2023-07-01 11:33:44] Training finished
[2023-07-01 11:33:47] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:33:47] [marian] Running on node20.datos.cluster.uy as process 17570 with command line:
[2023-07-01 11:33:47] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 110 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:33:47] [config] after: 0e
[2023-07-01 11:33:47] [config] after-batches: 0
[2023-07-01 11:33:47] [config] after-epochs: 110
[2023-07-01 11:33:47] [config] all-caps-every: 0
[2023-07-01 11:33:47] [config] allow-unk: false
[2023-07-01 11:33:47] [config] authors: false
[2023-07-01 11:33:47] [config] beam-size: 12
[2023-07-01 11:33:47] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:33:47] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:33:47] [config] bert-masking-fraction: 0.15
[2023-07-01 11:33:47] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:33:47] [config] bert-train-type-embeddings: true
[2023-07-01 11:33:47] [config] bert-type-vocab-size: 2
[2023-07-01 11:33:47] [config] build-info: ""
[2023-07-01 11:33:47] [config] check-gradient-nan: false
[2023-07-01 11:33:47] [config] check-nan: false
[2023-07-01 11:33:47] [config] cite: false
[2023-07-01 11:33:47] [config] clip-norm: 5
[2023-07-01 11:33:47] [config] cost-scaling:
[2023-07-01 11:33:47] [config]   []
[2023-07-01 11:33:47] [config] cost-type: ce-sum
[2023-07-01 11:33:47] [config] cpu-threads: 0
[2023-07-01 11:33:47] [config] data-threads: 8
[2023-07-01 11:33:47] [config] data-weighting: ""
[2023-07-01 11:33:47] [config] data-weighting-type: sentence
[2023-07-01 11:33:47] [config] dec-cell: gru
[2023-07-01 11:33:47] [config] dec-cell-base-depth: 2
[2023-07-01 11:33:47] [config] dec-cell-high-depth: 1
[2023-07-01 11:33:47] [config] dec-depth: 2
[2023-07-01 11:33:47] [config] devices:
[2023-07-01 11:33:47] [config]   - 0
[2023-07-01 11:33:47] [config] dim-emb: 512
[2023-07-01 11:33:47] [config] dim-rnn: 1024
[2023-07-01 11:33:47] [config] dim-vocabs:
[2023-07-01 11:33:47] [config]   - 16384
[2023-07-01 11:33:47] [config]   - 16384
[2023-07-01 11:33:47] [config] disp-first: 0
[2023-07-01 11:33:47] [config] disp-freq: 1000u
[2023-07-01 11:33:47] [config] disp-label-counts: true
[2023-07-01 11:33:47] [config] dropout-rnn: 0
[2023-07-01 11:33:47] [config] dropout-src: 0
[2023-07-01 11:33:47] [config] dropout-trg: 0
[2023-07-01 11:33:47] [config] dump-config: ""
[2023-07-01 11:33:47] [config] dynamic-gradient-scaling:
[2023-07-01 11:33:47] [config]   []
[2023-07-01 11:33:47] [config] early-stopping: 10
[2023-07-01 11:33:47] [config] early-stopping-on: first
[2023-07-01 11:33:47] [config] embedding-fix-src: false
[2023-07-01 11:33:47] [config] embedding-fix-trg: false
[2023-07-01 11:33:47] [config] embedding-normalization: false
[2023-07-01 11:33:47] [config] embedding-vectors:
[2023-07-01 11:33:47] [config]   []
[2023-07-01 11:33:47] [config] enc-cell: gru
[2023-07-01 11:33:47] [config] enc-cell-depth: 1
[2023-07-01 11:33:47] [config] enc-depth: 2
[2023-07-01 11:33:47] [config] enc-type: bidirectional
[2023-07-01 11:33:47] [config] english-title-case-every: 0
[2023-07-01 11:33:47] [config] exponential-smoothing: 0.0001
[2023-07-01 11:33:47] [config] factor-weight: 1
[2023-07-01 11:33:47] [config] factors-combine: sum
[2023-07-01 11:33:47] [config] factors-dim-emb: 0
[2023-07-01 11:33:47] [config] gradient-checkpointing: false
[2023-07-01 11:33:47] [config] gradient-norm-average-window: 100
[2023-07-01 11:33:47] [config] guided-alignment: none
[2023-07-01 11:33:47] [config] guided-alignment-cost: mse
[2023-07-01 11:33:47] [config] guided-alignment-weight: 0.1
[2023-07-01 11:33:47] [config] ignore-model-config: false
[2023-07-01 11:33:47] [config] input-types:
[2023-07-01 11:33:47] [config]   []
[2023-07-01 11:33:47] [config] interpolate-env-vars: false
[2023-07-01 11:33:47] [config] keep-best: false
[2023-07-01 11:33:47] [config] label-smoothing: 0.1
[2023-07-01 11:33:47] [config] layer-normalization: false
[2023-07-01 11:33:47] [config] learn-rate: 0.0003
[2023-07-01 11:33:47] [config] lemma-dependency: ""
[2023-07-01 11:33:47] [config] lemma-dim-emb: 0
[2023-07-01 11:33:47] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:33:47] [config] log-level: info
[2023-07-01 11:33:47] [config] log-time-zone: ""
[2023-07-01 11:33:47] [config] logical-epoch:
[2023-07-01 11:33:47] [config]   - 1e
[2023-07-01 11:33:47] [config]   - 0
[2023-07-01 11:33:47] [config] lr-decay: 0
[2023-07-01 11:33:47] [config] lr-decay-freq: 50000
[2023-07-01 11:33:47] [config] lr-decay-inv-sqrt:
[2023-07-01 11:33:47] [config]   - 16000
[2023-07-01 11:33:47] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:33:47] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:33:47] [config] lr-decay-start:
[2023-07-01 11:33:47] [config]   - 10
[2023-07-01 11:33:47] [config]   - 1
[2023-07-01 11:33:47] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:33:47] [config] lr-report: true
[2023-07-01 11:33:47] [config] lr-warmup: 16000
[2023-07-01 11:33:47] [config] lr-warmup-at-reload: false
[2023-07-01 11:33:47] [config] lr-warmup-cycle: false
[2023-07-01 11:33:47] [config] lr-warmup-start-rate: 0
[2023-07-01 11:33:47] [config] max-length: 100
[2023-07-01 11:33:47] [config] max-length-crop: false
[2023-07-01 11:33:47] [config] max-length-factor: 3
[2023-07-01 11:33:47] [config] maxi-batch: 100
[2023-07-01 11:33:47] [config] maxi-batch-sort: trg
[2023-07-01 11:33:47] [config] mini-batch: 1000
[2023-07-01 11:33:47] [config] mini-batch-fit: true
[2023-07-01 11:33:47] [config] mini-batch-fit-step: 10
[2023-07-01 11:33:47] [config] mini-batch-round-up: true
[2023-07-01 11:33:47] [config] mini-batch-track-lr: false
[2023-07-01 11:33:47] [config] mini-batch-warmup: 0
[2023-07-01 11:33:47] [config] mini-batch-words: 0
[2023-07-01 11:33:47] [config] mini-batch-words-ref: 0
[2023-07-01 11:33:47] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:33:47] [config] multi-loss-type: sum
[2023-07-01 11:33:47] [config] n-best: false
[2023-07-01 11:33:47] [config] no-nccl: false
[2023-07-01 11:33:47] [config] no-reload: false
[2023-07-01 11:33:47] [config] no-restore-corpus: false
[2023-07-01 11:33:47] [config] normalize: 1
[2023-07-01 11:33:47] [config] normalize-gradient: false
[2023-07-01 11:33:47] [config] num-devices: 0
[2023-07-01 11:33:47] [config] optimizer: adam
[2023-07-01 11:33:47] [config] optimizer-delay: 1
[2023-07-01 11:33:47] [config] optimizer-params:
[2023-07-01 11:33:47] [config]   - 0.9
[2023-07-01 11:33:47] [config]   - 0.98
[2023-07-01 11:33:47] [config]   - 1e-09
[2023-07-01 11:33:47] [config] output-omit-bias: false
[2023-07-01 11:33:47] [config] overwrite: true
[2023-07-01 11:33:47] [config] precision:
[2023-07-01 11:33:47] [config]   - float32
[2023-07-01 11:33:47] [config]   - float32
[2023-07-01 11:33:47] [config] pretrained-model: ""
[2023-07-01 11:33:47] [config] quantize-biases: false
[2023-07-01 11:33:47] [config] quantize-bits: 0
[2023-07-01 11:33:47] [config] quantize-log-based: false
[2023-07-01 11:33:47] [config] quantize-optimization-steps: 0
[2023-07-01 11:33:47] [config] quiet: false
[2023-07-01 11:33:47] [config] quiet-translation: true
[2023-07-01 11:33:47] [config] relative-paths: false
[2023-07-01 11:33:47] [config] right-left: false
[2023-07-01 11:33:47] [config] save-freq: 10000u
[2023-07-01 11:33:47] [config] seed: 1234
[2023-07-01 11:33:47] [config] sentencepiece-alphas:
[2023-07-01 11:33:47] [config]   []
[2023-07-01 11:33:47] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:33:47] [config] sentencepiece-options: ""
[2023-07-01 11:33:47] [config] sharding: global
[2023-07-01 11:33:47] [config] shuffle: data
[2023-07-01 11:33:47] [config] shuffle-in-ram: false
[2023-07-01 11:33:47] [config] sigterm: save-and-exit
[2023-07-01 11:33:47] [config] skip: false
[2023-07-01 11:33:47] [config] sqlite: ""
[2023-07-01 11:33:47] [config] sqlite-drop: false
[2023-07-01 11:33:47] [config] sync-freq: 200u
[2023-07-01 11:33:47] [config] sync-sgd: true
[2023-07-01 11:33:47] [config] tempdir: /tmp
[2023-07-01 11:33:47] [config] tied-embeddings: false
[2023-07-01 11:33:47] [config] tied-embeddings-all: true
[2023-07-01 11:33:47] [config] tied-embeddings-src: false
[2023-07-01 11:33:47] [config] train-embedder-rank:
[2023-07-01 11:33:47] [config]   []
[2023-07-01 11:33:47] [config] train-sets:
[2023-07-01 11:33:47] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:33:47] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:33:47] [config] transformer-aan-activation: swish
[2023-07-01 11:33:47] [config] transformer-aan-depth: 2
[2023-07-01 11:33:47] [config] transformer-aan-nogate: false
[2023-07-01 11:33:47] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:33:47] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:33:47] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:33:47] [config] transformer-depth-scaling: false
[2023-07-01 11:33:47] [config] transformer-dim-aan: 2048
[2023-07-01 11:33:47] [config] transformer-dim-ffn: 2048
[2023-07-01 11:33:47] [config] transformer-dropout: 0.1
[2023-07-01 11:33:47] [config] transformer-dropout-attention: 0
[2023-07-01 11:33:47] [config] transformer-dropout-ffn: 0
[2023-07-01 11:33:47] [config] transformer-ffn-activation: swish
[2023-07-01 11:33:47] [config] transformer-ffn-depth: 2
[2023-07-01 11:33:47] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:33:47] [config] transformer-heads: 8
[2023-07-01 11:33:47] [config] transformer-no-projection: false
[2023-07-01 11:33:47] [config] transformer-pool: false
[2023-07-01 11:33:47] [config] transformer-postprocess: dan
[2023-07-01 11:33:47] [config] transformer-postprocess-emb: d
[2023-07-01 11:33:47] [config] transformer-postprocess-top: ""
[2023-07-01 11:33:47] [config] transformer-preprocess: ""
[2023-07-01 11:33:47] [config] transformer-tied-layers:
[2023-07-01 11:33:47] [config]   []
[2023-07-01 11:33:47] [config] transformer-train-position-embeddings: false
[2023-07-01 11:33:47] [config] tsv: false
[2023-07-01 11:33:47] [config] tsv-fields: 0
[2023-07-01 11:33:47] [config] type: transformer
[2023-07-01 11:33:47] [config] ulr: false
[2023-07-01 11:33:47] [config] ulr-dim-emb: 0
[2023-07-01 11:33:47] [config] ulr-dropout: 0
[2023-07-01 11:33:47] [config] ulr-keys-vectors: ""
[2023-07-01 11:33:47] [config] ulr-query-vectors: ""
[2023-07-01 11:33:47] [config] ulr-softmax-temperature: 1
[2023-07-01 11:33:47] [config] ulr-trainable-transformation: false
[2023-07-01 11:33:47] [config] unlikelihood-loss: false
[2023-07-01 11:33:47] [config] valid-freq: 50000000
[2023-07-01 11:33:47] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:33:47] [config] valid-max-length: 1000
[2023-07-01 11:33:47] [config] valid-metrics:
[2023-07-01 11:33:47] [config]   - cross-entropy
[2023-07-01 11:33:47] [config]   - translation
[2023-07-01 11:33:47] [config] valid-mini-batch: 64
[2023-07-01 11:33:47] [config] valid-reset-stalled: false
[2023-07-01 11:33:47] [config] valid-script-args:
[2023-07-01 11:33:47] [config]   []
[2023-07-01 11:33:47] [config] valid-script-path: ""
[2023-07-01 11:33:47] [config] valid-sets:
[2023-07-01 11:33:47] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:33:47] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:33:47] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:33:47] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:33:47] [config] vocabs:
[2023-07-01 11:33:47] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:33:47] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:33:47] [config] word-penalty: 0
[2023-07-01 11:33:47] [config] word-scores: false
[2023-07-01 11:33:47] [config] workspace: 2048
[2023-07-01 11:33:47] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:33:47] Using synchronous SGD
[2023-07-01 11:33:48] Synced seed 1234
[2023-07-01 11:33:48] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:33:48] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:33:48] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:33:48] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:33:48] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:33:48] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:33:48] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:33:48] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:33:48] [comm] Using global sharding
[2023-07-01 11:33:48] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:33:48] [training] Using 1 GPUs
[2023-07-01 11:33:48] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:33:48] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:33:49] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:33:49] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:33:56] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:33:56] [valid] No post-processing script given for validating translator
[2023-07-01 11:33:56] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:33:56] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:33:56] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:33:56] [comm] Using global sharding
[2023-07-01 11:33:56] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:33:56] [training] Using 1 GPUs
[2023-07-01 11:33:56] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:33:57] Allocating memory for general optimizer shards
[2023-07-01 11:33:57] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:33:57] Loading Adam parameters
[2023-07-01 11:33:57] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:33:57] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:33:57] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:33:57] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:33:57] [data] Shuffling data
[2023-07-01 11:33:57] [data] Done reading 20,192 sentences
[2023-07-01 11:33:57] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:33:57] Training started
[2023-07-01 11:33:57] Training finished
[2023-07-01 11:34:00] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:34:00] [marian] Running on node20.datos.cluster.uy as process 17629 with command line:
[2023-07-01 11:34:00] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 111 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:34:00] [config] after: 0e
[2023-07-01 11:34:00] [config] after-batches: 0
[2023-07-01 11:34:00] [config] after-epochs: 111
[2023-07-01 11:34:00] [config] all-caps-every: 0
[2023-07-01 11:34:00] [config] allow-unk: false
[2023-07-01 11:34:00] [config] authors: false
[2023-07-01 11:34:00] [config] beam-size: 12
[2023-07-01 11:34:00] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:34:00] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:34:00] [config] bert-masking-fraction: 0.15
[2023-07-01 11:34:00] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:34:00] [config] bert-train-type-embeddings: true
[2023-07-01 11:34:00] [config] bert-type-vocab-size: 2
[2023-07-01 11:34:00] [config] build-info: ""
[2023-07-01 11:34:00] [config] check-gradient-nan: false
[2023-07-01 11:34:00] [config] check-nan: false
[2023-07-01 11:34:00] [config] cite: false
[2023-07-01 11:34:00] [config] clip-norm: 5
[2023-07-01 11:34:00] [config] cost-scaling:
[2023-07-01 11:34:00] [config]   []
[2023-07-01 11:34:00] [config] cost-type: ce-sum
[2023-07-01 11:34:00] [config] cpu-threads: 0
[2023-07-01 11:34:00] [config] data-threads: 8
[2023-07-01 11:34:00] [config] data-weighting: ""
[2023-07-01 11:34:00] [config] data-weighting-type: sentence
[2023-07-01 11:34:00] [config] dec-cell: gru
[2023-07-01 11:34:00] [config] dec-cell-base-depth: 2
[2023-07-01 11:34:00] [config] dec-cell-high-depth: 1
[2023-07-01 11:34:00] [config] dec-depth: 2
[2023-07-01 11:34:00] [config] devices:
[2023-07-01 11:34:00] [config]   - 0
[2023-07-01 11:34:00] [config] dim-emb: 512
[2023-07-01 11:34:00] [config] dim-rnn: 1024
[2023-07-01 11:34:00] [config] dim-vocabs:
[2023-07-01 11:34:00] [config]   - 16384
[2023-07-01 11:34:00] [config]   - 16384
[2023-07-01 11:34:00] [config] disp-first: 0
[2023-07-01 11:34:00] [config] disp-freq: 1000u
[2023-07-01 11:34:00] [config] disp-label-counts: true
[2023-07-01 11:34:00] [config] dropout-rnn: 0
[2023-07-01 11:34:00] [config] dropout-src: 0
[2023-07-01 11:34:00] [config] dropout-trg: 0
[2023-07-01 11:34:00] [config] dump-config: ""
[2023-07-01 11:34:00] [config] dynamic-gradient-scaling:
[2023-07-01 11:34:00] [config]   []
[2023-07-01 11:34:00] [config] early-stopping: 10
[2023-07-01 11:34:00] [config] early-stopping-on: first
[2023-07-01 11:34:00] [config] embedding-fix-src: false
[2023-07-01 11:34:00] [config] embedding-fix-trg: false
[2023-07-01 11:34:00] [config] embedding-normalization: false
[2023-07-01 11:34:00] [config] embedding-vectors:
[2023-07-01 11:34:00] [config]   []
[2023-07-01 11:34:00] [config] enc-cell: gru
[2023-07-01 11:34:00] [config] enc-cell-depth: 1
[2023-07-01 11:34:00] [config] enc-depth: 2
[2023-07-01 11:34:00] [config] enc-type: bidirectional
[2023-07-01 11:34:00] [config] english-title-case-every: 0
[2023-07-01 11:34:00] [config] exponential-smoothing: 0.0001
[2023-07-01 11:34:00] [config] factor-weight: 1
[2023-07-01 11:34:00] [config] factors-combine: sum
[2023-07-01 11:34:00] [config] factors-dim-emb: 0
[2023-07-01 11:34:00] [config] gradient-checkpointing: false
[2023-07-01 11:34:00] [config] gradient-norm-average-window: 100
[2023-07-01 11:34:00] [config] guided-alignment: none
[2023-07-01 11:34:00] [config] guided-alignment-cost: mse
[2023-07-01 11:34:00] [config] guided-alignment-weight: 0.1
[2023-07-01 11:34:00] [config] ignore-model-config: false
[2023-07-01 11:34:00] [config] input-types:
[2023-07-01 11:34:00] [config]   []
[2023-07-01 11:34:00] [config] interpolate-env-vars: false
[2023-07-01 11:34:00] [config] keep-best: false
[2023-07-01 11:34:00] [config] label-smoothing: 0.1
[2023-07-01 11:34:00] [config] layer-normalization: false
[2023-07-01 11:34:00] [config] learn-rate: 0.0003
[2023-07-01 11:34:00] [config] lemma-dependency: ""
[2023-07-01 11:34:00] [config] lemma-dim-emb: 0
[2023-07-01 11:34:00] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:34:00] [config] log-level: info
[2023-07-01 11:34:00] [config] log-time-zone: ""
[2023-07-01 11:34:00] [config] logical-epoch:
[2023-07-01 11:34:00] [config]   - 1e
[2023-07-01 11:34:00] [config]   - 0
[2023-07-01 11:34:00] [config] lr-decay: 0
[2023-07-01 11:34:00] [config] lr-decay-freq: 50000
[2023-07-01 11:34:00] [config] lr-decay-inv-sqrt:
[2023-07-01 11:34:00] [config]   - 16000
[2023-07-01 11:34:00] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:34:00] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:34:00] [config] lr-decay-start:
[2023-07-01 11:34:00] [config]   - 10
[2023-07-01 11:34:00] [config]   - 1
[2023-07-01 11:34:00] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:34:00] [config] lr-report: true
[2023-07-01 11:34:00] [config] lr-warmup: 16000
[2023-07-01 11:34:00] [config] lr-warmup-at-reload: false
[2023-07-01 11:34:00] [config] lr-warmup-cycle: false
[2023-07-01 11:34:00] [config] lr-warmup-start-rate: 0
[2023-07-01 11:34:00] [config] max-length: 100
[2023-07-01 11:34:00] [config] max-length-crop: false
[2023-07-01 11:34:00] [config] max-length-factor: 3
[2023-07-01 11:34:00] [config] maxi-batch: 100
[2023-07-01 11:34:00] [config] maxi-batch-sort: trg
[2023-07-01 11:34:00] [config] mini-batch: 1000
[2023-07-01 11:34:00] [config] mini-batch-fit: true
[2023-07-01 11:34:00] [config] mini-batch-fit-step: 10
[2023-07-01 11:34:00] [config] mini-batch-round-up: true
[2023-07-01 11:34:00] [config] mini-batch-track-lr: false
[2023-07-01 11:34:00] [config] mini-batch-warmup: 0
[2023-07-01 11:34:00] [config] mini-batch-words: 0
[2023-07-01 11:34:00] [config] mini-batch-words-ref: 0
[2023-07-01 11:34:00] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:34:00] [config] multi-loss-type: sum
[2023-07-01 11:34:00] [config] n-best: false
[2023-07-01 11:34:00] [config] no-nccl: false
[2023-07-01 11:34:00] [config] no-reload: false
[2023-07-01 11:34:00] [config] no-restore-corpus: false
[2023-07-01 11:34:00] [config] normalize: 1
[2023-07-01 11:34:00] [config] normalize-gradient: false
[2023-07-01 11:34:00] [config] num-devices: 0
[2023-07-01 11:34:00] [config] optimizer: adam
[2023-07-01 11:34:00] [config] optimizer-delay: 1
[2023-07-01 11:34:00] [config] optimizer-params:
[2023-07-01 11:34:00] [config]   - 0.9
[2023-07-01 11:34:00] [config]   - 0.98
[2023-07-01 11:34:00] [config]   - 1e-09
[2023-07-01 11:34:00] [config] output-omit-bias: false
[2023-07-01 11:34:00] [config] overwrite: true
[2023-07-01 11:34:00] [config] precision:
[2023-07-01 11:34:00] [config]   - float32
[2023-07-01 11:34:00] [config]   - float32
[2023-07-01 11:34:00] [config] pretrained-model: ""
[2023-07-01 11:34:00] [config] quantize-biases: false
[2023-07-01 11:34:00] [config] quantize-bits: 0
[2023-07-01 11:34:00] [config] quantize-log-based: false
[2023-07-01 11:34:00] [config] quantize-optimization-steps: 0
[2023-07-01 11:34:00] [config] quiet: false
[2023-07-01 11:34:00] [config] quiet-translation: true
[2023-07-01 11:34:00] [config] relative-paths: false
[2023-07-01 11:34:00] [config] right-left: false
[2023-07-01 11:34:00] [config] save-freq: 10000u
[2023-07-01 11:34:00] [config] seed: 1234
[2023-07-01 11:34:00] [config] sentencepiece-alphas:
[2023-07-01 11:34:00] [config]   []
[2023-07-01 11:34:00] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:34:00] [config] sentencepiece-options: ""
[2023-07-01 11:34:00] [config] sharding: global
[2023-07-01 11:34:00] [config] shuffle: data
[2023-07-01 11:34:00] [config] shuffle-in-ram: false
[2023-07-01 11:34:00] [config] sigterm: save-and-exit
[2023-07-01 11:34:00] [config] skip: false
[2023-07-01 11:34:00] [config] sqlite: ""
[2023-07-01 11:34:00] [config] sqlite-drop: false
[2023-07-01 11:34:00] [config] sync-freq: 200u
[2023-07-01 11:34:00] [config] sync-sgd: true
[2023-07-01 11:34:00] [config] tempdir: /tmp
[2023-07-01 11:34:00] [config] tied-embeddings: false
[2023-07-01 11:34:00] [config] tied-embeddings-all: true
[2023-07-01 11:34:00] [config] tied-embeddings-src: false
[2023-07-01 11:34:00] [config] train-embedder-rank:
[2023-07-01 11:34:00] [config]   []
[2023-07-01 11:34:00] [config] train-sets:
[2023-07-01 11:34:00] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:34:00] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:34:00] [config] transformer-aan-activation: swish
[2023-07-01 11:34:00] [config] transformer-aan-depth: 2
[2023-07-01 11:34:00] [config] transformer-aan-nogate: false
[2023-07-01 11:34:00] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:34:00] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:34:00] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:34:00] [config] transformer-depth-scaling: false
[2023-07-01 11:34:00] [config] transformer-dim-aan: 2048
[2023-07-01 11:34:00] [config] transformer-dim-ffn: 2048
[2023-07-01 11:34:00] [config] transformer-dropout: 0.1
[2023-07-01 11:34:00] [config] transformer-dropout-attention: 0
[2023-07-01 11:34:00] [config] transformer-dropout-ffn: 0
[2023-07-01 11:34:00] [config] transformer-ffn-activation: swish
[2023-07-01 11:34:00] [config] transformer-ffn-depth: 2
[2023-07-01 11:34:00] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:34:00] [config] transformer-heads: 8
[2023-07-01 11:34:00] [config] transformer-no-projection: false
[2023-07-01 11:34:00] [config] transformer-pool: false
[2023-07-01 11:34:00] [config] transformer-postprocess: dan
[2023-07-01 11:34:00] [config] transformer-postprocess-emb: d
[2023-07-01 11:34:00] [config] transformer-postprocess-top: ""
[2023-07-01 11:34:00] [config] transformer-preprocess: ""
[2023-07-01 11:34:00] [config] transformer-tied-layers:
[2023-07-01 11:34:00] [config]   []
[2023-07-01 11:34:00] [config] transformer-train-position-embeddings: false
[2023-07-01 11:34:00] [config] tsv: false
[2023-07-01 11:34:00] [config] tsv-fields: 0
[2023-07-01 11:34:00] [config] type: transformer
[2023-07-01 11:34:00] [config] ulr: false
[2023-07-01 11:34:00] [config] ulr-dim-emb: 0
[2023-07-01 11:34:00] [config] ulr-dropout: 0
[2023-07-01 11:34:00] [config] ulr-keys-vectors: ""
[2023-07-01 11:34:00] [config] ulr-query-vectors: ""
[2023-07-01 11:34:00] [config] ulr-softmax-temperature: 1
[2023-07-01 11:34:00] [config] ulr-trainable-transformation: false
[2023-07-01 11:34:00] [config] unlikelihood-loss: false
[2023-07-01 11:34:00] [config] valid-freq: 50000000
[2023-07-01 11:34:00] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:34:00] [config] valid-max-length: 1000
[2023-07-01 11:34:00] [config] valid-metrics:
[2023-07-01 11:34:00] [config]   - cross-entropy
[2023-07-01 11:34:00] [config]   - translation
[2023-07-01 11:34:00] [config] valid-mini-batch: 64
[2023-07-01 11:34:00] [config] valid-reset-stalled: false
[2023-07-01 11:34:00] [config] valid-script-args:
[2023-07-01 11:34:00] [config]   []
[2023-07-01 11:34:00] [config] valid-script-path: ""
[2023-07-01 11:34:00] [config] valid-sets:
[2023-07-01 11:34:00] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:34:00] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:34:00] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:34:00] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:34:00] [config] vocabs:
[2023-07-01 11:34:00] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:34:00] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:34:00] [config] word-penalty: 0
[2023-07-01 11:34:00] [config] word-scores: false
[2023-07-01 11:34:00] [config] workspace: 2048
[2023-07-01 11:34:00] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:34:00] Using synchronous SGD
[2023-07-01 11:34:01] Synced seed 1234
[2023-07-01 11:34:01] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:34:01] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:34:01] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:34:01] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:34:01] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:34:01] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:34:02] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:34:02] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:34:02] [comm] Using global sharding
[2023-07-01 11:34:02] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:34:02] [training] Using 1 GPUs
[2023-07-01 11:34:02] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:34:02] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:34:02] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:34:02] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:34:10] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:34:10] [valid] No post-processing script given for validating translator
[2023-07-01 11:34:10] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:34:10] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:34:10] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:34:10] [comm] Using global sharding
[2023-07-01 11:34:10] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:34:10] [training] Using 1 GPUs
[2023-07-01 11:34:10] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:34:10] Allocating memory for general optimizer shards
[2023-07-01 11:34:10] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:34:10] Loading Adam parameters
[2023-07-01 11:34:10] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:34:10] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:34:10] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:34:10] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:34:10] [data] Shuffling data
[2023-07-01 11:34:10] [data] Done reading 20,192 sentences
[2023-07-01 11:34:10] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:34:10] Training started
[2023-07-01 11:34:10] Training finished
[2023-07-01 11:34:15] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:34:15] [marian] Running on node20.datos.cluster.uy as process 17688 with command line:
[2023-07-01 11:34:15] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 112 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:34:15] [config] after: 0e
[2023-07-01 11:34:15] [config] after-batches: 0
[2023-07-01 11:34:15] [config] after-epochs: 112
[2023-07-01 11:34:15] [config] all-caps-every: 0
[2023-07-01 11:34:15] [config] allow-unk: false
[2023-07-01 11:34:15] [config] authors: false
[2023-07-01 11:34:15] [config] beam-size: 12
[2023-07-01 11:34:15] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:34:15] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:34:15] [config] bert-masking-fraction: 0.15
[2023-07-01 11:34:15] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:34:15] [config] bert-train-type-embeddings: true
[2023-07-01 11:34:15] [config] bert-type-vocab-size: 2
[2023-07-01 11:34:15] [config] build-info: ""
[2023-07-01 11:34:15] [config] check-gradient-nan: false
[2023-07-01 11:34:15] [config] check-nan: false
[2023-07-01 11:34:15] [config] cite: false
[2023-07-01 11:34:15] [config] clip-norm: 5
[2023-07-01 11:34:15] [config] cost-scaling:
[2023-07-01 11:34:15] [config]   []
[2023-07-01 11:34:15] [config] cost-type: ce-sum
[2023-07-01 11:34:15] [config] cpu-threads: 0
[2023-07-01 11:34:15] [config] data-threads: 8
[2023-07-01 11:34:15] [config] data-weighting: ""
[2023-07-01 11:34:15] [config] data-weighting-type: sentence
[2023-07-01 11:34:15] [config] dec-cell: gru
[2023-07-01 11:34:15] [config] dec-cell-base-depth: 2
[2023-07-01 11:34:15] [config] dec-cell-high-depth: 1
[2023-07-01 11:34:15] [config] dec-depth: 2
[2023-07-01 11:34:15] [config] devices:
[2023-07-01 11:34:15] [config]   - 0
[2023-07-01 11:34:15] [config] dim-emb: 512
[2023-07-01 11:34:15] [config] dim-rnn: 1024
[2023-07-01 11:34:15] [config] dim-vocabs:
[2023-07-01 11:34:15] [config]   - 16384
[2023-07-01 11:34:15] [config]   - 16384
[2023-07-01 11:34:15] [config] disp-first: 0
[2023-07-01 11:34:15] [config] disp-freq: 1000u
[2023-07-01 11:34:15] [config] disp-label-counts: true
[2023-07-01 11:34:15] [config] dropout-rnn: 0
[2023-07-01 11:34:15] [config] dropout-src: 0
[2023-07-01 11:34:15] [config] dropout-trg: 0
[2023-07-01 11:34:15] [config] dump-config: ""
[2023-07-01 11:34:15] [config] dynamic-gradient-scaling:
[2023-07-01 11:34:15] [config]   []
[2023-07-01 11:34:15] [config] early-stopping: 10
[2023-07-01 11:34:15] [config] early-stopping-on: first
[2023-07-01 11:34:15] [config] embedding-fix-src: false
[2023-07-01 11:34:15] [config] embedding-fix-trg: false
[2023-07-01 11:34:15] [config] embedding-normalization: false
[2023-07-01 11:34:15] [config] embedding-vectors:
[2023-07-01 11:34:15] [config]   []
[2023-07-01 11:34:15] [config] enc-cell: gru
[2023-07-01 11:34:15] [config] enc-cell-depth: 1
[2023-07-01 11:34:15] [config] enc-depth: 2
[2023-07-01 11:34:15] [config] enc-type: bidirectional
[2023-07-01 11:34:15] [config] english-title-case-every: 0
[2023-07-01 11:34:15] [config] exponential-smoothing: 0.0001
[2023-07-01 11:34:15] [config] factor-weight: 1
[2023-07-01 11:34:15] [config] factors-combine: sum
[2023-07-01 11:34:15] [config] factors-dim-emb: 0
[2023-07-01 11:34:15] [config] gradient-checkpointing: false
[2023-07-01 11:34:15] [config] gradient-norm-average-window: 100
[2023-07-01 11:34:15] [config] guided-alignment: none
[2023-07-01 11:34:15] [config] guided-alignment-cost: mse
[2023-07-01 11:34:15] [config] guided-alignment-weight: 0.1
[2023-07-01 11:34:15] [config] ignore-model-config: false
[2023-07-01 11:34:15] [config] input-types:
[2023-07-01 11:34:15] [config]   []
[2023-07-01 11:34:15] [config] interpolate-env-vars: false
[2023-07-01 11:34:15] [config] keep-best: false
[2023-07-01 11:34:15] [config] label-smoothing: 0.1
[2023-07-01 11:34:15] [config] layer-normalization: false
[2023-07-01 11:34:15] [config] learn-rate: 0.0003
[2023-07-01 11:34:15] [config] lemma-dependency: ""
[2023-07-01 11:34:15] [config] lemma-dim-emb: 0
[2023-07-01 11:34:15] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:34:15] [config] log-level: info
[2023-07-01 11:34:15] [config] log-time-zone: ""
[2023-07-01 11:34:15] [config] logical-epoch:
[2023-07-01 11:34:15] [config]   - 1e
[2023-07-01 11:34:15] [config]   - 0
[2023-07-01 11:34:15] [config] lr-decay: 0
[2023-07-01 11:34:15] [config] lr-decay-freq: 50000
[2023-07-01 11:34:15] [config] lr-decay-inv-sqrt:
[2023-07-01 11:34:15] [config]   - 16000
[2023-07-01 11:34:15] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:34:15] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:34:15] [config] lr-decay-start:
[2023-07-01 11:34:15] [config]   - 10
[2023-07-01 11:34:15] [config]   - 1
[2023-07-01 11:34:15] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:34:15] [config] lr-report: true
[2023-07-01 11:34:15] [config] lr-warmup: 16000
[2023-07-01 11:34:15] [config] lr-warmup-at-reload: false
[2023-07-01 11:34:15] [config] lr-warmup-cycle: false
[2023-07-01 11:34:15] [config] lr-warmup-start-rate: 0
[2023-07-01 11:34:15] [config] max-length: 100
[2023-07-01 11:34:15] [config] max-length-crop: false
[2023-07-01 11:34:15] [config] max-length-factor: 3
[2023-07-01 11:34:15] [config] maxi-batch: 100
[2023-07-01 11:34:15] [config] maxi-batch-sort: trg
[2023-07-01 11:34:15] [config] mini-batch: 1000
[2023-07-01 11:34:15] [config] mini-batch-fit: true
[2023-07-01 11:34:15] [config] mini-batch-fit-step: 10
[2023-07-01 11:34:15] [config] mini-batch-round-up: true
[2023-07-01 11:34:15] [config] mini-batch-track-lr: false
[2023-07-01 11:34:15] [config] mini-batch-warmup: 0
[2023-07-01 11:34:15] [config] mini-batch-words: 0
[2023-07-01 11:34:15] [config] mini-batch-words-ref: 0
[2023-07-01 11:34:15] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:34:15] [config] multi-loss-type: sum
[2023-07-01 11:34:15] [config] n-best: false
[2023-07-01 11:34:15] [config] no-nccl: false
[2023-07-01 11:34:15] [config] no-reload: false
[2023-07-01 11:34:15] [config] no-restore-corpus: false
[2023-07-01 11:34:15] [config] normalize: 1
[2023-07-01 11:34:15] [config] normalize-gradient: false
[2023-07-01 11:34:15] [config] num-devices: 0
[2023-07-01 11:34:15] [config] optimizer: adam
[2023-07-01 11:34:15] [config] optimizer-delay: 1
[2023-07-01 11:34:15] [config] optimizer-params:
[2023-07-01 11:34:15] [config]   - 0.9
[2023-07-01 11:34:15] [config]   - 0.98
[2023-07-01 11:34:15] [config]   - 1e-09
[2023-07-01 11:34:15] [config] output-omit-bias: false
[2023-07-01 11:34:15] [config] overwrite: true
[2023-07-01 11:34:15] [config] precision:
[2023-07-01 11:34:15] [config]   - float32
[2023-07-01 11:34:15] [config]   - float32
[2023-07-01 11:34:15] [config] pretrained-model: ""
[2023-07-01 11:34:15] [config] quantize-biases: false
[2023-07-01 11:34:15] [config] quantize-bits: 0
[2023-07-01 11:34:15] [config] quantize-log-based: false
[2023-07-01 11:34:15] [config] quantize-optimization-steps: 0
[2023-07-01 11:34:15] [config] quiet: false
[2023-07-01 11:34:15] [config] quiet-translation: true
[2023-07-01 11:34:15] [config] relative-paths: false
[2023-07-01 11:34:15] [config] right-left: false
[2023-07-01 11:34:15] [config] save-freq: 10000u
[2023-07-01 11:34:15] [config] seed: 1234
[2023-07-01 11:34:15] [config] sentencepiece-alphas:
[2023-07-01 11:34:15] [config]   []
[2023-07-01 11:34:15] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:34:15] [config] sentencepiece-options: ""
[2023-07-01 11:34:15] [config] sharding: global
[2023-07-01 11:34:15] [config] shuffle: data
[2023-07-01 11:34:15] [config] shuffle-in-ram: false
[2023-07-01 11:34:15] [config] sigterm: save-and-exit
[2023-07-01 11:34:15] [config] skip: false
[2023-07-01 11:34:15] [config] sqlite: ""
[2023-07-01 11:34:15] [config] sqlite-drop: false
[2023-07-01 11:34:15] [config] sync-freq: 200u
[2023-07-01 11:34:15] [config] sync-sgd: true
[2023-07-01 11:34:15] [config] tempdir: /tmp
[2023-07-01 11:34:15] [config] tied-embeddings: false
[2023-07-01 11:34:15] [config] tied-embeddings-all: true
[2023-07-01 11:34:15] [config] tied-embeddings-src: false
[2023-07-01 11:34:15] [config] train-embedder-rank:
[2023-07-01 11:34:15] [config]   []
[2023-07-01 11:34:15] [config] train-sets:
[2023-07-01 11:34:15] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:34:15] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:34:15] [config] transformer-aan-activation: swish
[2023-07-01 11:34:15] [config] transformer-aan-depth: 2
[2023-07-01 11:34:15] [config] transformer-aan-nogate: false
[2023-07-01 11:34:15] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:34:15] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:34:15] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:34:15] [config] transformer-depth-scaling: false
[2023-07-01 11:34:15] [config] transformer-dim-aan: 2048
[2023-07-01 11:34:15] [config] transformer-dim-ffn: 2048
[2023-07-01 11:34:15] [config] transformer-dropout: 0.1
[2023-07-01 11:34:15] [config] transformer-dropout-attention: 0
[2023-07-01 11:34:15] [config] transformer-dropout-ffn: 0
[2023-07-01 11:34:15] [config] transformer-ffn-activation: swish
[2023-07-01 11:34:15] [config] transformer-ffn-depth: 2
[2023-07-01 11:34:15] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:34:15] [config] transformer-heads: 8
[2023-07-01 11:34:15] [config] transformer-no-projection: false
[2023-07-01 11:34:15] [config] transformer-pool: false
[2023-07-01 11:34:15] [config] transformer-postprocess: dan
[2023-07-01 11:34:15] [config] transformer-postprocess-emb: d
[2023-07-01 11:34:15] [config] transformer-postprocess-top: ""
[2023-07-01 11:34:15] [config] transformer-preprocess: ""
[2023-07-01 11:34:15] [config] transformer-tied-layers:
[2023-07-01 11:34:15] [config]   []
[2023-07-01 11:34:15] [config] transformer-train-position-embeddings: false
[2023-07-01 11:34:15] [config] tsv: false
[2023-07-01 11:34:15] [config] tsv-fields: 0
[2023-07-01 11:34:15] [config] type: transformer
[2023-07-01 11:34:15] [config] ulr: false
[2023-07-01 11:34:15] [config] ulr-dim-emb: 0
[2023-07-01 11:34:15] [config] ulr-dropout: 0
[2023-07-01 11:34:15] [config] ulr-keys-vectors: ""
[2023-07-01 11:34:15] [config] ulr-query-vectors: ""
[2023-07-01 11:34:15] [config] ulr-softmax-temperature: 1
[2023-07-01 11:34:15] [config] ulr-trainable-transformation: false
[2023-07-01 11:34:15] [config] unlikelihood-loss: false
[2023-07-01 11:34:15] [config] valid-freq: 50000000
[2023-07-01 11:34:15] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:34:15] [config] valid-max-length: 1000
[2023-07-01 11:34:15] [config] valid-metrics:
[2023-07-01 11:34:15] [config]   - cross-entropy
[2023-07-01 11:34:15] [config]   - translation
[2023-07-01 11:34:15] [config] valid-mini-batch: 64
[2023-07-01 11:34:15] [config] valid-reset-stalled: false
[2023-07-01 11:34:15] [config] valid-script-args:
[2023-07-01 11:34:15] [config]   []
[2023-07-01 11:34:15] [config] valid-script-path: ""
[2023-07-01 11:34:15] [config] valid-sets:
[2023-07-01 11:34:15] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:34:15] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:34:15] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:34:15] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:34:15] [config] vocabs:
[2023-07-01 11:34:15] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:34:15] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:34:15] [config] word-penalty: 0
[2023-07-01 11:34:15] [config] word-scores: false
[2023-07-01 11:34:15] [config] workspace: 2048
[2023-07-01 11:34:15] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:34:15] Using synchronous SGD
[2023-07-01 11:34:15] Synced seed 1234
[2023-07-01 11:34:15] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:34:15] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:34:15] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:34:15] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:34:15] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:34:15] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:34:16] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:34:16] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:34:16] [comm] Using global sharding
[2023-07-01 11:34:16] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:34:16] [training] Using 1 GPUs
[2023-07-01 11:34:16] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:34:16] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:34:16] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:34:16] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:34:24] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:34:24] [valid] No post-processing script given for validating translator
[2023-07-01 11:34:24] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:34:24] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:34:24] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:34:24] [comm] Using global sharding
[2023-07-01 11:34:24] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:34:24] [training] Using 1 GPUs
[2023-07-01 11:34:24] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:34:24] Allocating memory for general optimizer shards
[2023-07-01 11:34:24] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:34:24] Loading Adam parameters
[2023-07-01 11:34:24] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:34:25] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:34:25] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:34:25] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:34:25] [data] Shuffling data
[2023-07-01 11:34:25] [data] Done reading 20,192 sentences
[2023-07-01 11:34:25] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:34:25] Training started
[2023-07-01 11:34:25] Training finished
[2023-07-01 11:34:28] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:34:28] [marian] Running on node20.datos.cluster.uy as process 17746 with command line:
[2023-07-01 11:34:28] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 113 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:34:28] [config] after: 0e
[2023-07-01 11:34:28] [config] after-batches: 0
[2023-07-01 11:34:28] [config] after-epochs: 113
[2023-07-01 11:34:28] [config] all-caps-every: 0
[2023-07-01 11:34:28] [config] allow-unk: false
[2023-07-01 11:34:28] [config] authors: false
[2023-07-01 11:34:28] [config] beam-size: 12
[2023-07-01 11:34:28] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:34:28] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:34:28] [config] bert-masking-fraction: 0.15
[2023-07-01 11:34:28] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:34:28] [config] bert-train-type-embeddings: true
[2023-07-01 11:34:28] [config] bert-type-vocab-size: 2
[2023-07-01 11:34:28] [config] build-info: ""
[2023-07-01 11:34:28] [config] check-gradient-nan: false
[2023-07-01 11:34:28] [config] check-nan: false
[2023-07-01 11:34:28] [config] cite: false
[2023-07-01 11:34:28] [config] clip-norm: 5
[2023-07-01 11:34:28] [config] cost-scaling:
[2023-07-01 11:34:28] [config]   []
[2023-07-01 11:34:28] [config] cost-type: ce-sum
[2023-07-01 11:34:28] [config] cpu-threads: 0
[2023-07-01 11:34:28] [config] data-threads: 8
[2023-07-01 11:34:28] [config] data-weighting: ""
[2023-07-01 11:34:28] [config] data-weighting-type: sentence
[2023-07-01 11:34:28] [config] dec-cell: gru
[2023-07-01 11:34:28] [config] dec-cell-base-depth: 2
[2023-07-01 11:34:28] [config] dec-cell-high-depth: 1
[2023-07-01 11:34:28] [config] dec-depth: 2
[2023-07-01 11:34:28] [config] devices:
[2023-07-01 11:34:28] [config]   - 0
[2023-07-01 11:34:28] [config] dim-emb: 512
[2023-07-01 11:34:28] [config] dim-rnn: 1024
[2023-07-01 11:34:28] [config] dim-vocabs:
[2023-07-01 11:34:28] [config]   - 16384
[2023-07-01 11:34:28] [config]   - 16384
[2023-07-01 11:34:28] [config] disp-first: 0
[2023-07-01 11:34:28] [config] disp-freq: 1000u
[2023-07-01 11:34:28] [config] disp-label-counts: true
[2023-07-01 11:34:28] [config] dropout-rnn: 0
[2023-07-01 11:34:28] [config] dropout-src: 0
[2023-07-01 11:34:28] [config] dropout-trg: 0
[2023-07-01 11:34:28] [config] dump-config: ""
[2023-07-01 11:34:28] [config] dynamic-gradient-scaling:
[2023-07-01 11:34:28] [config]   []
[2023-07-01 11:34:28] [config] early-stopping: 10
[2023-07-01 11:34:28] [config] early-stopping-on: first
[2023-07-01 11:34:28] [config] embedding-fix-src: false
[2023-07-01 11:34:28] [config] embedding-fix-trg: false
[2023-07-01 11:34:28] [config] embedding-normalization: false
[2023-07-01 11:34:28] [config] embedding-vectors:
[2023-07-01 11:34:28] [config]   []
[2023-07-01 11:34:28] [config] enc-cell: gru
[2023-07-01 11:34:28] [config] enc-cell-depth: 1
[2023-07-01 11:34:28] [config] enc-depth: 2
[2023-07-01 11:34:28] [config] enc-type: bidirectional
[2023-07-01 11:34:28] [config] english-title-case-every: 0
[2023-07-01 11:34:28] [config] exponential-smoothing: 0.0001
[2023-07-01 11:34:28] [config] factor-weight: 1
[2023-07-01 11:34:28] [config] factors-combine: sum
[2023-07-01 11:34:28] [config] factors-dim-emb: 0
[2023-07-01 11:34:28] [config] gradient-checkpointing: false
[2023-07-01 11:34:28] [config] gradient-norm-average-window: 100
[2023-07-01 11:34:28] [config] guided-alignment: none
[2023-07-01 11:34:28] [config] guided-alignment-cost: mse
[2023-07-01 11:34:28] [config] guided-alignment-weight: 0.1
[2023-07-01 11:34:28] [config] ignore-model-config: false
[2023-07-01 11:34:28] [config] input-types:
[2023-07-01 11:34:28] [config]   []
[2023-07-01 11:34:28] [config] interpolate-env-vars: false
[2023-07-01 11:34:28] [config] keep-best: false
[2023-07-01 11:34:28] [config] label-smoothing: 0.1
[2023-07-01 11:34:28] [config] layer-normalization: false
[2023-07-01 11:34:28] [config] learn-rate: 0.0003
[2023-07-01 11:34:28] [config] lemma-dependency: ""
[2023-07-01 11:34:28] [config] lemma-dim-emb: 0
[2023-07-01 11:34:28] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:34:28] [config] log-level: info
[2023-07-01 11:34:28] [config] log-time-zone: ""
[2023-07-01 11:34:28] [config] logical-epoch:
[2023-07-01 11:34:28] [config]   - 1e
[2023-07-01 11:34:28] [config]   - 0
[2023-07-01 11:34:28] [config] lr-decay: 0
[2023-07-01 11:34:28] [config] lr-decay-freq: 50000
[2023-07-01 11:34:28] [config] lr-decay-inv-sqrt:
[2023-07-01 11:34:28] [config]   - 16000
[2023-07-01 11:34:28] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:34:28] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:34:28] [config] lr-decay-start:
[2023-07-01 11:34:28] [config]   - 10
[2023-07-01 11:34:28] [config]   - 1
[2023-07-01 11:34:28] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:34:28] [config] lr-report: true
[2023-07-01 11:34:28] [config] lr-warmup: 16000
[2023-07-01 11:34:28] [config] lr-warmup-at-reload: false
[2023-07-01 11:34:28] [config] lr-warmup-cycle: false
[2023-07-01 11:34:28] [config] lr-warmup-start-rate: 0
[2023-07-01 11:34:28] [config] max-length: 100
[2023-07-01 11:34:28] [config] max-length-crop: false
[2023-07-01 11:34:28] [config] max-length-factor: 3
[2023-07-01 11:34:28] [config] maxi-batch: 100
[2023-07-01 11:34:28] [config] maxi-batch-sort: trg
[2023-07-01 11:34:28] [config] mini-batch: 1000
[2023-07-01 11:34:28] [config] mini-batch-fit: true
[2023-07-01 11:34:28] [config] mini-batch-fit-step: 10
[2023-07-01 11:34:28] [config] mini-batch-round-up: true
[2023-07-01 11:34:28] [config] mini-batch-track-lr: false
[2023-07-01 11:34:28] [config] mini-batch-warmup: 0
[2023-07-01 11:34:28] [config] mini-batch-words: 0
[2023-07-01 11:34:28] [config] mini-batch-words-ref: 0
[2023-07-01 11:34:28] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:34:28] [config] multi-loss-type: sum
[2023-07-01 11:34:28] [config] n-best: false
[2023-07-01 11:34:28] [config] no-nccl: false
[2023-07-01 11:34:28] [config] no-reload: false
[2023-07-01 11:34:28] [config] no-restore-corpus: false
[2023-07-01 11:34:28] [config] normalize: 1
[2023-07-01 11:34:28] [config] normalize-gradient: false
[2023-07-01 11:34:28] [config] num-devices: 0
[2023-07-01 11:34:28] [config] optimizer: adam
[2023-07-01 11:34:28] [config] optimizer-delay: 1
[2023-07-01 11:34:28] [config] optimizer-params:
[2023-07-01 11:34:28] [config]   - 0.9
[2023-07-01 11:34:28] [config]   - 0.98
[2023-07-01 11:34:28] [config]   - 1e-09
[2023-07-01 11:34:28] [config] output-omit-bias: false
[2023-07-01 11:34:28] [config] overwrite: true
[2023-07-01 11:34:28] [config] precision:
[2023-07-01 11:34:28] [config]   - float32
[2023-07-01 11:34:28] [config]   - float32
[2023-07-01 11:34:28] [config] pretrained-model: ""
[2023-07-01 11:34:28] [config] quantize-biases: false
[2023-07-01 11:34:28] [config] quantize-bits: 0
[2023-07-01 11:34:28] [config] quantize-log-based: false
[2023-07-01 11:34:28] [config] quantize-optimization-steps: 0
[2023-07-01 11:34:28] [config] quiet: false
[2023-07-01 11:34:28] [config] quiet-translation: true
[2023-07-01 11:34:28] [config] relative-paths: false
[2023-07-01 11:34:28] [config] right-left: false
[2023-07-01 11:34:28] [config] save-freq: 10000u
[2023-07-01 11:34:28] [config] seed: 1234
[2023-07-01 11:34:28] [config] sentencepiece-alphas:
[2023-07-01 11:34:28] [config]   []
[2023-07-01 11:34:28] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:34:28] [config] sentencepiece-options: ""
[2023-07-01 11:34:28] [config] sharding: global
[2023-07-01 11:34:28] [config] shuffle: data
[2023-07-01 11:34:28] [config] shuffle-in-ram: false
[2023-07-01 11:34:28] [config] sigterm: save-and-exit
[2023-07-01 11:34:28] [config] skip: false
[2023-07-01 11:34:28] [config] sqlite: ""
[2023-07-01 11:34:28] [config] sqlite-drop: false
[2023-07-01 11:34:28] [config] sync-freq: 200u
[2023-07-01 11:34:28] [config] sync-sgd: true
[2023-07-01 11:34:28] [config] tempdir: /tmp
[2023-07-01 11:34:28] [config] tied-embeddings: false
[2023-07-01 11:34:28] [config] tied-embeddings-all: true
[2023-07-01 11:34:28] [config] tied-embeddings-src: false
[2023-07-01 11:34:28] [config] train-embedder-rank:
[2023-07-01 11:34:28] [config]   []
[2023-07-01 11:34:28] [config] train-sets:
[2023-07-01 11:34:28] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:34:28] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:34:28] [config] transformer-aan-activation: swish
[2023-07-01 11:34:28] [config] transformer-aan-depth: 2
[2023-07-01 11:34:28] [config] transformer-aan-nogate: false
[2023-07-01 11:34:28] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:34:28] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:34:28] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:34:28] [config] transformer-depth-scaling: false
[2023-07-01 11:34:28] [config] transformer-dim-aan: 2048
[2023-07-01 11:34:28] [config] transformer-dim-ffn: 2048
[2023-07-01 11:34:28] [config] transformer-dropout: 0.1
[2023-07-01 11:34:28] [config] transformer-dropout-attention: 0
[2023-07-01 11:34:28] [config] transformer-dropout-ffn: 0
[2023-07-01 11:34:28] [config] transformer-ffn-activation: swish
[2023-07-01 11:34:28] [config] transformer-ffn-depth: 2
[2023-07-01 11:34:28] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:34:28] [config] transformer-heads: 8
[2023-07-01 11:34:28] [config] transformer-no-projection: false
[2023-07-01 11:34:28] [config] transformer-pool: false
[2023-07-01 11:34:28] [config] transformer-postprocess: dan
[2023-07-01 11:34:28] [config] transformer-postprocess-emb: d
[2023-07-01 11:34:28] [config] transformer-postprocess-top: ""
[2023-07-01 11:34:28] [config] transformer-preprocess: ""
[2023-07-01 11:34:28] [config] transformer-tied-layers:
[2023-07-01 11:34:28] [config]   []
[2023-07-01 11:34:28] [config] transformer-train-position-embeddings: false
[2023-07-01 11:34:28] [config] tsv: false
[2023-07-01 11:34:28] [config] tsv-fields: 0
[2023-07-01 11:34:28] [config] type: transformer
[2023-07-01 11:34:28] [config] ulr: false
[2023-07-01 11:34:28] [config] ulr-dim-emb: 0
[2023-07-01 11:34:28] [config] ulr-dropout: 0
[2023-07-01 11:34:28] [config] ulr-keys-vectors: ""
[2023-07-01 11:34:28] [config] ulr-query-vectors: ""
[2023-07-01 11:34:28] [config] ulr-softmax-temperature: 1
[2023-07-01 11:34:28] [config] ulr-trainable-transformation: false
[2023-07-01 11:34:28] [config] unlikelihood-loss: false
[2023-07-01 11:34:28] [config] valid-freq: 50000000
[2023-07-01 11:34:28] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:34:28] [config] valid-max-length: 1000
[2023-07-01 11:34:28] [config] valid-metrics:
[2023-07-01 11:34:28] [config]   - cross-entropy
[2023-07-01 11:34:28] [config]   - translation
[2023-07-01 11:34:28] [config] valid-mini-batch: 64
[2023-07-01 11:34:28] [config] valid-reset-stalled: false
[2023-07-01 11:34:28] [config] valid-script-args:
[2023-07-01 11:34:28] [config]   []
[2023-07-01 11:34:28] [config] valid-script-path: ""
[2023-07-01 11:34:28] [config] valid-sets:
[2023-07-01 11:34:28] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:34:28] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:34:28] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:34:28] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:34:28] [config] vocabs:
[2023-07-01 11:34:28] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:34:28] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:34:28] [config] word-penalty: 0
[2023-07-01 11:34:28] [config] word-scores: false
[2023-07-01 11:34:28] [config] workspace: 2048
[2023-07-01 11:34:28] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:34:28] Using synchronous SGD
[2023-07-01 11:34:28] Synced seed 1234
[2023-07-01 11:34:28] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:34:28] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:34:28] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:34:28] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:34:28] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:34:28] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:34:29] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:34:29] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:34:29] [comm] Using global sharding
[2023-07-01 11:34:29] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:34:29] [training] Using 1 GPUs
[2023-07-01 11:34:29] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:34:29] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:34:30] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:34:30] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:34:37] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:34:37] [valid] No post-processing script given for validating translator
[2023-07-01 11:34:37] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:34:37] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:34:37] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:34:37] [comm] Using global sharding
[2023-07-01 11:34:37] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:34:37] [training] Using 1 GPUs
[2023-07-01 11:34:37] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:34:38] Allocating memory for general optimizer shards
[2023-07-01 11:34:38] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:34:38] Loading Adam parameters
[2023-07-01 11:34:38] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:34:38] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:34:38] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:34:38] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:34:38] [data] Shuffling data
[2023-07-01 11:34:38] [data] Done reading 20,192 sentences
[2023-07-01 11:34:38] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:34:38] Training started
[2023-07-01 11:34:38] Training finished
[2023-07-01 11:34:42] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:34:42] [marian] Running on node20.datos.cluster.uy as process 17804 with command line:
[2023-07-01 11:34:42] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 114 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:34:42] [config] after: 0e
[2023-07-01 11:34:42] [config] after-batches: 0
[2023-07-01 11:34:42] [config] after-epochs: 114
[2023-07-01 11:34:42] [config] all-caps-every: 0
[2023-07-01 11:34:42] [config] allow-unk: false
[2023-07-01 11:34:42] [config] authors: false
[2023-07-01 11:34:42] [config] beam-size: 12
[2023-07-01 11:34:42] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:34:42] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:34:42] [config] bert-masking-fraction: 0.15
[2023-07-01 11:34:42] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:34:42] [config] bert-train-type-embeddings: true
[2023-07-01 11:34:42] [config] bert-type-vocab-size: 2
[2023-07-01 11:34:42] [config] build-info: ""
[2023-07-01 11:34:42] [config] check-gradient-nan: false
[2023-07-01 11:34:42] [config] check-nan: false
[2023-07-01 11:34:42] [config] cite: false
[2023-07-01 11:34:42] [config] clip-norm: 5
[2023-07-01 11:34:42] [config] cost-scaling:
[2023-07-01 11:34:42] [config]   []
[2023-07-01 11:34:42] [config] cost-type: ce-sum
[2023-07-01 11:34:42] [config] cpu-threads: 0
[2023-07-01 11:34:42] [config] data-threads: 8
[2023-07-01 11:34:42] [config] data-weighting: ""
[2023-07-01 11:34:42] [config] data-weighting-type: sentence
[2023-07-01 11:34:42] [config] dec-cell: gru
[2023-07-01 11:34:42] [config] dec-cell-base-depth: 2
[2023-07-01 11:34:42] [config] dec-cell-high-depth: 1
[2023-07-01 11:34:42] [config] dec-depth: 2
[2023-07-01 11:34:42] [config] devices:
[2023-07-01 11:34:42] [config]   - 0
[2023-07-01 11:34:42] [config] dim-emb: 512
[2023-07-01 11:34:42] [config] dim-rnn: 1024
[2023-07-01 11:34:42] [config] dim-vocabs:
[2023-07-01 11:34:42] [config]   - 16384
[2023-07-01 11:34:42] [config]   - 16384
[2023-07-01 11:34:42] [config] disp-first: 0
[2023-07-01 11:34:42] [config] disp-freq: 1000u
[2023-07-01 11:34:42] [config] disp-label-counts: true
[2023-07-01 11:34:42] [config] dropout-rnn: 0
[2023-07-01 11:34:42] [config] dropout-src: 0
[2023-07-01 11:34:42] [config] dropout-trg: 0
[2023-07-01 11:34:42] [config] dump-config: ""
[2023-07-01 11:34:42] [config] dynamic-gradient-scaling:
[2023-07-01 11:34:42] [config]   []
[2023-07-01 11:34:42] [config] early-stopping: 10
[2023-07-01 11:34:42] [config] early-stopping-on: first
[2023-07-01 11:34:42] [config] embedding-fix-src: false
[2023-07-01 11:34:42] [config] embedding-fix-trg: false
[2023-07-01 11:34:42] [config] embedding-normalization: false
[2023-07-01 11:34:42] [config] embedding-vectors:
[2023-07-01 11:34:42] [config]   []
[2023-07-01 11:34:42] [config] enc-cell: gru
[2023-07-01 11:34:42] [config] enc-cell-depth: 1
[2023-07-01 11:34:42] [config] enc-depth: 2
[2023-07-01 11:34:42] [config] enc-type: bidirectional
[2023-07-01 11:34:42] [config] english-title-case-every: 0
[2023-07-01 11:34:42] [config] exponential-smoothing: 0.0001
[2023-07-01 11:34:42] [config] factor-weight: 1
[2023-07-01 11:34:42] [config] factors-combine: sum
[2023-07-01 11:34:42] [config] factors-dim-emb: 0
[2023-07-01 11:34:42] [config] gradient-checkpointing: false
[2023-07-01 11:34:42] [config] gradient-norm-average-window: 100
[2023-07-01 11:34:42] [config] guided-alignment: none
[2023-07-01 11:34:42] [config] guided-alignment-cost: mse
[2023-07-01 11:34:42] [config] guided-alignment-weight: 0.1
[2023-07-01 11:34:42] [config] ignore-model-config: false
[2023-07-01 11:34:42] [config] input-types:
[2023-07-01 11:34:42] [config]   []
[2023-07-01 11:34:42] [config] interpolate-env-vars: false
[2023-07-01 11:34:42] [config] keep-best: false
[2023-07-01 11:34:42] [config] label-smoothing: 0.1
[2023-07-01 11:34:42] [config] layer-normalization: false
[2023-07-01 11:34:42] [config] learn-rate: 0.0003
[2023-07-01 11:34:42] [config] lemma-dependency: ""
[2023-07-01 11:34:42] [config] lemma-dim-emb: 0
[2023-07-01 11:34:42] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:34:42] [config] log-level: info
[2023-07-01 11:34:42] [config] log-time-zone: ""
[2023-07-01 11:34:42] [config] logical-epoch:
[2023-07-01 11:34:42] [config]   - 1e
[2023-07-01 11:34:42] [config]   - 0
[2023-07-01 11:34:42] [config] lr-decay: 0
[2023-07-01 11:34:42] [config] lr-decay-freq: 50000
[2023-07-01 11:34:42] [config] lr-decay-inv-sqrt:
[2023-07-01 11:34:42] [config]   - 16000
[2023-07-01 11:34:42] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:34:42] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:34:42] [config] lr-decay-start:
[2023-07-01 11:34:42] [config]   - 10
[2023-07-01 11:34:42] [config]   - 1
[2023-07-01 11:34:42] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:34:42] [config] lr-report: true
[2023-07-01 11:34:42] [config] lr-warmup: 16000
[2023-07-01 11:34:42] [config] lr-warmup-at-reload: false
[2023-07-01 11:34:42] [config] lr-warmup-cycle: false
[2023-07-01 11:34:42] [config] lr-warmup-start-rate: 0
[2023-07-01 11:34:42] [config] max-length: 100
[2023-07-01 11:34:42] [config] max-length-crop: false
[2023-07-01 11:34:42] [config] max-length-factor: 3
[2023-07-01 11:34:42] [config] maxi-batch: 100
[2023-07-01 11:34:42] [config] maxi-batch-sort: trg
[2023-07-01 11:34:42] [config] mini-batch: 1000
[2023-07-01 11:34:42] [config] mini-batch-fit: true
[2023-07-01 11:34:42] [config] mini-batch-fit-step: 10
[2023-07-01 11:34:42] [config] mini-batch-round-up: true
[2023-07-01 11:34:42] [config] mini-batch-track-lr: false
[2023-07-01 11:34:42] [config] mini-batch-warmup: 0
[2023-07-01 11:34:42] [config] mini-batch-words: 0
[2023-07-01 11:34:42] [config] mini-batch-words-ref: 0
[2023-07-01 11:34:42] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:34:42] [config] multi-loss-type: sum
[2023-07-01 11:34:42] [config] n-best: false
[2023-07-01 11:34:42] [config] no-nccl: false
[2023-07-01 11:34:42] [config] no-reload: false
[2023-07-01 11:34:42] [config] no-restore-corpus: false
[2023-07-01 11:34:42] [config] normalize: 1
[2023-07-01 11:34:42] [config] normalize-gradient: false
[2023-07-01 11:34:42] [config] num-devices: 0
[2023-07-01 11:34:42] [config] optimizer: adam
[2023-07-01 11:34:42] [config] optimizer-delay: 1
[2023-07-01 11:34:42] [config] optimizer-params:
[2023-07-01 11:34:42] [config]   - 0.9
[2023-07-01 11:34:42] [config]   - 0.98
[2023-07-01 11:34:42] [config]   - 1e-09
[2023-07-01 11:34:42] [config] output-omit-bias: false
[2023-07-01 11:34:42] [config] overwrite: true
[2023-07-01 11:34:42] [config] precision:
[2023-07-01 11:34:42] [config]   - float32
[2023-07-01 11:34:42] [config]   - float32
[2023-07-01 11:34:42] [config] pretrained-model: ""
[2023-07-01 11:34:42] [config] quantize-biases: false
[2023-07-01 11:34:42] [config] quantize-bits: 0
[2023-07-01 11:34:42] [config] quantize-log-based: false
[2023-07-01 11:34:42] [config] quantize-optimization-steps: 0
[2023-07-01 11:34:42] [config] quiet: false
[2023-07-01 11:34:42] [config] quiet-translation: true
[2023-07-01 11:34:42] [config] relative-paths: false
[2023-07-01 11:34:42] [config] right-left: false
[2023-07-01 11:34:42] [config] save-freq: 10000u
[2023-07-01 11:34:42] [config] seed: 1234
[2023-07-01 11:34:42] [config] sentencepiece-alphas:
[2023-07-01 11:34:42] [config]   []
[2023-07-01 11:34:42] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:34:42] [config] sentencepiece-options: ""
[2023-07-01 11:34:42] [config] sharding: global
[2023-07-01 11:34:42] [config] shuffle: data
[2023-07-01 11:34:42] [config] shuffle-in-ram: false
[2023-07-01 11:34:42] [config] sigterm: save-and-exit
[2023-07-01 11:34:42] [config] skip: false
[2023-07-01 11:34:42] [config] sqlite: ""
[2023-07-01 11:34:42] [config] sqlite-drop: false
[2023-07-01 11:34:42] [config] sync-freq: 200u
[2023-07-01 11:34:42] [config] sync-sgd: true
[2023-07-01 11:34:42] [config] tempdir: /tmp
[2023-07-01 11:34:42] [config] tied-embeddings: false
[2023-07-01 11:34:42] [config] tied-embeddings-all: true
[2023-07-01 11:34:42] [config] tied-embeddings-src: false
[2023-07-01 11:34:42] [config] train-embedder-rank:
[2023-07-01 11:34:42] [config]   []
[2023-07-01 11:34:42] [config] train-sets:
[2023-07-01 11:34:42] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:34:42] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:34:42] [config] transformer-aan-activation: swish
[2023-07-01 11:34:42] [config] transformer-aan-depth: 2
[2023-07-01 11:34:42] [config] transformer-aan-nogate: false
[2023-07-01 11:34:42] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:34:42] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:34:42] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:34:42] [config] transformer-depth-scaling: false
[2023-07-01 11:34:42] [config] transformer-dim-aan: 2048
[2023-07-01 11:34:42] [config] transformer-dim-ffn: 2048
[2023-07-01 11:34:42] [config] transformer-dropout: 0.1
[2023-07-01 11:34:42] [config] transformer-dropout-attention: 0
[2023-07-01 11:34:42] [config] transformer-dropout-ffn: 0
[2023-07-01 11:34:42] [config] transformer-ffn-activation: swish
[2023-07-01 11:34:42] [config] transformer-ffn-depth: 2
[2023-07-01 11:34:42] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:34:42] [config] transformer-heads: 8
[2023-07-01 11:34:42] [config] transformer-no-projection: false
[2023-07-01 11:34:42] [config] transformer-pool: false
[2023-07-01 11:34:42] [config] transformer-postprocess: dan
[2023-07-01 11:34:42] [config] transformer-postprocess-emb: d
[2023-07-01 11:34:42] [config] transformer-postprocess-top: ""
[2023-07-01 11:34:42] [config] transformer-preprocess: ""
[2023-07-01 11:34:42] [config] transformer-tied-layers:
[2023-07-01 11:34:42] [config]   []
[2023-07-01 11:34:42] [config] transformer-train-position-embeddings: false
[2023-07-01 11:34:42] [config] tsv: false
[2023-07-01 11:34:42] [config] tsv-fields: 0
[2023-07-01 11:34:42] [config] type: transformer
[2023-07-01 11:34:42] [config] ulr: false
[2023-07-01 11:34:42] [config] ulr-dim-emb: 0
[2023-07-01 11:34:42] [config] ulr-dropout: 0
[2023-07-01 11:34:42] [config] ulr-keys-vectors: ""
[2023-07-01 11:34:42] [config] ulr-query-vectors: ""
[2023-07-01 11:34:42] [config] ulr-softmax-temperature: 1
[2023-07-01 11:34:42] [config] ulr-trainable-transformation: false
[2023-07-01 11:34:42] [config] unlikelihood-loss: false
[2023-07-01 11:34:42] [config] valid-freq: 50000000
[2023-07-01 11:34:42] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:34:42] [config] valid-max-length: 1000
[2023-07-01 11:34:42] [config] valid-metrics:
[2023-07-01 11:34:42] [config]   - cross-entropy
[2023-07-01 11:34:42] [config]   - translation
[2023-07-01 11:34:42] [config] valid-mini-batch: 64
[2023-07-01 11:34:42] [config] valid-reset-stalled: false
[2023-07-01 11:34:42] [config] valid-script-args:
[2023-07-01 11:34:42] [config]   []
[2023-07-01 11:34:42] [config] valid-script-path: ""
[2023-07-01 11:34:42] [config] valid-sets:
[2023-07-01 11:34:42] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:34:42] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:34:42] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:34:42] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:34:42] [config] vocabs:
[2023-07-01 11:34:42] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:34:42] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:34:42] [config] word-penalty: 0
[2023-07-01 11:34:42] [config] word-scores: false
[2023-07-01 11:34:42] [config] workspace: 2048
[2023-07-01 11:34:42] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:34:42] Using synchronous SGD
[2023-07-01 11:34:42] Synced seed 1234
[2023-07-01 11:34:42] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:34:42] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:34:42] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:34:42] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:34:42] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:34:42] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:34:43] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:34:43] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:34:43] [comm] Using global sharding
[2023-07-01 11:34:43] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:34:43] [training] Using 1 GPUs
[2023-07-01 11:34:43] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:34:43] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:34:43] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:34:43] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:34:51] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:34:51] [valid] No post-processing script given for validating translator
[2023-07-01 11:34:51] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:34:51] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:34:51] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:34:51] [comm] Using global sharding
[2023-07-01 11:34:51] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:34:51] [training] Using 1 GPUs
[2023-07-01 11:34:51] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:34:51] Allocating memory for general optimizer shards
[2023-07-01 11:34:51] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:34:51] Loading Adam parameters
[2023-07-01 11:34:52] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:34:52] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:34:52] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:34:52] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:34:52] [data] Shuffling data
[2023-07-01 11:34:52] [data] Done reading 20,192 sentences
[2023-07-01 11:34:52] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:34:52] Training started
[2023-07-01 11:34:52] Training finished
[2023-07-01 11:34:55] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:34:55] [marian] Running on node20.datos.cluster.uy as process 17865 with command line:
[2023-07-01 11:34:55] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 115 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:34:55] [config] after: 0e
[2023-07-01 11:34:55] [config] after-batches: 0
[2023-07-01 11:34:55] [config] after-epochs: 115
[2023-07-01 11:34:55] [config] all-caps-every: 0
[2023-07-01 11:34:55] [config] allow-unk: false
[2023-07-01 11:34:55] [config] authors: false
[2023-07-01 11:34:55] [config] beam-size: 12
[2023-07-01 11:34:55] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:34:55] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:34:55] [config] bert-masking-fraction: 0.15
[2023-07-01 11:34:55] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:34:55] [config] bert-train-type-embeddings: true
[2023-07-01 11:34:55] [config] bert-type-vocab-size: 2
[2023-07-01 11:34:55] [config] build-info: ""
[2023-07-01 11:34:55] [config] check-gradient-nan: false
[2023-07-01 11:34:55] [config] check-nan: false
[2023-07-01 11:34:55] [config] cite: false
[2023-07-01 11:34:55] [config] clip-norm: 5
[2023-07-01 11:34:55] [config] cost-scaling:
[2023-07-01 11:34:55] [config]   []
[2023-07-01 11:34:55] [config] cost-type: ce-sum
[2023-07-01 11:34:55] [config] cpu-threads: 0
[2023-07-01 11:34:55] [config] data-threads: 8
[2023-07-01 11:34:55] [config] data-weighting: ""
[2023-07-01 11:34:55] [config] data-weighting-type: sentence
[2023-07-01 11:34:55] [config] dec-cell: gru
[2023-07-01 11:34:55] [config] dec-cell-base-depth: 2
[2023-07-01 11:34:55] [config] dec-cell-high-depth: 1
[2023-07-01 11:34:55] [config] dec-depth: 2
[2023-07-01 11:34:55] [config] devices:
[2023-07-01 11:34:55] [config]   - 0
[2023-07-01 11:34:55] [config] dim-emb: 512
[2023-07-01 11:34:55] [config] dim-rnn: 1024
[2023-07-01 11:34:55] [config] dim-vocabs:
[2023-07-01 11:34:55] [config]   - 16384
[2023-07-01 11:34:55] [config]   - 16384
[2023-07-01 11:34:55] [config] disp-first: 0
[2023-07-01 11:34:55] [config] disp-freq: 1000u
[2023-07-01 11:34:55] [config] disp-label-counts: true
[2023-07-01 11:34:55] [config] dropout-rnn: 0
[2023-07-01 11:34:55] [config] dropout-src: 0
[2023-07-01 11:34:55] [config] dropout-trg: 0
[2023-07-01 11:34:55] [config] dump-config: ""
[2023-07-01 11:34:55] [config] dynamic-gradient-scaling:
[2023-07-01 11:34:55] [config]   []
[2023-07-01 11:34:55] [config] early-stopping: 10
[2023-07-01 11:34:55] [config] early-stopping-on: first
[2023-07-01 11:34:55] [config] embedding-fix-src: false
[2023-07-01 11:34:55] [config] embedding-fix-trg: false
[2023-07-01 11:34:55] [config] embedding-normalization: false
[2023-07-01 11:34:55] [config] embedding-vectors:
[2023-07-01 11:34:55] [config]   []
[2023-07-01 11:34:55] [config] enc-cell: gru
[2023-07-01 11:34:55] [config] enc-cell-depth: 1
[2023-07-01 11:34:55] [config] enc-depth: 2
[2023-07-01 11:34:55] [config] enc-type: bidirectional
[2023-07-01 11:34:55] [config] english-title-case-every: 0
[2023-07-01 11:34:55] [config] exponential-smoothing: 0.0001
[2023-07-01 11:34:55] [config] factor-weight: 1
[2023-07-01 11:34:55] [config] factors-combine: sum
[2023-07-01 11:34:55] [config] factors-dim-emb: 0
[2023-07-01 11:34:55] [config] gradient-checkpointing: false
[2023-07-01 11:34:55] [config] gradient-norm-average-window: 100
[2023-07-01 11:34:55] [config] guided-alignment: none
[2023-07-01 11:34:55] [config] guided-alignment-cost: mse
[2023-07-01 11:34:55] [config] guided-alignment-weight: 0.1
[2023-07-01 11:34:55] [config] ignore-model-config: false
[2023-07-01 11:34:55] [config] input-types:
[2023-07-01 11:34:55] [config]   []
[2023-07-01 11:34:55] [config] interpolate-env-vars: false
[2023-07-01 11:34:55] [config] keep-best: false
[2023-07-01 11:34:55] [config] label-smoothing: 0.1
[2023-07-01 11:34:55] [config] layer-normalization: false
[2023-07-01 11:34:55] [config] learn-rate: 0.0003
[2023-07-01 11:34:55] [config] lemma-dependency: ""
[2023-07-01 11:34:55] [config] lemma-dim-emb: 0
[2023-07-01 11:34:55] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:34:55] [config] log-level: info
[2023-07-01 11:34:55] [config] log-time-zone: ""
[2023-07-01 11:34:55] [config] logical-epoch:
[2023-07-01 11:34:55] [config]   - 1e
[2023-07-01 11:34:55] [config]   - 0
[2023-07-01 11:34:55] [config] lr-decay: 0
[2023-07-01 11:34:55] [config] lr-decay-freq: 50000
[2023-07-01 11:34:55] [config] lr-decay-inv-sqrt:
[2023-07-01 11:34:55] [config]   - 16000
[2023-07-01 11:34:55] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:34:55] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:34:55] [config] lr-decay-start:
[2023-07-01 11:34:55] [config]   - 10
[2023-07-01 11:34:55] [config]   - 1
[2023-07-01 11:34:55] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:34:55] [config] lr-report: true
[2023-07-01 11:34:55] [config] lr-warmup: 16000
[2023-07-01 11:34:55] [config] lr-warmup-at-reload: false
[2023-07-01 11:34:55] [config] lr-warmup-cycle: false
[2023-07-01 11:34:55] [config] lr-warmup-start-rate: 0
[2023-07-01 11:34:55] [config] max-length: 100
[2023-07-01 11:34:55] [config] max-length-crop: false
[2023-07-01 11:34:55] [config] max-length-factor: 3
[2023-07-01 11:34:55] [config] maxi-batch: 100
[2023-07-01 11:34:55] [config] maxi-batch-sort: trg
[2023-07-01 11:34:55] [config] mini-batch: 1000
[2023-07-01 11:34:55] [config] mini-batch-fit: true
[2023-07-01 11:34:55] [config] mini-batch-fit-step: 10
[2023-07-01 11:34:55] [config] mini-batch-round-up: true
[2023-07-01 11:34:55] [config] mini-batch-track-lr: false
[2023-07-01 11:34:55] [config] mini-batch-warmup: 0
[2023-07-01 11:34:55] [config] mini-batch-words: 0
[2023-07-01 11:34:55] [config] mini-batch-words-ref: 0
[2023-07-01 11:34:55] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:34:55] [config] multi-loss-type: sum
[2023-07-01 11:34:55] [config] n-best: false
[2023-07-01 11:34:55] [config] no-nccl: false
[2023-07-01 11:34:55] [config] no-reload: false
[2023-07-01 11:34:55] [config] no-restore-corpus: false
[2023-07-01 11:34:55] [config] normalize: 1
[2023-07-01 11:34:55] [config] normalize-gradient: false
[2023-07-01 11:34:55] [config] num-devices: 0
[2023-07-01 11:34:55] [config] optimizer: adam
[2023-07-01 11:34:55] [config] optimizer-delay: 1
[2023-07-01 11:34:55] [config] optimizer-params:
[2023-07-01 11:34:55] [config]   - 0.9
[2023-07-01 11:34:55] [config]   - 0.98
[2023-07-01 11:34:55] [config]   - 1e-09
[2023-07-01 11:34:55] [config] output-omit-bias: false
[2023-07-01 11:34:55] [config] overwrite: true
[2023-07-01 11:34:55] [config] precision:
[2023-07-01 11:34:55] [config]   - float32
[2023-07-01 11:34:55] [config]   - float32
[2023-07-01 11:34:55] [config] pretrained-model: ""
[2023-07-01 11:34:55] [config] quantize-biases: false
[2023-07-01 11:34:55] [config] quantize-bits: 0
[2023-07-01 11:34:55] [config] quantize-log-based: false
[2023-07-01 11:34:55] [config] quantize-optimization-steps: 0
[2023-07-01 11:34:55] [config] quiet: false
[2023-07-01 11:34:55] [config] quiet-translation: true
[2023-07-01 11:34:55] [config] relative-paths: false
[2023-07-01 11:34:55] [config] right-left: false
[2023-07-01 11:34:55] [config] save-freq: 10000u
[2023-07-01 11:34:55] [config] seed: 1234
[2023-07-01 11:34:55] [config] sentencepiece-alphas:
[2023-07-01 11:34:55] [config]   []
[2023-07-01 11:34:55] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:34:55] [config] sentencepiece-options: ""
[2023-07-01 11:34:55] [config] sharding: global
[2023-07-01 11:34:55] [config] shuffle: data
[2023-07-01 11:34:55] [config] shuffle-in-ram: false
[2023-07-01 11:34:55] [config] sigterm: save-and-exit
[2023-07-01 11:34:55] [config] skip: false
[2023-07-01 11:34:55] [config] sqlite: ""
[2023-07-01 11:34:55] [config] sqlite-drop: false
[2023-07-01 11:34:55] [config] sync-freq: 200u
[2023-07-01 11:34:55] [config] sync-sgd: true
[2023-07-01 11:34:55] [config] tempdir: /tmp
[2023-07-01 11:34:55] [config] tied-embeddings: false
[2023-07-01 11:34:55] [config] tied-embeddings-all: true
[2023-07-01 11:34:55] [config] tied-embeddings-src: false
[2023-07-01 11:34:55] [config] train-embedder-rank:
[2023-07-01 11:34:55] [config]   []
[2023-07-01 11:34:55] [config] train-sets:
[2023-07-01 11:34:55] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:34:55] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:34:55] [config] transformer-aan-activation: swish
[2023-07-01 11:34:55] [config] transformer-aan-depth: 2
[2023-07-01 11:34:55] [config] transformer-aan-nogate: false
[2023-07-01 11:34:55] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:34:55] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:34:55] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:34:55] [config] transformer-depth-scaling: false
[2023-07-01 11:34:55] [config] transformer-dim-aan: 2048
[2023-07-01 11:34:55] [config] transformer-dim-ffn: 2048
[2023-07-01 11:34:55] [config] transformer-dropout: 0.1
[2023-07-01 11:34:55] [config] transformer-dropout-attention: 0
[2023-07-01 11:34:55] [config] transformer-dropout-ffn: 0
[2023-07-01 11:34:55] [config] transformer-ffn-activation: swish
[2023-07-01 11:34:55] [config] transformer-ffn-depth: 2
[2023-07-01 11:34:55] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:34:55] [config] transformer-heads: 8
[2023-07-01 11:34:55] [config] transformer-no-projection: false
[2023-07-01 11:34:55] [config] transformer-pool: false
[2023-07-01 11:34:55] [config] transformer-postprocess: dan
[2023-07-01 11:34:55] [config] transformer-postprocess-emb: d
[2023-07-01 11:34:55] [config] transformer-postprocess-top: ""
[2023-07-01 11:34:55] [config] transformer-preprocess: ""
[2023-07-01 11:34:55] [config] transformer-tied-layers:
[2023-07-01 11:34:55] [config]   []
[2023-07-01 11:34:55] [config] transformer-train-position-embeddings: false
[2023-07-01 11:34:55] [config] tsv: false
[2023-07-01 11:34:55] [config] tsv-fields: 0
[2023-07-01 11:34:55] [config] type: transformer
[2023-07-01 11:34:55] [config] ulr: false
[2023-07-01 11:34:55] [config] ulr-dim-emb: 0
[2023-07-01 11:34:55] [config] ulr-dropout: 0
[2023-07-01 11:34:55] [config] ulr-keys-vectors: ""
[2023-07-01 11:34:55] [config] ulr-query-vectors: ""
[2023-07-01 11:34:55] [config] ulr-softmax-temperature: 1
[2023-07-01 11:34:55] [config] ulr-trainable-transformation: false
[2023-07-01 11:34:55] [config] unlikelihood-loss: false
[2023-07-01 11:34:55] [config] valid-freq: 50000000
[2023-07-01 11:34:55] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:34:55] [config] valid-max-length: 1000
[2023-07-01 11:34:55] [config] valid-metrics:
[2023-07-01 11:34:55] [config]   - cross-entropy
[2023-07-01 11:34:55] [config]   - translation
[2023-07-01 11:34:55] [config] valid-mini-batch: 64
[2023-07-01 11:34:55] [config] valid-reset-stalled: false
[2023-07-01 11:34:55] [config] valid-script-args:
[2023-07-01 11:34:55] [config]   []
[2023-07-01 11:34:55] [config] valid-script-path: ""
[2023-07-01 11:34:55] [config] valid-sets:
[2023-07-01 11:34:55] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:34:55] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:34:55] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:34:55] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:34:55] [config] vocabs:
[2023-07-01 11:34:55] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:34:55] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:34:55] [config] word-penalty: 0
[2023-07-01 11:34:55] [config] word-scores: false
[2023-07-01 11:34:55] [config] workspace: 2048
[2023-07-01 11:34:55] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:34:55] Using synchronous SGD
[2023-07-01 11:34:56] Synced seed 1234
[2023-07-01 11:34:56] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:34:56] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:34:56] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:34:56] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:34:56] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:34:56] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:34:56] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:34:56] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:34:56] [comm] Using global sharding
[2023-07-01 11:34:56] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:34:56] [training] Using 1 GPUs
[2023-07-01 11:34:56] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:34:56] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:34:57] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:34:57] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:35:04] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:35:04] [valid] No post-processing script given for validating translator
[2023-07-01 11:35:04] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:35:04] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:35:04] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:35:04] [comm] Using global sharding
[2023-07-01 11:35:05] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:35:05] [training] Using 1 GPUs
[2023-07-01 11:35:05] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:35:05] Allocating memory for general optimizer shards
[2023-07-01 11:35:05] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:35:05] Loading Adam parameters
[2023-07-01 11:35:05] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:35:05] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:35:05] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:35:05] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:35:05] [data] Shuffling data
[2023-07-01 11:35:05] [data] Done reading 20,192 sentences
[2023-07-01 11:35:05] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:35:05] Training started
[2023-07-01 11:35:05] Training finished
[2023-07-01 11:35:09] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:35:09] [marian] Running on node20.datos.cluster.uy as process 17923 with command line:
[2023-07-01 11:35:09] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 116 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:35:09] [config] after: 0e
[2023-07-01 11:35:09] [config] after-batches: 0
[2023-07-01 11:35:09] [config] after-epochs: 116
[2023-07-01 11:35:09] [config] all-caps-every: 0
[2023-07-01 11:35:09] [config] allow-unk: false
[2023-07-01 11:35:09] [config] authors: false
[2023-07-01 11:35:09] [config] beam-size: 12
[2023-07-01 11:35:09] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:35:09] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:35:09] [config] bert-masking-fraction: 0.15
[2023-07-01 11:35:09] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:35:09] [config] bert-train-type-embeddings: true
[2023-07-01 11:35:09] [config] bert-type-vocab-size: 2
[2023-07-01 11:35:09] [config] build-info: ""
[2023-07-01 11:35:09] [config] check-gradient-nan: false
[2023-07-01 11:35:09] [config] check-nan: false
[2023-07-01 11:35:09] [config] cite: false
[2023-07-01 11:35:09] [config] clip-norm: 5
[2023-07-01 11:35:09] [config] cost-scaling:
[2023-07-01 11:35:09] [config]   []
[2023-07-01 11:35:09] [config] cost-type: ce-sum
[2023-07-01 11:35:09] [config] cpu-threads: 0
[2023-07-01 11:35:09] [config] data-threads: 8
[2023-07-01 11:35:09] [config] data-weighting: ""
[2023-07-01 11:35:09] [config] data-weighting-type: sentence
[2023-07-01 11:35:09] [config] dec-cell: gru
[2023-07-01 11:35:09] [config] dec-cell-base-depth: 2
[2023-07-01 11:35:09] [config] dec-cell-high-depth: 1
[2023-07-01 11:35:09] [config] dec-depth: 2
[2023-07-01 11:35:09] [config] devices:
[2023-07-01 11:35:09] [config]   - 0
[2023-07-01 11:35:09] [config] dim-emb: 512
[2023-07-01 11:35:09] [config] dim-rnn: 1024
[2023-07-01 11:35:09] [config] dim-vocabs:
[2023-07-01 11:35:09] [config]   - 16384
[2023-07-01 11:35:09] [config]   - 16384
[2023-07-01 11:35:09] [config] disp-first: 0
[2023-07-01 11:35:09] [config] disp-freq: 1000u
[2023-07-01 11:35:09] [config] disp-label-counts: true
[2023-07-01 11:35:09] [config] dropout-rnn: 0
[2023-07-01 11:35:09] [config] dropout-src: 0
[2023-07-01 11:35:09] [config] dropout-trg: 0
[2023-07-01 11:35:09] [config] dump-config: ""
[2023-07-01 11:35:09] [config] dynamic-gradient-scaling:
[2023-07-01 11:35:09] [config]   []
[2023-07-01 11:35:09] [config] early-stopping: 10
[2023-07-01 11:35:09] [config] early-stopping-on: first
[2023-07-01 11:35:09] [config] embedding-fix-src: false
[2023-07-01 11:35:09] [config] embedding-fix-trg: false
[2023-07-01 11:35:09] [config] embedding-normalization: false
[2023-07-01 11:35:09] [config] embedding-vectors:
[2023-07-01 11:35:09] [config]   []
[2023-07-01 11:35:09] [config] enc-cell: gru
[2023-07-01 11:35:09] [config] enc-cell-depth: 1
[2023-07-01 11:35:09] [config] enc-depth: 2
[2023-07-01 11:35:09] [config] enc-type: bidirectional
[2023-07-01 11:35:09] [config] english-title-case-every: 0
[2023-07-01 11:35:09] [config] exponential-smoothing: 0.0001
[2023-07-01 11:35:09] [config] factor-weight: 1
[2023-07-01 11:35:09] [config] factors-combine: sum
[2023-07-01 11:35:09] [config] factors-dim-emb: 0
[2023-07-01 11:35:09] [config] gradient-checkpointing: false
[2023-07-01 11:35:09] [config] gradient-norm-average-window: 100
[2023-07-01 11:35:09] [config] guided-alignment: none
[2023-07-01 11:35:09] [config] guided-alignment-cost: mse
[2023-07-01 11:35:09] [config] guided-alignment-weight: 0.1
[2023-07-01 11:35:09] [config] ignore-model-config: false
[2023-07-01 11:35:09] [config] input-types:
[2023-07-01 11:35:09] [config]   []
[2023-07-01 11:35:09] [config] interpolate-env-vars: false
[2023-07-01 11:35:09] [config] keep-best: false
[2023-07-01 11:35:09] [config] label-smoothing: 0.1
[2023-07-01 11:35:09] [config] layer-normalization: false
[2023-07-01 11:35:09] [config] learn-rate: 0.0003
[2023-07-01 11:35:09] [config] lemma-dependency: ""
[2023-07-01 11:35:09] [config] lemma-dim-emb: 0
[2023-07-01 11:35:09] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:35:09] [config] log-level: info
[2023-07-01 11:35:09] [config] log-time-zone: ""
[2023-07-01 11:35:09] [config] logical-epoch:
[2023-07-01 11:35:09] [config]   - 1e
[2023-07-01 11:35:09] [config]   - 0
[2023-07-01 11:35:09] [config] lr-decay: 0
[2023-07-01 11:35:09] [config] lr-decay-freq: 50000
[2023-07-01 11:35:09] [config] lr-decay-inv-sqrt:
[2023-07-01 11:35:09] [config]   - 16000
[2023-07-01 11:35:09] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:35:09] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:35:09] [config] lr-decay-start:
[2023-07-01 11:35:09] [config]   - 10
[2023-07-01 11:35:09] [config]   - 1
[2023-07-01 11:35:09] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:35:09] [config] lr-report: true
[2023-07-01 11:35:09] [config] lr-warmup: 16000
[2023-07-01 11:35:09] [config] lr-warmup-at-reload: false
[2023-07-01 11:35:09] [config] lr-warmup-cycle: false
[2023-07-01 11:35:09] [config] lr-warmup-start-rate: 0
[2023-07-01 11:35:09] [config] max-length: 100
[2023-07-01 11:35:09] [config] max-length-crop: false
[2023-07-01 11:35:09] [config] max-length-factor: 3
[2023-07-01 11:35:09] [config] maxi-batch: 100
[2023-07-01 11:35:09] [config] maxi-batch-sort: trg
[2023-07-01 11:35:09] [config] mini-batch: 1000
[2023-07-01 11:35:09] [config] mini-batch-fit: true
[2023-07-01 11:35:09] [config] mini-batch-fit-step: 10
[2023-07-01 11:35:09] [config] mini-batch-round-up: true
[2023-07-01 11:35:09] [config] mini-batch-track-lr: false
[2023-07-01 11:35:09] [config] mini-batch-warmup: 0
[2023-07-01 11:35:09] [config] mini-batch-words: 0
[2023-07-01 11:35:09] [config] mini-batch-words-ref: 0
[2023-07-01 11:35:09] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:35:09] [config] multi-loss-type: sum
[2023-07-01 11:35:09] [config] n-best: false
[2023-07-01 11:35:09] [config] no-nccl: false
[2023-07-01 11:35:09] [config] no-reload: false
[2023-07-01 11:35:09] [config] no-restore-corpus: false
[2023-07-01 11:35:09] [config] normalize: 1
[2023-07-01 11:35:09] [config] normalize-gradient: false
[2023-07-01 11:35:09] [config] num-devices: 0
[2023-07-01 11:35:09] [config] optimizer: adam
[2023-07-01 11:35:09] [config] optimizer-delay: 1
[2023-07-01 11:35:09] [config] optimizer-params:
[2023-07-01 11:35:09] [config]   - 0.9
[2023-07-01 11:35:09] [config]   - 0.98
[2023-07-01 11:35:09] [config]   - 1e-09
[2023-07-01 11:35:09] [config] output-omit-bias: false
[2023-07-01 11:35:09] [config] overwrite: true
[2023-07-01 11:35:09] [config] precision:
[2023-07-01 11:35:09] [config]   - float32
[2023-07-01 11:35:09] [config]   - float32
[2023-07-01 11:35:09] [config] pretrained-model: ""
[2023-07-01 11:35:09] [config] quantize-biases: false
[2023-07-01 11:35:09] [config] quantize-bits: 0
[2023-07-01 11:35:09] [config] quantize-log-based: false
[2023-07-01 11:35:09] [config] quantize-optimization-steps: 0
[2023-07-01 11:35:09] [config] quiet: false
[2023-07-01 11:35:09] [config] quiet-translation: true
[2023-07-01 11:35:09] [config] relative-paths: false
[2023-07-01 11:35:09] [config] right-left: false
[2023-07-01 11:35:09] [config] save-freq: 10000u
[2023-07-01 11:35:09] [config] seed: 1234
[2023-07-01 11:35:09] [config] sentencepiece-alphas:
[2023-07-01 11:35:09] [config]   []
[2023-07-01 11:35:09] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:35:09] [config] sentencepiece-options: ""
[2023-07-01 11:35:09] [config] sharding: global
[2023-07-01 11:35:09] [config] shuffle: data
[2023-07-01 11:35:09] [config] shuffle-in-ram: false
[2023-07-01 11:35:09] [config] sigterm: save-and-exit
[2023-07-01 11:35:09] [config] skip: false
[2023-07-01 11:35:09] [config] sqlite: ""
[2023-07-01 11:35:09] [config] sqlite-drop: false
[2023-07-01 11:35:09] [config] sync-freq: 200u
[2023-07-01 11:35:09] [config] sync-sgd: true
[2023-07-01 11:35:09] [config] tempdir: /tmp
[2023-07-01 11:35:09] [config] tied-embeddings: false
[2023-07-01 11:35:09] [config] tied-embeddings-all: true
[2023-07-01 11:35:09] [config] tied-embeddings-src: false
[2023-07-01 11:35:09] [config] train-embedder-rank:
[2023-07-01 11:35:09] [config]   []
[2023-07-01 11:35:09] [config] train-sets:
[2023-07-01 11:35:09] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:35:09] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:35:09] [config] transformer-aan-activation: swish
[2023-07-01 11:35:09] [config] transformer-aan-depth: 2
[2023-07-01 11:35:09] [config] transformer-aan-nogate: false
[2023-07-01 11:35:09] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:35:09] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:35:09] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:35:09] [config] transformer-depth-scaling: false
[2023-07-01 11:35:09] [config] transformer-dim-aan: 2048
[2023-07-01 11:35:09] [config] transformer-dim-ffn: 2048
[2023-07-01 11:35:09] [config] transformer-dropout: 0.1
[2023-07-01 11:35:09] [config] transformer-dropout-attention: 0
[2023-07-01 11:35:09] [config] transformer-dropout-ffn: 0
[2023-07-01 11:35:09] [config] transformer-ffn-activation: swish
[2023-07-01 11:35:09] [config] transformer-ffn-depth: 2
[2023-07-01 11:35:09] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:35:09] [config] transformer-heads: 8
[2023-07-01 11:35:09] [config] transformer-no-projection: false
[2023-07-01 11:35:09] [config] transformer-pool: false
[2023-07-01 11:35:09] [config] transformer-postprocess: dan
[2023-07-01 11:35:09] [config] transformer-postprocess-emb: d
[2023-07-01 11:35:09] [config] transformer-postprocess-top: ""
[2023-07-01 11:35:09] [config] transformer-preprocess: ""
[2023-07-01 11:35:09] [config] transformer-tied-layers:
[2023-07-01 11:35:09] [config]   []
[2023-07-01 11:35:09] [config] transformer-train-position-embeddings: false
[2023-07-01 11:35:09] [config] tsv: false
[2023-07-01 11:35:09] [config] tsv-fields: 0
[2023-07-01 11:35:09] [config] type: transformer
[2023-07-01 11:35:09] [config] ulr: false
[2023-07-01 11:35:09] [config] ulr-dim-emb: 0
[2023-07-01 11:35:09] [config] ulr-dropout: 0
[2023-07-01 11:35:09] [config] ulr-keys-vectors: ""
[2023-07-01 11:35:09] [config] ulr-query-vectors: ""
[2023-07-01 11:35:09] [config] ulr-softmax-temperature: 1
[2023-07-01 11:35:09] [config] ulr-trainable-transformation: false
[2023-07-01 11:35:09] [config] unlikelihood-loss: false
[2023-07-01 11:35:09] [config] valid-freq: 50000000
[2023-07-01 11:35:09] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:35:09] [config] valid-max-length: 1000
[2023-07-01 11:35:09] [config] valid-metrics:
[2023-07-01 11:35:09] [config]   - cross-entropy
[2023-07-01 11:35:09] [config]   - translation
[2023-07-01 11:35:09] [config] valid-mini-batch: 64
[2023-07-01 11:35:09] [config] valid-reset-stalled: false
[2023-07-01 11:35:09] [config] valid-script-args:
[2023-07-01 11:35:09] [config]   []
[2023-07-01 11:35:09] [config] valid-script-path: ""
[2023-07-01 11:35:09] [config] valid-sets:
[2023-07-01 11:35:09] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:35:09] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:35:09] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:35:09] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:35:09] [config] vocabs:
[2023-07-01 11:35:09] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:35:09] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:35:09] [config] word-penalty: 0
[2023-07-01 11:35:09] [config] word-scores: false
[2023-07-01 11:35:09] [config] workspace: 2048
[2023-07-01 11:35:09] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:35:09] Using synchronous SGD
[2023-07-01 11:35:09] Synced seed 1234
[2023-07-01 11:35:09] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:35:09] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:35:09] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:35:09] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:35:09] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:35:09] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:35:10] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:35:10] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:35:10] [comm] Using global sharding
[2023-07-01 11:35:10] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:35:10] [training] Using 1 GPUs
[2023-07-01 11:35:10] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:35:10] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:35:10] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:35:10] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:35:18] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:35:18] [valid] No post-processing script given for validating translator
[2023-07-01 11:35:18] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:35:18] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:35:18] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:35:18] [comm] Using global sharding
[2023-07-01 11:35:18] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:35:18] [training] Using 1 GPUs
[2023-07-01 11:35:18] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:35:19] Allocating memory for general optimizer shards
[2023-07-01 11:35:19] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:35:19] Loading Adam parameters
[2023-07-01 11:35:19] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:35:19] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:35:19] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:35:19] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:35:19] [data] Shuffling data
[2023-07-01 11:35:19] [data] Done reading 20,192 sentences
[2023-07-01 11:35:19] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:35:19] Training started
[2023-07-01 11:35:19] Training finished
[2023-07-01 11:35:23] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:35:23] [marian] Running on node20.datos.cluster.uy as process 17983 with command line:
[2023-07-01 11:35:23] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 117 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:35:23] [config] after: 0e
[2023-07-01 11:35:23] [config] after-batches: 0
[2023-07-01 11:35:23] [config] after-epochs: 117
[2023-07-01 11:35:23] [config] all-caps-every: 0
[2023-07-01 11:35:23] [config] allow-unk: false
[2023-07-01 11:35:23] [config] authors: false
[2023-07-01 11:35:23] [config] beam-size: 12
[2023-07-01 11:35:23] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:35:23] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:35:23] [config] bert-masking-fraction: 0.15
[2023-07-01 11:35:23] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:35:23] [config] bert-train-type-embeddings: true
[2023-07-01 11:35:23] [config] bert-type-vocab-size: 2
[2023-07-01 11:35:23] [config] build-info: ""
[2023-07-01 11:35:23] [config] check-gradient-nan: false
[2023-07-01 11:35:23] [config] check-nan: false
[2023-07-01 11:35:23] [config] cite: false
[2023-07-01 11:35:23] [config] clip-norm: 5
[2023-07-01 11:35:23] [config] cost-scaling:
[2023-07-01 11:35:23] [config]   []
[2023-07-01 11:35:23] [config] cost-type: ce-sum
[2023-07-01 11:35:23] [config] cpu-threads: 0
[2023-07-01 11:35:23] [config] data-threads: 8
[2023-07-01 11:35:23] [config] data-weighting: ""
[2023-07-01 11:35:23] [config] data-weighting-type: sentence
[2023-07-01 11:35:23] [config] dec-cell: gru
[2023-07-01 11:35:23] [config] dec-cell-base-depth: 2
[2023-07-01 11:35:23] [config] dec-cell-high-depth: 1
[2023-07-01 11:35:23] [config] dec-depth: 2
[2023-07-01 11:35:23] [config] devices:
[2023-07-01 11:35:23] [config]   - 0
[2023-07-01 11:35:23] [config] dim-emb: 512
[2023-07-01 11:35:23] [config] dim-rnn: 1024
[2023-07-01 11:35:23] [config] dim-vocabs:
[2023-07-01 11:35:23] [config]   - 16384
[2023-07-01 11:35:23] [config]   - 16384
[2023-07-01 11:35:23] [config] disp-first: 0
[2023-07-01 11:35:23] [config] disp-freq: 1000u
[2023-07-01 11:35:23] [config] disp-label-counts: true
[2023-07-01 11:35:23] [config] dropout-rnn: 0
[2023-07-01 11:35:23] [config] dropout-src: 0
[2023-07-01 11:35:23] [config] dropout-trg: 0
[2023-07-01 11:35:23] [config] dump-config: ""
[2023-07-01 11:35:23] [config] dynamic-gradient-scaling:
[2023-07-01 11:35:23] [config]   []
[2023-07-01 11:35:23] [config] early-stopping: 10
[2023-07-01 11:35:23] [config] early-stopping-on: first
[2023-07-01 11:35:23] [config] embedding-fix-src: false
[2023-07-01 11:35:23] [config] embedding-fix-trg: false
[2023-07-01 11:35:23] [config] embedding-normalization: false
[2023-07-01 11:35:23] [config] embedding-vectors:
[2023-07-01 11:35:23] [config]   []
[2023-07-01 11:35:23] [config] enc-cell: gru
[2023-07-01 11:35:23] [config] enc-cell-depth: 1
[2023-07-01 11:35:23] [config] enc-depth: 2
[2023-07-01 11:35:23] [config] enc-type: bidirectional
[2023-07-01 11:35:23] [config] english-title-case-every: 0
[2023-07-01 11:35:23] [config] exponential-smoothing: 0.0001
[2023-07-01 11:35:23] [config] factor-weight: 1
[2023-07-01 11:35:23] [config] factors-combine: sum
[2023-07-01 11:35:23] [config] factors-dim-emb: 0
[2023-07-01 11:35:23] [config] gradient-checkpointing: false
[2023-07-01 11:35:23] [config] gradient-norm-average-window: 100
[2023-07-01 11:35:23] [config] guided-alignment: none
[2023-07-01 11:35:23] [config] guided-alignment-cost: mse
[2023-07-01 11:35:23] [config] guided-alignment-weight: 0.1
[2023-07-01 11:35:23] [config] ignore-model-config: false
[2023-07-01 11:35:23] [config] input-types:
[2023-07-01 11:35:23] [config]   []
[2023-07-01 11:35:23] [config] interpolate-env-vars: false
[2023-07-01 11:35:23] [config] keep-best: false
[2023-07-01 11:35:23] [config] label-smoothing: 0.1
[2023-07-01 11:35:23] [config] layer-normalization: false
[2023-07-01 11:35:23] [config] learn-rate: 0.0003
[2023-07-01 11:35:23] [config] lemma-dependency: ""
[2023-07-01 11:35:23] [config] lemma-dim-emb: 0
[2023-07-01 11:35:23] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:35:23] [config] log-level: info
[2023-07-01 11:35:23] [config] log-time-zone: ""
[2023-07-01 11:35:23] [config] logical-epoch:
[2023-07-01 11:35:23] [config]   - 1e
[2023-07-01 11:35:23] [config]   - 0
[2023-07-01 11:35:23] [config] lr-decay: 0
[2023-07-01 11:35:23] [config] lr-decay-freq: 50000
[2023-07-01 11:35:23] [config] lr-decay-inv-sqrt:
[2023-07-01 11:35:23] [config]   - 16000
[2023-07-01 11:35:23] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:35:23] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:35:23] [config] lr-decay-start:
[2023-07-01 11:35:23] [config]   - 10
[2023-07-01 11:35:23] [config]   - 1
[2023-07-01 11:35:23] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:35:23] [config] lr-report: true
[2023-07-01 11:35:23] [config] lr-warmup: 16000
[2023-07-01 11:35:23] [config] lr-warmup-at-reload: false
[2023-07-01 11:35:23] [config] lr-warmup-cycle: false
[2023-07-01 11:35:23] [config] lr-warmup-start-rate: 0
[2023-07-01 11:35:23] [config] max-length: 100
[2023-07-01 11:35:23] [config] max-length-crop: false
[2023-07-01 11:35:23] [config] max-length-factor: 3
[2023-07-01 11:35:23] [config] maxi-batch: 100
[2023-07-01 11:35:23] [config] maxi-batch-sort: trg
[2023-07-01 11:35:23] [config] mini-batch: 1000
[2023-07-01 11:35:23] [config] mini-batch-fit: true
[2023-07-01 11:35:23] [config] mini-batch-fit-step: 10
[2023-07-01 11:35:23] [config] mini-batch-round-up: true
[2023-07-01 11:35:23] [config] mini-batch-track-lr: false
[2023-07-01 11:35:23] [config] mini-batch-warmup: 0
[2023-07-01 11:35:23] [config] mini-batch-words: 0
[2023-07-01 11:35:23] [config] mini-batch-words-ref: 0
[2023-07-01 11:35:23] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:35:23] [config] multi-loss-type: sum
[2023-07-01 11:35:23] [config] n-best: false
[2023-07-01 11:35:23] [config] no-nccl: false
[2023-07-01 11:35:23] [config] no-reload: false
[2023-07-01 11:35:23] [config] no-restore-corpus: false
[2023-07-01 11:35:23] [config] normalize: 1
[2023-07-01 11:35:23] [config] normalize-gradient: false
[2023-07-01 11:35:23] [config] num-devices: 0
[2023-07-01 11:35:23] [config] optimizer: adam
[2023-07-01 11:35:23] [config] optimizer-delay: 1
[2023-07-01 11:35:23] [config] optimizer-params:
[2023-07-01 11:35:23] [config]   - 0.9
[2023-07-01 11:35:23] [config]   - 0.98
[2023-07-01 11:35:23] [config]   - 1e-09
[2023-07-01 11:35:23] [config] output-omit-bias: false
[2023-07-01 11:35:23] [config] overwrite: true
[2023-07-01 11:35:23] [config] precision:
[2023-07-01 11:35:23] [config]   - float32
[2023-07-01 11:35:23] [config]   - float32
[2023-07-01 11:35:23] [config] pretrained-model: ""
[2023-07-01 11:35:23] [config] quantize-biases: false
[2023-07-01 11:35:23] [config] quantize-bits: 0
[2023-07-01 11:35:23] [config] quantize-log-based: false
[2023-07-01 11:35:23] [config] quantize-optimization-steps: 0
[2023-07-01 11:35:23] [config] quiet: false
[2023-07-01 11:35:23] [config] quiet-translation: true
[2023-07-01 11:35:23] [config] relative-paths: false
[2023-07-01 11:35:23] [config] right-left: false
[2023-07-01 11:35:23] [config] save-freq: 10000u
[2023-07-01 11:35:23] [config] seed: 1234
[2023-07-01 11:35:23] [config] sentencepiece-alphas:
[2023-07-01 11:35:23] [config]   []
[2023-07-01 11:35:23] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:35:23] [config] sentencepiece-options: ""
[2023-07-01 11:35:23] [config] sharding: global
[2023-07-01 11:35:23] [config] shuffle: data
[2023-07-01 11:35:23] [config] shuffle-in-ram: false
[2023-07-01 11:35:23] [config] sigterm: save-and-exit
[2023-07-01 11:35:23] [config] skip: false
[2023-07-01 11:35:23] [config] sqlite: ""
[2023-07-01 11:35:23] [config] sqlite-drop: false
[2023-07-01 11:35:23] [config] sync-freq: 200u
[2023-07-01 11:35:23] [config] sync-sgd: true
[2023-07-01 11:35:23] [config] tempdir: /tmp
[2023-07-01 11:35:23] [config] tied-embeddings: false
[2023-07-01 11:35:23] [config] tied-embeddings-all: true
[2023-07-01 11:35:23] [config] tied-embeddings-src: false
[2023-07-01 11:35:23] [config] train-embedder-rank:
[2023-07-01 11:35:23] [config]   []
[2023-07-01 11:35:23] [config] train-sets:
[2023-07-01 11:35:23] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:35:23] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:35:23] [config] transformer-aan-activation: swish
[2023-07-01 11:35:23] [config] transformer-aan-depth: 2
[2023-07-01 11:35:23] [config] transformer-aan-nogate: false
[2023-07-01 11:35:23] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:35:23] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:35:23] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:35:23] [config] transformer-depth-scaling: false
[2023-07-01 11:35:23] [config] transformer-dim-aan: 2048
[2023-07-01 11:35:23] [config] transformer-dim-ffn: 2048
[2023-07-01 11:35:23] [config] transformer-dropout: 0.1
[2023-07-01 11:35:23] [config] transformer-dropout-attention: 0
[2023-07-01 11:35:23] [config] transformer-dropout-ffn: 0
[2023-07-01 11:35:23] [config] transformer-ffn-activation: swish
[2023-07-01 11:35:23] [config] transformer-ffn-depth: 2
[2023-07-01 11:35:23] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:35:23] [config] transformer-heads: 8
[2023-07-01 11:35:23] [config] transformer-no-projection: false
[2023-07-01 11:35:23] [config] transformer-pool: false
[2023-07-01 11:35:23] [config] transformer-postprocess: dan
[2023-07-01 11:35:23] [config] transformer-postprocess-emb: d
[2023-07-01 11:35:23] [config] transformer-postprocess-top: ""
[2023-07-01 11:35:23] [config] transformer-preprocess: ""
[2023-07-01 11:35:23] [config] transformer-tied-layers:
[2023-07-01 11:35:23] [config]   []
[2023-07-01 11:35:23] [config] transformer-train-position-embeddings: false
[2023-07-01 11:35:23] [config] tsv: false
[2023-07-01 11:35:23] [config] tsv-fields: 0
[2023-07-01 11:35:23] [config] type: transformer
[2023-07-01 11:35:23] [config] ulr: false
[2023-07-01 11:35:23] [config] ulr-dim-emb: 0
[2023-07-01 11:35:23] [config] ulr-dropout: 0
[2023-07-01 11:35:23] [config] ulr-keys-vectors: ""
[2023-07-01 11:35:23] [config] ulr-query-vectors: ""
[2023-07-01 11:35:23] [config] ulr-softmax-temperature: 1
[2023-07-01 11:35:23] [config] ulr-trainable-transformation: false
[2023-07-01 11:35:23] [config] unlikelihood-loss: false
[2023-07-01 11:35:23] [config] valid-freq: 50000000
[2023-07-01 11:35:23] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:35:23] [config] valid-max-length: 1000
[2023-07-01 11:35:23] [config] valid-metrics:
[2023-07-01 11:35:23] [config]   - cross-entropy
[2023-07-01 11:35:23] [config]   - translation
[2023-07-01 11:35:23] [config] valid-mini-batch: 64
[2023-07-01 11:35:23] [config] valid-reset-stalled: false
[2023-07-01 11:35:23] [config] valid-script-args:
[2023-07-01 11:35:23] [config]   []
[2023-07-01 11:35:23] [config] valid-script-path: ""
[2023-07-01 11:35:23] [config] valid-sets:
[2023-07-01 11:35:23] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:35:23] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:35:23] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:35:23] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:35:23] [config] vocabs:
[2023-07-01 11:35:23] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:35:23] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:35:23] [config] word-penalty: 0
[2023-07-01 11:35:23] [config] word-scores: false
[2023-07-01 11:35:23] [config] workspace: 2048
[2023-07-01 11:35:23] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:35:23] Using synchronous SGD
[2023-07-01 11:35:23] Synced seed 1234
[2023-07-01 11:35:23] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:35:23] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:35:23] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:35:23] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:35:23] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:35:23] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:35:24] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:35:24] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:35:24] [comm] Using global sharding
[2023-07-01 11:35:24] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:35:24] [training] Using 1 GPUs
[2023-07-01 11:35:24] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:35:24] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:35:24] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:35:24] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:35:32] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:35:32] [valid] No post-processing script given for validating translator
[2023-07-01 11:35:32] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:35:32] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:35:32] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:35:32] [comm] Using global sharding
[2023-07-01 11:35:32] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:35:32] [training] Using 1 GPUs
[2023-07-01 11:35:32] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:35:32] Allocating memory for general optimizer shards
[2023-07-01 11:35:32] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:35:32] Loading Adam parameters
[2023-07-01 11:35:33] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:35:33] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:35:33] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:35:33] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:35:33] [data] Shuffling data
[2023-07-01 11:35:33] [data] Done reading 20,192 sentences
[2023-07-01 11:35:33] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:35:33] Training started
[2023-07-01 11:35:33] Training finished
[2023-07-01 11:35:36] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:35:36] [marian] Running on node20.datos.cluster.uy as process 18040 with command line:
[2023-07-01 11:35:36] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 118 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:35:36] [config] after: 0e
[2023-07-01 11:35:36] [config] after-batches: 0
[2023-07-01 11:35:36] [config] after-epochs: 118
[2023-07-01 11:35:36] [config] all-caps-every: 0
[2023-07-01 11:35:36] [config] allow-unk: false
[2023-07-01 11:35:36] [config] authors: false
[2023-07-01 11:35:36] [config] beam-size: 12
[2023-07-01 11:35:36] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:35:36] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:35:36] [config] bert-masking-fraction: 0.15
[2023-07-01 11:35:36] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:35:36] [config] bert-train-type-embeddings: true
[2023-07-01 11:35:36] [config] bert-type-vocab-size: 2
[2023-07-01 11:35:36] [config] build-info: ""
[2023-07-01 11:35:36] [config] check-gradient-nan: false
[2023-07-01 11:35:36] [config] check-nan: false
[2023-07-01 11:35:36] [config] cite: false
[2023-07-01 11:35:36] [config] clip-norm: 5
[2023-07-01 11:35:36] [config] cost-scaling:
[2023-07-01 11:35:36] [config]   []
[2023-07-01 11:35:36] [config] cost-type: ce-sum
[2023-07-01 11:35:36] [config] cpu-threads: 0
[2023-07-01 11:35:36] [config] data-threads: 8
[2023-07-01 11:35:36] [config] data-weighting: ""
[2023-07-01 11:35:36] [config] data-weighting-type: sentence
[2023-07-01 11:35:36] [config] dec-cell: gru
[2023-07-01 11:35:36] [config] dec-cell-base-depth: 2
[2023-07-01 11:35:36] [config] dec-cell-high-depth: 1
[2023-07-01 11:35:36] [config] dec-depth: 2
[2023-07-01 11:35:36] [config] devices:
[2023-07-01 11:35:36] [config]   - 0
[2023-07-01 11:35:36] [config] dim-emb: 512
[2023-07-01 11:35:36] [config] dim-rnn: 1024
[2023-07-01 11:35:36] [config] dim-vocabs:
[2023-07-01 11:35:36] [config]   - 16384
[2023-07-01 11:35:36] [config]   - 16384
[2023-07-01 11:35:36] [config] disp-first: 0
[2023-07-01 11:35:36] [config] disp-freq: 1000u
[2023-07-01 11:35:36] [config] disp-label-counts: true
[2023-07-01 11:35:36] [config] dropout-rnn: 0
[2023-07-01 11:35:36] [config] dropout-src: 0
[2023-07-01 11:35:36] [config] dropout-trg: 0
[2023-07-01 11:35:36] [config] dump-config: ""
[2023-07-01 11:35:36] [config] dynamic-gradient-scaling:
[2023-07-01 11:35:36] [config]   []
[2023-07-01 11:35:36] [config] early-stopping: 10
[2023-07-01 11:35:36] [config] early-stopping-on: first
[2023-07-01 11:35:36] [config] embedding-fix-src: false
[2023-07-01 11:35:36] [config] embedding-fix-trg: false
[2023-07-01 11:35:36] [config] embedding-normalization: false
[2023-07-01 11:35:36] [config] embedding-vectors:
[2023-07-01 11:35:36] [config]   []
[2023-07-01 11:35:36] [config] enc-cell: gru
[2023-07-01 11:35:36] [config] enc-cell-depth: 1
[2023-07-01 11:35:36] [config] enc-depth: 2
[2023-07-01 11:35:36] [config] enc-type: bidirectional
[2023-07-01 11:35:36] [config] english-title-case-every: 0
[2023-07-01 11:35:36] [config] exponential-smoothing: 0.0001
[2023-07-01 11:35:36] [config] factor-weight: 1
[2023-07-01 11:35:36] [config] factors-combine: sum
[2023-07-01 11:35:36] [config] factors-dim-emb: 0
[2023-07-01 11:35:36] [config] gradient-checkpointing: false
[2023-07-01 11:35:36] [config] gradient-norm-average-window: 100
[2023-07-01 11:35:36] [config] guided-alignment: none
[2023-07-01 11:35:36] [config] guided-alignment-cost: mse
[2023-07-01 11:35:36] [config] guided-alignment-weight: 0.1
[2023-07-01 11:35:36] [config] ignore-model-config: false
[2023-07-01 11:35:36] [config] input-types:
[2023-07-01 11:35:36] [config]   []
[2023-07-01 11:35:36] [config] interpolate-env-vars: false
[2023-07-01 11:35:36] [config] keep-best: false
[2023-07-01 11:35:36] [config] label-smoothing: 0.1
[2023-07-01 11:35:36] [config] layer-normalization: false
[2023-07-01 11:35:36] [config] learn-rate: 0.0003
[2023-07-01 11:35:36] [config] lemma-dependency: ""
[2023-07-01 11:35:36] [config] lemma-dim-emb: 0
[2023-07-01 11:35:36] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:35:36] [config] log-level: info
[2023-07-01 11:35:36] [config] log-time-zone: ""
[2023-07-01 11:35:36] [config] logical-epoch:
[2023-07-01 11:35:36] [config]   - 1e
[2023-07-01 11:35:36] [config]   - 0
[2023-07-01 11:35:36] [config] lr-decay: 0
[2023-07-01 11:35:36] [config] lr-decay-freq: 50000
[2023-07-01 11:35:36] [config] lr-decay-inv-sqrt:
[2023-07-01 11:35:36] [config]   - 16000
[2023-07-01 11:35:36] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:35:36] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:35:36] [config] lr-decay-start:
[2023-07-01 11:35:36] [config]   - 10
[2023-07-01 11:35:36] [config]   - 1
[2023-07-01 11:35:36] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:35:36] [config] lr-report: true
[2023-07-01 11:35:36] [config] lr-warmup: 16000
[2023-07-01 11:35:36] [config] lr-warmup-at-reload: false
[2023-07-01 11:35:36] [config] lr-warmup-cycle: false
[2023-07-01 11:35:36] [config] lr-warmup-start-rate: 0
[2023-07-01 11:35:36] [config] max-length: 100
[2023-07-01 11:35:36] [config] max-length-crop: false
[2023-07-01 11:35:36] [config] max-length-factor: 3
[2023-07-01 11:35:36] [config] maxi-batch: 100
[2023-07-01 11:35:36] [config] maxi-batch-sort: trg
[2023-07-01 11:35:36] [config] mini-batch: 1000
[2023-07-01 11:35:36] [config] mini-batch-fit: true
[2023-07-01 11:35:36] [config] mini-batch-fit-step: 10
[2023-07-01 11:35:36] [config] mini-batch-round-up: true
[2023-07-01 11:35:36] [config] mini-batch-track-lr: false
[2023-07-01 11:35:36] [config] mini-batch-warmup: 0
[2023-07-01 11:35:36] [config] mini-batch-words: 0
[2023-07-01 11:35:36] [config] mini-batch-words-ref: 0
[2023-07-01 11:35:36] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:35:36] [config] multi-loss-type: sum
[2023-07-01 11:35:36] [config] n-best: false
[2023-07-01 11:35:36] [config] no-nccl: false
[2023-07-01 11:35:36] [config] no-reload: false
[2023-07-01 11:35:36] [config] no-restore-corpus: false
[2023-07-01 11:35:36] [config] normalize: 1
[2023-07-01 11:35:36] [config] normalize-gradient: false
[2023-07-01 11:35:36] [config] num-devices: 0
[2023-07-01 11:35:36] [config] optimizer: adam
[2023-07-01 11:35:36] [config] optimizer-delay: 1
[2023-07-01 11:35:36] [config] optimizer-params:
[2023-07-01 11:35:36] [config]   - 0.9
[2023-07-01 11:35:36] [config]   - 0.98
[2023-07-01 11:35:36] [config]   - 1e-09
[2023-07-01 11:35:36] [config] output-omit-bias: false
[2023-07-01 11:35:36] [config] overwrite: true
[2023-07-01 11:35:36] [config] precision:
[2023-07-01 11:35:36] [config]   - float32
[2023-07-01 11:35:36] [config]   - float32
[2023-07-01 11:35:36] [config] pretrained-model: ""
[2023-07-01 11:35:36] [config] quantize-biases: false
[2023-07-01 11:35:36] [config] quantize-bits: 0
[2023-07-01 11:35:36] [config] quantize-log-based: false
[2023-07-01 11:35:36] [config] quantize-optimization-steps: 0
[2023-07-01 11:35:36] [config] quiet: false
[2023-07-01 11:35:36] [config] quiet-translation: true
[2023-07-01 11:35:36] [config] relative-paths: false
[2023-07-01 11:35:36] [config] right-left: false
[2023-07-01 11:35:36] [config] save-freq: 10000u
[2023-07-01 11:35:36] [config] seed: 1234
[2023-07-01 11:35:36] [config] sentencepiece-alphas:
[2023-07-01 11:35:36] [config]   []
[2023-07-01 11:35:36] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:35:36] [config] sentencepiece-options: ""
[2023-07-01 11:35:36] [config] sharding: global
[2023-07-01 11:35:36] [config] shuffle: data
[2023-07-01 11:35:36] [config] shuffle-in-ram: false
[2023-07-01 11:35:36] [config] sigterm: save-and-exit
[2023-07-01 11:35:36] [config] skip: false
[2023-07-01 11:35:36] [config] sqlite: ""
[2023-07-01 11:35:36] [config] sqlite-drop: false
[2023-07-01 11:35:36] [config] sync-freq: 200u
[2023-07-01 11:35:36] [config] sync-sgd: true
[2023-07-01 11:35:36] [config] tempdir: /tmp
[2023-07-01 11:35:36] [config] tied-embeddings: false
[2023-07-01 11:35:36] [config] tied-embeddings-all: true
[2023-07-01 11:35:36] [config] tied-embeddings-src: false
[2023-07-01 11:35:36] [config] train-embedder-rank:
[2023-07-01 11:35:36] [config]   []
[2023-07-01 11:35:36] [config] train-sets:
[2023-07-01 11:35:36] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:35:36] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:35:36] [config] transformer-aan-activation: swish
[2023-07-01 11:35:36] [config] transformer-aan-depth: 2
[2023-07-01 11:35:36] [config] transformer-aan-nogate: false
[2023-07-01 11:35:36] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:35:36] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:35:36] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:35:36] [config] transformer-depth-scaling: false
[2023-07-01 11:35:36] [config] transformer-dim-aan: 2048
[2023-07-01 11:35:36] [config] transformer-dim-ffn: 2048
[2023-07-01 11:35:36] [config] transformer-dropout: 0.1
[2023-07-01 11:35:36] [config] transformer-dropout-attention: 0
[2023-07-01 11:35:36] [config] transformer-dropout-ffn: 0
[2023-07-01 11:35:36] [config] transformer-ffn-activation: swish
[2023-07-01 11:35:36] [config] transformer-ffn-depth: 2
[2023-07-01 11:35:36] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:35:36] [config] transformer-heads: 8
[2023-07-01 11:35:36] [config] transformer-no-projection: false
[2023-07-01 11:35:36] [config] transformer-pool: false
[2023-07-01 11:35:36] [config] transformer-postprocess: dan
[2023-07-01 11:35:36] [config] transformer-postprocess-emb: d
[2023-07-01 11:35:36] [config] transformer-postprocess-top: ""
[2023-07-01 11:35:36] [config] transformer-preprocess: ""
[2023-07-01 11:35:36] [config] transformer-tied-layers:
[2023-07-01 11:35:36] [config]   []
[2023-07-01 11:35:36] [config] transformer-train-position-embeddings: false
[2023-07-01 11:35:36] [config] tsv: false
[2023-07-01 11:35:36] [config] tsv-fields: 0
[2023-07-01 11:35:36] [config] type: transformer
[2023-07-01 11:35:36] [config] ulr: false
[2023-07-01 11:35:36] [config] ulr-dim-emb: 0
[2023-07-01 11:35:36] [config] ulr-dropout: 0
[2023-07-01 11:35:36] [config] ulr-keys-vectors: ""
[2023-07-01 11:35:36] [config] ulr-query-vectors: ""
[2023-07-01 11:35:36] [config] ulr-softmax-temperature: 1
[2023-07-01 11:35:36] [config] ulr-trainable-transformation: false
[2023-07-01 11:35:36] [config] unlikelihood-loss: false
[2023-07-01 11:35:36] [config] valid-freq: 50000000
[2023-07-01 11:35:36] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:35:36] [config] valid-max-length: 1000
[2023-07-01 11:35:36] [config] valid-metrics:
[2023-07-01 11:35:36] [config]   - cross-entropy
[2023-07-01 11:35:36] [config]   - translation
[2023-07-01 11:35:36] [config] valid-mini-batch: 64
[2023-07-01 11:35:36] [config] valid-reset-stalled: false
[2023-07-01 11:35:36] [config] valid-script-args:
[2023-07-01 11:35:36] [config]   []
[2023-07-01 11:35:36] [config] valid-script-path: ""
[2023-07-01 11:35:36] [config] valid-sets:
[2023-07-01 11:35:36] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:35:36] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:35:36] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:35:36] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:35:36] [config] vocabs:
[2023-07-01 11:35:36] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:35:36] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:35:36] [config] word-penalty: 0
[2023-07-01 11:35:36] [config] word-scores: false
[2023-07-01 11:35:36] [config] workspace: 2048
[2023-07-01 11:35:36] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:35:36] Using synchronous SGD
[2023-07-01 11:35:36] Synced seed 1234
[2023-07-01 11:35:36] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:35:36] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:35:36] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:35:36] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:35:36] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:35:36] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:35:37] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:35:37] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:35:37] [comm] Using global sharding
[2023-07-01 11:35:37] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:35:37] [training] Using 1 GPUs
[2023-07-01 11:35:37] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:35:37] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:35:38] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:35:38] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:35:45] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:35:45] [valid] No post-processing script given for validating translator
[2023-07-01 11:35:45] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:35:45] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:35:45] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:35:45] [comm] Using global sharding
[2023-07-01 11:35:45] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:35:45] [training] Using 1 GPUs
[2023-07-01 11:35:45] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:35:46] Allocating memory for general optimizer shards
[2023-07-01 11:35:46] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:35:46] Loading Adam parameters
[2023-07-01 11:35:46] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:35:46] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:35:46] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:35:46] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:35:46] [data] Shuffling data
[2023-07-01 11:35:46] [data] Done reading 20,192 sentences
[2023-07-01 11:35:46] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:35:46] Training started
[2023-07-01 11:35:46] Training finished
[2023-07-01 11:35:50] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:35:50] [marian] Running on node20.datos.cluster.uy as process 18098 with command line:
[2023-07-01 11:35:50] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 119 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:35:50] [config] after: 0e
[2023-07-01 11:35:50] [config] after-batches: 0
[2023-07-01 11:35:50] [config] after-epochs: 119
[2023-07-01 11:35:50] [config] all-caps-every: 0
[2023-07-01 11:35:50] [config] allow-unk: false
[2023-07-01 11:35:50] [config] authors: false
[2023-07-01 11:35:50] [config] beam-size: 12
[2023-07-01 11:35:50] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:35:50] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:35:50] [config] bert-masking-fraction: 0.15
[2023-07-01 11:35:50] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:35:50] [config] bert-train-type-embeddings: true
[2023-07-01 11:35:50] [config] bert-type-vocab-size: 2
[2023-07-01 11:35:50] [config] build-info: ""
[2023-07-01 11:35:50] [config] check-gradient-nan: false
[2023-07-01 11:35:50] [config] check-nan: false
[2023-07-01 11:35:50] [config] cite: false
[2023-07-01 11:35:50] [config] clip-norm: 5
[2023-07-01 11:35:50] [config] cost-scaling:
[2023-07-01 11:35:50] [config]   []
[2023-07-01 11:35:50] [config] cost-type: ce-sum
[2023-07-01 11:35:50] [config] cpu-threads: 0
[2023-07-01 11:35:50] [config] data-threads: 8
[2023-07-01 11:35:50] [config] data-weighting: ""
[2023-07-01 11:35:50] [config] data-weighting-type: sentence
[2023-07-01 11:35:50] [config] dec-cell: gru
[2023-07-01 11:35:50] [config] dec-cell-base-depth: 2
[2023-07-01 11:35:50] [config] dec-cell-high-depth: 1
[2023-07-01 11:35:50] [config] dec-depth: 2
[2023-07-01 11:35:50] [config] devices:
[2023-07-01 11:35:50] [config]   - 0
[2023-07-01 11:35:50] [config] dim-emb: 512
[2023-07-01 11:35:50] [config] dim-rnn: 1024
[2023-07-01 11:35:50] [config] dim-vocabs:
[2023-07-01 11:35:50] [config]   - 16384
[2023-07-01 11:35:50] [config]   - 16384
[2023-07-01 11:35:50] [config] disp-first: 0
[2023-07-01 11:35:50] [config] disp-freq: 1000u
[2023-07-01 11:35:50] [config] disp-label-counts: true
[2023-07-01 11:35:50] [config] dropout-rnn: 0
[2023-07-01 11:35:50] [config] dropout-src: 0
[2023-07-01 11:35:50] [config] dropout-trg: 0
[2023-07-01 11:35:50] [config] dump-config: ""
[2023-07-01 11:35:50] [config] dynamic-gradient-scaling:
[2023-07-01 11:35:50] [config]   []
[2023-07-01 11:35:50] [config] early-stopping: 10
[2023-07-01 11:35:50] [config] early-stopping-on: first
[2023-07-01 11:35:50] [config] embedding-fix-src: false
[2023-07-01 11:35:50] [config] embedding-fix-trg: false
[2023-07-01 11:35:50] [config] embedding-normalization: false
[2023-07-01 11:35:50] [config] embedding-vectors:
[2023-07-01 11:35:50] [config]   []
[2023-07-01 11:35:50] [config] enc-cell: gru
[2023-07-01 11:35:50] [config] enc-cell-depth: 1
[2023-07-01 11:35:50] [config] enc-depth: 2
[2023-07-01 11:35:50] [config] enc-type: bidirectional
[2023-07-01 11:35:50] [config] english-title-case-every: 0
[2023-07-01 11:35:50] [config] exponential-smoothing: 0.0001
[2023-07-01 11:35:50] [config] factor-weight: 1
[2023-07-01 11:35:50] [config] factors-combine: sum
[2023-07-01 11:35:50] [config] factors-dim-emb: 0
[2023-07-01 11:35:50] [config] gradient-checkpointing: false
[2023-07-01 11:35:50] [config] gradient-norm-average-window: 100
[2023-07-01 11:35:50] [config] guided-alignment: none
[2023-07-01 11:35:50] [config] guided-alignment-cost: mse
[2023-07-01 11:35:50] [config] guided-alignment-weight: 0.1
[2023-07-01 11:35:50] [config] ignore-model-config: false
[2023-07-01 11:35:50] [config] input-types:
[2023-07-01 11:35:50] [config]   []
[2023-07-01 11:35:50] [config] interpolate-env-vars: false
[2023-07-01 11:35:50] [config] keep-best: false
[2023-07-01 11:35:50] [config] label-smoothing: 0.1
[2023-07-01 11:35:50] [config] layer-normalization: false
[2023-07-01 11:35:50] [config] learn-rate: 0.0003
[2023-07-01 11:35:50] [config] lemma-dependency: ""
[2023-07-01 11:35:50] [config] lemma-dim-emb: 0
[2023-07-01 11:35:50] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:35:50] [config] log-level: info
[2023-07-01 11:35:50] [config] log-time-zone: ""
[2023-07-01 11:35:50] [config] logical-epoch:
[2023-07-01 11:35:50] [config]   - 1e
[2023-07-01 11:35:50] [config]   - 0
[2023-07-01 11:35:50] [config] lr-decay: 0
[2023-07-01 11:35:50] [config] lr-decay-freq: 50000
[2023-07-01 11:35:50] [config] lr-decay-inv-sqrt:
[2023-07-01 11:35:50] [config]   - 16000
[2023-07-01 11:35:50] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:35:50] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:35:50] [config] lr-decay-start:
[2023-07-01 11:35:50] [config]   - 10
[2023-07-01 11:35:50] [config]   - 1
[2023-07-01 11:35:50] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:35:50] [config] lr-report: true
[2023-07-01 11:35:50] [config] lr-warmup: 16000
[2023-07-01 11:35:50] [config] lr-warmup-at-reload: false
[2023-07-01 11:35:50] [config] lr-warmup-cycle: false
[2023-07-01 11:35:50] [config] lr-warmup-start-rate: 0
[2023-07-01 11:35:50] [config] max-length: 100
[2023-07-01 11:35:50] [config] max-length-crop: false
[2023-07-01 11:35:50] [config] max-length-factor: 3
[2023-07-01 11:35:50] [config] maxi-batch: 100
[2023-07-01 11:35:50] [config] maxi-batch-sort: trg
[2023-07-01 11:35:50] [config] mini-batch: 1000
[2023-07-01 11:35:50] [config] mini-batch-fit: true
[2023-07-01 11:35:50] [config] mini-batch-fit-step: 10
[2023-07-01 11:35:50] [config] mini-batch-round-up: true
[2023-07-01 11:35:50] [config] mini-batch-track-lr: false
[2023-07-01 11:35:50] [config] mini-batch-warmup: 0
[2023-07-01 11:35:50] [config] mini-batch-words: 0
[2023-07-01 11:35:50] [config] mini-batch-words-ref: 0
[2023-07-01 11:35:50] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:35:50] [config] multi-loss-type: sum
[2023-07-01 11:35:50] [config] n-best: false
[2023-07-01 11:35:50] [config] no-nccl: false
[2023-07-01 11:35:50] [config] no-reload: false
[2023-07-01 11:35:50] [config] no-restore-corpus: false
[2023-07-01 11:35:50] [config] normalize: 1
[2023-07-01 11:35:50] [config] normalize-gradient: false
[2023-07-01 11:35:50] [config] num-devices: 0
[2023-07-01 11:35:50] [config] optimizer: adam
[2023-07-01 11:35:50] [config] optimizer-delay: 1
[2023-07-01 11:35:50] [config] optimizer-params:
[2023-07-01 11:35:50] [config]   - 0.9
[2023-07-01 11:35:50] [config]   - 0.98
[2023-07-01 11:35:50] [config]   - 1e-09
[2023-07-01 11:35:50] [config] output-omit-bias: false
[2023-07-01 11:35:50] [config] overwrite: true
[2023-07-01 11:35:50] [config] precision:
[2023-07-01 11:35:50] [config]   - float32
[2023-07-01 11:35:50] [config]   - float32
[2023-07-01 11:35:50] [config] pretrained-model: ""
[2023-07-01 11:35:50] [config] quantize-biases: false
[2023-07-01 11:35:50] [config] quantize-bits: 0
[2023-07-01 11:35:50] [config] quantize-log-based: false
[2023-07-01 11:35:50] [config] quantize-optimization-steps: 0
[2023-07-01 11:35:50] [config] quiet: false
[2023-07-01 11:35:50] [config] quiet-translation: true
[2023-07-01 11:35:50] [config] relative-paths: false
[2023-07-01 11:35:50] [config] right-left: false
[2023-07-01 11:35:50] [config] save-freq: 10000u
[2023-07-01 11:35:50] [config] seed: 1234
[2023-07-01 11:35:50] [config] sentencepiece-alphas:
[2023-07-01 11:35:50] [config]   []
[2023-07-01 11:35:50] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:35:50] [config] sentencepiece-options: ""
[2023-07-01 11:35:50] [config] sharding: global
[2023-07-01 11:35:50] [config] shuffle: data
[2023-07-01 11:35:50] [config] shuffle-in-ram: false
[2023-07-01 11:35:50] [config] sigterm: save-and-exit
[2023-07-01 11:35:50] [config] skip: false
[2023-07-01 11:35:50] [config] sqlite: ""
[2023-07-01 11:35:50] [config] sqlite-drop: false
[2023-07-01 11:35:50] [config] sync-freq: 200u
[2023-07-01 11:35:50] [config] sync-sgd: true
[2023-07-01 11:35:50] [config] tempdir: /tmp
[2023-07-01 11:35:50] [config] tied-embeddings: false
[2023-07-01 11:35:50] [config] tied-embeddings-all: true
[2023-07-01 11:35:50] [config] tied-embeddings-src: false
[2023-07-01 11:35:50] [config] train-embedder-rank:
[2023-07-01 11:35:50] [config]   []
[2023-07-01 11:35:50] [config] train-sets:
[2023-07-01 11:35:50] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:35:50] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:35:50] [config] transformer-aan-activation: swish
[2023-07-01 11:35:50] [config] transformer-aan-depth: 2
[2023-07-01 11:35:50] [config] transformer-aan-nogate: false
[2023-07-01 11:35:50] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:35:50] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:35:50] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:35:50] [config] transformer-depth-scaling: false
[2023-07-01 11:35:50] [config] transformer-dim-aan: 2048
[2023-07-01 11:35:50] [config] transformer-dim-ffn: 2048
[2023-07-01 11:35:50] [config] transformer-dropout: 0.1
[2023-07-01 11:35:50] [config] transformer-dropout-attention: 0
[2023-07-01 11:35:50] [config] transformer-dropout-ffn: 0
[2023-07-01 11:35:50] [config] transformer-ffn-activation: swish
[2023-07-01 11:35:50] [config] transformer-ffn-depth: 2
[2023-07-01 11:35:50] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:35:50] [config] transformer-heads: 8
[2023-07-01 11:35:50] [config] transformer-no-projection: false
[2023-07-01 11:35:50] [config] transformer-pool: false
[2023-07-01 11:35:50] [config] transformer-postprocess: dan
[2023-07-01 11:35:50] [config] transformer-postprocess-emb: d
[2023-07-01 11:35:50] [config] transformer-postprocess-top: ""
[2023-07-01 11:35:50] [config] transformer-preprocess: ""
[2023-07-01 11:35:50] [config] transformer-tied-layers:
[2023-07-01 11:35:50] [config]   []
[2023-07-01 11:35:50] [config] transformer-train-position-embeddings: false
[2023-07-01 11:35:50] [config] tsv: false
[2023-07-01 11:35:50] [config] tsv-fields: 0
[2023-07-01 11:35:50] [config] type: transformer
[2023-07-01 11:35:50] [config] ulr: false
[2023-07-01 11:35:50] [config] ulr-dim-emb: 0
[2023-07-01 11:35:50] [config] ulr-dropout: 0
[2023-07-01 11:35:50] [config] ulr-keys-vectors: ""
[2023-07-01 11:35:50] [config] ulr-query-vectors: ""
[2023-07-01 11:35:50] [config] ulr-softmax-temperature: 1
[2023-07-01 11:35:50] [config] ulr-trainable-transformation: false
[2023-07-01 11:35:50] [config] unlikelihood-loss: false
[2023-07-01 11:35:50] [config] valid-freq: 50000000
[2023-07-01 11:35:50] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:35:50] [config] valid-max-length: 1000
[2023-07-01 11:35:50] [config] valid-metrics:
[2023-07-01 11:35:50] [config]   - cross-entropy
[2023-07-01 11:35:50] [config]   - translation
[2023-07-01 11:35:50] [config] valid-mini-batch: 64
[2023-07-01 11:35:50] [config] valid-reset-stalled: false
[2023-07-01 11:35:50] [config] valid-script-args:
[2023-07-01 11:35:50] [config]   []
[2023-07-01 11:35:50] [config] valid-script-path: ""
[2023-07-01 11:35:50] [config] valid-sets:
[2023-07-01 11:35:50] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:35:50] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:35:50] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:35:50] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:35:50] [config] vocabs:
[2023-07-01 11:35:50] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:35:50] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:35:50] [config] word-penalty: 0
[2023-07-01 11:35:50] [config] word-scores: false
[2023-07-01 11:35:50] [config] workspace: 2048
[2023-07-01 11:35:50] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:35:50] Using synchronous SGD
[2023-07-01 11:35:50] Synced seed 1234
[2023-07-01 11:35:50] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:35:50] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:35:50] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:35:50] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:35:50] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:35:50] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:35:51] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:35:51] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:35:51] [comm] Using global sharding
[2023-07-01 11:35:51] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:35:51] [training] Using 1 GPUs
[2023-07-01 11:35:51] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:35:51] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:35:51] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:35:51] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:35:59] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:35:59] [valid] No post-processing script given for validating translator
[2023-07-01 11:35:59] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:35:59] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:35:59] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:35:59] [comm] Using global sharding
[2023-07-01 11:35:59] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:35:59] [training] Using 1 GPUs
[2023-07-01 11:35:59] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:36:00] Allocating memory for general optimizer shards
[2023-07-01 11:36:00] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:36:00] Loading Adam parameters
[2023-07-01 11:36:00] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:36:00] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:36:00] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:36:00] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:36:00] [data] Shuffling data
[2023-07-01 11:36:00] [data] Done reading 20,192 sentences
[2023-07-01 11:36:00] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:36:00] Training started
[2023-07-01 11:36:00] Training finished
[2023-07-01 11:36:04] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:36:04] [marian] Running on node20.datos.cluster.uy as process 18160 with command line:
[2023-07-01 11:36:04] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 120 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:36:04] [config] after: 0e
[2023-07-01 11:36:04] [config] after-batches: 0
[2023-07-01 11:36:04] [config] after-epochs: 120
[2023-07-01 11:36:04] [config] all-caps-every: 0
[2023-07-01 11:36:04] [config] allow-unk: false
[2023-07-01 11:36:04] [config] authors: false
[2023-07-01 11:36:04] [config] beam-size: 12
[2023-07-01 11:36:04] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:36:04] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:36:04] [config] bert-masking-fraction: 0.15
[2023-07-01 11:36:04] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:36:04] [config] bert-train-type-embeddings: true
[2023-07-01 11:36:04] [config] bert-type-vocab-size: 2
[2023-07-01 11:36:04] [config] build-info: ""
[2023-07-01 11:36:04] [config] check-gradient-nan: false
[2023-07-01 11:36:04] [config] check-nan: false
[2023-07-01 11:36:04] [config] cite: false
[2023-07-01 11:36:04] [config] clip-norm: 5
[2023-07-01 11:36:04] [config] cost-scaling:
[2023-07-01 11:36:04] [config]   []
[2023-07-01 11:36:04] [config] cost-type: ce-sum
[2023-07-01 11:36:04] [config] cpu-threads: 0
[2023-07-01 11:36:04] [config] data-threads: 8
[2023-07-01 11:36:04] [config] data-weighting: ""
[2023-07-01 11:36:04] [config] data-weighting-type: sentence
[2023-07-01 11:36:04] [config] dec-cell: gru
[2023-07-01 11:36:04] [config] dec-cell-base-depth: 2
[2023-07-01 11:36:04] [config] dec-cell-high-depth: 1
[2023-07-01 11:36:04] [config] dec-depth: 2
[2023-07-01 11:36:04] [config] devices:
[2023-07-01 11:36:04] [config]   - 0
[2023-07-01 11:36:04] [config] dim-emb: 512
[2023-07-01 11:36:04] [config] dim-rnn: 1024
[2023-07-01 11:36:04] [config] dim-vocabs:
[2023-07-01 11:36:04] [config]   - 16384
[2023-07-01 11:36:04] [config]   - 16384
[2023-07-01 11:36:04] [config] disp-first: 0
[2023-07-01 11:36:04] [config] disp-freq: 1000u
[2023-07-01 11:36:04] [config] disp-label-counts: true
[2023-07-01 11:36:04] [config] dropout-rnn: 0
[2023-07-01 11:36:04] [config] dropout-src: 0
[2023-07-01 11:36:04] [config] dropout-trg: 0
[2023-07-01 11:36:04] [config] dump-config: ""
[2023-07-01 11:36:04] [config] dynamic-gradient-scaling:
[2023-07-01 11:36:04] [config]   []
[2023-07-01 11:36:04] [config] early-stopping: 10
[2023-07-01 11:36:04] [config] early-stopping-on: first
[2023-07-01 11:36:04] [config] embedding-fix-src: false
[2023-07-01 11:36:04] [config] embedding-fix-trg: false
[2023-07-01 11:36:04] [config] embedding-normalization: false
[2023-07-01 11:36:04] [config] embedding-vectors:
[2023-07-01 11:36:04] [config]   []
[2023-07-01 11:36:04] [config] enc-cell: gru
[2023-07-01 11:36:04] [config] enc-cell-depth: 1
[2023-07-01 11:36:04] [config] enc-depth: 2
[2023-07-01 11:36:04] [config] enc-type: bidirectional
[2023-07-01 11:36:04] [config] english-title-case-every: 0
[2023-07-01 11:36:04] [config] exponential-smoothing: 0.0001
[2023-07-01 11:36:04] [config] factor-weight: 1
[2023-07-01 11:36:04] [config] factors-combine: sum
[2023-07-01 11:36:04] [config] factors-dim-emb: 0
[2023-07-01 11:36:04] [config] gradient-checkpointing: false
[2023-07-01 11:36:04] [config] gradient-norm-average-window: 100
[2023-07-01 11:36:04] [config] guided-alignment: none
[2023-07-01 11:36:04] [config] guided-alignment-cost: mse
[2023-07-01 11:36:04] [config] guided-alignment-weight: 0.1
[2023-07-01 11:36:04] [config] ignore-model-config: false
[2023-07-01 11:36:04] [config] input-types:
[2023-07-01 11:36:04] [config]   []
[2023-07-01 11:36:04] [config] interpolate-env-vars: false
[2023-07-01 11:36:04] [config] keep-best: false
[2023-07-01 11:36:04] [config] label-smoothing: 0.1
[2023-07-01 11:36:04] [config] layer-normalization: false
[2023-07-01 11:36:04] [config] learn-rate: 0.0003
[2023-07-01 11:36:04] [config] lemma-dependency: ""
[2023-07-01 11:36:04] [config] lemma-dim-emb: 0
[2023-07-01 11:36:04] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:36:04] [config] log-level: info
[2023-07-01 11:36:04] [config] log-time-zone: ""
[2023-07-01 11:36:04] [config] logical-epoch:
[2023-07-01 11:36:04] [config]   - 1e
[2023-07-01 11:36:04] [config]   - 0
[2023-07-01 11:36:04] [config] lr-decay: 0
[2023-07-01 11:36:04] [config] lr-decay-freq: 50000
[2023-07-01 11:36:04] [config] lr-decay-inv-sqrt:
[2023-07-01 11:36:04] [config]   - 16000
[2023-07-01 11:36:04] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:36:04] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:36:04] [config] lr-decay-start:
[2023-07-01 11:36:04] [config]   - 10
[2023-07-01 11:36:04] [config]   - 1
[2023-07-01 11:36:04] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:36:04] [config] lr-report: true
[2023-07-01 11:36:04] [config] lr-warmup: 16000
[2023-07-01 11:36:04] [config] lr-warmup-at-reload: false
[2023-07-01 11:36:04] [config] lr-warmup-cycle: false
[2023-07-01 11:36:04] [config] lr-warmup-start-rate: 0
[2023-07-01 11:36:04] [config] max-length: 100
[2023-07-01 11:36:04] [config] max-length-crop: false
[2023-07-01 11:36:04] [config] max-length-factor: 3
[2023-07-01 11:36:04] [config] maxi-batch: 100
[2023-07-01 11:36:04] [config] maxi-batch-sort: trg
[2023-07-01 11:36:04] [config] mini-batch: 1000
[2023-07-01 11:36:04] [config] mini-batch-fit: true
[2023-07-01 11:36:04] [config] mini-batch-fit-step: 10
[2023-07-01 11:36:04] [config] mini-batch-round-up: true
[2023-07-01 11:36:04] [config] mini-batch-track-lr: false
[2023-07-01 11:36:04] [config] mini-batch-warmup: 0
[2023-07-01 11:36:04] [config] mini-batch-words: 0
[2023-07-01 11:36:04] [config] mini-batch-words-ref: 0
[2023-07-01 11:36:04] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:36:04] [config] multi-loss-type: sum
[2023-07-01 11:36:04] [config] n-best: false
[2023-07-01 11:36:04] [config] no-nccl: false
[2023-07-01 11:36:04] [config] no-reload: false
[2023-07-01 11:36:04] [config] no-restore-corpus: false
[2023-07-01 11:36:04] [config] normalize: 1
[2023-07-01 11:36:04] [config] normalize-gradient: false
[2023-07-01 11:36:04] [config] num-devices: 0
[2023-07-01 11:36:04] [config] optimizer: adam
[2023-07-01 11:36:04] [config] optimizer-delay: 1
[2023-07-01 11:36:04] [config] optimizer-params:
[2023-07-01 11:36:04] [config]   - 0.9
[2023-07-01 11:36:04] [config]   - 0.98
[2023-07-01 11:36:04] [config]   - 1e-09
[2023-07-01 11:36:04] [config] output-omit-bias: false
[2023-07-01 11:36:04] [config] overwrite: true
[2023-07-01 11:36:04] [config] precision:
[2023-07-01 11:36:04] [config]   - float32
[2023-07-01 11:36:04] [config]   - float32
[2023-07-01 11:36:04] [config] pretrained-model: ""
[2023-07-01 11:36:04] [config] quantize-biases: false
[2023-07-01 11:36:04] [config] quantize-bits: 0
[2023-07-01 11:36:04] [config] quantize-log-based: false
[2023-07-01 11:36:04] [config] quantize-optimization-steps: 0
[2023-07-01 11:36:04] [config] quiet: false
[2023-07-01 11:36:04] [config] quiet-translation: true
[2023-07-01 11:36:04] [config] relative-paths: false
[2023-07-01 11:36:04] [config] right-left: false
[2023-07-01 11:36:04] [config] save-freq: 10000u
[2023-07-01 11:36:04] [config] seed: 1234
[2023-07-01 11:36:04] [config] sentencepiece-alphas:
[2023-07-01 11:36:04] [config]   []
[2023-07-01 11:36:04] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:36:04] [config] sentencepiece-options: ""
[2023-07-01 11:36:04] [config] sharding: global
[2023-07-01 11:36:04] [config] shuffle: data
[2023-07-01 11:36:04] [config] shuffle-in-ram: false
[2023-07-01 11:36:04] [config] sigterm: save-and-exit
[2023-07-01 11:36:04] [config] skip: false
[2023-07-01 11:36:04] [config] sqlite: ""
[2023-07-01 11:36:04] [config] sqlite-drop: false
[2023-07-01 11:36:04] [config] sync-freq: 200u
[2023-07-01 11:36:04] [config] sync-sgd: true
[2023-07-01 11:36:04] [config] tempdir: /tmp
[2023-07-01 11:36:04] [config] tied-embeddings: false
[2023-07-01 11:36:04] [config] tied-embeddings-all: true
[2023-07-01 11:36:04] [config] tied-embeddings-src: false
[2023-07-01 11:36:04] [config] train-embedder-rank:
[2023-07-01 11:36:04] [config]   []
[2023-07-01 11:36:04] [config] train-sets:
[2023-07-01 11:36:04] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:36:04] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:36:04] [config] transformer-aan-activation: swish
[2023-07-01 11:36:04] [config] transformer-aan-depth: 2
[2023-07-01 11:36:04] [config] transformer-aan-nogate: false
[2023-07-01 11:36:04] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:36:04] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:36:04] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:36:04] [config] transformer-depth-scaling: false
[2023-07-01 11:36:04] [config] transformer-dim-aan: 2048
[2023-07-01 11:36:04] [config] transformer-dim-ffn: 2048
[2023-07-01 11:36:04] [config] transformer-dropout: 0.1
[2023-07-01 11:36:04] [config] transformer-dropout-attention: 0
[2023-07-01 11:36:04] [config] transformer-dropout-ffn: 0
[2023-07-01 11:36:04] [config] transformer-ffn-activation: swish
[2023-07-01 11:36:04] [config] transformer-ffn-depth: 2
[2023-07-01 11:36:04] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:36:04] [config] transformer-heads: 8
[2023-07-01 11:36:04] [config] transformer-no-projection: false
[2023-07-01 11:36:04] [config] transformer-pool: false
[2023-07-01 11:36:04] [config] transformer-postprocess: dan
[2023-07-01 11:36:04] [config] transformer-postprocess-emb: d
[2023-07-01 11:36:04] [config] transformer-postprocess-top: ""
[2023-07-01 11:36:04] [config] transformer-preprocess: ""
[2023-07-01 11:36:04] [config] transformer-tied-layers:
[2023-07-01 11:36:04] [config]   []
[2023-07-01 11:36:04] [config] transformer-train-position-embeddings: false
[2023-07-01 11:36:04] [config] tsv: false
[2023-07-01 11:36:04] [config] tsv-fields: 0
[2023-07-01 11:36:04] [config] type: transformer
[2023-07-01 11:36:04] [config] ulr: false
[2023-07-01 11:36:04] [config] ulr-dim-emb: 0
[2023-07-01 11:36:04] [config] ulr-dropout: 0
[2023-07-01 11:36:04] [config] ulr-keys-vectors: ""
[2023-07-01 11:36:04] [config] ulr-query-vectors: ""
[2023-07-01 11:36:04] [config] ulr-softmax-temperature: 1
[2023-07-01 11:36:04] [config] ulr-trainable-transformation: false
[2023-07-01 11:36:04] [config] unlikelihood-loss: false
[2023-07-01 11:36:04] [config] valid-freq: 50000000
[2023-07-01 11:36:04] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:36:04] [config] valid-max-length: 1000
[2023-07-01 11:36:04] [config] valid-metrics:
[2023-07-01 11:36:04] [config]   - cross-entropy
[2023-07-01 11:36:04] [config]   - translation
[2023-07-01 11:36:04] [config] valid-mini-batch: 64
[2023-07-01 11:36:04] [config] valid-reset-stalled: false
[2023-07-01 11:36:04] [config] valid-script-args:
[2023-07-01 11:36:04] [config]   []
[2023-07-01 11:36:04] [config] valid-script-path: ""
[2023-07-01 11:36:04] [config] valid-sets:
[2023-07-01 11:36:04] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:36:04] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:36:04] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:36:04] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:36:04] [config] vocabs:
[2023-07-01 11:36:04] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:36:04] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:36:04] [config] word-penalty: 0
[2023-07-01 11:36:04] [config] word-scores: false
[2023-07-01 11:36:04] [config] workspace: 2048
[2023-07-01 11:36:04] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:36:04] Using synchronous SGD
[2023-07-01 11:36:04] Synced seed 1234
[2023-07-01 11:36:04] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:36:04] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:36:04] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:36:04] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:36:04] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:36:04] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:36:05] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:36:05] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:36:05] [comm] Using global sharding
[2023-07-01 11:36:05] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:36:05] [training] Using 1 GPUs
[2023-07-01 11:36:05] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:36:05] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:36:05] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:36:05] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:36:13] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:36:13] [valid] No post-processing script given for validating translator
[2023-07-01 11:36:13] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:36:13] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:36:13] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:36:13] [comm] Using global sharding
[2023-07-01 11:36:13] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:36:13] [training] Using 1 GPUs
[2023-07-01 11:36:13] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:36:13] Allocating memory for general optimizer shards
[2023-07-01 11:36:13] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:36:13] Loading Adam parameters
[2023-07-01 11:36:13] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:36:14] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:36:14] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:36:14] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:36:14] [data] Shuffling data
[2023-07-01 11:36:14] [data] Done reading 20,192 sentences
[2023-07-01 11:36:14] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:36:14] Training started
[2023-07-01 11:36:14] Training finished
[2023-07-01 11:36:17] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:36:17] [marian] Running on node20.datos.cluster.uy as process 18218 with command line:
[2023-07-01 11:36:17] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 121 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:36:17] [config] after: 0e
[2023-07-01 11:36:17] [config] after-batches: 0
[2023-07-01 11:36:17] [config] after-epochs: 121
[2023-07-01 11:36:17] [config] all-caps-every: 0
[2023-07-01 11:36:17] [config] allow-unk: false
[2023-07-01 11:36:17] [config] authors: false
[2023-07-01 11:36:17] [config] beam-size: 12
[2023-07-01 11:36:17] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:36:17] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:36:17] [config] bert-masking-fraction: 0.15
[2023-07-01 11:36:17] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:36:17] [config] bert-train-type-embeddings: true
[2023-07-01 11:36:17] [config] bert-type-vocab-size: 2
[2023-07-01 11:36:17] [config] build-info: ""
[2023-07-01 11:36:17] [config] check-gradient-nan: false
[2023-07-01 11:36:17] [config] check-nan: false
[2023-07-01 11:36:17] [config] cite: false
[2023-07-01 11:36:17] [config] clip-norm: 5
[2023-07-01 11:36:17] [config] cost-scaling:
[2023-07-01 11:36:17] [config]   []
[2023-07-01 11:36:17] [config] cost-type: ce-sum
[2023-07-01 11:36:17] [config] cpu-threads: 0
[2023-07-01 11:36:17] [config] data-threads: 8
[2023-07-01 11:36:17] [config] data-weighting: ""
[2023-07-01 11:36:17] [config] data-weighting-type: sentence
[2023-07-01 11:36:17] [config] dec-cell: gru
[2023-07-01 11:36:17] [config] dec-cell-base-depth: 2
[2023-07-01 11:36:17] [config] dec-cell-high-depth: 1
[2023-07-01 11:36:17] [config] dec-depth: 2
[2023-07-01 11:36:17] [config] devices:
[2023-07-01 11:36:17] [config]   - 0
[2023-07-01 11:36:17] [config] dim-emb: 512
[2023-07-01 11:36:17] [config] dim-rnn: 1024
[2023-07-01 11:36:17] [config] dim-vocabs:
[2023-07-01 11:36:17] [config]   - 16384
[2023-07-01 11:36:17] [config]   - 16384
[2023-07-01 11:36:17] [config] disp-first: 0
[2023-07-01 11:36:17] [config] disp-freq: 1000u
[2023-07-01 11:36:17] [config] disp-label-counts: true
[2023-07-01 11:36:17] [config] dropout-rnn: 0
[2023-07-01 11:36:17] [config] dropout-src: 0
[2023-07-01 11:36:17] [config] dropout-trg: 0
[2023-07-01 11:36:17] [config] dump-config: ""
[2023-07-01 11:36:17] [config] dynamic-gradient-scaling:
[2023-07-01 11:36:17] [config]   []
[2023-07-01 11:36:17] [config] early-stopping: 10
[2023-07-01 11:36:17] [config] early-stopping-on: first
[2023-07-01 11:36:17] [config] embedding-fix-src: false
[2023-07-01 11:36:17] [config] embedding-fix-trg: false
[2023-07-01 11:36:17] [config] embedding-normalization: false
[2023-07-01 11:36:17] [config] embedding-vectors:
[2023-07-01 11:36:17] [config]   []
[2023-07-01 11:36:17] [config] enc-cell: gru
[2023-07-01 11:36:17] [config] enc-cell-depth: 1
[2023-07-01 11:36:17] [config] enc-depth: 2
[2023-07-01 11:36:17] [config] enc-type: bidirectional
[2023-07-01 11:36:17] [config] english-title-case-every: 0
[2023-07-01 11:36:17] [config] exponential-smoothing: 0.0001
[2023-07-01 11:36:17] [config] factor-weight: 1
[2023-07-01 11:36:17] [config] factors-combine: sum
[2023-07-01 11:36:17] [config] factors-dim-emb: 0
[2023-07-01 11:36:17] [config] gradient-checkpointing: false
[2023-07-01 11:36:17] [config] gradient-norm-average-window: 100
[2023-07-01 11:36:17] [config] guided-alignment: none
[2023-07-01 11:36:17] [config] guided-alignment-cost: mse
[2023-07-01 11:36:17] [config] guided-alignment-weight: 0.1
[2023-07-01 11:36:17] [config] ignore-model-config: false
[2023-07-01 11:36:17] [config] input-types:
[2023-07-01 11:36:17] [config]   []
[2023-07-01 11:36:17] [config] interpolate-env-vars: false
[2023-07-01 11:36:17] [config] keep-best: false
[2023-07-01 11:36:17] [config] label-smoothing: 0.1
[2023-07-01 11:36:17] [config] layer-normalization: false
[2023-07-01 11:36:17] [config] learn-rate: 0.0003
[2023-07-01 11:36:17] [config] lemma-dependency: ""
[2023-07-01 11:36:17] [config] lemma-dim-emb: 0
[2023-07-01 11:36:17] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:36:17] [config] log-level: info
[2023-07-01 11:36:17] [config] log-time-zone: ""
[2023-07-01 11:36:17] [config] logical-epoch:
[2023-07-01 11:36:17] [config]   - 1e
[2023-07-01 11:36:17] [config]   - 0
[2023-07-01 11:36:17] [config] lr-decay: 0
[2023-07-01 11:36:17] [config] lr-decay-freq: 50000
[2023-07-01 11:36:17] [config] lr-decay-inv-sqrt:
[2023-07-01 11:36:17] [config]   - 16000
[2023-07-01 11:36:17] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:36:17] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:36:17] [config] lr-decay-start:
[2023-07-01 11:36:17] [config]   - 10
[2023-07-01 11:36:17] [config]   - 1
[2023-07-01 11:36:17] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:36:17] [config] lr-report: true
[2023-07-01 11:36:17] [config] lr-warmup: 16000
[2023-07-01 11:36:17] [config] lr-warmup-at-reload: false
[2023-07-01 11:36:17] [config] lr-warmup-cycle: false
[2023-07-01 11:36:17] [config] lr-warmup-start-rate: 0
[2023-07-01 11:36:17] [config] max-length: 100
[2023-07-01 11:36:17] [config] max-length-crop: false
[2023-07-01 11:36:17] [config] max-length-factor: 3
[2023-07-01 11:36:17] [config] maxi-batch: 100
[2023-07-01 11:36:17] [config] maxi-batch-sort: trg
[2023-07-01 11:36:17] [config] mini-batch: 1000
[2023-07-01 11:36:17] [config] mini-batch-fit: true
[2023-07-01 11:36:17] [config] mini-batch-fit-step: 10
[2023-07-01 11:36:17] [config] mini-batch-round-up: true
[2023-07-01 11:36:17] [config] mini-batch-track-lr: false
[2023-07-01 11:36:17] [config] mini-batch-warmup: 0
[2023-07-01 11:36:17] [config] mini-batch-words: 0
[2023-07-01 11:36:17] [config] mini-batch-words-ref: 0
[2023-07-01 11:36:17] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:36:17] [config] multi-loss-type: sum
[2023-07-01 11:36:17] [config] n-best: false
[2023-07-01 11:36:17] [config] no-nccl: false
[2023-07-01 11:36:17] [config] no-reload: false
[2023-07-01 11:36:17] [config] no-restore-corpus: false
[2023-07-01 11:36:17] [config] normalize: 1
[2023-07-01 11:36:17] [config] normalize-gradient: false
[2023-07-01 11:36:17] [config] num-devices: 0
[2023-07-01 11:36:17] [config] optimizer: adam
[2023-07-01 11:36:17] [config] optimizer-delay: 1
[2023-07-01 11:36:17] [config] optimizer-params:
[2023-07-01 11:36:17] [config]   - 0.9
[2023-07-01 11:36:17] [config]   - 0.98
[2023-07-01 11:36:17] [config]   - 1e-09
[2023-07-01 11:36:17] [config] output-omit-bias: false
[2023-07-01 11:36:17] [config] overwrite: true
[2023-07-01 11:36:17] [config] precision:
[2023-07-01 11:36:17] [config]   - float32
[2023-07-01 11:36:17] [config]   - float32
[2023-07-01 11:36:17] [config] pretrained-model: ""
[2023-07-01 11:36:17] [config] quantize-biases: false
[2023-07-01 11:36:17] [config] quantize-bits: 0
[2023-07-01 11:36:17] [config] quantize-log-based: false
[2023-07-01 11:36:17] [config] quantize-optimization-steps: 0
[2023-07-01 11:36:17] [config] quiet: false
[2023-07-01 11:36:17] [config] quiet-translation: true
[2023-07-01 11:36:17] [config] relative-paths: false
[2023-07-01 11:36:17] [config] right-left: false
[2023-07-01 11:36:17] [config] save-freq: 10000u
[2023-07-01 11:36:17] [config] seed: 1234
[2023-07-01 11:36:17] [config] sentencepiece-alphas:
[2023-07-01 11:36:17] [config]   []
[2023-07-01 11:36:17] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:36:17] [config] sentencepiece-options: ""
[2023-07-01 11:36:17] [config] sharding: global
[2023-07-01 11:36:17] [config] shuffle: data
[2023-07-01 11:36:17] [config] shuffle-in-ram: false
[2023-07-01 11:36:17] [config] sigterm: save-and-exit
[2023-07-01 11:36:17] [config] skip: false
[2023-07-01 11:36:17] [config] sqlite: ""
[2023-07-01 11:36:17] [config] sqlite-drop: false
[2023-07-01 11:36:17] [config] sync-freq: 200u
[2023-07-01 11:36:17] [config] sync-sgd: true
[2023-07-01 11:36:17] [config] tempdir: /tmp
[2023-07-01 11:36:17] [config] tied-embeddings: false
[2023-07-01 11:36:17] [config] tied-embeddings-all: true
[2023-07-01 11:36:17] [config] tied-embeddings-src: false
[2023-07-01 11:36:17] [config] train-embedder-rank:
[2023-07-01 11:36:17] [config]   []
[2023-07-01 11:36:17] [config] train-sets:
[2023-07-01 11:36:17] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:36:17] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:36:17] [config] transformer-aan-activation: swish
[2023-07-01 11:36:17] [config] transformer-aan-depth: 2
[2023-07-01 11:36:17] [config] transformer-aan-nogate: false
[2023-07-01 11:36:17] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:36:17] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:36:17] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:36:17] [config] transformer-depth-scaling: false
[2023-07-01 11:36:17] [config] transformer-dim-aan: 2048
[2023-07-01 11:36:17] [config] transformer-dim-ffn: 2048
[2023-07-01 11:36:17] [config] transformer-dropout: 0.1
[2023-07-01 11:36:17] [config] transformer-dropout-attention: 0
[2023-07-01 11:36:17] [config] transformer-dropout-ffn: 0
[2023-07-01 11:36:17] [config] transformer-ffn-activation: swish
[2023-07-01 11:36:17] [config] transformer-ffn-depth: 2
[2023-07-01 11:36:17] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:36:17] [config] transformer-heads: 8
[2023-07-01 11:36:17] [config] transformer-no-projection: false
[2023-07-01 11:36:17] [config] transformer-pool: false
[2023-07-01 11:36:17] [config] transformer-postprocess: dan
[2023-07-01 11:36:17] [config] transformer-postprocess-emb: d
[2023-07-01 11:36:17] [config] transformer-postprocess-top: ""
[2023-07-01 11:36:17] [config] transformer-preprocess: ""
[2023-07-01 11:36:17] [config] transformer-tied-layers:
[2023-07-01 11:36:17] [config]   []
[2023-07-01 11:36:17] [config] transformer-train-position-embeddings: false
[2023-07-01 11:36:17] [config] tsv: false
[2023-07-01 11:36:17] [config] tsv-fields: 0
[2023-07-01 11:36:17] [config] type: transformer
[2023-07-01 11:36:17] [config] ulr: false
[2023-07-01 11:36:17] [config] ulr-dim-emb: 0
[2023-07-01 11:36:17] [config] ulr-dropout: 0
[2023-07-01 11:36:17] [config] ulr-keys-vectors: ""
[2023-07-01 11:36:17] [config] ulr-query-vectors: ""
[2023-07-01 11:36:17] [config] ulr-softmax-temperature: 1
[2023-07-01 11:36:17] [config] ulr-trainable-transformation: false
[2023-07-01 11:36:17] [config] unlikelihood-loss: false
[2023-07-01 11:36:17] [config] valid-freq: 50000000
[2023-07-01 11:36:17] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:36:17] [config] valid-max-length: 1000
[2023-07-01 11:36:17] [config] valid-metrics:
[2023-07-01 11:36:17] [config]   - cross-entropy
[2023-07-01 11:36:17] [config]   - translation
[2023-07-01 11:36:17] [config] valid-mini-batch: 64
[2023-07-01 11:36:17] [config] valid-reset-stalled: false
[2023-07-01 11:36:17] [config] valid-script-args:
[2023-07-01 11:36:17] [config]   []
[2023-07-01 11:36:17] [config] valid-script-path: ""
[2023-07-01 11:36:17] [config] valid-sets:
[2023-07-01 11:36:17] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:36:17] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:36:17] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:36:17] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:36:17] [config] vocabs:
[2023-07-01 11:36:17] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:36:17] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:36:17] [config] word-penalty: 0
[2023-07-01 11:36:17] [config] word-scores: false
[2023-07-01 11:36:17] [config] workspace: 2048
[2023-07-01 11:36:17] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:36:17] Using synchronous SGD
[2023-07-01 11:36:17] Synced seed 1234
[2023-07-01 11:36:17] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:36:18] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:36:18] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:36:18] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:36:18] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:36:18] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:36:18] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:36:18] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:36:18] [comm] Using global sharding
[2023-07-01 11:36:18] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:36:18] [training] Using 1 GPUs
[2023-07-01 11:36:18] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:36:18] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:36:19] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:36:19] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:36:26] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:36:26] [valid] No post-processing script given for validating translator
[2023-07-01 11:36:26] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:36:26] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:36:26] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:36:26] [comm] Using global sharding
[2023-07-01 11:36:26] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:36:26] [training] Using 1 GPUs
[2023-07-01 11:36:26] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:36:27] Allocating memory for general optimizer shards
[2023-07-01 11:36:27] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:36:27] Loading Adam parameters
[2023-07-01 11:36:27] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:36:27] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:36:27] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:36:27] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:36:27] [data] Shuffling data
[2023-07-01 11:36:27] [data] Done reading 20,192 sentences
[2023-07-01 11:36:27] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:36:27] Training started
[2023-07-01 11:36:27] Training finished
[2023-07-01 11:36:31] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:36:31] [marian] Running on node20.datos.cluster.uy as process 18276 with command line:
[2023-07-01 11:36:31] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 122 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:36:31] [config] after: 0e
[2023-07-01 11:36:31] [config] after-batches: 0
[2023-07-01 11:36:31] [config] after-epochs: 122
[2023-07-01 11:36:31] [config] all-caps-every: 0
[2023-07-01 11:36:31] [config] allow-unk: false
[2023-07-01 11:36:31] [config] authors: false
[2023-07-01 11:36:31] [config] beam-size: 12
[2023-07-01 11:36:31] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:36:31] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:36:31] [config] bert-masking-fraction: 0.15
[2023-07-01 11:36:31] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:36:31] [config] bert-train-type-embeddings: true
[2023-07-01 11:36:31] [config] bert-type-vocab-size: 2
[2023-07-01 11:36:31] [config] build-info: ""
[2023-07-01 11:36:31] [config] check-gradient-nan: false
[2023-07-01 11:36:31] [config] check-nan: false
[2023-07-01 11:36:31] [config] cite: false
[2023-07-01 11:36:31] [config] clip-norm: 5
[2023-07-01 11:36:31] [config] cost-scaling:
[2023-07-01 11:36:31] [config]   []
[2023-07-01 11:36:31] [config] cost-type: ce-sum
[2023-07-01 11:36:31] [config] cpu-threads: 0
[2023-07-01 11:36:31] [config] data-threads: 8
[2023-07-01 11:36:31] [config] data-weighting: ""
[2023-07-01 11:36:31] [config] data-weighting-type: sentence
[2023-07-01 11:36:31] [config] dec-cell: gru
[2023-07-01 11:36:31] [config] dec-cell-base-depth: 2
[2023-07-01 11:36:31] [config] dec-cell-high-depth: 1
[2023-07-01 11:36:31] [config] dec-depth: 2
[2023-07-01 11:36:31] [config] devices:
[2023-07-01 11:36:31] [config]   - 0
[2023-07-01 11:36:31] [config] dim-emb: 512
[2023-07-01 11:36:31] [config] dim-rnn: 1024
[2023-07-01 11:36:31] [config] dim-vocabs:
[2023-07-01 11:36:31] [config]   - 16384
[2023-07-01 11:36:31] [config]   - 16384
[2023-07-01 11:36:31] [config] disp-first: 0
[2023-07-01 11:36:31] [config] disp-freq: 1000u
[2023-07-01 11:36:31] [config] disp-label-counts: true
[2023-07-01 11:36:31] [config] dropout-rnn: 0
[2023-07-01 11:36:31] [config] dropout-src: 0
[2023-07-01 11:36:31] [config] dropout-trg: 0
[2023-07-01 11:36:31] [config] dump-config: ""
[2023-07-01 11:36:31] [config] dynamic-gradient-scaling:
[2023-07-01 11:36:31] [config]   []
[2023-07-01 11:36:31] [config] early-stopping: 10
[2023-07-01 11:36:31] [config] early-stopping-on: first
[2023-07-01 11:36:31] [config] embedding-fix-src: false
[2023-07-01 11:36:31] [config] embedding-fix-trg: false
[2023-07-01 11:36:31] [config] embedding-normalization: false
[2023-07-01 11:36:31] [config] embedding-vectors:
[2023-07-01 11:36:31] [config]   []
[2023-07-01 11:36:31] [config] enc-cell: gru
[2023-07-01 11:36:31] [config] enc-cell-depth: 1
[2023-07-01 11:36:31] [config] enc-depth: 2
[2023-07-01 11:36:31] [config] enc-type: bidirectional
[2023-07-01 11:36:31] [config] english-title-case-every: 0
[2023-07-01 11:36:31] [config] exponential-smoothing: 0.0001
[2023-07-01 11:36:31] [config] factor-weight: 1
[2023-07-01 11:36:31] [config] factors-combine: sum
[2023-07-01 11:36:31] [config] factors-dim-emb: 0
[2023-07-01 11:36:31] [config] gradient-checkpointing: false
[2023-07-01 11:36:31] [config] gradient-norm-average-window: 100
[2023-07-01 11:36:31] [config] guided-alignment: none
[2023-07-01 11:36:31] [config] guided-alignment-cost: mse
[2023-07-01 11:36:31] [config] guided-alignment-weight: 0.1
[2023-07-01 11:36:31] [config] ignore-model-config: false
[2023-07-01 11:36:31] [config] input-types:
[2023-07-01 11:36:31] [config]   []
[2023-07-01 11:36:31] [config] interpolate-env-vars: false
[2023-07-01 11:36:31] [config] keep-best: false
[2023-07-01 11:36:31] [config] label-smoothing: 0.1
[2023-07-01 11:36:31] [config] layer-normalization: false
[2023-07-01 11:36:31] [config] learn-rate: 0.0003
[2023-07-01 11:36:31] [config] lemma-dependency: ""
[2023-07-01 11:36:31] [config] lemma-dim-emb: 0
[2023-07-01 11:36:31] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:36:31] [config] log-level: info
[2023-07-01 11:36:31] [config] log-time-zone: ""
[2023-07-01 11:36:31] [config] logical-epoch:
[2023-07-01 11:36:31] [config]   - 1e
[2023-07-01 11:36:31] [config]   - 0
[2023-07-01 11:36:31] [config] lr-decay: 0
[2023-07-01 11:36:31] [config] lr-decay-freq: 50000
[2023-07-01 11:36:31] [config] lr-decay-inv-sqrt:
[2023-07-01 11:36:31] [config]   - 16000
[2023-07-01 11:36:31] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:36:31] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:36:31] [config] lr-decay-start:
[2023-07-01 11:36:31] [config]   - 10
[2023-07-01 11:36:31] [config]   - 1
[2023-07-01 11:36:31] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:36:31] [config] lr-report: true
[2023-07-01 11:36:31] [config] lr-warmup: 16000
[2023-07-01 11:36:31] [config] lr-warmup-at-reload: false
[2023-07-01 11:36:31] [config] lr-warmup-cycle: false
[2023-07-01 11:36:31] [config] lr-warmup-start-rate: 0
[2023-07-01 11:36:31] [config] max-length: 100
[2023-07-01 11:36:31] [config] max-length-crop: false
[2023-07-01 11:36:31] [config] max-length-factor: 3
[2023-07-01 11:36:31] [config] maxi-batch: 100
[2023-07-01 11:36:31] [config] maxi-batch-sort: trg
[2023-07-01 11:36:31] [config] mini-batch: 1000
[2023-07-01 11:36:31] [config] mini-batch-fit: true
[2023-07-01 11:36:31] [config] mini-batch-fit-step: 10
[2023-07-01 11:36:31] [config] mini-batch-round-up: true
[2023-07-01 11:36:31] [config] mini-batch-track-lr: false
[2023-07-01 11:36:31] [config] mini-batch-warmup: 0
[2023-07-01 11:36:31] [config] mini-batch-words: 0
[2023-07-01 11:36:31] [config] mini-batch-words-ref: 0
[2023-07-01 11:36:31] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:36:31] [config] multi-loss-type: sum
[2023-07-01 11:36:31] [config] n-best: false
[2023-07-01 11:36:31] [config] no-nccl: false
[2023-07-01 11:36:31] [config] no-reload: false
[2023-07-01 11:36:31] [config] no-restore-corpus: false
[2023-07-01 11:36:31] [config] normalize: 1
[2023-07-01 11:36:31] [config] normalize-gradient: false
[2023-07-01 11:36:31] [config] num-devices: 0
[2023-07-01 11:36:31] [config] optimizer: adam
[2023-07-01 11:36:31] [config] optimizer-delay: 1
[2023-07-01 11:36:31] [config] optimizer-params:
[2023-07-01 11:36:31] [config]   - 0.9
[2023-07-01 11:36:31] [config]   - 0.98
[2023-07-01 11:36:31] [config]   - 1e-09
[2023-07-01 11:36:31] [config] output-omit-bias: false
[2023-07-01 11:36:31] [config] overwrite: true
[2023-07-01 11:36:31] [config] precision:
[2023-07-01 11:36:31] [config]   - float32
[2023-07-01 11:36:31] [config]   - float32
[2023-07-01 11:36:31] [config] pretrained-model: ""
[2023-07-01 11:36:31] [config] quantize-biases: false
[2023-07-01 11:36:31] [config] quantize-bits: 0
[2023-07-01 11:36:31] [config] quantize-log-based: false
[2023-07-01 11:36:31] [config] quantize-optimization-steps: 0
[2023-07-01 11:36:31] [config] quiet: false
[2023-07-01 11:36:31] [config] quiet-translation: true
[2023-07-01 11:36:31] [config] relative-paths: false
[2023-07-01 11:36:31] [config] right-left: false
[2023-07-01 11:36:31] [config] save-freq: 10000u
[2023-07-01 11:36:31] [config] seed: 1234
[2023-07-01 11:36:31] [config] sentencepiece-alphas:
[2023-07-01 11:36:31] [config]   []
[2023-07-01 11:36:31] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:36:31] [config] sentencepiece-options: ""
[2023-07-01 11:36:31] [config] sharding: global
[2023-07-01 11:36:31] [config] shuffle: data
[2023-07-01 11:36:31] [config] shuffle-in-ram: false
[2023-07-01 11:36:31] [config] sigterm: save-and-exit
[2023-07-01 11:36:31] [config] skip: false
[2023-07-01 11:36:31] [config] sqlite: ""
[2023-07-01 11:36:31] [config] sqlite-drop: false
[2023-07-01 11:36:31] [config] sync-freq: 200u
[2023-07-01 11:36:31] [config] sync-sgd: true
[2023-07-01 11:36:31] [config] tempdir: /tmp
[2023-07-01 11:36:31] [config] tied-embeddings: false
[2023-07-01 11:36:31] [config] tied-embeddings-all: true
[2023-07-01 11:36:31] [config] tied-embeddings-src: false
[2023-07-01 11:36:31] [config] train-embedder-rank:
[2023-07-01 11:36:31] [config]   []
[2023-07-01 11:36:31] [config] train-sets:
[2023-07-01 11:36:31] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:36:31] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:36:31] [config] transformer-aan-activation: swish
[2023-07-01 11:36:31] [config] transformer-aan-depth: 2
[2023-07-01 11:36:31] [config] transformer-aan-nogate: false
[2023-07-01 11:36:31] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:36:31] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:36:31] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:36:31] [config] transformer-depth-scaling: false
[2023-07-01 11:36:31] [config] transformer-dim-aan: 2048
[2023-07-01 11:36:31] [config] transformer-dim-ffn: 2048
[2023-07-01 11:36:31] [config] transformer-dropout: 0.1
[2023-07-01 11:36:31] [config] transformer-dropout-attention: 0
[2023-07-01 11:36:31] [config] transformer-dropout-ffn: 0
[2023-07-01 11:36:31] [config] transformer-ffn-activation: swish
[2023-07-01 11:36:31] [config] transformer-ffn-depth: 2
[2023-07-01 11:36:31] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:36:31] [config] transformer-heads: 8
[2023-07-01 11:36:31] [config] transformer-no-projection: false
[2023-07-01 11:36:31] [config] transformer-pool: false
[2023-07-01 11:36:31] [config] transformer-postprocess: dan
[2023-07-01 11:36:31] [config] transformer-postprocess-emb: d
[2023-07-01 11:36:31] [config] transformer-postprocess-top: ""
[2023-07-01 11:36:31] [config] transformer-preprocess: ""
[2023-07-01 11:36:31] [config] transformer-tied-layers:
[2023-07-01 11:36:31] [config]   []
[2023-07-01 11:36:31] [config] transformer-train-position-embeddings: false
[2023-07-01 11:36:31] [config] tsv: false
[2023-07-01 11:36:31] [config] tsv-fields: 0
[2023-07-01 11:36:31] [config] type: transformer
[2023-07-01 11:36:31] [config] ulr: false
[2023-07-01 11:36:31] [config] ulr-dim-emb: 0
[2023-07-01 11:36:31] [config] ulr-dropout: 0
[2023-07-01 11:36:31] [config] ulr-keys-vectors: ""
[2023-07-01 11:36:31] [config] ulr-query-vectors: ""
[2023-07-01 11:36:31] [config] ulr-softmax-temperature: 1
[2023-07-01 11:36:31] [config] ulr-trainable-transformation: false
[2023-07-01 11:36:31] [config] unlikelihood-loss: false
[2023-07-01 11:36:31] [config] valid-freq: 50000000
[2023-07-01 11:36:31] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:36:31] [config] valid-max-length: 1000
[2023-07-01 11:36:31] [config] valid-metrics:
[2023-07-01 11:36:31] [config]   - cross-entropy
[2023-07-01 11:36:31] [config]   - translation
[2023-07-01 11:36:31] [config] valid-mini-batch: 64
[2023-07-01 11:36:31] [config] valid-reset-stalled: false
[2023-07-01 11:36:31] [config] valid-script-args:
[2023-07-01 11:36:31] [config]   []
[2023-07-01 11:36:31] [config] valid-script-path: ""
[2023-07-01 11:36:31] [config] valid-sets:
[2023-07-01 11:36:31] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:36:31] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:36:31] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:36:31] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:36:31] [config] vocabs:
[2023-07-01 11:36:31] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:36:31] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:36:31] [config] word-penalty: 0
[2023-07-01 11:36:31] [config] word-scores: false
[2023-07-01 11:36:31] [config] workspace: 2048
[2023-07-01 11:36:31] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:36:31] Using synchronous SGD
[2023-07-01 11:36:31] Synced seed 1234
[2023-07-01 11:36:31] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:36:31] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:36:31] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:36:31] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:36:31] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:36:31] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:36:32] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:36:32] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:36:32] [comm] Using global sharding
[2023-07-01 11:36:32] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:36:32] [training] Using 1 GPUs
[2023-07-01 11:36:32] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:36:32] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:36:32] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:36:33] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:36:40] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:36:40] [valid] No post-processing script given for validating translator
[2023-07-01 11:36:40] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:36:40] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:36:40] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:36:40] [comm] Using global sharding
[2023-07-01 11:36:40] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:36:40] [training] Using 1 GPUs
[2023-07-01 11:36:40] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:36:41] Allocating memory for general optimizer shards
[2023-07-01 11:36:41] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:36:41] Loading Adam parameters
[2023-07-01 11:36:41] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:36:41] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:36:41] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:36:41] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:36:41] [data] Shuffling data
[2023-07-01 11:36:41] [data] Done reading 20,192 sentences
[2023-07-01 11:36:41] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:36:41] Training started
[2023-07-01 11:36:41] Training finished
[2023-07-01 11:36:44] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:36:44] [marian] Running on node20.datos.cluster.uy as process 18334 with command line:
[2023-07-01 11:36:44] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 123 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:36:44] [config] after: 0e
[2023-07-01 11:36:44] [config] after-batches: 0
[2023-07-01 11:36:44] [config] after-epochs: 123
[2023-07-01 11:36:44] [config] all-caps-every: 0
[2023-07-01 11:36:44] [config] allow-unk: false
[2023-07-01 11:36:44] [config] authors: false
[2023-07-01 11:36:44] [config] beam-size: 12
[2023-07-01 11:36:44] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:36:44] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:36:44] [config] bert-masking-fraction: 0.15
[2023-07-01 11:36:44] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:36:44] [config] bert-train-type-embeddings: true
[2023-07-01 11:36:44] [config] bert-type-vocab-size: 2
[2023-07-01 11:36:44] [config] build-info: ""
[2023-07-01 11:36:44] [config] check-gradient-nan: false
[2023-07-01 11:36:44] [config] check-nan: false
[2023-07-01 11:36:44] [config] cite: false
[2023-07-01 11:36:44] [config] clip-norm: 5
[2023-07-01 11:36:44] [config] cost-scaling:
[2023-07-01 11:36:44] [config]   []
[2023-07-01 11:36:44] [config] cost-type: ce-sum
[2023-07-01 11:36:44] [config] cpu-threads: 0
[2023-07-01 11:36:44] [config] data-threads: 8
[2023-07-01 11:36:44] [config] data-weighting: ""
[2023-07-01 11:36:44] [config] data-weighting-type: sentence
[2023-07-01 11:36:44] [config] dec-cell: gru
[2023-07-01 11:36:44] [config] dec-cell-base-depth: 2
[2023-07-01 11:36:44] [config] dec-cell-high-depth: 1
[2023-07-01 11:36:44] [config] dec-depth: 2
[2023-07-01 11:36:44] [config] devices:
[2023-07-01 11:36:44] [config]   - 0
[2023-07-01 11:36:44] [config] dim-emb: 512
[2023-07-01 11:36:44] [config] dim-rnn: 1024
[2023-07-01 11:36:44] [config] dim-vocabs:
[2023-07-01 11:36:44] [config]   - 16384
[2023-07-01 11:36:44] [config]   - 16384
[2023-07-01 11:36:44] [config] disp-first: 0
[2023-07-01 11:36:44] [config] disp-freq: 1000u
[2023-07-01 11:36:44] [config] disp-label-counts: true
[2023-07-01 11:36:44] [config] dropout-rnn: 0
[2023-07-01 11:36:44] [config] dropout-src: 0
[2023-07-01 11:36:44] [config] dropout-trg: 0
[2023-07-01 11:36:44] [config] dump-config: ""
[2023-07-01 11:36:44] [config] dynamic-gradient-scaling:
[2023-07-01 11:36:44] [config]   []
[2023-07-01 11:36:44] [config] early-stopping: 10
[2023-07-01 11:36:44] [config] early-stopping-on: first
[2023-07-01 11:36:44] [config] embedding-fix-src: false
[2023-07-01 11:36:44] [config] embedding-fix-trg: false
[2023-07-01 11:36:44] [config] embedding-normalization: false
[2023-07-01 11:36:44] [config] embedding-vectors:
[2023-07-01 11:36:44] [config]   []
[2023-07-01 11:36:44] [config] enc-cell: gru
[2023-07-01 11:36:44] [config] enc-cell-depth: 1
[2023-07-01 11:36:44] [config] enc-depth: 2
[2023-07-01 11:36:44] [config] enc-type: bidirectional
[2023-07-01 11:36:44] [config] english-title-case-every: 0
[2023-07-01 11:36:44] [config] exponential-smoothing: 0.0001
[2023-07-01 11:36:44] [config] factor-weight: 1
[2023-07-01 11:36:44] [config] factors-combine: sum
[2023-07-01 11:36:44] [config] factors-dim-emb: 0
[2023-07-01 11:36:44] [config] gradient-checkpointing: false
[2023-07-01 11:36:44] [config] gradient-norm-average-window: 100
[2023-07-01 11:36:44] [config] guided-alignment: none
[2023-07-01 11:36:44] [config] guided-alignment-cost: mse
[2023-07-01 11:36:44] [config] guided-alignment-weight: 0.1
[2023-07-01 11:36:44] [config] ignore-model-config: false
[2023-07-01 11:36:44] [config] input-types:
[2023-07-01 11:36:44] [config]   []
[2023-07-01 11:36:44] [config] interpolate-env-vars: false
[2023-07-01 11:36:44] [config] keep-best: false
[2023-07-01 11:36:44] [config] label-smoothing: 0.1
[2023-07-01 11:36:44] [config] layer-normalization: false
[2023-07-01 11:36:44] [config] learn-rate: 0.0003
[2023-07-01 11:36:44] [config] lemma-dependency: ""
[2023-07-01 11:36:44] [config] lemma-dim-emb: 0
[2023-07-01 11:36:44] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:36:44] [config] log-level: info
[2023-07-01 11:36:44] [config] log-time-zone: ""
[2023-07-01 11:36:44] [config] logical-epoch:
[2023-07-01 11:36:44] [config]   - 1e
[2023-07-01 11:36:44] [config]   - 0
[2023-07-01 11:36:44] [config] lr-decay: 0
[2023-07-01 11:36:44] [config] lr-decay-freq: 50000
[2023-07-01 11:36:44] [config] lr-decay-inv-sqrt:
[2023-07-01 11:36:44] [config]   - 16000
[2023-07-01 11:36:44] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:36:44] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:36:44] [config] lr-decay-start:
[2023-07-01 11:36:44] [config]   - 10
[2023-07-01 11:36:44] [config]   - 1
[2023-07-01 11:36:44] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:36:44] [config] lr-report: true
[2023-07-01 11:36:44] [config] lr-warmup: 16000
[2023-07-01 11:36:44] [config] lr-warmup-at-reload: false
[2023-07-01 11:36:44] [config] lr-warmup-cycle: false
[2023-07-01 11:36:44] [config] lr-warmup-start-rate: 0
[2023-07-01 11:36:44] [config] max-length: 100
[2023-07-01 11:36:44] [config] max-length-crop: false
[2023-07-01 11:36:44] [config] max-length-factor: 3
[2023-07-01 11:36:44] [config] maxi-batch: 100
[2023-07-01 11:36:44] [config] maxi-batch-sort: trg
[2023-07-01 11:36:44] [config] mini-batch: 1000
[2023-07-01 11:36:44] [config] mini-batch-fit: true
[2023-07-01 11:36:44] [config] mini-batch-fit-step: 10
[2023-07-01 11:36:44] [config] mini-batch-round-up: true
[2023-07-01 11:36:44] [config] mini-batch-track-lr: false
[2023-07-01 11:36:44] [config] mini-batch-warmup: 0
[2023-07-01 11:36:44] [config] mini-batch-words: 0
[2023-07-01 11:36:44] [config] mini-batch-words-ref: 0
[2023-07-01 11:36:44] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:36:44] [config] multi-loss-type: sum
[2023-07-01 11:36:44] [config] n-best: false
[2023-07-01 11:36:44] [config] no-nccl: false
[2023-07-01 11:36:44] [config] no-reload: false
[2023-07-01 11:36:44] [config] no-restore-corpus: false
[2023-07-01 11:36:44] [config] normalize: 1
[2023-07-01 11:36:44] [config] normalize-gradient: false
[2023-07-01 11:36:44] [config] num-devices: 0
[2023-07-01 11:36:44] [config] optimizer: adam
[2023-07-01 11:36:44] [config] optimizer-delay: 1
[2023-07-01 11:36:44] [config] optimizer-params:
[2023-07-01 11:36:44] [config]   - 0.9
[2023-07-01 11:36:44] [config]   - 0.98
[2023-07-01 11:36:44] [config]   - 1e-09
[2023-07-01 11:36:44] [config] output-omit-bias: false
[2023-07-01 11:36:44] [config] overwrite: true
[2023-07-01 11:36:44] [config] precision:
[2023-07-01 11:36:44] [config]   - float32
[2023-07-01 11:36:44] [config]   - float32
[2023-07-01 11:36:44] [config] pretrained-model: ""
[2023-07-01 11:36:44] [config] quantize-biases: false
[2023-07-01 11:36:44] [config] quantize-bits: 0
[2023-07-01 11:36:44] [config] quantize-log-based: false
[2023-07-01 11:36:44] [config] quantize-optimization-steps: 0
[2023-07-01 11:36:44] [config] quiet: false
[2023-07-01 11:36:44] [config] quiet-translation: true
[2023-07-01 11:36:44] [config] relative-paths: false
[2023-07-01 11:36:44] [config] right-left: false
[2023-07-01 11:36:44] [config] save-freq: 10000u
[2023-07-01 11:36:44] [config] seed: 1234
[2023-07-01 11:36:44] [config] sentencepiece-alphas:
[2023-07-01 11:36:44] [config]   []
[2023-07-01 11:36:44] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:36:44] [config] sentencepiece-options: ""
[2023-07-01 11:36:44] [config] sharding: global
[2023-07-01 11:36:44] [config] shuffle: data
[2023-07-01 11:36:44] [config] shuffle-in-ram: false
[2023-07-01 11:36:44] [config] sigterm: save-and-exit
[2023-07-01 11:36:44] [config] skip: false
[2023-07-01 11:36:44] [config] sqlite: ""
[2023-07-01 11:36:44] [config] sqlite-drop: false
[2023-07-01 11:36:44] [config] sync-freq: 200u
[2023-07-01 11:36:44] [config] sync-sgd: true
[2023-07-01 11:36:44] [config] tempdir: /tmp
[2023-07-01 11:36:44] [config] tied-embeddings: false
[2023-07-01 11:36:44] [config] tied-embeddings-all: true
[2023-07-01 11:36:44] [config] tied-embeddings-src: false
[2023-07-01 11:36:44] [config] train-embedder-rank:
[2023-07-01 11:36:44] [config]   []
[2023-07-01 11:36:44] [config] train-sets:
[2023-07-01 11:36:44] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:36:44] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:36:44] [config] transformer-aan-activation: swish
[2023-07-01 11:36:44] [config] transformer-aan-depth: 2
[2023-07-01 11:36:44] [config] transformer-aan-nogate: false
[2023-07-01 11:36:44] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:36:44] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:36:44] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:36:44] [config] transformer-depth-scaling: false
[2023-07-01 11:36:44] [config] transformer-dim-aan: 2048
[2023-07-01 11:36:44] [config] transformer-dim-ffn: 2048
[2023-07-01 11:36:44] [config] transformer-dropout: 0.1
[2023-07-01 11:36:44] [config] transformer-dropout-attention: 0
[2023-07-01 11:36:44] [config] transformer-dropout-ffn: 0
[2023-07-01 11:36:44] [config] transformer-ffn-activation: swish
[2023-07-01 11:36:44] [config] transformer-ffn-depth: 2
[2023-07-01 11:36:44] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:36:44] [config] transformer-heads: 8
[2023-07-01 11:36:44] [config] transformer-no-projection: false
[2023-07-01 11:36:44] [config] transformer-pool: false
[2023-07-01 11:36:44] [config] transformer-postprocess: dan
[2023-07-01 11:36:44] [config] transformer-postprocess-emb: d
[2023-07-01 11:36:44] [config] transformer-postprocess-top: ""
[2023-07-01 11:36:44] [config] transformer-preprocess: ""
[2023-07-01 11:36:44] [config] transformer-tied-layers:
[2023-07-01 11:36:44] [config]   []
[2023-07-01 11:36:44] [config] transformer-train-position-embeddings: false
[2023-07-01 11:36:44] [config] tsv: false
[2023-07-01 11:36:44] [config] tsv-fields: 0
[2023-07-01 11:36:44] [config] type: transformer
[2023-07-01 11:36:44] [config] ulr: false
[2023-07-01 11:36:44] [config] ulr-dim-emb: 0
[2023-07-01 11:36:44] [config] ulr-dropout: 0
[2023-07-01 11:36:44] [config] ulr-keys-vectors: ""
[2023-07-01 11:36:44] [config] ulr-query-vectors: ""
[2023-07-01 11:36:44] [config] ulr-softmax-temperature: 1
[2023-07-01 11:36:44] [config] ulr-trainable-transformation: false
[2023-07-01 11:36:44] [config] unlikelihood-loss: false
[2023-07-01 11:36:44] [config] valid-freq: 50000000
[2023-07-01 11:36:44] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:36:44] [config] valid-max-length: 1000
[2023-07-01 11:36:44] [config] valid-metrics:
[2023-07-01 11:36:44] [config]   - cross-entropy
[2023-07-01 11:36:44] [config]   - translation
[2023-07-01 11:36:44] [config] valid-mini-batch: 64
[2023-07-01 11:36:44] [config] valid-reset-stalled: false
[2023-07-01 11:36:44] [config] valid-script-args:
[2023-07-01 11:36:44] [config]   []
[2023-07-01 11:36:44] [config] valid-script-path: ""
[2023-07-01 11:36:44] [config] valid-sets:
[2023-07-01 11:36:44] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:36:44] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:36:44] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:36:44] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:36:44] [config] vocabs:
[2023-07-01 11:36:44] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:36:44] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:36:44] [config] word-penalty: 0
[2023-07-01 11:36:44] [config] word-scores: false
[2023-07-01 11:36:44] [config] workspace: 2048
[2023-07-01 11:36:44] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:36:44] Using synchronous SGD
[2023-07-01 11:36:45] Synced seed 1234
[2023-07-01 11:36:45] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:36:45] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:36:45] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:36:45] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:36:45] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:36:45] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:36:46] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:36:46] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:36:46] [comm] Using global sharding
[2023-07-01 11:36:46] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:36:46] [training] Using 1 GPUs
[2023-07-01 11:36:46] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:36:46] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:36:46] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:36:46] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:36:53] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:36:53] [valid] No post-processing script given for validating translator
[2023-07-01 11:36:53] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:36:53] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:36:54] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:36:54] [comm] Using global sharding
[2023-07-01 11:36:54] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:36:54] [training] Using 1 GPUs
[2023-07-01 11:36:54] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:36:54] Allocating memory for general optimizer shards
[2023-07-01 11:36:54] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:36:54] Loading Adam parameters
[2023-07-01 11:36:54] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:36:54] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:36:54] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:36:54] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:36:54] [data] Shuffling data
[2023-07-01 11:36:54] [data] Done reading 20,192 sentences
[2023-07-01 11:36:54] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:36:54] Training started
[2023-07-01 11:36:54] Training finished
[2023-07-01 11:36:58] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:36:58] [marian] Running on node20.datos.cluster.uy as process 18392 with command line:
[2023-07-01 11:36:58] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 124 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:36:58] [config] after: 0e
[2023-07-01 11:36:58] [config] after-batches: 0
[2023-07-01 11:36:58] [config] after-epochs: 124
[2023-07-01 11:36:58] [config] all-caps-every: 0
[2023-07-01 11:36:58] [config] allow-unk: false
[2023-07-01 11:36:58] [config] authors: false
[2023-07-01 11:36:58] [config] beam-size: 12
[2023-07-01 11:36:58] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:36:58] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:36:58] [config] bert-masking-fraction: 0.15
[2023-07-01 11:36:58] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:36:58] [config] bert-train-type-embeddings: true
[2023-07-01 11:36:58] [config] bert-type-vocab-size: 2
[2023-07-01 11:36:58] [config] build-info: ""
[2023-07-01 11:36:58] [config] check-gradient-nan: false
[2023-07-01 11:36:58] [config] check-nan: false
[2023-07-01 11:36:58] [config] cite: false
[2023-07-01 11:36:58] [config] clip-norm: 5
[2023-07-01 11:36:58] [config] cost-scaling:
[2023-07-01 11:36:58] [config]   []
[2023-07-01 11:36:58] [config] cost-type: ce-sum
[2023-07-01 11:36:58] [config] cpu-threads: 0
[2023-07-01 11:36:58] [config] data-threads: 8
[2023-07-01 11:36:58] [config] data-weighting: ""
[2023-07-01 11:36:58] [config] data-weighting-type: sentence
[2023-07-01 11:36:58] [config] dec-cell: gru
[2023-07-01 11:36:58] [config] dec-cell-base-depth: 2
[2023-07-01 11:36:58] [config] dec-cell-high-depth: 1
[2023-07-01 11:36:58] [config] dec-depth: 2
[2023-07-01 11:36:58] [config] devices:
[2023-07-01 11:36:58] [config]   - 0
[2023-07-01 11:36:58] [config] dim-emb: 512
[2023-07-01 11:36:58] [config] dim-rnn: 1024
[2023-07-01 11:36:58] [config] dim-vocabs:
[2023-07-01 11:36:58] [config]   - 16384
[2023-07-01 11:36:58] [config]   - 16384
[2023-07-01 11:36:58] [config] disp-first: 0
[2023-07-01 11:36:58] [config] disp-freq: 1000u
[2023-07-01 11:36:58] [config] disp-label-counts: true
[2023-07-01 11:36:58] [config] dropout-rnn: 0
[2023-07-01 11:36:58] [config] dropout-src: 0
[2023-07-01 11:36:58] [config] dropout-trg: 0
[2023-07-01 11:36:58] [config] dump-config: ""
[2023-07-01 11:36:58] [config] dynamic-gradient-scaling:
[2023-07-01 11:36:58] [config]   []
[2023-07-01 11:36:58] [config] early-stopping: 10
[2023-07-01 11:36:58] [config] early-stopping-on: first
[2023-07-01 11:36:58] [config] embedding-fix-src: false
[2023-07-01 11:36:58] [config] embedding-fix-trg: false
[2023-07-01 11:36:58] [config] embedding-normalization: false
[2023-07-01 11:36:58] [config] embedding-vectors:
[2023-07-01 11:36:58] [config]   []
[2023-07-01 11:36:58] [config] enc-cell: gru
[2023-07-01 11:36:58] [config] enc-cell-depth: 1
[2023-07-01 11:36:58] [config] enc-depth: 2
[2023-07-01 11:36:58] [config] enc-type: bidirectional
[2023-07-01 11:36:58] [config] english-title-case-every: 0
[2023-07-01 11:36:58] [config] exponential-smoothing: 0.0001
[2023-07-01 11:36:58] [config] factor-weight: 1
[2023-07-01 11:36:58] [config] factors-combine: sum
[2023-07-01 11:36:58] [config] factors-dim-emb: 0
[2023-07-01 11:36:58] [config] gradient-checkpointing: false
[2023-07-01 11:36:58] [config] gradient-norm-average-window: 100
[2023-07-01 11:36:58] [config] guided-alignment: none
[2023-07-01 11:36:58] [config] guided-alignment-cost: mse
[2023-07-01 11:36:58] [config] guided-alignment-weight: 0.1
[2023-07-01 11:36:58] [config] ignore-model-config: false
[2023-07-01 11:36:58] [config] input-types:
[2023-07-01 11:36:58] [config]   []
[2023-07-01 11:36:58] [config] interpolate-env-vars: false
[2023-07-01 11:36:58] [config] keep-best: false
[2023-07-01 11:36:58] [config] label-smoothing: 0.1
[2023-07-01 11:36:58] [config] layer-normalization: false
[2023-07-01 11:36:58] [config] learn-rate: 0.0003
[2023-07-01 11:36:58] [config] lemma-dependency: ""
[2023-07-01 11:36:58] [config] lemma-dim-emb: 0
[2023-07-01 11:36:58] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:36:58] [config] log-level: info
[2023-07-01 11:36:58] [config] log-time-zone: ""
[2023-07-01 11:36:58] [config] logical-epoch:
[2023-07-01 11:36:58] [config]   - 1e
[2023-07-01 11:36:58] [config]   - 0
[2023-07-01 11:36:58] [config] lr-decay: 0
[2023-07-01 11:36:58] [config] lr-decay-freq: 50000
[2023-07-01 11:36:58] [config] lr-decay-inv-sqrt:
[2023-07-01 11:36:58] [config]   - 16000
[2023-07-01 11:36:58] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:36:58] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:36:58] [config] lr-decay-start:
[2023-07-01 11:36:58] [config]   - 10
[2023-07-01 11:36:58] [config]   - 1
[2023-07-01 11:36:58] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:36:58] [config] lr-report: true
[2023-07-01 11:36:58] [config] lr-warmup: 16000
[2023-07-01 11:36:58] [config] lr-warmup-at-reload: false
[2023-07-01 11:36:58] [config] lr-warmup-cycle: false
[2023-07-01 11:36:58] [config] lr-warmup-start-rate: 0
[2023-07-01 11:36:58] [config] max-length: 100
[2023-07-01 11:36:58] [config] max-length-crop: false
[2023-07-01 11:36:58] [config] max-length-factor: 3
[2023-07-01 11:36:58] [config] maxi-batch: 100
[2023-07-01 11:36:58] [config] maxi-batch-sort: trg
[2023-07-01 11:36:58] [config] mini-batch: 1000
[2023-07-01 11:36:58] [config] mini-batch-fit: true
[2023-07-01 11:36:58] [config] mini-batch-fit-step: 10
[2023-07-01 11:36:58] [config] mini-batch-round-up: true
[2023-07-01 11:36:58] [config] mini-batch-track-lr: false
[2023-07-01 11:36:58] [config] mini-batch-warmup: 0
[2023-07-01 11:36:58] [config] mini-batch-words: 0
[2023-07-01 11:36:58] [config] mini-batch-words-ref: 0
[2023-07-01 11:36:58] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:36:58] [config] multi-loss-type: sum
[2023-07-01 11:36:58] [config] n-best: false
[2023-07-01 11:36:58] [config] no-nccl: false
[2023-07-01 11:36:58] [config] no-reload: false
[2023-07-01 11:36:58] [config] no-restore-corpus: false
[2023-07-01 11:36:58] [config] normalize: 1
[2023-07-01 11:36:58] [config] normalize-gradient: false
[2023-07-01 11:36:58] [config] num-devices: 0
[2023-07-01 11:36:58] [config] optimizer: adam
[2023-07-01 11:36:58] [config] optimizer-delay: 1
[2023-07-01 11:36:58] [config] optimizer-params:
[2023-07-01 11:36:58] [config]   - 0.9
[2023-07-01 11:36:58] [config]   - 0.98
[2023-07-01 11:36:58] [config]   - 1e-09
[2023-07-01 11:36:58] [config] output-omit-bias: false
[2023-07-01 11:36:58] [config] overwrite: true
[2023-07-01 11:36:58] [config] precision:
[2023-07-01 11:36:58] [config]   - float32
[2023-07-01 11:36:58] [config]   - float32
[2023-07-01 11:36:58] [config] pretrained-model: ""
[2023-07-01 11:36:58] [config] quantize-biases: false
[2023-07-01 11:36:58] [config] quantize-bits: 0
[2023-07-01 11:36:58] [config] quantize-log-based: false
[2023-07-01 11:36:58] [config] quantize-optimization-steps: 0
[2023-07-01 11:36:58] [config] quiet: false
[2023-07-01 11:36:58] [config] quiet-translation: true
[2023-07-01 11:36:58] [config] relative-paths: false
[2023-07-01 11:36:58] [config] right-left: false
[2023-07-01 11:36:58] [config] save-freq: 10000u
[2023-07-01 11:36:58] [config] seed: 1234
[2023-07-01 11:36:58] [config] sentencepiece-alphas:
[2023-07-01 11:36:58] [config]   []
[2023-07-01 11:36:58] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:36:58] [config] sentencepiece-options: ""
[2023-07-01 11:36:58] [config] sharding: global
[2023-07-01 11:36:58] [config] shuffle: data
[2023-07-01 11:36:58] [config] shuffle-in-ram: false
[2023-07-01 11:36:58] [config] sigterm: save-and-exit
[2023-07-01 11:36:58] [config] skip: false
[2023-07-01 11:36:58] [config] sqlite: ""
[2023-07-01 11:36:58] [config] sqlite-drop: false
[2023-07-01 11:36:58] [config] sync-freq: 200u
[2023-07-01 11:36:58] [config] sync-sgd: true
[2023-07-01 11:36:58] [config] tempdir: /tmp
[2023-07-01 11:36:58] [config] tied-embeddings: false
[2023-07-01 11:36:58] [config] tied-embeddings-all: true
[2023-07-01 11:36:58] [config] tied-embeddings-src: false
[2023-07-01 11:36:58] [config] train-embedder-rank:
[2023-07-01 11:36:58] [config]   []
[2023-07-01 11:36:58] [config] train-sets:
[2023-07-01 11:36:58] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:36:58] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:36:58] [config] transformer-aan-activation: swish
[2023-07-01 11:36:58] [config] transformer-aan-depth: 2
[2023-07-01 11:36:58] [config] transformer-aan-nogate: false
[2023-07-01 11:36:58] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:36:58] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:36:58] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:36:58] [config] transformer-depth-scaling: false
[2023-07-01 11:36:58] [config] transformer-dim-aan: 2048
[2023-07-01 11:36:58] [config] transformer-dim-ffn: 2048
[2023-07-01 11:36:58] [config] transformer-dropout: 0.1
[2023-07-01 11:36:58] [config] transformer-dropout-attention: 0
[2023-07-01 11:36:58] [config] transformer-dropout-ffn: 0
[2023-07-01 11:36:58] [config] transformer-ffn-activation: swish
[2023-07-01 11:36:58] [config] transformer-ffn-depth: 2
[2023-07-01 11:36:58] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:36:58] [config] transformer-heads: 8
[2023-07-01 11:36:58] [config] transformer-no-projection: false
[2023-07-01 11:36:58] [config] transformer-pool: false
[2023-07-01 11:36:58] [config] transformer-postprocess: dan
[2023-07-01 11:36:58] [config] transformer-postprocess-emb: d
[2023-07-01 11:36:58] [config] transformer-postprocess-top: ""
[2023-07-01 11:36:58] [config] transformer-preprocess: ""
[2023-07-01 11:36:58] [config] transformer-tied-layers:
[2023-07-01 11:36:58] [config]   []
[2023-07-01 11:36:58] [config] transformer-train-position-embeddings: false
[2023-07-01 11:36:58] [config] tsv: false
[2023-07-01 11:36:58] [config] tsv-fields: 0
[2023-07-01 11:36:58] [config] type: transformer
[2023-07-01 11:36:58] [config] ulr: false
[2023-07-01 11:36:58] [config] ulr-dim-emb: 0
[2023-07-01 11:36:58] [config] ulr-dropout: 0
[2023-07-01 11:36:58] [config] ulr-keys-vectors: ""
[2023-07-01 11:36:58] [config] ulr-query-vectors: ""
[2023-07-01 11:36:58] [config] ulr-softmax-temperature: 1
[2023-07-01 11:36:58] [config] ulr-trainable-transformation: false
[2023-07-01 11:36:58] [config] unlikelihood-loss: false
[2023-07-01 11:36:58] [config] valid-freq: 50000000
[2023-07-01 11:36:58] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:36:58] [config] valid-max-length: 1000
[2023-07-01 11:36:58] [config] valid-metrics:
[2023-07-01 11:36:58] [config]   - cross-entropy
[2023-07-01 11:36:58] [config]   - translation
[2023-07-01 11:36:58] [config] valid-mini-batch: 64
[2023-07-01 11:36:58] [config] valid-reset-stalled: false
[2023-07-01 11:36:58] [config] valid-script-args:
[2023-07-01 11:36:58] [config]   []
[2023-07-01 11:36:58] [config] valid-script-path: ""
[2023-07-01 11:36:58] [config] valid-sets:
[2023-07-01 11:36:58] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:36:58] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:36:58] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:36:58] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:36:58] [config] vocabs:
[2023-07-01 11:36:58] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:36:58] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:36:58] [config] word-penalty: 0
[2023-07-01 11:36:58] [config] word-scores: false
[2023-07-01 11:36:58] [config] workspace: 2048
[2023-07-01 11:36:58] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:36:58] Using synchronous SGD
[2023-07-01 11:36:58] Synced seed 1234
[2023-07-01 11:36:58] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:36:58] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:36:58] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:36:58] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:36:58] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:36:58] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:36:59] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:36:59] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:36:59] [comm] Using global sharding
[2023-07-01 11:36:59] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:36:59] [training] Using 1 GPUs
[2023-07-01 11:36:59] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:36:59] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:36:59] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:37:00] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:37:07] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:37:07] [valid] No post-processing script given for validating translator
[2023-07-01 11:37:07] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:37:07] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:37:07] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:37:07] [comm] Using global sharding
[2023-07-01 11:37:07] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:37:07] [training] Using 1 GPUs
[2023-07-01 11:37:07] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:37:08] Allocating memory for general optimizer shards
[2023-07-01 11:37:08] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:37:08] Loading Adam parameters
[2023-07-01 11:37:08] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:37:08] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:37:08] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:37:08] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:37:08] [data] Shuffling data
[2023-07-01 11:37:08] [data] Done reading 20,192 sentences
[2023-07-01 11:37:08] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:37:08] Training started
[2023-07-01 11:37:08] Training finished
[2023-07-01 11:37:11] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:37:11] [marian] Running on node20.datos.cluster.uy as process 18564 with command line:
[2023-07-01 11:37:11] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 125 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:37:11] [config] after: 0e
[2023-07-01 11:37:11] [config] after-batches: 0
[2023-07-01 11:37:11] [config] after-epochs: 125
[2023-07-01 11:37:11] [config] all-caps-every: 0
[2023-07-01 11:37:11] [config] allow-unk: false
[2023-07-01 11:37:11] [config] authors: false
[2023-07-01 11:37:11] [config] beam-size: 12
[2023-07-01 11:37:11] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:37:11] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:37:11] [config] bert-masking-fraction: 0.15
[2023-07-01 11:37:11] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:37:11] [config] bert-train-type-embeddings: true
[2023-07-01 11:37:11] [config] bert-type-vocab-size: 2
[2023-07-01 11:37:11] [config] build-info: ""
[2023-07-01 11:37:11] [config] check-gradient-nan: false
[2023-07-01 11:37:11] [config] check-nan: false
[2023-07-01 11:37:11] [config] cite: false
[2023-07-01 11:37:11] [config] clip-norm: 5
[2023-07-01 11:37:11] [config] cost-scaling:
[2023-07-01 11:37:11] [config]   []
[2023-07-01 11:37:11] [config] cost-type: ce-sum
[2023-07-01 11:37:11] [config] cpu-threads: 0
[2023-07-01 11:37:11] [config] data-threads: 8
[2023-07-01 11:37:11] [config] data-weighting: ""
[2023-07-01 11:37:11] [config] data-weighting-type: sentence
[2023-07-01 11:37:11] [config] dec-cell: gru
[2023-07-01 11:37:11] [config] dec-cell-base-depth: 2
[2023-07-01 11:37:11] [config] dec-cell-high-depth: 1
[2023-07-01 11:37:11] [config] dec-depth: 2
[2023-07-01 11:37:11] [config] devices:
[2023-07-01 11:37:11] [config]   - 0
[2023-07-01 11:37:11] [config] dim-emb: 512
[2023-07-01 11:37:11] [config] dim-rnn: 1024
[2023-07-01 11:37:11] [config] dim-vocabs:
[2023-07-01 11:37:11] [config]   - 16384
[2023-07-01 11:37:11] [config]   - 16384
[2023-07-01 11:37:11] [config] disp-first: 0
[2023-07-01 11:37:11] [config] disp-freq: 1000u
[2023-07-01 11:37:11] [config] disp-label-counts: true
[2023-07-01 11:37:11] [config] dropout-rnn: 0
[2023-07-01 11:37:11] [config] dropout-src: 0
[2023-07-01 11:37:11] [config] dropout-trg: 0
[2023-07-01 11:37:11] [config] dump-config: ""
[2023-07-01 11:37:11] [config] dynamic-gradient-scaling:
[2023-07-01 11:37:11] [config]   []
[2023-07-01 11:37:11] [config] early-stopping: 10
[2023-07-01 11:37:11] [config] early-stopping-on: first
[2023-07-01 11:37:11] [config] embedding-fix-src: false
[2023-07-01 11:37:11] [config] embedding-fix-trg: false
[2023-07-01 11:37:11] [config] embedding-normalization: false
[2023-07-01 11:37:11] [config] embedding-vectors:
[2023-07-01 11:37:11] [config]   []
[2023-07-01 11:37:11] [config] enc-cell: gru
[2023-07-01 11:37:11] [config] enc-cell-depth: 1
[2023-07-01 11:37:11] [config] enc-depth: 2
[2023-07-01 11:37:11] [config] enc-type: bidirectional
[2023-07-01 11:37:11] [config] english-title-case-every: 0
[2023-07-01 11:37:11] [config] exponential-smoothing: 0.0001
[2023-07-01 11:37:11] [config] factor-weight: 1
[2023-07-01 11:37:11] [config] factors-combine: sum
[2023-07-01 11:37:11] [config] factors-dim-emb: 0
[2023-07-01 11:37:11] [config] gradient-checkpointing: false
[2023-07-01 11:37:11] [config] gradient-norm-average-window: 100
[2023-07-01 11:37:11] [config] guided-alignment: none
[2023-07-01 11:37:11] [config] guided-alignment-cost: mse
[2023-07-01 11:37:11] [config] guided-alignment-weight: 0.1
[2023-07-01 11:37:11] [config] ignore-model-config: false
[2023-07-01 11:37:11] [config] input-types:
[2023-07-01 11:37:11] [config]   []
[2023-07-01 11:37:11] [config] interpolate-env-vars: false
[2023-07-01 11:37:11] [config] keep-best: false
[2023-07-01 11:37:11] [config] label-smoothing: 0.1
[2023-07-01 11:37:11] [config] layer-normalization: false
[2023-07-01 11:37:11] [config] learn-rate: 0.0003
[2023-07-01 11:37:11] [config] lemma-dependency: ""
[2023-07-01 11:37:11] [config] lemma-dim-emb: 0
[2023-07-01 11:37:11] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:37:11] [config] log-level: info
[2023-07-01 11:37:11] [config] log-time-zone: ""
[2023-07-01 11:37:11] [config] logical-epoch:
[2023-07-01 11:37:11] [config]   - 1e
[2023-07-01 11:37:11] [config]   - 0
[2023-07-01 11:37:11] [config] lr-decay: 0
[2023-07-01 11:37:11] [config] lr-decay-freq: 50000
[2023-07-01 11:37:11] [config] lr-decay-inv-sqrt:
[2023-07-01 11:37:11] [config]   - 16000
[2023-07-01 11:37:11] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:37:11] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:37:11] [config] lr-decay-start:
[2023-07-01 11:37:11] [config]   - 10
[2023-07-01 11:37:11] [config]   - 1
[2023-07-01 11:37:11] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:37:11] [config] lr-report: true
[2023-07-01 11:37:11] [config] lr-warmup: 16000
[2023-07-01 11:37:11] [config] lr-warmup-at-reload: false
[2023-07-01 11:37:11] [config] lr-warmup-cycle: false
[2023-07-01 11:37:11] [config] lr-warmup-start-rate: 0
[2023-07-01 11:37:11] [config] max-length: 100
[2023-07-01 11:37:11] [config] max-length-crop: false
[2023-07-01 11:37:11] [config] max-length-factor: 3
[2023-07-01 11:37:11] [config] maxi-batch: 100
[2023-07-01 11:37:11] [config] maxi-batch-sort: trg
[2023-07-01 11:37:11] [config] mini-batch: 1000
[2023-07-01 11:37:11] [config] mini-batch-fit: true
[2023-07-01 11:37:11] [config] mini-batch-fit-step: 10
[2023-07-01 11:37:11] [config] mini-batch-round-up: true
[2023-07-01 11:37:11] [config] mini-batch-track-lr: false
[2023-07-01 11:37:11] [config] mini-batch-warmup: 0
[2023-07-01 11:37:11] [config] mini-batch-words: 0
[2023-07-01 11:37:11] [config] mini-batch-words-ref: 0
[2023-07-01 11:37:11] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:37:11] [config] multi-loss-type: sum
[2023-07-01 11:37:11] [config] n-best: false
[2023-07-01 11:37:11] [config] no-nccl: false
[2023-07-01 11:37:11] [config] no-reload: false
[2023-07-01 11:37:11] [config] no-restore-corpus: false
[2023-07-01 11:37:11] [config] normalize: 1
[2023-07-01 11:37:11] [config] normalize-gradient: false
[2023-07-01 11:37:11] [config] num-devices: 0
[2023-07-01 11:37:11] [config] optimizer: adam
[2023-07-01 11:37:11] [config] optimizer-delay: 1
[2023-07-01 11:37:11] [config] optimizer-params:
[2023-07-01 11:37:11] [config]   - 0.9
[2023-07-01 11:37:11] [config]   - 0.98
[2023-07-01 11:37:11] [config]   - 1e-09
[2023-07-01 11:37:11] [config] output-omit-bias: false
[2023-07-01 11:37:11] [config] overwrite: true
[2023-07-01 11:37:11] [config] precision:
[2023-07-01 11:37:11] [config]   - float32
[2023-07-01 11:37:11] [config]   - float32
[2023-07-01 11:37:11] [config] pretrained-model: ""
[2023-07-01 11:37:11] [config] quantize-biases: false
[2023-07-01 11:37:11] [config] quantize-bits: 0
[2023-07-01 11:37:11] [config] quantize-log-based: false
[2023-07-01 11:37:11] [config] quantize-optimization-steps: 0
[2023-07-01 11:37:11] [config] quiet: false
[2023-07-01 11:37:11] [config] quiet-translation: true
[2023-07-01 11:37:11] [config] relative-paths: false
[2023-07-01 11:37:11] [config] right-left: false
[2023-07-01 11:37:11] [config] save-freq: 10000u
[2023-07-01 11:37:11] [config] seed: 1234
[2023-07-01 11:37:11] [config] sentencepiece-alphas:
[2023-07-01 11:37:11] [config]   []
[2023-07-01 11:37:11] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:37:11] [config] sentencepiece-options: ""
[2023-07-01 11:37:11] [config] sharding: global
[2023-07-01 11:37:11] [config] shuffle: data
[2023-07-01 11:37:11] [config] shuffle-in-ram: false
[2023-07-01 11:37:11] [config] sigterm: save-and-exit
[2023-07-01 11:37:11] [config] skip: false
[2023-07-01 11:37:11] [config] sqlite: ""
[2023-07-01 11:37:11] [config] sqlite-drop: false
[2023-07-01 11:37:11] [config] sync-freq: 200u
[2023-07-01 11:37:11] [config] sync-sgd: true
[2023-07-01 11:37:11] [config] tempdir: /tmp
[2023-07-01 11:37:11] [config] tied-embeddings: false
[2023-07-01 11:37:11] [config] tied-embeddings-all: true
[2023-07-01 11:37:11] [config] tied-embeddings-src: false
[2023-07-01 11:37:11] [config] train-embedder-rank:
[2023-07-01 11:37:11] [config]   []
[2023-07-01 11:37:11] [config] train-sets:
[2023-07-01 11:37:11] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:37:11] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:37:11] [config] transformer-aan-activation: swish
[2023-07-01 11:37:11] [config] transformer-aan-depth: 2
[2023-07-01 11:37:11] [config] transformer-aan-nogate: false
[2023-07-01 11:37:11] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:37:11] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:37:11] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:37:11] [config] transformer-depth-scaling: false
[2023-07-01 11:37:11] [config] transformer-dim-aan: 2048
[2023-07-01 11:37:11] [config] transformer-dim-ffn: 2048
[2023-07-01 11:37:11] [config] transformer-dropout: 0.1
[2023-07-01 11:37:11] [config] transformer-dropout-attention: 0
[2023-07-01 11:37:11] [config] transformer-dropout-ffn: 0
[2023-07-01 11:37:11] [config] transformer-ffn-activation: swish
[2023-07-01 11:37:11] [config] transformer-ffn-depth: 2
[2023-07-01 11:37:11] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:37:11] [config] transformer-heads: 8
[2023-07-01 11:37:11] [config] transformer-no-projection: false
[2023-07-01 11:37:11] [config] transformer-pool: false
[2023-07-01 11:37:11] [config] transformer-postprocess: dan
[2023-07-01 11:37:11] [config] transformer-postprocess-emb: d
[2023-07-01 11:37:11] [config] transformer-postprocess-top: ""
[2023-07-01 11:37:11] [config] transformer-preprocess: ""
[2023-07-01 11:37:11] [config] transformer-tied-layers:
[2023-07-01 11:37:11] [config]   []
[2023-07-01 11:37:11] [config] transformer-train-position-embeddings: false
[2023-07-01 11:37:11] [config] tsv: false
[2023-07-01 11:37:11] [config] tsv-fields: 0
[2023-07-01 11:37:11] [config] type: transformer
[2023-07-01 11:37:11] [config] ulr: false
[2023-07-01 11:37:11] [config] ulr-dim-emb: 0
[2023-07-01 11:37:11] [config] ulr-dropout: 0
[2023-07-01 11:37:11] [config] ulr-keys-vectors: ""
[2023-07-01 11:37:11] [config] ulr-query-vectors: ""
[2023-07-01 11:37:11] [config] ulr-softmax-temperature: 1
[2023-07-01 11:37:11] [config] ulr-trainable-transformation: false
[2023-07-01 11:37:11] [config] unlikelihood-loss: false
[2023-07-01 11:37:11] [config] valid-freq: 50000000
[2023-07-01 11:37:11] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:37:11] [config] valid-max-length: 1000
[2023-07-01 11:37:11] [config] valid-metrics:
[2023-07-01 11:37:11] [config]   - cross-entropy
[2023-07-01 11:37:11] [config]   - translation
[2023-07-01 11:37:11] [config] valid-mini-batch: 64
[2023-07-01 11:37:11] [config] valid-reset-stalled: false
[2023-07-01 11:37:11] [config] valid-script-args:
[2023-07-01 11:37:11] [config]   []
[2023-07-01 11:37:11] [config] valid-script-path: ""
[2023-07-01 11:37:11] [config] valid-sets:
[2023-07-01 11:37:11] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:37:11] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:37:11] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:37:11] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:37:11] [config] vocabs:
[2023-07-01 11:37:11] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:37:11] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:37:11] [config] word-penalty: 0
[2023-07-01 11:37:11] [config] word-scores: false
[2023-07-01 11:37:11] [config] workspace: 2048
[2023-07-01 11:37:11] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:37:11] Using synchronous SGD
[2023-07-01 11:37:12] Synced seed 1234
[2023-07-01 11:37:12] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:37:12] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:37:12] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:37:12] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:37:12] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:37:12] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:37:13] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:37:13] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:37:13] [comm] Using global sharding
[2023-07-01 11:37:13] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:37:13] [training] Using 1 GPUs
[2023-07-01 11:37:13] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:37:13] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:37:13] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:37:13] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:37:21] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:37:21] [valid] No post-processing script given for validating translator
[2023-07-01 11:37:21] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:37:21] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:37:21] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:37:21] [comm] Using global sharding
[2023-07-01 11:37:21] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:37:21] [training] Using 1 GPUs
[2023-07-01 11:37:21] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:37:21] Allocating memory for general optimizer shards
[2023-07-01 11:37:21] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:37:21] Loading Adam parameters
[2023-07-01 11:37:21] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:37:21] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:37:21] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:37:21] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:37:21] [data] Shuffling data
[2023-07-01 11:37:21] [data] Done reading 20,192 sentences
[2023-07-01 11:37:21] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:37:21] Training started
[2023-07-01 11:37:21] Training finished
[2023-07-01 11:37:25] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:37:25] [marian] Running on node20.datos.cluster.uy as process 18807 with command line:
[2023-07-01 11:37:25] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 126 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:37:25] [config] after: 0e
[2023-07-01 11:37:25] [config] after-batches: 0
[2023-07-01 11:37:25] [config] after-epochs: 126
[2023-07-01 11:37:25] [config] all-caps-every: 0
[2023-07-01 11:37:25] [config] allow-unk: false
[2023-07-01 11:37:25] [config] authors: false
[2023-07-01 11:37:25] [config] beam-size: 12
[2023-07-01 11:37:25] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:37:25] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:37:25] [config] bert-masking-fraction: 0.15
[2023-07-01 11:37:25] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:37:25] [config] bert-train-type-embeddings: true
[2023-07-01 11:37:25] [config] bert-type-vocab-size: 2
[2023-07-01 11:37:25] [config] build-info: ""
[2023-07-01 11:37:25] [config] check-gradient-nan: false
[2023-07-01 11:37:25] [config] check-nan: false
[2023-07-01 11:37:25] [config] cite: false
[2023-07-01 11:37:25] [config] clip-norm: 5
[2023-07-01 11:37:25] [config] cost-scaling:
[2023-07-01 11:37:25] [config]   []
[2023-07-01 11:37:25] [config] cost-type: ce-sum
[2023-07-01 11:37:25] [config] cpu-threads: 0
[2023-07-01 11:37:25] [config] data-threads: 8
[2023-07-01 11:37:25] [config] data-weighting: ""
[2023-07-01 11:37:25] [config] data-weighting-type: sentence
[2023-07-01 11:37:25] [config] dec-cell: gru
[2023-07-01 11:37:25] [config] dec-cell-base-depth: 2
[2023-07-01 11:37:25] [config] dec-cell-high-depth: 1
[2023-07-01 11:37:25] [config] dec-depth: 2
[2023-07-01 11:37:25] [config] devices:
[2023-07-01 11:37:25] [config]   - 0
[2023-07-01 11:37:25] [config] dim-emb: 512
[2023-07-01 11:37:25] [config] dim-rnn: 1024
[2023-07-01 11:37:25] [config] dim-vocabs:
[2023-07-01 11:37:25] [config]   - 16384
[2023-07-01 11:37:25] [config]   - 16384
[2023-07-01 11:37:25] [config] disp-first: 0
[2023-07-01 11:37:25] [config] disp-freq: 1000u
[2023-07-01 11:37:25] [config] disp-label-counts: true
[2023-07-01 11:37:25] [config] dropout-rnn: 0
[2023-07-01 11:37:25] [config] dropout-src: 0
[2023-07-01 11:37:25] [config] dropout-trg: 0
[2023-07-01 11:37:25] [config] dump-config: ""
[2023-07-01 11:37:25] [config] dynamic-gradient-scaling:
[2023-07-01 11:37:25] [config]   []
[2023-07-01 11:37:25] [config] early-stopping: 10
[2023-07-01 11:37:25] [config] early-stopping-on: first
[2023-07-01 11:37:25] [config] embedding-fix-src: false
[2023-07-01 11:37:25] [config] embedding-fix-trg: false
[2023-07-01 11:37:25] [config] embedding-normalization: false
[2023-07-01 11:37:25] [config] embedding-vectors:
[2023-07-01 11:37:25] [config]   []
[2023-07-01 11:37:25] [config] enc-cell: gru
[2023-07-01 11:37:25] [config] enc-cell-depth: 1
[2023-07-01 11:37:25] [config] enc-depth: 2
[2023-07-01 11:37:25] [config] enc-type: bidirectional
[2023-07-01 11:37:25] [config] english-title-case-every: 0
[2023-07-01 11:37:25] [config] exponential-smoothing: 0.0001
[2023-07-01 11:37:25] [config] factor-weight: 1
[2023-07-01 11:37:25] [config] factors-combine: sum
[2023-07-01 11:37:25] [config] factors-dim-emb: 0
[2023-07-01 11:37:25] [config] gradient-checkpointing: false
[2023-07-01 11:37:25] [config] gradient-norm-average-window: 100
[2023-07-01 11:37:25] [config] guided-alignment: none
[2023-07-01 11:37:25] [config] guided-alignment-cost: mse
[2023-07-01 11:37:25] [config] guided-alignment-weight: 0.1
[2023-07-01 11:37:25] [config] ignore-model-config: false
[2023-07-01 11:37:25] [config] input-types:
[2023-07-01 11:37:25] [config]   []
[2023-07-01 11:37:25] [config] interpolate-env-vars: false
[2023-07-01 11:37:25] [config] keep-best: false
[2023-07-01 11:37:25] [config] label-smoothing: 0.1
[2023-07-01 11:37:25] [config] layer-normalization: false
[2023-07-01 11:37:25] [config] learn-rate: 0.0003
[2023-07-01 11:37:25] [config] lemma-dependency: ""
[2023-07-01 11:37:25] [config] lemma-dim-emb: 0
[2023-07-01 11:37:25] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:37:25] [config] log-level: info
[2023-07-01 11:37:25] [config] log-time-zone: ""
[2023-07-01 11:37:25] [config] logical-epoch:
[2023-07-01 11:37:25] [config]   - 1e
[2023-07-01 11:37:25] [config]   - 0
[2023-07-01 11:37:25] [config] lr-decay: 0
[2023-07-01 11:37:25] [config] lr-decay-freq: 50000
[2023-07-01 11:37:25] [config] lr-decay-inv-sqrt:
[2023-07-01 11:37:25] [config]   - 16000
[2023-07-01 11:37:25] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:37:25] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:37:25] [config] lr-decay-start:
[2023-07-01 11:37:25] [config]   - 10
[2023-07-01 11:37:25] [config]   - 1
[2023-07-01 11:37:25] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:37:25] [config] lr-report: true
[2023-07-01 11:37:25] [config] lr-warmup: 16000
[2023-07-01 11:37:25] [config] lr-warmup-at-reload: false
[2023-07-01 11:37:25] [config] lr-warmup-cycle: false
[2023-07-01 11:37:25] [config] lr-warmup-start-rate: 0
[2023-07-01 11:37:25] [config] max-length: 100
[2023-07-01 11:37:25] [config] max-length-crop: false
[2023-07-01 11:37:25] [config] max-length-factor: 3
[2023-07-01 11:37:25] [config] maxi-batch: 100
[2023-07-01 11:37:25] [config] maxi-batch-sort: trg
[2023-07-01 11:37:25] [config] mini-batch: 1000
[2023-07-01 11:37:25] [config] mini-batch-fit: true
[2023-07-01 11:37:25] [config] mini-batch-fit-step: 10
[2023-07-01 11:37:25] [config] mini-batch-round-up: true
[2023-07-01 11:37:25] [config] mini-batch-track-lr: false
[2023-07-01 11:37:25] [config] mini-batch-warmup: 0
[2023-07-01 11:37:25] [config] mini-batch-words: 0
[2023-07-01 11:37:25] [config] mini-batch-words-ref: 0
[2023-07-01 11:37:25] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:37:25] [config] multi-loss-type: sum
[2023-07-01 11:37:25] [config] n-best: false
[2023-07-01 11:37:25] [config] no-nccl: false
[2023-07-01 11:37:25] [config] no-reload: false
[2023-07-01 11:37:25] [config] no-restore-corpus: false
[2023-07-01 11:37:25] [config] normalize: 1
[2023-07-01 11:37:25] [config] normalize-gradient: false
[2023-07-01 11:37:25] [config] num-devices: 0
[2023-07-01 11:37:25] [config] optimizer: adam
[2023-07-01 11:37:25] [config] optimizer-delay: 1
[2023-07-01 11:37:25] [config] optimizer-params:
[2023-07-01 11:37:25] [config]   - 0.9
[2023-07-01 11:37:25] [config]   - 0.98
[2023-07-01 11:37:25] [config]   - 1e-09
[2023-07-01 11:37:25] [config] output-omit-bias: false
[2023-07-01 11:37:25] [config] overwrite: true
[2023-07-01 11:37:25] [config] precision:
[2023-07-01 11:37:25] [config]   - float32
[2023-07-01 11:37:25] [config]   - float32
[2023-07-01 11:37:25] [config] pretrained-model: ""
[2023-07-01 11:37:25] [config] quantize-biases: false
[2023-07-01 11:37:25] [config] quantize-bits: 0
[2023-07-01 11:37:25] [config] quantize-log-based: false
[2023-07-01 11:37:25] [config] quantize-optimization-steps: 0
[2023-07-01 11:37:25] [config] quiet: false
[2023-07-01 11:37:25] [config] quiet-translation: true
[2023-07-01 11:37:25] [config] relative-paths: false
[2023-07-01 11:37:25] [config] right-left: false
[2023-07-01 11:37:25] [config] save-freq: 10000u
[2023-07-01 11:37:25] [config] seed: 1234
[2023-07-01 11:37:25] [config] sentencepiece-alphas:
[2023-07-01 11:37:25] [config]   []
[2023-07-01 11:37:25] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:37:25] [config] sentencepiece-options: ""
[2023-07-01 11:37:25] [config] sharding: global
[2023-07-01 11:37:25] [config] shuffle: data
[2023-07-01 11:37:25] [config] shuffle-in-ram: false
[2023-07-01 11:37:25] [config] sigterm: save-and-exit
[2023-07-01 11:37:25] [config] skip: false
[2023-07-01 11:37:25] [config] sqlite: ""
[2023-07-01 11:37:25] [config] sqlite-drop: false
[2023-07-01 11:37:25] [config] sync-freq: 200u
[2023-07-01 11:37:25] [config] sync-sgd: true
[2023-07-01 11:37:25] [config] tempdir: /tmp
[2023-07-01 11:37:25] [config] tied-embeddings: false
[2023-07-01 11:37:25] [config] tied-embeddings-all: true
[2023-07-01 11:37:25] [config] tied-embeddings-src: false
[2023-07-01 11:37:25] [config] train-embedder-rank:
[2023-07-01 11:37:25] [config]   []
[2023-07-01 11:37:25] [config] train-sets:
[2023-07-01 11:37:25] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:37:25] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:37:25] [config] transformer-aan-activation: swish
[2023-07-01 11:37:25] [config] transformer-aan-depth: 2
[2023-07-01 11:37:25] [config] transformer-aan-nogate: false
[2023-07-01 11:37:25] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:37:25] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:37:25] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:37:25] [config] transformer-depth-scaling: false
[2023-07-01 11:37:25] [config] transformer-dim-aan: 2048
[2023-07-01 11:37:25] [config] transformer-dim-ffn: 2048
[2023-07-01 11:37:25] [config] transformer-dropout: 0.1
[2023-07-01 11:37:25] [config] transformer-dropout-attention: 0
[2023-07-01 11:37:25] [config] transformer-dropout-ffn: 0
[2023-07-01 11:37:25] [config] transformer-ffn-activation: swish
[2023-07-01 11:37:25] [config] transformer-ffn-depth: 2
[2023-07-01 11:37:25] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:37:25] [config] transformer-heads: 8
[2023-07-01 11:37:25] [config] transformer-no-projection: false
[2023-07-01 11:37:25] [config] transformer-pool: false
[2023-07-01 11:37:25] [config] transformer-postprocess: dan
[2023-07-01 11:37:25] [config] transformer-postprocess-emb: d
[2023-07-01 11:37:25] [config] transformer-postprocess-top: ""
[2023-07-01 11:37:25] [config] transformer-preprocess: ""
[2023-07-01 11:37:25] [config] transformer-tied-layers:
[2023-07-01 11:37:25] [config]   []
[2023-07-01 11:37:25] [config] transformer-train-position-embeddings: false
[2023-07-01 11:37:25] [config] tsv: false
[2023-07-01 11:37:25] [config] tsv-fields: 0
[2023-07-01 11:37:25] [config] type: transformer
[2023-07-01 11:37:25] [config] ulr: false
[2023-07-01 11:37:25] [config] ulr-dim-emb: 0
[2023-07-01 11:37:25] [config] ulr-dropout: 0
[2023-07-01 11:37:25] [config] ulr-keys-vectors: ""
[2023-07-01 11:37:25] [config] ulr-query-vectors: ""
[2023-07-01 11:37:25] [config] ulr-softmax-temperature: 1
[2023-07-01 11:37:25] [config] ulr-trainable-transformation: false
[2023-07-01 11:37:25] [config] unlikelihood-loss: false
[2023-07-01 11:37:25] [config] valid-freq: 50000000
[2023-07-01 11:37:25] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:37:25] [config] valid-max-length: 1000
[2023-07-01 11:37:25] [config] valid-metrics:
[2023-07-01 11:37:25] [config]   - cross-entropy
[2023-07-01 11:37:25] [config]   - translation
[2023-07-01 11:37:25] [config] valid-mini-batch: 64
[2023-07-01 11:37:25] [config] valid-reset-stalled: false
[2023-07-01 11:37:25] [config] valid-script-args:
[2023-07-01 11:37:25] [config]   []
[2023-07-01 11:37:25] [config] valid-script-path: ""
[2023-07-01 11:37:25] [config] valid-sets:
[2023-07-01 11:37:25] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:37:25] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:37:25] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:37:25] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:37:25] [config] vocabs:
[2023-07-01 11:37:25] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:37:25] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:37:25] [config] word-penalty: 0
[2023-07-01 11:37:25] [config] word-scores: false
[2023-07-01 11:37:25] [config] workspace: 2048
[2023-07-01 11:37:25] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:37:25] Using synchronous SGD
[2023-07-01 11:37:25] Synced seed 1234
[2023-07-01 11:37:25] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:37:25] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:37:25] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:37:25] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:37:25] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:37:25] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:37:26] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:37:26] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:37:26] [comm] Using global sharding
[2023-07-01 11:37:26] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:37:26] [training] Using 1 GPUs
[2023-07-01 11:37:26] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:37:26] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:37:27] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:37:27] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:37:34] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:37:34] [valid] No post-processing script given for validating translator
[2023-07-01 11:37:34] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:37:34] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:37:34] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:37:34] [comm] Using global sharding
[2023-07-01 11:37:34] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:37:34] [training] Using 1 GPUs
[2023-07-01 11:37:34] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:37:35] Allocating memory for general optimizer shards
[2023-07-01 11:37:35] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:37:35] Loading Adam parameters
[2023-07-01 11:37:35] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:37:35] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:37:35] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:37:35] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:37:35] [data] Shuffling data
[2023-07-01 11:37:35] [data] Done reading 20,192 sentences
[2023-07-01 11:37:35] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:37:35] Training started
[2023-07-01 11:37:35] Training finished
[2023-07-01 11:37:39] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:37:39] [marian] Running on node20.datos.cluster.uy as process 18880 with command line:
[2023-07-01 11:37:39] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 127 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:37:39] [config] after: 0e
[2023-07-01 11:37:39] [config] after-batches: 0
[2023-07-01 11:37:39] [config] after-epochs: 127
[2023-07-01 11:37:39] [config] all-caps-every: 0
[2023-07-01 11:37:39] [config] allow-unk: false
[2023-07-01 11:37:39] [config] authors: false
[2023-07-01 11:37:39] [config] beam-size: 12
[2023-07-01 11:37:39] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:37:39] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:37:39] [config] bert-masking-fraction: 0.15
[2023-07-01 11:37:39] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:37:39] [config] bert-train-type-embeddings: true
[2023-07-01 11:37:39] [config] bert-type-vocab-size: 2
[2023-07-01 11:37:39] [config] build-info: ""
[2023-07-01 11:37:39] [config] check-gradient-nan: false
[2023-07-01 11:37:39] [config] check-nan: false
[2023-07-01 11:37:39] [config] cite: false
[2023-07-01 11:37:39] [config] clip-norm: 5
[2023-07-01 11:37:39] [config] cost-scaling:
[2023-07-01 11:37:39] [config]   []
[2023-07-01 11:37:39] [config] cost-type: ce-sum
[2023-07-01 11:37:39] [config] cpu-threads: 0
[2023-07-01 11:37:39] [config] data-threads: 8
[2023-07-01 11:37:39] [config] data-weighting: ""
[2023-07-01 11:37:39] [config] data-weighting-type: sentence
[2023-07-01 11:37:39] [config] dec-cell: gru
[2023-07-01 11:37:39] [config] dec-cell-base-depth: 2
[2023-07-01 11:37:39] [config] dec-cell-high-depth: 1
[2023-07-01 11:37:39] [config] dec-depth: 2
[2023-07-01 11:37:39] [config] devices:
[2023-07-01 11:37:39] [config]   - 0
[2023-07-01 11:37:39] [config] dim-emb: 512
[2023-07-01 11:37:39] [config] dim-rnn: 1024
[2023-07-01 11:37:39] [config] dim-vocabs:
[2023-07-01 11:37:39] [config]   - 16384
[2023-07-01 11:37:39] [config]   - 16384
[2023-07-01 11:37:39] [config] disp-first: 0
[2023-07-01 11:37:39] [config] disp-freq: 1000u
[2023-07-01 11:37:39] [config] disp-label-counts: true
[2023-07-01 11:37:39] [config] dropout-rnn: 0
[2023-07-01 11:37:39] [config] dropout-src: 0
[2023-07-01 11:37:39] [config] dropout-trg: 0
[2023-07-01 11:37:39] [config] dump-config: ""
[2023-07-01 11:37:39] [config] dynamic-gradient-scaling:
[2023-07-01 11:37:39] [config]   []
[2023-07-01 11:37:39] [config] early-stopping: 10
[2023-07-01 11:37:39] [config] early-stopping-on: first
[2023-07-01 11:37:39] [config] embedding-fix-src: false
[2023-07-01 11:37:39] [config] embedding-fix-trg: false
[2023-07-01 11:37:39] [config] embedding-normalization: false
[2023-07-01 11:37:39] [config] embedding-vectors:
[2023-07-01 11:37:39] [config]   []
[2023-07-01 11:37:39] [config] enc-cell: gru
[2023-07-01 11:37:39] [config] enc-cell-depth: 1
[2023-07-01 11:37:39] [config] enc-depth: 2
[2023-07-01 11:37:39] [config] enc-type: bidirectional
[2023-07-01 11:37:39] [config] english-title-case-every: 0
[2023-07-01 11:37:39] [config] exponential-smoothing: 0.0001
[2023-07-01 11:37:39] [config] factor-weight: 1
[2023-07-01 11:37:39] [config] factors-combine: sum
[2023-07-01 11:37:39] [config] factors-dim-emb: 0
[2023-07-01 11:37:39] [config] gradient-checkpointing: false
[2023-07-01 11:37:39] [config] gradient-norm-average-window: 100
[2023-07-01 11:37:39] [config] guided-alignment: none
[2023-07-01 11:37:39] [config] guided-alignment-cost: mse
[2023-07-01 11:37:39] [config] guided-alignment-weight: 0.1
[2023-07-01 11:37:39] [config] ignore-model-config: false
[2023-07-01 11:37:39] [config] input-types:
[2023-07-01 11:37:39] [config]   []
[2023-07-01 11:37:39] [config] interpolate-env-vars: false
[2023-07-01 11:37:39] [config] keep-best: false
[2023-07-01 11:37:39] [config] label-smoothing: 0.1
[2023-07-01 11:37:39] [config] layer-normalization: false
[2023-07-01 11:37:39] [config] learn-rate: 0.0003
[2023-07-01 11:37:39] [config] lemma-dependency: ""
[2023-07-01 11:37:39] [config] lemma-dim-emb: 0
[2023-07-01 11:37:39] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:37:39] [config] log-level: info
[2023-07-01 11:37:39] [config] log-time-zone: ""
[2023-07-01 11:37:39] [config] logical-epoch:
[2023-07-01 11:37:39] [config]   - 1e
[2023-07-01 11:37:39] [config]   - 0
[2023-07-01 11:37:39] [config] lr-decay: 0
[2023-07-01 11:37:39] [config] lr-decay-freq: 50000
[2023-07-01 11:37:39] [config] lr-decay-inv-sqrt:
[2023-07-01 11:37:39] [config]   - 16000
[2023-07-01 11:37:39] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:37:39] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:37:39] [config] lr-decay-start:
[2023-07-01 11:37:39] [config]   - 10
[2023-07-01 11:37:39] [config]   - 1
[2023-07-01 11:37:39] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:37:39] [config] lr-report: true
[2023-07-01 11:37:39] [config] lr-warmup: 16000
[2023-07-01 11:37:39] [config] lr-warmup-at-reload: false
[2023-07-01 11:37:39] [config] lr-warmup-cycle: false
[2023-07-01 11:37:39] [config] lr-warmup-start-rate: 0
[2023-07-01 11:37:39] [config] max-length: 100
[2023-07-01 11:37:39] [config] max-length-crop: false
[2023-07-01 11:37:39] [config] max-length-factor: 3
[2023-07-01 11:37:39] [config] maxi-batch: 100
[2023-07-01 11:37:39] [config] maxi-batch-sort: trg
[2023-07-01 11:37:39] [config] mini-batch: 1000
[2023-07-01 11:37:39] [config] mini-batch-fit: true
[2023-07-01 11:37:39] [config] mini-batch-fit-step: 10
[2023-07-01 11:37:39] [config] mini-batch-round-up: true
[2023-07-01 11:37:39] [config] mini-batch-track-lr: false
[2023-07-01 11:37:39] [config] mini-batch-warmup: 0
[2023-07-01 11:37:39] [config] mini-batch-words: 0
[2023-07-01 11:37:39] [config] mini-batch-words-ref: 0
[2023-07-01 11:37:39] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:37:39] [config] multi-loss-type: sum
[2023-07-01 11:37:39] [config] n-best: false
[2023-07-01 11:37:39] [config] no-nccl: false
[2023-07-01 11:37:39] [config] no-reload: false
[2023-07-01 11:37:39] [config] no-restore-corpus: false
[2023-07-01 11:37:39] [config] normalize: 1
[2023-07-01 11:37:39] [config] normalize-gradient: false
[2023-07-01 11:37:39] [config] num-devices: 0
[2023-07-01 11:37:39] [config] optimizer: adam
[2023-07-01 11:37:39] [config] optimizer-delay: 1
[2023-07-01 11:37:39] [config] optimizer-params:
[2023-07-01 11:37:39] [config]   - 0.9
[2023-07-01 11:37:39] [config]   - 0.98
[2023-07-01 11:37:39] [config]   - 1e-09
[2023-07-01 11:37:39] [config] output-omit-bias: false
[2023-07-01 11:37:39] [config] overwrite: true
[2023-07-01 11:37:39] [config] precision:
[2023-07-01 11:37:39] [config]   - float32
[2023-07-01 11:37:39] [config]   - float32
[2023-07-01 11:37:39] [config] pretrained-model: ""
[2023-07-01 11:37:39] [config] quantize-biases: false
[2023-07-01 11:37:39] [config] quantize-bits: 0
[2023-07-01 11:37:39] [config] quantize-log-based: false
[2023-07-01 11:37:39] [config] quantize-optimization-steps: 0
[2023-07-01 11:37:39] [config] quiet: false
[2023-07-01 11:37:39] [config] quiet-translation: true
[2023-07-01 11:37:39] [config] relative-paths: false
[2023-07-01 11:37:39] [config] right-left: false
[2023-07-01 11:37:39] [config] save-freq: 10000u
[2023-07-01 11:37:39] [config] seed: 1234
[2023-07-01 11:37:39] [config] sentencepiece-alphas:
[2023-07-01 11:37:39] [config]   []
[2023-07-01 11:37:39] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:37:39] [config] sentencepiece-options: ""
[2023-07-01 11:37:39] [config] sharding: global
[2023-07-01 11:37:39] [config] shuffle: data
[2023-07-01 11:37:39] [config] shuffle-in-ram: false
[2023-07-01 11:37:39] [config] sigterm: save-and-exit
[2023-07-01 11:37:39] [config] skip: false
[2023-07-01 11:37:39] [config] sqlite: ""
[2023-07-01 11:37:39] [config] sqlite-drop: false
[2023-07-01 11:37:39] [config] sync-freq: 200u
[2023-07-01 11:37:39] [config] sync-sgd: true
[2023-07-01 11:37:39] [config] tempdir: /tmp
[2023-07-01 11:37:39] [config] tied-embeddings: false
[2023-07-01 11:37:39] [config] tied-embeddings-all: true
[2023-07-01 11:37:39] [config] tied-embeddings-src: false
[2023-07-01 11:37:39] [config] train-embedder-rank:
[2023-07-01 11:37:39] [config]   []
[2023-07-01 11:37:39] [config] train-sets:
[2023-07-01 11:37:39] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:37:39] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:37:39] [config] transformer-aan-activation: swish
[2023-07-01 11:37:39] [config] transformer-aan-depth: 2
[2023-07-01 11:37:39] [config] transformer-aan-nogate: false
[2023-07-01 11:37:39] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:37:39] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:37:39] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:37:39] [config] transformer-depth-scaling: false
[2023-07-01 11:37:39] [config] transformer-dim-aan: 2048
[2023-07-01 11:37:39] [config] transformer-dim-ffn: 2048
[2023-07-01 11:37:39] [config] transformer-dropout: 0.1
[2023-07-01 11:37:39] [config] transformer-dropout-attention: 0
[2023-07-01 11:37:39] [config] transformer-dropout-ffn: 0
[2023-07-01 11:37:39] [config] transformer-ffn-activation: swish
[2023-07-01 11:37:39] [config] transformer-ffn-depth: 2
[2023-07-01 11:37:39] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:37:39] [config] transformer-heads: 8
[2023-07-01 11:37:39] [config] transformer-no-projection: false
[2023-07-01 11:37:39] [config] transformer-pool: false
[2023-07-01 11:37:39] [config] transformer-postprocess: dan
[2023-07-01 11:37:39] [config] transformer-postprocess-emb: d
[2023-07-01 11:37:39] [config] transformer-postprocess-top: ""
[2023-07-01 11:37:39] [config] transformer-preprocess: ""
[2023-07-01 11:37:39] [config] transformer-tied-layers:
[2023-07-01 11:37:39] [config]   []
[2023-07-01 11:37:39] [config] transformer-train-position-embeddings: false
[2023-07-01 11:37:39] [config] tsv: false
[2023-07-01 11:37:39] [config] tsv-fields: 0
[2023-07-01 11:37:39] [config] type: transformer
[2023-07-01 11:37:39] [config] ulr: false
[2023-07-01 11:37:39] [config] ulr-dim-emb: 0
[2023-07-01 11:37:39] [config] ulr-dropout: 0
[2023-07-01 11:37:39] [config] ulr-keys-vectors: ""
[2023-07-01 11:37:39] [config] ulr-query-vectors: ""
[2023-07-01 11:37:39] [config] ulr-softmax-temperature: 1
[2023-07-01 11:37:39] [config] ulr-trainable-transformation: false
[2023-07-01 11:37:39] [config] unlikelihood-loss: false
[2023-07-01 11:37:39] [config] valid-freq: 50000000
[2023-07-01 11:37:39] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:37:39] [config] valid-max-length: 1000
[2023-07-01 11:37:39] [config] valid-metrics:
[2023-07-01 11:37:39] [config]   - cross-entropy
[2023-07-01 11:37:39] [config]   - translation
[2023-07-01 11:37:39] [config] valid-mini-batch: 64
[2023-07-01 11:37:39] [config] valid-reset-stalled: false
[2023-07-01 11:37:39] [config] valid-script-args:
[2023-07-01 11:37:39] [config]   []
[2023-07-01 11:37:39] [config] valid-script-path: ""
[2023-07-01 11:37:39] [config] valid-sets:
[2023-07-01 11:37:39] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:37:39] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:37:39] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:37:39] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:37:39] [config] vocabs:
[2023-07-01 11:37:39] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:37:39] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:37:39] [config] word-penalty: 0
[2023-07-01 11:37:39] [config] word-scores: false
[2023-07-01 11:37:39] [config] workspace: 2048
[2023-07-01 11:37:39] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:37:39] Using synchronous SGD
[2023-07-01 11:37:39] Synced seed 1234
[2023-07-01 11:37:39] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:37:39] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:37:39] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:37:39] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:37:39] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:37:39] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:37:40] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:37:40] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:37:40] [comm] Using global sharding
[2023-07-01 11:37:40] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:37:40] [training] Using 1 GPUs
[2023-07-01 11:37:40] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:37:40] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:37:40] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:37:40] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:37:48] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:37:48] [valid] No post-processing script given for validating translator
[2023-07-01 11:37:48] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:37:48] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:37:48] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:37:48] [comm] Using global sharding
[2023-07-01 11:37:48] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:37:48] [training] Using 1 GPUs
[2023-07-01 11:37:48] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:37:48] Allocating memory for general optimizer shards
[2023-07-01 11:37:48] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:37:48] Loading Adam parameters
[2023-07-01 11:37:48] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:37:48] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:37:48] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:37:48] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:37:48] [data] Shuffling data
[2023-07-01 11:37:48] [data] Done reading 20,192 sentences
[2023-07-01 11:37:48] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:37:48] Training started
[2023-07-01 11:37:48] Training finished
[2023-07-01 11:37:52] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:37:52] [marian] Running on node20.datos.cluster.uy as process 18941 with command line:
[2023-07-01 11:37:52] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 128 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:37:52] [config] after: 0e
[2023-07-01 11:37:52] [config] after-batches: 0
[2023-07-01 11:37:52] [config] after-epochs: 128
[2023-07-01 11:37:52] [config] all-caps-every: 0
[2023-07-01 11:37:52] [config] allow-unk: false
[2023-07-01 11:37:52] [config] authors: false
[2023-07-01 11:37:52] [config] beam-size: 12
[2023-07-01 11:37:52] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:37:52] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:37:52] [config] bert-masking-fraction: 0.15
[2023-07-01 11:37:52] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:37:52] [config] bert-train-type-embeddings: true
[2023-07-01 11:37:52] [config] bert-type-vocab-size: 2
[2023-07-01 11:37:52] [config] build-info: ""
[2023-07-01 11:37:52] [config] check-gradient-nan: false
[2023-07-01 11:37:52] [config] check-nan: false
[2023-07-01 11:37:52] [config] cite: false
[2023-07-01 11:37:52] [config] clip-norm: 5
[2023-07-01 11:37:52] [config] cost-scaling:
[2023-07-01 11:37:52] [config]   []
[2023-07-01 11:37:52] [config] cost-type: ce-sum
[2023-07-01 11:37:52] [config] cpu-threads: 0
[2023-07-01 11:37:52] [config] data-threads: 8
[2023-07-01 11:37:52] [config] data-weighting: ""
[2023-07-01 11:37:52] [config] data-weighting-type: sentence
[2023-07-01 11:37:52] [config] dec-cell: gru
[2023-07-01 11:37:52] [config] dec-cell-base-depth: 2
[2023-07-01 11:37:52] [config] dec-cell-high-depth: 1
[2023-07-01 11:37:52] [config] dec-depth: 2
[2023-07-01 11:37:52] [config] devices:
[2023-07-01 11:37:52] [config]   - 0
[2023-07-01 11:37:52] [config] dim-emb: 512
[2023-07-01 11:37:52] [config] dim-rnn: 1024
[2023-07-01 11:37:52] [config] dim-vocabs:
[2023-07-01 11:37:52] [config]   - 16384
[2023-07-01 11:37:52] [config]   - 16384
[2023-07-01 11:37:52] [config] disp-first: 0
[2023-07-01 11:37:52] [config] disp-freq: 1000u
[2023-07-01 11:37:52] [config] disp-label-counts: true
[2023-07-01 11:37:52] [config] dropout-rnn: 0
[2023-07-01 11:37:52] [config] dropout-src: 0
[2023-07-01 11:37:52] [config] dropout-trg: 0
[2023-07-01 11:37:52] [config] dump-config: ""
[2023-07-01 11:37:52] [config] dynamic-gradient-scaling:
[2023-07-01 11:37:52] [config]   []
[2023-07-01 11:37:52] [config] early-stopping: 10
[2023-07-01 11:37:52] [config] early-stopping-on: first
[2023-07-01 11:37:52] [config] embedding-fix-src: false
[2023-07-01 11:37:52] [config] embedding-fix-trg: false
[2023-07-01 11:37:52] [config] embedding-normalization: false
[2023-07-01 11:37:52] [config] embedding-vectors:
[2023-07-01 11:37:52] [config]   []
[2023-07-01 11:37:52] [config] enc-cell: gru
[2023-07-01 11:37:52] [config] enc-cell-depth: 1
[2023-07-01 11:37:52] [config] enc-depth: 2
[2023-07-01 11:37:52] [config] enc-type: bidirectional
[2023-07-01 11:37:52] [config] english-title-case-every: 0
[2023-07-01 11:37:52] [config] exponential-smoothing: 0.0001
[2023-07-01 11:37:52] [config] factor-weight: 1
[2023-07-01 11:37:52] [config] factors-combine: sum
[2023-07-01 11:37:52] [config] factors-dim-emb: 0
[2023-07-01 11:37:52] [config] gradient-checkpointing: false
[2023-07-01 11:37:52] [config] gradient-norm-average-window: 100
[2023-07-01 11:37:52] [config] guided-alignment: none
[2023-07-01 11:37:52] [config] guided-alignment-cost: mse
[2023-07-01 11:37:52] [config] guided-alignment-weight: 0.1
[2023-07-01 11:37:52] [config] ignore-model-config: false
[2023-07-01 11:37:52] [config] input-types:
[2023-07-01 11:37:52] [config]   []
[2023-07-01 11:37:52] [config] interpolate-env-vars: false
[2023-07-01 11:37:52] [config] keep-best: false
[2023-07-01 11:37:52] [config] label-smoothing: 0.1
[2023-07-01 11:37:52] [config] layer-normalization: false
[2023-07-01 11:37:52] [config] learn-rate: 0.0003
[2023-07-01 11:37:52] [config] lemma-dependency: ""
[2023-07-01 11:37:52] [config] lemma-dim-emb: 0
[2023-07-01 11:37:52] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:37:52] [config] log-level: info
[2023-07-01 11:37:52] [config] log-time-zone: ""
[2023-07-01 11:37:52] [config] logical-epoch:
[2023-07-01 11:37:52] [config]   - 1e
[2023-07-01 11:37:52] [config]   - 0
[2023-07-01 11:37:52] [config] lr-decay: 0
[2023-07-01 11:37:52] [config] lr-decay-freq: 50000
[2023-07-01 11:37:52] [config] lr-decay-inv-sqrt:
[2023-07-01 11:37:52] [config]   - 16000
[2023-07-01 11:37:52] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:37:52] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:37:52] [config] lr-decay-start:
[2023-07-01 11:37:52] [config]   - 10
[2023-07-01 11:37:52] [config]   - 1
[2023-07-01 11:37:52] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:37:52] [config] lr-report: true
[2023-07-01 11:37:52] [config] lr-warmup: 16000
[2023-07-01 11:37:52] [config] lr-warmup-at-reload: false
[2023-07-01 11:37:52] [config] lr-warmup-cycle: false
[2023-07-01 11:37:52] [config] lr-warmup-start-rate: 0
[2023-07-01 11:37:52] [config] max-length: 100
[2023-07-01 11:37:52] [config] max-length-crop: false
[2023-07-01 11:37:52] [config] max-length-factor: 3
[2023-07-01 11:37:52] [config] maxi-batch: 100
[2023-07-01 11:37:52] [config] maxi-batch-sort: trg
[2023-07-01 11:37:52] [config] mini-batch: 1000
[2023-07-01 11:37:52] [config] mini-batch-fit: true
[2023-07-01 11:37:52] [config] mini-batch-fit-step: 10
[2023-07-01 11:37:52] [config] mini-batch-round-up: true
[2023-07-01 11:37:52] [config] mini-batch-track-lr: false
[2023-07-01 11:37:52] [config] mini-batch-warmup: 0
[2023-07-01 11:37:52] [config] mini-batch-words: 0
[2023-07-01 11:37:52] [config] mini-batch-words-ref: 0
[2023-07-01 11:37:52] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:37:52] [config] multi-loss-type: sum
[2023-07-01 11:37:52] [config] n-best: false
[2023-07-01 11:37:52] [config] no-nccl: false
[2023-07-01 11:37:52] [config] no-reload: false
[2023-07-01 11:37:52] [config] no-restore-corpus: false
[2023-07-01 11:37:52] [config] normalize: 1
[2023-07-01 11:37:52] [config] normalize-gradient: false
[2023-07-01 11:37:52] [config] num-devices: 0
[2023-07-01 11:37:52] [config] optimizer: adam
[2023-07-01 11:37:52] [config] optimizer-delay: 1
[2023-07-01 11:37:52] [config] optimizer-params:
[2023-07-01 11:37:52] [config]   - 0.9
[2023-07-01 11:37:52] [config]   - 0.98
[2023-07-01 11:37:52] [config]   - 1e-09
[2023-07-01 11:37:52] [config] output-omit-bias: false
[2023-07-01 11:37:52] [config] overwrite: true
[2023-07-01 11:37:52] [config] precision:
[2023-07-01 11:37:52] [config]   - float32
[2023-07-01 11:37:52] [config]   - float32
[2023-07-01 11:37:52] [config] pretrained-model: ""
[2023-07-01 11:37:52] [config] quantize-biases: false
[2023-07-01 11:37:52] [config] quantize-bits: 0
[2023-07-01 11:37:52] [config] quantize-log-based: false
[2023-07-01 11:37:52] [config] quantize-optimization-steps: 0
[2023-07-01 11:37:52] [config] quiet: false
[2023-07-01 11:37:52] [config] quiet-translation: true
[2023-07-01 11:37:52] [config] relative-paths: false
[2023-07-01 11:37:52] [config] right-left: false
[2023-07-01 11:37:52] [config] save-freq: 10000u
[2023-07-01 11:37:52] [config] seed: 1234
[2023-07-01 11:37:52] [config] sentencepiece-alphas:
[2023-07-01 11:37:52] [config]   []
[2023-07-01 11:37:52] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:37:52] [config] sentencepiece-options: ""
[2023-07-01 11:37:52] [config] sharding: global
[2023-07-01 11:37:52] [config] shuffle: data
[2023-07-01 11:37:52] [config] shuffle-in-ram: false
[2023-07-01 11:37:52] [config] sigterm: save-and-exit
[2023-07-01 11:37:52] [config] skip: false
[2023-07-01 11:37:52] [config] sqlite: ""
[2023-07-01 11:37:52] [config] sqlite-drop: false
[2023-07-01 11:37:52] [config] sync-freq: 200u
[2023-07-01 11:37:52] [config] sync-sgd: true
[2023-07-01 11:37:52] [config] tempdir: /tmp
[2023-07-01 11:37:52] [config] tied-embeddings: false
[2023-07-01 11:37:52] [config] tied-embeddings-all: true
[2023-07-01 11:37:52] [config] tied-embeddings-src: false
[2023-07-01 11:37:52] [config] train-embedder-rank:
[2023-07-01 11:37:52] [config]   []
[2023-07-01 11:37:52] [config] train-sets:
[2023-07-01 11:37:52] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:37:52] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:37:52] [config] transformer-aan-activation: swish
[2023-07-01 11:37:52] [config] transformer-aan-depth: 2
[2023-07-01 11:37:52] [config] transformer-aan-nogate: false
[2023-07-01 11:37:52] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:37:52] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:37:52] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:37:52] [config] transformer-depth-scaling: false
[2023-07-01 11:37:52] [config] transformer-dim-aan: 2048
[2023-07-01 11:37:52] [config] transformer-dim-ffn: 2048
[2023-07-01 11:37:52] [config] transformer-dropout: 0.1
[2023-07-01 11:37:52] [config] transformer-dropout-attention: 0
[2023-07-01 11:37:52] [config] transformer-dropout-ffn: 0
[2023-07-01 11:37:52] [config] transformer-ffn-activation: swish
[2023-07-01 11:37:52] [config] transformer-ffn-depth: 2
[2023-07-01 11:37:52] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:37:52] [config] transformer-heads: 8
[2023-07-01 11:37:52] [config] transformer-no-projection: false
[2023-07-01 11:37:52] [config] transformer-pool: false
[2023-07-01 11:37:52] [config] transformer-postprocess: dan
[2023-07-01 11:37:52] [config] transformer-postprocess-emb: d
[2023-07-01 11:37:52] [config] transformer-postprocess-top: ""
[2023-07-01 11:37:52] [config] transformer-preprocess: ""
[2023-07-01 11:37:52] [config] transformer-tied-layers:
[2023-07-01 11:37:52] [config]   []
[2023-07-01 11:37:52] [config] transformer-train-position-embeddings: false
[2023-07-01 11:37:52] [config] tsv: false
[2023-07-01 11:37:52] [config] tsv-fields: 0
[2023-07-01 11:37:52] [config] type: transformer
[2023-07-01 11:37:52] [config] ulr: false
[2023-07-01 11:37:52] [config] ulr-dim-emb: 0
[2023-07-01 11:37:52] [config] ulr-dropout: 0
[2023-07-01 11:37:52] [config] ulr-keys-vectors: ""
[2023-07-01 11:37:52] [config] ulr-query-vectors: ""
[2023-07-01 11:37:52] [config] ulr-softmax-temperature: 1
[2023-07-01 11:37:52] [config] ulr-trainable-transformation: false
[2023-07-01 11:37:52] [config] unlikelihood-loss: false
[2023-07-01 11:37:52] [config] valid-freq: 50000000
[2023-07-01 11:37:52] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:37:52] [config] valid-max-length: 1000
[2023-07-01 11:37:52] [config] valid-metrics:
[2023-07-01 11:37:52] [config]   - cross-entropy
[2023-07-01 11:37:52] [config]   - translation
[2023-07-01 11:37:52] [config] valid-mini-batch: 64
[2023-07-01 11:37:52] [config] valid-reset-stalled: false
[2023-07-01 11:37:52] [config] valid-script-args:
[2023-07-01 11:37:52] [config]   []
[2023-07-01 11:37:52] [config] valid-script-path: ""
[2023-07-01 11:37:52] [config] valid-sets:
[2023-07-01 11:37:52] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:37:52] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:37:52] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:37:52] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:37:52] [config] vocabs:
[2023-07-01 11:37:52] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:37:52] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:37:52] [config] word-penalty: 0
[2023-07-01 11:37:52] [config] word-scores: false
[2023-07-01 11:37:52] [config] workspace: 2048
[2023-07-01 11:37:52] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:37:52] Using synchronous SGD
[2023-07-01 11:37:52] Synced seed 1234
[2023-07-01 11:37:52] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:37:52] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:37:52] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:37:52] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:37:52] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:37:52] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:37:53] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:37:53] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:37:53] [comm] Using global sharding
[2023-07-01 11:37:53] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:37:53] [training] Using 1 GPUs
[2023-07-01 11:37:53] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:37:53] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:37:53] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:37:54] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:38:01] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:38:01] [valid] No post-processing script given for validating translator
[2023-07-01 11:38:01] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:38:01] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:38:01] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:38:01] [comm] Using global sharding
[2023-07-01 11:38:01] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:38:01] [training] Using 1 GPUs
[2023-07-01 11:38:01] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:38:02] Allocating memory for general optimizer shards
[2023-07-01 11:38:02] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:38:02] Loading Adam parameters
[2023-07-01 11:38:02] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:38:02] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:38:02] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:38:02] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:38:02] [data] Shuffling data
[2023-07-01 11:38:02] [data] Done reading 20,192 sentences
[2023-07-01 11:38:02] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:38:02] Training started
[2023-07-01 11:38:02] Training finished
[2023-07-01 11:38:05] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:38:05] [marian] Running on node20.datos.cluster.uy as process 19000 with command line:
[2023-07-01 11:38:05] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 129 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:38:05] [config] after: 0e
[2023-07-01 11:38:05] [config] after-batches: 0
[2023-07-01 11:38:05] [config] after-epochs: 129
[2023-07-01 11:38:05] [config] all-caps-every: 0
[2023-07-01 11:38:05] [config] allow-unk: false
[2023-07-01 11:38:05] [config] authors: false
[2023-07-01 11:38:05] [config] beam-size: 12
[2023-07-01 11:38:05] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:38:05] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:38:05] [config] bert-masking-fraction: 0.15
[2023-07-01 11:38:05] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:38:05] [config] bert-train-type-embeddings: true
[2023-07-01 11:38:05] [config] bert-type-vocab-size: 2
[2023-07-01 11:38:05] [config] build-info: ""
[2023-07-01 11:38:05] [config] check-gradient-nan: false
[2023-07-01 11:38:05] [config] check-nan: false
[2023-07-01 11:38:05] [config] cite: false
[2023-07-01 11:38:05] [config] clip-norm: 5
[2023-07-01 11:38:05] [config] cost-scaling:
[2023-07-01 11:38:05] [config]   []
[2023-07-01 11:38:05] [config] cost-type: ce-sum
[2023-07-01 11:38:05] [config] cpu-threads: 0
[2023-07-01 11:38:05] [config] data-threads: 8
[2023-07-01 11:38:05] [config] data-weighting: ""
[2023-07-01 11:38:05] [config] data-weighting-type: sentence
[2023-07-01 11:38:05] [config] dec-cell: gru
[2023-07-01 11:38:05] [config] dec-cell-base-depth: 2
[2023-07-01 11:38:05] [config] dec-cell-high-depth: 1
[2023-07-01 11:38:05] [config] dec-depth: 2
[2023-07-01 11:38:05] [config] devices:
[2023-07-01 11:38:05] [config]   - 0
[2023-07-01 11:38:05] [config] dim-emb: 512
[2023-07-01 11:38:05] [config] dim-rnn: 1024
[2023-07-01 11:38:05] [config] dim-vocabs:
[2023-07-01 11:38:05] [config]   - 16384
[2023-07-01 11:38:05] [config]   - 16384
[2023-07-01 11:38:05] [config] disp-first: 0
[2023-07-01 11:38:05] [config] disp-freq: 1000u
[2023-07-01 11:38:05] [config] disp-label-counts: true
[2023-07-01 11:38:05] [config] dropout-rnn: 0
[2023-07-01 11:38:05] [config] dropout-src: 0
[2023-07-01 11:38:05] [config] dropout-trg: 0
[2023-07-01 11:38:05] [config] dump-config: ""
[2023-07-01 11:38:05] [config] dynamic-gradient-scaling:
[2023-07-01 11:38:05] [config]   []
[2023-07-01 11:38:05] [config] early-stopping: 10
[2023-07-01 11:38:05] [config] early-stopping-on: first
[2023-07-01 11:38:05] [config] embedding-fix-src: false
[2023-07-01 11:38:05] [config] embedding-fix-trg: false
[2023-07-01 11:38:05] [config] embedding-normalization: false
[2023-07-01 11:38:05] [config] embedding-vectors:
[2023-07-01 11:38:05] [config]   []
[2023-07-01 11:38:05] [config] enc-cell: gru
[2023-07-01 11:38:05] [config] enc-cell-depth: 1
[2023-07-01 11:38:05] [config] enc-depth: 2
[2023-07-01 11:38:05] [config] enc-type: bidirectional
[2023-07-01 11:38:05] [config] english-title-case-every: 0
[2023-07-01 11:38:05] [config] exponential-smoothing: 0.0001
[2023-07-01 11:38:05] [config] factor-weight: 1
[2023-07-01 11:38:05] [config] factors-combine: sum
[2023-07-01 11:38:05] [config] factors-dim-emb: 0
[2023-07-01 11:38:05] [config] gradient-checkpointing: false
[2023-07-01 11:38:05] [config] gradient-norm-average-window: 100
[2023-07-01 11:38:05] [config] guided-alignment: none
[2023-07-01 11:38:05] [config] guided-alignment-cost: mse
[2023-07-01 11:38:05] [config] guided-alignment-weight: 0.1
[2023-07-01 11:38:05] [config] ignore-model-config: false
[2023-07-01 11:38:05] [config] input-types:
[2023-07-01 11:38:05] [config]   []
[2023-07-01 11:38:05] [config] interpolate-env-vars: false
[2023-07-01 11:38:05] [config] keep-best: false
[2023-07-01 11:38:05] [config] label-smoothing: 0.1
[2023-07-01 11:38:05] [config] layer-normalization: false
[2023-07-01 11:38:05] [config] learn-rate: 0.0003
[2023-07-01 11:38:05] [config] lemma-dependency: ""
[2023-07-01 11:38:05] [config] lemma-dim-emb: 0
[2023-07-01 11:38:05] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:38:05] [config] log-level: info
[2023-07-01 11:38:05] [config] log-time-zone: ""
[2023-07-01 11:38:05] [config] logical-epoch:
[2023-07-01 11:38:05] [config]   - 1e
[2023-07-01 11:38:05] [config]   - 0
[2023-07-01 11:38:05] [config] lr-decay: 0
[2023-07-01 11:38:05] [config] lr-decay-freq: 50000
[2023-07-01 11:38:05] [config] lr-decay-inv-sqrt:
[2023-07-01 11:38:05] [config]   - 16000
[2023-07-01 11:38:05] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:38:05] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:38:05] [config] lr-decay-start:
[2023-07-01 11:38:05] [config]   - 10
[2023-07-01 11:38:05] [config]   - 1
[2023-07-01 11:38:05] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:38:05] [config] lr-report: true
[2023-07-01 11:38:05] [config] lr-warmup: 16000
[2023-07-01 11:38:05] [config] lr-warmup-at-reload: false
[2023-07-01 11:38:05] [config] lr-warmup-cycle: false
[2023-07-01 11:38:05] [config] lr-warmup-start-rate: 0
[2023-07-01 11:38:05] [config] max-length: 100
[2023-07-01 11:38:05] [config] max-length-crop: false
[2023-07-01 11:38:05] [config] max-length-factor: 3
[2023-07-01 11:38:05] [config] maxi-batch: 100
[2023-07-01 11:38:05] [config] maxi-batch-sort: trg
[2023-07-01 11:38:05] [config] mini-batch: 1000
[2023-07-01 11:38:05] [config] mini-batch-fit: true
[2023-07-01 11:38:05] [config] mini-batch-fit-step: 10
[2023-07-01 11:38:05] [config] mini-batch-round-up: true
[2023-07-01 11:38:05] [config] mini-batch-track-lr: false
[2023-07-01 11:38:05] [config] mini-batch-warmup: 0
[2023-07-01 11:38:05] [config] mini-batch-words: 0
[2023-07-01 11:38:05] [config] mini-batch-words-ref: 0
[2023-07-01 11:38:05] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:38:05] [config] multi-loss-type: sum
[2023-07-01 11:38:05] [config] n-best: false
[2023-07-01 11:38:05] [config] no-nccl: false
[2023-07-01 11:38:05] [config] no-reload: false
[2023-07-01 11:38:05] [config] no-restore-corpus: false
[2023-07-01 11:38:05] [config] normalize: 1
[2023-07-01 11:38:05] [config] normalize-gradient: false
[2023-07-01 11:38:05] [config] num-devices: 0
[2023-07-01 11:38:05] [config] optimizer: adam
[2023-07-01 11:38:05] [config] optimizer-delay: 1
[2023-07-01 11:38:05] [config] optimizer-params:
[2023-07-01 11:38:05] [config]   - 0.9
[2023-07-01 11:38:05] [config]   - 0.98
[2023-07-01 11:38:05] [config]   - 1e-09
[2023-07-01 11:38:05] [config] output-omit-bias: false
[2023-07-01 11:38:05] [config] overwrite: true
[2023-07-01 11:38:05] [config] precision:
[2023-07-01 11:38:05] [config]   - float32
[2023-07-01 11:38:05] [config]   - float32
[2023-07-01 11:38:05] [config] pretrained-model: ""
[2023-07-01 11:38:05] [config] quantize-biases: false
[2023-07-01 11:38:05] [config] quantize-bits: 0
[2023-07-01 11:38:05] [config] quantize-log-based: false
[2023-07-01 11:38:05] [config] quantize-optimization-steps: 0
[2023-07-01 11:38:05] [config] quiet: false
[2023-07-01 11:38:05] [config] quiet-translation: true
[2023-07-01 11:38:05] [config] relative-paths: false
[2023-07-01 11:38:05] [config] right-left: false
[2023-07-01 11:38:05] [config] save-freq: 10000u
[2023-07-01 11:38:05] [config] seed: 1234
[2023-07-01 11:38:05] [config] sentencepiece-alphas:
[2023-07-01 11:38:05] [config]   []
[2023-07-01 11:38:05] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:38:05] [config] sentencepiece-options: ""
[2023-07-01 11:38:05] [config] sharding: global
[2023-07-01 11:38:05] [config] shuffle: data
[2023-07-01 11:38:05] [config] shuffle-in-ram: false
[2023-07-01 11:38:05] [config] sigterm: save-and-exit
[2023-07-01 11:38:05] [config] skip: false
[2023-07-01 11:38:05] [config] sqlite: ""
[2023-07-01 11:38:05] [config] sqlite-drop: false
[2023-07-01 11:38:05] [config] sync-freq: 200u
[2023-07-01 11:38:05] [config] sync-sgd: true
[2023-07-01 11:38:05] [config] tempdir: /tmp
[2023-07-01 11:38:05] [config] tied-embeddings: false
[2023-07-01 11:38:05] [config] tied-embeddings-all: true
[2023-07-01 11:38:05] [config] tied-embeddings-src: false
[2023-07-01 11:38:05] [config] train-embedder-rank:
[2023-07-01 11:38:05] [config]   []
[2023-07-01 11:38:05] [config] train-sets:
[2023-07-01 11:38:05] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:38:05] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:38:05] [config] transformer-aan-activation: swish
[2023-07-01 11:38:05] [config] transformer-aan-depth: 2
[2023-07-01 11:38:05] [config] transformer-aan-nogate: false
[2023-07-01 11:38:05] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:38:05] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:38:05] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:38:05] [config] transformer-depth-scaling: false
[2023-07-01 11:38:05] [config] transformer-dim-aan: 2048
[2023-07-01 11:38:05] [config] transformer-dim-ffn: 2048
[2023-07-01 11:38:05] [config] transformer-dropout: 0.1
[2023-07-01 11:38:05] [config] transformer-dropout-attention: 0
[2023-07-01 11:38:05] [config] transformer-dropout-ffn: 0
[2023-07-01 11:38:05] [config] transformer-ffn-activation: swish
[2023-07-01 11:38:05] [config] transformer-ffn-depth: 2
[2023-07-01 11:38:05] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:38:05] [config] transformer-heads: 8
[2023-07-01 11:38:05] [config] transformer-no-projection: false
[2023-07-01 11:38:05] [config] transformer-pool: false
[2023-07-01 11:38:05] [config] transformer-postprocess: dan
[2023-07-01 11:38:05] [config] transformer-postprocess-emb: d
[2023-07-01 11:38:05] [config] transformer-postprocess-top: ""
[2023-07-01 11:38:05] [config] transformer-preprocess: ""
[2023-07-01 11:38:05] [config] transformer-tied-layers:
[2023-07-01 11:38:05] [config]   []
[2023-07-01 11:38:05] [config] transformer-train-position-embeddings: false
[2023-07-01 11:38:05] [config] tsv: false
[2023-07-01 11:38:05] [config] tsv-fields: 0
[2023-07-01 11:38:05] [config] type: transformer
[2023-07-01 11:38:05] [config] ulr: false
[2023-07-01 11:38:05] [config] ulr-dim-emb: 0
[2023-07-01 11:38:05] [config] ulr-dropout: 0
[2023-07-01 11:38:05] [config] ulr-keys-vectors: ""
[2023-07-01 11:38:05] [config] ulr-query-vectors: ""
[2023-07-01 11:38:05] [config] ulr-softmax-temperature: 1
[2023-07-01 11:38:05] [config] ulr-trainable-transformation: false
[2023-07-01 11:38:05] [config] unlikelihood-loss: false
[2023-07-01 11:38:05] [config] valid-freq: 50000000
[2023-07-01 11:38:05] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:38:05] [config] valid-max-length: 1000
[2023-07-01 11:38:05] [config] valid-metrics:
[2023-07-01 11:38:05] [config]   - cross-entropy
[2023-07-01 11:38:05] [config]   - translation
[2023-07-01 11:38:05] [config] valid-mini-batch: 64
[2023-07-01 11:38:05] [config] valid-reset-stalled: false
[2023-07-01 11:38:05] [config] valid-script-args:
[2023-07-01 11:38:05] [config]   []
[2023-07-01 11:38:05] [config] valid-script-path: ""
[2023-07-01 11:38:05] [config] valid-sets:
[2023-07-01 11:38:05] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:38:05] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:38:05] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:38:05] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:38:05] [config] vocabs:
[2023-07-01 11:38:05] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:38:05] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:38:05] [config] word-penalty: 0
[2023-07-01 11:38:05] [config] word-scores: false
[2023-07-01 11:38:05] [config] workspace: 2048
[2023-07-01 11:38:05] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:38:05] Using synchronous SGD
[2023-07-01 11:38:06] Synced seed 1234
[2023-07-01 11:38:06] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:38:06] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:38:06] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:38:06] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:38:06] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:38:06] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:38:07] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:38:07] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:38:07] [comm] Using global sharding
[2023-07-01 11:38:07] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:38:07] [training] Using 1 GPUs
[2023-07-01 11:38:07] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:38:07] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:38:07] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:38:07] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:38:14] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:38:14] [valid] No post-processing script given for validating translator
[2023-07-01 11:38:15] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:38:15] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:38:15] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:38:15] [comm] Using global sharding
[2023-07-01 11:38:15] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:38:15] [training] Using 1 GPUs
[2023-07-01 11:38:15] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:38:15] Allocating memory for general optimizer shards
[2023-07-01 11:38:15] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:38:15] Loading Adam parameters
[2023-07-01 11:38:15] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:38:16] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:38:16] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:38:16] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:38:16] [data] Shuffling data
[2023-07-01 11:38:16] [data] Done reading 20,192 sentences
[2023-07-01 11:38:16] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:38:16] Training started
[2023-07-01 11:38:16] Training finished
[2023-07-01 11:38:19] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:38:19] [marian] Running on node20.datos.cluster.uy as process 19058 with command line:
[2023-07-01 11:38:19] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 130 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:38:19] [config] after: 0e
[2023-07-01 11:38:19] [config] after-batches: 0
[2023-07-01 11:38:19] [config] after-epochs: 130
[2023-07-01 11:38:19] [config] all-caps-every: 0
[2023-07-01 11:38:19] [config] allow-unk: false
[2023-07-01 11:38:19] [config] authors: false
[2023-07-01 11:38:19] [config] beam-size: 12
[2023-07-01 11:38:19] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:38:19] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:38:19] [config] bert-masking-fraction: 0.15
[2023-07-01 11:38:19] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:38:19] [config] bert-train-type-embeddings: true
[2023-07-01 11:38:19] [config] bert-type-vocab-size: 2
[2023-07-01 11:38:19] [config] build-info: ""
[2023-07-01 11:38:19] [config] check-gradient-nan: false
[2023-07-01 11:38:19] [config] check-nan: false
[2023-07-01 11:38:19] [config] cite: false
[2023-07-01 11:38:19] [config] clip-norm: 5
[2023-07-01 11:38:19] [config] cost-scaling:
[2023-07-01 11:38:19] [config]   []
[2023-07-01 11:38:19] [config] cost-type: ce-sum
[2023-07-01 11:38:19] [config] cpu-threads: 0
[2023-07-01 11:38:19] [config] data-threads: 8
[2023-07-01 11:38:19] [config] data-weighting: ""
[2023-07-01 11:38:19] [config] data-weighting-type: sentence
[2023-07-01 11:38:19] [config] dec-cell: gru
[2023-07-01 11:38:19] [config] dec-cell-base-depth: 2
[2023-07-01 11:38:19] [config] dec-cell-high-depth: 1
[2023-07-01 11:38:19] [config] dec-depth: 2
[2023-07-01 11:38:19] [config] devices:
[2023-07-01 11:38:19] [config]   - 0
[2023-07-01 11:38:19] [config] dim-emb: 512
[2023-07-01 11:38:19] [config] dim-rnn: 1024
[2023-07-01 11:38:19] [config] dim-vocabs:
[2023-07-01 11:38:19] [config]   - 16384
[2023-07-01 11:38:19] [config]   - 16384
[2023-07-01 11:38:19] [config] disp-first: 0
[2023-07-01 11:38:19] [config] disp-freq: 1000u
[2023-07-01 11:38:19] [config] disp-label-counts: true
[2023-07-01 11:38:19] [config] dropout-rnn: 0
[2023-07-01 11:38:19] [config] dropout-src: 0
[2023-07-01 11:38:19] [config] dropout-trg: 0
[2023-07-01 11:38:19] [config] dump-config: ""
[2023-07-01 11:38:19] [config] dynamic-gradient-scaling:
[2023-07-01 11:38:19] [config]   []
[2023-07-01 11:38:19] [config] early-stopping: 10
[2023-07-01 11:38:19] [config] early-stopping-on: first
[2023-07-01 11:38:19] [config] embedding-fix-src: false
[2023-07-01 11:38:19] [config] embedding-fix-trg: false
[2023-07-01 11:38:19] [config] embedding-normalization: false
[2023-07-01 11:38:19] [config] embedding-vectors:
[2023-07-01 11:38:19] [config]   []
[2023-07-01 11:38:19] [config] enc-cell: gru
[2023-07-01 11:38:19] [config] enc-cell-depth: 1
[2023-07-01 11:38:19] [config] enc-depth: 2
[2023-07-01 11:38:19] [config] enc-type: bidirectional
[2023-07-01 11:38:19] [config] english-title-case-every: 0
[2023-07-01 11:38:19] [config] exponential-smoothing: 0.0001
[2023-07-01 11:38:19] [config] factor-weight: 1
[2023-07-01 11:38:19] [config] factors-combine: sum
[2023-07-01 11:38:19] [config] factors-dim-emb: 0
[2023-07-01 11:38:19] [config] gradient-checkpointing: false
[2023-07-01 11:38:19] [config] gradient-norm-average-window: 100
[2023-07-01 11:38:19] [config] guided-alignment: none
[2023-07-01 11:38:19] [config] guided-alignment-cost: mse
[2023-07-01 11:38:19] [config] guided-alignment-weight: 0.1
[2023-07-01 11:38:19] [config] ignore-model-config: false
[2023-07-01 11:38:19] [config] input-types:
[2023-07-01 11:38:19] [config]   []
[2023-07-01 11:38:19] [config] interpolate-env-vars: false
[2023-07-01 11:38:19] [config] keep-best: false
[2023-07-01 11:38:19] [config] label-smoothing: 0.1
[2023-07-01 11:38:19] [config] layer-normalization: false
[2023-07-01 11:38:19] [config] learn-rate: 0.0003
[2023-07-01 11:38:19] [config] lemma-dependency: ""
[2023-07-01 11:38:19] [config] lemma-dim-emb: 0
[2023-07-01 11:38:19] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:38:19] [config] log-level: info
[2023-07-01 11:38:19] [config] log-time-zone: ""
[2023-07-01 11:38:19] [config] logical-epoch:
[2023-07-01 11:38:19] [config]   - 1e
[2023-07-01 11:38:19] [config]   - 0
[2023-07-01 11:38:19] [config] lr-decay: 0
[2023-07-01 11:38:19] [config] lr-decay-freq: 50000
[2023-07-01 11:38:19] [config] lr-decay-inv-sqrt:
[2023-07-01 11:38:19] [config]   - 16000
[2023-07-01 11:38:19] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:38:19] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:38:19] [config] lr-decay-start:
[2023-07-01 11:38:19] [config]   - 10
[2023-07-01 11:38:19] [config]   - 1
[2023-07-01 11:38:19] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:38:19] [config] lr-report: true
[2023-07-01 11:38:19] [config] lr-warmup: 16000
[2023-07-01 11:38:19] [config] lr-warmup-at-reload: false
[2023-07-01 11:38:19] [config] lr-warmup-cycle: false
[2023-07-01 11:38:19] [config] lr-warmup-start-rate: 0
[2023-07-01 11:38:19] [config] max-length: 100
[2023-07-01 11:38:19] [config] max-length-crop: false
[2023-07-01 11:38:19] [config] max-length-factor: 3
[2023-07-01 11:38:19] [config] maxi-batch: 100
[2023-07-01 11:38:19] [config] maxi-batch-sort: trg
[2023-07-01 11:38:19] [config] mini-batch: 1000
[2023-07-01 11:38:19] [config] mini-batch-fit: true
[2023-07-01 11:38:19] [config] mini-batch-fit-step: 10
[2023-07-01 11:38:19] [config] mini-batch-round-up: true
[2023-07-01 11:38:19] [config] mini-batch-track-lr: false
[2023-07-01 11:38:19] [config] mini-batch-warmup: 0
[2023-07-01 11:38:19] [config] mini-batch-words: 0
[2023-07-01 11:38:19] [config] mini-batch-words-ref: 0
[2023-07-01 11:38:19] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:38:19] [config] multi-loss-type: sum
[2023-07-01 11:38:19] [config] n-best: false
[2023-07-01 11:38:19] [config] no-nccl: false
[2023-07-01 11:38:19] [config] no-reload: false
[2023-07-01 11:38:19] [config] no-restore-corpus: false
[2023-07-01 11:38:19] [config] normalize: 1
[2023-07-01 11:38:19] [config] normalize-gradient: false
[2023-07-01 11:38:19] [config] num-devices: 0
[2023-07-01 11:38:19] [config] optimizer: adam
[2023-07-01 11:38:19] [config] optimizer-delay: 1
[2023-07-01 11:38:19] [config] optimizer-params:
[2023-07-01 11:38:19] [config]   - 0.9
[2023-07-01 11:38:19] [config]   - 0.98
[2023-07-01 11:38:19] [config]   - 1e-09
[2023-07-01 11:38:19] [config] output-omit-bias: false
[2023-07-01 11:38:19] [config] overwrite: true
[2023-07-01 11:38:19] [config] precision:
[2023-07-01 11:38:19] [config]   - float32
[2023-07-01 11:38:19] [config]   - float32
[2023-07-01 11:38:19] [config] pretrained-model: ""
[2023-07-01 11:38:19] [config] quantize-biases: false
[2023-07-01 11:38:19] [config] quantize-bits: 0
[2023-07-01 11:38:19] [config] quantize-log-based: false
[2023-07-01 11:38:19] [config] quantize-optimization-steps: 0
[2023-07-01 11:38:19] [config] quiet: false
[2023-07-01 11:38:19] [config] quiet-translation: true
[2023-07-01 11:38:19] [config] relative-paths: false
[2023-07-01 11:38:19] [config] right-left: false
[2023-07-01 11:38:19] [config] save-freq: 10000u
[2023-07-01 11:38:19] [config] seed: 1234
[2023-07-01 11:38:19] [config] sentencepiece-alphas:
[2023-07-01 11:38:19] [config]   []
[2023-07-01 11:38:19] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:38:19] [config] sentencepiece-options: ""
[2023-07-01 11:38:19] [config] sharding: global
[2023-07-01 11:38:19] [config] shuffle: data
[2023-07-01 11:38:19] [config] shuffle-in-ram: false
[2023-07-01 11:38:19] [config] sigterm: save-and-exit
[2023-07-01 11:38:19] [config] skip: false
[2023-07-01 11:38:19] [config] sqlite: ""
[2023-07-01 11:38:19] [config] sqlite-drop: false
[2023-07-01 11:38:19] [config] sync-freq: 200u
[2023-07-01 11:38:19] [config] sync-sgd: true
[2023-07-01 11:38:19] [config] tempdir: /tmp
[2023-07-01 11:38:19] [config] tied-embeddings: false
[2023-07-01 11:38:19] [config] tied-embeddings-all: true
[2023-07-01 11:38:19] [config] tied-embeddings-src: false
[2023-07-01 11:38:19] [config] train-embedder-rank:
[2023-07-01 11:38:19] [config]   []
[2023-07-01 11:38:19] [config] train-sets:
[2023-07-01 11:38:19] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:38:19] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:38:19] [config] transformer-aan-activation: swish
[2023-07-01 11:38:19] [config] transformer-aan-depth: 2
[2023-07-01 11:38:19] [config] transformer-aan-nogate: false
[2023-07-01 11:38:19] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:38:19] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:38:19] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:38:19] [config] transformer-depth-scaling: false
[2023-07-01 11:38:19] [config] transformer-dim-aan: 2048
[2023-07-01 11:38:19] [config] transformer-dim-ffn: 2048
[2023-07-01 11:38:19] [config] transformer-dropout: 0.1
[2023-07-01 11:38:19] [config] transformer-dropout-attention: 0
[2023-07-01 11:38:19] [config] transformer-dropout-ffn: 0
[2023-07-01 11:38:19] [config] transformer-ffn-activation: swish
[2023-07-01 11:38:19] [config] transformer-ffn-depth: 2
[2023-07-01 11:38:19] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:38:19] [config] transformer-heads: 8
[2023-07-01 11:38:19] [config] transformer-no-projection: false
[2023-07-01 11:38:19] [config] transformer-pool: false
[2023-07-01 11:38:19] [config] transformer-postprocess: dan
[2023-07-01 11:38:19] [config] transformer-postprocess-emb: d
[2023-07-01 11:38:19] [config] transformer-postprocess-top: ""
[2023-07-01 11:38:19] [config] transformer-preprocess: ""
[2023-07-01 11:38:19] [config] transformer-tied-layers:
[2023-07-01 11:38:19] [config]   []
[2023-07-01 11:38:19] [config] transformer-train-position-embeddings: false
[2023-07-01 11:38:19] [config] tsv: false
[2023-07-01 11:38:19] [config] tsv-fields: 0
[2023-07-01 11:38:19] [config] type: transformer
[2023-07-01 11:38:19] [config] ulr: false
[2023-07-01 11:38:19] [config] ulr-dim-emb: 0
[2023-07-01 11:38:19] [config] ulr-dropout: 0
[2023-07-01 11:38:19] [config] ulr-keys-vectors: ""
[2023-07-01 11:38:19] [config] ulr-query-vectors: ""
[2023-07-01 11:38:19] [config] ulr-softmax-temperature: 1
[2023-07-01 11:38:19] [config] ulr-trainable-transformation: false
[2023-07-01 11:38:19] [config] unlikelihood-loss: false
[2023-07-01 11:38:19] [config] valid-freq: 50000000
[2023-07-01 11:38:19] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:38:19] [config] valid-max-length: 1000
[2023-07-01 11:38:19] [config] valid-metrics:
[2023-07-01 11:38:19] [config]   - cross-entropy
[2023-07-01 11:38:19] [config]   - translation
[2023-07-01 11:38:19] [config] valid-mini-batch: 64
[2023-07-01 11:38:19] [config] valid-reset-stalled: false
[2023-07-01 11:38:19] [config] valid-script-args:
[2023-07-01 11:38:19] [config]   []
[2023-07-01 11:38:19] [config] valid-script-path: ""
[2023-07-01 11:38:19] [config] valid-sets:
[2023-07-01 11:38:19] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:38:19] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:38:19] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:38:19] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:38:19] [config] vocabs:
[2023-07-01 11:38:19] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:38:19] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:38:19] [config] word-penalty: 0
[2023-07-01 11:38:19] [config] word-scores: false
[2023-07-01 11:38:19] [config] workspace: 2048
[2023-07-01 11:38:19] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:38:19] Using synchronous SGD
[2023-07-01 11:38:19] Synced seed 1234
[2023-07-01 11:38:19] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:38:19] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:38:19] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:38:20] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:38:20] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:38:20] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:38:20] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:38:20] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:38:20] [comm] Using global sharding
[2023-07-01 11:38:21] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:38:21] [training] Using 1 GPUs
[2023-07-01 11:38:21] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:38:21] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:38:21] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:38:21] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:38:28] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:38:28] [valid] No post-processing script given for validating translator
[2023-07-01 11:38:28] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:38:28] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:38:28] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:38:28] [comm] Using global sharding
[2023-07-01 11:38:28] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:38:28] [training] Using 1 GPUs
[2023-07-01 11:38:28] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:38:29] Allocating memory for general optimizer shards
[2023-07-01 11:38:29] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:38:29] Loading Adam parameters
[2023-07-01 11:38:29] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:38:29] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:38:29] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:38:29] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:38:29] [data] Shuffling data
[2023-07-01 11:38:29] [data] Done reading 20,192 sentences
[2023-07-01 11:38:29] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:38:29] Training started
[2023-07-01 11:38:29] Training finished
[2023-07-01 11:38:32] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:38:32] [marian] Running on node20.datos.cluster.uy as process 19118 with command line:
[2023-07-01 11:38:32] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 131 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:38:32] [config] after: 0e
[2023-07-01 11:38:32] [config] after-batches: 0
[2023-07-01 11:38:32] [config] after-epochs: 131
[2023-07-01 11:38:32] [config] all-caps-every: 0
[2023-07-01 11:38:32] [config] allow-unk: false
[2023-07-01 11:38:32] [config] authors: false
[2023-07-01 11:38:32] [config] beam-size: 12
[2023-07-01 11:38:32] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:38:32] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:38:32] [config] bert-masking-fraction: 0.15
[2023-07-01 11:38:32] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:38:32] [config] bert-train-type-embeddings: true
[2023-07-01 11:38:32] [config] bert-type-vocab-size: 2
[2023-07-01 11:38:32] [config] build-info: ""
[2023-07-01 11:38:32] [config] check-gradient-nan: false
[2023-07-01 11:38:32] [config] check-nan: false
[2023-07-01 11:38:32] [config] cite: false
[2023-07-01 11:38:32] [config] clip-norm: 5
[2023-07-01 11:38:32] [config] cost-scaling:
[2023-07-01 11:38:32] [config]   []
[2023-07-01 11:38:32] [config] cost-type: ce-sum
[2023-07-01 11:38:32] [config] cpu-threads: 0
[2023-07-01 11:38:32] [config] data-threads: 8
[2023-07-01 11:38:32] [config] data-weighting: ""
[2023-07-01 11:38:32] [config] data-weighting-type: sentence
[2023-07-01 11:38:32] [config] dec-cell: gru
[2023-07-01 11:38:32] [config] dec-cell-base-depth: 2
[2023-07-01 11:38:32] [config] dec-cell-high-depth: 1
[2023-07-01 11:38:32] [config] dec-depth: 2
[2023-07-01 11:38:32] [config] devices:
[2023-07-01 11:38:32] [config]   - 0
[2023-07-01 11:38:32] [config] dim-emb: 512
[2023-07-01 11:38:32] [config] dim-rnn: 1024
[2023-07-01 11:38:32] [config] dim-vocabs:
[2023-07-01 11:38:32] [config]   - 16384
[2023-07-01 11:38:32] [config]   - 16384
[2023-07-01 11:38:32] [config] disp-first: 0
[2023-07-01 11:38:32] [config] disp-freq: 1000u
[2023-07-01 11:38:32] [config] disp-label-counts: true
[2023-07-01 11:38:32] [config] dropout-rnn: 0
[2023-07-01 11:38:32] [config] dropout-src: 0
[2023-07-01 11:38:32] [config] dropout-trg: 0
[2023-07-01 11:38:32] [config] dump-config: ""
[2023-07-01 11:38:32] [config] dynamic-gradient-scaling:
[2023-07-01 11:38:32] [config]   []
[2023-07-01 11:38:32] [config] early-stopping: 10
[2023-07-01 11:38:32] [config] early-stopping-on: first
[2023-07-01 11:38:32] [config] embedding-fix-src: false
[2023-07-01 11:38:32] [config] embedding-fix-trg: false
[2023-07-01 11:38:32] [config] embedding-normalization: false
[2023-07-01 11:38:32] [config] embedding-vectors:
[2023-07-01 11:38:32] [config]   []
[2023-07-01 11:38:32] [config] enc-cell: gru
[2023-07-01 11:38:32] [config] enc-cell-depth: 1
[2023-07-01 11:38:32] [config] enc-depth: 2
[2023-07-01 11:38:32] [config] enc-type: bidirectional
[2023-07-01 11:38:32] [config] english-title-case-every: 0
[2023-07-01 11:38:32] [config] exponential-smoothing: 0.0001
[2023-07-01 11:38:32] [config] factor-weight: 1
[2023-07-01 11:38:32] [config] factors-combine: sum
[2023-07-01 11:38:32] [config] factors-dim-emb: 0
[2023-07-01 11:38:32] [config] gradient-checkpointing: false
[2023-07-01 11:38:32] [config] gradient-norm-average-window: 100
[2023-07-01 11:38:32] [config] guided-alignment: none
[2023-07-01 11:38:32] [config] guided-alignment-cost: mse
[2023-07-01 11:38:32] [config] guided-alignment-weight: 0.1
[2023-07-01 11:38:32] [config] ignore-model-config: false
[2023-07-01 11:38:32] [config] input-types:
[2023-07-01 11:38:32] [config]   []
[2023-07-01 11:38:32] [config] interpolate-env-vars: false
[2023-07-01 11:38:32] [config] keep-best: false
[2023-07-01 11:38:32] [config] label-smoothing: 0.1
[2023-07-01 11:38:32] [config] layer-normalization: false
[2023-07-01 11:38:32] [config] learn-rate: 0.0003
[2023-07-01 11:38:32] [config] lemma-dependency: ""
[2023-07-01 11:38:32] [config] lemma-dim-emb: 0
[2023-07-01 11:38:32] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:38:32] [config] log-level: info
[2023-07-01 11:38:32] [config] log-time-zone: ""
[2023-07-01 11:38:32] [config] logical-epoch:
[2023-07-01 11:38:32] [config]   - 1e
[2023-07-01 11:38:32] [config]   - 0
[2023-07-01 11:38:32] [config] lr-decay: 0
[2023-07-01 11:38:32] [config] lr-decay-freq: 50000
[2023-07-01 11:38:32] [config] lr-decay-inv-sqrt:
[2023-07-01 11:38:32] [config]   - 16000
[2023-07-01 11:38:32] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:38:32] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:38:32] [config] lr-decay-start:
[2023-07-01 11:38:32] [config]   - 10
[2023-07-01 11:38:32] [config]   - 1
[2023-07-01 11:38:32] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:38:32] [config] lr-report: true
[2023-07-01 11:38:32] [config] lr-warmup: 16000
[2023-07-01 11:38:32] [config] lr-warmup-at-reload: false
[2023-07-01 11:38:32] [config] lr-warmup-cycle: false
[2023-07-01 11:38:32] [config] lr-warmup-start-rate: 0
[2023-07-01 11:38:32] [config] max-length: 100
[2023-07-01 11:38:32] [config] max-length-crop: false
[2023-07-01 11:38:32] [config] max-length-factor: 3
[2023-07-01 11:38:32] [config] maxi-batch: 100
[2023-07-01 11:38:32] [config] maxi-batch-sort: trg
[2023-07-01 11:38:32] [config] mini-batch: 1000
[2023-07-01 11:38:32] [config] mini-batch-fit: true
[2023-07-01 11:38:32] [config] mini-batch-fit-step: 10
[2023-07-01 11:38:32] [config] mini-batch-round-up: true
[2023-07-01 11:38:32] [config] mini-batch-track-lr: false
[2023-07-01 11:38:32] [config] mini-batch-warmup: 0
[2023-07-01 11:38:32] [config] mini-batch-words: 0
[2023-07-01 11:38:32] [config] mini-batch-words-ref: 0
[2023-07-01 11:38:32] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:38:32] [config] multi-loss-type: sum
[2023-07-01 11:38:32] [config] n-best: false
[2023-07-01 11:38:32] [config] no-nccl: false
[2023-07-01 11:38:32] [config] no-reload: false
[2023-07-01 11:38:32] [config] no-restore-corpus: false
[2023-07-01 11:38:32] [config] normalize: 1
[2023-07-01 11:38:32] [config] normalize-gradient: false
[2023-07-01 11:38:32] [config] num-devices: 0
[2023-07-01 11:38:32] [config] optimizer: adam
[2023-07-01 11:38:32] [config] optimizer-delay: 1
[2023-07-01 11:38:32] [config] optimizer-params:
[2023-07-01 11:38:32] [config]   - 0.9
[2023-07-01 11:38:32] [config]   - 0.98
[2023-07-01 11:38:32] [config]   - 1e-09
[2023-07-01 11:38:32] [config] output-omit-bias: false
[2023-07-01 11:38:32] [config] overwrite: true
[2023-07-01 11:38:32] [config] precision:
[2023-07-01 11:38:32] [config]   - float32
[2023-07-01 11:38:32] [config]   - float32
[2023-07-01 11:38:32] [config] pretrained-model: ""
[2023-07-01 11:38:32] [config] quantize-biases: false
[2023-07-01 11:38:32] [config] quantize-bits: 0
[2023-07-01 11:38:32] [config] quantize-log-based: false
[2023-07-01 11:38:32] [config] quantize-optimization-steps: 0
[2023-07-01 11:38:32] [config] quiet: false
[2023-07-01 11:38:32] [config] quiet-translation: true
[2023-07-01 11:38:32] [config] relative-paths: false
[2023-07-01 11:38:32] [config] right-left: false
[2023-07-01 11:38:32] [config] save-freq: 10000u
[2023-07-01 11:38:32] [config] seed: 1234
[2023-07-01 11:38:32] [config] sentencepiece-alphas:
[2023-07-01 11:38:32] [config]   []
[2023-07-01 11:38:32] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:38:32] [config] sentencepiece-options: ""
[2023-07-01 11:38:32] [config] sharding: global
[2023-07-01 11:38:32] [config] shuffle: data
[2023-07-01 11:38:32] [config] shuffle-in-ram: false
[2023-07-01 11:38:32] [config] sigterm: save-and-exit
[2023-07-01 11:38:32] [config] skip: false
[2023-07-01 11:38:32] [config] sqlite: ""
[2023-07-01 11:38:32] [config] sqlite-drop: false
[2023-07-01 11:38:32] [config] sync-freq: 200u
[2023-07-01 11:38:32] [config] sync-sgd: true
[2023-07-01 11:38:32] [config] tempdir: /tmp
[2023-07-01 11:38:32] [config] tied-embeddings: false
[2023-07-01 11:38:32] [config] tied-embeddings-all: true
[2023-07-01 11:38:32] [config] tied-embeddings-src: false
[2023-07-01 11:38:32] [config] train-embedder-rank:
[2023-07-01 11:38:32] [config]   []
[2023-07-01 11:38:32] [config] train-sets:
[2023-07-01 11:38:32] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:38:32] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:38:32] [config] transformer-aan-activation: swish
[2023-07-01 11:38:32] [config] transformer-aan-depth: 2
[2023-07-01 11:38:32] [config] transformer-aan-nogate: false
[2023-07-01 11:38:32] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:38:32] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:38:32] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:38:32] [config] transformer-depth-scaling: false
[2023-07-01 11:38:32] [config] transformer-dim-aan: 2048
[2023-07-01 11:38:32] [config] transformer-dim-ffn: 2048
[2023-07-01 11:38:32] [config] transformer-dropout: 0.1
[2023-07-01 11:38:32] [config] transformer-dropout-attention: 0
[2023-07-01 11:38:32] [config] transformer-dropout-ffn: 0
[2023-07-01 11:38:32] [config] transformer-ffn-activation: swish
[2023-07-01 11:38:32] [config] transformer-ffn-depth: 2
[2023-07-01 11:38:32] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:38:32] [config] transformer-heads: 8
[2023-07-01 11:38:32] [config] transformer-no-projection: false
[2023-07-01 11:38:32] [config] transformer-pool: false
[2023-07-01 11:38:32] [config] transformer-postprocess: dan
[2023-07-01 11:38:32] [config] transformer-postprocess-emb: d
[2023-07-01 11:38:32] [config] transformer-postprocess-top: ""
[2023-07-01 11:38:32] [config] transformer-preprocess: ""
[2023-07-01 11:38:32] [config] transformer-tied-layers:
[2023-07-01 11:38:32] [config]   []
[2023-07-01 11:38:32] [config] transformer-train-position-embeddings: false
[2023-07-01 11:38:32] [config] tsv: false
[2023-07-01 11:38:32] [config] tsv-fields: 0
[2023-07-01 11:38:32] [config] type: transformer
[2023-07-01 11:38:32] [config] ulr: false
[2023-07-01 11:38:32] [config] ulr-dim-emb: 0
[2023-07-01 11:38:32] [config] ulr-dropout: 0
[2023-07-01 11:38:32] [config] ulr-keys-vectors: ""
[2023-07-01 11:38:32] [config] ulr-query-vectors: ""
[2023-07-01 11:38:32] [config] ulr-softmax-temperature: 1
[2023-07-01 11:38:32] [config] ulr-trainable-transformation: false
[2023-07-01 11:38:32] [config] unlikelihood-loss: false
[2023-07-01 11:38:32] [config] valid-freq: 50000000
[2023-07-01 11:38:32] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:38:32] [config] valid-max-length: 1000
[2023-07-01 11:38:32] [config] valid-metrics:
[2023-07-01 11:38:32] [config]   - cross-entropy
[2023-07-01 11:38:32] [config]   - translation
[2023-07-01 11:38:32] [config] valid-mini-batch: 64
[2023-07-01 11:38:32] [config] valid-reset-stalled: false
[2023-07-01 11:38:32] [config] valid-script-args:
[2023-07-01 11:38:32] [config]   []
[2023-07-01 11:38:32] [config] valid-script-path: ""
[2023-07-01 11:38:32] [config] valid-sets:
[2023-07-01 11:38:32] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:38:32] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:38:32] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:38:32] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:38:32] [config] vocabs:
[2023-07-01 11:38:32] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:38:32] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:38:32] [config] word-penalty: 0
[2023-07-01 11:38:32] [config] word-scores: false
[2023-07-01 11:38:32] [config] workspace: 2048
[2023-07-01 11:38:32] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:38:32] Using synchronous SGD
[2023-07-01 11:38:33] Synced seed 1234
[2023-07-01 11:38:33] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:38:33] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:38:33] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:38:33] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:38:33] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:38:33] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:38:34] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:38:34] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:38:34] [comm] Using global sharding
[2023-07-01 11:38:34] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:38:34] [training] Using 1 GPUs
[2023-07-01 11:38:34] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:38:34] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:38:34] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:38:34] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:38:41] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:38:41] [valid] No post-processing script given for validating translator
[2023-07-01 11:38:42] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:38:42] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:38:42] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:38:42] [comm] Using global sharding
[2023-07-01 11:38:42] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:38:42] [training] Using 1 GPUs
[2023-07-01 11:38:42] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:38:42] Allocating memory for general optimizer shards
[2023-07-01 11:38:42] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:38:42] Loading Adam parameters
[2023-07-01 11:38:42] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:38:42] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:38:43] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:38:43] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:38:43] [data] Shuffling data
[2023-07-01 11:38:43] [data] Done reading 20,192 sentences
[2023-07-01 11:38:43] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:38:43] Training started
[2023-07-01 11:38:43] Training finished
[2023-07-01 11:38:46] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:38:46] [marian] Running on node20.datos.cluster.uy as process 19178 with command line:
[2023-07-01 11:38:46] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 132 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:38:46] [config] after: 0e
[2023-07-01 11:38:46] [config] after-batches: 0
[2023-07-01 11:38:46] [config] after-epochs: 132
[2023-07-01 11:38:46] [config] all-caps-every: 0
[2023-07-01 11:38:46] [config] allow-unk: false
[2023-07-01 11:38:46] [config] authors: false
[2023-07-01 11:38:46] [config] beam-size: 12
[2023-07-01 11:38:46] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:38:46] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:38:46] [config] bert-masking-fraction: 0.15
[2023-07-01 11:38:46] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:38:46] [config] bert-train-type-embeddings: true
[2023-07-01 11:38:46] [config] bert-type-vocab-size: 2
[2023-07-01 11:38:46] [config] build-info: ""
[2023-07-01 11:38:46] [config] check-gradient-nan: false
[2023-07-01 11:38:46] [config] check-nan: false
[2023-07-01 11:38:46] [config] cite: false
[2023-07-01 11:38:46] [config] clip-norm: 5
[2023-07-01 11:38:46] [config] cost-scaling:
[2023-07-01 11:38:46] [config]   []
[2023-07-01 11:38:46] [config] cost-type: ce-sum
[2023-07-01 11:38:46] [config] cpu-threads: 0
[2023-07-01 11:38:46] [config] data-threads: 8
[2023-07-01 11:38:46] [config] data-weighting: ""
[2023-07-01 11:38:46] [config] data-weighting-type: sentence
[2023-07-01 11:38:46] [config] dec-cell: gru
[2023-07-01 11:38:46] [config] dec-cell-base-depth: 2
[2023-07-01 11:38:46] [config] dec-cell-high-depth: 1
[2023-07-01 11:38:46] [config] dec-depth: 2
[2023-07-01 11:38:46] [config] devices:
[2023-07-01 11:38:46] [config]   - 0
[2023-07-01 11:38:46] [config] dim-emb: 512
[2023-07-01 11:38:46] [config] dim-rnn: 1024
[2023-07-01 11:38:46] [config] dim-vocabs:
[2023-07-01 11:38:46] [config]   - 16384
[2023-07-01 11:38:46] [config]   - 16384
[2023-07-01 11:38:46] [config] disp-first: 0
[2023-07-01 11:38:46] [config] disp-freq: 1000u
[2023-07-01 11:38:46] [config] disp-label-counts: true
[2023-07-01 11:38:46] [config] dropout-rnn: 0
[2023-07-01 11:38:46] [config] dropout-src: 0
[2023-07-01 11:38:46] [config] dropout-trg: 0
[2023-07-01 11:38:46] [config] dump-config: ""
[2023-07-01 11:38:46] [config] dynamic-gradient-scaling:
[2023-07-01 11:38:46] [config]   []
[2023-07-01 11:38:46] [config] early-stopping: 10
[2023-07-01 11:38:46] [config] early-stopping-on: first
[2023-07-01 11:38:46] [config] embedding-fix-src: false
[2023-07-01 11:38:46] [config] embedding-fix-trg: false
[2023-07-01 11:38:46] [config] embedding-normalization: false
[2023-07-01 11:38:46] [config] embedding-vectors:
[2023-07-01 11:38:46] [config]   []
[2023-07-01 11:38:46] [config] enc-cell: gru
[2023-07-01 11:38:46] [config] enc-cell-depth: 1
[2023-07-01 11:38:46] [config] enc-depth: 2
[2023-07-01 11:38:46] [config] enc-type: bidirectional
[2023-07-01 11:38:46] [config] english-title-case-every: 0
[2023-07-01 11:38:46] [config] exponential-smoothing: 0.0001
[2023-07-01 11:38:46] [config] factor-weight: 1
[2023-07-01 11:38:46] [config] factors-combine: sum
[2023-07-01 11:38:46] [config] factors-dim-emb: 0
[2023-07-01 11:38:46] [config] gradient-checkpointing: false
[2023-07-01 11:38:46] [config] gradient-norm-average-window: 100
[2023-07-01 11:38:46] [config] guided-alignment: none
[2023-07-01 11:38:46] [config] guided-alignment-cost: mse
[2023-07-01 11:38:46] [config] guided-alignment-weight: 0.1
[2023-07-01 11:38:46] [config] ignore-model-config: false
[2023-07-01 11:38:46] [config] input-types:
[2023-07-01 11:38:46] [config]   []
[2023-07-01 11:38:46] [config] interpolate-env-vars: false
[2023-07-01 11:38:46] [config] keep-best: false
[2023-07-01 11:38:46] [config] label-smoothing: 0.1
[2023-07-01 11:38:46] [config] layer-normalization: false
[2023-07-01 11:38:46] [config] learn-rate: 0.0003
[2023-07-01 11:38:46] [config] lemma-dependency: ""
[2023-07-01 11:38:46] [config] lemma-dim-emb: 0
[2023-07-01 11:38:46] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:38:46] [config] log-level: info
[2023-07-01 11:38:46] [config] log-time-zone: ""
[2023-07-01 11:38:46] [config] logical-epoch:
[2023-07-01 11:38:46] [config]   - 1e
[2023-07-01 11:38:46] [config]   - 0
[2023-07-01 11:38:46] [config] lr-decay: 0
[2023-07-01 11:38:46] [config] lr-decay-freq: 50000
[2023-07-01 11:38:46] [config] lr-decay-inv-sqrt:
[2023-07-01 11:38:46] [config]   - 16000
[2023-07-01 11:38:46] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:38:46] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:38:46] [config] lr-decay-start:
[2023-07-01 11:38:46] [config]   - 10
[2023-07-01 11:38:46] [config]   - 1
[2023-07-01 11:38:46] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:38:46] [config] lr-report: true
[2023-07-01 11:38:46] [config] lr-warmup: 16000
[2023-07-01 11:38:46] [config] lr-warmup-at-reload: false
[2023-07-01 11:38:46] [config] lr-warmup-cycle: false
[2023-07-01 11:38:46] [config] lr-warmup-start-rate: 0
[2023-07-01 11:38:46] [config] max-length: 100
[2023-07-01 11:38:46] [config] max-length-crop: false
[2023-07-01 11:38:46] [config] max-length-factor: 3
[2023-07-01 11:38:46] [config] maxi-batch: 100
[2023-07-01 11:38:46] [config] maxi-batch-sort: trg
[2023-07-01 11:38:46] [config] mini-batch: 1000
[2023-07-01 11:38:46] [config] mini-batch-fit: true
[2023-07-01 11:38:46] [config] mini-batch-fit-step: 10
[2023-07-01 11:38:46] [config] mini-batch-round-up: true
[2023-07-01 11:38:46] [config] mini-batch-track-lr: false
[2023-07-01 11:38:46] [config] mini-batch-warmup: 0
[2023-07-01 11:38:46] [config] mini-batch-words: 0
[2023-07-01 11:38:46] [config] mini-batch-words-ref: 0
[2023-07-01 11:38:46] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:38:46] [config] multi-loss-type: sum
[2023-07-01 11:38:46] [config] n-best: false
[2023-07-01 11:38:46] [config] no-nccl: false
[2023-07-01 11:38:46] [config] no-reload: false
[2023-07-01 11:38:46] [config] no-restore-corpus: false
[2023-07-01 11:38:46] [config] normalize: 1
[2023-07-01 11:38:46] [config] normalize-gradient: false
[2023-07-01 11:38:46] [config] num-devices: 0
[2023-07-01 11:38:46] [config] optimizer: adam
[2023-07-01 11:38:46] [config] optimizer-delay: 1
[2023-07-01 11:38:46] [config] optimizer-params:
[2023-07-01 11:38:46] [config]   - 0.9
[2023-07-01 11:38:46] [config]   - 0.98
[2023-07-01 11:38:46] [config]   - 1e-09
[2023-07-01 11:38:46] [config] output-omit-bias: false
[2023-07-01 11:38:46] [config] overwrite: true
[2023-07-01 11:38:46] [config] precision:
[2023-07-01 11:38:46] [config]   - float32
[2023-07-01 11:38:46] [config]   - float32
[2023-07-01 11:38:46] [config] pretrained-model: ""
[2023-07-01 11:38:46] [config] quantize-biases: false
[2023-07-01 11:38:46] [config] quantize-bits: 0
[2023-07-01 11:38:46] [config] quantize-log-based: false
[2023-07-01 11:38:46] [config] quantize-optimization-steps: 0
[2023-07-01 11:38:46] [config] quiet: false
[2023-07-01 11:38:46] [config] quiet-translation: true
[2023-07-01 11:38:46] [config] relative-paths: false
[2023-07-01 11:38:46] [config] right-left: false
[2023-07-01 11:38:46] [config] save-freq: 10000u
[2023-07-01 11:38:46] [config] seed: 1234
[2023-07-01 11:38:46] [config] sentencepiece-alphas:
[2023-07-01 11:38:46] [config]   []
[2023-07-01 11:38:46] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:38:46] [config] sentencepiece-options: ""
[2023-07-01 11:38:46] [config] sharding: global
[2023-07-01 11:38:46] [config] shuffle: data
[2023-07-01 11:38:46] [config] shuffle-in-ram: false
[2023-07-01 11:38:46] [config] sigterm: save-and-exit
[2023-07-01 11:38:46] [config] skip: false
[2023-07-01 11:38:46] [config] sqlite: ""
[2023-07-01 11:38:46] [config] sqlite-drop: false
[2023-07-01 11:38:46] [config] sync-freq: 200u
[2023-07-01 11:38:46] [config] sync-sgd: true
[2023-07-01 11:38:46] [config] tempdir: /tmp
[2023-07-01 11:38:46] [config] tied-embeddings: false
[2023-07-01 11:38:46] [config] tied-embeddings-all: true
[2023-07-01 11:38:46] [config] tied-embeddings-src: false
[2023-07-01 11:38:46] [config] train-embedder-rank:
[2023-07-01 11:38:46] [config]   []
[2023-07-01 11:38:46] [config] train-sets:
[2023-07-01 11:38:46] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:38:46] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:38:46] [config] transformer-aan-activation: swish
[2023-07-01 11:38:46] [config] transformer-aan-depth: 2
[2023-07-01 11:38:46] [config] transformer-aan-nogate: false
[2023-07-01 11:38:46] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:38:46] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:38:46] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:38:46] [config] transformer-depth-scaling: false
[2023-07-01 11:38:46] [config] transformer-dim-aan: 2048
[2023-07-01 11:38:46] [config] transformer-dim-ffn: 2048
[2023-07-01 11:38:46] [config] transformer-dropout: 0.1
[2023-07-01 11:38:46] [config] transformer-dropout-attention: 0
[2023-07-01 11:38:46] [config] transformer-dropout-ffn: 0
[2023-07-01 11:38:46] [config] transformer-ffn-activation: swish
[2023-07-01 11:38:46] [config] transformer-ffn-depth: 2
[2023-07-01 11:38:46] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:38:46] [config] transformer-heads: 8
[2023-07-01 11:38:46] [config] transformer-no-projection: false
[2023-07-01 11:38:46] [config] transformer-pool: false
[2023-07-01 11:38:46] [config] transformer-postprocess: dan
[2023-07-01 11:38:46] [config] transformer-postprocess-emb: d
[2023-07-01 11:38:46] [config] transformer-postprocess-top: ""
[2023-07-01 11:38:46] [config] transformer-preprocess: ""
[2023-07-01 11:38:46] [config] transformer-tied-layers:
[2023-07-01 11:38:46] [config]   []
[2023-07-01 11:38:46] [config] transformer-train-position-embeddings: false
[2023-07-01 11:38:46] [config] tsv: false
[2023-07-01 11:38:46] [config] tsv-fields: 0
[2023-07-01 11:38:46] [config] type: transformer
[2023-07-01 11:38:46] [config] ulr: false
[2023-07-01 11:38:46] [config] ulr-dim-emb: 0
[2023-07-01 11:38:46] [config] ulr-dropout: 0
[2023-07-01 11:38:46] [config] ulr-keys-vectors: ""
[2023-07-01 11:38:46] [config] ulr-query-vectors: ""
[2023-07-01 11:38:46] [config] ulr-softmax-temperature: 1
[2023-07-01 11:38:46] [config] ulr-trainable-transformation: false
[2023-07-01 11:38:46] [config] unlikelihood-loss: false
[2023-07-01 11:38:46] [config] valid-freq: 50000000
[2023-07-01 11:38:46] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:38:46] [config] valid-max-length: 1000
[2023-07-01 11:38:46] [config] valid-metrics:
[2023-07-01 11:38:46] [config]   - cross-entropy
[2023-07-01 11:38:46] [config]   - translation
[2023-07-01 11:38:46] [config] valid-mini-batch: 64
[2023-07-01 11:38:46] [config] valid-reset-stalled: false
[2023-07-01 11:38:46] [config] valid-script-args:
[2023-07-01 11:38:46] [config]   []
[2023-07-01 11:38:46] [config] valid-script-path: ""
[2023-07-01 11:38:46] [config] valid-sets:
[2023-07-01 11:38:46] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:38:46] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:38:46] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:38:46] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:38:46] [config] vocabs:
[2023-07-01 11:38:46] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:38:46] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:38:46] [config] word-penalty: 0
[2023-07-01 11:38:46] [config] word-scores: false
[2023-07-01 11:38:46] [config] workspace: 2048
[2023-07-01 11:38:46] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:38:46] Using synchronous SGD
[2023-07-01 11:38:47] Synced seed 1234
[2023-07-01 11:38:47] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:38:47] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:38:47] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:38:47] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:38:47] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:38:47] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:38:47] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:38:47] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:38:47] [comm] Using global sharding
[2023-07-01 11:38:47] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:38:47] [training] Using 1 GPUs
[2023-07-01 11:38:47] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:38:47] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:38:48] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:38:48] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:38:55] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:38:55] [valid] No post-processing script given for validating translator
[2023-07-01 11:38:55] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:38:55] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:38:55] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:38:55] [comm] Using global sharding
[2023-07-01 11:38:56] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:38:56] [training] Using 1 GPUs
[2023-07-01 11:38:56] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:38:56] Allocating memory for general optimizer shards
[2023-07-01 11:38:56] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:38:56] Loading Adam parameters
[2023-07-01 11:38:56] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:38:56] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:38:56] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:38:56] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:38:56] [data] Shuffling data
[2023-07-01 11:38:56] [data] Done reading 20,192 sentences
[2023-07-01 11:38:56] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:38:56] Training started
[2023-07-01 11:38:56] Training finished
[2023-07-01 11:39:00] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:39:00] [marian] Running on node20.datos.cluster.uy as process 19235 with command line:
[2023-07-01 11:39:00] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 133 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:39:00] [config] after: 0e
[2023-07-01 11:39:00] [config] after-batches: 0
[2023-07-01 11:39:00] [config] after-epochs: 133
[2023-07-01 11:39:00] [config] all-caps-every: 0
[2023-07-01 11:39:00] [config] allow-unk: false
[2023-07-01 11:39:00] [config] authors: false
[2023-07-01 11:39:00] [config] beam-size: 12
[2023-07-01 11:39:00] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:39:00] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:39:00] [config] bert-masking-fraction: 0.15
[2023-07-01 11:39:00] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:39:00] [config] bert-train-type-embeddings: true
[2023-07-01 11:39:00] [config] bert-type-vocab-size: 2
[2023-07-01 11:39:00] [config] build-info: ""
[2023-07-01 11:39:00] [config] check-gradient-nan: false
[2023-07-01 11:39:00] [config] check-nan: false
[2023-07-01 11:39:00] [config] cite: false
[2023-07-01 11:39:00] [config] clip-norm: 5
[2023-07-01 11:39:00] [config] cost-scaling:
[2023-07-01 11:39:00] [config]   []
[2023-07-01 11:39:00] [config] cost-type: ce-sum
[2023-07-01 11:39:00] [config] cpu-threads: 0
[2023-07-01 11:39:00] [config] data-threads: 8
[2023-07-01 11:39:00] [config] data-weighting: ""
[2023-07-01 11:39:00] [config] data-weighting-type: sentence
[2023-07-01 11:39:00] [config] dec-cell: gru
[2023-07-01 11:39:00] [config] dec-cell-base-depth: 2
[2023-07-01 11:39:00] [config] dec-cell-high-depth: 1
[2023-07-01 11:39:00] [config] dec-depth: 2
[2023-07-01 11:39:00] [config] devices:
[2023-07-01 11:39:00] [config]   - 0
[2023-07-01 11:39:00] [config] dim-emb: 512
[2023-07-01 11:39:00] [config] dim-rnn: 1024
[2023-07-01 11:39:00] [config] dim-vocabs:
[2023-07-01 11:39:00] [config]   - 16384
[2023-07-01 11:39:00] [config]   - 16384
[2023-07-01 11:39:00] [config] disp-first: 0
[2023-07-01 11:39:00] [config] disp-freq: 1000u
[2023-07-01 11:39:00] [config] disp-label-counts: true
[2023-07-01 11:39:00] [config] dropout-rnn: 0
[2023-07-01 11:39:00] [config] dropout-src: 0
[2023-07-01 11:39:00] [config] dropout-trg: 0
[2023-07-01 11:39:00] [config] dump-config: ""
[2023-07-01 11:39:00] [config] dynamic-gradient-scaling:
[2023-07-01 11:39:00] [config]   []
[2023-07-01 11:39:00] [config] early-stopping: 10
[2023-07-01 11:39:00] [config] early-stopping-on: first
[2023-07-01 11:39:00] [config] embedding-fix-src: false
[2023-07-01 11:39:00] [config] embedding-fix-trg: false
[2023-07-01 11:39:00] [config] embedding-normalization: false
[2023-07-01 11:39:00] [config] embedding-vectors:
[2023-07-01 11:39:00] [config]   []
[2023-07-01 11:39:00] [config] enc-cell: gru
[2023-07-01 11:39:00] [config] enc-cell-depth: 1
[2023-07-01 11:39:00] [config] enc-depth: 2
[2023-07-01 11:39:00] [config] enc-type: bidirectional
[2023-07-01 11:39:00] [config] english-title-case-every: 0
[2023-07-01 11:39:00] [config] exponential-smoothing: 0.0001
[2023-07-01 11:39:00] [config] factor-weight: 1
[2023-07-01 11:39:00] [config] factors-combine: sum
[2023-07-01 11:39:00] [config] factors-dim-emb: 0
[2023-07-01 11:39:00] [config] gradient-checkpointing: false
[2023-07-01 11:39:00] [config] gradient-norm-average-window: 100
[2023-07-01 11:39:00] [config] guided-alignment: none
[2023-07-01 11:39:00] [config] guided-alignment-cost: mse
[2023-07-01 11:39:00] [config] guided-alignment-weight: 0.1
[2023-07-01 11:39:00] [config] ignore-model-config: false
[2023-07-01 11:39:00] [config] input-types:
[2023-07-01 11:39:00] [config]   []
[2023-07-01 11:39:00] [config] interpolate-env-vars: false
[2023-07-01 11:39:00] [config] keep-best: false
[2023-07-01 11:39:00] [config] label-smoothing: 0.1
[2023-07-01 11:39:00] [config] layer-normalization: false
[2023-07-01 11:39:00] [config] learn-rate: 0.0003
[2023-07-01 11:39:00] [config] lemma-dependency: ""
[2023-07-01 11:39:00] [config] lemma-dim-emb: 0
[2023-07-01 11:39:00] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:39:00] [config] log-level: info
[2023-07-01 11:39:00] [config] log-time-zone: ""
[2023-07-01 11:39:00] [config] logical-epoch:
[2023-07-01 11:39:00] [config]   - 1e
[2023-07-01 11:39:00] [config]   - 0
[2023-07-01 11:39:00] [config] lr-decay: 0
[2023-07-01 11:39:00] [config] lr-decay-freq: 50000
[2023-07-01 11:39:00] [config] lr-decay-inv-sqrt:
[2023-07-01 11:39:00] [config]   - 16000
[2023-07-01 11:39:00] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:39:00] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:39:00] [config] lr-decay-start:
[2023-07-01 11:39:00] [config]   - 10
[2023-07-01 11:39:00] [config]   - 1
[2023-07-01 11:39:00] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:39:00] [config] lr-report: true
[2023-07-01 11:39:00] [config] lr-warmup: 16000
[2023-07-01 11:39:00] [config] lr-warmup-at-reload: false
[2023-07-01 11:39:00] [config] lr-warmup-cycle: false
[2023-07-01 11:39:00] [config] lr-warmup-start-rate: 0
[2023-07-01 11:39:00] [config] max-length: 100
[2023-07-01 11:39:00] [config] max-length-crop: false
[2023-07-01 11:39:00] [config] max-length-factor: 3
[2023-07-01 11:39:00] [config] maxi-batch: 100
[2023-07-01 11:39:00] [config] maxi-batch-sort: trg
[2023-07-01 11:39:00] [config] mini-batch: 1000
[2023-07-01 11:39:00] [config] mini-batch-fit: true
[2023-07-01 11:39:00] [config] mini-batch-fit-step: 10
[2023-07-01 11:39:00] [config] mini-batch-round-up: true
[2023-07-01 11:39:00] [config] mini-batch-track-lr: false
[2023-07-01 11:39:00] [config] mini-batch-warmup: 0
[2023-07-01 11:39:00] [config] mini-batch-words: 0
[2023-07-01 11:39:00] [config] mini-batch-words-ref: 0
[2023-07-01 11:39:00] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:39:00] [config] multi-loss-type: sum
[2023-07-01 11:39:00] [config] n-best: false
[2023-07-01 11:39:00] [config] no-nccl: false
[2023-07-01 11:39:00] [config] no-reload: false
[2023-07-01 11:39:00] [config] no-restore-corpus: false
[2023-07-01 11:39:00] [config] normalize: 1
[2023-07-01 11:39:00] [config] normalize-gradient: false
[2023-07-01 11:39:00] [config] num-devices: 0
[2023-07-01 11:39:00] [config] optimizer: adam
[2023-07-01 11:39:00] [config] optimizer-delay: 1
[2023-07-01 11:39:00] [config] optimizer-params:
[2023-07-01 11:39:00] [config]   - 0.9
[2023-07-01 11:39:00] [config]   - 0.98
[2023-07-01 11:39:00] [config]   - 1e-09
[2023-07-01 11:39:00] [config] output-omit-bias: false
[2023-07-01 11:39:00] [config] overwrite: true
[2023-07-01 11:39:00] [config] precision:
[2023-07-01 11:39:00] [config]   - float32
[2023-07-01 11:39:00] [config]   - float32
[2023-07-01 11:39:00] [config] pretrained-model: ""
[2023-07-01 11:39:00] [config] quantize-biases: false
[2023-07-01 11:39:00] [config] quantize-bits: 0
[2023-07-01 11:39:00] [config] quantize-log-based: false
[2023-07-01 11:39:00] [config] quantize-optimization-steps: 0
[2023-07-01 11:39:00] [config] quiet: false
[2023-07-01 11:39:00] [config] quiet-translation: true
[2023-07-01 11:39:00] [config] relative-paths: false
[2023-07-01 11:39:00] [config] right-left: false
[2023-07-01 11:39:00] [config] save-freq: 10000u
[2023-07-01 11:39:00] [config] seed: 1234
[2023-07-01 11:39:00] [config] sentencepiece-alphas:
[2023-07-01 11:39:00] [config]   []
[2023-07-01 11:39:00] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:39:00] [config] sentencepiece-options: ""
[2023-07-01 11:39:00] [config] sharding: global
[2023-07-01 11:39:00] [config] shuffle: data
[2023-07-01 11:39:00] [config] shuffle-in-ram: false
[2023-07-01 11:39:00] [config] sigterm: save-and-exit
[2023-07-01 11:39:00] [config] skip: false
[2023-07-01 11:39:00] [config] sqlite: ""
[2023-07-01 11:39:00] [config] sqlite-drop: false
[2023-07-01 11:39:00] [config] sync-freq: 200u
[2023-07-01 11:39:00] [config] sync-sgd: true
[2023-07-01 11:39:00] [config] tempdir: /tmp
[2023-07-01 11:39:00] [config] tied-embeddings: false
[2023-07-01 11:39:00] [config] tied-embeddings-all: true
[2023-07-01 11:39:00] [config] tied-embeddings-src: false
[2023-07-01 11:39:00] [config] train-embedder-rank:
[2023-07-01 11:39:00] [config]   []
[2023-07-01 11:39:00] [config] train-sets:
[2023-07-01 11:39:00] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:39:00] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:39:00] [config] transformer-aan-activation: swish
[2023-07-01 11:39:00] [config] transformer-aan-depth: 2
[2023-07-01 11:39:00] [config] transformer-aan-nogate: false
[2023-07-01 11:39:00] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:39:00] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:39:00] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:39:00] [config] transformer-depth-scaling: false
[2023-07-01 11:39:00] [config] transformer-dim-aan: 2048
[2023-07-01 11:39:00] [config] transformer-dim-ffn: 2048
[2023-07-01 11:39:00] [config] transformer-dropout: 0.1
[2023-07-01 11:39:00] [config] transformer-dropout-attention: 0
[2023-07-01 11:39:00] [config] transformer-dropout-ffn: 0
[2023-07-01 11:39:00] [config] transformer-ffn-activation: swish
[2023-07-01 11:39:00] [config] transformer-ffn-depth: 2
[2023-07-01 11:39:00] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:39:00] [config] transformer-heads: 8
[2023-07-01 11:39:00] [config] transformer-no-projection: false
[2023-07-01 11:39:00] [config] transformer-pool: false
[2023-07-01 11:39:00] [config] transformer-postprocess: dan
[2023-07-01 11:39:00] [config] transformer-postprocess-emb: d
[2023-07-01 11:39:00] [config] transformer-postprocess-top: ""
[2023-07-01 11:39:00] [config] transformer-preprocess: ""
[2023-07-01 11:39:00] [config] transformer-tied-layers:
[2023-07-01 11:39:00] [config]   []
[2023-07-01 11:39:00] [config] transformer-train-position-embeddings: false
[2023-07-01 11:39:00] [config] tsv: false
[2023-07-01 11:39:00] [config] tsv-fields: 0
[2023-07-01 11:39:00] [config] type: transformer
[2023-07-01 11:39:00] [config] ulr: false
[2023-07-01 11:39:00] [config] ulr-dim-emb: 0
[2023-07-01 11:39:00] [config] ulr-dropout: 0
[2023-07-01 11:39:00] [config] ulr-keys-vectors: ""
[2023-07-01 11:39:00] [config] ulr-query-vectors: ""
[2023-07-01 11:39:00] [config] ulr-softmax-temperature: 1
[2023-07-01 11:39:00] [config] ulr-trainable-transformation: false
[2023-07-01 11:39:00] [config] unlikelihood-loss: false
[2023-07-01 11:39:00] [config] valid-freq: 50000000
[2023-07-01 11:39:00] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:39:00] [config] valid-max-length: 1000
[2023-07-01 11:39:00] [config] valid-metrics:
[2023-07-01 11:39:00] [config]   - cross-entropy
[2023-07-01 11:39:00] [config]   - translation
[2023-07-01 11:39:00] [config] valid-mini-batch: 64
[2023-07-01 11:39:00] [config] valid-reset-stalled: false
[2023-07-01 11:39:00] [config] valid-script-args:
[2023-07-01 11:39:00] [config]   []
[2023-07-01 11:39:00] [config] valid-script-path: ""
[2023-07-01 11:39:00] [config] valid-sets:
[2023-07-01 11:39:00] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:39:00] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:39:00] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:39:00] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:39:00] [config] vocabs:
[2023-07-01 11:39:00] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:39:00] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:39:00] [config] word-penalty: 0
[2023-07-01 11:39:00] [config] word-scores: false
[2023-07-01 11:39:00] [config] workspace: 2048
[2023-07-01 11:39:00] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:39:00] Using synchronous SGD
[2023-07-01 11:39:00] Synced seed 1234
[2023-07-01 11:39:00] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:39:00] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:39:00] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:39:00] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:39:00] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:39:00] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:39:01] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:39:01] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:39:01] [comm] Using global sharding
[2023-07-01 11:39:01] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:39:01] [training] Using 1 GPUs
[2023-07-01 11:39:01] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:39:01] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:39:01] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:39:01] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:39:09] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:39:09] [valid] No post-processing script given for validating translator
[2023-07-01 11:39:09] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:39:09] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:39:09] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:39:09] [comm] Using global sharding
[2023-07-01 11:39:09] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:39:09] [training] Using 1 GPUs
[2023-07-01 11:39:09] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:39:10] Allocating memory for general optimizer shards
[2023-07-01 11:39:10] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:39:10] Loading Adam parameters
[2023-07-01 11:39:10] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:39:10] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:39:10] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:39:10] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:39:10] [data] Shuffling data
[2023-07-01 11:39:10] [data] Done reading 20,192 sentences
[2023-07-01 11:39:10] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:39:10] Training started
[2023-07-01 11:39:10] Training finished
[2023-07-01 11:39:14] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:39:14] [marian] Running on node20.datos.cluster.uy as process 19295 with command line:
[2023-07-01 11:39:14] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 134 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:39:14] [config] after: 0e
[2023-07-01 11:39:14] [config] after-batches: 0
[2023-07-01 11:39:14] [config] after-epochs: 134
[2023-07-01 11:39:14] [config] all-caps-every: 0
[2023-07-01 11:39:14] [config] allow-unk: false
[2023-07-01 11:39:14] [config] authors: false
[2023-07-01 11:39:14] [config] beam-size: 12
[2023-07-01 11:39:14] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:39:14] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:39:14] [config] bert-masking-fraction: 0.15
[2023-07-01 11:39:14] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:39:14] [config] bert-train-type-embeddings: true
[2023-07-01 11:39:14] [config] bert-type-vocab-size: 2
[2023-07-01 11:39:14] [config] build-info: ""
[2023-07-01 11:39:14] [config] check-gradient-nan: false
[2023-07-01 11:39:14] [config] check-nan: false
[2023-07-01 11:39:14] [config] cite: false
[2023-07-01 11:39:14] [config] clip-norm: 5
[2023-07-01 11:39:14] [config] cost-scaling:
[2023-07-01 11:39:14] [config]   []
[2023-07-01 11:39:14] [config] cost-type: ce-sum
[2023-07-01 11:39:14] [config] cpu-threads: 0
[2023-07-01 11:39:14] [config] data-threads: 8
[2023-07-01 11:39:14] [config] data-weighting: ""
[2023-07-01 11:39:14] [config] data-weighting-type: sentence
[2023-07-01 11:39:14] [config] dec-cell: gru
[2023-07-01 11:39:14] [config] dec-cell-base-depth: 2
[2023-07-01 11:39:14] [config] dec-cell-high-depth: 1
[2023-07-01 11:39:14] [config] dec-depth: 2
[2023-07-01 11:39:14] [config] devices:
[2023-07-01 11:39:14] [config]   - 0
[2023-07-01 11:39:14] [config] dim-emb: 512
[2023-07-01 11:39:14] [config] dim-rnn: 1024
[2023-07-01 11:39:14] [config] dim-vocabs:
[2023-07-01 11:39:14] [config]   - 16384
[2023-07-01 11:39:14] [config]   - 16384
[2023-07-01 11:39:14] [config] disp-first: 0
[2023-07-01 11:39:14] [config] disp-freq: 1000u
[2023-07-01 11:39:14] [config] disp-label-counts: true
[2023-07-01 11:39:14] [config] dropout-rnn: 0
[2023-07-01 11:39:14] [config] dropout-src: 0
[2023-07-01 11:39:14] [config] dropout-trg: 0
[2023-07-01 11:39:14] [config] dump-config: ""
[2023-07-01 11:39:14] [config] dynamic-gradient-scaling:
[2023-07-01 11:39:14] [config]   []
[2023-07-01 11:39:14] [config] early-stopping: 10
[2023-07-01 11:39:14] [config] early-stopping-on: first
[2023-07-01 11:39:14] [config] embedding-fix-src: false
[2023-07-01 11:39:14] [config] embedding-fix-trg: false
[2023-07-01 11:39:14] [config] embedding-normalization: false
[2023-07-01 11:39:14] [config] embedding-vectors:
[2023-07-01 11:39:14] [config]   []
[2023-07-01 11:39:14] [config] enc-cell: gru
[2023-07-01 11:39:14] [config] enc-cell-depth: 1
[2023-07-01 11:39:14] [config] enc-depth: 2
[2023-07-01 11:39:14] [config] enc-type: bidirectional
[2023-07-01 11:39:14] [config] english-title-case-every: 0
[2023-07-01 11:39:14] [config] exponential-smoothing: 0.0001
[2023-07-01 11:39:14] [config] factor-weight: 1
[2023-07-01 11:39:14] [config] factors-combine: sum
[2023-07-01 11:39:14] [config] factors-dim-emb: 0
[2023-07-01 11:39:14] [config] gradient-checkpointing: false
[2023-07-01 11:39:14] [config] gradient-norm-average-window: 100
[2023-07-01 11:39:14] [config] guided-alignment: none
[2023-07-01 11:39:14] [config] guided-alignment-cost: mse
[2023-07-01 11:39:14] [config] guided-alignment-weight: 0.1
[2023-07-01 11:39:14] [config] ignore-model-config: false
[2023-07-01 11:39:14] [config] input-types:
[2023-07-01 11:39:14] [config]   []
[2023-07-01 11:39:14] [config] interpolate-env-vars: false
[2023-07-01 11:39:14] [config] keep-best: false
[2023-07-01 11:39:14] [config] label-smoothing: 0.1
[2023-07-01 11:39:14] [config] layer-normalization: false
[2023-07-01 11:39:14] [config] learn-rate: 0.0003
[2023-07-01 11:39:14] [config] lemma-dependency: ""
[2023-07-01 11:39:14] [config] lemma-dim-emb: 0
[2023-07-01 11:39:14] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:39:14] [config] log-level: info
[2023-07-01 11:39:14] [config] log-time-zone: ""
[2023-07-01 11:39:14] [config] logical-epoch:
[2023-07-01 11:39:14] [config]   - 1e
[2023-07-01 11:39:14] [config]   - 0
[2023-07-01 11:39:14] [config] lr-decay: 0
[2023-07-01 11:39:14] [config] lr-decay-freq: 50000
[2023-07-01 11:39:14] [config] lr-decay-inv-sqrt:
[2023-07-01 11:39:14] [config]   - 16000
[2023-07-01 11:39:14] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:39:14] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:39:14] [config] lr-decay-start:
[2023-07-01 11:39:14] [config]   - 10
[2023-07-01 11:39:14] [config]   - 1
[2023-07-01 11:39:14] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:39:14] [config] lr-report: true
[2023-07-01 11:39:14] [config] lr-warmup: 16000
[2023-07-01 11:39:14] [config] lr-warmup-at-reload: false
[2023-07-01 11:39:14] [config] lr-warmup-cycle: false
[2023-07-01 11:39:14] [config] lr-warmup-start-rate: 0
[2023-07-01 11:39:14] [config] max-length: 100
[2023-07-01 11:39:14] [config] max-length-crop: false
[2023-07-01 11:39:14] [config] max-length-factor: 3
[2023-07-01 11:39:14] [config] maxi-batch: 100
[2023-07-01 11:39:14] [config] maxi-batch-sort: trg
[2023-07-01 11:39:14] [config] mini-batch: 1000
[2023-07-01 11:39:14] [config] mini-batch-fit: true
[2023-07-01 11:39:14] [config] mini-batch-fit-step: 10
[2023-07-01 11:39:14] [config] mini-batch-round-up: true
[2023-07-01 11:39:14] [config] mini-batch-track-lr: false
[2023-07-01 11:39:14] [config] mini-batch-warmup: 0
[2023-07-01 11:39:14] [config] mini-batch-words: 0
[2023-07-01 11:39:14] [config] mini-batch-words-ref: 0
[2023-07-01 11:39:14] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:39:14] [config] multi-loss-type: sum
[2023-07-01 11:39:14] [config] n-best: false
[2023-07-01 11:39:14] [config] no-nccl: false
[2023-07-01 11:39:14] [config] no-reload: false
[2023-07-01 11:39:14] [config] no-restore-corpus: false
[2023-07-01 11:39:14] [config] normalize: 1
[2023-07-01 11:39:14] [config] normalize-gradient: false
[2023-07-01 11:39:14] [config] num-devices: 0
[2023-07-01 11:39:14] [config] optimizer: adam
[2023-07-01 11:39:14] [config] optimizer-delay: 1
[2023-07-01 11:39:14] [config] optimizer-params:
[2023-07-01 11:39:14] [config]   - 0.9
[2023-07-01 11:39:14] [config]   - 0.98
[2023-07-01 11:39:14] [config]   - 1e-09
[2023-07-01 11:39:14] [config] output-omit-bias: false
[2023-07-01 11:39:14] [config] overwrite: true
[2023-07-01 11:39:14] [config] precision:
[2023-07-01 11:39:14] [config]   - float32
[2023-07-01 11:39:14] [config]   - float32
[2023-07-01 11:39:14] [config] pretrained-model: ""
[2023-07-01 11:39:14] [config] quantize-biases: false
[2023-07-01 11:39:14] [config] quantize-bits: 0
[2023-07-01 11:39:14] [config] quantize-log-based: false
[2023-07-01 11:39:14] [config] quantize-optimization-steps: 0
[2023-07-01 11:39:14] [config] quiet: false
[2023-07-01 11:39:14] [config] quiet-translation: true
[2023-07-01 11:39:14] [config] relative-paths: false
[2023-07-01 11:39:14] [config] right-left: false
[2023-07-01 11:39:14] [config] save-freq: 10000u
[2023-07-01 11:39:14] [config] seed: 1234
[2023-07-01 11:39:14] [config] sentencepiece-alphas:
[2023-07-01 11:39:14] [config]   []
[2023-07-01 11:39:14] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:39:14] [config] sentencepiece-options: ""
[2023-07-01 11:39:14] [config] sharding: global
[2023-07-01 11:39:14] [config] shuffle: data
[2023-07-01 11:39:14] [config] shuffle-in-ram: false
[2023-07-01 11:39:14] [config] sigterm: save-and-exit
[2023-07-01 11:39:14] [config] skip: false
[2023-07-01 11:39:14] [config] sqlite: ""
[2023-07-01 11:39:14] [config] sqlite-drop: false
[2023-07-01 11:39:14] [config] sync-freq: 200u
[2023-07-01 11:39:14] [config] sync-sgd: true
[2023-07-01 11:39:14] [config] tempdir: /tmp
[2023-07-01 11:39:14] [config] tied-embeddings: false
[2023-07-01 11:39:14] [config] tied-embeddings-all: true
[2023-07-01 11:39:14] [config] tied-embeddings-src: false
[2023-07-01 11:39:14] [config] train-embedder-rank:
[2023-07-01 11:39:14] [config]   []
[2023-07-01 11:39:14] [config] train-sets:
[2023-07-01 11:39:14] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:39:14] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:39:14] [config] transformer-aan-activation: swish
[2023-07-01 11:39:14] [config] transformer-aan-depth: 2
[2023-07-01 11:39:14] [config] transformer-aan-nogate: false
[2023-07-01 11:39:14] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:39:14] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:39:14] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:39:14] [config] transformer-depth-scaling: false
[2023-07-01 11:39:14] [config] transformer-dim-aan: 2048
[2023-07-01 11:39:14] [config] transformer-dim-ffn: 2048
[2023-07-01 11:39:14] [config] transformer-dropout: 0.1
[2023-07-01 11:39:14] [config] transformer-dropout-attention: 0
[2023-07-01 11:39:14] [config] transformer-dropout-ffn: 0
[2023-07-01 11:39:14] [config] transformer-ffn-activation: swish
[2023-07-01 11:39:14] [config] transformer-ffn-depth: 2
[2023-07-01 11:39:14] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:39:14] [config] transformer-heads: 8
[2023-07-01 11:39:14] [config] transformer-no-projection: false
[2023-07-01 11:39:14] [config] transformer-pool: false
[2023-07-01 11:39:14] [config] transformer-postprocess: dan
[2023-07-01 11:39:14] [config] transformer-postprocess-emb: d
[2023-07-01 11:39:14] [config] transformer-postprocess-top: ""
[2023-07-01 11:39:14] [config] transformer-preprocess: ""
[2023-07-01 11:39:14] [config] transformer-tied-layers:
[2023-07-01 11:39:14] [config]   []
[2023-07-01 11:39:14] [config] transformer-train-position-embeddings: false
[2023-07-01 11:39:14] [config] tsv: false
[2023-07-01 11:39:14] [config] tsv-fields: 0
[2023-07-01 11:39:14] [config] type: transformer
[2023-07-01 11:39:14] [config] ulr: false
[2023-07-01 11:39:14] [config] ulr-dim-emb: 0
[2023-07-01 11:39:14] [config] ulr-dropout: 0
[2023-07-01 11:39:14] [config] ulr-keys-vectors: ""
[2023-07-01 11:39:14] [config] ulr-query-vectors: ""
[2023-07-01 11:39:14] [config] ulr-softmax-temperature: 1
[2023-07-01 11:39:14] [config] ulr-trainable-transformation: false
[2023-07-01 11:39:14] [config] unlikelihood-loss: false
[2023-07-01 11:39:14] [config] valid-freq: 50000000
[2023-07-01 11:39:14] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:39:14] [config] valid-max-length: 1000
[2023-07-01 11:39:14] [config] valid-metrics:
[2023-07-01 11:39:14] [config]   - cross-entropy
[2023-07-01 11:39:14] [config]   - translation
[2023-07-01 11:39:14] [config] valid-mini-batch: 64
[2023-07-01 11:39:14] [config] valid-reset-stalled: false
[2023-07-01 11:39:14] [config] valid-script-args:
[2023-07-01 11:39:14] [config]   []
[2023-07-01 11:39:14] [config] valid-script-path: ""
[2023-07-01 11:39:14] [config] valid-sets:
[2023-07-01 11:39:14] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:39:14] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:39:14] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:39:14] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:39:14] [config] vocabs:
[2023-07-01 11:39:14] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:39:14] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:39:14] [config] word-penalty: 0
[2023-07-01 11:39:14] [config] word-scores: false
[2023-07-01 11:39:14] [config] workspace: 2048
[2023-07-01 11:39:14] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:39:14] Using synchronous SGD
[2023-07-01 11:39:14] Synced seed 1234
[2023-07-01 11:39:14] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:39:14] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:39:14] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:39:14] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:39:14] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:39:14] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:39:15] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:39:15] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:39:15] [comm] Using global sharding
[2023-07-01 11:39:15] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:39:15] [training] Using 1 GPUs
[2023-07-01 11:39:15] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:39:15] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:39:15] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:39:15] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:39:23] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:39:23] [valid] No post-processing script given for validating translator
[2023-07-01 11:39:23] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:39:23] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:39:23] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:39:23] [comm] Using global sharding
[2023-07-01 11:39:23] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:39:23] [training] Using 1 GPUs
[2023-07-01 11:39:23] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:39:24] Allocating memory for general optimizer shards
[2023-07-01 11:39:24] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:39:24] Loading Adam parameters
[2023-07-01 11:39:24] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:39:24] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:39:24] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:39:24] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:39:24] [data] Shuffling data
[2023-07-01 11:39:24] [data] Done reading 20,192 sentences
[2023-07-01 11:39:24] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:39:24] Training started
[2023-07-01 11:39:24] Training finished
[2023-07-01 11:39:27] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:39:27] [marian] Running on node20.datos.cluster.uy as process 19352 with command line:
[2023-07-01 11:39:27] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 135 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:39:27] [config] after: 0e
[2023-07-01 11:39:27] [config] after-batches: 0
[2023-07-01 11:39:27] [config] after-epochs: 135
[2023-07-01 11:39:27] [config] all-caps-every: 0
[2023-07-01 11:39:27] [config] allow-unk: false
[2023-07-01 11:39:27] [config] authors: false
[2023-07-01 11:39:27] [config] beam-size: 12
[2023-07-01 11:39:27] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:39:27] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:39:27] [config] bert-masking-fraction: 0.15
[2023-07-01 11:39:27] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:39:27] [config] bert-train-type-embeddings: true
[2023-07-01 11:39:27] [config] bert-type-vocab-size: 2
[2023-07-01 11:39:27] [config] build-info: ""
[2023-07-01 11:39:27] [config] check-gradient-nan: false
[2023-07-01 11:39:27] [config] check-nan: false
[2023-07-01 11:39:27] [config] cite: false
[2023-07-01 11:39:27] [config] clip-norm: 5
[2023-07-01 11:39:27] [config] cost-scaling:
[2023-07-01 11:39:27] [config]   []
[2023-07-01 11:39:27] [config] cost-type: ce-sum
[2023-07-01 11:39:27] [config] cpu-threads: 0
[2023-07-01 11:39:27] [config] data-threads: 8
[2023-07-01 11:39:27] [config] data-weighting: ""
[2023-07-01 11:39:27] [config] data-weighting-type: sentence
[2023-07-01 11:39:27] [config] dec-cell: gru
[2023-07-01 11:39:27] [config] dec-cell-base-depth: 2
[2023-07-01 11:39:27] [config] dec-cell-high-depth: 1
[2023-07-01 11:39:27] [config] dec-depth: 2
[2023-07-01 11:39:27] [config] devices:
[2023-07-01 11:39:27] [config]   - 0
[2023-07-01 11:39:27] [config] dim-emb: 512
[2023-07-01 11:39:27] [config] dim-rnn: 1024
[2023-07-01 11:39:27] [config] dim-vocabs:
[2023-07-01 11:39:27] [config]   - 16384
[2023-07-01 11:39:27] [config]   - 16384
[2023-07-01 11:39:27] [config] disp-first: 0
[2023-07-01 11:39:27] [config] disp-freq: 1000u
[2023-07-01 11:39:27] [config] disp-label-counts: true
[2023-07-01 11:39:27] [config] dropout-rnn: 0
[2023-07-01 11:39:27] [config] dropout-src: 0
[2023-07-01 11:39:27] [config] dropout-trg: 0
[2023-07-01 11:39:27] [config] dump-config: ""
[2023-07-01 11:39:27] [config] dynamic-gradient-scaling:
[2023-07-01 11:39:27] [config]   []
[2023-07-01 11:39:27] [config] early-stopping: 10
[2023-07-01 11:39:27] [config] early-stopping-on: first
[2023-07-01 11:39:27] [config] embedding-fix-src: false
[2023-07-01 11:39:27] [config] embedding-fix-trg: false
[2023-07-01 11:39:27] [config] embedding-normalization: false
[2023-07-01 11:39:27] [config] embedding-vectors:
[2023-07-01 11:39:27] [config]   []
[2023-07-01 11:39:27] [config] enc-cell: gru
[2023-07-01 11:39:27] [config] enc-cell-depth: 1
[2023-07-01 11:39:27] [config] enc-depth: 2
[2023-07-01 11:39:27] [config] enc-type: bidirectional
[2023-07-01 11:39:27] [config] english-title-case-every: 0
[2023-07-01 11:39:27] [config] exponential-smoothing: 0.0001
[2023-07-01 11:39:27] [config] factor-weight: 1
[2023-07-01 11:39:27] [config] factors-combine: sum
[2023-07-01 11:39:27] [config] factors-dim-emb: 0
[2023-07-01 11:39:27] [config] gradient-checkpointing: false
[2023-07-01 11:39:27] [config] gradient-norm-average-window: 100
[2023-07-01 11:39:27] [config] guided-alignment: none
[2023-07-01 11:39:27] [config] guided-alignment-cost: mse
[2023-07-01 11:39:27] [config] guided-alignment-weight: 0.1
[2023-07-01 11:39:27] [config] ignore-model-config: false
[2023-07-01 11:39:27] [config] input-types:
[2023-07-01 11:39:27] [config]   []
[2023-07-01 11:39:27] [config] interpolate-env-vars: false
[2023-07-01 11:39:27] [config] keep-best: false
[2023-07-01 11:39:27] [config] label-smoothing: 0.1
[2023-07-01 11:39:27] [config] layer-normalization: false
[2023-07-01 11:39:27] [config] learn-rate: 0.0003
[2023-07-01 11:39:27] [config] lemma-dependency: ""
[2023-07-01 11:39:27] [config] lemma-dim-emb: 0
[2023-07-01 11:39:27] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:39:27] [config] log-level: info
[2023-07-01 11:39:27] [config] log-time-zone: ""
[2023-07-01 11:39:27] [config] logical-epoch:
[2023-07-01 11:39:27] [config]   - 1e
[2023-07-01 11:39:27] [config]   - 0
[2023-07-01 11:39:27] [config] lr-decay: 0
[2023-07-01 11:39:27] [config] lr-decay-freq: 50000
[2023-07-01 11:39:27] [config] lr-decay-inv-sqrt:
[2023-07-01 11:39:27] [config]   - 16000
[2023-07-01 11:39:27] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:39:27] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:39:27] [config] lr-decay-start:
[2023-07-01 11:39:27] [config]   - 10
[2023-07-01 11:39:27] [config]   - 1
[2023-07-01 11:39:27] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:39:27] [config] lr-report: true
[2023-07-01 11:39:27] [config] lr-warmup: 16000
[2023-07-01 11:39:27] [config] lr-warmup-at-reload: false
[2023-07-01 11:39:27] [config] lr-warmup-cycle: false
[2023-07-01 11:39:27] [config] lr-warmup-start-rate: 0
[2023-07-01 11:39:27] [config] max-length: 100
[2023-07-01 11:39:27] [config] max-length-crop: false
[2023-07-01 11:39:27] [config] max-length-factor: 3
[2023-07-01 11:39:27] [config] maxi-batch: 100
[2023-07-01 11:39:27] [config] maxi-batch-sort: trg
[2023-07-01 11:39:27] [config] mini-batch: 1000
[2023-07-01 11:39:27] [config] mini-batch-fit: true
[2023-07-01 11:39:27] [config] mini-batch-fit-step: 10
[2023-07-01 11:39:27] [config] mini-batch-round-up: true
[2023-07-01 11:39:27] [config] mini-batch-track-lr: false
[2023-07-01 11:39:27] [config] mini-batch-warmup: 0
[2023-07-01 11:39:27] [config] mini-batch-words: 0
[2023-07-01 11:39:27] [config] mini-batch-words-ref: 0
[2023-07-01 11:39:27] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:39:27] [config] multi-loss-type: sum
[2023-07-01 11:39:27] [config] n-best: false
[2023-07-01 11:39:27] [config] no-nccl: false
[2023-07-01 11:39:27] [config] no-reload: false
[2023-07-01 11:39:27] [config] no-restore-corpus: false
[2023-07-01 11:39:27] [config] normalize: 1
[2023-07-01 11:39:27] [config] normalize-gradient: false
[2023-07-01 11:39:27] [config] num-devices: 0
[2023-07-01 11:39:27] [config] optimizer: adam
[2023-07-01 11:39:27] [config] optimizer-delay: 1
[2023-07-01 11:39:27] [config] optimizer-params:
[2023-07-01 11:39:27] [config]   - 0.9
[2023-07-01 11:39:27] [config]   - 0.98
[2023-07-01 11:39:27] [config]   - 1e-09
[2023-07-01 11:39:27] [config] output-omit-bias: false
[2023-07-01 11:39:27] [config] overwrite: true
[2023-07-01 11:39:27] [config] precision:
[2023-07-01 11:39:27] [config]   - float32
[2023-07-01 11:39:27] [config]   - float32
[2023-07-01 11:39:27] [config] pretrained-model: ""
[2023-07-01 11:39:27] [config] quantize-biases: false
[2023-07-01 11:39:27] [config] quantize-bits: 0
[2023-07-01 11:39:27] [config] quantize-log-based: false
[2023-07-01 11:39:27] [config] quantize-optimization-steps: 0
[2023-07-01 11:39:27] [config] quiet: false
[2023-07-01 11:39:27] [config] quiet-translation: true
[2023-07-01 11:39:27] [config] relative-paths: false
[2023-07-01 11:39:27] [config] right-left: false
[2023-07-01 11:39:27] [config] save-freq: 10000u
[2023-07-01 11:39:27] [config] seed: 1234
[2023-07-01 11:39:27] [config] sentencepiece-alphas:
[2023-07-01 11:39:27] [config]   []
[2023-07-01 11:39:27] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:39:27] [config] sentencepiece-options: ""
[2023-07-01 11:39:27] [config] sharding: global
[2023-07-01 11:39:27] [config] shuffle: data
[2023-07-01 11:39:27] [config] shuffle-in-ram: false
[2023-07-01 11:39:27] [config] sigterm: save-and-exit
[2023-07-01 11:39:27] [config] skip: false
[2023-07-01 11:39:27] [config] sqlite: ""
[2023-07-01 11:39:27] [config] sqlite-drop: false
[2023-07-01 11:39:27] [config] sync-freq: 200u
[2023-07-01 11:39:27] [config] sync-sgd: true
[2023-07-01 11:39:27] [config] tempdir: /tmp
[2023-07-01 11:39:27] [config] tied-embeddings: false
[2023-07-01 11:39:27] [config] tied-embeddings-all: true
[2023-07-01 11:39:27] [config] tied-embeddings-src: false
[2023-07-01 11:39:27] [config] train-embedder-rank:
[2023-07-01 11:39:27] [config]   []
[2023-07-01 11:39:27] [config] train-sets:
[2023-07-01 11:39:27] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:39:27] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:39:27] [config] transformer-aan-activation: swish
[2023-07-01 11:39:27] [config] transformer-aan-depth: 2
[2023-07-01 11:39:27] [config] transformer-aan-nogate: false
[2023-07-01 11:39:27] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:39:27] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:39:27] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:39:27] [config] transformer-depth-scaling: false
[2023-07-01 11:39:27] [config] transformer-dim-aan: 2048
[2023-07-01 11:39:27] [config] transformer-dim-ffn: 2048
[2023-07-01 11:39:27] [config] transformer-dropout: 0.1
[2023-07-01 11:39:27] [config] transformer-dropout-attention: 0
[2023-07-01 11:39:27] [config] transformer-dropout-ffn: 0
[2023-07-01 11:39:27] [config] transformer-ffn-activation: swish
[2023-07-01 11:39:27] [config] transformer-ffn-depth: 2
[2023-07-01 11:39:27] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:39:27] [config] transformer-heads: 8
[2023-07-01 11:39:27] [config] transformer-no-projection: false
[2023-07-01 11:39:27] [config] transformer-pool: false
[2023-07-01 11:39:27] [config] transformer-postprocess: dan
[2023-07-01 11:39:27] [config] transformer-postprocess-emb: d
[2023-07-01 11:39:27] [config] transformer-postprocess-top: ""
[2023-07-01 11:39:27] [config] transformer-preprocess: ""
[2023-07-01 11:39:27] [config] transformer-tied-layers:
[2023-07-01 11:39:27] [config]   []
[2023-07-01 11:39:27] [config] transformer-train-position-embeddings: false
[2023-07-01 11:39:27] [config] tsv: false
[2023-07-01 11:39:27] [config] tsv-fields: 0
[2023-07-01 11:39:27] [config] type: transformer
[2023-07-01 11:39:27] [config] ulr: false
[2023-07-01 11:39:27] [config] ulr-dim-emb: 0
[2023-07-01 11:39:27] [config] ulr-dropout: 0
[2023-07-01 11:39:27] [config] ulr-keys-vectors: ""
[2023-07-01 11:39:27] [config] ulr-query-vectors: ""
[2023-07-01 11:39:27] [config] ulr-softmax-temperature: 1
[2023-07-01 11:39:27] [config] ulr-trainable-transformation: false
[2023-07-01 11:39:27] [config] unlikelihood-loss: false
[2023-07-01 11:39:27] [config] valid-freq: 50000000
[2023-07-01 11:39:27] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:39:27] [config] valid-max-length: 1000
[2023-07-01 11:39:27] [config] valid-metrics:
[2023-07-01 11:39:27] [config]   - cross-entropy
[2023-07-01 11:39:27] [config]   - translation
[2023-07-01 11:39:27] [config] valid-mini-batch: 64
[2023-07-01 11:39:27] [config] valid-reset-stalled: false
[2023-07-01 11:39:27] [config] valid-script-args:
[2023-07-01 11:39:27] [config]   []
[2023-07-01 11:39:27] [config] valid-script-path: ""
[2023-07-01 11:39:27] [config] valid-sets:
[2023-07-01 11:39:27] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:39:27] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:39:27] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:39:27] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:39:27] [config] vocabs:
[2023-07-01 11:39:27] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:39:27] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:39:27] [config] word-penalty: 0
[2023-07-01 11:39:27] [config] word-scores: false
[2023-07-01 11:39:27] [config] workspace: 2048
[2023-07-01 11:39:27] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:39:27] Using synchronous SGD
[2023-07-01 11:39:27] Synced seed 1234
[2023-07-01 11:39:27] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:39:28] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:39:28] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:39:28] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:39:28] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:39:28] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:39:28] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:39:28] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:39:28] [comm] Using global sharding
[2023-07-01 11:39:28] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:39:28] [training] Using 1 GPUs
[2023-07-01 11:39:28] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:39:28] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:39:29] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:39:29] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:39:36] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:39:36] [valid] No post-processing script given for validating translator
[2023-07-01 11:39:36] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:39:36] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:39:36] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:39:36] [comm] Using global sharding
[2023-07-01 11:39:36] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:39:36] [training] Using 1 GPUs
[2023-07-01 11:39:36] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:39:37] Allocating memory for general optimizer shards
[2023-07-01 11:39:37] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:39:37] Loading Adam parameters
[2023-07-01 11:39:37] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:39:37] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:39:37] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:39:37] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:39:37] [data] Shuffling data
[2023-07-01 11:39:37] [data] Done reading 20,192 sentences
[2023-07-01 11:39:37] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:39:37] Training started
[2023-07-01 11:39:37] Training finished
[2023-07-01 11:39:41] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:39:41] [marian] Running on node20.datos.cluster.uy as process 19410 with command line:
[2023-07-01 11:39:41] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 136 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:39:41] [config] after: 0e
[2023-07-01 11:39:41] [config] after-batches: 0
[2023-07-01 11:39:41] [config] after-epochs: 136
[2023-07-01 11:39:41] [config] all-caps-every: 0
[2023-07-01 11:39:41] [config] allow-unk: false
[2023-07-01 11:39:41] [config] authors: false
[2023-07-01 11:39:41] [config] beam-size: 12
[2023-07-01 11:39:41] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:39:41] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:39:41] [config] bert-masking-fraction: 0.15
[2023-07-01 11:39:41] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:39:41] [config] bert-train-type-embeddings: true
[2023-07-01 11:39:41] [config] bert-type-vocab-size: 2
[2023-07-01 11:39:41] [config] build-info: ""
[2023-07-01 11:39:41] [config] check-gradient-nan: false
[2023-07-01 11:39:41] [config] check-nan: false
[2023-07-01 11:39:41] [config] cite: false
[2023-07-01 11:39:41] [config] clip-norm: 5
[2023-07-01 11:39:41] [config] cost-scaling:
[2023-07-01 11:39:41] [config]   []
[2023-07-01 11:39:41] [config] cost-type: ce-sum
[2023-07-01 11:39:41] [config] cpu-threads: 0
[2023-07-01 11:39:41] [config] data-threads: 8
[2023-07-01 11:39:41] [config] data-weighting: ""
[2023-07-01 11:39:41] [config] data-weighting-type: sentence
[2023-07-01 11:39:41] [config] dec-cell: gru
[2023-07-01 11:39:41] [config] dec-cell-base-depth: 2
[2023-07-01 11:39:41] [config] dec-cell-high-depth: 1
[2023-07-01 11:39:41] [config] dec-depth: 2
[2023-07-01 11:39:41] [config] devices:
[2023-07-01 11:39:41] [config]   - 0
[2023-07-01 11:39:41] [config] dim-emb: 512
[2023-07-01 11:39:41] [config] dim-rnn: 1024
[2023-07-01 11:39:41] [config] dim-vocabs:
[2023-07-01 11:39:41] [config]   - 16384
[2023-07-01 11:39:41] [config]   - 16384
[2023-07-01 11:39:41] [config] disp-first: 0
[2023-07-01 11:39:41] [config] disp-freq: 1000u
[2023-07-01 11:39:41] [config] disp-label-counts: true
[2023-07-01 11:39:41] [config] dropout-rnn: 0
[2023-07-01 11:39:41] [config] dropout-src: 0
[2023-07-01 11:39:41] [config] dropout-trg: 0
[2023-07-01 11:39:41] [config] dump-config: ""
[2023-07-01 11:39:41] [config] dynamic-gradient-scaling:
[2023-07-01 11:39:41] [config]   []
[2023-07-01 11:39:41] [config] early-stopping: 10
[2023-07-01 11:39:41] [config] early-stopping-on: first
[2023-07-01 11:39:41] [config] embedding-fix-src: false
[2023-07-01 11:39:41] [config] embedding-fix-trg: false
[2023-07-01 11:39:41] [config] embedding-normalization: false
[2023-07-01 11:39:41] [config] embedding-vectors:
[2023-07-01 11:39:41] [config]   []
[2023-07-01 11:39:41] [config] enc-cell: gru
[2023-07-01 11:39:41] [config] enc-cell-depth: 1
[2023-07-01 11:39:41] [config] enc-depth: 2
[2023-07-01 11:39:41] [config] enc-type: bidirectional
[2023-07-01 11:39:41] [config] english-title-case-every: 0
[2023-07-01 11:39:41] [config] exponential-smoothing: 0.0001
[2023-07-01 11:39:41] [config] factor-weight: 1
[2023-07-01 11:39:41] [config] factors-combine: sum
[2023-07-01 11:39:41] [config] factors-dim-emb: 0
[2023-07-01 11:39:41] [config] gradient-checkpointing: false
[2023-07-01 11:39:41] [config] gradient-norm-average-window: 100
[2023-07-01 11:39:41] [config] guided-alignment: none
[2023-07-01 11:39:41] [config] guided-alignment-cost: mse
[2023-07-01 11:39:41] [config] guided-alignment-weight: 0.1
[2023-07-01 11:39:41] [config] ignore-model-config: false
[2023-07-01 11:39:41] [config] input-types:
[2023-07-01 11:39:41] [config]   []
[2023-07-01 11:39:41] [config] interpolate-env-vars: false
[2023-07-01 11:39:41] [config] keep-best: false
[2023-07-01 11:39:41] [config] label-smoothing: 0.1
[2023-07-01 11:39:41] [config] layer-normalization: false
[2023-07-01 11:39:41] [config] learn-rate: 0.0003
[2023-07-01 11:39:41] [config] lemma-dependency: ""
[2023-07-01 11:39:41] [config] lemma-dim-emb: 0
[2023-07-01 11:39:41] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:39:41] [config] log-level: info
[2023-07-01 11:39:41] [config] log-time-zone: ""
[2023-07-01 11:39:41] [config] logical-epoch:
[2023-07-01 11:39:41] [config]   - 1e
[2023-07-01 11:39:41] [config]   - 0
[2023-07-01 11:39:41] [config] lr-decay: 0
[2023-07-01 11:39:41] [config] lr-decay-freq: 50000
[2023-07-01 11:39:41] [config] lr-decay-inv-sqrt:
[2023-07-01 11:39:41] [config]   - 16000
[2023-07-01 11:39:41] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:39:41] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:39:41] [config] lr-decay-start:
[2023-07-01 11:39:41] [config]   - 10
[2023-07-01 11:39:41] [config]   - 1
[2023-07-01 11:39:41] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:39:41] [config] lr-report: true
[2023-07-01 11:39:41] [config] lr-warmup: 16000
[2023-07-01 11:39:41] [config] lr-warmup-at-reload: false
[2023-07-01 11:39:41] [config] lr-warmup-cycle: false
[2023-07-01 11:39:41] [config] lr-warmup-start-rate: 0
[2023-07-01 11:39:41] [config] max-length: 100
[2023-07-01 11:39:41] [config] max-length-crop: false
[2023-07-01 11:39:41] [config] max-length-factor: 3
[2023-07-01 11:39:41] [config] maxi-batch: 100
[2023-07-01 11:39:41] [config] maxi-batch-sort: trg
[2023-07-01 11:39:41] [config] mini-batch: 1000
[2023-07-01 11:39:41] [config] mini-batch-fit: true
[2023-07-01 11:39:41] [config] mini-batch-fit-step: 10
[2023-07-01 11:39:41] [config] mini-batch-round-up: true
[2023-07-01 11:39:41] [config] mini-batch-track-lr: false
[2023-07-01 11:39:41] [config] mini-batch-warmup: 0
[2023-07-01 11:39:41] [config] mini-batch-words: 0
[2023-07-01 11:39:41] [config] mini-batch-words-ref: 0
[2023-07-01 11:39:41] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:39:41] [config] multi-loss-type: sum
[2023-07-01 11:39:41] [config] n-best: false
[2023-07-01 11:39:41] [config] no-nccl: false
[2023-07-01 11:39:41] [config] no-reload: false
[2023-07-01 11:39:41] [config] no-restore-corpus: false
[2023-07-01 11:39:41] [config] normalize: 1
[2023-07-01 11:39:41] [config] normalize-gradient: false
[2023-07-01 11:39:41] [config] num-devices: 0
[2023-07-01 11:39:41] [config] optimizer: adam
[2023-07-01 11:39:41] [config] optimizer-delay: 1
[2023-07-01 11:39:41] [config] optimizer-params:
[2023-07-01 11:39:41] [config]   - 0.9
[2023-07-01 11:39:41] [config]   - 0.98
[2023-07-01 11:39:41] [config]   - 1e-09
[2023-07-01 11:39:41] [config] output-omit-bias: false
[2023-07-01 11:39:41] [config] overwrite: true
[2023-07-01 11:39:41] [config] precision:
[2023-07-01 11:39:41] [config]   - float32
[2023-07-01 11:39:41] [config]   - float32
[2023-07-01 11:39:41] [config] pretrained-model: ""
[2023-07-01 11:39:41] [config] quantize-biases: false
[2023-07-01 11:39:41] [config] quantize-bits: 0
[2023-07-01 11:39:41] [config] quantize-log-based: false
[2023-07-01 11:39:41] [config] quantize-optimization-steps: 0
[2023-07-01 11:39:41] [config] quiet: false
[2023-07-01 11:39:41] [config] quiet-translation: true
[2023-07-01 11:39:41] [config] relative-paths: false
[2023-07-01 11:39:41] [config] right-left: false
[2023-07-01 11:39:41] [config] save-freq: 10000u
[2023-07-01 11:39:41] [config] seed: 1234
[2023-07-01 11:39:41] [config] sentencepiece-alphas:
[2023-07-01 11:39:41] [config]   []
[2023-07-01 11:39:41] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:39:41] [config] sentencepiece-options: ""
[2023-07-01 11:39:41] [config] sharding: global
[2023-07-01 11:39:41] [config] shuffle: data
[2023-07-01 11:39:41] [config] shuffle-in-ram: false
[2023-07-01 11:39:41] [config] sigterm: save-and-exit
[2023-07-01 11:39:41] [config] skip: false
[2023-07-01 11:39:41] [config] sqlite: ""
[2023-07-01 11:39:41] [config] sqlite-drop: false
[2023-07-01 11:39:41] [config] sync-freq: 200u
[2023-07-01 11:39:41] [config] sync-sgd: true
[2023-07-01 11:39:41] [config] tempdir: /tmp
[2023-07-01 11:39:41] [config] tied-embeddings: false
[2023-07-01 11:39:41] [config] tied-embeddings-all: true
[2023-07-01 11:39:41] [config] tied-embeddings-src: false
[2023-07-01 11:39:41] [config] train-embedder-rank:
[2023-07-01 11:39:41] [config]   []
[2023-07-01 11:39:41] [config] train-sets:
[2023-07-01 11:39:41] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:39:41] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:39:41] [config] transformer-aan-activation: swish
[2023-07-01 11:39:41] [config] transformer-aan-depth: 2
[2023-07-01 11:39:41] [config] transformer-aan-nogate: false
[2023-07-01 11:39:41] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:39:41] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:39:41] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:39:41] [config] transformer-depth-scaling: false
[2023-07-01 11:39:41] [config] transformer-dim-aan: 2048
[2023-07-01 11:39:41] [config] transformer-dim-ffn: 2048
[2023-07-01 11:39:41] [config] transformer-dropout: 0.1
[2023-07-01 11:39:41] [config] transformer-dropout-attention: 0
[2023-07-01 11:39:41] [config] transformer-dropout-ffn: 0
[2023-07-01 11:39:41] [config] transformer-ffn-activation: swish
[2023-07-01 11:39:41] [config] transformer-ffn-depth: 2
[2023-07-01 11:39:41] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:39:41] [config] transformer-heads: 8
[2023-07-01 11:39:41] [config] transformer-no-projection: false
[2023-07-01 11:39:41] [config] transformer-pool: false
[2023-07-01 11:39:41] [config] transformer-postprocess: dan
[2023-07-01 11:39:41] [config] transformer-postprocess-emb: d
[2023-07-01 11:39:41] [config] transformer-postprocess-top: ""
[2023-07-01 11:39:41] [config] transformer-preprocess: ""
[2023-07-01 11:39:41] [config] transformer-tied-layers:
[2023-07-01 11:39:41] [config]   []
[2023-07-01 11:39:41] [config] transformer-train-position-embeddings: false
[2023-07-01 11:39:41] [config] tsv: false
[2023-07-01 11:39:41] [config] tsv-fields: 0
[2023-07-01 11:39:41] [config] type: transformer
[2023-07-01 11:39:41] [config] ulr: false
[2023-07-01 11:39:41] [config] ulr-dim-emb: 0
[2023-07-01 11:39:41] [config] ulr-dropout: 0
[2023-07-01 11:39:41] [config] ulr-keys-vectors: ""
[2023-07-01 11:39:41] [config] ulr-query-vectors: ""
[2023-07-01 11:39:41] [config] ulr-softmax-temperature: 1
[2023-07-01 11:39:41] [config] ulr-trainable-transformation: false
[2023-07-01 11:39:41] [config] unlikelihood-loss: false
[2023-07-01 11:39:41] [config] valid-freq: 50000000
[2023-07-01 11:39:41] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:39:41] [config] valid-max-length: 1000
[2023-07-01 11:39:41] [config] valid-metrics:
[2023-07-01 11:39:41] [config]   - cross-entropy
[2023-07-01 11:39:41] [config]   - translation
[2023-07-01 11:39:41] [config] valid-mini-batch: 64
[2023-07-01 11:39:41] [config] valid-reset-stalled: false
[2023-07-01 11:39:41] [config] valid-script-args:
[2023-07-01 11:39:41] [config]   []
[2023-07-01 11:39:41] [config] valid-script-path: ""
[2023-07-01 11:39:41] [config] valid-sets:
[2023-07-01 11:39:41] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:39:41] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:39:41] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:39:41] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:39:41] [config] vocabs:
[2023-07-01 11:39:41] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:39:41] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:39:41] [config] word-penalty: 0
[2023-07-01 11:39:41] [config] word-scores: false
[2023-07-01 11:39:41] [config] workspace: 2048
[2023-07-01 11:39:41] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:39:41] Using synchronous SGD
[2023-07-01 11:39:41] Synced seed 1234
[2023-07-01 11:39:41] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:39:41] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:39:41] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:39:41] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:39:41] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:39:41] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:39:42] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:39:42] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:39:42] [comm] Using global sharding
[2023-07-01 11:39:42] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:39:42] [training] Using 1 GPUs
[2023-07-01 11:39:42] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:39:42] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:39:42] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:39:42] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:39:50] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:39:50] [valid] No post-processing script given for validating translator
[2023-07-01 11:39:50] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:39:50] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:39:50] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:39:50] [comm] Using global sharding
[2023-07-01 11:39:50] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:39:50] [training] Using 1 GPUs
[2023-07-01 11:39:50] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:39:50] Allocating memory for general optimizer shards
[2023-07-01 11:39:50] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:39:50] Loading Adam parameters
[2023-07-01 11:39:50] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:39:50] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:39:50] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:39:50] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:39:50] [data] Shuffling data
[2023-07-01 11:39:50] [data] Done reading 20,192 sentences
[2023-07-01 11:39:50] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:39:50] Training started
[2023-07-01 11:39:50] Training finished
[2023-07-01 11:39:54] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:39:54] [marian] Running on node20.datos.cluster.uy as process 19471 with command line:
[2023-07-01 11:39:54] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 137 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:39:54] [config] after: 0e
[2023-07-01 11:39:54] [config] after-batches: 0
[2023-07-01 11:39:54] [config] after-epochs: 137
[2023-07-01 11:39:54] [config] all-caps-every: 0
[2023-07-01 11:39:54] [config] allow-unk: false
[2023-07-01 11:39:54] [config] authors: false
[2023-07-01 11:39:54] [config] beam-size: 12
[2023-07-01 11:39:54] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:39:54] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:39:54] [config] bert-masking-fraction: 0.15
[2023-07-01 11:39:54] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:39:54] [config] bert-train-type-embeddings: true
[2023-07-01 11:39:54] [config] bert-type-vocab-size: 2
[2023-07-01 11:39:54] [config] build-info: ""
[2023-07-01 11:39:54] [config] check-gradient-nan: false
[2023-07-01 11:39:54] [config] check-nan: false
[2023-07-01 11:39:54] [config] cite: false
[2023-07-01 11:39:54] [config] clip-norm: 5
[2023-07-01 11:39:54] [config] cost-scaling:
[2023-07-01 11:39:54] [config]   []
[2023-07-01 11:39:54] [config] cost-type: ce-sum
[2023-07-01 11:39:54] [config] cpu-threads: 0
[2023-07-01 11:39:54] [config] data-threads: 8
[2023-07-01 11:39:54] [config] data-weighting: ""
[2023-07-01 11:39:54] [config] data-weighting-type: sentence
[2023-07-01 11:39:54] [config] dec-cell: gru
[2023-07-01 11:39:54] [config] dec-cell-base-depth: 2
[2023-07-01 11:39:54] [config] dec-cell-high-depth: 1
[2023-07-01 11:39:54] [config] dec-depth: 2
[2023-07-01 11:39:54] [config] devices:
[2023-07-01 11:39:54] [config]   - 0
[2023-07-01 11:39:54] [config] dim-emb: 512
[2023-07-01 11:39:54] [config] dim-rnn: 1024
[2023-07-01 11:39:54] [config] dim-vocabs:
[2023-07-01 11:39:54] [config]   - 16384
[2023-07-01 11:39:54] [config]   - 16384
[2023-07-01 11:39:54] [config] disp-first: 0
[2023-07-01 11:39:54] [config] disp-freq: 1000u
[2023-07-01 11:39:54] [config] disp-label-counts: true
[2023-07-01 11:39:54] [config] dropout-rnn: 0
[2023-07-01 11:39:54] [config] dropout-src: 0
[2023-07-01 11:39:54] [config] dropout-trg: 0
[2023-07-01 11:39:54] [config] dump-config: ""
[2023-07-01 11:39:54] [config] dynamic-gradient-scaling:
[2023-07-01 11:39:54] [config]   []
[2023-07-01 11:39:54] [config] early-stopping: 10
[2023-07-01 11:39:54] [config] early-stopping-on: first
[2023-07-01 11:39:54] [config] embedding-fix-src: false
[2023-07-01 11:39:54] [config] embedding-fix-trg: false
[2023-07-01 11:39:54] [config] embedding-normalization: false
[2023-07-01 11:39:54] [config] embedding-vectors:
[2023-07-01 11:39:54] [config]   []
[2023-07-01 11:39:54] [config] enc-cell: gru
[2023-07-01 11:39:54] [config] enc-cell-depth: 1
[2023-07-01 11:39:54] [config] enc-depth: 2
[2023-07-01 11:39:54] [config] enc-type: bidirectional
[2023-07-01 11:39:54] [config] english-title-case-every: 0
[2023-07-01 11:39:54] [config] exponential-smoothing: 0.0001
[2023-07-01 11:39:54] [config] factor-weight: 1
[2023-07-01 11:39:54] [config] factors-combine: sum
[2023-07-01 11:39:54] [config] factors-dim-emb: 0
[2023-07-01 11:39:54] [config] gradient-checkpointing: false
[2023-07-01 11:39:54] [config] gradient-norm-average-window: 100
[2023-07-01 11:39:54] [config] guided-alignment: none
[2023-07-01 11:39:54] [config] guided-alignment-cost: mse
[2023-07-01 11:39:54] [config] guided-alignment-weight: 0.1
[2023-07-01 11:39:54] [config] ignore-model-config: false
[2023-07-01 11:39:54] [config] input-types:
[2023-07-01 11:39:54] [config]   []
[2023-07-01 11:39:54] [config] interpolate-env-vars: false
[2023-07-01 11:39:54] [config] keep-best: false
[2023-07-01 11:39:54] [config] label-smoothing: 0.1
[2023-07-01 11:39:54] [config] layer-normalization: false
[2023-07-01 11:39:54] [config] learn-rate: 0.0003
[2023-07-01 11:39:54] [config] lemma-dependency: ""
[2023-07-01 11:39:54] [config] lemma-dim-emb: 0
[2023-07-01 11:39:54] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:39:54] [config] log-level: info
[2023-07-01 11:39:54] [config] log-time-zone: ""
[2023-07-01 11:39:54] [config] logical-epoch:
[2023-07-01 11:39:54] [config]   - 1e
[2023-07-01 11:39:54] [config]   - 0
[2023-07-01 11:39:54] [config] lr-decay: 0
[2023-07-01 11:39:54] [config] lr-decay-freq: 50000
[2023-07-01 11:39:54] [config] lr-decay-inv-sqrt:
[2023-07-01 11:39:54] [config]   - 16000
[2023-07-01 11:39:54] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:39:54] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:39:54] [config] lr-decay-start:
[2023-07-01 11:39:54] [config]   - 10
[2023-07-01 11:39:54] [config]   - 1
[2023-07-01 11:39:54] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:39:54] [config] lr-report: true
[2023-07-01 11:39:54] [config] lr-warmup: 16000
[2023-07-01 11:39:54] [config] lr-warmup-at-reload: false
[2023-07-01 11:39:54] [config] lr-warmup-cycle: false
[2023-07-01 11:39:54] [config] lr-warmup-start-rate: 0
[2023-07-01 11:39:54] [config] max-length: 100
[2023-07-01 11:39:54] [config] max-length-crop: false
[2023-07-01 11:39:54] [config] max-length-factor: 3
[2023-07-01 11:39:54] [config] maxi-batch: 100
[2023-07-01 11:39:54] [config] maxi-batch-sort: trg
[2023-07-01 11:39:54] [config] mini-batch: 1000
[2023-07-01 11:39:54] [config] mini-batch-fit: true
[2023-07-01 11:39:54] [config] mini-batch-fit-step: 10
[2023-07-01 11:39:54] [config] mini-batch-round-up: true
[2023-07-01 11:39:54] [config] mini-batch-track-lr: false
[2023-07-01 11:39:54] [config] mini-batch-warmup: 0
[2023-07-01 11:39:54] [config] mini-batch-words: 0
[2023-07-01 11:39:54] [config] mini-batch-words-ref: 0
[2023-07-01 11:39:54] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:39:54] [config] multi-loss-type: sum
[2023-07-01 11:39:54] [config] n-best: false
[2023-07-01 11:39:54] [config] no-nccl: false
[2023-07-01 11:39:54] [config] no-reload: false
[2023-07-01 11:39:54] [config] no-restore-corpus: false
[2023-07-01 11:39:54] [config] normalize: 1
[2023-07-01 11:39:54] [config] normalize-gradient: false
[2023-07-01 11:39:54] [config] num-devices: 0
[2023-07-01 11:39:54] [config] optimizer: adam
[2023-07-01 11:39:54] [config] optimizer-delay: 1
[2023-07-01 11:39:54] [config] optimizer-params:
[2023-07-01 11:39:54] [config]   - 0.9
[2023-07-01 11:39:54] [config]   - 0.98
[2023-07-01 11:39:54] [config]   - 1e-09
[2023-07-01 11:39:54] [config] output-omit-bias: false
[2023-07-01 11:39:54] [config] overwrite: true
[2023-07-01 11:39:54] [config] precision:
[2023-07-01 11:39:54] [config]   - float32
[2023-07-01 11:39:54] [config]   - float32
[2023-07-01 11:39:54] [config] pretrained-model: ""
[2023-07-01 11:39:54] [config] quantize-biases: false
[2023-07-01 11:39:54] [config] quantize-bits: 0
[2023-07-01 11:39:54] [config] quantize-log-based: false
[2023-07-01 11:39:54] [config] quantize-optimization-steps: 0
[2023-07-01 11:39:54] [config] quiet: false
[2023-07-01 11:39:54] [config] quiet-translation: true
[2023-07-01 11:39:54] [config] relative-paths: false
[2023-07-01 11:39:54] [config] right-left: false
[2023-07-01 11:39:54] [config] save-freq: 10000u
[2023-07-01 11:39:54] [config] seed: 1234
[2023-07-01 11:39:54] [config] sentencepiece-alphas:
[2023-07-01 11:39:54] [config]   []
[2023-07-01 11:39:54] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:39:54] [config] sentencepiece-options: ""
[2023-07-01 11:39:54] [config] sharding: global
[2023-07-01 11:39:54] [config] shuffle: data
[2023-07-01 11:39:54] [config] shuffle-in-ram: false
[2023-07-01 11:39:54] [config] sigterm: save-and-exit
[2023-07-01 11:39:54] [config] skip: false
[2023-07-01 11:39:54] [config] sqlite: ""
[2023-07-01 11:39:54] [config] sqlite-drop: false
[2023-07-01 11:39:54] [config] sync-freq: 200u
[2023-07-01 11:39:54] [config] sync-sgd: true
[2023-07-01 11:39:54] [config] tempdir: /tmp
[2023-07-01 11:39:54] [config] tied-embeddings: false
[2023-07-01 11:39:54] [config] tied-embeddings-all: true
[2023-07-01 11:39:54] [config] tied-embeddings-src: false
[2023-07-01 11:39:54] [config] train-embedder-rank:
[2023-07-01 11:39:54] [config]   []
[2023-07-01 11:39:54] [config] train-sets:
[2023-07-01 11:39:54] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:39:54] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:39:54] [config] transformer-aan-activation: swish
[2023-07-01 11:39:54] [config] transformer-aan-depth: 2
[2023-07-01 11:39:54] [config] transformer-aan-nogate: false
[2023-07-01 11:39:54] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:39:54] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:39:54] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:39:54] [config] transformer-depth-scaling: false
[2023-07-01 11:39:54] [config] transformer-dim-aan: 2048
[2023-07-01 11:39:54] [config] transformer-dim-ffn: 2048
[2023-07-01 11:39:54] [config] transformer-dropout: 0.1
[2023-07-01 11:39:54] [config] transformer-dropout-attention: 0
[2023-07-01 11:39:54] [config] transformer-dropout-ffn: 0
[2023-07-01 11:39:54] [config] transformer-ffn-activation: swish
[2023-07-01 11:39:54] [config] transformer-ffn-depth: 2
[2023-07-01 11:39:54] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:39:54] [config] transformer-heads: 8
[2023-07-01 11:39:54] [config] transformer-no-projection: false
[2023-07-01 11:39:54] [config] transformer-pool: false
[2023-07-01 11:39:54] [config] transformer-postprocess: dan
[2023-07-01 11:39:54] [config] transformer-postprocess-emb: d
[2023-07-01 11:39:54] [config] transformer-postprocess-top: ""
[2023-07-01 11:39:54] [config] transformer-preprocess: ""
[2023-07-01 11:39:54] [config] transformer-tied-layers:
[2023-07-01 11:39:54] [config]   []
[2023-07-01 11:39:54] [config] transformer-train-position-embeddings: false
[2023-07-01 11:39:54] [config] tsv: false
[2023-07-01 11:39:54] [config] tsv-fields: 0
[2023-07-01 11:39:54] [config] type: transformer
[2023-07-01 11:39:54] [config] ulr: false
[2023-07-01 11:39:54] [config] ulr-dim-emb: 0
[2023-07-01 11:39:54] [config] ulr-dropout: 0
[2023-07-01 11:39:54] [config] ulr-keys-vectors: ""
[2023-07-01 11:39:54] [config] ulr-query-vectors: ""
[2023-07-01 11:39:54] [config] ulr-softmax-temperature: 1
[2023-07-01 11:39:54] [config] ulr-trainable-transformation: false
[2023-07-01 11:39:54] [config] unlikelihood-loss: false
[2023-07-01 11:39:54] [config] valid-freq: 50000000
[2023-07-01 11:39:54] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:39:54] [config] valid-max-length: 1000
[2023-07-01 11:39:54] [config] valid-metrics:
[2023-07-01 11:39:54] [config]   - cross-entropy
[2023-07-01 11:39:54] [config]   - translation
[2023-07-01 11:39:54] [config] valid-mini-batch: 64
[2023-07-01 11:39:54] [config] valid-reset-stalled: false
[2023-07-01 11:39:54] [config] valid-script-args:
[2023-07-01 11:39:54] [config]   []
[2023-07-01 11:39:54] [config] valid-script-path: ""
[2023-07-01 11:39:54] [config] valid-sets:
[2023-07-01 11:39:54] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:39:54] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:39:54] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:39:54] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:39:54] [config] vocabs:
[2023-07-01 11:39:54] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:39:54] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:39:54] [config] word-penalty: 0
[2023-07-01 11:39:54] [config] word-scores: false
[2023-07-01 11:39:54] [config] workspace: 2048
[2023-07-01 11:39:54] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:39:54] Using synchronous SGD
[2023-07-01 11:39:54] Synced seed 1234
[2023-07-01 11:39:54] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:39:55] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:39:55] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:39:55] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:39:55] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:39:55] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:39:55] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:39:55] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:39:55] [comm] Using global sharding
[2023-07-01 11:39:55] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:39:55] [training] Using 1 GPUs
[2023-07-01 11:39:55] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:39:55] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:39:56] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:39:56] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:40:03] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:40:03] [valid] No post-processing script given for validating translator
[2023-07-01 11:40:03] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:40:03] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:40:03] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:40:03] [comm] Using global sharding
[2023-07-01 11:40:03] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:40:03] [training] Using 1 GPUs
[2023-07-01 11:40:03] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:40:04] Allocating memory for general optimizer shards
[2023-07-01 11:40:04] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:40:04] Loading Adam parameters
[2023-07-01 11:40:04] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:40:04] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:40:04] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:40:04] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:40:04] [data] Shuffling data
[2023-07-01 11:40:04] [data] Done reading 20,192 sentences
[2023-07-01 11:40:04] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:40:04] Training started
[2023-07-01 11:40:04] Training finished
[2023-07-01 11:40:07] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:40:07] [marian] Running on node20.datos.cluster.uy as process 19530 with command line:
[2023-07-01 11:40:07] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 138 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:40:07] [config] after: 0e
[2023-07-01 11:40:07] [config] after-batches: 0
[2023-07-01 11:40:07] [config] after-epochs: 138
[2023-07-01 11:40:07] [config] all-caps-every: 0
[2023-07-01 11:40:07] [config] allow-unk: false
[2023-07-01 11:40:07] [config] authors: false
[2023-07-01 11:40:07] [config] beam-size: 12
[2023-07-01 11:40:07] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:40:07] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:40:07] [config] bert-masking-fraction: 0.15
[2023-07-01 11:40:07] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:40:07] [config] bert-train-type-embeddings: true
[2023-07-01 11:40:07] [config] bert-type-vocab-size: 2
[2023-07-01 11:40:07] [config] build-info: ""
[2023-07-01 11:40:07] [config] check-gradient-nan: false
[2023-07-01 11:40:07] [config] check-nan: false
[2023-07-01 11:40:07] [config] cite: false
[2023-07-01 11:40:07] [config] clip-norm: 5
[2023-07-01 11:40:07] [config] cost-scaling:
[2023-07-01 11:40:07] [config]   []
[2023-07-01 11:40:07] [config] cost-type: ce-sum
[2023-07-01 11:40:07] [config] cpu-threads: 0
[2023-07-01 11:40:07] [config] data-threads: 8
[2023-07-01 11:40:07] [config] data-weighting: ""
[2023-07-01 11:40:07] [config] data-weighting-type: sentence
[2023-07-01 11:40:07] [config] dec-cell: gru
[2023-07-01 11:40:07] [config] dec-cell-base-depth: 2
[2023-07-01 11:40:07] [config] dec-cell-high-depth: 1
[2023-07-01 11:40:07] [config] dec-depth: 2
[2023-07-01 11:40:07] [config] devices:
[2023-07-01 11:40:07] [config]   - 0
[2023-07-01 11:40:07] [config] dim-emb: 512
[2023-07-01 11:40:07] [config] dim-rnn: 1024
[2023-07-01 11:40:07] [config] dim-vocabs:
[2023-07-01 11:40:07] [config]   - 16384
[2023-07-01 11:40:07] [config]   - 16384
[2023-07-01 11:40:07] [config] disp-first: 0
[2023-07-01 11:40:07] [config] disp-freq: 1000u
[2023-07-01 11:40:07] [config] disp-label-counts: true
[2023-07-01 11:40:07] [config] dropout-rnn: 0
[2023-07-01 11:40:07] [config] dropout-src: 0
[2023-07-01 11:40:07] [config] dropout-trg: 0
[2023-07-01 11:40:07] [config] dump-config: ""
[2023-07-01 11:40:07] [config] dynamic-gradient-scaling:
[2023-07-01 11:40:07] [config]   []
[2023-07-01 11:40:07] [config] early-stopping: 10
[2023-07-01 11:40:07] [config] early-stopping-on: first
[2023-07-01 11:40:07] [config] embedding-fix-src: false
[2023-07-01 11:40:07] [config] embedding-fix-trg: false
[2023-07-01 11:40:07] [config] embedding-normalization: false
[2023-07-01 11:40:07] [config] embedding-vectors:
[2023-07-01 11:40:07] [config]   []
[2023-07-01 11:40:07] [config] enc-cell: gru
[2023-07-01 11:40:07] [config] enc-cell-depth: 1
[2023-07-01 11:40:07] [config] enc-depth: 2
[2023-07-01 11:40:07] [config] enc-type: bidirectional
[2023-07-01 11:40:07] [config] english-title-case-every: 0
[2023-07-01 11:40:07] [config] exponential-smoothing: 0.0001
[2023-07-01 11:40:07] [config] factor-weight: 1
[2023-07-01 11:40:07] [config] factors-combine: sum
[2023-07-01 11:40:07] [config] factors-dim-emb: 0
[2023-07-01 11:40:07] [config] gradient-checkpointing: false
[2023-07-01 11:40:07] [config] gradient-norm-average-window: 100
[2023-07-01 11:40:07] [config] guided-alignment: none
[2023-07-01 11:40:07] [config] guided-alignment-cost: mse
[2023-07-01 11:40:07] [config] guided-alignment-weight: 0.1
[2023-07-01 11:40:07] [config] ignore-model-config: false
[2023-07-01 11:40:07] [config] input-types:
[2023-07-01 11:40:07] [config]   []
[2023-07-01 11:40:07] [config] interpolate-env-vars: false
[2023-07-01 11:40:07] [config] keep-best: false
[2023-07-01 11:40:07] [config] label-smoothing: 0.1
[2023-07-01 11:40:07] [config] layer-normalization: false
[2023-07-01 11:40:07] [config] learn-rate: 0.0003
[2023-07-01 11:40:07] [config] lemma-dependency: ""
[2023-07-01 11:40:07] [config] lemma-dim-emb: 0
[2023-07-01 11:40:07] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:40:07] [config] log-level: info
[2023-07-01 11:40:07] [config] log-time-zone: ""
[2023-07-01 11:40:07] [config] logical-epoch:
[2023-07-01 11:40:07] [config]   - 1e
[2023-07-01 11:40:07] [config]   - 0
[2023-07-01 11:40:07] [config] lr-decay: 0
[2023-07-01 11:40:07] [config] lr-decay-freq: 50000
[2023-07-01 11:40:07] [config] lr-decay-inv-sqrt:
[2023-07-01 11:40:07] [config]   - 16000
[2023-07-01 11:40:07] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:40:07] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:40:07] [config] lr-decay-start:
[2023-07-01 11:40:07] [config]   - 10
[2023-07-01 11:40:07] [config]   - 1
[2023-07-01 11:40:07] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:40:07] [config] lr-report: true
[2023-07-01 11:40:07] [config] lr-warmup: 16000
[2023-07-01 11:40:07] [config] lr-warmup-at-reload: false
[2023-07-01 11:40:07] [config] lr-warmup-cycle: false
[2023-07-01 11:40:07] [config] lr-warmup-start-rate: 0
[2023-07-01 11:40:07] [config] max-length: 100
[2023-07-01 11:40:07] [config] max-length-crop: false
[2023-07-01 11:40:07] [config] max-length-factor: 3
[2023-07-01 11:40:07] [config] maxi-batch: 100
[2023-07-01 11:40:07] [config] maxi-batch-sort: trg
[2023-07-01 11:40:07] [config] mini-batch: 1000
[2023-07-01 11:40:07] [config] mini-batch-fit: true
[2023-07-01 11:40:07] [config] mini-batch-fit-step: 10
[2023-07-01 11:40:07] [config] mini-batch-round-up: true
[2023-07-01 11:40:07] [config] mini-batch-track-lr: false
[2023-07-01 11:40:07] [config] mini-batch-warmup: 0
[2023-07-01 11:40:07] [config] mini-batch-words: 0
[2023-07-01 11:40:07] [config] mini-batch-words-ref: 0
[2023-07-01 11:40:07] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:40:07] [config] multi-loss-type: sum
[2023-07-01 11:40:07] [config] n-best: false
[2023-07-01 11:40:07] [config] no-nccl: false
[2023-07-01 11:40:07] [config] no-reload: false
[2023-07-01 11:40:07] [config] no-restore-corpus: false
[2023-07-01 11:40:07] [config] normalize: 1
[2023-07-01 11:40:07] [config] normalize-gradient: false
[2023-07-01 11:40:07] [config] num-devices: 0
[2023-07-01 11:40:07] [config] optimizer: adam
[2023-07-01 11:40:07] [config] optimizer-delay: 1
[2023-07-01 11:40:07] [config] optimizer-params:
[2023-07-01 11:40:07] [config]   - 0.9
[2023-07-01 11:40:07] [config]   - 0.98
[2023-07-01 11:40:07] [config]   - 1e-09
[2023-07-01 11:40:07] [config] output-omit-bias: false
[2023-07-01 11:40:07] [config] overwrite: true
[2023-07-01 11:40:07] [config] precision:
[2023-07-01 11:40:07] [config]   - float32
[2023-07-01 11:40:07] [config]   - float32
[2023-07-01 11:40:07] [config] pretrained-model: ""
[2023-07-01 11:40:07] [config] quantize-biases: false
[2023-07-01 11:40:07] [config] quantize-bits: 0
[2023-07-01 11:40:07] [config] quantize-log-based: false
[2023-07-01 11:40:07] [config] quantize-optimization-steps: 0
[2023-07-01 11:40:07] [config] quiet: false
[2023-07-01 11:40:07] [config] quiet-translation: true
[2023-07-01 11:40:07] [config] relative-paths: false
[2023-07-01 11:40:07] [config] right-left: false
[2023-07-01 11:40:07] [config] save-freq: 10000u
[2023-07-01 11:40:07] [config] seed: 1234
[2023-07-01 11:40:07] [config] sentencepiece-alphas:
[2023-07-01 11:40:07] [config]   []
[2023-07-01 11:40:07] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:40:07] [config] sentencepiece-options: ""
[2023-07-01 11:40:07] [config] sharding: global
[2023-07-01 11:40:07] [config] shuffle: data
[2023-07-01 11:40:07] [config] shuffle-in-ram: false
[2023-07-01 11:40:07] [config] sigterm: save-and-exit
[2023-07-01 11:40:08] [config] skip: false
[2023-07-01 11:40:08] [config] sqlite: ""
[2023-07-01 11:40:08] [config] sqlite-drop: false
[2023-07-01 11:40:08] [config] sync-freq: 200u
[2023-07-01 11:40:08] [config] sync-sgd: true
[2023-07-01 11:40:08] [config] tempdir: /tmp
[2023-07-01 11:40:08] [config] tied-embeddings: false
[2023-07-01 11:40:08] [config] tied-embeddings-all: true
[2023-07-01 11:40:08] [config] tied-embeddings-src: false
[2023-07-01 11:40:08] [config] train-embedder-rank:
[2023-07-01 11:40:08] [config]   []
[2023-07-01 11:40:08] [config] train-sets:
[2023-07-01 11:40:08] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:40:08] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:40:08] [config] transformer-aan-activation: swish
[2023-07-01 11:40:08] [config] transformer-aan-depth: 2
[2023-07-01 11:40:08] [config] transformer-aan-nogate: false
[2023-07-01 11:40:08] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:40:08] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:40:08] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:40:08] [config] transformer-depth-scaling: false
[2023-07-01 11:40:08] [config] transformer-dim-aan: 2048
[2023-07-01 11:40:08] [config] transformer-dim-ffn: 2048
[2023-07-01 11:40:08] [config] transformer-dropout: 0.1
[2023-07-01 11:40:08] [config] transformer-dropout-attention: 0
[2023-07-01 11:40:08] [config] transformer-dropout-ffn: 0
[2023-07-01 11:40:08] [config] transformer-ffn-activation: swish
[2023-07-01 11:40:08] [config] transformer-ffn-depth: 2
[2023-07-01 11:40:08] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:40:08] [config] transformer-heads: 8
[2023-07-01 11:40:08] [config] transformer-no-projection: false
[2023-07-01 11:40:08] [config] transformer-pool: false
[2023-07-01 11:40:08] [config] transformer-postprocess: dan
[2023-07-01 11:40:08] [config] transformer-postprocess-emb: d
[2023-07-01 11:40:08] [config] transformer-postprocess-top: ""
[2023-07-01 11:40:08] [config] transformer-preprocess: ""
[2023-07-01 11:40:08] [config] transformer-tied-layers:
[2023-07-01 11:40:08] [config]   []
[2023-07-01 11:40:08] [config] transformer-train-position-embeddings: false
[2023-07-01 11:40:08] [config] tsv: false
[2023-07-01 11:40:08] [config] tsv-fields: 0
[2023-07-01 11:40:08] [config] type: transformer
[2023-07-01 11:40:08] [config] ulr: false
[2023-07-01 11:40:08] [config] ulr-dim-emb: 0
[2023-07-01 11:40:08] [config] ulr-dropout: 0
[2023-07-01 11:40:08] [config] ulr-keys-vectors: ""
[2023-07-01 11:40:08] [config] ulr-query-vectors: ""
[2023-07-01 11:40:08] [config] ulr-softmax-temperature: 1
[2023-07-01 11:40:08] [config] ulr-trainable-transformation: false
[2023-07-01 11:40:08] [config] unlikelihood-loss: false
[2023-07-01 11:40:08] [config] valid-freq: 50000000
[2023-07-01 11:40:08] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:40:08] [config] valid-max-length: 1000
[2023-07-01 11:40:08] [config] valid-metrics:
[2023-07-01 11:40:08] [config]   - cross-entropy
[2023-07-01 11:40:08] [config]   - translation
[2023-07-01 11:40:08] [config] valid-mini-batch: 64
[2023-07-01 11:40:08] [config] valid-reset-stalled: false
[2023-07-01 11:40:08] [config] valid-script-args:
[2023-07-01 11:40:08] [config]   []
[2023-07-01 11:40:08] [config] valid-script-path: ""
[2023-07-01 11:40:08] [config] valid-sets:
[2023-07-01 11:40:08] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:40:08] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:40:08] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:40:08] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:40:08] [config] vocabs:
[2023-07-01 11:40:08] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:40:08] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:40:08] [config] word-penalty: 0
[2023-07-01 11:40:08] [config] word-scores: false
[2023-07-01 11:40:08] [config] workspace: 2048
[2023-07-01 11:40:08] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:40:08] Using synchronous SGD
[2023-07-01 11:40:08] Synced seed 1234
[2023-07-01 11:40:08] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:40:08] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:40:08] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:40:08] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:40:08] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:40:08] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:40:09] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:40:09] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:40:09] [comm] Using global sharding
[2023-07-01 11:40:09] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:40:09] [training] Using 1 GPUs
[2023-07-01 11:40:09] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:40:09] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:40:09] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:40:09] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:40:17] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:40:17] [valid] No post-processing script given for validating translator
[2023-07-01 11:40:17] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:40:17] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:40:17] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:40:17] [comm] Using global sharding
[2023-07-01 11:40:17] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:40:17] [training] Using 1 GPUs
[2023-07-01 11:40:17] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:40:17] Allocating memory for general optimizer shards
[2023-07-01 11:40:17] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:40:17] Loading Adam parameters
[2023-07-01 11:40:17] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:40:17] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:40:17] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:40:17] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:40:17] [data] Shuffling data
[2023-07-01 11:40:17] [data] Done reading 20,192 sentences
[2023-07-01 11:40:17] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:40:17] Training started
[2023-07-01 11:40:17] Training finished
[2023-07-01 11:40:21] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:40:21] [marian] Running on node20.datos.cluster.uy as process 19589 with command line:
[2023-07-01 11:40:21] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 139 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:40:21] [config] after: 0e
[2023-07-01 11:40:21] [config] after-batches: 0
[2023-07-01 11:40:21] [config] after-epochs: 139
[2023-07-01 11:40:21] [config] all-caps-every: 0
[2023-07-01 11:40:21] [config] allow-unk: false
[2023-07-01 11:40:21] [config] authors: false
[2023-07-01 11:40:21] [config] beam-size: 12
[2023-07-01 11:40:21] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:40:21] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:40:21] [config] bert-masking-fraction: 0.15
[2023-07-01 11:40:21] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:40:21] [config] bert-train-type-embeddings: true
[2023-07-01 11:40:21] [config] bert-type-vocab-size: 2
[2023-07-01 11:40:21] [config] build-info: ""
[2023-07-01 11:40:21] [config] check-gradient-nan: false
[2023-07-01 11:40:21] [config] check-nan: false
[2023-07-01 11:40:21] [config] cite: false
[2023-07-01 11:40:21] [config] clip-norm: 5
[2023-07-01 11:40:21] [config] cost-scaling:
[2023-07-01 11:40:21] [config]   []
[2023-07-01 11:40:21] [config] cost-type: ce-sum
[2023-07-01 11:40:21] [config] cpu-threads: 0
[2023-07-01 11:40:21] [config] data-threads: 8
[2023-07-01 11:40:21] [config] data-weighting: ""
[2023-07-01 11:40:21] [config] data-weighting-type: sentence
[2023-07-01 11:40:21] [config] dec-cell: gru
[2023-07-01 11:40:21] [config] dec-cell-base-depth: 2
[2023-07-01 11:40:21] [config] dec-cell-high-depth: 1
[2023-07-01 11:40:21] [config] dec-depth: 2
[2023-07-01 11:40:21] [config] devices:
[2023-07-01 11:40:21] [config]   - 0
[2023-07-01 11:40:21] [config] dim-emb: 512
[2023-07-01 11:40:21] [config] dim-rnn: 1024
[2023-07-01 11:40:21] [config] dim-vocabs:
[2023-07-01 11:40:21] [config]   - 16384
[2023-07-01 11:40:21] [config]   - 16384
[2023-07-01 11:40:21] [config] disp-first: 0
[2023-07-01 11:40:21] [config] disp-freq: 1000u
[2023-07-01 11:40:21] [config] disp-label-counts: true
[2023-07-01 11:40:21] [config] dropout-rnn: 0
[2023-07-01 11:40:21] [config] dropout-src: 0
[2023-07-01 11:40:21] [config] dropout-trg: 0
[2023-07-01 11:40:21] [config] dump-config: ""
[2023-07-01 11:40:21] [config] dynamic-gradient-scaling:
[2023-07-01 11:40:21] [config]   []
[2023-07-01 11:40:21] [config] early-stopping: 10
[2023-07-01 11:40:21] [config] early-stopping-on: first
[2023-07-01 11:40:21] [config] embedding-fix-src: false
[2023-07-01 11:40:21] [config] embedding-fix-trg: false
[2023-07-01 11:40:21] [config] embedding-normalization: false
[2023-07-01 11:40:21] [config] embedding-vectors:
[2023-07-01 11:40:21] [config]   []
[2023-07-01 11:40:21] [config] enc-cell: gru
[2023-07-01 11:40:21] [config] enc-cell-depth: 1
[2023-07-01 11:40:21] [config] enc-depth: 2
[2023-07-01 11:40:21] [config] enc-type: bidirectional
[2023-07-01 11:40:21] [config] english-title-case-every: 0
[2023-07-01 11:40:21] [config] exponential-smoothing: 0.0001
[2023-07-01 11:40:21] [config] factor-weight: 1
[2023-07-01 11:40:21] [config] factors-combine: sum
[2023-07-01 11:40:21] [config] factors-dim-emb: 0
[2023-07-01 11:40:21] [config] gradient-checkpointing: false
[2023-07-01 11:40:21] [config] gradient-norm-average-window: 100
[2023-07-01 11:40:21] [config] guided-alignment: none
[2023-07-01 11:40:21] [config] guided-alignment-cost: mse
[2023-07-01 11:40:21] [config] guided-alignment-weight: 0.1
[2023-07-01 11:40:21] [config] ignore-model-config: false
[2023-07-01 11:40:21] [config] input-types:
[2023-07-01 11:40:21] [config]   []
[2023-07-01 11:40:21] [config] interpolate-env-vars: false
[2023-07-01 11:40:21] [config] keep-best: false
[2023-07-01 11:40:21] [config] label-smoothing: 0.1
[2023-07-01 11:40:21] [config] layer-normalization: false
[2023-07-01 11:40:21] [config] learn-rate: 0.0003
[2023-07-01 11:40:21] [config] lemma-dependency: ""
[2023-07-01 11:40:21] [config] lemma-dim-emb: 0
[2023-07-01 11:40:21] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:40:21] [config] log-level: info
[2023-07-01 11:40:21] [config] log-time-zone: ""
[2023-07-01 11:40:21] [config] logical-epoch:
[2023-07-01 11:40:21] [config]   - 1e
[2023-07-01 11:40:21] [config]   - 0
[2023-07-01 11:40:21] [config] lr-decay: 0
[2023-07-01 11:40:21] [config] lr-decay-freq: 50000
[2023-07-01 11:40:21] [config] lr-decay-inv-sqrt:
[2023-07-01 11:40:21] [config]   - 16000
[2023-07-01 11:40:21] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:40:21] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:40:21] [config] lr-decay-start:
[2023-07-01 11:40:21] [config]   - 10
[2023-07-01 11:40:21] [config]   - 1
[2023-07-01 11:40:21] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:40:21] [config] lr-report: true
[2023-07-01 11:40:21] [config] lr-warmup: 16000
[2023-07-01 11:40:21] [config] lr-warmup-at-reload: false
[2023-07-01 11:40:21] [config] lr-warmup-cycle: false
[2023-07-01 11:40:21] [config] lr-warmup-start-rate: 0
[2023-07-01 11:40:21] [config] max-length: 100
[2023-07-01 11:40:21] [config] max-length-crop: false
[2023-07-01 11:40:21] [config] max-length-factor: 3
[2023-07-01 11:40:21] [config] maxi-batch: 100
[2023-07-01 11:40:21] [config] maxi-batch-sort: trg
[2023-07-01 11:40:21] [config] mini-batch: 1000
[2023-07-01 11:40:21] [config] mini-batch-fit: true
[2023-07-01 11:40:21] [config] mini-batch-fit-step: 10
[2023-07-01 11:40:21] [config] mini-batch-round-up: true
[2023-07-01 11:40:21] [config] mini-batch-track-lr: false
[2023-07-01 11:40:21] [config] mini-batch-warmup: 0
[2023-07-01 11:40:21] [config] mini-batch-words: 0
[2023-07-01 11:40:21] [config] mini-batch-words-ref: 0
[2023-07-01 11:40:21] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:40:21] [config] multi-loss-type: sum
[2023-07-01 11:40:21] [config] n-best: false
[2023-07-01 11:40:21] [config] no-nccl: false
[2023-07-01 11:40:21] [config] no-reload: false
[2023-07-01 11:40:21] [config] no-restore-corpus: false
[2023-07-01 11:40:21] [config] normalize: 1
[2023-07-01 11:40:21] [config] normalize-gradient: false
[2023-07-01 11:40:21] [config] num-devices: 0
[2023-07-01 11:40:21] [config] optimizer: adam
[2023-07-01 11:40:21] [config] optimizer-delay: 1
[2023-07-01 11:40:21] [config] optimizer-params:
[2023-07-01 11:40:21] [config]   - 0.9
[2023-07-01 11:40:21] [config]   - 0.98
[2023-07-01 11:40:21] [config]   - 1e-09
[2023-07-01 11:40:21] [config] output-omit-bias: false
[2023-07-01 11:40:21] [config] overwrite: true
[2023-07-01 11:40:21] [config] precision:
[2023-07-01 11:40:21] [config]   - float32
[2023-07-01 11:40:21] [config]   - float32
[2023-07-01 11:40:21] [config] pretrained-model: ""
[2023-07-01 11:40:21] [config] quantize-biases: false
[2023-07-01 11:40:21] [config] quantize-bits: 0
[2023-07-01 11:40:21] [config] quantize-log-based: false
[2023-07-01 11:40:21] [config] quantize-optimization-steps: 0
[2023-07-01 11:40:21] [config] quiet: false
[2023-07-01 11:40:21] [config] quiet-translation: true
[2023-07-01 11:40:21] [config] relative-paths: false
[2023-07-01 11:40:21] [config] right-left: false
[2023-07-01 11:40:21] [config] save-freq: 10000u
[2023-07-01 11:40:21] [config] seed: 1234
[2023-07-01 11:40:21] [config] sentencepiece-alphas:
[2023-07-01 11:40:21] [config]   []
[2023-07-01 11:40:21] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:40:21] [config] sentencepiece-options: ""
[2023-07-01 11:40:21] [config] sharding: global
[2023-07-01 11:40:21] [config] shuffle: data
[2023-07-01 11:40:21] [config] shuffle-in-ram: false
[2023-07-01 11:40:21] [config] sigterm: save-and-exit
[2023-07-01 11:40:21] [config] skip: false
[2023-07-01 11:40:21] [config] sqlite: ""
[2023-07-01 11:40:21] [config] sqlite-drop: false
[2023-07-01 11:40:21] [config] sync-freq: 200u
[2023-07-01 11:40:21] [config] sync-sgd: true
[2023-07-01 11:40:21] [config] tempdir: /tmp
[2023-07-01 11:40:21] [config] tied-embeddings: false
[2023-07-01 11:40:21] [config] tied-embeddings-all: true
[2023-07-01 11:40:21] [config] tied-embeddings-src: false
[2023-07-01 11:40:21] [config] train-embedder-rank:
[2023-07-01 11:40:21] [config]   []
[2023-07-01 11:40:21] [config] train-sets:
[2023-07-01 11:40:21] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:40:21] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:40:21] [config] transformer-aan-activation: swish
[2023-07-01 11:40:21] [config] transformer-aan-depth: 2
[2023-07-01 11:40:21] [config] transformer-aan-nogate: false
[2023-07-01 11:40:21] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:40:21] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:40:21] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:40:21] [config] transformer-depth-scaling: false
[2023-07-01 11:40:21] [config] transformer-dim-aan: 2048
[2023-07-01 11:40:21] [config] transformer-dim-ffn: 2048
[2023-07-01 11:40:21] [config] transformer-dropout: 0.1
[2023-07-01 11:40:21] [config] transformer-dropout-attention: 0
[2023-07-01 11:40:21] [config] transformer-dropout-ffn: 0
[2023-07-01 11:40:21] [config] transformer-ffn-activation: swish
[2023-07-01 11:40:21] [config] transformer-ffn-depth: 2
[2023-07-01 11:40:21] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:40:21] [config] transformer-heads: 8
[2023-07-01 11:40:21] [config] transformer-no-projection: false
[2023-07-01 11:40:21] [config] transformer-pool: false
[2023-07-01 11:40:21] [config] transformer-postprocess: dan
[2023-07-01 11:40:21] [config] transformer-postprocess-emb: d
[2023-07-01 11:40:21] [config] transformer-postprocess-top: ""
[2023-07-01 11:40:21] [config] transformer-preprocess: ""
[2023-07-01 11:40:21] [config] transformer-tied-layers:
[2023-07-01 11:40:21] [config]   []
[2023-07-01 11:40:21] [config] transformer-train-position-embeddings: false
[2023-07-01 11:40:21] [config] tsv: false
[2023-07-01 11:40:21] [config] tsv-fields: 0
[2023-07-01 11:40:21] [config] type: transformer
[2023-07-01 11:40:21] [config] ulr: false
[2023-07-01 11:40:21] [config] ulr-dim-emb: 0
[2023-07-01 11:40:21] [config] ulr-dropout: 0
[2023-07-01 11:40:21] [config] ulr-keys-vectors: ""
[2023-07-01 11:40:21] [config] ulr-query-vectors: ""
[2023-07-01 11:40:21] [config] ulr-softmax-temperature: 1
[2023-07-01 11:40:21] [config] ulr-trainable-transformation: false
[2023-07-01 11:40:21] [config] unlikelihood-loss: false
[2023-07-01 11:40:21] [config] valid-freq: 50000000
[2023-07-01 11:40:21] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:40:21] [config] valid-max-length: 1000
[2023-07-01 11:40:21] [config] valid-metrics:
[2023-07-01 11:40:21] [config]   - cross-entropy
[2023-07-01 11:40:21] [config]   - translation
[2023-07-01 11:40:21] [config] valid-mini-batch: 64
[2023-07-01 11:40:21] [config] valid-reset-stalled: false
[2023-07-01 11:40:21] [config] valid-script-args:
[2023-07-01 11:40:21] [config]   []
[2023-07-01 11:40:21] [config] valid-script-path: ""
[2023-07-01 11:40:21] [config] valid-sets:
[2023-07-01 11:40:21] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:40:21] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:40:21] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:40:21] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:40:21] [config] vocabs:
[2023-07-01 11:40:21] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:40:21] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:40:21] [config] word-penalty: 0
[2023-07-01 11:40:21] [config] word-scores: false
[2023-07-01 11:40:21] [config] workspace: 2048
[2023-07-01 11:40:21] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:40:21] Using synchronous SGD
[2023-07-01 11:40:22] Synced seed 1234
[2023-07-01 11:40:22] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:40:22] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:40:22] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:40:22] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:40:22] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:40:22] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:40:23] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:40:23] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:40:23] [comm] Using global sharding
[2023-07-01 11:40:23] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:40:23] [training] Using 1 GPUs
[2023-07-01 11:40:23] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:40:23] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:40:23] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:40:23] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:40:30] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:40:30] [valid] No post-processing script given for validating translator
[2023-07-01 11:40:31] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:40:31] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:40:31] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:40:31] [comm] Using global sharding
[2023-07-01 11:40:31] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:40:31] [training] Using 1 GPUs
[2023-07-01 11:40:31] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:40:31] Allocating memory for general optimizer shards
[2023-07-01 11:40:31] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:40:31] Loading Adam parameters
[2023-07-01 11:40:31] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:40:31] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:40:31] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:40:31] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:40:31] [data] Shuffling data
[2023-07-01 11:40:31] [data] Done reading 20,192 sentences
[2023-07-01 11:40:31] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:40:31] Training started
[2023-07-01 11:40:31] Training finished
[2023-07-01 11:40:35] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:40:35] [marian] Running on node20.datos.cluster.uy as process 19647 with command line:
[2023-07-01 11:40:35] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 140 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:40:35] [config] after: 0e
[2023-07-01 11:40:35] [config] after-batches: 0
[2023-07-01 11:40:35] [config] after-epochs: 140
[2023-07-01 11:40:35] [config] all-caps-every: 0
[2023-07-01 11:40:35] [config] allow-unk: false
[2023-07-01 11:40:35] [config] authors: false
[2023-07-01 11:40:35] [config] beam-size: 12
[2023-07-01 11:40:35] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:40:35] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:40:35] [config] bert-masking-fraction: 0.15
[2023-07-01 11:40:35] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:40:35] [config] bert-train-type-embeddings: true
[2023-07-01 11:40:35] [config] bert-type-vocab-size: 2
[2023-07-01 11:40:35] [config] build-info: ""
[2023-07-01 11:40:35] [config] check-gradient-nan: false
[2023-07-01 11:40:35] [config] check-nan: false
[2023-07-01 11:40:35] [config] cite: false
[2023-07-01 11:40:35] [config] clip-norm: 5
[2023-07-01 11:40:35] [config] cost-scaling:
[2023-07-01 11:40:35] [config]   []
[2023-07-01 11:40:35] [config] cost-type: ce-sum
[2023-07-01 11:40:35] [config] cpu-threads: 0
[2023-07-01 11:40:35] [config] data-threads: 8
[2023-07-01 11:40:35] [config] data-weighting: ""
[2023-07-01 11:40:35] [config] data-weighting-type: sentence
[2023-07-01 11:40:35] [config] dec-cell: gru
[2023-07-01 11:40:35] [config] dec-cell-base-depth: 2
[2023-07-01 11:40:35] [config] dec-cell-high-depth: 1
[2023-07-01 11:40:35] [config] dec-depth: 2
[2023-07-01 11:40:35] [config] devices:
[2023-07-01 11:40:35] [config]   - 0
[2023-07-01 11:40:35] [config] dim-emb: 512
[2023-07-01 11:40:35] [config] dim-rnn: 1024
[2023-07-01 11:40:35] [config] dim-vocabs:
[2023-07-01 11:40:35] [config]   - 16384
[2023-07-01 11:40:35] [config]   - 16384
[2023-07-01 11:40:35] [config] disp-first: 0
[2023-07-01 11:40:35] [config] disp-freq: 1000u
[2023-07-01 11:40:35] [config] disp-label-counts: true
[2023-07-01 11:40:35] [config] dropout-rnn: 0
[2023-07-01 11:40:35] [config] dropout-src: 0
[2023-07-01 11:40:35] [config] dropout-trg: 0
[2023-07-01 11:40:35] [config] dump-config: ""
[2023-07-01 11:40:35] [config] dynamic-gradient-scaling:
[2023-07-01 11:40:35] [config]   []
[2023-07-01 11:40:35] [config] early-stopping: 10
[2023-07-01 11:40:35] [config] early-stopping-on: first
[2023-07-01 11:40:35] [config] embedding-fix-src: false
[2023-07-01 11:40:35] [config] embedding-fix-trg: false
[2023-07-01 11:40:35] [config] embedding-normalization: false
[2023-07-01 11:40:35] [config] embedding-vectors:
[2023-07-01 11:40:35] [config]   []
[2023-07-01 11:40:35] [config] enc-cell: gru
[2023-07-01 11:40:35] [config] enc-cell-depth: 1
[2023-07-01 11:40:35] [config] enc-depth: 2
[2023-07-01 11:40:35] [config] enc-type: bidirectional
[2023-07-01 11:40:35] [config] english-title-case-every: 0
[2023-07-01 11:40:35] [config] exponential-smoothing: 0.0001
[2023-07-01 11:40:35] [config] factor-weight: 1
[2023-07-01 11:40:35] [config] factors-combine: sum
[2023-07-01 11:40:35] [config] factors-dim-emb: 0
[2023-07-01 11:40:35] [config] gradient-checkpointing: false
[2023-07-01 11:40:35] [config] gradient-norm-average-window: 100
[2023-07-01 11:40:35] [config] guided-alignment: none
[2023-07-01 11:40:35] [config] guided-alignment-cost: mse
[2023-07-01 11:40:35] [config] guided-alignment-weight: 0.1
[2023-07-01 11:40:35] [config] ignore-model-config: false
[2023-07-01 11:40:35] [config] input-types:
[2023-07-01 11:40:35] [config]   []
[2023-07-01 11:40:35] [config] interpolate-env-vars: false
[2023-07-01 11:40:35] [config] keep-best: false
[2023-07-01 11:40:35] [config] label-smoothing: 0.1
[2023-07-01 11:40:35] [config] layer-normalization: false
[2023-07-01 11:40:35] [config] learn-rate: 0.0003
[2023-07-01 11:40:35] [config] lemma-dependency: ""
[2023-07-01 11:40:35] [config] lemma-dim-emb: 0
[2023-07-01 11:40:35] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:40:35] [config] log-level: info
[2023-07-01 11:40:35] [config] log-time-zone: ""
[2023-07-01 11:40:35] [config] logical-epoch:
[2023-07-01 11:40:35] [config]   - 1e
[2023-07-01 11:40:35] [config]   - 0
[2023-07-01 11:40:35] [config] lr-decay: 0
[2023-07-01 11:40:35] [config] lr-decay-freq: 50000
[2023-07-01 11:40:35] [config] lr-decay-inv-sqrt:
[2023-07-01 11:40:35] [config]   - 16000
[2023-07-01 11:40:35] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:40:35] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:40:35] [config] lr-decay-start:
[2023-07-01 11:40:35] [config]   - 10
[2023-07-01 11:40:35] [config]   - 1
[2023-07-01 11:40:35] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:40:35] [config] lr-report: true
[2023-07-01 11:40:35] [config] lr-warmup: 16000
[2023-07-01 11:40:35] [config] lr-warmup-at-reload: false
[2023-07-01 11:40:35] [config] lr-warmup-cycle: false
[2023-07-01 11:40:35] [config] lr-warmup-start-rate: 0
[2023-07-01 11:40:35] [config] max-length: 100
[2023-07-01 11:40:35] [config] max-length-crop: false
[2023-07-01 11:40:35] [config] max-length-factor: 3
[2023-07-01 11:40:35] [config] maxi-batch: 100
[2023-07-01 11:40:35] [config] maxi-batch-sort: trg
[2023-07-01 11:40:35] [config] mini-batch: 1000
[2023-07-01 11:40:35] [config] mini-batch-fit: true
[2023-07-01 11:40:35] [config] mini-batch-fit-step: 10
[2023-07-01 11:40:35] [config] mini-batch-round-up: true
[2023-07-01 11:40:35] [config] mini-batch-track-lr: false
[2023-07-01 11:40:35] [config] mini-batch-warmup: 0
[2023-07-01 11:40:35] [config] mini-batch-words: 0
[2023-07-01 11:40:35] [config] mini-batch-words-ref: 0
[2023-07-01 11:40:35] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:40:35] [config] multi-loss-type: sum
[2023-07-01 11:40:35] [config] n-best: false
[2023-07-01 11:40:35] [config] no-nccl: false
[2023-07-01 11:40:35] [config] no-reload: false
[2023-07-01 11:40:35] [config] no-restore-corpus: false
[2023-07-01 11:40:35] [config] normalize: 1
[2023-07-01 11:40:35] [config] normalize-gradient: false
[2023-07-01 11:40:35] [config] num-devices: 0
[2023-07-01 11:40:35] [config] optimizer: adam
[2023-07-01 11:40:35] [config] optimizer-delay: 1
[2023-07-01 11:40:35] [config] optimizer-params:
[2023-07-01 11:40:35] [config]   - 0.9
[2023-07-01 11:40:35] [config]   - 0.98
[2023-07-01 11:40:35] [config]   - 1e-09
[2023-07-01 11:40:35] [config] output-omit-bias: false
[2023-07-01 11:40:35] [config] overwrite: true
[2023-07-01 11:40:35] [config] precision:
[2023-07-01 11:40:35] [config]   - float32
[2023-07-01 11:40:35] [config]   - float32
[2023-07-01 11:40:35] [config] pretrained-model: ""
[2023-07-01 11:40:35] [config] quantize-biases: false
[2023-07-01 11:40:35] [config] quantize-bits: 0
[2023-07-01 11:40:35] [config] quantize-log-based: false
[2023-07-01 11:40:35] [config] quantize-optimization-steps: 0
[2023-07-01 11:40:35] [config] quiet: false
[2023-07-01 11:40:35] [config] quiet-translation: true
[2023-07-01 11:40:35] [config] relative-paths: false
[2023-07-01 11:40:35] [config] right-left: false
[2023-07-01 11:40:35] [config] save-freq: 10000u
[2023-07-01 11:40:35] [config] seed: 1234
[2023-07-01 11:40:35] [config] sentencepiece-alphas:
[2023-07-01 11:40:35] [config]   []
[2023-07-01 11:40:35] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:40:35] [config] sentencepiece-options: ""
[2023-07-01 11:40:35] [config] sharding: global
[2023-07-01 11:40:35] [config] shuffle: data
[2023-07-01 11:40:35] [config] shuffle-in-ram: false
[2023-07-01 11:40:35] [config] sigterm: save-and-exit
[2023-07-01 11:40:35] [config] skip: false
[2023-07-01 11:40:35] [config] sqlite: ""
[2023-07-01 11:40:35] [config] sqlite-drop: false
[2023-07-01 11:40:35] [config] sync-freq: 200u
[2023-07-01 11:40:35] [config] sync-sgd: true
[2023-07-01 11:40:35] [config] tempdir: /tmp
[2023-07-01 11:40:35] [config] tied-embeddings: false
[2023-07-01 11:40:35] [config] tied-embeddings-all: true
[2023-07-01 11:40:35] [config] tied-embeddings-src: false
[2023-07-01 11:40:35] [config] train-embedder-rank:
[2023-07-01 11:40:35] [config]   []
[2023-07-01 11:40:35] [config] train-sets:
[2023-07-01 11:40:35] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:40:35] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:40:35] [config] transformer-aan-activation: swish
[2023-07-01 11:40:35] [config] transformer-aan-depth: 2
[2023-07-01 11:40:35] [config] transformer-aan-nogate: false
[2023-07-01 11:40:35] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:40:35] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:40:35] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:40:35] [config] transformer-depth-scaling: false
[2023-07-01 11:40:35] [config] transformer-dim-aan: 2048
[2023-07-01 11:40:35] [config] transformer-dim-ffn: 2048
[2023-07-01 11:40:35] [config] transformer-dropout: 0.1
[2023-07-01 11:40:35] [config] transformer-dropout-attention: 0
[2023-07-01 11:40:35] [config] transformer-dropout-ffn: 0
[2023-07-01 11:40:35] [config] transformer-ffn-activation: swish
[2023-07-01 11:40:35] [config] transformer-ffn-depth: 2
[2023-07-01 11:40:35] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:40:35] [config] transformer-heads: 8
[2023-07-01 11:40:35] [config] transformer-no-projection: false
[2023-07-01 11:40:35] [config] transformer-pool: false
[2023-07-01 11:40:35] [config] transformer-postprocess: dan
[2023-07-01 11:40:35] [config] transformer-postprocess-emb: d
[2023-07-01 11:40:35] [config] transformer-postprocess-top: ""
[2023-07-01 11:40:35] [config] transformer-preprocess: ""
[2023-07-01 11:40:35] [config] transformer-tied-layers:
[2023-07-01 11:40:35] [config]   []
[2023-07-01 11:40:35] [config] transformer-train-position-embeddings: false
[2023-07-01 11:40:35] [config] tsv: false
[2023-07-01 11:40:35] [config] tsv-fields: 0
[2023-07-01 11:40:35] [config] type: transformer
[2023-07-01 11:40:35] [config] ulr: false
[2023-07-01 11:40:35] [config] ulr-dim-emb: 0
[2023-07-01 11:40:35] [config] ulr-dropout: 0
[2023-07-01 11:40:35] [config] ulr-keys-vectors: ""
[2023-07-01 11:40:35] [config] ulr-query-vectors: ""
[2023-07-01 11:40:35] [config] ulr-softmax-temperature: 1
[2023-07-01 11:40:35] [config] ulr-trainable-transformation: false
[2023-07-01 11:40:35] [config] unlikelihood-loss: false
[2023-07-01 11:40:35] [config] valid-freq: 50000000
[2023-07-01 11:40:35] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:40:35] [config] valid-max-length: 1000
[2023-07-01 11:40:35] [config] valid-metrics:
[2023-07-01 11:40:35] [config]   - cross-entropy
[2023-07-01 11:40:35] [config]   - translation
[2023-07-01 11:40:35] [config] valid-mini-batch: 64
[2023-07-01 11:40:35] [config] valid-reset-stalled: false
[2023-07-01 11:40:35] [config] valid-script-args:
[2023-07-01 11:40:35] [config]   []
[2023-07-01 11:40:35] [config] valid-script-path: ""
[2023-07-01 11:40:35] [config] valid-sets:
[2023-07-01 11:40:35] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:40:35] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:40:35] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:40:35] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:40:35] [config] vocabs:
[2023-07-01 11:40:35] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:40:35] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:40:35] [config] word-penalty: 0
[2023-07-01 11:40:35] [config] word-scores: false
[2023-07-01 11:40:35] [config] workspace: 2048
[2023-07-01 11:40:35] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:40:35] Using synchronous SGD
[2023-07-01 11:40:35] Synced seed 1234
[2023-07-01 11:40:35] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:40:35] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:40:35] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:40:35] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:40:35] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:40:35] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:40:36] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:40:36] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:40:36] [comm] Using global sharding
[2023-07-01 11:40:36] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:40:36] [training] Using 1 GPUs
[2023-07-01 11:40:36] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:40:36] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:40:37] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:40:37] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:40:44] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:40:44] [valid] No post-processing script given for validating translator
[2023-07-01 11:40:44] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:40:44] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:40:44] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:40:44] [comm] Using global sharding
[2023-07-01 11:40:44] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:40:44] [training] Using 1 GPUs
[2023-07-01 11:40:44] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:40:45] Allocating memory for general optimizer shards
[2023-07-01 11:40:45] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:40:45] Loading Adam parameters
[2023-07-01 11:40:45] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:40:45] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:40:45] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:40:45] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:40:45] [data] Shuffling data
[2023-07-01 11:40:45] [data] Done reading 20,192 sentences
[2023-07-01 11:40:45] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:40:45] Training started
[2023-07-01 11:40:45] Training finished
[2023-07-01 11:40:48] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:40:48] [marian] Running on node20.datos.cluster.uy as process 19704 with command line:
[2023-07-01 11:40:48] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 141 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:40:48] [config] after: 0e
[2023-07-01 11:40:48] [config] after-batches: 0
[2023-07-01 11:40:48] [config] after-epochs: 141
[2023-07-01 11:40:48] [config] all-caps-every: 0
[2023-07-01 11:40:48] [config] allow-unk: false
[2023-07-01 11:40:48] [config] authors: false
[2023-07-01 11:40:48] [config] beam-size: 12
[2023-07-01 11:40:48] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:40:48] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:40:48] [config] bert-masking-fraction: 0.15
[2023-07-01 11:40:48] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:40:48] [config] bert-train-type-embeddings: true
[2023-07-01 11:40:48] [config] bert-type-vocab-size: 2
[2023-07-01 11:40:48] [config] build-info: ""
[2023-07-01 11:40:48] [config] check-gradient-nan: false
[2023-07-01 11:40:48] [config] check-nan: false
[2023-07-01 11:40:48] [config] cite: false
[2023-07-01 11:40:48] [config] clip-norm: 5
[2023-07-01 11:40:48] [config] cost-scaling:
[2023-07-01 11:40:48] [config]   []
[2023-07-01 11:40:48] [config] cost-type: ce-sum
[2023-07-01 11:40:48] [config] cpu-threads: 0
[2023-07-01 11:40:48] [config] data-threads: 8
[2023-07-01 11:40:48] [config] data-weighting: ""
[2023-07-01 11:40:48] [config] data-weighting-type: sentence
[2023-07-01 11:40:48] [config] dec-cell: gru
[2023-07-01 11:40:48] [config] dec-cell-base-depth: 2
[2023-07-01 11:40:48] [config] dec-cell-high-depth: 1
[2023-07-01 11:40:48] [config] dec-depth: 2
[2023-07-01 11:40:48] [config] devices:
[2023-07-01 11:40:48] [config]   - 0
[2023-07-01 11:40:48] [config] dim-emb: 512
[2023-07-01 11:40:48] [config] dim-rnn: 1024
[2023-07-01 11:40:48] [config] dim-vocabs:
[2023-07-01 11:40:48] [config]   - 16384
[2023-07-01 11:40:48] [config]   - 16384
[2023-07-01 11:40:48] [config] disp-first: 0
[2023-07-01 11:40:48] [config] disp-freq: 1000u
[2023-07-01 11:40:48] [config] disp-label-counts: true
[2023-07-01 11:40:48] [config] dropout-rnn: 0
[2023-07-01 11:40:48] [config] dropout-src: 0
[2023-07-01 11:40:48] [config] dropout-trg: 0
[2023-07-01 11:40:48] [config] dump-config: ""
[2023-07-01 11:40:48] [config] dynamic-gradient-scaling:
[2023-07-01 11:40:48] [config]   []
[2023-07-01 11:40:48] [config] early-stopping: 10
[2023-07-01 11:40:48] [config] early-stopping-on: first
[2023-07-01 11:40:48] [config] embedding-fix-src: false
[2023-07-01 11:40:48] [config] embedding-fix-trg: false
[2023-07-01 11:40:48] [config] embedding-normalization: false
[2023-07-01 11:40:48] [config] embedding-vectors:
[2023-07-01 11:40:48] [config]   []
[2023-07-01 11:40:48] [config] enc-cell: gru
[2023-07-01 11:40:48] [config] enc-cell-depth: 1
[2023-07-01 11:40:48] [config] enc-depth: 2
[2023-07-01 11:40:48] [config] enc-type: bidirectional
[2023-07-01 11:40:48] [config] english-title-case-every: 0
[2023-07-01 11:40:48] [config] exponential-smoothing: 0.0001
[2023-07-01 11:40:48] [config] factor-weight: 1
[2023-07-01 11:40:48] [config] factors-combine: sum
[2023-07-01 11:40:48] [config] factors-dim-emb: 0
[2023-07-01 11:40:48] [config] gradient-checkpointing: false
[2023-07-01 11:40:48] [config] gradient-norm-average-window: 100
[2023-07-01 11:40:48] [config] guided-alignment: none
[2023-07-01 11:40:48] [config] guided-alignment-cost: mse
[2023-07-01 11:40:48] [config] guided-alignment-weight: 0.1
[2023-07-01 11:40:48] [config] ignore-model-config: false
[2023-07-01 11:40:48] [config] input-types:
[2023-07-01 11:40:48] [config]   []
[2023-07-01 11:40:48] [config] interpolate-env-vars: false
[2023-07-01 11:40:48] [config] keep-best: false
[2023-07-01 11:40:48] [config] label-smoothing: 0.1
[2023-07-01 11:40:48] [config] layer-normalization: false
[2023-07-01 11:40:48] [config] learn-rate: 0.0003
[2023-07-01 11:40:48] [config] lemma-dependency: ""
[2023-07-01 11:40:48] [config] lemma-dim-emb: 0
[2023-07-01 11:40:48] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:40:48] [config] log-level: info
[2023-07-01 11:40:48] [config] log-time-zone: ""
[2023-07-01 11:40:48] [config] logical-epoch:
[2023-07-01 11:40:48] [config]   - 1e
[2023-07-01 11:40:48] [config]   - 0
[2023-07-01 11:40:48] [config] lr-decay: 0
[2023-07-01 11:40:48] [config] lr-decay-freq: 50000
[2023-07-01 11:40:48] [config] lr-decay-inv-sqrt:
[2023-07-01 11:40:48] [config]   - 16000
[2023-07-01 11:40:48] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:40:48] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:40:48] [config] lr-decay-start:
[2023-07-01 11:40:48] [config]   - 10
[2023-07-01 11:40:48] [config]   - 1
[2023-07-01 11:40:48] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:40:48] [config] lr-report: true
[2023-07-01 11:40:48] [config] lr-warmup: 16000
[2023-07-01 11:40:48] [config] lr-warmup-at-reload: false
[2023-07-01 11:40:48] [config] lr-warmup-cycle: false
[2023-07-01 11:40:48] [config] lr-warmup-start-rate: 0
[2023-07-01 11:40:48] [config] max-length: 100
[2023-07-01 11:40:48] [config] max-length-crop: false
[2023-07-01 11:40:48] [config] max-length-factor: 3
[2023-07-01 11:40:48] [config] maxi-batch: 100
[2023-07-01 11:40:48] [config] maxi-batch-sort: trg
[2023-07-01 11:40:48] [config] mini-batch: 1000
[2023-07-01 11:40:48] [config] mini-batch-fit: true
[2023-07-01 11:40:48] [config] mini-batch-fit-step: 10
[2023-07-01 11:40:48] [config] mini-batch-round-up: true
[2023-07-01 11:40:48] [config] mini-batch-track-lr: false
[2023-07-01 11:40:48] [config] mini-batch-warmup: 0
[2023-07-01 11:40:48] [config] mini-batch-words: 0
[2023-07-01 11:40:48] [config] mini-batch-words-ref: 0
[2023-07-01 11:40:48] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:40:48] [config] multi-loss-type: sum
[2023-07-01 11:40:48] [config] n-best: false
[2023-07-01 11:40:48] [config] no-nccl: false
[2023-07-01 11:40:48] [config] no-reload: false
[2023-07-01 11:40:48] [config] no-restore-corpus: false
[2023-07-01 11:40:48] [config] normalize: 1
[2023-07-01 11:40:48] [config] normalize-gradient: false
[2023-07-01 11:40:48] [config] num-devices: 0
[2023-07-01 11:40:48] [config] optimizer: adam
[2023-07-01 11:40:48] [config] optimizer-delay: 1
[2023-07-01 11:40:48] [config] optimizer-params:
[2023-07-01 11:40:48] [config]   - 0.9
[2023-07-01 11:40:48] [config]   - 0.98
[2023-07-01 11:40:48] [config]   - 1e-09
[2023-07-01 11:40:48] [config] output-omit-bias: false
[2023-07-01 11:40:48] [config] overwrite: true
[2023-07-01 11:40:48] [config] precision:
[2023-07-01 11:40:48] [config]   - float32
[2023-07-01 11:40:48] [config]   - float32
[2023-07-01 11:40:48] [config] pretrained-model: ""
[2023-07-01 11:40:48] [config] quantize-biases: false
[2023-07-01 11:40:48] [config] quantize-bits: 0
[2023-07-01 11:40:48] [config] quantize-log-based: false
[2023-07-01 11:40:48] [config] quantize-optimization-steps: 0
[2023-07-01 11:40:48] [config] quiet: false
[2023-07-01 11:40:48] [config] quiet-translation: true
[2023-07-01 11:40:48] [config] relative-paths: false
[2023-07-01 11:40:48] [config] right-left: false
[2023-07-01 11:40:48] [config] save-freq: 10000u
[2023-07-01 11:40:48] [config] seed: 1234
[2023-07-01 11:40:48] [config] sentencepiece-alphas:
[2023-07-01 11:40:48] [config]   []
[2023-07-01 11:40:48] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:40:48] [config] sentencepiece-options: ""
[2023-07-01 11:40:48] [config] sharding: global
[2023-07-01 11:40:48] [config] shuffle: data
[2023-07-01 11:40:48] [config] shuffle-in-ram: false
[2023-07-01 11:40:48] [config] sigterm: save-and-exit
[2023-07-01 11:40:48] [config] skip: false
[2023-07-01 11:40:48] [config] sqlite: ""
[2023-07-01 11:40:48] [config] sqlite-drop: false
[2023-07-01 11:40:48] [config] sync-freq: 200u
[2023-07-01 11:40:48] [config] sync-sgd: true
[2023-07-01 11:40:48] [config] tempdir: /tmp
[2023-07-01 11:40:48] [config] tied-embeddings: false
[2023-07-01 11:40:48] [config] tied-embeddings-all: true
[2023-07-01 11:40:48] [config] tied-embeddings-src: false
[2023-07-01 11:40:48] [config] train-embedder-rank:
[2023-07-01 11:40:48] [config]   []
[2023-07-01 11:40:48] [config] train-sets:
[2023-07-01 11:40:48] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:40:48] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:40:48] [config] transformer-aan-activation: swish
[2023-07-01 11:40:48] [config] transformer-aan-depth: 2
[2023-07-01 11:40:48] [config] transformer-aan-nogate: false
[2023-07-01 11:40:48] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:40:48] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:40:48] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:40:48] [config] transformer-depth-scaling: false
[2023-07-01 11:40:48] [config] transformer-dim-aan: 2048
[2023-07-01 11:40:48] [config] transformer-dim-ffn: 2048
[2023-07-01 11:40:48] [config] transformer-dropout: 0.1
[2023-07-01 11:40:48] [config] transformer-dropout-attention: 0
[2023-07-01 11:40:48] [config] transformer-dropout-ffn: 0
[2023-07-01 11:40:48] [config] transformer-ffn-activation: swish
[2023-07-01 11:40:48] [config] transformer-ffn-depth: 2
[2023-07-01 11:40:48] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:40:48] [config] transformer-heads: 8
[2023-07-01 11:40:48] [config] transformer-no-projection: false
[2023-07-01 11:40:48] [config] transformer-pool: false
[2023-07-01 11:40:48] [config] transformer-postprocess: dan
[2023-07-01 11:40:48] [config] transformer-postprocess-emb: d
[2023-07-01 11:40:48] [config] transformer-postprocess-top: ""
[2023-07-01 11:40:48] [config] transformer-preprocess: ""
[2023-07-01 11:40:48] [config] transformer-tied-layers:
[2023-07-01 11:40:48] [config]   []
[2023-07-01 11:40:48] [config] transformer-train-position-embeddings: false
[2023-07-01 11:40:48] [config] tsv: false
[2023-07-01 11:40:48] [config] tsv-fields: 0
[2023-07-01 11:40:48] [config] type: transformer
[2023-07-01 11:40:48] [config] ulr: false
[2023-07-01 11:40:48] [config] ulr-dim-emb: 0
[2023-07-01 11:40:48] [config] ulr-dropout: 0
[2023-07-01 11:40:48] [config] ulr-keys-vectors: ""
[2023-07-01 11:40:48] [config] ulr-query-vectors: ""
[2023-07-01 11:40:48] [config] ulr-softmax-temperature: 1
[2023-07-01 11:40:48] [config] ulr-trainable-transformation: false
[2023-07-01 11:40:48] [config] unlikelihood-loss: false
[2023-07-01 11:40:48] [config] valid-freq: 50000000
[2023-07-01 11:40:48] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:40:48] [config] valid-max-length: 1000
[2023-07-01 11:40:48] [config] valid-metrics:
[2023-07-01 11:40:48] [config]   - cross-entropy
[2023-07-01 11:40:48] [config]   - translation
[2023-07-01 11:40:48] [config] valid-mini-batch: 64
[2023-07-01 11:40:48] [config] valid-reset-stalled: false
[2023-07-01 11:40:48] [config] valid-script-args:
[2023-07-01 11:40:48] [config]   []
[2023-07-01 11:40:48] [config] valid-script-path: ""
[2023-07-01 11:40:48] [config] valid-sets:
[2023-07-01 11:40:48] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:40:48] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:40:48] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:40:48] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:40:48] [config] vocabs:
[2023-07-01 11:40:48] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:40:48] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:40:48] [config] word-penalty: 0
[2023-07-01 11:40:48] [config] word-scores: false
[2023-07-01 11:40:48] [config] workspace: 2048
[2023-07-01 11:40:48] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:40:48] Using synchronous SGD
[2023-07-01 11:40:49] Synced seed 1234
[2023-07-01 11:40:49] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:40:49] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:40:49] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:40:49] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:40:49] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:40:49] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:40:49] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:40:50] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:40:50] [comm] Using global sharding
[2023-07-01 11:40:50] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:40:50] [training] Using 1 GPUs
[2023-07-01 11:40:50] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:40:50] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:40:50] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:40:50] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:40:57] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:40:57] [valid] No post-processing script given for validating translator
[2023-07-01 11:40:58] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:40:58] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:40:58] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:40:58] [comm] Using global sharding
[2023-07-01 11:40:58] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:40:58] [training] Using 1 GPUs
[2023-07-01 11:40:58] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:40:58] Allocating memory for general optimizer shards
[2023-07-01 11:40:58] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:40:58] Loading Adam parameters
[2023-07-01 11:40:58] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:40:58] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:40:58] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:40:58] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:40:58] [data] Shuffling data
[2023-07-01 11:40:58] [data] Done reading 20,192 sentences
[2023-07-01 11:40:58] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:40:58] Training started
[2023-07-01 11:40:58] Training finished
[2023-07-01 11:41:02] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:41:02] [marian] Running on node20.datos.cluster.uy as process 19766 with command line:
[2023-07-01 11:41:02] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 142 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:41:02] [config] after: 0e
[2023-07-01 11:41:02] [config] after-batches: 0
[2023-07-01 11:41:02] [config] after-epochs: 142
[2023-07-01 11:41:02] [config] all-caps-every: 0
[2023-07-01 11:41:02] [config] allow-unk: false
[2023-07-01 11:41:02] [config] authors: false
[2023-07-01 11:41:02] [config] beam-size: 12
[2023-07-01 11:41:02] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:41:02] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:41:02] [config] bert-masking-fraction: 0.15
[2023-07-01 11:41:02] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:41:02] [config] bert-train-type-embeddings: true
[2023-07-01 11:41:02] [config] bert-type-vocab-size: 2
[2023-07-01 11:41:02] [config] build-info: ""
[2023-07-01 11:41:02] [config] check-gradient-nan: false
[2023-07-01 11:41:02] [config] check-nan: false
[2023-07-01 11:41:02] [config] cite: false
[2023-07-01 11:41:02] [config] clip-norm: 5
[2023-07-01 11:41:02] [config] cost-scaling:
[2023-07-01 11:41:02] [config]   []
[2023-07-01 11:41:02] [config] cost-type: ce-sum
[2023-07-01 11:41:02] [config] cpu-threads: 0
[2023-07-01 11:41:02] [config] data-threads: 8
[2023-07-01 11:41:02] [config] data-weighting: ""
[2023-07-01 11:41:02] [config] data-weighting-type: sentence
[2023-07-01 11:41:02] [config] dec-cell: gru
[2023-07-01 11:41:02] [config] dec-cell-base-depth: 2
[2023-07-01 11:41:02] [config] dec-cell-high-depth: 1
[2023-07-01 11:41:02] [config] dec-depth: 2
[2023-07-01 11:41:02] [config] devices:
[2023-07-01 11:41:02] [config]   - 0
[2023-07-01 11:41:02] [config] dim-emb: 512
[2023-07-01 11:41:02] [config] dim-rnn: 1024
[2023-07-01 11:41:02] [config] dim-vocabs:
[2023-07-01 11:41:02] [config]   - 16384
[2023-07-01 11:41:02] [config]   - 16384
[2023-07-01 11:41:02] [config] disp-first: 0
[2023-07-01 11:41:02] [config] disp-freq: 1000u
[2023-07-01 11:41:02] [config] disp-label-counts: true
[2023-07-01 11:41:02] [config] dropout-rnn: 0
[2023-07-01 11:41:02] [config] dropout-src: 0
[2023-07-01 11:41:02] [config] dropout-trg: 0
[2023-07-01 11:41:02] [config] dump-config: ""
[2023-07-01 11:41:02] [config] dynamic-gradient-scaling:
[2023-07-01 11:41:02] [config]   []
[2023-07-01 11:41:02] [config] early-stopping: 10
[2023-07-01 11:41:02] [config] early-stopping-on: first
[2023-07-01 11:41:02] [config] embedding-fix-src: false
[2023-07-01 11:41:02] [config] embedding-fix-trg: false
[2023-07-01 11:41:02] [config] embedding-normalization: false
[2023-07-01 11:41:02] [config] embedding-vectors:
[2023-07-01 11:41:02] [config]   []
[2023-07-01 11:41:02] [config] enc-cell: gru
[2023-07-01 11:41:02] [config] enc-cell-depth: 1
[2023-07-01 11:41:02] [config] enc-depth: 2
[2023-07-01 11:41:02] [config] enc-type: bidirectional
[2023-07-01 11:41:02] [config] english-title-case-every: 0
[2023-07-01 11:41:02] [config] exponential-smoothing: 0.0001
[2023-07-01 11:41:02] [config] factor-weight: 1
[2023-07-01 11:41:02] [config] factors-combine: sum
[2023-07-01 11:41:02] [config] factors-dim-emb: 0
[2023-07-01 11:41:02] [config] gradient-checkpointing: false
[2023-07-01 11:41:02] [config] gradient-norm-average-window: 100
[2023-07-01 11:41:02] [config] guided-alignment: none
[2023-07-01 11:41:02] [config] guided-alignment-cost: mse
[2023-07-01 11:41:02] [config] guided-alignment-weight: 0.1
[2023-07-01 11:41:02] [config] ignore-model-config: false
[2023-07-01 11:41:02] [config] input-types:
[2023-07-01 11:41:02] [config]   []
[2023-07-01 11:41:02] [config] interpolate-env-vars: false
[2023-07-01 11:41:02] [config] keep-best: false
[2023-07-01 11:41:02] [config] label-smoothing: 0.1
[2023-07-01 11:41:02] [config] layer-normalization: false
[2023-07-01 11:41:02] [config] learn-rate: 0.0003
[2023-07-01 11:41:02] [config] lemma-dependency: ""
[2023-07-01 11:41:02] [config] lemma-dim-emb: 0
[2023-07-01 11:41:02] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:41:02] [config] log-level: info
[2023-07-01 11:41:02] [config] log-time-zone: ""
[2023-07-01 11:41:02] [config] logical-epoch:
[2023-07-01 11:41:02] [config]   - 1e
[2023-07-01 11:41:02] [config]   - 0
[2023-07-01 11:41:02] [config] lr-decay: 0
[2023-07-01 11:41:02] [config] lr-decay-freq: 50000
[2023-07-01 11:41:02] [config] lr-decay-inv-sqrt:
[2023-07-01 11:41:02] [config]   - 16000
[2023-07-01 11:41:02] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:41:02] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:41:02] [config] lr-decay-start:
[2023-07-01 11:41:02] [config]   - 10
[2023-07-01 11:41:02] [config]   - 1
[2023-07-01 11:41:02] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:41:02] [config] lr-report: true
[2023-07-01 11:41:02] [config] lr-warmup: 16000
[2023-07-01 11:41:02] [config] lr-warmup-at-reload: false
[2023-07-01 11:41:02] [config] lr-warmup-cycle: false
[2023-07-01 11:41:02] [config] lr-warmup-start-rate: 0
[2023-07-01 11:41:02] [config] max-length: 100
[2023-07-01 11:41:02] [config] max-length-crop: false
[2023-07-01 11:41:02] [config] max-length-factor: 3
[2023-07-01 11:41:02] [config] maxi-batch: 100
[2023-07-01 11:41:02] [config] maxi-batch-sort: trg
[2023-07-01 11:41:02] [config] mini-batch: 1000
[2023-07-01 11:41:02] [config] mini-batch-fit: true
[2023-07-01 11:41:02] [config] mini-batch-fit-step: 10
[2023-07-01 11:41:02] [config] mini-batch-round-up: true
[2023-07-01 11:41:02] [config] mini-batch-track-lr: false
[2023-07-01 11:41:02] [config] mini-batch-warmup: 0
[2023-07-01 11:41:02] [config] mini-batch-words: 0
[2023-07-01 11:41:02] [config] mini-batch-words-ref: 0
[2023-07-01 11:41:02] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:41:02] [config] multi-loss-type: sum
[2023-07-01 11:41:02] [config] n-best: false
[2023-07-01 11:41:02] [config] no-nccl: false
[2023-07-01 11:41:02] [config] no-reload: false
[2023-07-01 11:41:02] [config] no-restore-corpus: false
[2023-07-01 11:41:02] [config] normalize: 1
[2023-07-01 11:41:02] [config] normalize-gradient: false
[2023-07-01 11:41:02] [config] num-devices: 0
[2023-07-01 11:41:02] [config] optimizer: adam
[2023-07-01 11:41:02] [config] optimizer-delay: 1
[2023-07-01 11:41:02] [config] optimizer-params:
[2023-07-01 11:41:02] [config]   - 0.9
[2023-07-01 11:41:02] [config]   - 0.98
[2023-07-01 11:41:02] [config]   - 1e-09
[2023-07-01 11:41:02] [config] output-omit-bias: false
[2023-07-01 11:41:02] [config] overwrite: true
[2023-07-01 11:41:02] [config] precision:
[2023-07-01 11:41:02] [config]   - float32
[2023-07-01 11:41:02] [config]   - float32
[2023-07-01 11:41:02] [config] pretrained-model: ""
[2023-07-01 11:41:02] [config] quantize-biases: false
[2023-07-01 11:41:02] [config] quantize-bits: 0
[2023-07-01 11:41:02] [config] quantize-log-based: false
[2023-07-01 11:41:02] [config] quantize-optimization-steps: 0
[2023-07-01 11:41:02] [config] quiet: false
[2023-07-01 11:41:02] [config] quiet-translation: true
[2023-07-01 11:41:02] [config] relative-paths: false
[2023-07-01 11:41:02] [config] right-left: false
[2023-07-01 11:41:02] [config] save-freq: 10000u
[2023-07-01 11:41:02] [config] seed: 1234
[2023-07-01 11:41:02] [config] sentencepiece-alphas:
[2023-07-01 11:41:02] [config]   []
[2023-07-01 11:41:02] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:41:02] [config] sentencepiece-options: ""
[2023-07-01 11:41:02] [config] sharding: global
[2023-07-01 11:41:02] [config] shuffle: data
[2023-07-01 11:41:02] [config] shuffle-in-ram: false
[2023-07-01 11:41:02] [config] sigterm: save-and-exit
[2023-07-01 11:41:02] [config] skip: false
[2023-07-01 11:41:02] [config] sqlite: ""
[2023-07-01 11:41:02] [config] sqlite-drop: false
[2023-07-01 11:41:02] [config] sync-freq: 200u
[2023-07-01 11:41:02] [config] sync-sgd: true
[2023-07-01 11:41:02] [config] tempdir: /tmp
[2023-07-01 11:41:02] [config] tied-embeddings: false
[2023-07-01 11:41:02] [config] tied-embeddings-all: true
[2023-07-01 11:41:02] [config] tied-embeddings-src: false
[2023-07-01 11:41:02] [config] train-embedder-rank:
[2023-07-01 11:41:02] [config]   []
[2023-07-01 11:41:02] [config] train-sets:
[2023-07-01 11:41:02] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:41:02] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:41:02] [config] transformer-aan-activation: swish
[2023-07-01 11:41:02] [config] transformer-aan-depth: 2
[2023-07-01 11:41:02] [config] transformer-aan-nogate: false
[2023-07-01 11:41:02] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:41:02] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:41:02] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:41:02] [config] transformer-depth-scaling: false
[2023-07-01 11:41:02] [config] transformer-dim-aan: 2048
[2023-07-01 11:41:02] [config] transformer-dim-ffn: 2048
[2023-07-01 11:41:02] [config] transformer-dropout: 0.1
[2023-07-01 11:41:02] [config] transformer-dropout-attention: 0
[2023-07-01 11:41:02] [config] transformer-dropout-ffn: 0
[2023-07-01 11:41:02] [config] transformer-ffn-activation: swish
[2023-07-01 11:41:02] [config] transformer-ffn-depth: 2
[2023-07-01 11:41:02] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:41:02] [config] transformer-heads: 8
[2023-07-01 11:41:02] [config] transformer-no-projection: false
[2023-07-01 11:41:02] [config] transformer-pool: false
[2023-07-01 11:41:02] [config] transformer-postprocess: dan
[2023-07-01 11:41:02] [config] transformer-postprocess-emb: d
[2023-07-01 11:41:02] [config] transformer-postprocess-top: ""
[2023-07-01 11:41:02] [config] transformer-preprocess: ""
[2023-07-01 11:41:02] [config] transformer-tied-layers:
[2023-07-01 11:41:02] [config]   []
[2023-07-01 11:41:02] [config] transformer-train-position-embeddings: false
[2023-07-01 11:41:02] [config] tsv: false
[2023-07-01 11:41:02] [config] tsv-fields: 0
[2023-07-01 11:41:02] [config] type: transformer
[2023-07-01 11:41:02] [config] ulr: false
[2023-07-01 11:41:02] [config] ulr-dim-emb: 0
[2023-07-01 11:41:02] [config] ulr-dropout: 0
[2023-07-01 11:41:02] [config] ulr-keys-vectors: ""
[2023-07-01 11:41:02] [config] ulr-query-vectors: ""
[2023-07-01 11:41:02] [config] ulr-softmax-temperature: 1
[2023-07-01 11:41:02] [config] ulr-trainable-transformation: false
[2023-07-01 11:41:02] [config] unlikelihood-loss: false
[2023-07-01 11:41:02] [config] valid-freq: 50000000
[2023-07-01 11:41:02] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:41:02] [config] valid-max-length: 1000
[2023-07-01 11:41:02] [config] valid-metrics:
[2023-07-01 11:41:02] [config]   - cross-entropy
[2023-07-01 11:41:02] [config]   - translation
[2023-07-01 11:41:02] [config] valid-mini-batch: 64
[2023-07-01 11:41:02] [config] valid-reset-stalled: false
[2023-07-01 11:41:02] [config] valid-script-args:
[2023-07-01 11:41:02] [config]   []
[2023-07-01 11:41:02] [config] valid-script-path: ""
[2023-07-01 11:41:02] [config] valid-sets:
[2023-07-01 11:41:02] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:41:02] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:41:02] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:41:02] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:41:02] [config] vocabs:
[2023-07-01 11:41:02] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:41:02] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:41:02] [config] word-penalty: 0
[2023-07-01 11:41:02] [config] word-scores: false
[2023-07-01 11:41:02] [config] workspace: 2048
[2023-07-01 11:41:02] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:41:02] Using synchronous SGD
[2023-07-01 11:41:03] Synced seed 1234
[2023-07-01 11:41:03] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:41:03] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:41:03] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:41:03] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:41:03] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:41:03] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:41:03] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:41:03] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:41:03] [comm] Using global sharding
[2023-07-01 11:41:03] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:41:03] [training] Using 1 GPUs
[2023-07-01 11:41:03] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:41:03] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:41:04] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:41:04] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:41:11] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:41:11] [valid] No post-processing script given for validating translator
[2023-07-01 11:41:11] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:41:11] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:41:11] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:41:11] [comm] Using global sharding
[2023-07-01 11:41:11] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:41:11] [training] Using 1 GPUs
[2023-07-01 11:41:11] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:41:12] Allocating memory for general optimizer shards
[2023-07-01 11:41:12] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:41:12] Loading Adam parameters
[2023-07-01 11:41:12] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:41:12] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:41:12] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:41:12] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:41:12] [data] Shuffling data
[2023-07-01 11:41:12] [data] Done reading 20,192 sentences
[2023-07-01 11:41:12] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:41:12] Training started
[2023-07-01 11:41:12] Training finished
[2023-07-01 11:41:16] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:41:16] [marian] Running on node20.datos.cluster.uy as process 19824 with command line:
[2023-07-01 11:41:16] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 143 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:41:16] [config] after: 0e
[2023-07-01 11:41:16] [config] after-batches: 0
[2023-07-01 11:41:16] [config] after-epochs: 143
[2023-07-01 11:41:16] [config] all-caps-every: 0
[2023-07-01 11:41:16] [config] allow-unk: false
[2023-07-01 11:41:16] [config] authors: false
[2023-07-01 11:41:16] [config] beam-size: 12
[2023-07-01 11:41:16] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:41:16] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:41:16] [config] bert-masking-fraction: 0.15
[2023-07-01 11:41:16] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:41:16] [config] bert-train-type-embeddings: true
[2023-07-01 11:41:16] [config] bert-type-vocab-size: 2
[2023-07-01 11:41:16] [config] build-info: ""
[2023-07-01 11:41:16] [config] check-gradient-nan: false
[2023-07-01 11:41:16] [config] check-nan: false
[2023-07-01 11:41:16] [config] cite: false
[2023-07-01 11:41:16] [config] clip-norm: 5
[2023-07-01 11:41:16] [config] cost-scaling:
[2023-07-01 11:41:16] [config]   []
[2023-07-01 11:41:16] [config] cost-type: ce-sum
[2023-07-01 11:41:16] [config] cpu-threads: 0
[2023-07-01 11:41:16] [config] data-threads: 8
[2023-07-01 11:41:16] [config] data-weighting: ""
[2023-07-01 11:41:16] [config] data-weighting-type: sentence
[2023-07-01 11:41:16] [config] dec-cell: gru
[2023-07-01 11:41:16] [config] dec-cell-base-depth: 2
[2023-07-01 11:41:16] [config] dec-cell-high-depth: 1
[2023-07-01 11:41:16] [config] dec-depth: 2
[2023-07-01 11:41:16] [config] devices:
[2023-07-01 11:41:16] [config]   - 0
[2023-07-01 11:41:16] [config] dim-emb: 512
[2023-07-01 11:41:16] [config] dim-rnn: 1024
[2023-07-01 11:41:16] [config] dim-vocabs:
[2023-07-01 11:41:16] [config]   - 16384
[2023-07-01 11:41:16] [config]   - 16384
[2023-07-01 11:41:16] [config] disp-first: 0
[2023-07-01 11:41:16] [config] disp-freq: 1000u
[2023-07-01 11:41:16] [config] disp-label-counts: true
[2023-07-01 11:41:16] [config] dropout-rnn: 0
[2023-07-01 11:41:16] [config] dropout-src: 0
[2023-07-01 11:41:16] [config] dropout-trg: 0
[2023-07-01 11:41:16] [config] dump-config: ""
[2023-07-01 11:41:16] [config] dynamic-gradient-scaling:
[2023-07-01 11:41:16] [config]   []
[2023-07-01 11:41:16] [config] early-stopping: 10
[2023-07-01 11:41:16] [config] early-stopping-on: first
[2023-07-01 11:41:16] [config] embedding-fix-src: false
[2023-07-01 11:41:16] [config] embedding-fix-trg: false
[2023-07-01 11:41:16] [config] embedding-normalization: false
[2023-07-01 11:41:16] [config] embedding-vectors:
[2023-07-01 11:41:16] [config]   []
[2023-07-01 11:41:16] [config] enc-cell: gru
[2023-07-01 11:41:16] [config] enc-cell-depth: 1
[2023-07-01 11:41:16] [config] enc-depth: 2
[2023-07-01 11:41:16] [config] enc-type: bidirectional
[2023-07-01 11:41:16] [config] english-title-case-every: 0
[2023-07-01 11:41:16] [config] exponential-smoothing: 0.0001
[2023-07-01 11:41:16] [config] factor-weight: 1
[2023-07-01 11:41:16] [config] factors-combine: sum
[2023-07-01 11:41:16] [config] factors-dim-emb: 0
[2023-07-01 11:41:16] [config] gradient-checkpointing: false
[2023-07-01 11:41:16] [config] gradient-norm-average-window: 100
[2023-07-01 11:41:16] [config] guided-alignment: none
[2023-07-01 11:41:16] [config] guided-alignment-cost: mse
[2023-07-01 11:41:16] [config] guided-alignment-weight: 0.1
[2023-07-01 11:41:16] [config] ignore-model-config: false
[2023-07-01 11:41:16] [config] input-types:
[2023-07-01 11:41:16] [config]   []
[2023-07-01 11:41:16] [config] interpolate-env-vars: false
[2023-07-01 11:41:16] [config] keep-best: false
[2023-07-01 11:41:16] [config] label-smoothing: 0.1
[2023-07-01 11:41:16] [config] layer-normalization: false
[2023-07-01 11:41:16] [config] learn-rate: 0.0003
[2023-07-01 11:41:16] [config] lemma-dependency: ""
[2023-07-01 11:41:16] [config] lemma-dim-emb: 0
[2023-07-01 11:41:16] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:41:16] [config] log-level: info
[2023-07-01 11:41:16] [config] log-time-zone: ""
[2023-07-01 11:41:16] [config] logical-epoch:
[2023-07-01 11:41:16] [config]   - 1e
[2023-07-01 11:41:16] [config]   - 0
[2023-07-01 11:41:16] [config] lr-decay: 0
[2023-07-01 11:41:16] [config] lr-decay-freq: 50000
[2023-07-01 11:41:16] [config] lr-decay-inv-sqrt:
[2023-07-01 11:41:16] [config]   - 16000
[2023-07-01 11:41:16] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:41:16] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:41:16] [config] lr-decay-start:
[2023-07-01 11:41:16] [config]   - 10
[2023-07-01 11:41:16] [config]   - 1
[2023-07-01 11:41:16] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:41:16] [config] lr-report: true
[2023-07-01 11:41:16] [config] lr-warmup: 16000
[2023-07-01 11:41:16] [config] lr-warmup-at-reload: false
[2023-07-01 11:41:16] [config] lr-warmup-cycle: false
[2023-07-01 11:41:16] [config] lr-warmup-start-rate: 0
[2023-07-01 11:41:16] [config] max-length: 100
[2023-07-01 11:41:16] [config] max-length-crop: false
[2023-07-01 11:41:16] [config] max-length-factor: 3
[2023-07-01 11:41:16] [config] maxi-batch: 100
[2023-07-01 11:41:16] [config] maxi-batch-sort: trg
[2023-07-01 11:41:16] [config] mini-batch: 1000
[2023-07-01 11:41:16] [config] mini-batch-fit: true
[2023-07-01 11:41:16] [config] mini-batch-fit-step: 10
[2023-07-01 11:41:16] [config] mini-batch-round-up: true
[2023-07-01 11:41:16] [config] mini-batch-track-lr: false
[2023-07-01 11:41:16] [config] mini-batch-warmup: 0
[2023-07-01 11:41:16] [config] mini-batch-words: 0
[2023-07-01 11:41:16] [config] mini-batch-words-ref: 0
[2023-07-01 11:41:16] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:41:16] [config] multi-loss-type: sum
[2023-07-01 11:41:16] [config] n-best: false
[2023-07-01 11:41:16] [config] no-nccl: false
[2023-07-01 11:41:16] [config] no-reload: false
[2023-07-01 11:41:16] [config] no-restore-corpus: false
[2023-07-01 11:41:16] [config] normalize: 1
[2023-07-01 11:41:16] [config] normalize-gradient: false
[2023-07-01 11:41:16] [config] num-devices: 0
[2023-07-01 11:41:16] [config] optimizer: adam
[2023-07-01 11:41:16] [config] optimizer-delay: 1
[2023-07-01 11:41:16] [config] optimizer-params:
[2023-07-01 11:41:16] [config]   - 0.9
[2023-07-01 11:41:16] [config]   - 0.98
[2023-07-01 11:41:16] [config]   - 1e-09
[2023-07-01 11:41:16] [config] output-omit-bias: false
[2023-07-01 11:41:16] [config] overwrite: true
[2023-07-01 11:41:16] [config] precision:
[2023-07-01 11:41:16] [config]   - float32
[2023-07-01 11:41:16] [config]   - float32
[2023-07-01 11:41:16] [config] pretrained-model: ""
[2023-07-01 11:41:16] [config] quantize-biases: false
[2023-07-01 11:41:16] [config] quantize-bits: 0
[2023-07-01 11:41:16] [config] quantize-log-based: false
[2023-07-01 11:41:16] [config] quantize-optimization-steps: 0
[2023-07-01 11:41:16] [config] quiet: false
[2023-07-01 11:41:16] [config] quiet-translation: true
[2023-07-01 11:41:16] [config] relative-paths: false
[2023-07-01 11:41:16] [config] right-left: false
[2023-07-01 11:41:16] [config] save-freq: 10000u
[2023-07-01 11:41:16] [config] seed: 1234
[2023-07-01 11:41:16] [config] sentencepiece-alphas:
[2023-07-01 11:41:16] [config]   []
[2023-07-01 11:41:16] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:41:16] [config] sentencepiece-options: ""
[2023-07-01 11:41:16] [config] sharding: global
[2023-07-01 11:41:16] [config] shuffle: data
[2023-07-01 11:41:16] [config] shuffle-in-ram: false
[2023-07-01 11:41:16] [config] sigterm: save-and-exit
[2023-07-01 11:41:16] [config] skip: false
[2023-07-01 11:41:16] [config] sqlite: ""
[2023-07-01 11:41:16] [config] sqlite-drop: false
[2023-07-01 11:41:16] [config] sync-freq: 200u
[2023-07-01 11:41:16] [config] sync-sgd: true
[2023-07-01 11:41:16] [config] tempdir: /tmp
[2023-07-01 11:41:16] [config] tied-embeddings: false
[2023-07-01 11:41:16] [config] tied-embeddings-all: true
[2023-07-01 11:41:16] [config] tied-embeddings-src: false
[2023-07-01 11:41:16] [config] train-embedder-rank:
[2023-07-01 11:41:16] [config]   []
[2023-07-01 11:41:16] [config] train-sets:
[2023-07-01 11:41:16] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:41:16] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:41:16] [config] transformer-aan-activation: swish
[2023-07-01 11:41:16] [config] transformer-aan-depth: 2
[2023-07-01 11:41:16] [config] transformer-aan-nogate: false
[2023-07-01 11:41:16] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:41:16] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:41:16] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:41:16] [config] transformer-depth-scaling: false
[2023-07-01 11:41:16] [config] transformer-dim-aan: 2048
[2023-07-01 11:41:16] [config] transformer-dim-ffn: 2048
[2023-07-01 11:41:16] [config] transformer-dropout: 0.1
[2023-07-01 11:41:16] [config] transformer-dropout-attention: 0
[2023-07-01 11:41:16] [config] transformer-dropout-ffn: 0
[2023-07-01 11:41:16] [config] transformer-ffn-activation: swish
[2023-07-01 11:41:16] [config] transformer-ffn-depth: 2
[2023-07-01 11:41:16] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:41:16] [config] transformer-heads: 8
[2023-07-01 11:41:16] [config] transformer-no-projection: false
[2023-07-01 11:41:16] [config] transformer-pool: false
[2023-07-01 11:41:16] [config] transformer-postprocess: dan
[2023-07-01 11:41:16] [config] transformer-postprocess-emb: d
[2023-07-01 11:41:16] [config] transformer-postprocess-top: ""
[2023-07-01 11:41:16] [config] transformer-preprocess: ""
[2023-07-01 11:41:16] [config] transformer-tied-layers:
[2023-07-01 11:41:16] [config]   []
[2023-07-01 11:41:16] [config] transformer-train-position-embeddings: false
[2023-07-01 11:41:16] [config] tsv: false
[2023-07-01 11:41:16] [config] tsv-fields: 0
[2023-07-01 11:41:16] [config] type: transformer
[2023-07-01 11:41:16] [config] ulr: false
[2023-07-01 11:41:16] [config] ulr-dim-emb: 0
[2023-07-01 11:41:16] [config] ulr-dropout: 0
[2023-07-01 11:41:16] [config] ulr-keys-vectors: ""
[2023-07-01 11:41:16] [config] ulr-query-vectors: ""
[2023-07-01 11:41:16] [config] ulr-softmax-temperature: 1
[2023-07-01 11:41:16] [config] ulr-trainable-transformation: false
[2023-07-01 11:41:16] [config] unlikelihood-loss: false
[2023-07-01 11:41:16] [config] valid-freq: 50000000
[2023-07-01 11:41:16] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:41:16] [config] valid-max-length: 1000
[2023-07-01 11:41:16] [config] valid-metrics:
[2023-07-01 11:41:16] [config]   - cross-entropy
[2023-07-01 11:41:16] [config]   - translation
[2023-07-01 11:41:16] [config] valid-mini-batch: 64
[2023-07-01 11:41:16] [config] valid-reset-stalled: false
[2023-07-01 11:41:16] [config] valid-script-args:
[2023-07-01 11:41:16] [config]   []
[2023-07-01 11:41:16] [config] valid-script-path: ""
[2023-07-01 11:41:16] [config] valid-sets:
[2023-07-01 11:41:16] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:41:16] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:41:16] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:41:16] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:41:16] [config] vocabs:
[2023-07-01 11:41:16] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:41:16] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:41:16] [config] word-penalty: 0
[2023-07-01 11:41:16] [config] word-scores: false
[2023-07-01 11:41:16] [config] workspace: 2048
[2023-07-01 11:41:16] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:41:16] Using synchronous SGD
[2023-07-01 11:41:16] Synced seed 1234
[2023-07-01 11:41:16] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:41:16] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:41:16] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:41:16] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:41:16] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:41:16] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:41:17] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:41:17] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:41:17] [comm] Using global sharding
[2023-07-01 11:41:17] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:41:17] [training] Using 1 GPUs
[2023-07-01 11:41:17] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:41:17] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:41:17] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:41:17] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:41:25] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:41:25] [valid] No post-processing script given for validating translator
[2023-07-01 11:41:25] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:41:25] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:41:25] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:41:25] [comm] Using global sharding
[2023-07-01 11:41:25] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:41:25] [training] Using 1 GPUs
[2023-07-01 11:41:25] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:41:25] Allocating memory for general optimizer shards
[2023-07-01 11:41:25] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:41:25] Loading Adam parameters
[2023-07-01 11:41:25] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:41:25] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:41:26] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:41:26] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:41:26] [data] Shuffling data
[2023-07-01 11:41:26] [data] Done reading 20,192 sentences
[2023-07-01 11:41:26] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:41:26] Training started
[2023-07-01 11:41:26] Training finished
[2023-07-01 11:41:29] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:41:29] [marian] Running on node20.datos.cluster.uy as process 19882 with command line:
[2023-07-01 11:41:29] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 144 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:41:29] [config] after: 0e
[2023-07-01 11:41:29] [config] after-batches: 0
[2023-07-01 11:41:29] [config] after-epochs: 144
[2023-07-01 11:41:29] [config] all-caps-every: 0
[2023-07-01 11:41:29] [config] allow-unk: false
[2023-07-01 11:41:29] [config] authors: false
[2023-07-01 11:41:29] [config] beam-size: 12
[2023-07-01 11:41:29] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:41:29] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:41:29] [config] bert-masking-fraction: 0.15
[2023-07-01 11:41:29] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:41:29] [config] bert-train-type-embeddings: true
[2023-07-01 11:41:29] [config] bert-type-vocab-size: 2
[2023-07-01 11:41:29] [config] build-info: ""
[2023-07-01 11:41:29] [config] check-gradient-nan: false
[2023-07-01 11:41:29] [config] check-nan: false
[2023-07-01 11:41:29] [config] cite: false
[2023-07-01 11:41:29] [config] clip-norm: 5
[2023-07-01 11:41:29] [config] cost-scaling:
[2023-07-01 11:41:29] [config]   []
[2023-07-01 11:41:29] [config] cost-type: ce-sum
[2023-07-01 11:41:29] [config] cpu-threads: 0
[2023-07-01 11:41:29] [config] data-threads: 8
[2023-07-01 11:41:29] [config] data-weighting: ""
[2023-07-01 11:41:29] [config] data-weighting-type: sentence
[2023-07-01 11:41:29] [config] dec-cell: gru
[2023-07-01 11:41:29] [config] dec-cell-base-depth: 2
[2023-07-01 11:41:29] [config] dec-cell-high-depth: 1
[2023-07-01 11:41:29] [config] dec-depth: 2
[2023-07-01 11:41:29] [config] devices:
[2023-07-01 11:41:29] [config]   - 0
[2023-07-01 11:41:29] [config] dim-emb: 512
[2023-07-01 11:41:29] [config] dim-rnn: 1024
[2023-07-01 11:41:29] [config] dim-vocabs:
[2023-07-01 11:41:29] [config]   - 16384
[2023-07-01 11:41:29] [config]   - 16384
[2023-07-01 11:41:29] [config] disp-first: 0
[2023-07-01 11:41:29] [config] disp-freq: 1000u
[2023-07-01 11:41:29] [config] disp-label-counts: true
[2023-07-01 11:41:29] [config] dropout-rnn: 0
[2023-07-01 11:41:29] [config] dropout-src: 0
[2023-07-01 11:41:29] [config] dropout-trg: 0
[2023-07-01 11:41:29] [config] dump-config: ""
[2023-07-01 11:41:29] [config] dynamic-gradient-scaling:
[2023-07-01 11:41:29] [config]   []
[2023-07-01 11:41:29] [config] early-stopping: 10
[2023-07-01 11:41:29] [config] early-stopping-on: first
[2023-07-01 11:41:29] [config] embedding-fix-src: false
[2023-07-01 11:41:29] [config] embedding-fix-trg: false
[2023-07-01 11:41:29] [config] embedding-normalization: false
[2023-07-01 11:41:29] [config] embedding-vectors:
[2023-07-01 11:41:29] [config]   []
[2023-07-01 11:41:29] [config] enc-cell: gru
[2023-07-01 11:41:29] [config] enc-cell-depth: 1
[2023-07-01 11:41:29] [config] enc-depth: 2
[2023-07-01 11:41:29] [config] enc-type: bidirectional
[2023-07-01 11:41:29] [config] english-title-case-every: 0
[2023-07-01 11:41:29] [config] exponential-smoothing: 0.0001
[2023-07-01 11:41:29] [config] factor-weight: 1
[2023-07-01 11:41:29] [config] factors-combine: sum
[2023-07-01 11:41:29] [config] factors-dim-emb: 0
[2023-07-01 11:41:29] [config] gradient-checkpointing: false
[2023-07-01 11:41:29] [config] gradient-norm-average-window: 100
[2023-07-01 11:41:29] [config] guided-alignment: none
[2023-07-01 11:41:29] [config] guided-alignment-cost: mse
[2023-07-01 11:41:29] [config] guided-alignment-weight: 0.1
[2023-07-01 11:41:29] [config] ignore-model-config: false
[2023-07-01 11:41:29] [config] input-types:
[2023-07-01 11:41:29] [config]   []
[2023-07-01 11:41:29] [config] interpolate-env-vars: false
[2023-07-01 11:41:29] [config] keep-best: false
[2023-07-01 11:41:29] [config] label-smoothing: 0.1
[2023-07-01 11:41:29] [config] layer-normalization: false
[2023-07-01 11:41:29] [config] learn-rate: 0.0003
[2023-07-01 11:41:29] [config] lemma-dependency: ""
[2023-07-01 11:41:29] [config] lemma-dim-emb: 0
[2023-07-01 11:41:29] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:41:29] [config] log-level: info
[2023-07-01 11:41:29] [config] log-time-zone: ""
[2023-07-01 11:41:29] [config] logical-epoch:
[2023-07-01 11:41:29] [config]   - 1e
[2023-07-01 11:41:29] [config]   - 0
[2023-07-01 11:41:29] [config] lr-decay: 0
[2023-07-01 11:41:29] [config] lr-decay-freq: 50000
[2023-07-01 11:41:29] [config] lr-decay-inv-sqrt:
[2023-07-01 11:41:29] [config]   - 16000
[2023-07-01 11:41:29] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:41:29] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:41:29] [config] lr-decay-start:
[2023-07-01 11:41:29] [config]   - 10
[2023-07-01 11:41:29] [config]   - 1
[2023-07-01 11:41:29] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:41:29] [config] lr-report: true
[2023-07-01 11:41:29] [config] lr-warmup: 16000
[2023-07-01 11:41:29] [config] lr-warmup-at-reload: false
[2023-07-01 11:41:29] [config] lr-warmup-cycle: false
[2023-07-01 11:41:29] [config] lr-warmup-start-rate: 0
[2023-07-01 11:41:29] [config] max-length: 100
[2023-07-01 11:41:29] [config] max-length-crop: false
[2023-07-01 11:41:29] [config] max-length-factor: 3
[2023-07-01 11:41:29] [config] maxi-batch: 100
[2023-07-01 11:41:29] [config] maxi-batch-sort: trg
[2023-07-01 11:41:29] [config] mini-batch: 1000
[2023-07-01 11:41:29] [config] mini-batch-fit: true
[2023-07-01 11:41:29] [config] mini-batch-fit-step: 10
[2023-07-01 11:41:29] [config] mini-batch-round-up: true
[2023-07-01 11:41:29] [config] mini-batch-track-lr: false
[2023-07-01 11:41:29] [config] mini-batch-warmup: 0
[2023-07-01 11:41:29] [config] mini-batch-words: 0
[2023-07-01 11:41:29] [config] mini-batch-words-ref: 0
[2023-07-01 11:41:29] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:41:29] [config] multi-loss-type: sum
[2023-07-01 11:41:29] [config] n-best: false
[2023-07-01 11:41:29] [config] no-nccl: false
[2023-07-01 11:41:29] [config] no-reload: false
[2023-07-01 11:41:29] [config] no-restore-corpus: false
[2023-07-01 11:41:29] [config] normalize: 1
[2023-07-01 11:41:29] [config] normalize-gradient: false
[2023-07-01 11:41:29] [config] num-devices: 0
[2023-07-01 11:41:29] [config] optimizer: adam
[2023-07-01 11:41:29] [config] optimizer-delay: 1
[2023-07-01 11:41:29] [config] optimizer-params:
[2023-07-01 11:41:29] [config]   - 0.9
[2023-07-01 11:41:29] [config]   - 0.98
[2023-07-01 11:41:29] [config]   - 1e-09
[2023-07-01 11:41:29] [config] output-omit-bias: false
[2023-07-01 11:41:29] [config] overwrite: true
[2023-07-01 11:41:29] [config] precision:
[2023-07-01 11:41:29] [config]   - float32
[2023-07-01 11:41:29] [config]   - float32
[2023-07-01 11:41:29] [config] pretrained-model: ""
[2023-07-01 11:41:29] [config] quantize-biases: false
[2023-07-01 11:41:29] [config] quantize-bits: 0
[2023-07-01 11:41:29] [config] quantize-log-based: false
[2023-07-01 11:41:29] [config] quantize-optimization-steps: 0
[2023-07-01 11:41:29] [config] quiet: false
[2023-07-01 11:41:29] [config] quiet-translation: true
[2023-07-01 11:41:29] [config] relative-paths: false
[2023-07-01 11:41:29] [config] right-left: false
[2023-07-01 11:41:29] [config] save-freq: 10000u
[2023-07-01 11:41:29] [config] seed: 1234
[2023-07-01 11:41:29] [config] sentencepiece-alphas:
[2023-07-01 11:41:29] [config]   []
[2023-07-01 11:41:29] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:41:29] [config] sentencepiece-options: ""
[2023-07-01 11:41:29] [config] sharding: global
[2023-07-01 11:41:29] [config] shuffle: data
[2023-07-01 11:41:29] [config] shuffle-in-ram: false
[2023-07-01 11:41:29] [config] sigterm: save-and-exit
[2023-07-01 11:41:29] [config] skip: false
[2023-07-01 11:41:29] [config] sqlite: ""
[2023-07-01 11:41:29] [config] sqlite-drop: false
[2023-07-01 11:41:29] [config] sync-freq: 200u
[2023-07-01 11:41:29] [config] sync-sgd: true
[2023-07-01 11:41:29] [config] tempdir: /tmp
[2023-07-01 11:41:29] [config] tied-embeddings: false
[2023-07-01 11:41:29] [config] tied-embeddings-all: true
[2023-07-01 11:41:29] [config] tied-embeddings-src: false
[2023-07-01 11:41:29] [config] train-embedder-rank:
[2023-07-01 11:41:29] [config]   []
[2023-07-01 11:41:29] [config] train-sets:
[2023-07-01 11:41:29] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:41:29] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:41:29] [config] transformer-aan-activation: swish
[2023-07-01 11:41:29] [config] transformer-aan-depth: 2
[2023-07-01 11:41:29] [config] transformer-aan-nogate: false
[2023-07-01 11:41:29] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:41:29] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:41:29] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:41:29] [config] transformer-depth-scaling: false
[2023-07-01 11:41:29] [config] transformer-dim-aan: 2048
[2023-07-01 11:41:29] [config] transformer-dim-ffn: 2048
[2023-07-01 11:41:29] [config] transformer-dropout: 0.1
[2023-07-01 11:41:29] [config] transformer-dropout-attention: 0
[2023-07-01 11:41:29] [config] transformer-dropout-ffn: 0
[2023-07-01 11:41:29] [config] transformer-ffn-activation: swish
[2023-07-01 11:41:29] [config] transformer-ffn-depth: 2
[2023-07-01 11:41:29] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:41:29] [config] transformer-heads: 8
[2023-07-01 11:41:29] [config] transformer-no-projection: false
[2023-07-01 11:41:29] [config] transformer-pool: false
[2023-07-01 11:41:29] [config] transformer-postprocess: dan
[2023-07-01 11:41:29] [config] transformer-postprocess-emb: d
[2023-07-01 11:41:29] [config] transformer-postprocess-top: ""
[2023-07-01 11:41:29] [config] transformer-preprocess: ""
[2023-07-01 11:41:29] [config] transformer-tied-layers:
[2023-07-01 11:41:29] [config]   []
[2023-07-01 11:41:29] [config] transformer-train-position-embeddings: false
[2023-07-01 11:41:29] [config] tsv: false
[2023-07-01 11:41:29] [config] tsv-fields: 0
[2023-07-01 11:41:29] [config] type: transformer
[2023-07-01 11:41:29] [config] ulr: false
[2023-07-01 11:41:29] [config] ulr-dim-emb: 0
[2023-07-01 11:41:29] [config] ulr-dropout: 0
[2023-07-01 11:41:29] [config] ulr-keys-vectors: ""
[2023-07-01 11:41:29] [config] ulr-query-vectors: ""
[2023-07-01 11:41:29] [config] ulr-softmax-temperature: 1
[2023-07-01 11:41:29] [config] ulr-trainable-transformation: false
[2023-07-01 11:41:29] [config] unlikelihood-loss: false
[2023-07-01 11:41:29] [config] valid-freq: 50000000
[2023-07-01 11:41:29] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:41:29] [config] valid-max-length: 1000
[2023-07-01 11:41:29] [config] valid-metrics:
[2023-07-01 11:41:29] [config]   - cross-entropy
[2023-07-01 11:41:29] [config]   - translation
[2023-07-01 11:41:29] [config] valid-mini-batch: 64
[2023-07-01 11:41:29] [config] valid-reset-stalled: false
[2023-07-01 11:41:29] [config] valid-script-args:
[2023-07-01 11:41:29] [config]   []
[2023-07-01 11:41:29] [config] valid-script-path: ""
[2023-07-01 11:41:29] [config] valid-sets:
[2023-07-01 11:41:29] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:41:29] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:41:29] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:41:29] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:41:29] [config] vocabs:
[2023-07-01 11:41:29] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:41:29] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:41:29] [config] word-penalty: 0
[2023-07-01 11:41:29] [config] word-scores: false
[2023-07-01 11:41:29] [config] workspace: 2048
[2023-07-01 11:41:29] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:41:29] Using synchronous SGD
[2023-07-01 11:41:30] Synced seed 1234
[2023-07-01 11:41:30] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:41:30] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:41:30] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:41:30] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:41:30] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:41:30] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:41:30] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:41:30] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:41:30] [comm] Using global sharding
[2023-07-01 11:41:31] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:41:31] [training] Using 1 GPUs
[2023-07-01 11:41:31] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:41:31] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:41:31] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:41:31] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:41:38] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:41:38] [valid] No post-processing script given for validating translator
[2023-07-01 11:41:38] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:41:38] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:41:38] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:41:38] [comm] Using global sharding
[2023-07-01 11:41:38] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:41:38] [training] Using 1 GPUs
[2023-07-01 11:41:38] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:41:39] Allocating memory for general optimizer shards
[2023-07-01 11:41:39] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:41:39] Loading Adam parameters
[2023-07-01 11:41:39] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:41:39] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:41:39] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:41:39] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:41:39] [data] Shuffling data
[2023-07-01 11:41:39] [data] Done reading 20,192 sentences
[2023-07-01 11:41:39] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:41:39] Training started
[2023-07-01 11:41:39] Training finished
[2023-07-01 11:41:43] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:41:43] [marian] Running on node20.datos.cluster.uy as process 19940 with command line:
[2023-07-01 11:41:43] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 145 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:41:43] [config] after: 0e
[2023-07-01 11:41:43] [config] after-batches: 0
[2023-07-01 11:41:43] [config] after-epochs: 145
[2023-07-01 11:41:43] [config] all-caps-every: 0
[2023-07-01 11:41:43] [config] allow-unk: false
[2023-07-01 11:41:43] [config] authors: false
[2023-07-01 11:41:43] [config] beam-size: 12
[2023-07-01 11:41:43] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:41:43] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:41:43] [config] bert-masking-fraction: 0.15
[2023-07-01 11:41:43] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:41:43] [config] bert-train-type-embeddings: true
[2023-07-01 11:41:43] [config] bert-type-vocab-size: 2
[2023-07-01 11:41:43] [config] build-info: ""
[2023-07-01 11:41:43] [config] check-gradient-nan: false
[2023-07-01 11:41:43] [config] check-nan: false
[2023-07-01 11:41:43] [config] cite: false
[2023-07-01 11:41:43] [config] clip-norm: 5
[2023-07-01 11:41:43] [config] cost-scaling:
[2023-07-01 11:41:43] [config]   []
[2023-07-01 11:41:43] [config] cost-type: ce-sum
[2023-07-01 11:41:43] [config] cpu-threads: 0
[2023-07-01 11:41:43] [config] data-threads: 8
[2023-07-01 11:41:43] [config] data-weighting: ""
[2023-07-01 11:41:43] [config] data-weighting-type: sentence
[2023-07-01 11:41:43] [config] dec-cell: gru
[2023-07-01 11:41:43] [config] dec-cell-base-depth: 2
[2023-07-01 11:41:43] [config] dec-cell-high-depth: 1
[2023-07-01 11:41:43] [config] dec-depth: 2
[2023-07-01 11:41:43] [config] devices:
[2023-07-01 11:41:43] [config]   - 0
[2023-07-01 11:41:43] [config] dim-emb: 512
[2023-07-01 11:41:43] [config] dim-rnn: 1024
[2023-07-01 11:41:43] [config] dim-vocabs:
[2023-07-01 11:41:43] [config]   - 16384
[2023-07-01 11:41:43] [config]   - 16384
[2023-07-01 11:41:43] [config] disp-first: 0
[2023-07-01 11:41:43] [config] disp-freq: 1000u
[2023-07-01 11:41:43] [config] disp-label-counts: true
[2023-07-01 11:41:43] [config] dropout-rnn: 0
[2023-07-01 11:41:43] [config] dropout-src: 0
[2023-07-01 11:41:43] [config] dropout-trg: 0
[2023-07-01 11:41:43] [config] dump-config: ""
[2023-07-01 11:41:43] [config] dynamic-gradient-scaling:
[2023-07-01 11:41:43] [config]   []
[2023-07-01 11:41:43] [config] early-stopping: 10
[2023-07-01 11:41:43] [config] early-stopping-on: first
[2023-07-01 11:41:43] [config] embedding-fix-src: false
[2023-07-01 11:41:43] [config] embedding-fix-trg: false
[2023-07-01 11:41:43] [config] embedding-normalization: false
[2023-07-01 11:41:43] [config] embedding-vectors:
[2023-07-01 11:41:43] [config]   []
[2023-07-01 11:41:43] [config] enc-cell: gru
[2023-07-01 11:41:43] [config] enc-cell-depth: 1
[2023-07-01 11:41:43] [config] enc-depth: 2
[2023-07-01 11:41:43] [config] enc-type: bidirectional
[2023-07-01 11:41:43] [config] english-title-case-every: 0
[2023-07-01 11:41:43] [config] exponential-smoothing: 0.0001
[2023-07-01 11:41:43] [config] factor-weight: 1
[2023-07-01 11:41:43] [config] factors-combine: sum
[2023-07-01 11:41:43] [config] factors-dim-emb: 0
[2023-07-01 11:41:43] [config] gradient-checkpointing: false
[2023-07-01 11:41:43] [config] gradient-norm-average-window: 100
[2023-07-01 11:41:43] [config] guided-alignment: none
[2023-07-01 11:41:43] [config] guided-alignment-cost: mse
[2023-07-01 11:41:43] [config] guided-alignment-weight: 0.1
[2023-07-01 11:41:43] [config] ignore-model-config: false
[2023-07-01 11:41:43] [config] input-types:
[2023-07-01 11:41:43] [config]   []
[2023-07-01 11:41:43] [config] interpolate-env-vars: false
[2023-07-01 11:41:43] [config] keep-best: false
[2023-07-01 11:41:43] [config] label-smoothing: 0.1
[2023-07-01 11:41:43] [config] layer-normalization: false
[2023-07-01 11:41:43] [config] learn-rate: 0.0003
[2023-07-01 11:41:43] [config] lemma-dependency: ""
[2023-07-01 11:41:43] [config] lemma-dim-emb: 0
[2023-07-01 11:41:43] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:41:43] [config] log-level: info
[2023-07-01 11:41:43] [config] log-time-zone: ""
[2023-07-01 11:41:43] [config] logical-epoch:
[2023-07-01 11:41:43] [config]   - 1e
[2023-07-01 11:41:43] [config]   - 0
[2023-07-01 11:41:43] [config] lr-decay: 0
[2023-07-01 11:41:43] [config] lr-decay-freq: 50000
[2023-07-01 11:41:43] [config] lr-decay-inv-sqrt:
[2023-07-01 11:41:43] [config]   - 16000
[2023-07-01 11:41:43] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:41:43] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:41:43] [config] lr-decay-start:
[2023-07-01 11:41:43] [config]   - 10
[2023-07-01 11:41:43] [config]   - 1
[2023-07-01 11:41:43] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:41:43] [config] lr-report: true
[2023-07-01 11:41:43] [config] lr-warmup: 16000
[2023-07-01 11:41:43] [config] lr-warmup-at-reload: false
[2023-07-01 11:41:43] [config] lr-warmup-cycle: false
[2023-07-01 11:41:43] [config] lr-warmup-start-rate: 0
[2023-07-01 11:41:43] [config] max-length: 100
[2023-07-01 11:41:43] [config] max-length-crop: false
[2023-07-01 11:41:43] [config] max-length-factor: 3
[2023-07-01 11:41:43] [config] maxi-batch: 100
[2023-07-01 11:41:43] [config] maxi-batch-sort: trg
[2023-07-01 11:41:43] [config] mini-batch: 1000
[2023-07-01 11:41:43] [config] mini-batch-fit: true
[2023-07-01 11:41:43] [config] mini-batch-fit-step: 10
[2023-07-01 11:41:43] [config] mini-batch-round-up: true
[2023-07-01 11:41:43] [config] mini-batch-track-lr: false
[2023-07-01 11:41:43] [config] mini-batch-warmup: 0
[2023-07-01 11:41:43] [config] mini-batch-words: 0
[2023-07-01 11:41:43] [config] mini-batch-words-ref: 0
[2023-07-01 11:41:43] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:41:43] [config] multi-loss-type: sum
[2023-07-01 11:41:43] [config] n-best: false
[2023-07-01 11:41:43] [config] no-nccl: false
[2023-07-01 11:41:43] [config] no-reload: false
[2023-07-01 11:41:43] [config] no-restore-corpus: false
[2023-07-01 11:41:43] [config] normalize: 1
[2023-07-01 11:41:43] [config] normalize-gradient: false
[2023-07-01 11:41:43] [config] num-devices: 0
[2023-07-01 11:41:43] [config] optimizer: adam
[2023-07-01 11:41:43] [config] optimizer-delay: 1
[2023-07-01 11:41:43] [config] optimizer-params:
[2023-07-01 11:41:43] [config]   - 0.9
[2023-07-01 11:41:43] [config]   - 0.98
[2023-07-01 11:41:43] [config]   - 1e-09
[2023-07-01 11:41:43] [config] output-omit-bias: false
[2023-07-01 11:41:43] [config] overwrite: true
[2023-07-01 11:41:43] [config] precision:
[2023-07-01 11:41:43] [config]   - float32
[2023-07-01 11:41:43] [config]   - float32
[2023-07-01 11:41:43] [config] pretrained-model: ""
[2023-07-01 11:41:43] [config] quantize-biases: false
[2023-07-01 11:41:43] [config] quantize-bits: 0
[2023-07-01 11:41:43] [config] quantize-log-based: false
[2023-07-01 11:41:43] [config] quantize-optimization-steps: 0
[2023-07-01 11:41:43] [config] quiet: false
[2023-07-01 11:41:43] [config] quiet-translation: true
[2023-07-01 11:41:43] [config] relative-paths: false
[2023-07-01 11:41:43] [config] right-left: false
[2023-07-01 11:41:43] [config] save-freq: 10000u
[2023-07-01 11:41:43] [config] seed: 1234
[2023-07-01 11:41:43] [config] sentencepiece-alphas:
[2023-07-01 11:41:43] [config]   []
[2023-07-01 11:41:43] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:41:43] [config] sentencepiece-options: ""
[2023-07-01 11:41:43] [config] sharding: global
[2023-07-01 11:41:43] [config] shuffle: data
[2023-07-01 11:41:43] [config] shuffle-in-ram: false
[2023-07-01 11:41:43] [config] sigterm: save-and-exit
[2023-07-01 11:41:43] [config] skip: false
[2023-07-01 11:41:43] [config] sqlite: ""
[2023-07-01 11:41:43] [config] sqlite-drop: false
[2023-07-01 11:41:43] [config] sync-freq: 200u
[2023-07-01 11:41:43] [config] sync-sgd: true
[2023-07-01 11:41:43] [config] tempdir: /tmp
[2023-07-01 11:41:43] [config] tied-embeddings: false
[2023-07-01 11:41:43] [config] tied-embeddings-all: true
[2023-07-01 11:41:43] [config] tied-embeddings-src: false
[2023-07-01 11:41:43] [config] train-embedder-rank:
[2023-07-01 11:41:43] [config]   []
[2023-07-01 11:41:43] [config] train-sets:
[2023-07-01 11:41:43] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:41:43] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:41:43] [config] transformer-aan-activation: swish
[2023-07-01 11:41:43] [config] transformer-aan-depth: 2
[2023-07-01 11:41:43] [config] transformer-aan-nogate: false
[2023-07-01 11:41:43] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:41:43] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:41:43] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:41:43] [config] transformer-depth-scaling: false
[2023-07-01 11:41:43] [config] transformer-dim-aan: 2048
[2023-07-01 11:41:43] [config] transformer-dim-ffn: 2048
[2023-07-01 11:41:43] [config] transformer-dropout: 0.1
[2023-07-01 11:41:43] [config] transformer-dropout-attention: 0
[2023-07-01 11:41:43] [config] transformer-dropout-ffn: 0
[2023-07-01 11:41:43] [config] transformer-ffn-activation: swish
[2023-07-01 11:41:43] [config] transformer-ffn-depth: 2
[2023-07-01 11:41:43] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:41:43] [config] transformer-heads: 8
[2023-07-01 11:41:43] [config] transformer-no-projection: false
[2023-07-01 11:41:43] [config] transformer-pool: false
[2023-07-01 11:41:43] [config] transformer-postprocess: dan
[2023-07-01 11:41:43] [config] transformer-postprocess-emb: d
[2023-07-01 11:41:43] [config] transformer-postprocess-top: ""
[2023-07-01 11:41:43] [config] transformer-preprocess: ""
[2023-07-01 11:41:43] [config] transformer-tied-layers:
[2023-07-01 11:41:43] [config]   []
[2023-07-01 11:41:43] [config] transformer-train-position-embeddings: false
[2023-07-01 11:41:43] [config] tsv: false
[2023-07-01 11:41:43] [config] tsv-fields: 0
[2023-07-01 11:41:43] [config] type: transformer
[2023-07-01 11:41:43] [config] ulr: false
[2023-07-01 11:41:43] [config] ulr-dim-emb: 0
[2023-07-01 11:41:43] [config] ulr-dropout: 0
[2023-07-01 11:41:43] [config] ulr-keys-vectors: ""
[2023-07-01 11:41:43] [config] ulr-query-vectors: ""
[2023-07-01 11:41:43] [config] ulr-softmax-temperature: 1
[2023-07-01 11:41:43] [config] ulr-trainable-transformation: false
[2023-07-01 11:41:43] [config] unlikelihood-loss: false
[2023-07-01 11:41:43] [config] valid-freq: 50000000
[2023-07-01 11:41:43] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:41:43] [config] valid-max-length: 1000
[2023-07-01 11:41:43] [config] valid-metrics:
[2023-07-01 11:41:43] [config]   - cross-entropy
[2023-07-01 11:41:43] [config]   - translation
[2023-07-01 11:41:43] [config] valid-mini-batch: 64
[2023-07-01 11:41:43] [config] valid-reset-stalled: false
[2023-07-01 11:41:43] [config] valid-script-args:
[2023-07-01 11:41:43] [config]   []
[2023-07-01 11:41:43] [config] valid-script-path: ""
[2023-07-01 11:41:43] [config] valid-sets:
[2023-07-01 11:41:43] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:41:43] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:41:43] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:41:43] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:41:43] [config] vocabs:
[2023-07-01 11:41:43] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:41:43] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:41:43] [config] word-penalty: 0
[2023-07-01 11:41:43] [config] word-scores: false
[2023-07-01 11:41:43] [config] workspace: 2048
[2023-07-01 11:41:43] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:41:43] Using synchronous SGD
[2023-07-01 11:41:43] Synced seed 1234
[2023-07-01 11:41:43] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:41:43] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:41:43] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:41:43] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:41:43] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:41:43] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:41:44] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:41:44] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:41:44] [comm] Using global sharding
[2023-07-01 11:41:44] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:41:44] [training] Using 1 GPUs
[2023-07-01 11:41:44] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:41:44] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:41:44] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:41:44] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:41:52] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:41:52] [valid] No post-processing script given for validating translator
[2023-07-01 11:41:52] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:41:52] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:41:52] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:41:52] [comm] Using global sharding
[2023-07-01 11:41:52] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:41:52] [training] Using 1 GPUs
[2023-07-01 11:41:52] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:41:52] Allocating memory for general optimizer shards
[2023-07-01 11:41:52] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:41:52] Loading Adam parameters
[2023-07-01 11:41:53] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:41:53] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:41:53] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:41:53] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:41:53] [data] Shuffling data
[2023-07-01 11:41:53] [data] Done reading 20,192 sentences
[2023-07-01 11:41:53] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:41:53] Training started
[2023-07-01 11:41:53] Training finished
[2023-07-01 11:41:56] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:41:56] [marian] Running on node20.datos.cluster.uy as process 19999 with command line:
[2023-07-01 11:41:56] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 146 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:41:56] [config] after: 0e
[2023-07-01 11:41:56] [config] after-batches: 0
[2023-07-01 11:41:56] [config] after-epochs: 146
[2023-07-01 11:41:56] [config] all-caps-every: 0
[2023-07-01 11:41:56] [config] allow-unk: false
[2023-07-01 11:41:56] [config] authors: false
[2023-07-01 11:41:56] [config] beam-size: 12
[2023-07-01 11:41:56] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:41:56] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:41:56] [config] bert-masking-fraction: 0.15
[2023-07-01 11:41:56] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:41:56] [config] bert-train-type-embeddings: true
[2023-07-01 11:41:56] [config] bert-type-vocab-size: 2
[2023-07-01 11:41:56] [config] build-info: ""
[2023-07-01 11:41:56] [config] check-gradient-nan: false
[2023-07-01 11:41:56] [config] check-nan: false
[2023-07-01 11:41:56] [config] cite: false
[2023-07-01 11:41:56] [config] clip-norm: 5
[2023-07-01 11:41:56] [config] cost-scaling:
[2023-07-01 11:41:56] [config]   []
[2023-07-01 11:41:56] [config] cost-type: ce-sum
[2023-07-01 11:41:56] [config] cpu-threads: 0
[2023-07-01 11:41:56] [config] data-threads: 8
[2023-07-01 11:41:56] [config] data-weighting: ""
[2023-07-01 11:41:56] [config] data-weighting-type: sentence
[2023-07-01 11:41:56] [config] dec-cell: gru
[2023-07-01 11:41:56] [config] dec-cell-base-depth: 2
[2023-07-01 11:41:56] [config] dec-cell-high-depth: 1
[2023-07-01 11:41:56] [config] dec-depth: 2
[2023-07-01 11:41:56] [config] devices:
[2023-07-01 11:41:56] [config]   - 0
[2023-07-01 11:41:56] [config] dim-emb: 512
[2023-07-01 11:41:56] [config] dim-rnn: 1024
[2023-07-01 11:41:56] [config] dim-vocabs:
[2023-07-01 11:41:56] [config]   - 16384
[2023-07-01 11:41:56] [config]   - 16384
[2023-07-01 11:41:56] [config] disp-first: 0
[2023-07-01 11:41:56] [config] disp-freq: 1000u
[2023-07-01 11:41:56] [config] disp-label-counts: true
[2023-07-01 11:41:56] [config] dropout-rnn: 0
[2023-07-01 11:41:56] [config] dropout-src: 0
[2023-07-01 11:41:56] [config] dropout-trg: 0
[2023-07-01 11:41:56] [config] dump-config: ""
[2023-07-01 11:41:56] [config] dynamic-gradient-scaling:
[2023-07-01 11:41:56] [config]   []
[2023-07-01 11:41:56] [config] early-stopping: 10
[2023-07-01 11:41:56] [config] early-stopping-on: first
[2023-07-01 11:41:56] [config] embedding-fix-src: false
[2023-07-01 11:41:56] [config] embedding-fix-trg: false
[2023-07-01 11:41:56] [config] embedding-normalization: false
[2023-07-01 11:41:56] [config] embedding-vectors:
[2023-07-01 11:41:56] [config]   []
[2023-07-01 11:41:56] [config] enc-cell: gru
[2023-07-01 11:41:56] [config] enc-cell-depth: 1
[2023-07-01 11:41:56] [config] enc-depth: 2
[2023-07-01 11:41:56] [config] enc-type: bidirectional
[2023-07-01 11:41:56] [config] english-title-case-every: 0
[2023-07-01 11:41:56] [config] exponential-smoothing: 0.0001
[2023-07-01 11:41:56] [config] factor-weight: 1
[2023-07-01 11:41:56] [config] factors-combine: sum
[2023-07-01 11:41:56] [config] factors-dim-emb: 0
[2023-07-01 11:41:56] [config] gradient-checkpointing: false
[2023-07-01 11:41:56] [config] gradient-norm-average-window: 100
[2023-07-01 11:41:56] [config] guided-alignment: none
[2023-07-01 11:41:56] [config] guided-alignment-cost: mse
[2023-07-01 11:41:56] [config] guided-alignment-weight: 0.1
[2023-07-01 11:41:56] [config] ignore-model-config: false
[2023-07-01 11:41:56] [config] input-types:
[2023-07-01 11:41:56] [config]   []
[2023-07-01 11:41:56] [config] interpolate-env-vars: false
[2023-07-01 11:41:56] [config] keep-best: false
[2023-07-01 11:41:56] [config] label-smoothing: 0.1
[2023-07-01 11:41:56] [config] layer-normalization: false
[2023-07-01 11:41:56] [config] learn-rate: 0.0003
[2023-07-01 11:41:56] [config] lemma-dependency: ""
[2023-07-01 11:41:56] [config] lemma-dim-emb: 0
[2023-07-01 11:41:56] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:41:56] [config] log-level: info
[2023-07-01 11:41:56] [config] log-time-zone: ""
[2023-07-01 11:41:56] [config] logical-epoch:
[2023-07-01 11:41:56] [config]   - 1e
[2023-07-01 11:41:56] [config]   - 0
[2023-07-01 11:41:56] [config] lr-decay: 0
[2023-07-01 11:41:56] [config] lr-decay-freq: 50000
[2023-07-01 11:41:56] [config] lr-decay-inv-sqrt:
[2023-07-01 11:41:56] [config]   - 16000
[2023-07-01 11:41:56] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:41:56] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:41:56] [config] lr-decay-start:
[2023-07-01 11:41:56] [config]   - 10
[2023-07-01 11:41:56] [config]   - 1
[2023-07-01 11:41:56] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:41:56] [config] lr-report: true
[2023-07-01 11:41:56] [config] lr-warmup: 16000
[2023-07-01 11:41:56] [config] lr-warmup-at-reload: false
[2023-07-01 11:41:56] [config] lr-warmup-cycle: false
[2023-07-01 11:41:56] [config] lr-warmup-start-rate: 0
[2023-07-01 11:41:56] [config] max-length: 100
[2023-07-01 11:41:56] [config] max-length-crop: false
[2023-07-01 11:41:56] [config] max-length-factor: 3
[2023-07-01 11:41:56] [config] maxi-batch: 100
[2023-07-01 11:41:56] [config] maxi-batch-sort: trg
[2023-07-01 11:41:56] [config] mini-batch: 1000
[2023-07-01 11:41:56] [config] mini-batch-fit: true
[2023-07-01 11:41:56] [config] mini-batch-fit-step: 10
[2023-07-01 11:41:56] [config] mini-batch-round-up: true
[2023-07-01 11:41:56] [config] mini-batch-track-lr: false
[2023-07-01 11:41:56] [config] mini-batch-warmup: 0
[2023-07-01 11:41:56] [config] mini-batch-words: 0
[2023-07-01 11:41:56] [config] mini-batch-words-ref: 0
[2023-07-01 11:41:56] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:41:56] [config] multi-loss-type: sum
[2023-07-01 11:41:56] [config] n-best: false
[2023-07-01 11:41:56] [config] no-nccl: false
[2023-07-01 11:41:56] [config] no-reload: false
[2023-07-01 11:41:56] [config] no-restore-corpus: false
[2023-07-01 11:41:56] [config] normalize: 1
[2023-07-01 11:41:56] [config] normalize-gradient: false
[2023-07-01 11:41:56] [config] num-devices: 0
[2023-07-01 11:41:56] [config] optimizer: adam
[2023-07-01 11:41:56] [config] optimizer-delay: 1
[2023-07-01 11:41:56] [config] optimizer-params:
[2023-07-01 11:41:56] [config]   - 0.9
[2023-07-01 11:41:56] [config]   - 0.98
[2023-07-01 11:41:56] [config]   - 1e-09
[2023-07-01 11:41:56] [config] output-omit-bias: false
[2023-07-01 11:41:56] [config] overwrite: true
[2023-07-01 11:41:56] [config] precision:
[2023-07-01 11:41:56] [config]   - float32
[2023-07-01 11:41:56] [config]   - float32
[2023-07-01 11:41:56] [config] pretrained-model: ""
[2023-07-01 11:41:56] [config] quantize-biases: false
[2023-07-01 11:41:56] [config] quantize-bits: 0
[2023-07-01 11:41:56] [config] quantize-log-based: false
[2023-07-01 11:41:56] [config] quantize-optimization-steps: 0
[2023-07-01 11:41:56] [config] quiet: false
[2023-07-01 11:41:56] [config] quiet-translation: true
[2023-07-01 11:41:56] [config] relative-paths: false
[2023-07-01 11:41:56] [config] right-left: false
[2023-07-01 11:41:56] [config] save-freq: 10000u
[2023-07-01 11:41:56] [config] seed: 1234
[2023-07-01 11:41:56] [config] sentencepiece-alphas:
[2023-07-01 11:41:56] [config]   []
[2023-07-01 11:41:56] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:41:56] [config] sentencepiece-options: ""
[2023-07-01 11:41:56] [config] sharding: global
[2023-07-01 11:41:56] [config] shuffle: data
[2023-07-01 11:41:56] [config] shuffle-in-ram: false
[2023-07-01 11:41:56] [config] sigterm: save-and-exit
[2023-07-01 11:41:56] [config] skip: false
[2023-07-01 11:41:56] [config] sqlite: ""
[2023-07-01 11:41:56] [config] sqlite-drop: false
[2023-07-01 11:41:56] [config] sync-freq: 200u
[2023-07-01 11:41:56] [config] sync-sgd: true
[2023-07-01 11:41:56] [config] tempdir: /tmp
[2023-07-01 11:41:56] [config] tied-embeddings: false
[2023-07-01 11:41:56] [config] tied-embeddings-all: true
[2023-07-01 11:41:56] [config] tied-embeddings-src: false
[2023-07-01 11:41:56] [config] train-embedder-rank:
[2023-07-01 11:41:56] [config]   []
[2023-07-01 11:41:56] [config] train-sets:
[2023-07-01 11:41:56] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:41:56] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:41:56] [config] transformer-aan-activation: swish
[2023-07-01 11:41:56] [config] transformer-aan-depth: 2
[2023-07-01 11:41:56] [config] transformer-aan-nogate: false
[2023-07-01 11:41:56] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:41:56] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:41:56] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:41:56] [config] transformer-depth-scaling: false
[2023-07-01 11:41:56] [config] transformer-dim-aan: 2048
[2023-07-01 11:41:56] [config] transformer-dim-ffn: 2048
[2023-07-01 11:41:56] [config] transformer-dropout: 0.1
[2023-07-01 11:41:56] [config] transformer-dropout-attention: 0
[2023-07-01 11:41:56] [config] transformer-dropout-ffn: 0
[2023-07-01 11:41:56] [config] transformer-ffn-activation: swish
[2023-07-01 11:41:56] [config] transformer-ffn-depth: 2
[2023-07-01 11:41:56] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:41:56] [config] transformer-heads: 8
[2023-07-01 11:41:56] [config] transformer-no-projection: false
[2023-07-01 11:41:56] [config] transformer-pool: false
[2023-07-01 11:41:56] [config] transformer-postprocess: dan
[2023-07-01 11:41:56] [config] transformer-postprocess-emb: d
[2023-07-01 11:41:56] [config] transformer-postprocess-top: ""
[2023-07-01 11:41:56] [config] transformer-preprocess: ""
[2023-07-01 11:41:56] [config] transformer-tied-layers:
[2023-07-01 11:41:56] [config]   []
[2023-07-01 11:41:56] [config] transformer-train-position-embeddings: false
[2023-07-01 11:41:56] [config] tsv: false
[2023-07-01 11:41:56] [config] tsv-fields: 0
[2023-07-01 11:41:56] [config] type: transformer
[2023-07-01 11:41:56] [config] ulr: false
[2023-07-01 11:41:56] [config] ulr-dim-emb: 0
[2023-07-01 11:41:56] [config] ulr-dropout: 0
[2023-07-01 11:41:56] [config] ulr-keys-vectors: ""
[2023-07-01 11:41:56] [config] ulr-query-vectors: ""
[2023-07-01 11:41:56] [config] ulr-softmax-temperature: 1
[2023-07-01 11:41:56] [config] ulr-trainable-transformation: false
[2023-07-01 11:41:56] [config] unlikelihood-loss: false
[2023-07-01 11:41:56] [config] valid-freq: 50000000
[2023-07-01 11:41:56] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:41:56] [config] valid-max-length: 1000
[2023-07-01 11:41:56] [config] valid-metrics:
[2023-07-01 11:41:56] [config]   - cross-entropy
[2023-07-01 11:41:56] [config]   - translation
[2023-07-01 11:41:56] [config] valid-mini-batch: 64
[2023-07-01 11:41:56] [config] valid-reset-stalled: false
[2023-07-01 11:41:56] [config] valid-script-args:
[2023-07-01 11:41:56] [config]   []
[2023-07-01 11:41:56] [config] valid-script-path: ""
[2023-07-01 11:41:56] [config] valid-sets:
[2023-07-01 11:41:56] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:41:56] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:41:56] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:41:56] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:41:56] [config] vocabs:
[2023-07-01 11:41:56] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:41:56] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:41:56] [config] word-penalty: 0
[2023-07-01 11:41:56] [config] word-scores: false
[2023-07-01 11:41:56] [config] workspace: 2048
[2023-07-01 11:41:56] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:41:56] Using synchronous SGD
[2023-07-01 11:41:56] Synced seed 1234
[2023-07-01 11:41:56] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:41:56] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:41:56] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:41:57] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:41:57] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:41:57] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:41:57] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:41:57] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:41:57] [comm] Using global sharding
[2023-07-01 11:41:57] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:41:57] [training] Using 1 GPUs
[2023-07-01 11:41:57] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:41:57] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:41:58] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:41:58] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:42:05] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:42:05] [valid] No post-processing script given for validating translator
[2023-07-01 11:42:05] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:42:05] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:42:05] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:42:05] [comm] Using global sharding
[2023-07-01 11:42:05] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:42:05] [training] Using 1 GPUs
[2023-07-01 11:42:05] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:42:06] Allocating memory for general optimizer shards
[2023-07-01 11:42:06] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:42:06] Loading Adam parameters
[2023-07-01 11:42:06] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:42:06] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:42:06] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:42:06] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:42:06] [data] Shuffling data
[2023-07-01 11:42:06] [data] Done reading 20,192 sentences
[2023-07-01 11:42:06] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:42:06] Training started
[2023-07-01 11:42:06] Training finished
[2023-07-01 11:42:10] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:42:10] [marian] Running on node20.datos.cluster.uy as process 20058 with command line:
[2023-07-01 11:42:10] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 147 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:42:10] [config] after: 0e
[2023-07-01 11:42:10] [config] after-batches: 0
[2023-07-01 11:42:10] [config] after-epochs: 147
[2023-07-01 11:42:10] [config] all-caps-every: 0
[2023-07-01 11:42:10] [config] allow-unk: false
[2023-07-01 11:42:10] [config] authors: false
[2023-07-01 11:42:10] [config] beam-size: 12
[2023-07-01 11:42:10] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:42:10] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:42:10] [config] bert-masking-fraction: 0.15
[2023-07-01 11:42:10] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:42:10] [config] bert-train-type-embeddings: true
[2023-07-01 11:42:10] [config] bert-type-vocab-size: 2
[2023-07-01 11:42:10] [config] build-info: ""
[2023-07-01 11:42:10] [config] check-gradient-nan: false
[2023-07-01 11:42:10] [config] check-nan: false
[2023-07-01 11:42:10] [config] cite: false
[2023-07-01 11:42:10] [config] clip-norm: 5
[2023-07-01 11:42:10] [config] cost-scaling:
[2023-07-01 11:42:10] [config]   []
[2023-07-01 11:42:10] [config] cost-type: ce-sum
[2023-07-01 11:42:10] [config] cpu-threads: 0
[2023-07-01 11:42:10] [config] data-threads: 8
[2023-07-01 11:42:10] [config] data-weighting: ""
[2023-07-01 11:42:10] [config] data-weighting-type: sentence
[2023-07-01 11:42:10] [config] dec-cell: gru
[2023-07-01 11:42:10] [config] dec-cell-base-depth: 2
[2023-07-01 11:42:10] [config] dec-cell-high-depth: 1
[2023-07-01 11:42:10] [config] dec-depth: 2
[2023-07-01 11:42:10] [config] devices:
[2023-07-01 11:42:10] [config]   - 0
[2023-07-01 11:42:10] [config] dim-emb: 512
[2023-07-01 11:42:10] [config] dim-rnn: 1024
[2023-07-01 11:42:10] [config] dim-vocabs:
[2023-07-01 11:42:10] [config]   - 16384
[2023-07-01 11:42:10] [config]   - 16384
[2023-07-01 11:42:10] [config] disp-first: 0
[2023-07-01 11:42:10] [config] disp-freq: 1000u
[2023-07-01 11:42:10] [config] disp-label-counts: true
[2023-07-01 11:42:10] [config] dropout-rnn: 0
[2023-07-01 11:42:10] [config] dropout-src: 0
[2023-07-01 11:42:10] [config] dropout-trg: 0
[2023-07-01 11:42:10] [config] dump-config: ""
[2023-07-01 11:42:10] [config] dynamic-gradient-scaling:
[2023-07-01 11:42:10] [config]   []
[2023-07-01 11:42:10] [config] early-stopping: 10
[2023-07-01 11:42:10] [config] early-stopping-on: first
[2023-07-01 11:42:10] [config] embedding-fix-src: false
[2023-07-01 11:42:10] [config] embedding-fix-trg: false
[2023-07-01 11:42:10] [config] embedding-normalization: false
[2023-07-01 11:42:10] [config] embedding-vectors:
[2023-07-01 11:42:10] [config]   []
[2023-07-01 11:42:10] [config] enc-cell: gru
[2023-07-01 11:42:10] [config] enc-cell-depth: 1
[2023-07-01 11:42:10] [config] enc-depth: 2
[2023-07-01 11:42:10] [config] enc-type: bidirectional
[2023-07-01 11:42:10] [config] english-title-case-every: 0
[2023-07-01 11:42:10] [config] exponential-smoothing: 0.0001
[2023-07-01 11:42:10] [config] factor-weight: 1
[2023-07-01 11:42:10] [config] factors-combine: sum
[2023-07-01 11:42:10] [config] factors-dim-emb: 0
[2023-07-01 11:42:10] [config] gradient-checkpointing: false
[2023-07-01 11:42:10] [config] gradient-norm-average-window: 100
[2023-07-01 11:42:10] [config] guided-alignment: none
[2023-07-01 11:42:10] [config] guided-alignment-cost: mse
[2023-07-01 11:42:10] [config] guided-alignment-weight: 0.1
[2023-07-01 11:42:10] [config] ignore-model-config: false
[2023-07-01 11:42:10] [config] input-types:
[2023-07-01 11:42:10] [config]   []
[2023-07-01 11:42:10] [config] interpolate-env-vars: false
[2023-07-01 11:42:10] [config] keep-best: false
[2023-07-01 11:42:10] [config] label-smoothing: 0.1
[2023-07-01 11:42:10] [config] layer-normalization: false
[2023-07-01 11:42:10] [config] learn-rate: 0.0003
[2023-07-01 11:42:10] [config] lemma-dependency: ""
[2023-07-01 11:42:10] [config] lemma-dim-emb: 0
[2023-07-01 11:42:10] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:42:10] [config] log-level: info
[2023-07-01 11:42:10] [config] log-time-zone: ""
[2023-07-01 11:42:10] [config] logical-epoch:
[2023-07-01 11:42:10] [config]   - 1e
[2023-07-01 11:42:10] [config]   - 0
[2023-07-01 11:42:10] [config] lr-decay: 0
[2023-07-01 11:42:10] [config] lr-decay-freq: 50000
[2023-07-01 11:42:10] [config] lr-decay-inv-sqrt:
[2023-07-01 11:42:10] [config]   - 16000
[2023-07-01 11:42:10] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:42:10] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:42:10] [config] lr-decay-start:
[2023-07-01 11:42:10] [config]   - 10
[2023-07-01 11:42:10] [config]   - 1
[2023-07-01 11:42:10] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:42:10] [config] lr-report: true
[2023-07-01 11:42:10] [config] lr-warmup: 16000
[2023-07-01 11:42:10] [config] lr-warmup-at-reload: false
[2023-07-01 11:42:10] [config] lr-warmup-cycle: false
[2023-07-01 11:42:10] [config] lr-warmup-start-rate: 0
[2023-07-01 11:42:10] [config] max-length: 100
[2023-07-01 11:42:10] [config] max-length-crop: false
[2023-07-01 11:42:10] [config] max-length-factor: 3
[2023-07-01 11:42:10] [config] maxi-batch: 100
[2023-07-01 11:42:10] [config] maxi-batch-sort: trg
[2023-07-01 11:42:10] [config] mini-batch: 1000
[2023-07-01 11:42:10] [config] mini-batch-fit: true
[2023-07-01 11:42:10] [config] mini-batch-fit-step: 10
[2023-07-01 11:42:10] [config] mini-batch-round-up: true
[2023-07-01 11:42:10] [config] mini-batch-track-lr: false
[2023-07-01 11:42:10] [config] mini-batch-warmup: 0
[2023-07-01 11:42:10] [config] mini-batch-words: 0
[2023-07-01 11:42:10] [config] mini-batch-words-ref: 0
[2023-07-01 11:42:10] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:42:10] [config] multi-loss-type: sum
[2023-07-01 11:42:10] [config] n-best: false
[2023-07-01 11:42:10] [config] no-nccl: false
[2023-07-01 11:42:10] [config] no-reload: false
[2023-07-01 11:42:10] [config] no-restore-corpus: false
[2023-07-01 11:42:10] [config] normalize: 1
[2023-07-01 11:42:10] [config] normalize-gradient: false
[2023-07-01 11:42:10] [config] num-devices: 0
[2023-07-01 11:42:10] [config] optimizer: adam
[2023-07-01 11:42:10] [config] optimizer-delay: 1
[2023-07-01 11:42:10] [config] optimizer-params:
[2023-07-01 11:42:10] [config]   - 0.9
[2023-07-01 11:42:10] [config]   - 0.98
[2023-07-01 11:42:10] [config]   - 1e-09
[2023-07-01 11:42:10] [config] output-omit-bias: false
[2023-07-01 11:42:10] [config] overwrite: true
[2023-07-01 11:42:10] [config] precision:
[2023-07-01 11:42:10] [config]   - float32
[2023-07-01 11:42:10] [config]   - float32
[2023-07-01 11:42:10] [config] pretrained-model: ""
[2023-07-01 11:42:10] [config] quantize-biases: false
[2023-07-01 11:42:10] [config] quantize-bits: 0
[2023-07-01 11:42:10] [config] quantize-log-based: false
[2023-07-01 11:42:10] [config] quantize-optimization-steps: 0
[2023-07-01 11:42:10] [config] quiet: false
[2023-07-01 11:42:10] [config] quiet-translation: true
[2023-07-01 11:42:10] [config] relative-paths: false
[2023-07-01 11:42:10] [config] right-left: false
[2023-07-01 11:42:10] [config] save-freq: 10000u
[2023-07-01 11:42:10] [config] seed: 1234
[2023-07-01 11:42:10] [config] sentencepiece-alphas:
[2023-07-01 11:42:10] [config]   []
[2023-07-01 11:42:10] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:42:10] [config] sentencepiece-options: ""
[2023-07-01 11:42:10] [config] sharding: global
[2023-07-01 11:42:10] [config] shuffle: data
[2023-07-01 11:42:10] [config] shuffle-in-ram: false
[2023-07-01 11:42:10] [config] sigterm: save-and-exit
[2023-07-01 11:42:10] [config] skip: false
[2023-07-01 11:42:10] [config] sqlite: ""
[2023-07-01 11:42:10] [config] sqlite-drop: false
[2023-07-01 11:42:10] [config] sync-freq: 200u
[2023-07-01 11:42:10] [config] sync-sgd: true
[2023-07-01 11:42:10] [config] tempdir: /tmp
[2023-07-01 11:42:10] [config] tied-embeddings: false
[2023-07-01 11:42:10] [config] tied-embeddings-all: true
[2023-07-01 11:42:10] [config] tied-embeddings-src: false
[2023-07-01 11:42:10] [config] train-embedder-rank:
[2023-07-01 11:42:10] [config]   []
[2023-07-01 11:42:10] [config] train-sets:
[2023-07-01 11:42:10] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:42:10] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:42:10] [config] transformer-aan-activation: swish
[2023-07-01 11:42:10] [config] transformer-aan-depth: 2
[2023-07-01 11:42:10] [config] transformer-aan-nogate: false
[2023-07-01 11:42:10] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:42:10] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:42:10] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:42:10] [config] transformer-depth-scaling: false
[2023-07-01 11:42:10] [config] transformer-dim-aan: 2048
[2023-07-01 11:42:10] [config] transformer-dim-ffn: 2048
[2023-07-01 11:42:10] [config] transformer-dropout: 0.1
[2023-07-01 11:42:10] [config] transformer-dropout-attention: 0
[2023-07-01 11:42:10] [config] transformer-dropout-ffn: 0
[2023-07-01 11:42:10] [config] transformer-ffn-activation: swish
[2023-07-01 11:42:10] [config] transformer-ffn-depth: 2
[2023-07-01 11:42:10] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:42:10] [config] transformer-heads: 8
[2023-07-01 11:42:10] [config] transformer-no-projection: false
[2023-07-01 11:42:10] [config] transformer-pool: false
[2023-07-01 11:42:10] [config] transformer-postprocess: dan
[2023-07-01 11:42:10] [config] transformer-postprocess-emb: d
[2023-07-01 11:42:10] [config] transformer-postprocess-top: ""
[2023-07-01 11:42:10] [config] transformer-preprocess: ""
[2023-07-01 11:42:10] [config] transformer-tied-layers:
[2023-07-01 11:42:10] [config]   []
[2023-07-01 11:42:10] [config] transformer-train-position-embeddings: false
[2023-07-01 11:42:10] [config] tsv: false
[2023-07-01 11:42:10] [config] tsv-fields: 0
[2023-07-01 11:42:10] [config] type: transformer
[2023-07-01 11:42:10] [config] ulr: false
[2023-07-01 11:42:10] [config] ulr-dim-emb: 0
[2023-07-01 11:42:10] [config] ulr-dropout: 0
[2023-07-01 11:42:10] [config] ulr-keys-vectors: ""
[2023-07-01 11:42:10] [config] ulr-query-vectors: ""
[2023-07-01 11:42:10] [config] ulr-softmax-temperature: 1
[2023-07-01 11:42:10] [config] ulr-trainable-transformation: false
[2023-07-01 11:42:10] [config] unlikelihood-loss: false
[2023-07-01 11:42:10] [config] valid-freq: 50000000
[2023-07-01 11:42:10] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:42:10] [config] valid-max-length: 1000
[2023-07-01 11:42:10] [config] valid-metrics:
[2023-07-01 11:42:10] [config]   - cross-entropy
[2023-07-01 11:42:10] [config]   - translation
[2023-07-01 11:42:10] [config] valid-mini-batch: 64
[2023-07-01 11:42:10] [config] valid-reset-stalled: false
[2023-07-01 11:42:10] [config] valid-script-args:
[2023-07-01 11:42:10] [config]   []
[2023-07-01 11:42:10] [config] valid-script-path: ""
[2023-07-01 11:42:10] [config] valid-sets:
[2023-07-01 11:42:10] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:42:10] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:42:10] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:42:10] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:42:10] [config] vocabs:
[2023-07-01 11:42:10] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:42:10] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:42:10] [config] word-penalty: 0
[2023-07-01 11:42:10] [config] word-scores: false
[2023-07-01 11:42:10] [config] workspace: 2048
[2023-07-01 11:42:10] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:42:10] Using synchronous SGD
[2023-07-01 11:42:10] Synced seed 1234
[2023-07-01 11:42:10] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:42:10] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:42:10] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:42:10] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:42:10] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:42:10] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:42:11] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:42:11] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:42:11] [comm] Using global sharding
[2023-07-01 11:42:11] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:42:11] [training] Using 1 GPUs
[2023-07-01 11:42:11] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:42:11] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:42:11] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:42:11] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:42:19] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:42:19] [valid] No post-processing script given for validating translator
[2023-07-01 11:42:19] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:42:19] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:42:19] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:42:19] [comm] Using global sharding
[2023-07-01 11:42:19] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:42:19] [training] Using 1 GPUs
[2023-07-01 11:42:19] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:42:19] Allocating memory for general optimizer shards
[2023-07-01 11:42:19] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:42:19] Loading Adam parameters
[2023-07-01 11:42:19] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:42:19] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:42:19] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:42:19] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:42:19] [data] Shuffling data
[2023-07-01 11:42:19] [data] Done reading 20,192 sentences
[2023-07-01 11:42:19] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:42:19] Training started
[2023-07-01 11:42:19] Training finished
[2023-07-01 11:42:23] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:42:23] [marian] Running on node20.datos.cluster.uy as process 20120 with command line:
[2023-07-01 11:42:23] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 148 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:42:23] [config] after: 0e
[2023-07-01 11:42:23] [config] after-batches: 0
[2023-07-01 11:42:23] [config] after-epochs: 148
[2023-07-01 11:42:23] [config] all-caps-every: 0
[2023-07-01 11:42:23] [config] allow-unk: false
[2023-07-01 11:42:23] [config] authors: false
[2023-07-01 11:42:23] [config] beam-size: 12
[2023-07-01 11:42:23] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:42:23] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:42:23] [config] bert-masking-fraction: 0.15
[2023-07-01 11:42:23] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:42:23] [config] bert-train-type-embeddings: true
[2023-07-01 11:42:23] [config] bert-type-vocab-size: 2
[2023-07-01 11:42:23] [config] build-info: ""
[2023-07-01 11:42:23] [config] check-gradient-nan: false
[2023-07-01 11:42:23] [config] check-nan: false
[2023-07-01 11:42:23] [config] cite: false
[2023-07-01 11:42:23] [config] clip-norm: 5
[2023-07-01 11:42:23] [config] cost-scaling:
[2023-07-01 11:42:23] [config]   []
[2023-07-01 11:42:23] [config] cost-type: ce-sum
[2023-07-01 11:42:23] [config] cpu-threads: 0
[2023-07-01 11:42:23] [config] data-threads: 8
[2023-07-01 11:42:23] [config] data-weighting: ""
[2023-07-01 11:42:23] [config] data-weighting-type: sentence
[2023-07-01 11:42:23] [config] dec-cell: gru
[2023-07-01 11:42:23] [config] dec-cell-base-depth: 2
[2023-07-01 11:42:23] [config] dec-cell-high-depth: 1
[2023-07-01 11:42:23] [config] dec-depth: 2
[2023-07-01 11:42:23] [config] devices:
[2023-07-01 11:42:23] [config]   - 0
[2023-07-01 11:42:23] [config] dim-emb: 512
[2023-07-01 11:42:23] [config] dim-rnn: 1024
[2023-07-01 11:42:23] [config] dim-vocabs:
[2023-07-01 11:42:23] [config]   - 16384
[2023-07-01 11:42:23] [config]   - 16384
[2023-07-01 11:42:23] [config] disp-first: 0
[2023-07-01 11:42:23] [config] disp-freq: 1000u
[2023-07-01 11:42:23] [config] disp-label-counts: true
[2023-07-01 11:42:23] [config] dropout-rnn: 0
[2023-07-01 11:42:23] [config] dropout-src: 0
[2023-07-01 11:42:23] [config] dropout-trg: 0
[2023-07-01 11:42:23] [config] dump-config: ""
[2023-07-01 11:42:23] [config] dynamic-gradient-scaling:
[2023-07-01 11:42:23] [config]   []
[2023-07-01 11:42:23] [config] early-stopping: 10
[2023-07-01 11:42:23] [config] early-stopping-on: first
[2023-07-01 11:42:23] [config] embedding-fix-src: false
[2023-07-01 11:42:23] [config] embedding-fix-trg: false
[2023-07-01 11:42:23] [config] embedding-normalization: false
[2023-07-01 11:42:23] [config] embedding-vectors:
[2023-07-01 11:42:23] [config]   []
[2023-07-01 11:42:23] [config] enc-cell: gru
[2023-07-01 11:42:23] [config] enc-cell-depth: 1
[2023-07-01 11:42:23] [config] enc-depth: 2
[2023-07-01 11:42:23] [config] enc-type: bidirectional
[2023-07-01 11:42:23] [config] english-title-case-every: 0
[2023-07-01 11:42:23] [config] exponential-smoothing: 0.0001
[2023-07-01 11:42:23] [config] factor-weight: 1
[2023-07-01 11:42:23] [config] factors-combine: sum
[2023-07-01 11:42:23] [config] factors-dim-emb: 0
[2023-07-01 11:42:23] [config] gradient-checkpointing: false
[2023-07-01 11:42:23] [config] gradient-norm-average-window: 100
[2023-07-01 11:42:23] [config] guided-alignment: none
[2023-07-01 11:42:23] [config] guided-alignment-cost: mse
[2023-07-01 11:42:23] [config] guided-alignment-weight: 0.1
[2023-07-01 11:42:23] [config] ignore-model-config: false
[2023-07-01 11:42:23] [config] input-types:
[2023-07-01 11:42:23] [config]   []
[2023-07-01 11:42:23] [config] interpolate-env-vars: false
[2023-07-01 11:42:23] [config] keep-best: false
[2023-07-01 11:42:23] [config] label-smoothing: 0.1
[2023-07-01 11:42:23] [config] layer-normalization: false
[2023-07-01 11:42:23] [config] learn-rate: 0.0003
[2023-07-01 11:42:23] [config] lemma-dependency: ""
[2023-07-01 11:42:23] [config] lemma-dim-emb: 0
[2023-07-01 11:42:23] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:42:23] [config] log-level: info
[2023-07-01 11:42:23] [config] log-time-zone: ""
[2023-07-01 11:42:23] [config] logical-epoch:
[2023-07-01 11:42:23] [config]   - 1e
[2023-07-01 11:42:23] [config]   - 0
[2023-07-01 11:42:23] [config] lr-decay: 0
[2023-07-01 11:42:23] [config] lr-decay-freq: 50000
[2023-07-01 11:42:23] [config] lr-decay-inv-sqrt:
[2023-07-01 11:42:23] [config]   - 16000
[2023-07-01 11:42:23] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:42:23] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:42:23] [config] lr-decay-start:
[2023-07-01 11:42:23] [config]   - 10
[2023-07-01 11:42:23] [config]   - 1
[2023-07-01 11:42:23] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:42:23] [config] lr-report: true
[2023-07-01 11:42:23] [config] lr-warmup: 16000
[2023-07-01 11:42:23] [config] lr-warmup-at-reload: false
[2023-07-01 11:42:23] [config] lr-warmup-cycle: false
[2023-07-01 11:42:23] [config] lr-warmup-start-rate: 0
[2023-07-01 11:42:23] [config] max-length: 100
[2023-07-01 11:42:23] [config] max-length-crop: false
[2023-07-01 11:42:23] [config] max-length-factor: 3
[2023-07-01 11:42:23] [config] maxi-batch: 100
[2023-07-01 11:42:23] [config] maxi-batch-sort: trg
[2023-07-01 11:42:23] [config] mini-batch: 1000
[2023-07-01 11:42:23] [config] mini-batch-fit: true
[2023-07-01 11:42:23] [config] mini-batch-fit-step: 10
[2023-07-01 11:42:23] [config] mini-batch-round-up: true
[2023-07-01 11:42:23] [config] mini-batch-track-lr: false
[2023-07-01 11:42:23] [config] mini-batch-warmup: 0
[2023-07-01 11:42:23] [config] mini-batch-words: 0
[2023-07-01 11:42:23] [config] mini-batch-words-ref: 0
[2023-07-01 11:42:23] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:42:23] [config] multi-loss-type: sum
[2023-07-01 11:42:23] [config] n-best: false
[2023-07-01 11:42:23] [config] no-nccl: false
[2023-07-01 11:42:23] [config] no-reload: false
[2023-07-01 11:42:23] [config] no-restore-corpus: false
[2023-07-01 11:42:23] [config] normalize: 1
[2023-07-01 11:42:23] [config] normalize-gradient: false
[2023-07-01 11:42:23] [config] num-devices: 0
[2023-07-01 11:42:23] [config] optimizer: adam
[2023-07-01 11:42:23] [config] optimizer-delay: 1
[2023-07-01 11:42:23] [config] optimizer-params:
[2023-07-01 11:42:23] [config]   - 0.9
[2023-07-01 11:42:23] [config]   - 0.98
[2023-07-01 11:42:23] [config]   - 1e-09
[2023-07-01 11:42:23] [config] output-omit-bias: false
[2023-07-01 11:42:23] [config] overwrite: true
[2023-07-01 11:42:23] [config] precision:
[2023-07-01 11:42:23] [config]   - float32
[2023-07-01 11:42:23] [config]   - float32
[2023-07-01 11:42:23] [config] pretrained-model: ""
[2023-07-01 11:42:23] [config] quantize-biases: false
[2023-07-01 11:42:23] [config] quantize-bits: 0
[2023-07-01 11:42:23] [config] quantize-log-based: false
[2023-07-01 11:42:23] [config] quantize-optimization-steps: 0
[2023-07-01 11:42:23] [config] quiet: false
[2023-07-01 11:42:23] [config] quiet-translation: true
[2023-07-01 11:42:23] [config] relative-paths: false
[2023-07-01 11:42:23] [config] right-left: false
[2023-07-01 11:42:23] [config] save-freq: 10000u
[2023-07-01 11:42:23] [config] seed: 1234
[2023-07-01 11:42:23] [config] sentencepiece-alphas:
[2023-07-01 11:42:23] [config]   []
[2023-07-01 11:42:23] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:42:23] [config] sentencepiece-options: ""
[2023-07-01 11:42:23] [config] sharding: global
[2023-07-01 11:42:23] [config] shuffle: data
[2023-07-01 11:42:23] [config] shuffle-in-ram: false
[2023-07-01 11:42:23] [config] sigterm: save-and-exit
[2023-07-01 11:42:23] [config] skip: false
[2023-07-01 11:42:23] [config] sqlite: ""
[2023-07-01 11:42:23] [config] sqlite-drop: false
[2023-07-01 11:42:23] [config] sync-freq: 200u
[2023-07-01 11:42:23] [config] sync-sgd: true
[2023-07-01 11:42:23] [config] tempdir: /tmp
[2023-07-01 11:42:23] [config] tied-embeddings: false
[2023-07-01 11:42:23] [config] tied-embeddings-all: true
[2023-07-01 11:42:23] [config] tied-embeddings-src: false
[2023-07-01 11:42:23] [config] train-embedder-rank:
[2023-07-01 11:42:23] [config]   []
[2023-07-01 11:42:23] [config] train-sets:
[2023-07-01 11:42:23] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:42:23] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:42:23] [config] transformer-aan-activation: swish
[2023-07-01 11:42:23] [config] transformer-aan-depth: 2
[2023-07-01 11:42:23] [config] transformer-aan-nogate: false
[2023-07-01 11:42:23] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:42:23] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:42:23] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:42:23] [config] transformer-depth-scaling: false
[2023-07-01 11:42:23] [config] transformer-dim-aan: 2048
[2023-07-01 11:42:23] [config] transformer-dim-ffn: 2048
[2023-07-01 11:42:23] [config] transformer-dropout: 0.1
[2023-07-01 11:42:23] [config] transformer-dropout-attention: 0
[2023-07-01 11:42:23] [config] transformer-dropout-ffn: 0
[2023-07-01 11:42:23] [config] transformer-ffn-activation: swish
[2023-07-01 11:42:23] [config] transformer-ffn-depth: 2
[2023-07-01 11:42:23] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:42:23] [config] transformer-heads: 8
[2023-07-01 11:42:23] [config] transformer-no-projection: false
[2023-07-01 11:42:23] [config] transformer-pool: false
[2023-07-01 11:42:23] [config] transformer-postprocess: dan
[2023-07-01 11:42:23] [config] transformer-postprocess-emb: d
[2023-07-01 11:42:23] [config] transformer-postprocess-top: ""
[2023-07-01 11:42:23] [config] transformer-preprocess: ""
[2023-07-01 11:42:23] [config] transformer-tied-layers:
[2023-07-01 11:42:23] [config]   []
[2023-07-01 11:42:23] [config] transformer-train-position-embeddings: false
[2023-07-01 11:42:23] [config] tsv: false
[2023-07-01 11:42:23] [config] tsv-fields: 0
[2023-07-01 11:42:23] [config] type: transformer
[2023-07-01 11:42:23] [config] ulr: false
[2023-07-01 11:42:23] [config] ulr-dim-emb: 0
[2023-07-01 11:42:23] [config] ulr-dropout: 0
[2023-07-01 11:42:23] [config] ulr-keys-vectors: ""
[2023-07-01 11:42:23] [config] ulr-query-vectors: ""
[2023-07-01 11:42:23] [config] ulr-softmax-temperature: 1
[2023-07-01 11:42:23] [config] ulr-trainable-transformation: false
[2023-07-01 11:42:23] [config] unlikelihood-loss: false
[2023-07-01 11:42:23] [config] valid-freq: 50000000
[2023-07-01 11:42:23] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:42:23] [config] valid-max-length: 1000
[2023-07-01 11:42:23] [config] valid-metrics:
[2023-07-01 11:42:23] [config]   - cross-entropy
[2023-07-01 11:42:23] [config]   - translation
[2023-07-01 11:42:23] [config] valid-mini-batch: 64
[2023-07-01 11:42:23] [config] valid-reset-stalled: false
[2023-07-01 11:42:23] [config] valid-script-args:
[2023-07-01 11:42:23] [config]   []
[2023-07-01 11:42:23] [config] valid-script-path: ""
[2023-07-01 11:42:23] [config] valid-sets:
[2023-07-01 11:42:23] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:42:23] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:42:23] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:42:23] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:42:23] [config] vocabs:
[2023-07-01 11:42:23] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:42:23] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:42:23] [config] word-penalty: 0
[2023-07-01 11:42:23] [config] word-scores: false
[2023-07-01 11:42:23] [config] workspace: 2048
[2023-07-01 11:42:23] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:42:23] Using synchronous SGD
[2023-07-01 11:42:23] Synced seed 1234
[2023-07-01 11:42:23] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:42:23] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:42:23] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:42:23] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:42:23] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:42:23] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:42:24] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:42:24] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:42:24] [comm] Using global sharding
[2023-07-01 11:42:24] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:42:24] [training] Using 1 GPUs
[2023-07-01 11:42:24] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:42:24] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:42:25] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:42:25] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:42:32] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:42:32] [valid] No post-processing script given for validating translator
[2023-07-01 11:42:32] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:42:32] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:42:32] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:42:32] [comm] Using global sharding
[2023-07-01 11:42:32] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:42:32] [training] Using 1 GPUs
[2023-07-01 11:42:32] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:42:33] Allocating memory for general optimizer shards
[2023-07-01 11:42:33] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:42:33] Loading Adam parameters
[2023-07-01 11:42:33] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:42:33] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:42:33] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:42:33] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:42:33] [data] Shuffling data
[2023-07-01 11:42:33] [data] Done reading 20,192 sentences
[2023-07-01 11:42:33] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:42:33] Training started
[2023-07-01 11:42:33] Training finished
[2023-07-01 11:42:36] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:42:36] [marian] Running on node20.datos.cluster.uy as process 20178 with command line:
[2023-07-01 11:42:36] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 149 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:42:36] [config] after: 0e
[2023-07-01 11:42:36] [config] after-batches: 0
[2023-07-01 11:42:36] [config] after-epochs: 149
[2023-07-01 11:42:36] [config] all-caps-every: 0
[2023-07-01 11:42:36] [config] allow-unk: false
[2023-07-01 11:42:36] [config] authors: false
[2023-07-01 11:42:36] [config] beam-size: 12
[2023-07-01 11:42:36] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:42:36] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:42:36] [config] bert-masking-fraction: 0.15
[2023-07-01 11:42:36] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:42:36] [config] bert-train-type-embeddings: true
[2023-07-01 11:42:36] [config] bert-type-vocab-size: 2
[2023-07-01 11:42:36] [config] build-info: ""
[2023-07-01 11:42:36] [config] check-gradient-nan: false
[2023-07-01 11:42:36] [config] check-nan: false
[2023-07-01 11:42:36] [config] cite: false
[2023-07-01 11:42:36] [config] clip-norm: 5
[2023-07-01 11:42:36] [config] cost-scaling:
[2023-07-01 11:42:36] [config]   []
[2023-07-01 11:42:36] [config] cost-type: ce-sum
[2023-07-01 11:42:36] [config] cpu-threads: 0
[2023-07-01 11:42:36] [config] data-threads: 8
[2023-07-01 11:42:36] [config] data-weighting: ""
[2023-07-01 11:42:36] [config] data-weighting-type: sentence
[2023-07-01 11:42:36] [config] dec-cell: gru
[2023-07-01 11:42:36] [config] dec-cell-base-depth: 2
[2023-07-01 11:42:36] [config] dec-cell-high-depth: 1
[2023-07-01 11:42:36] [config] dec-depth: 2
[2023-07-01 11:42:36] [config] devices:
[2023-07-01 11:42:36] [config]   - 0
[2023-07-01 11:42:36] [config] dim-emb: 512
[2023-07-01 11:42:36] [config] dim-rnn: 1024
[2023-07-01 11:42:36] [config] dim-vocabs:
[2023-07-01 11:42:36] [config]   - 16384
[2023-07-01 11:42:36] [config]   - 16384
[2023-07-01 11:42:36] [config] disp-first: 0
[2023-07-01 11:42:36] [config] disp-freq: 1000u
[2023-07-01 11:42:36] [config] disp-label-counts: true
[2023-07-01 11:42:36] [config] dropout-rnn: 0
[2023-07-01 11:42:36] [config] dropout-src: 0
[2023-07-01 11:42:36] [config] dropout-trg: 0
[2023-07-01 11:42:36] [config] dump-config: ""
[2023-07-01 11:42:36] [config] dynamic-gradient-scaling:
[2023-07-01 11:42:36] [config]   []
[2023-07-01 11:42:36] [config] early-stopping: 10
[2023-07-01 11:42:36] [config] early-stopping-on: first
[2023-07-01 11:42:36] [config] embedding-fix-src: false
[2023-07-01 11:42:36] [config] embedding-fix-trg: false
[2023-07-01 11:42:36] [config] embedding-normalization: false
[2023-07-01 11:42:36] [config] embedding-vectors:
[2023-07-01 11:42:36] [config]   []
[2023-07-01 11:42:36] [config] enc-cell: gru
[2023-07-01 11:42:36] [config] enc-cell-depth: 1
[2023-07-01 11:42:36] [config] enc-depth: 2
[2023-07-01 11:42:36] [config] enc-type: bidirectional
[2023-07-01 11:42:36] [config] english-title-case-every: 0
[2023-07-01 11:42:36] [config] exponential-smoothing: 0.0001
[2023-07-01 11:42:36] [config] factor-weight: 1
[2023-07-01 11:42:36] [config] factors-combine: sum
[2023-07-01 11:42:36] [config] factors-dim-emb: 0
[2023-07-01 11:42:36] [config] gradient-checkpointing: false
[2023-07-01 11:42:36] [config] gradient-norm-average-window: 100
[2023-07-01 11:42:36] [config] guided-alignment: none
[2023-07-01 11:42:36] [config] guided-alignment-cost: mse
[2023-07-01 11:42:36] [config] guided-alignment-weight: 0.1
[2023-07-01 11:42:36] [config] ignore-model-config: false
[2023-07-01 11:42:36] [config] input-types:
[2023-07-01 11:42:36] [config]   []
[2023-07-01 11:42:36] [config] interpolate-env-vars: false
[2023-07-01 11:42:36] [config] keep-best: false
[2023-07-01 11:42:36] [config] label-smoothing: 0.1
[2023-07-01 11:42:36] [config] layer-normalization: false
[2023-07-01 11:42:36] [config] learn-rate: 0.0003
[2023-07-01 11:42:36] [config] lemma-dependency: ""
[2023-07-01 11:42:36] [config] lemma-dim-emb: 0
[2023-07-01 11:42:36] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:42:36] [config] log-level: info
[2023-07-01 11:42:36] [config] log-time-zone: ""
[2023-07-01 11:42:36] [config] logical-epoch:
[2023-07-01 11:42:36] [config]   - 1e
[2023-07-01 11:42:36] [config]   - 0
[2023-07-01 11:42:36] [config] lr-decay: 0
[2023-07-01 11:42:36] [config] lr-decay-freq: 50000
[2023-07-01 11:42:36] [config] lr-decay-inv-sqrt:
[2023-07-01 11:42:36] [config]   - 16000
[2023-07-01 11:42:36] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:42:36] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:42:36] [config] lr-decay-start:
[2023-07-01 11:42:36] [config]   - 10
[2023-07-01 11:42:36] [config]   - 1
[2023-07-01 11:42:36] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:42:36] [config] lr-report: true
[2023-07-01 11:42:36] [config] lr-warmup: 16000
[2023-07-01 11:42:36] [config] lr-warmup-at-reload: false
[2023-07-01 11:42:36] [config] lr-warmup-cycle: false
[2023-07-01 11:42:36] [config] lr-warmup-start-rate: 0
[2023-07-01 11:42:36] [config] max-length: 100
[2023-07-01 11:42:36] [config] max-length-crop: false
[2023-07-01 11:42:36] [config] max-length-factor: 3
[2023-07-01 11:42:36] [config] maxi-batch: 100
[2023-07-01 11:42:36] [config] maxi-batch-sort: trg
[2023-07-01 11:42:36] [config] mini-batch: 1000
[2023-07-01 11:42:36] [config] mini-batch-fit: true
[2023-07-01 11:42:36] [config] mini-batch-fit-step: 10
[2023-07-01 11:42:36] [config] mini-batch-round-up: true
[2023-07-01 11:42:36] [config] mini-batch-track-lr: false
[2023-07-01 11:42:36] [config] mini-batch-warmup: 0
[2023-07-01 11:42:36] [config] mini-batch-words: 0
[2023-07-01 11:42:36] [config] mini-batch-words-ref: 0
[2023-07-01 11:42:36] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:42:36] [config] multi-loss-type: sum
[2023-07-01 11:42:36] [config] n-best: false
[2023-07-01 11:42:36] [config] no-nccl: false
[2023-07-01 11:42:36] [config] no-reload: false
[2023-07-01 11:42:36] [config] no-restore-corpus: false
[2023-07-01 11:42:36] [config] normalize: 1
[2023-07-01 11:42:36] [config] normalize-gradient: false
[2023-07-01 11:42:36] [config] num-devices: 0
[2023-07-01 11:42:36] [config] optimizer: adam
[2023-07-01 11:42:36] [config] optimizer-delay: 1
[2023-07-01 11:42:36] [config] optimizer-params:
[2023-07-01 11:42:36] [config]   - 0.9
[2023-07-01 11:42:36] [config]   - 0.98
[2023-07-01 11:42:36] [config]   - 1e-09
[2023-07-01 11:42:36] [config] output-omit-bias: false
[2023-07-01 11:42:36] [config] overwrite: true
[2023-07-01 11:42:36] [config] precision:
[2023-07-01 11:42:36] [config]   - float32
[2023-07-01 11:42:36] [config]   - float32
[2023-07-01 11:42:36] [config] pretrained-model: ""
[2023-07-01 11:42:36] [config] quantize-biases: false
[2023-07-01 11:42:36] [config] quantize-bits: 0
[2023-07-01 11:42:36] [config] quantize-log-based: false
[2023-07-01 11:42:36] [config] quantize-optimization-steps: 0
[2023-07-01 11:42:36] [config] quiet: false
[2023-07-01 11:42:36] [config] quiet-translation: true
[2023-07-01 11:42:36] [config] relative-paths: false
[2023-07-01 11:42:36] [config] right-left: false
[2023-07-01 11:42:36] [config] save-freq: 10000u
[2023-07-01 11:42:36] [config] seed: 1234
[2023-07-01 11:42:36] [config] sentencepiece-alphas:
[2023-07-01 11:42:36] [config]   []
[2023-07-01 11:42:36] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:42:36] [config] sentencepiece-options: ""
[2023-07-01 11:42:36] [config] sharding: global
[2023-07-01 11:42:36] [config] shuffle: data
[2023-07-01 11:42:36] [config] shuffle-in-ram: false
[2023-07-01 11:42:36] [config] sigterm: save-and-exit
[2023-07-01 11:42:36] [config] skip: false
[2023-07-01 11:42:36] [config] sqlite: ""
[2023-07-01 11:42:36] [config] sqlite-drop: false
[2023-07-01 11:42:36] [config] sync-freq: 200u
[2023-07-01 11:42:36] [config] sync-sgd: true
[2023-07-01 11:42:36] [config] tempdir: /tmp
[2023-07-01 11:42:36] [config] tied-embeddings: false
[2023-07-01 11:42:36] [config] tied-embeddings-all: true
[2023-07-01 11:42:36] [config] tied-embeddings-src: false
[2023-07-01 11:42:36] [config] train-embedder-rank:
[2023-07-01 11:42:36] [config]   []
[2023-07-01 11:42:36] [config] train-sets:
[2023-07-01 11:42:36] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:42:36] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:42:36] [config] transformer-aan-activation: swish
[2023-07-01 11:42:36] [config] transformer-aan-depth: 2
[2023-07-01 11:42:36] [config] transformer-aan-nogate: false
[2023-07-01 11:42:36] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:42:36] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:42:36] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:42:36] [config] transformer-depth-scaling: false
[2023-07-01 11:42:36] [config] transformer-dim-aan: 2048
[2023-07-01 11:42:36] [config] transformer-dim-ffn: 2048
[2023-07-01 11:42:36] [config] transformer-dropout: 0.1
[2023-07-01 11:42:36] [config] transformer-dropout-attention: 0
[2023-07-01 11:42:36] [config] transformer-dropout-ffn: 0
[2023-07-01 11:42:36] [config] transformer-ffn-activation: swish
[2023-07-01 11:42:36] [config] transformer-ffn-depth: 2
[2023-07-01 11:42:36] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:42:36] [config] transformer-heads: 8
[2023-07-01 11:42:36] [config] transformer-no-projection: false
[2023-07-01 11:42:36] [config] transformer-pool: false
[2023-07-01 11:42:36] [config] transformer-postprocess: dan
[2023-07-01 11:42:36] [config] transformer-postprocess-emb: d
[2023-07-01 11:42:36] [config] transformer-postprocess-top: ""
[2023-07-01 11:42:36] [config] transformer-preprocess: ""
[2023-07-01 11:42:36] [config] transformer-tied-layers:
[2023-07-01 11:42:36] [config]   []
[2023-07-01 11:42:36] [config] transformer-train-position-embeddings: false
[2023-07-01 11:42:36] [config] tsv: false
[2023-07-01 11:42:36] [config] tsv-fields: 0
[2023-07-01 11:42:36] [config] type: transformer
[2023-07-01 11:42:36] [config] ulr: false
[2023-07-01 11:42:36] [config] ulr-dim-emb: 0
[2023-07-01 11:42:36] [config] ulr-dropout: 0
[2023-07-01 11:42:36] [config] ulr-keys-vectors: ""
[2023-07-01 11:42:36] [config] ulr-query-vectors: ""
[2023-07-01 11:42:36] [config] ulr-softmax-temperature: 1
[2023-07-01 11:42:36] [config] ulr-trainable-transformation: false
[2023-07-01 11:42:36] [config] unlikelihood-loss: false
[2023-07-01 11:42:36] [config] valid-freq: 50000000
[2023-07-01 11:42:36] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:42:36] [config] valid-max-length: 1000
[2023-07-01 11:42:36] [config] valid-metrics:
[2023-07-01 11:42:36] [config]   - cross-entropy
[2023-07-01 11:42:36] [config]   - translation
[2023-07-01 11:42:36] [config] valid-mini-batch: 64
[2023-07-01 11:42:36] [config] valid-reset-stalled: false
[2023-07-01 11:42:36] [config] valid-script-args:
[2023-07-01 11:42:36] [config]   []
[2023-07-01 11:42:36] [config] valid-script-path: ""
[2023-07-01 11:42:36] [config] valid-sets:
[2023-07-01 11:42:36] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:42:36] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:42:36] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:42:36] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:42:36] [config] vocabs:
[2023-07-01 11:42:36] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:42:36] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:42:36] [config] word-penalty: 0
[2023-07-01 11:42:36] [config] word-scores: false
[2023-07-01 11:42:36] [config] workspace: 2048
[2023-07-01 11:42:36] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:42:36] Using synchronous SGD
[2023-07-01 11:42:37] Synced seed 1234
[2023-07-01 11:42:37] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:42:37] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:42:37] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:42:37] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:42:37] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:42:37] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:42:38] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:42:38] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:42:38] [comm] Using global sharding
[2023-07-01 11:42:38] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:42:38] [training] Using 1 GPUs
[2023-07-01 11:42:38] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:42:38] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:42:38] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:42:38] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:42:46] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:42:46] [valid] No post-processing script given for validating translator
[2023-07-01 11:42:46] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:42:46] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:42:46] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:42:46] [comm] Using global sharding
[2023-07-01 11:42:46] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:42:46] [training] Using 1 GPUs
[2023-07-01 11:42:46] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:42:46] Allocating memory for general optimizer shards
[2023-07-01 11:42:46] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:42:46] Loading Adam parameters
[2023-07-01 11:42:46] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:42:47] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:42:47] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:42:47] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:42:47] [data] Shuffling data
[2023-07-01 11:42:47] [data] Done reading 20,192 sentences
[2023-07-01 11:42:47] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:42:47] Training started
[2023-07-01 11:42:47] Training finished
[2023-07-01 11:42:50] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:42:50] [marian] Running on node20.datos.cluster.uy as process 20236 with command line:
[2023-07-01 11:42:50] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 150 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:42:50] [config] after: 0e
[2023-07-01 11:42:50] [config] after-batches: 0
[2023-07-01 11:42:50] [config] after-epochs: 150
[2023-07-01 11:42:50] [config] all-caps-every: 0
[2023-07-01 11:42:50] [config] allow-unk: false
[2023-07-01 11:42:50] [config] authors: false
[2023-07-01 11:42:50] [config] beam-size: 12
[2023-07-01 11:42:50] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:42:50] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:42:50] [config] bert-masking-fraction: 0.15
[2023-07-01 11:42:50] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:42:50] [config] bert-train-type-embeddings: true
[2023-07-01 11:42:50] [config] bert-type-vocab-size: 2
[2023-07-01 11:42:50] [config] build-info: ""
[2023-07-01 11:42:50] [config] check-gradient-nan: false
[2023-07-01 11:42:50] [config] check-nan: false
[2023-07-01 11:42:50] [config] cite: false
[2023-07-01 11:42:50] [config] clip-norm: 5
[2023-07-01 11:42:50] [config] cost-scaling:
[2023-07-01 11:42:50] [config]   []
[2023-07-01 11:42:50] [config] cost-type: ce-sum
[2023-07-01 11:42:50] [config] cpu-threads: 0
[2023-07-01 11:42:50] [config] data-threads: 8
[2023-07-01 11:42:50] [config] data-weighting: ""
[2023-07-01 11:42:50] [config] data-weighting-type: sentence
[2023-07-01 11:42:50] [config] dec-cell: gru
[2023-07-01 11:42:50] [config] dec-cell-base-depth: 2
[2023-07-01 11:42:50] [config] dec-cell-high-depth: 1
[2023-07-01 11:42:50] [config] dec-depth: 2
[2023-07-01 11:42:50] [config] devices:
[2023-07-01 11:42:50] [config]   - 0
[2023-07-01 11:42:50] [config] dim-emb: 512
[2023-07-01 11:42:50] [config] dim-rnn: 1024
[2023-07-01 11:42:50] [config] dim-vocabs:
[2023-07-01 11:42:50] [config]   - 16384
[2023-07-01 11:42:50] [config]   - 16384
[2023-07-01 11:42:50] [config] disp-first: 0
[2023-07-01 11:42:50] [config] disp-freq: 1000u
[2023-07-01 11:42:50] [config] disp-label-counts: true
[2023-07-01 11:42:50] [config] dropout-rnn: 0
[2023-07-01 11:42:50] [config] dropout-src: 0
[2023-07-01 11:42:50] [config] dropout-trg: 0
[2023-07-01 11:42:50] [config] dump-config: ""
[2023-07-01 11:42:50] [config] dynamic-gradient-scaling:
[2023-07-01 11:42:50] [config]   []
[2023-07-01 11:42:50] [config] early-stopping: 10
[2023-07-01 11:42:50] [config] early-stopping-on: first
[2023-07-01 11:42:50] [config] embedding-fix-src: false
[2023-07-01 11:42:50] [config] embedding-fix-trg: false
[2023-07-01 11:42:50] [config] embedding-normalization: false
[2023-07-01 11:42:50] [config] embedding-vectors:
[2023-07-01 11:42:50] [config]   []
[2023-07-01 11:42:50] [config] enc-cell: gru
[2023-07-01 11:42:50] [config] enc-cell-depth: 1
[2023-07-01 11:42:50] [config] enc-depth: 2
[2023-07-01 11:42:50] [config] enc-type: bidirectional
[2023-07-01 11:42:50] [config] english-title-case-every: 0
[2023-07-01 11:42:50] [config] exponential-smoothing: 0.0001
[2023-07-01 11:42:50] [config] factor-weight: 1
[2023-07-01 11:42:50] [config] factors-combine: sum
[2023-07-01 11:42:50] [config] factors-dim-emb: 0
[2023-07-01 11:42:50] [config] gradient-checkpointing: false
[2023-07-01 11:42:50] [config] gradient-norm-average-window: 100
[2023-07-01 11:42:50] [config] guided-alignment: none
[2023-07-01 11:42:50] [config] guided-alignment-cost: mse
[2023-07-01 11:42:50] [config] guided-alignment-weight: 0.1
[2023-07-01 11:42:50] [config] ignore-model-config: false
[2023-07-01 11:42:50] [config] input-types:
[2023-07-01 11:42:50] [config]   []
[2023-07-01 11:42:50] [config] interpolate-env-vars: false
[2023-07-01 11:42:50] [config] keep-best: false
[2023-07-01 11:42:50] [config] label-smoothing: 0.1
[2023-07-01 11:42:50] [config] layer-normalization: false
[2023-07-01 11:42:50] [config] learn-rate: 0.0003
[2023-07-01 11:42:50] [config] lemma-dependency: ""
[2023-07-01 11:42:50] [config] lemma-dim-emb: 0
[2023-07-01 11:42:50] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:42:50] [config] log-level: info
[2023-07-01 11:42:50] [config] log-time-zone: ""
[2023-07-01 11:42:50] [config] logical-epoch:
[2023-07-01 11:42:50] [config]   - 1e
[2023-07-01 11:42:50] [config]   - 0
[2023-07-01 11:42:50] [config] lr-decay: 0
[2023-07-01 11:42:50] [config] lr-decay-freq: 50000
[2023-07-01 11:42:50] [config] lr-decay-inv-sqrt:
[2023-07-01 11:42:50] [config]   - 16000
[2023-07-01 11:42:50] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:42:50] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:42:50] [config] lr-decay-start:
[2023-07-01 11:42:50] [config]   - 10
[2023-07-01 11:42:50] [config]   - 1
[2023-07-01 11:42:50] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:42:50] [config] lr-report: true
[2023-07-01 11:42:50] [config] lr-warmup: 16000
[2023-07-01 11:42:50] [config] lr-warmup-at-reload: false
[2023-07-01 11:42:50] [config] lr-warmup-cycle: false
[2023-07-01 11:42:50] [config] lr-warmup-start-rate: 0
[2023-07-01 11:42:50] [config] max-length: 100
[2023-07-01 11:42:50] [config] max-length-crop: false
[2023-07-01 11:42:50] [config] max-length-factor: 3
[2023-07-01 11:42:50] [config] maxi-batch: 100
[2023-07-01 11:42:50] [config] maxi-batch-sort: trg
[2023-07-01 11:42:50] [config] mini-batch: 1000
[2023-07-01 11:42:50] [config] mini-batch-fit: true
[2023-07-01 11:42:50] [config] mini-batch-fit-step: 10
[2023-07-01 11:42:50] [config] mini-batch-round-up: true
[2023-07-01 11:42:50] [config] mini-batch-track-lr: false
[2023-07-01 11:42:50] [config] mini-batch-warmup: 0
[2023-07-01 11:42:50] [config] mini-batch-words: 0
[2023-07-01 11:42:50] [config] mini-batch-words-ref: 0
[2023-07-01 11:42:50] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:42:50] [config] multi-loss-type: sum
[2023-07-01 11:42:50] [config] n-best: false
[2023-07-01 11:42:50] [config] no-nccl: false
[2023-07-01 11:42:50] [config] no-reload: false
[2023-07-01 11:42:50] [config] no-restore-corpus: false
[2023-07-01 11:42:50] [config] normalize: 1
[2023-07-01 11:42:50] [config] normalize-gradient: false
[2023-07-01 11:42:50] [config] num-devices: 0
[2023-07-01 11:42:50] [config] optimizer: adam
[2023-07-01 11:42:50] [config] optimizer-delay: 1
[2023-07-01 11:42:50] [config] optimizer-params:
[2023-07-01 11:42:50] [config]   - 0.9
[2023-07-01 11:42:50] [config]   - 0.98
[2023-07-01 11:42:50] [config]   - 1e-09
[2023-07-01 11:42:50] [config] output-omit-bias: false
[2023-07-01 11:42:50] [config] overwrite: true
[2023-07-01 11:42:50] [config] precision:
[2023-07-01 11:42:50] [config]   - float32
[2023-07-01 11:42:50] [config]   - float32
[2023-07-01 11:42:50] [config] pretrained-model: ""
[2023-07-01 11:42:50] [config] quantize-biases: false
[2023-07-01 11:42:50] [config] quantize-bits: 0
[2023-07-01 11:42:50] [config] quantize-log-based: false
[2023-07-01 11:42:50] [config] quantize-optimization-steps: 0
[2023-07-01 11:42:50] [config] quiet: false
[2023-07-01 11:42:50] [config] quiet-translation: true
[2023-07-01 11:42:50] [config] relative-paths: false
[2023-07-01 11:42:50] [config] right-left: false
[2023-07-01 11:42:50] [config] save-freq: 10000u
[2023-07-01 11:42:50] [config] seed: 1234
[2023-07-01 11:42:50] [config] sentencepiece-alphas:
[2023-07-01 11:42:50] [config]   []
[2023-07-01 11:42:50] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:42:50] [config] sentencepiece-options: ""
[2023-07-01 11:42:50] [config] sharding: global
[2023-07-01 11:42:50] [config] shuffle: data
[2023-07-01 11:42:50] [config] shuffle-in-ram: false
[2023-07-01 11:42:50] [config] sigterm: save-and-exit
[2023-07-01 11:42:50] [config] skip: false
[2023-07-01 11:42:50] [config] sqlite: ""
[2023-07-01 11:42:50] [config] sqlite-drop: false
[2023-07-01 11:42:50] [config] sync-freq: 200u
[2023-07-01 11:42:50] [config] sync-sgd: true
[2023-07-01 11:42:50] [config] tempdir: /tmp
[2023-07-01 11:42:50] [config] tied-embeddings: false
[2023-07-01 11:42:50] [config] tied-embeddings-all: true
[2023-07-01 11:42:50] [config] tied-embeddings-src: false
[2023-07-01 11:42:50] [config] train-embedder-rank:
[2023-07-01 11:42:50] [config]   []
[2023-07-01 11:42:50] [config] train-sets:
[2023-07-01 11:42:50] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:42:50] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:42:50] [config] transformer-aan-activation: swish
[2023-07-01 11:42:50] [config] transformer-aan-depth: 2
[2023-07-01 11:42:50] [config] transformer-aan-nogate: false
[2023-07-01 11:42:50] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:42:50] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:42:50] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:42:50] [config] transformer-depth-scaling: false
[2023-07-01 11:42:50] [config] transformer-dim-aan: 2048
[2023-07-01 11:42:50] [config] transformer-dim-ffn: 2048
[2023-07-01 11:42:50] [config] transformer-dropout: 0.1
[2023-07-01 11:42:50] [config] transformer-dropout-attention: 0
[2023-07-01 11:42:50] [config] transformer-dropout-ffn: 0
[2023-07-01 11:42:50] [config] transformer-ffn-activation: swish
[2023-07-01 11:42:50] [config] transformer-ffn-depth: 2
[2023-07-01 11:42:50] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:42:50] [config] transformer-heads: 8
[2023-07-01 11:42:50] [config] transformer-no-projection: false
[2023-07-01 11:42:50] [config] transformer-pool: false
[2023-07-01 11:42:50] [config] transformer-postprocess: dan
[2023-07-01 11:42:50] [config] transformer-postprocess-emb: d
[2023-07-01 11:42:50] [config] transformer-postprocess-top: ""
[2023-07-01 11:42:50] [config] transformer-preprocess: ""
[2023-07-01 11:42:50] [config] transformer-tied-layers:
[2023-07-01 11:42:50] [config]   []
[2023-07-01 11:42:50] [config] transformer-train-position-embeddings: false
[2023-07-01 11:42:50] [config] tsv: false
[2023-07-01 11:42:50] [config] tsv-fields: 0
[2023-07-01 11:42:50] [config] type: transformer
[2023-07-01 11:42:50] [config] ulr: false
[2023-07-01 11:42:50] [config] ulr-dim-emb: 0
[2023-07-01 11:42:50] [config] ulr-dropout: 0
[2023-07-01 11:42:50] [config] ulr-keys-vectors: ""
[2023-07-01 11:42:50] [config] ulr-query-vectors: ""
[2023-07-01 11:42:50] [config] ulr-softmax-temperature: 1
[2023-07-01 11:42:50] [config] ulr-trainable-transformation: false
[2023-07-01 11:42:50] [config] unlikelihood-loss: false
[2023-07-01 11:42:50] [config] valid-freq: 50000000
[2023-07-01 11:42:50] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:42:50] [config] valid-max-length: 1000
[2023-07-01 11:42:50] [config] valid-metrics:
[2023-07-01 11:42:50] [config]   - cross-entropy
[2023-07-01 11:42:50] [config]   - translation
[2023-07-01 11:42:50] [config] valid-mini-batch: 64
[2023-07-01 11:42:50] [config] valid-reset-stalled: false
[2023-07-01 11:42:50] [config] valid-script-args:
[2023-07-01 11:42:50] [config]   []
[2023-07-01 11:42:50] [config] valid-script-path: ""
[2023-07-01 11:42:50] [config] valid-sets:
[2023-07-01 11:42:50] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:42:50] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:42:50] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:42:50] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:42:50] [config] vocabs:
[2023-07-01 11:42:50] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:42:50] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:42:50] [config] word-penalty: 0
[2023-07-01 11:42:50] [config] word-scores: false
[2023-07-01 11:42:50] [config] workspace: 2048
[2023-07-01 11:42:50] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:42:50] Using synchronous SGD
[2023-07-01 11:42:50] Synced seed 1234
[2023-07-01 11:42:50] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:42:51] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:42:51] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:42:51] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:42:51] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:42:51] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:42:51] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:42:51] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:42:51] [comm] Using global sharding
[2023-07-01 11:42:51] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:42:51] [training] Using 1 GPUs
[2023-07-01 11:42:51] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:42:51] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:42:52] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:42:52] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:42:59] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:42:59] [valid] No post-processing script given for validating translator
[2023-07-01 11:42:59] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:42:59] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:42:59] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:42:59] [comm] Using global sharding
[2023-07-01 11:42:59] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:42:59] [training] Using 1 GPUs
[2023-07-01 11:42:59] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:43:00] Allocating memory for general optimizer shards
[2023-07-01 11:43:00] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:43:00] Loading Adam parameters
[2023-07-01 11:43:00] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:43:00] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:43:00] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:43:00] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:43:00] [data] Shuffling data
[2023-07-01 11:43:00] [data] Done reading 20,192 sentences
[2023-07-01 11:43:00] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:43:00] Training started
[2023-07-01 11:43:00] Training finished
[2023-07-01 11:43:04] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:43:04] [marian] Running on node20.datos.cluster.uy as process 20295 with command line:
[2023-07-01 11:43:04] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 151 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:43:04] [config] after: 0e
[2023-07-01 11:43:04] [config] after-batches: 0
[2023-07-01 11:43:04] [config] after-epochs: 151
[2023-07-01 11:43:04] [config] all-caps-every: 0
[2023-07-01 11:43:04] [config] allow-unk: false
[2023-07-01 11:43:04] [config] authors: false
[2023-07-01 11:43:04] [config] beam-size: 12
[2023-07-01 11:43:04] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:43:04] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:43:04] [config] bert-masking-fraction: 0.15
[2023-07-01 11:43:04] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:43:04] [config] bert-train-type-embeddings: true
[2023-07-01 11:43:04] [config] bert-type-vocab-size: 2
[2023-07-01 11:43:04] [config] build-info: ""
[2023-07-01 11:43:04] [config] check-gradient-nan: false
[2023-07-01 11:43:04] [config] check-nan: false
[2023-07-01 11:43:04] [config] cite: false
[2023-07-01 11:43:04] [config] clip-norm: 5
[2023-07-01 11:43:04] [config] cost-scaling:
[2023-07-01 11:43:04] [config]   []
[2023-07-01 11:43:04] [config] cost-type: ce-sum
[2023-07-01 11:43:04] [config] cpu-threads: 0
[2023-07-01 11:43:04] [config] data-threads: 8
[2023-07-01 11:43:04] [config] data-weighting: ""
[2023-07-01 11:43:04] [config] data-weighting-type: sentence
[2023-07-01 11:43:04] [config] dec-cell: gru
[2023-07-01 11:43:04] [config] dec-cell-base-depth: 2
[2023-07-01 11:43:04] [config] dec-cell-high-depth: 1
[2023-07-01 11:43:04] [config] dec-depth: 2
[2023-07-01 11:43:04] [config] devices:
[2023-07-01 11:43:04] [config]   - 0
[2023-07-01 11:43:04] [config] dim-emb: 512
[2023-07-01 11:43:04] [config] dim-rnn: 1024
[2023-07-01 11:43:04] [config] dim-vocabs:
[2023-07-01 11:43:04] [config]   - 16384
[2023-07-01 11:43:04] [config]   - 16384
[2023-07-01 11:43:04] [config] disp-first: 0
[2023-07-01 11:43:04] [config] disp-freq: 1000u
[2023-07-01 11:43:04] [config] disp-label-counts: true
[2023-07-01 11:43:04] [config] dropout-rnn: 0
[2023-07-01 11:43:04] [config] dropout-src: 0
[2023-07-01 11:43:04] [config] dropout-trg: 0
[2023-07-01 11:43:04] [config] dump-config: ""
[2023-07-01 11:43:04] [config] dynamic-gradient-scaling:
[2023-07-01 11:43:04] [config]   []
[2023-07-01 11:43:04] [config] early-stopping: 10
[2023-07-01 11:43:04] [config] early-stopping-on: first
[2023-07-01 11:43:04] [config] embedding-fix-src: false
[2023-07-01 11:43:04] [config] embedding-fix-trg: false
[2023-07-01 11:43:04] [config] embedding-normalization: false
[2023-07-01 11:43:04] [config] embedding-vectors:
[2023-07-01 11:43:04] [config]   []
[2023-07-01 11:43:04] [config] enc-cell: gru
[2023-07-01 11:43:04] [config] enc-cell-depth: 1
[2023-07-01 11:43:04] [config] enc-depth: 2
[2023-07-01 11:43:04] [config] enc-type: bidirectional
[2023-07-01 11:43:04] [config] english-title-case-every: 0
[2023-07-01 11:43:04] [config] exponential-smoothing: 0.0001
[2023-07-01 11:43:04] [config] factor-weight: 1
[2023-07-01 11:43:04] [config] factors-combine: sum
[2023-07-01 11:43:04] [config] factors-dim-emb: 0
[2023-07-01 11:43:04] [config] gradient-checkpointing: false
[2023-07-01 11:43:04] [config] gradient-norm-average-window: 100
[2023-07-01 11:43:04] [config] guided-alignment: none
[2023-07-01 11:43:04] [config] guided-alignment-cost: mse
[2023-07-01 11:43:04] [config] guided-alignment-weight: 0.1
[2023-07-01 11:43:04] [config] ignore-model-config: false
[2023-07-01 11:43:04] [config] input-types:
[2023-07-01 11:43:04] [config]   []
[2023-07-01 11:43:04] [config] interpolate-env-vars: false
[2023-07-01 11:43:04] [config] keep-best: false
[2023-07-01 11:43:04] [config] label-smoothing: 0.1
[2023-07-01 11:43:04] [config] layer-normalization: false
[2023-07-01 11:43:04] [config] learn-rate: 0.0003
[2023-07-01 11:43:04] [config] lemma-dependency: ""
[2023-07-01 11:43:04] [config] lemma-dim-emb: 0
[2023-07-01 11:43:04] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:43:04] [config] log-level: info
[2023-07-01 11:43:04] [config] log-time-zone: ""
[2023-07-01 11:43:04] [config] logical-epoch:
[2023-07-01 11:43:04] [config]   - 1e
[2023-07-01 11:43:04] [config]   - 0
[2023-07-01 11:43:04] [config] lr-decay: 0
[2023-07-01 11:43:04] [config] lr-decay-freq: 50000
[2023-07-01 11:43:04] [config] lr-decay-inv-sqrt:
[2023-07-01 11:43:04] [config]   - 16000
[2023-07-01 11:43:04] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:43:04] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:43:04] [config] lr-decay-start:
[2023-07-01 11:43:04] [config]   - 10
[2023-07-01 11:43:04] [config]   - 1
[2023-07-01 11:43:04] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:43:04] [config] lr-report: true
[2023-07-01 11:43:04] [config] lr-warmup: 16000
[2023-07-01 11:43:04] [config] lr-warmup-at-reload: false
[2023-07-01 11:43:04] [config] lr-warmup-cycle: false
[2023-07-01 11:43:04] [config] lr-warmup-start-rate: 0
[2023-07-01 11:43:04] [config] max-length: 100
[2023-07-01 11:43:04] [config] max-length-crop: false
[2023-07-01 11:43:04] [config] max-length-factor: 3
[2023-07-01 11:43:04] [config] maxi-batch: 100
[2023-07-01 11:43:04] [config] maxi-batch-sort: trg
[2023-07-01 11:43:04] [config] mini-batch: 1000
[2023-07-01 11:43:04] [config] mini-batch-fit: true
[2023-07-01 11:43:04] [config] mini-batch-fit-step: 10
[2023-07-01 11:43:04] [config] mini-batch-round-up: true
[2023-07-01 11:43:04] [config] mini-batch-track-lr: false
[2023-07-01 11:43:04] [config] mini-batch-warmup: 0
[2023-07-01 11:43:04] [config] mini-batch-words: 0
[2023-07-01 11:43:04] [config] mini-batch-words-ref: 0
[2023-07-01 11:43:04] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:43:04] [config] multi-loss-type: sum
[2023-07-01 11:43:04] [config] n-best: false
[2023-07-01 11:43:04] [config] no-nccl: false
[2023-07-01 11:43:04] [config] no-reload: false
[2023-07-01 11:43:04] [config] no-restore-corpus: false
[2023-07-01 11:43:04] [config] normalize: 1
[2023-07-01 11:43:04] [config] normalize-gradient: false
[2023-07-01 11:43:04] [config] num-devices: 0
[2023-07-01 11:43:04] [config] optimizer: adam
[2023-07-01 11:43:04] [config] optimizer-delay: 1
[2023-07-01 11:43:04] [config] optimizer-params:
[2023-07-01 11:43:04] [config]   - 0.9
[2023-07-01 11:43:04] [config]   - 0.98
[2023-07-01 11:43:04] [config]   - 1e-09
[2023-07-01 11:43:04] [config] output-omit-bias: false
[2023-07-01 11:43:04] [config] overwrite: true
[2023-07-01 11:43:04] [config] precision:
[2023-07-01 11:43:04] [config]   - float32
[2023-07-01 11:43:04] [config]   - float32
[2023-07-01 11:43:04] [config] pretrained-model: ""
[2023-07-01 11:43:04] [config] quantize-biases: false
[2023-07-01 11:43:04] [config] quantize-bits: 0
[2023-07-01 11:43:04] [config] quantize-log-based: false
[2023-07-01 11:43:04] [config] quantize-optimization-steps: 0
[2023-07-01 11:43:04] [config] quiet: false
[2023-07-01 11:43:04] [config] quiet-translation: true
[2023-07-01 11:43:04] [config] relative-paths: false
[2023-07-01 11:43:04] [config] right-left: false
[2023-07-01 11:43:04] [config] save-freq: 10000u
[2023-07-01 11:43:04] [config] seed: 1234
[2023-07-01 11:43:04] [config] sentencepiece-alphas:
[2023-07-01 11:43:04] [config]   []
[2023-07-01 11:43:04] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:43:04] [config] sentencepiece-options: ""
[2023-07-01 11:43:04] [config] sharding: global
[2023-07-01 11:43:04] [config] shuffle: data
[2023-07-01 11:43:04] [config] shuffle-in-ram: false
[2023-07-01 11:43:04] [config] sigterm: save-and-exit
[2023-07-01 11:43:04] [config] skip: false
[2023-07-01 11:43:04] [config] sqlite: ""
[2023-07-01 11:43:04] [config] sqlite-drop: false
[2023-07-01 11:43:04] [config] sync-freq: 200u
[2023-07-01 11:43:04] [config] sync-sgd: true
[2023-07-01 11:43:04] [config] tempdir: /tmp
[2023-07-01 11:43:04] [config] tied-embeddings: false
[2023-07-01 11:43:04] [config] tied-embeddings-all: true
[2023-07-01 11:43:04] [config] tied-embeddings-src: false
[2023-07-01 11:43:04] [config] train-embedder-rank:
[2023-07-01 11:43:04] [config]   []
[2023-07-01 11:43:04] [config] train-sets:
[2023-07-01 11:43:04] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:43:04] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:43:04] [config] transformer-aan-activation: swish
[2023-07-01 11:43:04] [config] transformer-aan-depth: 2
[2023-07-01 11:43:04] [config] transformer-aan-nogate: false
[2023-07-01 11:43:04] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:43:04] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:43:04] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:43:04] [config] transformer-depth-scaling: false
[2023-07-01 11:43:04] [config] transformer-dim-aan: 2048
[2023-07-01 11:43:04] [config] transformer-dim-ffn: 2048
[2023-07-01 11:43:04] [config] transformer-dropout: 0.1
[2023-07-01 11:43:04] [config] transformer-dropout-attention: 0
[2023-07-01 11:43:04] [config] transformer-dropout-ffn: 0
[2023-07-01 11:43:04] [config] transformer-ffn-activation: swish
[2023-07-01 11:43:04] [config] transformer-ffn-depth: 2
[2023-07-01 11:43:04] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:43:04] [config] transformer-heads: 8
[2023-07-01 11:43:04] [config] transformer-no-projection: false
[2023-07-01 11:43:04] [config] transformer-pool: false
[2023-07-01 11:43:04] [config] transformer-postprocess: dan
[2023-07-01 11:43:04] [config] transformer-postprocess-emb: d
[2023-07-01 11:43:04] [config] transformer-postprocess-top: ""
[2023-07-01 11:43:04] [config] transformer-preprocess: ""
[2023-07-01 11:43:04] [config] transformer-tied-layers:
[2023-07-01 11:43:04] [config]   []
[2023-07-01 11:43:04] [config] transformer-train-position-embeddings: false
[2023-07-01 11:43:04] [config] tsv: false
[2023-07-01 11:43:04] [config] tsv-fields: 0
[2023-07-01 11:43:04] [config] type: transformer
[2023-07-01 11:43:04] [config] ulr: false
[2023-07-01 11:43:04] [config] ulr-dim-emb: 0
[2023-07-01 11:43:04] [config] ulr-dropout: 0
[2023-07-01 11:43:04] [config] ulr-keys-vectors: ""
[2023-07-01 11:43:04] [config] ulr-query-vectors: ""
[2023-07-01 11:43:04] [config] ulr-softmax-temperature: 1
[2023-07-01 11:43:04] [config] ulr-trainable-transformation: false
[2023-07-01 11:43:04] [config] unlikelihood-loss: false
[2023-07-01 11:43:04] [config] valid-freq: 50000000
[2023-07-01 11:43:04] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:43:04] [config] valid-max-length: 1000
[2023-07-01 11:43:04] [config] valid-metrics:
[2023-07-01 11:43:04] [config]   - cross-entropy
[2023-07-01 11:43:04] [config]   - translation
[2023-07-01 11:43:04] [config] valid-mini-batch: 64
[2023-07-01 11:43:04] [config] valid-reset-stalled: false
[2023-07-01 11:43:04] [config] valid-script-args:
[2023-07-01 11:43:04] [config]   []
[2023-07-01 11:43:04] [config] valid-script-path: ""
[2023-07-01 11:43:04] [config] valid-sets:
[2023-07-01 11:43:04] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:43:04] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:43:04] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:43:04] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:43:04] [config] vocabs:
[2023-07-01 11:43:04] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:43:04] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:43:04] [config] word-penalty: 0
[2023-07-01 11:43:04] [config] word-scores: false
[2023-07-01 11:43:04] [config] workspace: 2048
[2023-07-01 11:43:04] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:43:04] Using synchronous SGD
[2023-07-01 11:43:04] Synced seed 1234
[2023-07-01 11:43:04] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:43:04] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:43:04] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:43:04] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:43:04] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:43:04] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:43:05] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:43:05] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:43:05] [comm] Using global sharding
[2023-07-01 11:43:05] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:43:05] [training] Using 1 GPUs
[2023-07-01 11:43:05] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:43:05] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:43:05] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:43:05] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:43:13] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:43:13] [valid] No post-processing script given for validating translator
[2023-07-01 11:43:13] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:43:13] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:43:13] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:43:13] [comm] Using global sharding
[2023-07-01 11:43:13] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:43:13] [training] Using 1 GPUs
[2023-07-01 11:43:13] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:43:14] Allocating memory for general optimizer shards
[2023-07-01 11:43:14] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:43:14] Loading Adam parameters
[2023-07-01 11:43:14] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:43:14] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:43:14] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:43:14] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:43:14] [data] Shuffling data
[2023-07-01 11:43:14] [data] Done reading 20,192 sentences
[2023-07-01 11:43:14] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:43:14] Training started
[2023-07-01 11:43:14] Training finished
[2023-07-01 11:43:17] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:43:17] [marian] Running on node20.datos.cluster.uy as process 20353 with command line:
[2023-07-01 11:43:17] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 152 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:43:17] [config] after: 0e
[2023-07-01 11:43:17] [config] after-batches: 0
[2023-07-01 11:43:17] [config] after-epochs: 152
[2023-07-01 11:43:17] [config] all-caps-every: 0
[2023-07-01 11:43:17] [config] allow-unk: false
[2023-07-01 11:43:17] [config] authors: false
[2023-07-01 11:43:17] [config] beam-size: 12
[2023-07-01 11:43:17] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:43:17] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:43:17] [config] bert-masking-fraction: 0.15
[2023-07-01 11:43:17] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:43:17] [config] bert-train-type-embeddings: true
[2023-07-01 11:43:17] [config] bert-type-vocab-size: 2
[2023-07-01 11:43:17] [config] build-info: ""
[2023-07-01 11:43:17] [config] check-gradient-nan: false
[2023-07-01 11:43:17] [config] check-nan: false
[2023-07-01 11:43:17] [config] cite: false
[2023-07-01 11:43:17] [config] clip-norm: 5
[2023-07-01 11:43:17] [config] cost-scaling:
[2023-07-01 11:43:17] [config]   []
[2023-07-01 11:43:17] [config] cost-type: ce-sum
[2023-07-01 11:43:17] [config] cpu-threads: 0
[2023-07-01 11:43:17] [config] data-threads: 8
[2023-07-01 11:43:17] [config] data-weighting: ""
[2023-07-01 11:43:17] [config] data-weighting-type: sentence
[2023-07-01 11:43:17] [config] dec-cell: gru
[2023-07-01 11:43:17] [config] dec-cell-base-depth: 2
[2023-07-01 11:43:17] [config] dec-cell-high-depth: 1
[2023-07-01 11:43:17] [config] dec-depth: 2
[2023-07-01 11:43:17] [config] devices:
[2023-07-01 11:43:17] [config]   - 0
[2023-07-01 11:43:17] [config] dim-emb: 512
[2023-07-01 11:43:17] [config] dim-rnn: 1024
[2023-07-01 11:43:17] [config] dim-vocabs:
[2023-07-01 11:43:17] [config]   - 16384
[2023-07-01 11:43:17] [config]   - 16384
[2023-07-01 11:43:17] [config] disp-first: 0
[2023-07-01 11:43:17] [config] disp-freq: 1000u
[2023-07-01 11:43:17] [config] disp-label-counts: true
[2023-07-01 11:43:17] [config] dropout-rnn: 0
[2023-07-01 11:43:17] [config] dropout-src: 0
[2023-07-01 11:43:17] [config] dropout-trg: 0
[2023-07-01 11:43:17] [config] dump-config: ""
[2023-07-01 11:43:17] [config] dynamic-gradient-scaling:
[2023-07-01 11:43:17] [config]   []
[2023-07-01 11:43:17] [config] early-stopping: 10
[2023-07-01 11:43:17] [config] early-stopping-on: first
[2023-07-01 11:43:17] [config] embedding-fix-src: false
[2023-07-01 11:43:17] [config] embedding-fix-trg: false
[2023-07-01 11:43:17] [config] embedding-normalization: false
[2023-07-01 11:43:17] [config] embedding-vectors:
[2023-07-01 11:43:17] [config]   []
[2023-07-01 11:43:17] [config] enc-cell: gru
[2023-07-01 11:43:17] [config] enc-cell-depth: 1
[2023-07-01 11:43:17] [config] enc-depth: 2
[2023-07-01 11:43:17] [config] enc-type: bidirectional
[2023-07-01 11:43:17] [config] english-title-case-every: 0
[2023-07-01 11:43:17] [config] exponential-smoothing: 0.0001
[2023-07-01 11:43:17] [config] factor-weight: 1
[2023-07-01 11:43:17] [config] factors-combine: sum
[2023-07-01 11:43:17] [config] factors-dim-emb: 0
[2023-07-01 11:43:17] [config] gradient-checkpointing: false
[2023-07-01 11:43:17] [config] gradient-norm-average-window: 100
[2023-07-01 11:43:17] [config] guided-alignment: none
[2023-07-01 11:43:17] [config] guided-alignment-cost: mse
[2023-07-01 11:43:17] [config] guided-alignment-weight: 0.1
[2023-07-01 11:43:17] [config] ignore-model-config: false
[2023-07-01 11:43:17] [config] input-types:
[2023-07-01 11:43:17] [config]   []
[2023-07-01 11:43:17] [config] interpolate-env-vars: false
[2023-07-01 11:43:17] [config] keep-best: false
[2023-07-01 11:43:17] [config] label-smoothing: 0.1
[2023-07-01 11:43:17] [config] layer-normalization: false
[2023-07-01 11:43:17] [config] learn-rate: 0.0003
[2023-07-01 11:43:17] [config] lemma-dependency: ""
[2023-07-01 11:43:17] [config] lemma-dim-emb: 0
[2023-07-01 11:43:17] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:43:17] [config] log-level: info
[2023-07-01 11:43:17] [config] log-time-zone: ""
[2023-07-01 11:43:17] [config] logical-epoch:
[2023-07-01 11:43:17] [config]   - 1e
[2023-07-01 11:43:17] [config]   - 0
[2023-07-01 11:43:17] [config] lr-decay: 0
[2023-07-01 11:43:17] [config] lr-decay-freq: 50000
[2023-07-01 11:43:17] [config] lr-decay-inv-sqrt:
[2023-07-01 11:43:17] [config]   - 16000
[2023-07-01 11:43:17] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:43:17] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:43:17] [config] lr-decay-start:
[2023-07-01 11:43:17] [config]   - 10
[2023-07-01 11:43:17] [config]   - 1
[2023-07-01 11:43:17] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:43:17] [config] lr-report: true
[2023-07-01 11:43:17] [config] lr-warmup: 16000
[2023-07-01 11:43:17] [config] lr-warmup-at-reload: false
[2023-07-01 11:43:17] [config] lr-warmup-cycle: false
[2023-07-01 11:43:17] [config] lr-warmup-start-rate: 0
[2023-07-01 11:43:17] [config] max-length: 100
[2023-07-01 11:43:17] [config] max-length-crop: false
[2023-07-01 11:43:17] [config] max-length-factor: 3
[2023-07-01 11:43:17] [config] maxi-batch: 100
[2023-07-01 11:43:17] [config] maxi-batch-sort: trg
[2023-07-01 11:43:17] [config] mini-batch: 1000
[2023-07-01 11:43:17] [config] mini-batch-fit: true
[2023-07-01 11:43:17] [config] mini-batch-fit-step: 10
[2023-07-01 11:43:17] [config] mini-batch-round-up: true
[2023-07-01 11:43:17] [config] mini-batch-track-lr: false
[2023-07-01 11:43:17] [config] mini-batch-warmup: 0
[2023-07-01 11:43:17] [config] mini-batch-words: 0
[2023-07-01 11:43:17] [config] mini-batch-words-ref: 0
[2023-07-01 11:43:17] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:43:17] [config] multi-loss-type: sum
[2023-07-01 11:43:17] [config] n-best: false
[2023-07-01 11:43:17] [config] no-nccl: false
[2023-07-01 11:43:17] [config] no-reload: false
[2023-07-01 11:43:17] [config] no-restore-corpus: false
[2023-07-01 11:43:17] [config] normalize: 1
[2023-07-01 11:43:17] [config] normalize-gradient: false
[2023-07-01 11:43:17] [config] num-devices: 0
[2023-07-01 11:43:17] [config] optimizer: adam
[2023-07-01 11:43:17] [config] optimizer-delay: 1
[2023-07-01 11:43:17] [config] optimizer-params:
[2023-07-01 11:43:17] [config]   - 0.9
[2023-07-01 11:43:17] [config]   - 0.98
[2023-07-01 11:43:17] [config]   - 1e-09
[2023-07-01 11:43:17] [config] output-omit-bias: false
[2023-07-01 11:43:17] [config] overwrite: true
[2023-07-01 11:43:17] [config] precision:
[2023-07-01 11:43:17] [config]   - float32
[2023-07-01 11:43:17] [config]   - float32
[2023-07-01 11:43:17] [config] pretrained-model: ""
[2023-07-01 11:43:17] [config] quantize-biases: false
[2023-07-01 11:43:17] [config] quantize-bits: 0
[2023-07-01 11:43:17] [config] quantize-log-based: false
[2023-07-01 11:43:17] [config] quantize-optimization-steps: 0
[2023-07-01 11:43:17] [config] quiet: false
[2023-07-01 11:43:17] [config] quiet-translation: true
[2023-07-01 11:43:17] [config] relative-paths: false
[2023-07-01 11:43:17] [config] right-left: false
[2023-07-01 11:43:17] [config] save-freq: 10000u
[2023-07-01 11:43:17] [config] seed: 1234
[2023-07-01 11:43:17] [config] sentencepiece-alphas:
[2023-07-01 11:43:17] [config]   []
[2023-07-01 11:43:17] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:43:17] [config] sentencepiece-options: ""
[2023-07-01 11:43:17] [config] sharding: global
[2023-07-01 11:43:17] [config] shuffle: data
[2023-07-01 11:43:17] [config] shuffle-in-ram: false
[2023-07-01 11:43:17] [config] sigterm: save-and-exit
[2023-07-01 11:43:17] [config] skip: false
[2023-07-01 11:43:17] [config] sqlite: ""
[2023-07-01 11:43:17] [config] sqlite-drop: false
[2023-07-01 11:43:17] [config] sync-freq: 200u
[2023-07-01 11:43:17] [config] sync-sgd: true
[2023-07-01 11:43:17] [config] tempdir: /tmp
[2023-07-01 11:43:17] [config] tied-embeddings: false
[2023-07-01 11:43:17] [config] tied-embeddings-all: true
[2023-07-01 11:43:17] [config] tied-embeddings-src: false
[2023-07-01 11:43:17] [config] train-embedder-rank:
[2023-07-01 11:43:17] [config]   []
[2023-07-01 11:43:17] [config] train-sets:
[2023-07-01 11:43:17] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:43:17] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:43:17] [config] transformer-aan-activation: swish
[2023-07-01 11:43:17] [config] transformer-aan-depth: 2
[2023-07-01 11:43:17] [config] transformer-aan-nogate: false
[2023-07-01 11:43:17] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:43:17] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:43:17] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:43:17] [config] transformer-depth-scaling: false
[2023-07-01 11:43:17] [config] transformer-dim-aan: 2048
[2023-07-01 11:43:17] [config] transformer-dim-ffn: 2048
[2023-07-01 11:43:17] [config] transformer-dropout: 0.1
[2023-07-01 11:43:17] [config] transformer-dropout-attention: 0
[2023-07-01 11:43:17] [config] transformer-dropout-ffn: 0
[2023-07-01 11:43:17] [config] transformer-ffn-activation: swish
[2023-07-01 11:43:17] [config] transformer-ffn-depth: 2
[2023-07-01 11:43:17] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:43:17] [config] transformer-heads: 8
[2023-07-01 11:43:17] [config] transformer-no-projection: false
[2023-07-01 11:43:17] [config] transformer-pool: false
[2023-07-01 11:43:17] [config] transformer-postprocess: dan
[2023-07-01 11:43:17] [config] transformer-postprocess-emb: d
[2023-07-01 11:43:17] [config] transformer-postprocess-top: ""
[2023-07-01 11:43:17] [config] transformer-preprocess: ""
[2023-07-01 11:43:17] [config] transformer-tied-layers:
[2023-07-01 11:43:17] [config]   []
[2023-07-01 11:43:17] [config] transformer-train-position-embeddings: false
[2023-07-01 11:43:17] [config] tsv: false
[2023-07-01 11:43:17] [config] tsv-fields: 0
[2023-07-01 11:43:17] [config] type: transformer
[2023-07-01 11:43:17] [config] ulr: false
[2023-07-01 11:43:17] [config] ulr-dim-emb: 0
[2023-07-01 11:43:17] [config] ulr-dropout: 0
[2023-07-01 11:43:17] [config] ulr-keys-vectors: ""
[2023-07-01 11:43:17] [config] ulr-query-vectors: ""
[2023-07-01 11:43:17] [config] ulr-softmax-temperature: 1
[2023-07-01 11:43:17] [config] ulr-trainable-transformation: false
[2023-07-01 11:43:17] [config] unlikelihood-loss: false
[2023-07-01 11:43:17] [config] valid-freq: 50000000
[2023-07-01 11:43:17] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:43:17] [config] valid-max-length: 1000
[2023-07-01 11:43:17] [config] valid-metrics:
[2023-07-01 11:43:17] [config]   - cross-entropy
[2023-07-01 11:43:17] [config]   - translation
[2023-07-01 11:43:17] [config] valid-mini-batch: 64
[2023-07-01 11:43:17] [config] valid-reset-stalled: false
[2023-07-01 11:43:17] [config] valid-script-args:
[2023-07-01 11:43:17] [config]   []
[2023-07-01 11:43:17] [config] valid-script-path: ""
[2023-07-01 11:43:17] [config] valid-sets:
[2023-07-01 11:43:17] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:43:17] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:43:17] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:43:17] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:43:17] [config] vocabs:
[2023-07-01 11:43:17] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:43:17] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:43:17] [config] word-penalty: 0
[2023-07-01 11:43:17] [config] word-scores: false
[2023-07-01 11:43:17] [config] workspace: 2048
[2023-07-01 11:43:17] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:43:17] Using synchronous SGD
[2023-07-01 11:43:18] Synced seed 1234
[2023-07-01 11:43:18] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:43:18] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:43:18] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:43:18] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:43:18] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:43:18] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:43:19] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:43:19] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:43:19] [comm] Using global sharding
[2023-07-01 11:43:19] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:43:19] [training] Using 1 GPUs
[2023-07-01 11:43:19] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:43:19] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:43:19] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:43:19] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:43:27] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:43:27] [valid] No post-processing script given for validating translator
[2023-07-01 11:43:27] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:43:27] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:43:27] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:43:27] [comm] Using global sharding
[2023-07-01 11:43:27] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:43:27] [training] Using 1 GPUs
[2023-07-01 11:43:27] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:43:27] Allocating memory for general optimizer shards
[2023-07-01 11:43:27] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:43:27] Loading Adam parameters
[2023-07-01 11:43:27] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:43:27] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:43:27] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:43:27] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:43:27] [data] Shuffling data
[2023-07-01 11:43:27] [data] Done reading 20,192 sentences
[2023-07-01 11:43:28] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:43:28] Training started
[2023-07-01 11:43:28] Training finished
[2023-07-01 11:43:31] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:43:31] [marian] Running on node20.datos.cluster.uy as process 20410 with command line:
[2023-07-01 11:43:31] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 153 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:43:31] [config] after: 0e
[2023-07-01 11:43:31] [config] after-batches: 0
[2023-07-01 11:43:31] [config] after-epochs: 153
[2023-07-01 11:43:31] [config] all-caps-every: 0
[2023-07-01 11:43:31] [config] allow-unk: false
[2023-07-01 11:43:31] [config] authors: false
[2023-07-01 11:43:31] [config] beam-size: 12
[2023-07-01 11:43:31] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:43:31] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:43:31] [config] bert-masking-fraction: 0.15
[2023-07-01 11:43:31] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:43:31] [config] bert-train-type-embeddings: true
[2023-07-01 11:43:31] [config] bert-type-vocab-size: 2
[2023-07-01 11:43:31] [config] build-info: ""
[2023-07-01 11:43:31] [config] check-gradient-nan: false
[2023-07-01 11:43:31] [config] check-nan: false
[2023-07-01 11:43:31] [config] cite: false
[2023-07-01 11:43:31] [config] clip-norm: 5
[2023-07-01 11:43:31] [config] cost-scaling:
[2023-07-01 11:43:31] [config]   []
[2023-07-01 11:43:31] [config] cost-type: ce-sum
[2023-07-01 11:43:31] [config] cpu-threads: 0
[2023-07-01 11:43:31] [config] data-threads: 8
[2023-07-01 11:43:31] [config] data-weighting: ""
[2023-07-01 11:43:31] [config] data-weighting-type: sentence
[2023-07-01 11:43:31] [config] dec-cell: gru
[2023-07-01 11:43:31] [config] dec-cell-base-depth: 2
[2023-07-01 11:43:31] [config] dec-cell-high-depth: 1
[2023-07-01 11:43:31] [config] dec-depth: 2
[2023-07-01 11:43:31] [config] devices:
[2023-07-01 11:43:31] [config]   - 0
[2023-07-01 11:43:31] [config] dim-emb: 512
[2023-07-01 11:43:31] [config] dim-rnn: 1024
[2023-07-01 11:43:31] [config] dim-vocabs:
[2023-07-01 11:43:31] [config]   - 16384
[2023-07-01 11:43:31] [config]   - 16384
[2023-07-01 11:43:31] [config] disp-first: 0
[2023-07-01 11:43:31] [config] disp-freq: 1000u
[2023-07-01 11:43:31] [config] disp-label-counts: true
[2023-07-01 11:43:31] [config] dropout-rnn: 0
[2023-07-01 11:43:31] [config] dropout-src: 0
[2023-07-01 11:43:31] [config] dropout-trg: 0
[2023-07-01 11:43:31] [config] dump-config: ""
[2023-07-01 11:43:31] [config] dynamic-gradient-scaling:
[2023-07-01 11:43:31] [config]   []
[2023-07-01 11:43:31] [config] early-stopping: 10
[2023-07-01 11:43:31] [config] early-stopping-on: first
[2023-07-01 11:43:31] [config] embedding-fix-src: false
[2023-07-01 11:43:31] [config] embedding-fix-trg: false
[2023-07-01 11:43:31] [config] embedding-normalization: false
[2023-07-01 11:43:31] [config] embedding-vectors:
[2023-07-01 11:43:31] [config]   []
[2023-07-01 11:43:31] [config] enc-cell: gru
[2023-07-01 11:43:31] [config] enc-cell-depth: 1
[2023-07-01 11:43:31] [config] enc-depth: 2
[2023-07-01 11:43:31] [config] enc-type: bidirectional
[2023-07-01 11:43:31] [config] english-title-case-every: 0
[2023-07-01 11:43:31] [config] exponential-smoothing: 0.0001
[2023-07-01 11:43:31] [config] factor-weight: 1
[2023-07-01 11:43:31] [config] factors-combine: sum
[2023-07-01 11:43:31] [config] factors-dim-emb: 0
[2023-07-01 11:43:31] [config] gradient-checkpointing: false
[2023-07-01 11:43:31] [config] gradient-norm-average-window: 100
[2023-07-01 11:43:31] [config] guided-alignment: none
[2023-07-01 11:43:31] [config] guided-alignment-cost: mse
[2023-07-01 11:43:31] [config] guided-alignment-weight: 0.1
[2023-07-01 11:43:31] [config] ignore-model-config: false
[2023-07-01 11:43:31] [config] input-types:
[2023-07-01 11:43:31] [config]   []
[2023-07-01 11:43:31] [config] interpolate-env-vars: false
[2023-07-01 11:43:31] [config] keep-best: false
[2023-07-01 11:43:31] [config] label-smoothing: 0.1
[2023-07-01 11:43:31] [config] layer-normalization: false
[2023-07-01 11:43:31] [config] learn-rate: 0.0003
[2023-07-01 11:43:31] [config] lemma-dependency: ""
[2023-07-01 11:43:31] [config] lemma-dim-emb: 0
[2023-07-01 11:43:31] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:43:31] [config] log-level: info
[2023-07-01 11:43:31] [config] log-time-zone: ""
[2023-07-01 11:43:31] [config] logical-epoch:
[2023-07-01 11:43:31] [config]   - 1e
[2023-07-01 11:43:31] [config]   - 0
[2023-07-01 11:43:31] [config] lr-decay: 0
[2023-07-01 11:43:31] [config] lr-decay-freq: 50000
[2023-07-01 11:43:31] [config] lr-decay-inv-sqrt:
[2023-07-01 11:43:31] [config]   - 16000
[2023-07-01 11:43:31] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:43:31] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:43:31] [config] lr-decay-start:
[2023-07-01 11:43:31] [config]   - 10
[2023-07-01 11:43:31] [config]   - 1
[2023-07-01 11:43:31] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:43:31] [config] lr-report: true
[2023-07-01 11:43:31] [config] lr-warmup: 16000
[2023-07-01 11:43:31] [config] lr-warmup-at-reload: false
[2023-07-01 11:43:31] [config] lr-warmup-cycle: false
[2023-07-01 11:43:31] [config] lr-warmup-start-rate: 0
[2023-07-01 11:43:31] [config] max-length: 100
[2023-07-01 11:43:31] [config] max-length-crop: false
[2023-07-01 11:43:31] [config] max-length-factor: 3
[2023-07-01 11:43:31] [config] maxi-batch: 100
[2023-07-01 11:43:31] [config] maxi-batch-sort: trg
[2023-07-01 11:43:31] [config] mini-batch: 1000
[2023-07-01 11:43:31] [config] mini-batch-fit: true
[2023-07-01 11:43:31] [config] mini-batch-fit-step: 10
[2023-07-01 11:43:31] [config] mini-batch-round-up: true
[2023-07-01 11:43:31] [config] mini-batch-track-lr: false
[2023-07-01 11:43:31] [config] mini-batch-warmup: 0
[2023-07-01 11:43:31] [config] mini-batch-words: 0
[2023-07-01 11:43:31] [config] mini-batch-words-ref: 0
[2023-07-01 11:43:31] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:43:31] [config] multi-loss-type: sum
[2023-07-01 11:43:31] [config] n-best: false
[2023-07-01 11:43:31] [config] no-nccl: false
[2023-07-01 11:43:31] [config] no-reload: false
[2023-07-01 11:43:31] [config] no-restore-corpus: false
[2023-07-01 11:43:31] [config] normalize: 1
[2023-07-01 11:43:31] [config] normalize-gradient: false
[2023-07-01 11:43:31] [config] num-devices: 0
[2023-07-01 11:43:31] [config] optimizer: adam
[2023-07-01 11:43:31] [config] optimizer-delay: 1
[2023-07-01 11:43:31] [config] optimizer-params:
[2023-07-01 11:43:31] [config]   - 0.9
[2023-07-01 11:43:31] [config]   - 0.98
[2023-07-01 11:43:31] [config]   - 1e-09
[2023-07-01 11:43:31] [config] output-omit-bias: false
[2023-07-01 11:43:31] [config] overwrite: true
[2023-07-01 11:43:31] [config] precision:
[2023-07-01 11:43:31] [config]   - float32
[2023-07-01 11:43:31] [config]   - float32
[2023-07-01 11:43:31] [config] pretrained-model: ""
[2023-07-01 11:43:31] [config] quantize-biases: false
[2023-07-01 11:43:31] [config] quantize-bits: 0
[2023-07-01 11:43:31] [config] quantize-log-based: false
[2023-07-01 11:43:31] [config] quantize-optimization-steps: 0
[2023-07-01 11:43:31] [config] quiet: false
[2023-07-01 11:43:31] [config] quiet-translation: true
[2023-07-01 11:43:31] [config] relative-paths: false
[2023-07-01 11:43:31] [config] right-left: false
[2023-07-01 11:43:31] [config] save-freq: 10000u
[2023-07-01 11:43:31] [config] seed: 1234
[2023-07-01 11:43:31] [config] sentencepiece-alphas:
[2023-07-01 11:43:31] [config]   []
[2023-07-01 11:43:31] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:43:31] [config] sentencepiece-options: ""
[2023-07-01 11:43:31] [config] sharding: global
[2023-07-01 11:43:31] [config] shuffle: data
[2023-07-01 11:43:31] [config] shuffle-in-ram: false
[2023-07-01 11:43:31] [config] sigterm: save-and-exit
[2023-07-01 11:43:31] [config] skip: false
[2023-07-01 11:43:31] [config] sqlite: ""
[2023-07-01 11:43:31] [config] sqlite-drop: false
[2023-07-01 11:43:31] [config] sync-freq: 200u
[2023-07-01 11:43:31] [config] sync-sgd: true
[2023-07-01 11:43:31] [config] tempdir: /tmp
[2023-07-01 11:43:31] [config] tied-embeddings: false
[2023-07-01 11:43:31] [config] tied-embeddings-all: true
[2023-07-01 11:43:31] [config] tied-embeddings-src: false
[2023-07-01 11:43:31] [config] train-embedder-rank:
[2023-07-01 11:43:31] [config]   []
[2023-07-01 11:43:31] [config] train-sets:
[2023-07-01 11:43:31] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:43:31] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:43:31] [config] transformer-aan-activation: swish
[2023-07-01 11:43:31] [config] transformer-aan-depth: 2
[2023-07-01 11:43:31] [config] transformer-aan-nogate: false
[2023-07-01 11:43:31] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:43:31] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:43:31] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:43:31] [config] transformer-depth-scaling: false
[2023-07-01 11:43:31] [config] transformer-dim-aan: 2048
[2023-07-01 11:43:31] [config] transformer-dim-ffn: 2048
[2023-07-01 11:43:31] [config] transformer-dropout: 0.1
[2023-07-01 11:43:31] [config] transformer-dropout-attention: 0
[2023-07-01 11:43:31] [config] transformer-dropout-ffn: 0
[2023-07-01 11:43:31] [config] transformer-ffn-activation: swish
[2023-07-01 11:43:31] [config] transformer-ffn-depth: 2
[2023-07-01 11:43:31] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:43:31] [config] transformer-heads: 8
[2023-07-01 11:43:31] [config] transformer-no-projection: false
[2023-07-01 11:43:31] [config] transformer-pool: false
[2023-07-01 11:43:31] [config] transformer-postprocess: dan
[2023-07-01 11:43:31] [config] transformer-postprocess-emb: d
[2023-07-01 11:43:31] [config] transformer-postprocess-top: ""
[2023-07-01 11:43:31] [config] transformer-preprocess: ""
[2023-07-01 11:43:31] [config] transformer-tied-layers:
[2023-07-01 11:43:31] [config]   []
[2023-07-01 11:43:31] [config] transformer-train-position-embeddings: false
[2023-07-01 11:43:31] [config] tsv: false
[2023-07-01 11:43:31] [config] tsv-fields: 0
[2023-07-01 11:43:31] [config] type: transformer
[2023-07-01 11:43:31] [config] ulr: false
[2023-07-01 11:43:31] [config] ulr-dim-emb: 0
[2023-07-01 11:43:31] [config] ulr-dropout: 0
[2023-07-01 11:43:31] [config] ulr-keys-vectors: ""
[2023-07-01 11:43:31] [config] ulr-query-vectors: ""
[2023-07-01 11:43:31] [config] ulr-softmax-temperature: 1
[2023-07-01 11:43:31] [config] ulr-trainable-transformation: false
[2023-07-01 11:43:31] [config] unlikelihood-loss: false
[2023-07-01 11:43:31] [config] valid-freq: 50000000
[2023-07-01 11:43:31] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:43:31] [config] valid-max-length: 1000
[2023-07-01 11:43:31] [config] valid-metrics:
[2023-07-01 11:43:31] [config]   - cross-entropy
[2023-07-01 11:43:31] [config]   - translation
[2023-07-01 11:43:31] [config] valid-mini-batch: 64
[2023-07-01 11:43:31] [config] valid-reset-stalled: false
[2023-07-01 11:43:31] [config] valid-script-args:
[2023-07-01 11:43:31] [config]   []
[2023-07-01 11:43:31] [config] valid-script-path: ""
[2023-07-01 11:43:31] [config] valid-sets:
[2023-07-01 11:43:31] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:43:31] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:43:31] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:43:31] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:43:31] [config] vocabs:
[2023-07-01 11:43:31] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:43:31] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:43:31] [config] word-penalty: 0
[2023-07-01 11:43:31] [config] word-scores: false
[2023-07-01 11:43:31] [config] workspace: 2048
[2023-07-01 11:43:31] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:43:31] Using synchronous SGD
[2023-07-01 11:43:31] Synced seed 1234
[2023-07-01 11:43:31] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:43:31] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:43:31] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:43:31] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:43:31] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:43:31] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:43:32] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:43:32] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:43:32] [comm] Using global sharding
[2023-07-01 11:43:32] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:43:32] [training] Using 1 GPUs
[2023-07-01 11:43:32] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:43:32] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:43:33] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:43:33] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:43:40] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:43:40] [valid] No post-processing script given for validating translator
[2023-07-01 11:43:40] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:43:40] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:43:40] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:43:40] [comm] Using global sharding
[2023-07-01 11:43:40] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:43:40] [training] Using 1 GPUs
[2023-07-01 11:43:40] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:43:41] Allocating memory for general optimizer shards
[2023-07-01 11:43:41] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:43:41] Loading Adam parameters
[2023-07-01 11:43:41] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:43:41] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:43:41] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:43:41] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:43:41] [data] Shuffling data
[2023-07-01 11:43:41] [data] Done reading 20,192 sentences
[2023-07-01 11:43:41] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:43:41] Training started
[2023-07-01 11:43:41] Training finished
[2023-07-01 11:43:45] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:43:45] [marian] Running on node20.datos.cluster.uy as process 20471 with command line:
[2023-07-01 11:43:45] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 154 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:43:45] [config] after: 0e
[2023-07-01 11:43:45] [config] after-batches: 0
[2023-07-01 11:43:45] [config] after-epochs: 154
[2023-07-01 11:43:45] [config] all-caps-every: 0
[2023-07-01 11:43:45] [config] allow-unk: false
[2023-07-01 11:43:45] [config] authors: false
[2023-07-01 11:43:45] [config] beam-size: 12
[2023-07-01 11:43:45] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:43:45] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:43:45] [config] bert-masking-fraction: 0.15
[2023-07-01 11:43:45] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:43:45] [config] bert-train-type-embeddings: true
[2023-07-01 11:43:45] [config] bert-type-vocab-size: 2
[2023-07-01 11:43:45] [config] build-info: ""
[2023-07-01 11:43:45] [config] check-gradient-nan: false
[2023-07-01 11:43:45] [config] check-nan: false
[2023-07-01 11:43:45] [config] cite: false
[2023-07-01 11:43:45] [config] clip-norm: 5
[2023-07-01 11:43:45] [config] cost-scaling:
[2023-07-01 11:43:45] [config]   []
[2023-07-01 11:43:45] [config] cost-type: ce-sum
[2023-07-01 11:43:45] [config] cpu-threads: 0
[2023-07-01 11:43:45] [config] data-threads: 8
[2023-07-01 11:43:45] [config] data-weighting: ""
[2023-07-01 11:43:45] [config] data-weighting-type: sentence
[2023-07-01 11:43:45] [config] dec-cell: gru
[2023-07-01 11:43:45] [config] dec-cell-base-depth: 2
[2023-07-01 11:43:45] [config] dec-cell-high-depth: 1
[2023-07-01 11:43:45] [config] dec-depth: 2
[2023-07-01 11:43:45] [config] devices:
[2023-07-01 11:43:45] [config]   - 0
[2023-07-01 11:43:45] [config] dim-emb: 512
[2023-07-01 11:43:45] [config] dim-rnn: 1024
[2023-07-01 11:43:45] [config] dim-vocabs:
[2023-07-01 11:43:45] [config]   - 16384
[2023-07-01 11:43:45] [config]   - 16384
[2023-07-01 11:43:45] [config] disp-first: 0
[2023-07-01 11:43:45] [config] disp-freq: 1000u
[2023-07-01 11:43:45] [config] disp-label-counts: true
[2023-07-01 11:43:45] [config] dropout-rnn: 0
[2023-07-01 11:43:45] [config] dropout-src: 0
[2023-07-01 11:43:45] [config] dropout-trg: 0
[2023-07-01 11:43:45] [config] dump-config: ""
[2023-07-01 11:43:45] [config] dynamic-gradient-scaling:
[2023-07-01 11:43:45] [config]   []
[2023-07-01 11:43:45] [config] early-stopping: 10
[2023-07-01 11:43:45] [config] early-stopping-on: first
[2023-07-01 11:43:45] [config] embedding-fix-src: false
[2023-07-01 11:43:45] [config] embedding-fix-trg: false
[2023-07-01 11:43:45] [config] embedding-normalization: false
[2023-07-01 11:43:45] [config] embedding-vectors:
[2023-07-01 11:43:45] [config]   []
[2023-07-01 11:43:45] [config] enc-cell: gru
[2023-07-01 11:43:45] [config] enc-cell-depth: 1
[2023-07-01 11:43:45] [config] enc-depth: 2
[2023-07-01 11:43:45] [config] enc-type: bidirectional
[2023-07-01 11:43:45] [config] english-title-case-every: 0
[2023-07-01 11:43:45] [config] exponential-smoothing: 0.0001
[2023-07-01 11:43:45] [config] factor-weight: 1
[2023-07-01 11:43:45] [config] factors-combine: sum
[2023-07-01 11:43:45] [config] factors-dim-emb: 0
[2023-07-01 11:43:45] [config] gradient-checkpointing: false
[2023-07-01 11:43:45] [config] gradient-norm-average-window: 100
[2023-07-01 11:43:45] [config] guided-alignment: none
[2023-07-01 11:43:45] [config] guided-alignment-cost: mse
[2023-07-01 11:43:45] [config] guided-alignment-weight: 0.1
[2023-07-01 11:43:45] [config] ignore-model-config: false
[2023-07-01 11:43:45] [config] input-types:
[2023-07-01 11:43:45] [config]   []
[2023-07-01 11:43:45] [config] interpolate-env-vars: false
[2023-07-01 11:43:45] [config] keep-best: false
[2023-07-01 11:43:45] [config] label-smoothing: 0.1
[2023-07-01 11:43:45] [config] layer-normalization: false
[2023-07-01 11:43:45] [config] learn-rate: 0.0003
[2023-07-01 11:43:45] [config] lemma-dependency: ""
[2023-07-01 11:43:45] [config] lemma-dim-emb: 0
[2023-07-01 11:43:45] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:43:45] [config] log-level: info
[2023-07-01 11:43:45] [config] log-time-zone: ""
[2023-07-01 11:43:45] [config] logical-epoch:
[2023-07-01 11:43:45] [config]   - 1e
[2023-07-01 11:43:45] [config]   - 0
[2023-07-01 11:43:45] [config] lr-decay: 0
[2023-07-01 11:43:45] [config] lr-decay-freq: 50000
[2023-07-01 11:43:45] [config] lr-decay-inv-sqrt:
[2023-07-01 11:43:45] [config]   - 16000
[2023-07-01 11:43:45] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:43:45] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:43:45] [config] lr-decay-start:
[2023-07-01 11:43:45] [config]   - 10
[2023-07-01 11:43:45] [config]   - 1
[2023-07-01 11:43:45] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:43:45] [config] lr-report: true
[2023-07-01 11:43:45] [config] lr-warmup: 16000
[2023-07-01 11:43:45] [config] lr-warmup-at-reload: false
[2023-07-01 11:43:45] [config] lr-warmup-cycle: false
[2023-07-01 11:43:45] [config] lr-warmup-start-rate: 0
[2023-07-01 11:43:45] [config] max-length: 100
[2023-07-01 11:43:45] [config] max-length-crop: false
[2023-07-01 11:43:45] [config] max-length-factor: 3
[2023-07-01 11:43:45] [config] maxi-batch: 100
[2023-07-01 11:43:45] [config] maxi-batch-sort: trg
[2023-07-01 11:43:45] [config] mini-batch: 1000
[2023-07-01 11:43:45] [config] mini-batch-fit: true
[2023-07-01 11:43:45] [config] mini-batch-fit-step: 10
[2023-07-01 11:43:45] [config] mini-batch-round-up: true
[2023-07-01 11:43:45] [config] mini-batch-track-lr: false
[2023-07-01 11:43:45] [config] mini-batch-warmup: 0
[2023-07-01 11:43:45] [config] mini-batch-words: 0
[2023-07-01 11:43:45] [config] mini-batch-words-ref: 0
[2023-07-01 11:43:45] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:43:45] [config] multi-loss-type: sum
[2023-07-01 11:43:45] [config] n-best: false
[2023-07-01 11:43:45] [config] no-nccl: false
[2023-07-01 11:43:45] [config] no-reload: false
[2023-07-01 11:43:45] [config] no-restore-corpus: false
[2023-07-01 11:43:45] [config] normalize: 1
[2023-07-01 11:43:45] [config] normalize-gradient: false
[2023-07-01 11:43:45] [config] num-devices: 0
[2023-07-01 11:43:45] [config] optimizer: adam
[2023-07-01 11:43:45] [config] optimizer-delay: 1
[2023-07-01 11:43:45] [config] optimizer-params:
[2023-07-01 11:43:45] [config]   - 0.9
[2023-07-01 11:43:45] [config]   - 0.98
[2023-07-01 11:43:45] [config]   - 1e-09
[2023-07-01 11:43:45] [config] output-omit-bias: false
[2023-07-01 11:43:45] [config] overwrite: true
[2023-07-01 11:43:45] [config] precision:
[2023-07-01 11:43:45] [config]   - float32
[2023-07-01 11:43:45] [config]   - float32
[2023-07-01 11:43:45] [config] pretrained-model: ""
[2023-07-01 11:43:45] [config] quantize-biases: false
[2023-07-01 11:43:45] [config] quantize-bits: 0
[2023-07-01 11:43:45] [config] quantize-log-based: false
[2023-07-01 11:43:45] [config] quantize-optimization-steps: 0
[2023-07-01 11:43:45] [config] quiet: false
[2023-07-01 11:43:45] [config] quiet-translation: true
[2023-07-01 11:43:45] [config] relative-paths: false
[2023-07-01 11:43:45] [config] right-left: false
[2023-07-01 11:43:45] [config] save-freq: 10000u
[2023-07-01 11:43:45] [config] seed: 1234
[2023-07-01 11:43:45] [config] sentencepiece-alphas:
[2023-07-01 11:43:45] [config]   []
[2023-07-01 11:43:45] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:43:45] [config] sentencepiece-options: ""
[2023-07-01 11:43:45] [config] sharding: global
[2023-07-01 11:43:45] [config] shuffle: data
[2023-07-01 11:43:45] [config] shuffle-in-ram: false
[2023-07-01 11:43:45] [config] sigterm: save-and-exit
[2023-07-01 11:43:45] [config] skip: false
[2023-07-01 11:43:45] [config] sqlite: ""
[2023-07-01 11:43:45] [config] sqlite-drop: false
[2023-07-01 11:43:45] [config] sync-freq: 200u
[2023-07-01 11:43:45] [config] sync-sgd: true
[2023-07-01 11:43:45] [config] tempdir: /tmp
[2023-07-01 11:43:45] [config] tied-embeddings: false
[2023-07-01 11:43:45] [config] tied-embeddings-all: true
[2023-07-01 11:43:45] [config] tied-embeddings-src: false
[2023-07-01 11:43:45] [config] train-embedder-rank:
[2023-07-01 11:43:45] [config]   []
[2023-07-01 11:43:45] [config] train-sets:
[2023-07-01 11:43:45] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:43:45] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:43:45] [config] transformer-aan-activation: swish
[2023-07-01 11:43:45] [config] transformer-aan-depth: 2
[2023-07-01 11:43:45] [config] transformer-aan-nogate: false
[2023-07-01 11:43:45] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:43:45] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:43:45] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:43:45] [config] transformer-depth-scaling: false
[2023-07-01 11:43:45] [config] transformer-dim-aan: 2048
[2023-07-01 11:43:45] [config] transformer-dim-ffn: 2048
[2023-07-01 11:43:45] [config] transformer-dropout: 0.1
[2023-07-01 11:43:45] [config] transformer-dropout-attention: 0
[2023-07-01 11:43:45] [config] transformer-dropout-ffn: 0
[2023-07-01 11:43:45] [config] transformer-ffn-activation: swish
[2023-07-01 11:43:45] [config] transformer-ffn-depth: 2
[2023-07-01 11:43:45] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:43:45] [config] transformer-heads: 8
[2023-07-01 11:43:45] [config] transformer-no-projection: false
[2023-07-01 11:43:45] [config] transformer-pool: false
[2023-07-01 11:43:45] [config] transformer-postprocess: dan
[2023-07-01 11:43:45] [config] transformer-postprocess-emb: d
[2023-07-01 11:43:45] [config] transformer-postprocess-top: ""
[2023-07-01 11:43:45] [config] transformer-preprocess: ""
[2023-07-01 11:43:45] [config] transformer-tied-layers:
[2023-07-01 11:43:45] [config]   []
[2023-07-01 11:43:45] [config] transformer-train-position-embeddings: false
[2023-07-01 11:43:45] [config] tsv: false
[2023-07-01 11:43:45] [config] tsv-fields: 0
[2023-07-01 11:43:45] [config] type: transformer
[2023-07-01 11:43:45] [config] ulr: false
[2023-07-01 11:43:45] [config] ulr-dim-emb: 0
[2023-07-01 11:43:45] [config] ulr-dropout: 0
[2023-07-01 11:43:45] [config] ulr-keys-vectors: ""
[2023-07-01 11:43:45] [config] ulr-query-vectors: ""
[2023-07-01 11:43:45] [config] ulr-softmax-temperature: 1
[2023-07-01 11:43:45] [config] ulr-trainable-transformation: false
[2023-07-01 11:43:45] [config] unlikelihood-loss: false
[2023-07-01 11:43:45] [config] valid-freq: 50000000
[2023-07-01 11:43:45] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:43:45] [config] valid-max-length: 1000
[2023-07-01 11:43:45] [config] valid-metrics:
[2023-07-01 11:43:45] [config]   - cross-entropy
[2023-07-01 11:43:45] [config]   - translation
[2023-07-01 11:43:45] [config] valid-mini-batch: 64
[2023-07-01 11:43:45] [config] valid-reset-stalled: false
[2023-07-01 11:43:45] [config] valid-script-args:
[2023-07-01 11:43:45] [config]   []
[2023-07-01 11:43:45] [config] valid-script-path: ""
[2023-07-01 11:43:45] [config] valid-sets:
[2023-07-01 11:43:45] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:43:45] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:43:45] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:43:45] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:43:45] [config] vocabs:
[2023-07-01 11:43:45] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:43:45] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:43:45] [config] word-penalty: 0
[2023-07-01 11:43:45] [config] word-scores: false
[2023-07-01 11:43:45] [config] workspace: 2048
[2023-07-01 11:43:45] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:43:45] Using synchronous SGD
[2023-07-01 11:43:45] Synced seed 1234
[2023-07-01 11:43:45] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:43:45] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:43:45] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:43:45] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:43:45] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:43:45] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:43:46] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:43:46] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:43:46] [comm] Using global sharding
[2023-07-01 11:43:46] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:43:46] [training] Using 1 GPUs
[2023-07-01 11:43:46] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:43:46] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:43:46] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:43:46] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:43:54] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:43:54] [valid] No post-processing script given for validating translator
[2023-07-01 11:43:54] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:43:54] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:43:54] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:43:54] [comm] Using global sharding
[2023-07-01 11:43:54] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:43:54] [training] Using 1 GPUs
[2023-07-01 11:43:54] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:43:54] Allocating memory for general optimizer shards
[2023-07-01 11:43:54] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:43:54] Loading Adam parameters
[2023-07-01 11:43:54] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:43:54] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:43:55] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:43:55] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:43:55] [data] Shuffling data
[2023-07-01 11:43:55] [data] Done reading 20,192 sentences
[2023-07-01 11:43:55] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:43:55] Training started
[2023-07-01 11:43:55] Training finished
[2023-07-01 11:43:58] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:43:58] [marian] Running on node20.datos.cluster.uy as process 20529 with command line:
[2023-07-01 11:43:58] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 155 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:43:58] [config] after: 0e
[2023-07-01 11:43:58] [config] after-batches: 0
[2023-07-01 11:43:58] [config] after-epochs: 155
[2023-07-01 11:43:58] [config] all-caps-every: 0
[2023-07-01 11:43:58] [config] allow-unk: false
[2023-07-01 11:43:58] [config] authors: false
[2023-07-01 11:43:58] [config] beam-size: 12
[2023-07-01 11:43:58] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:43:58] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:43:58] [config] bert-masking-fraction: 0.15
[2023-07-01 11:43:58] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:43:58] [config] bert-train-type-embeddings: true
[2023-07-01 11:43:58] [config] bert-type-vocab-size: 2
[2023-07-01 11:43:58] [config] build-info: ""
[2023-07-01 11:43:58] [config] check-gradient-nan: false
[2023-07-01 11:43:58] [config] check-nan: false
[2023-07-01 11:43:58] [config] cite: false
[2023-07-01 11:43:58] [config] clip-norm: 5
[2023-07-01 11:43:58] [config] cost-scaling:
[2023-07-01 11:43:58] [config]   []
[2023-07-01 11:43:58] [config] cost-type: ce-sum
[2023-07-01 11:43:58] [config] cpu-threads: 0
[2023-07-01 11:43:58] [config] data-threads: 8
[2023-07-01 11:43:58] [config] data-weighting: ""
[2023-07-01 11:43:58] [config] data-weighting-type: sentence
[2023-07-01 11:43:58] [config] dec-cell: gru
[2023-07-01 11:43:58] [config] dec-cell-base-depth: 2
[2023-07-01 11:43:58] [config] dec-cell-high-depth: 1
[2023-07-01 11:43:58] [config] dec-depth: 2
[2023-07-01 11:43:58] [config] devices:
[2023-07-01 11:43:58] [config]   - 0
[2023-07-01 11:43:58] [config] dim-emb: 512
[2023-07-01 11:43:58] [config] dim-rnn: 1024
[2023-07-01 11:43:58] [config] dim-vocabs:
[2023-07-01 11:43:58] [config]   - 16384
[2023-07-01 11:43:58] [config]   - 16384
[2023-07-01 11:43:58] [config] disp-first: 0
[2023-07-01 11:43:58] [config] disp-freq: 1000u
[2023-07-01 11:43:58] [config] disp-label-counts: true
[2023-07-01 11:43:58] [config] dropout-rnn: 0
[2023-07-01 11:43:58] [config] dropout-src: 0
[2023-07-01 11:43:58] [config] dropout-trg: 0
[2023-07-01 11:43:58] [config] dump-config: ""
[2023-07-01 11:43:58] [config] dynamic-gradient-scaling:
[2023-07-01 11:43:58] [config]   []
[2023-07-01 11:43:58] [config] early-stopping: 10
[2023-07-01 11:43:58] [config] early-stopping-on: first
[2023-07-01 11:43:58] [config] embedding-fix-src: false
[2023-07-01 11:43:58] [config] embedding-fix-trg: false
[2023-07-01 11:43:58] [config] embedding-normalization: false
[2023-07-01 11:43:58] [config] embedding-vectors:
[2023-07-01 11:43:58] [config]   []
[2023-07-01 11:43:58] [config] enc-cell: gru
[2023-07-01 11:43:58] [config] enc-cell-depth: 1
[2023-07-01 11:43:58] [config] enc-depth: 2
[2023-07-01 11:43:58] [config] enc-type: bidirectional
[2023-07-01 11:43:58] [config] english-title-case-every: 0
[2023-07-01 11:43:58] [config] exponential-smoothing: 0.0001
[2023-07-01 11:43:58] [config] factor-weight: 1
[2023-07-01 11:43:58] [config] factors-combine: sum
[2023-07-01 11:43:58] [config] factors-dim-emb: 0
[2023-07-01 11:43:58] [config] gradient-checkpointing: false
[2023-07-01 11:43:58] [config] gradient-norm-average-window: 100
[2023-07-01 11:43:58] [config] guided-alignment: none
[2023-07-01 11:43:58] [config] guided-alignment-cost: mse
[2023-07-01 11:43:58] [config] guided-alignment-weight: 0.1
[2023-07-01 11:43:58] [config] ignore-model-config: false
[2023-07-01 11:43:58] [config] input-types:
[2023-07-01 11:43:58] [config]   []
[2023-07-01 11:43:58] [config] interpolate-env-vars: false
[2023-07-01 11:43:58] [config] keep-best: false
[2023-07-01 11:43:58] [config] label-smoothing: 0.1
[2023-07-01 11:43:58] [config] layer-normalization: false
[2023-07-01 11:43:58] [config] learn-rate: 0.0003
[2023-07-01 11:43:58] [config] lemma-dependency: ""
[2023-07-01 11:43:58] [config] lemma-dim-emb: 0
[2023-07-01 11:43:58] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:43:58] [config] log-level: info
[2023-07-01 11:43:58] [config] log-time-zone: ""
[2023-07-01 11:43:58] [config] logical-epoch:
[2023-07-01 11:43:58] [config]   - 1e
[2023-07-01 11:43:58] [config]   - 0
[2023-07-01 11:43:58] [config] lr-decay: 0
[2023-07-01 11:43:58] [config] lr-decay-freq: 50000
[2023-07-01 11:43:58] [config] lr-decay-inv-sqrt:
[2023-07-01 11:43:58] [config]   - 16000
[2023-07-01 11:43:58] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:43:58] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:43:58] [config] lr-decay-start:
[2023-07-01 11:43:58] [config]   - 10
[2023-07-01 11:43:58] [config]   - 1
[2023-07-01 11:43:58] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:43:58] [config] lr-report: true
[2023-07-01 11:43:58] [config] lr-warmup: 16000
[2023-07-01 11:43:58] [config] lr-warmup-at-reload: false
[2023-07-01 11:43:58] [config] lr-warmup-cycle: false
[2023-07-01 11:43:58] [config] lr-warmup-start-rate: 0
[2023-07-01 11:43:58] [config] max-length: 100
[2023-07-01 11:43:58] [config] max-length-crop: false
[2023-07-01 11:43:58] [config] max-length-factor: 3
[2023-07-01 11:43:58] [config] maxi-batch: 100
[2023-07-01 11:43:58] [config] maxi-batch-sort: trg
[2023-07-01 11:43:58] [config] mini-batch: 1000
[2023-07-01 11:43:58] [config] mini-batch-fit: true
[2023-07-01 11:43:58] [config] mini-batch-fit-step: 10
[2023-07-01 11:43:58] [config] mini-batch-round-up: true
[2023-07-01 11:43:58] [config] mini-batch-track-lr: false
[2023-07-01 11:43:58] [config] mini-batch-warmup: 0
[2023-07-01 11:43:58] [config] mini-batch-words: 0
[2023-07-01 11:43:58] [config] mini-batch-words-ref: 0
[2023-07-01 11:43:58] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:43:58] [config] multi-loss-type: sum
[2023-07-01 11:43:58] [config] n-best: false
[2023-07-01 11:43:58] [config] no-nccl: false
[2023-07-01 11:43:58] [config] no-reload: false
[2023-07-01 11:43:58] [config] no-restore-corpus: false
[2023-07-01 11:43:58] [config] normalize: 1
[2023-07-01 11:43:58] [config] normalize-gradient: false
[2023-07-01 11:43:58] [config] num-devices: 0
[2023-07-01 11:43:58] [config] optimizer: adam
[2023-07-01 11:43:58] [config] optimizer-delay: 1
[2023-07-01 11:43:58] [config] optimizer-params:
[2023-07-01 11:43:58] [config]   - 0.9
[2023-07-01 11:43:58] [config]   - 0.98
[2023-07-01 11:43:58] [config]   - 1e-09
[2023-07-01 11:43:58] [config] output-omit-bias: false
[2023-07-01 11:43:58] [config] overwrite: true
[2023-07-01 11:43:58] [config] precision:
[2023-07-01 11:43:58] [config]   - float32
[2023-07-01 11:43:58] [config]   - float32
[2023-07-01 11:43:58] [config] pretrained-model: ""
[2023-07-01 11:43:58] [config] quantize-biases: false
[2023-07-01 11:43:58] [config] quantize-bits: 0
[2023-07-01 11:43:58] [config] quantize-log-based: false
[2023-07-01 11:43:58] [config] quantize-optimization-steps: 0
[2023-07-01 11:43:58] [config] quiet: false
[2023-07-01 11:43:58] [config] quiet-translation: true
[2023-07-01 11:43:58] [config] relative-paths: false
[2023-07-01 11:43:58] [config] right-left: false
[2023-07-01 11:43:58] [config] save-freq: 10000u
[2023-07-01 11:43:58] [config] seed: 1234
[2023-07-01 11:43:58] [config] sentencepiece-alphas:
[2023-07-01 11:43:58] [config]   []
[2023-07-01 11:43:58] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:43:58] [config] sentencepiece-options: ""
[2023-07-01 11:43:58] [config] sharding: global
[2023-07-01 11:43:58] [config] shuffle: data
[2023-07-01 11:43:58] [config] shuffle-in-ram: false
[2023-07-01 11:43:58] [config] sigterm: save-and-exit
[2023-07-01 11:43:58] [config] skip: false
[2023-07-01 11:43:58] [config] sqlite: ""
[2023-07-01 11:43:58] [config] sqlite-drop: false
[2023-07-01 11:43:58] [config] sync-freq: 200u
[2023-07-01 11:43:58] [config] sync-sgd: true
[2023-07-01 11:43:58] [config] tempdir: /tmp
[2023-07-01 11:43:58] [config] tied-embeddings: false
[2023-07-01 11:43:58] [config] tied-embeddings-all: true
[2023-07-01 11:43:58] [config] tied-embeddings-src: false
[2023-07-01 11:43:58] [config] train-embedder-rank:
[2023-07-01 11:43:58] [config]   []
[2023-07-01 11:43:58] [config] train-sets:
[2023-07-01 11:43:58] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:43:58] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:43:58] [config] transformer-aan-activation: swish
[2023-07-01 11:43:58] [config] transformer-aan-depth: 2
[2023-07-01 11:43:58] [config] transformer-aan-nogate: false
[2023-07-01 11:43:58] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:43:58] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:43:58] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:43:58] [config] transformer-depth-scaling: false
[2023-07-01 11:43:58] [config] transformer-dim-aan: 2048
[2023-07-01 11:43:58] [config] transformer-dim-ffn: 2048
[2023-07-01 11:43:58] [config] transformer-dropout: 0.1
[2023-07-01 11:43:58] [config] transformer-dropout-attention: 0
[2023-07-01 11:43:58] [config] transformer-dropout-ffn: 0
[2023-07-01 11:43:58] [config] transformer-ffn-activation: swish
[2023-07-01 11:43:58] [config] transformer-ffn-depth: 2
[2023-07-01 11:43:58] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:43:58] [config] transformer-heads: 8
[2023-07-01 11:43:58] [config] transformer-no-projection: false
[2023-07-01 11:43:58] [config] transformer-pool: false
[2023-07-01 11:43:58] [config] transformer-postprocess: dan
[2023-07-01 11:43:58] [config] transformer-postprocess-emb: d
[2023-07-01 11:43:58] [config] transformer-postprocess-top: ""
[2023-07-01 11:43:58] [config] transformer-preprocess: ""
[2023-07-01 11:43:58] [config] transformer-tied-layers:
[2023-07-01 11:43:58] [config]   []
[2023-07-01 11:43:58] [config] transformer-train-position-embeddings: false
[2023-07-01 11:43:58] [config] tsv: false
[2023-07-01 11:43:58] [config] tsv-fields: 0
[2023-07-01 11:43:58] [config] type: transformer
[2023-07-01 11:43:58] [config] ulr: false
[2023-07-01 11:43:58] [config] ulr-dim-emb: 0
[2023-07-01 11:43:58] [config] ulr-dropout: 0
[2023-07-01 11:43:58] [config] ulr-keys-vectors: ""
[2023-07-01 11:43:58] [config] ulr-query-vectors: ""
[2023-07-01 11:43:58] [config] ulr-softmax-temperature: 1
[2023-07-01 11:43:58] [config] ulr-trainable-transformation: false
[2023-07-01 11:43:58] [config] unlikelihood-loss: false
[2023-07-01 11:43:58] [config] valid-freq: 50000000
[2023-07-01 11:43:58] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:43:58] [config] valid-max-length: 1000
[2023-07-01 11:43:58] [config] valid-metrics:
[2023-07-01 11:43:58] [config]   - cross-entropy
[2023-07-01 11:43:58] [config]   - translation
[2023-07-01 11:43:58] [config] valid-mini-batch: 64
[2023-07-01 11:43:58] [config] valid-reset-stalled: false
[2023-07-01 11:43:58] [config] valid-script-args:
[2023-07-01 11:43:58] [config]   []
[2023-07-01 11:43:58] [config] valid-script-path: ""
[2023-07-01 11:43:58] [config] valid-sets:
[2023-07-01 11:43:58] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:43:58] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:43:58] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:43:58] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:43:58] [config] vocabs:
[2023-07-01 11:43:58] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:43:58] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:43:58] [config] word-penalty: 0
[2023-07-01 11:43:58] [config] word-scores: false
[2023-07-01 11:43:58] [config] workspace: 2048
[2023-07-01 11:43:58] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:43:58] Using synchronous SGD
[2023-07-01 11:43:58] Synced seed 1234
[2023-07-01 11:43:58] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:43:58] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:43:58] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:43:59] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:43:59] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:43:59] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:43:59] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:43:59] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:43:59] [comm] Using global sharding
[2023-07-01 11:43:59] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:43:59] [training] Using 1 GPUs
[2023-07-01 11:43:59] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:43:59] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:44:00] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:44:00] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:44:07] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:44:07] [valid] No post-processing script given for validating translator
[2023-07-01 11:44:07] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:44:07] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:44:07] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:44:07] [comm] Using global sharding
[2023-07-01 11:44:07] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:44:07] [training] Using 1 GPUs
[2023-07-01 11:44:07] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:44:08] Allocating memory for general optimizer shards
[2023-07-01 11:44:08] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:44:08] Loading Adam parameters
[2023-07-01 11:44:08] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:44:08] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:44:08] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:44:08] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:44:08] [data] Shuffling data
[2023-07-01 11:44:08] [data] Done reading 20,192 sentences
[2023-07-01 11:44:08] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:44:08] Training started
[2023-07-01 11:44:08] Training finished
[2023-07-01 11:44:12] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:44:12] [marian] Running on node20.datos.cluster.uy as process 20588 with command line:
[2023-07-01 11:44:12] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 156 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:44:12] [config] after: 0e
[2023-07-01 11:44:12] [config] after-batches: 0
[2023-07-01 11:44:12] [config] after-epochs: 156
[2023-07-01 11:44:12] [config] all-caps-every: 0
[2023-07-01 11:44:12] [config] allow-unk: false
[2023-07-01 11:44:12] [config] authors: false
[2023-07-01 11:44:12] [config] beam-size: 12
[2023-07-01 11:44:12] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:44:12] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:44:12] [config] bert-masking-fraction: 0.15
[2023-07-01 11:44:12] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:44:12] [config] bert-train-type-embeddings: true
[2023-07-01 11:44:12] [config] bert-type-vocab-size: 2
[2023-07-01 11:44:12] [config] build-info: ""
[2023-07-01 11:44:12] [config] check-gradient-nan: false
[2023-07-01 11:44:12] [config] check-nan: false
[2023-07-01 11:44:12] [config] cite: false
[2023-07-01 11:44:12] [config] clip-norm: 5
[2023-07-01 11:44:12] [config] cost-scaling:
[2023-07-01 11:44:12] [config]   []
[2023-07-01 11:44:12] [config] cost-type: ce-sum
[2023-07-01 11:44:12] [config] cpu-threads: 0
[2023-07-01 11:44:12] [config] data-threads: 8
[2023-07-01 11:44:12] [config] data-weighting: ""
[2023-07-01 11:44:12] [config] data-weighting-type: sentence
[2023-07-01 11:44:12] [config] dec-cell: gru
[2023-07-01 11:44:12] [config] dec-cell-base-depth: 2
[2023-07-01 11:44:12] [config] dec-cell-high-depth: 1
[2023-07-01 11:44:12] [config] dec-depth: 2
[2023-07-01 11:44:12] [config] devices:
[2023-07-01 11:44:12] [config]   - 0
[2023-07-01 11:44:12] [config] dim-emb: 512
[2023-07-01 11:44:12] [config] dim-rnn: 1024
[2023-07-01 11:44:12] [config] dim-vocabs:
[2023-07-01 11:44:12] [config]   - 16384
[2023-07-01 11:44:12] [config]   - 16384
[2023-07-01 11:44:12] [config] disp-first: 0
[2023-07-01 11:44:12] [config] disp-freq: 1000u
[2023-07-01 11:44:12] [config] disp-label-counts: true
[2023-07-01 11:44:12] [config] dropout-rnn: 0
[2023-07-01 11:44:12] [config] dropout-src: 0
[2023-07-01 11:44:12] [config] dropout-trg: 0
[2023-07-01 11:44:12] [config] dump-config: ""
[2023-07-01 11:44:12] [config] dynamic-gradient-scaling:
[2023-07-01 11:44:12] [config]   []
[2023-07-01 11:44:12] [config] early-stopping: 10
[2023-07-01 11:44:12] [config] early-stopping-on: first
[2023-07-01 11:44:12] [config] embedding-fix-src: false
[2023-07-01 11:44:12] [config] embedding-fix-trg: false
[2023-07-01 11:44:12] [config] embedding-normalization: false
[2023-07-01 11:44:12] [config] embedding-vectors:
[2023-07-01 11:44:12] [config]   []
[2023-07-01 11:44:12] [config] enc-cell: gru
[2023-07-01 11:44:12] [config] enc-cell-depth: 1
[2023-07-01 11:44:12] [config] enc-depth: 2
[2023-07-01 11:44:12] [config] enc-type: bidirectional
[2023-07-01 11:44:12] [config] english-title-case-every: 0
[2023-07-01 11:44:12] [config] exponential-smoothing: 0.0001
[2023-07-01 11:44:12] [config] factor-weight: 1
[2023-07-01 11:44:12] [config] factors-combine: sum
[2023-07-01 11:44:12] [config] factors-dim-emb: 0
[2023-07-01 11:44:12] [config] gradient-checkpointing: false
[2023-07-01 11:44:12] [config] gradient-norm-average-window: 100
[2023-07-01 11:44:12] [config] guided-alignment: none
[2023-07-01 11:44:12] [config] guided-alignment-cost: mse
[2023-07-01 11:44:12] [config] guided-alignment-weight: 0.1
[2023-07-01 11:44:12] [config] ignore-model-config: false
[2023-07-01 11:44:12] [config] input-types:
[2023-07-01 11:44:12] [config]   []
[2023-07-01 11:44:12] [config] interpolate-env-vars: false
[2023-07-01 11:44:12] [config] keep-best: false
[2023-07-01 11:44:12] [config] label-smoothing: 0.1
[2023-07-01 11:44:12] [config] layer-normalization: false
[2023-07-01 11:44:12] [config] learn-rate: 0.0003
[2023-07-01 11:44:12] [config] lemma-dependency: ""
[2023-07-01 11:44:12] [config] lemma-dim-emb: 0
[2023-07-01 11:44:12] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:44:12] [config] log-level: info
[2023-07-01 11:44:12] [config] log-time-zone: ""
[2023-07-01 11:44:12] [config] logical-epoch:
[2023-07-01 11:44:12] [config]   - 1e
[2023-07-01 11:44:12] [config]   - 0
[2023-07-01 11:44:12] [config] lr-decay: 0
[2023-07-01 11:44:12] [config] lr-decay-freq: 50000
[2023-07-01 11:44:12] [config] lr-decay-inv-sqrt:
[2023-07-01 11:44:12] [config]   - 16000
[2023-07-01 11:44:12] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:44:12] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:44:12] [config] lr-decay-start:
[2023-07-01 11:44:12] [config]   - 10
[2023-07-01 11:44:12] [config]   - 1
[2023-07-01 11:44:12] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:44:12] [config] lr-report: true
[2023-07-01 11:44:12] [config] lr-warmup: 16000
[2023-07-01 11:44:12] [config] lr-warmup-at-reload: false
[2023-07-01 11:44:12] [config] lr-warmup-cycle: false
[2023-07-01 11:44:12] [config] lr-warmup-start-rate: 0
[2023-07-01 11:44:12] [config] max-length: 100
[2023-07-01 11:44:12] [config] max-length-crop: false
[2023-07-01 11:44:12] [config] max-length-factor: 3
[2023-07-01 11:44:12] [config] maxi-batch: 100
[2023-07-01 11:44:12] [config] maxi-batch-sort: trg
[2023-07-01 11:44:12] [config] mini-batch: 1000
[2023-07-01 11:44:12] [config] mini-batch-fit: true
[2023-07-01 11:44:12] [config] mini-batch-fit-step: 10
[2023-07-01 11:44:12] [config] mini-batch-round-up: true
[2023-07-01 11:44:12] [config] mini-batch-track-lr: false
[2023-07-01 11:44:12] [config] mini-batch-warmup: 0
[2023-07-01 11:44:12] [config] mini-batch-words: 0
[2023-07-01 11:44:12] [config] mini-batch-words-ref: 0
[2023-07-01 11:44:12] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:44:12] [config] multi-loss-type: sum
[2023-07-01 11:44:12] [config] n-best: false
[2023-07-01 11:44:12] [config] no-nccl: false
[2023-07-01 11:44:12] [config] no-reload: false
[2023-07-01 11:44:12] [config] no-restore-corpus: false
[2023-07-01 11:44:12] [config] normalize: 1
[2023-07-01 11:44:12] [config] normalize-gradient: false
[2023-07-01 11:44:12] [config] num-devices: 0
[2023-07-01 11:44:12] [config] optimizer: adam
[2023-07-01 11:44:12] [config] optimizer-delay: 1
[2023-07-01 11:44:12] [config] optimizer-params:
[2023-07-01 11:44:12] [config]   - 0.9
[2023-07-01 11:44:12] [config]   - 0.98
[2023-07-01 11:44:12] [config]   - 1e-09
[2023-07-01 11:44:12] [config] output-omit-bias: false
[2023-07-01 11:44:12] [config] overwrite: true
[2023-07-01 11:44:12] [config] precision:
[2023-07-01 11:44:12] [config]   - float32
[2023-07-01 11:44:12] [config]   - float32
[2023-07-01 11:44:12] [config] pretrained-model: ""
[2023-07-01 11:44:12] [config] quantize-biases: false
[2023-07-01 11:44:12] [config] quantize-bits: 0
[2023-07-01 11:44:12] [config] quantize-log-based: false
[2023-07-01 11:44:12] [config] quantize-optimization-steps: 0
[2023-07-01 11:44:12] [config] quiet: false
[2023-07-01 11:44:12] [config] quiet-translation: true
[2023-07-01 11:44:12] [config] relative-paths: false
[2023-07-01 11:44:12] [config] right-left: false
[2023-07-01 11:44:12] [config] save-freq: 10000u
[2023-07-01 11:44:12] [config] seed: 1234
[2023-07-01 11:44:12] [config] sentencepiece-alphas:
[2023-07-01 11:44:12] [config]   []
[2023-07-01 11:44:12] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:44:12] [config] sentencepiece-options: ""
[2023-07-01 11:44:12] [config] sharding: global
[2023-07-01 11:44:12] [config] shuffle: data
[2023-07-01 11:44:12] [config] shuffle-in-ram: false
[2023-07-01 11:44:12] [config] sigterm: save-and-exit
[2023-07-01 11:44:12] [config] skip: false
[2023-07-01 11:44:12] [config] sqlite: ""
[2023-07-01 11:44:12] [config] sqlite-drop: false
[2023-07-01 11:44:12] [config] sync-freq: 200u
[2023-07-01 11:44:12] [config] sync-sgd: true
[2023-07-01 11:44:12] [config] tempdir: /tmp
[2023-07-01 11:44:12] [config] tied-embeddings: false
[2023-07-01 11:44:12] [config] tied-embeddings-all: true
[2023-07-01 11:44:12] [config] tied-embeddings-src: false
[2023-07-01 11:44:12] [config] train-embedder-rank:
[2023-07-01 11:44:12] [config]   []
[2023-07-01 11:44:12] [config] train-sets:
[2023-07-01 11:44:12] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:44:12] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:44:12] [config] transformer-aan-activation: swish
[2023-07-01 11:44:12] [config] transformer-aan-depth: 2
[2023-07-01 11:44:12] [config] transformer-aan-nogate: false
[2023-07-01 11:44:12] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:44:12] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:44:12] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:44:12] [config] transformer-depth-scaling: false
[2023-07-01 11:44:12] [config] transformer-dim-aan: 2048
[2023-07-01 11:44:12] [config] transformer-dim-ffn: 2048
[2023-07-01 11:44:12] [config] transformer-dropout: 0.1
[2023-07-01 11:44:12] [config] transformer-dropout-attention: 0
[2023-07-01 11:44:12] [config] transformer-dropout-ffn: 0
[2023-07-01 11:44:12] [config] transformer-ffn-activation: swish
[2023-07-01 11:44:12] [config] transformer-ffn-depth: 2
[2023-07-01 11:44:12] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:44:12] [config] transformer-heads: 8
[2023-07-01 11:44:12] [config] transformer-no-projection: false
[2023-07-01 11:44:12] [config] transformer-pool: false
[2023-07-01 11:44:12] [config] transformer-postprocess: dan
[2023-07-01 11:44:12] [config] transformer-postprocess-emb: d
[2023-07-01 11:44:12] [config] transformer-postprocess-top: ""
[2023-07-01 11:44:12] [config] transformer-preprocess: ""
[2023-07-01 11:44:12] [config] transformer-tied-layers:
[2023-07-01 11:44:12] [config]   []
[2023-07-01 11:44:12] [config] transformer-train-position-embeddings: false
[2023-07-01 11:44:12] [config] tsv: false
[2023-07-01 11:44:12] [config] tsv-fields: 0
[2023-07-01 11:44:12] [config] type: transformer
[2023-07-01 11:44:12] [config] ulr: false
[2023-07-01 11:44:12] [config] ulr-dim-emb: 0
[2023-07-01 11:44:12] [config] ulr-dropout: 0
[2023-07-01 11:44:12] [config] ulr-keys-vectors: ""
[2023-07-01 11:44:12] [config] ulr-query-vectors: ""
[2023-07-01 11:44:12] [config] ulr-softmax-temperature: 1
[2023-07-01 11:44:12] [config] ulr-trainable-transformation: false
[2023-07-01 11:44:12] [config] unlikelihood-loss: false
[2023-07-01 11:44:12] [config] valid-freq: 50000000
[2023-07-01 11:44:12] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:44:12] [config] valid-max-length: 1000
[2023-07-01 11:44:12] [config] valid-metrics:
[2023-07-01 11:44:12] [config]   - cross-entropy
[2023-07-01 11:44:12] [config]   - translation
[2023-07-01 11:44:12] [config] valid-mini-batch: 64
[2023-07-01 11:44:12] [config] valid-reset-stalled: false
[2023-07-01 11:44:12] [config] valid-script-args:
[2023-07-01 11:44:12] [config]   []
[2023-07-01 11:44:12] [config] valid-script-path: ""
[2023-07-01 11:44:12] [config] valid-sets:
[2023-07-01 11:44:12] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:44:12] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:44:12] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:44:12] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:44:12] [config] vocabs:
[2023-07-01 11:44:12] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:44:12] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:44:12] [config] word-penalty: 0
[2023-07-01 11:44:12] [config] word-scores: false
[2023-07-01 11:44:12] [config] workspace: 2048
[2023-07-01 11:44:12] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:44:12] Using synchronous SGD
[2023-07-01 11:44:12] Synced seed 1234
[2023-07-01 11:44:12] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:44:12] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:44:12] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:44:12] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:44:12] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:44:12] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:44:13] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:44:13] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:44:13] [comm] Using global sharding
[2023-07-01 11:44:13] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:44:13] [training] Using 1 GPUs
[2023-07-01 11:44:13] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:44:13] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:44:13] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:44:13] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:44:21] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:44:21] [valid] No post-processing script given for validating translator
[2023-07-01 11:44:21] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:44:21] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:44:21] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:44:21] [comm] Using global sharding
[2023-07-01 11:44:21] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:44:21] [training] Using 1 GPUs
[2023-07-01 11:44:21] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:44:21] Allocating memory for general optimizer shards
[2023-07-01 11:44:21] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:44:21] Loading Adam parameters
[2023-07-01 11:44:21] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:44:21] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:44:21] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:44:21] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:44:21] [data] Shuffling data
[2023-07-01 11:44:21] [data] Done reading 20,192 sentences
[2023-07-01 11:44:22] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:44:22] Training started
[2023-07-01 11:44:22] Training finished
[2023-07-01 11:44:25] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:44:25] [marian] Running on node20.datos.cluster.uy as process 20646 with command line:
[2023-07-01 11:44:25] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 157 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:44:25] [config] after: 0e
[2023-07-01 11:44:25] [config] after-batches: 0
[2023-07-01 11:44:25] [config] after-epochs: 157
[2023-07-01 11:44:25] [config] all-caps-every: 0
[2023-07-01 11:44:25] [config] allow-unk: false
[2023-07-01 11:44:25] [config] authors: false
[2023-07-01 11:44:25] [config] beam-size: 12
[2023-07-01 11:44:25] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:44:25] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:44:25] [config] bert-masking-fraction: 0.15
[2023-07-01 11:44:25] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:44:25] [config] bert-train-type-embeddings: true
[2023-07-01 11:44:25] [config] bert-type-vocab-size: 2
[2023-07-01 11:44:25] [config] build-info: ""
[2023-07-01 11:44:25] [config] check-gradient-nan: false
[2023-07-01 11:44:25] [config] check-nan: false
[2023-07-01 11:44:25] [config] cite: false
[2023-07-01 11:44:25] [config] clip-norm: 5
[2023-07-01 11:44:25] [config] cost-scaling:
[2023-07-01 11:44:25] [config]   []
[2023-07-01 11:44:25] [config] cost-type: ce-sum
[2023-07-01 11:44:25] [config] cpu-threads: 0
[2023-07-01 11:44:25] [config] data-threads: 8
[2023-07-01 11:44:25] [config] data-weighting: ""
[2023-07-01 11:44:25] [config] data-weighting-type: sentence
[2023-07-01 11:44:25] [config] dec-cell: gru
[2023-07-01 11:44:25] [config] dec-cell-base-depth: 2
[2023-07-01 11:44:25] [config] dec-cell-high-depth: 1
[2023-07-01 11:44:25] [config] dec-depth: 2
[2023-07-01 11:44:25] [config] devices:
[2023-07-01 11:44:25] [config]   - 0
[2023-07-01 11:44:25] [config] dim-emb: 512
[2023-07-01 11:44:25] [config] dim-rnn: 1024
[2023-07-01 11:44:25] [config] dim-vocabs:
[2023-07-01 11:44:25] [config]   - 16384
[2023-07-01 11:44:25] [config]   - 16384
[2023-07-01 11:44:25] [config] disp-first: 0
[2023-07-01 11:44:25] [config] disp-freq: 1000u
[2023-07-01 11:44:25] [config] disp-label-counts: true
[2023-07-01 11:44:25] [config] dropout-rnn: 0
[2023-07-01 11:44:25] [config] dropout-src: 0
[2023-07-01 11:44:25] [config] dropout-trg: 0
[2023-07-01 11:44:25] [config] dump-config: ""
[2023-07-01 11:44:25] [config] dynamic-gradient-scaling:
[2023-07-01 11:44:25] [config]   []
[2023-07-01 11:44:25] [config] early-stopping: 10
[2023-07-01 11:44:25] [config] early-stopping-on: first
[2023-07-01 11:44:25] [config] embedding-fix-src: false
[2023-07-01 11:44:25] [config] embedding-fix-trg: false
[2023-07-01 11:44:25] [config] embedding-normalization: false
[2023-07-01 11:44:25] [config] embedding-vectors:
[2023-07-01 11:44:25] [config]   []
[2023-07-01 11:44:25] [config] enc-cell: gru
[2023-07-01 11:44:25] [config] enc-cell-depth: 1
[2023-07-01 11:44:25] [config] enc-depth: 2
[2023-07-01 11:44:25] [config] enc-type: bidirectional
[2023-07-01 11:44:25] [config] english-title-case-every: 0
[2023-07-01 11:44:25] [config] exponential-smoothing: 0.0001
[2023-07-01 11:44:25] [config] factor-weight: 1
[2023-07-01 11:44:25] [config] factors-combine: sum
[2023-07-01 11:44:25] [config] factors-dim-emb: 0
[2023-07-01 11:44:25] [config] gradient-checkpointing: false
[2023-07-01 11:44:25] [config] gradient-norm-average-window: 100
[2023-07-01 11:44:25] [config] guided-alignment: none
[2023-07-01 11:44:25] [config] guided-alignment-cost: mse
[2023-07-01 11:44:25] [config] guided-alignment-weight: 0.1
[2023-07-01 11:44:25] [config] ignore-model-config: false
[2023-07-01 11:44:25] [config] input-types:
[2023-07-01 11:44:25] [config]   []
[2023-07-01 11:44:25] [config] interpolate-env-vars: false
[2023-07-01 11:44:25] [config] keep-best: false
[2023-07-01 11:44:25] [config] label-smoothing: 0.1
[2023-07-01 11:44:25] [config] layer-normalization: false
[2023-07-01 11:44:25] [config] learn-rate: 0.0003
[2023-07-01 11:44:25] [config] lemma-dependency: ""
[2023-07-01 11:44:25] [config] lemma-dim-emb: 0
[2023-07-01 11:44:25] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:44:25] [config] log-level: info
[2023-07-01 11:44:25] [config] log-time-zone: ""
[2023-07-01 11:44:25] [config] logical-epoch:
[2023-07-01 11:44:25] [config]   - 1e
[2023-07-01 11:44:25] [config]   - 0
[2023-07-01 11:44:25] [config] lr-decay: 0
[2023-07-01 11:44:25] [config] lr-decay-freq: 50000
[2023-07-01 11:44:25] [config] lr-decay-inv-sqrt:
[2023-07-01 11:44:25] [config]   - 16000
[2023-07-01 11:44:25] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:44:25] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:44:25] [config] lr-decay-start:
[2023-07-01 11:44:25] [config]   - 10
[2023-07-01 11:44:25] [config]   - 1
[2023-07-01 11:44:25] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:44:25] [config] lr-report: true
[2023-07-01 11:44:25] [config] lr-warmup: 16000
[2023-07-01 11:44:25] [config] lr-warmup-at-reload: false
[2023-07-01 11:44:25] [config] lr-warmup-cycle: false
[2023-07-01 11:44:25] [config] lr-warmup-start-rate: 0
[2023-07-01 11:44:25] [config] max-length: 100
[2023-07-01 11:44:25] [config] max-length-crop: false
[2023-07-01 11:44:25] [config] max-length-factor: 3
[2023-07-01 11:44:25] [config] maxi-batch: 100
[2023-07-01 11:44:25] [config] maxi-batch-sort: trg
[2023-07-01 11:44:25] [config] mini-batch: 1000
[2023-07-01 11:44:25] [config] mini-batch-fit: true
[2023-07-01 11:44:25] [config] mini-batch-fit-step: 10
[2023-07-01 11:44:25] [config] mini-batch-round-up: true
[2023-07-01 11:44:25] [config] mini-batch-track-lr: false
[2023-07-01 11:44:25] [config] mini-batch-warmup: 0
[2023-07-01 11:44:25] [config] mini-batch-words: 0
[2023-07-01 11:44:25] [config] mini-batch-words-ref: 0
[2023-07-01 11:44:25] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:44:25] [config] multi-loss-type: sum
[2023-07-01 11:44:25] [config] n-best: false
[2023-07-01 11:44:25] [config] no-nccl: false
[2023-07-01 11:44:25] [config] no-reload: false
[2023-07-01 11:44:25] [config] no-restore-corpus: false
[2023-07-01 11:44:25] [config] normalize: 1
[2023-07-01 11:44:25] [config] normalize-gradient: false
[2023-07-01 11:44:25] [config] num-devices: 0
[2023-07-01 11:44:25] [config] optimizer: adam
[2023-07-01 11:44:25] [config] optimizer-delay: 1
[2023-07-01 11:44:25] [config] optimizer-params:
[2023-07-01 11:44:25] [config]   - 0.9
[2023-07-01 11:44:25] [config]   - 0.98
[2023-07-01 11:44:25] [config]   - 1e-09
[2023-07-01 11:44:25] [config] output-omit-bias: false
[2023-07-01 11:44:25] [config] overwrite: true
[2023-07-01 11:44:25] [config] precision:
[2023-07-01 11:44:25] [config]   - float32
[2023-07-01 11:44:25] [config]   - float32
[2023-07-01 11:44:25] [config] pretrained-model: ""
[2023-07-01 11:44:25] [config] quantize-biases: false
[2023-07-01 11:44:25] [config] quantize-bits: 0
[2023-07-01 11:44:25] [config] quantize-log-based: false
[2023-07-01 11:44:25] [config] quantize-optimization-steps: 0
[2023-07-01 11:44:25] [config] quiet: false
[2023-07-01 11:44:25] [config] quiet-translation: true
[2023-07-01 11:44:25] [config] relative-paths: false
[2023-07-01 11:44:25] [config] right-left: false
[2023-07-01 11:44:25] [config] save-freq: 10000u
[2023-07-01 11:44:25] [config] seed: 1234
[2023-07-01 11:44:25] [config] sentencepiece-alphas:
[2023-07-01 11:44:25] [config]   []
[2023-07-01 11:44:25] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:44:25] [config] sentencepiece-options: ""
[2023-07-01 11:44:25] [config] sharding: global
[2023-07-01 11:44:25] [config] shuffle: data
[2023-07-01 11:44:25] [config] shuffle-in-ram: false
[2023-07-01 11:44:25] [config] sigterm: save-and-exit
[2023-07-01 11:44:25] [config] skip: false
[2023-07-01 11:44:25] [config] sqlite: ""
[2023-07-01 11:44:25] [config] sqlite-drop: false
[2023-07-01 11:44:25] [config] sync-freq: 200u
[2023-07-01 11:44:25] [config] sync-sgd: true
[2023-07-01 11:44:25] [config] tempdir: /tmp
[2023-07-01 11:44:25] [config] tied-embeddings: false
[2023-07-01 11:44:25] [config] tied-embeddings-all: true
[2023-07-01 11:44:25] [config] tied-embeddings-src: false
[2023-07-01 11:44:25] [config] train-embedder-rank:
[2023-07-01 11:44:25] [config]   []
[2023-07-01 11:44:25] [config] train-sets:
[2023-07-01 11:44:25] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:44:25] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:44:25] [config] transformer-aan-activation: swish
[2023-07-01 11:44:25] [config] transformer-aan-depth: 2
[2023-07-01 11:44:25] [config] transformer-aan-nogate: false
[2023-07-01 11:44:25] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:44:25] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:44:25] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:44:25] [config] transformer-depth-scaling: false
[2023-07-01 11:44:25] [config] transformer-dim-aan: 2048
[2023-07-01 11:44:25] [config] transformer-dim-ffn: 2048
[2023-07-01 11:44:25] [config] transformer-dropout: 0.1
[2023-07-01 11:44:25] [config] transformer-dropout-attention: 0
[2023-07-01 11:44:25] [config] transformer-dropout-ffn: 0
[2023-07-01 11:44:25] [config] transformer-ffn-activation: swish
[2023-07-01 11:44:25] [config] transformer-ffn-depth: 2
[2023-07-01 11:44:25] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:44:25] [config] transformer-heads: 8
[2023-07-01 11:44:25] [config] transformer-no-projection: false
[2023-07-01 11:44:25] [config] transformer-pool: false
[2023-07-01 11:44:25] [config] transformer-postprocess: dan
[2023-07-01 11:44:25] [config] transformer-postprocess-emb: d
[2023-07-01 11:44:25] [config] transformer-postprocess-top: ""
[2023-07-01 11:44:25] [config] transformer-preprocess: ""
[2023-07-01 11:44:25] [config] transformer-tied-layers:
[2023-07-01 11:44:25] [config]   []
[2023-07-01 11:44:25] [config] transformer-train-position-embeddings: false
[2023-07-01 11:44:25] [config] tsv: false
[2023-07-01 11:44:25] [config] tsv-fields: 0
[2023-07-01 11:44:25] [config] type: transformer
[2023-07-01 11:44:25] [config] ulr: false
[2023-07-01 11:44:25] [config] ulr-dim-emb: 0
[2023-07-01 11:44:25] [config] ulr-dropout: 0
[2023-07-01 11:44:25] [config] ulr-keys-vectors: ""
[2023-07-01 11:44:25] [config] ulr-query-vectors: ""
[2023-07-01 11:44:25] [config] ulr-softmax-temperature: 1
[2023-07-01 11:44:25] [config] ulr-trainable-transformation: false
[2023-07-01 11:44:25] [config] unlikelihood-loss: false
[2023-07-01 11:44:25] [config] valid-freq: 50000000
[2023-07-01 11:44:25] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:44:25] [config] valid-max-length: 1000
[2023-07-01 11:44:25] [config] valid-metrics:
[2023-07-01 11:44:25] [config]   - cross-entropy
[2023-07-01 11:44:25] [config]   - translation
[2023-07-01 11:44:25] [config] valid-mini-batch: 64
[2023-07-01 11:44:25] [config] valid-reset-stalled: false
[2023-07-01 11:44:25] [config] valid-script-args:
[2023-07-01 11:44:25] [config]   []
[2023-07-01 11:44:25] [config] valid-script-path: ""
[2023-07-01 11:44:25] [config] valid-sets:
[2023-07-01 11:44:25] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:44:25] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:44:25] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:44:25] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:44:25] [config] vocabs:
[2023-07-01 11:44:25] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:44:25] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:44:25] [config] word-penalty: 0
[2023-07-01 11:44:25] [config] word-scores: false
[2023-07-01 11:44:25] [config] workspace: 2048
[2023-07-01 11:44:25] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:44:25] Using synchronous SGD
[2023-07-01 11:44:26] Synced seed 1234
[2023-07-01 11:44:26] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:44:26] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:44:26] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:44:26] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:44:26] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:44:26] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:44:26] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:44:27] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:44:27] [comm] Using global sharding
[2023-07-01 11:44:27] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:44:27] [training] Using 1 GPUs
[2023-07-01 11:44:27] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:44:27] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:44:27] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:44:27] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:44:34] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:44:35] [valid] No post-processing script given for validating translator
[2023-07-01 11:44:35] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:44:35] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:44:35] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:44:35] [comm] Using global sharding
[2023-07-01 11:44:35] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:44:35] [training] Using 1 GPUs
[2023-07-01 11:44:35] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:44:35] Allocating memory for general optimizer shards
[2023-07-01 11:44:35] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:44:35] Loading Adam parameters
[2023-07-01 11:44:35] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:44:35] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:44:35] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:44:35] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:44:35] [data] Shuffling data
[2023-07-01 11:44:35] [data] Done reading 20,192 sentences
[2023-07-01 11:44:35] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:44:35] Training started
[2023-07-01 11:44:35] Training finished
[2023-07-01 11:44:39] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:44:39] [marian] Running on node20.datos.cluster.uy as process 20704 with command line:
[2023-07-01 11:44:39] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 158 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:44:39] [config] after: 0e
[2023-07-01 11:44:39] [config] after-batches: 0
[2023-07-01 11:44:39] [config] after-epochs: 158
[2023-07-01 11:44:39] [config] all-caps-every: 0
[2023-07-01 11:44:39] [config] allow-unk: false
[2023-07-01 11:44:39] [config] authors: false
[2023-07-01 11:44:39] [config] beam-size: 12
[2023-07-01 11:44:39] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:44:39] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:44:39] [config] bert-masking-fraction: 0.15
[2023-07-01 11:44:39] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:44:39] [config] bert-train-type-embeddings: true
[2023-07-01 11:44:39] [config] bert-type-vocab-size: 2
[2023-07-01 11:44:39] [config] build-info: ""
[2023-07-01 11:44:39] [config] check-gradient-nan: false
[2023-07-01 11:44:39] [config] check-nan: false
[2023-07-01 11:44:39] [config] cite: false
[2023-07-01 11:44:39] [config] clip-norm: 5
[2023-07-01 11:44:39] [config] cost-scaling:
[2023-07-01 11:44:39] [config]   []
[2023-07-01 11:44:39] [config] cost-type: ce-sum
[2023-07-01 11:44:39] [config] cpu-threads: 0
[2023-07-01 11:44:39] [config] data-threads: 8
[2023-07-01 11:44:39] [config] data-weighting: ""
[2023-07-01 11:44:39] [config] data-weighting-type: sentence
[2023-07-01 11:44:39] [config] dec-cell: gru
[2023-07-01 11:44:39] [config] dec-cell-base-depth: 2
[2023-07-01 11:44:39] [config] dec-cell-high-depth: 1
[2023-07-01 11:44:39] [config] dec-depth: 2
[2023-07-01 11:44:39] [config] devices:
[2023-07-01 11:44:39] [config]   - 0
[2023-07-01 11:44:39] [config] dim-emb: 512
[2023-07-01 11:44:39] [config] dim-rnn: 1024
[2023-07-01 11:44:39] [config] dim-vocabs:
[2023-07-01 11:44:39] [config]   - 16384
[2023-07-01 11:44:39] [config]   - 16384
[2023-07-01 11:44:39] [config] disp-first: 0
[2023-07-01 11:44:39] [config] disp-freq: 1000u
[2023-07-01 11:44:39] [config] disp-label-counts: true
[2023-07-01 11:44:39] [config] dropout-rnn: 0
[2023-07-01 11:44:39] [config] dropout-src: 0
[2023-07-01 11:44:39] [config] dropout-trg: 0
[2023-07-01 11:44:39] [config] dump-config: ""
[2023-07-01 11:44:39] [config] dynamic-gradient-scaling:
[2023-07-01 11:44:39] [config]   []
[2023-07-01 11:44:39] [config] early-stopping: 10
[2023-07-01 11:44:39] [config] early-stopping-on: first
[2023-07-01 11:44:39] [config] embedding-fix-src: false
[2023-07-01 11:44:39] [config] embedding-fix-trg: false
[2023-07-01 11:44:39] [config] embedding-normalization: false
[2023-07-01 11:44:39] [config] embedding-vectors:
[2023-07-01 11:44:39] [config]   []
[2023-07-01 11:44:39] [config] enc-cell: gru
[2023-07-01 11:44:39] [config] enc-cell-depth: 1
[2023-07-01 11:44:39] [config] enc-depth: 2
[2023-07-01 11:44:39] [config] enc-type: bidirectional
[2023-07-01 11:44:39] [config] english-title-case-every: 0
[2023-07-01 11:44:39] [config] exponential-smoothing: 0.0001
[2023-07-01 11:44:39] [config] factor-weight: 1
[2023-07-01 11:44:39] [config] factors-combine: sum
[2023-07-01 11:44:39] [config] factors-dim-emb: 0
[2023-07-01 11:44:39] [config] gradient-checkpointing: false
[2023-07-01 11:44:39] [config] gradient-norm-average-window: 100
[2023-07-01 11:44:39] [config] guided-alignment: none
[2023-07-01 11:44:39] [config] guided-alignment-cost: mse
[2023-07-01 11:44:39] [config] guided-alignment-weight: 0.1
[2023-07-01 11:44:39] [config] ignore-model-config: false
[2023-07-01 11:44:39] [config] input-types:
[2023-07-01 11:44:39] [config]   []
[2023-07-01 11:44:39] [config] interpolate-env-vars: false
[2023-07-01 11:44:39] [config] keep-best: false
[2023-07-01 11:44:39] [config] label-smoothing: 0.1
[2023-07-01 11:44:39] [config] layer-normalization: false
[2023-07-01 11:44:39] [config] learn-rate: 0.0003
[2023-07-01 11:44:39] [config] lemma-dependency: ""
[2023-07-01 11:44:39] [config] lemma-dim-emb: 0
[2023-07-01 11:44:39] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:44:39] [config] log-level: info
[2023-07-01 11:44:39] [config] log-time-zone: ""
[2023-07-01 11:44:39] [config] logical-epoch:
[2023-07-01 11:44:39] [config]   - 1e
[2023-07-01 11:44:39] [config]   - 0
[2023-07-01 11:44:39] [config] lr-decay: 0
[2023-07-01 11:44:39] [config] lr-decay-freq: 50000
[2023-07-01 11:44:39] [config] lr-decay-inv-sqrt:
[2023-07-01 11:44:39] [config]   - 16000
[2023-07-01 11:44:39] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:44:39] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:44:39] [config] lr-decay-start:
[2023-07-01 11:44:39] [config]   - 10
[2023-07-01 11:44:39] [config]   - 1
[2023-07-01 11:44:39] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:44:39] [config] lr-report: true
[2023-07-01 11:44:39] [config] lr-warmup: 16000
[2023-07-01 11:44:39] [config] lr-warmup-at-reload: false
[2023-07-01 11:44:39] [config] lr-warmup-cycle: false
[2023-07-01 11:44:39] [config] lr-warmup-start-rate: 0
[2023-07-01 11:44:39] [config] max-length: 100
[2023-07-01 11:44:39] [config] max-length-crop: false
[2023-07-01 11:44:39] [config] max-length-factor: 3
[2023-07-01 11:44:39] [config] maxi-batch: 100
[2023-07-01 11:44:39] [config] maxi-batch-sort: trg
[2023-07-01 11:44:39] [config] mini-batch: 1000
[2023-07-01 11:44:39] [config] mini-batch-fit: true
[2023-07-01 11:44:39] [config] mini-batch-fit-step: 10
[2023-07-01 11:44:39] [config] mini-batch-round-up: true
[2023-07-01 11:44:39] [config] mini-batch-track-lr: false
[2023-07-01 11:44:39] [config] mini-batch-warmup: 0
[2023-07-01 11:44:39] [config] mini-batch-words: 0
[2023-07-01 11:44:39] [config] mini-batch-words-ref: 0
[2023-07-01 11:44:39] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:44:39] [config] multi-loss-type: sum
[2023-07-01 11:44:39] [config] n-best: false
[2023-07-01 11:44:39] [config] no-nccl: false
[2023-07-01 11:44:39] [config] no-reload: false
[2023-07-01 11:44:39] [config] no-restore-corpus: false
[2023-07-01 11:44:39] [config] normalize: 1
[2023-07-01 11:44:39] [config] normalize-gradient: false
[2023-07-01 11:44:39] [config] num-devices: 0
[2023-07-01 11:44:39] [config] optimizer: adam
[2023-07-01 11:44:39] [config] optimizer-delay: 1
[2023-07-01 11:44:39] [config] optimizer-params:
[2023-07-01 11:44:39] [config]   - 0.9
[2023-07-01 11:44:39] [config]   - 0.98
[2023-07-01 11:44:39] [config]   - 1e-09
[2023-07-01 11:44:39] [config] output-omit-bias: false
[2023-07-01 11:44:39] [config] overwrite: true
[2023-07-01 11:44:39] [config] precision:
[2023-07-01 11:44:39] [config]   - float32
[2023-07-01 11:44:39] [config]   - float32
[2023-07-01 11:44:39] [config] pretrained-model: ""
[2023-07-01 11:44:39] [config] quantize-biases: false
[2023-07-01 11:44:39] [config] quantize-bits: 0
[2023-07-01 11:44:39] [config] quantize-log-based: false
[2023-07-01 11:44:39] [config] quantize-optimization-steps: 0
[2023-07-01 11:44:39] [config] quiet: false
[2023-07-01 11:44:39] [config] quiet-translation: true
[2023-07-01 11:44:39] [config] relative-paths: false
[2023-07-01 11:44:39] [config] right-left: false
[2023-07-01 11:44:39] [config] save-freq: 10000u
[2023-07-01 11:44:39] [config] seed: 1234
[2023-07-01 11:44:39] [config] sentencepiece-alphas:
[2023-07-01 11:44:39] [config]   []
[2023-07-01 11:44:39] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:44:39] [config] sentencepiece-options: ""
[2023-07-01 11:44:39] [config] sharding: global
[2023-07-01 11:44:39] [config] shuffle: data
[2023-07-01 11:44:39] [config] shuffle-in-ram: false
[2023-07-01 11:44:39] [config] sigterm: save-and-exit
[2023-07-01 11:44:39] [config] skip: false
[2023-07-01 11:44:39] [config] sqlite: ""
[2023-07-01 11:44:39] [config] sqlite-drop: false
[2023-07-01 11:44:39] [config] sync-freq: 200u
[2023-07-01 11:44:39] [config] sync-sgd: true
[2023-07-01 11:44:39] [config] tempdir: /tmp
[2023-07-01 11:44:39] [config] tied-embeddings: false
[2023-07-01 11:44:39] [config] tied-embeddings-all: true
[2023-07-01 11:44:39] [config] tied-embeddings-src: false
[2023-07-01 11:44:39] [config] train-embedder-rank:
[2023-07-01 11:44:39] [config]   []
[2023-07-01 11:44:39] [config] train-sets:
[2023-07-01 11:44:39] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:44:39] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:44:39] [config] transformer-aan-activation: swish
[2023-07-01 11:44:39] [config] transformer-aan-depth: 2
[2023-07-01 11:44:39] [config] transformer-aan-nogate: false
[2023-07-01 11:44:39] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:44:39] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:44:39] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:44:39] [config] transformer-depth-scaling: false
[2023-07-01 11:44:39] [config] transformer-dim-aan: 2048
[2023-07-01 11:44:39] [config] transformer-dim-ffn: 2048
[2023-07-01 11:44:39] [config] transformer-dropout: 0.1
[2023-07-01 11:44:39] [config] transformer-dropout-attention: 0
[2023-07-01 11:44:39] [config] transformer-dropout-ffn: 0
[2023-07-01 11:44:39] [config] transformer-ffn-activation: swish
[2023-07-01 11:44:39] [config] transformer-ffn-depth: 2
[2023-07-01 11:44:39] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:44:39] [config] transformer-heads: 8
[2023-07-01 11:44:39] [config] transformer-no-projection: false
[2023-07-01 11:44:39] [config] transformer-pool: false
[2023-07-01 11:44:39] [config] transformer-postprocess: dan
[2023-07-01 11:44:39] [config] transformer-postprocess-emb: d
[2023-07-01 11:44:39] [config] transformer-postprocess-top: ""
[2023-07-01 11:44:39] [config] transformer-preprocess: ""
[2023-07-01 11:44:39] [config] transformer-tied-layers:
[2023-07-01 11:44:39] [config]   []
[2023-07-01 11:44:39] [config] transformer-train-position-embeddings: false
[2023-07-01 11:44:39] [config] tsv: false
[2023-07-01 11:44:39] [config] tsv-fields: 0
[2023-07-01 11:44:39] [config] type: transformer
[2023-07-01 11:44:39] [config] ulr: false
[2023-07-01 11:44:39] [config] ulr-dim-emb: 0
[2023-07-01 11:44:39] [config] ulr-dropout: 0
[2023-07-01 11:44:39] [config] ulr-keys-vectors: ""
[2023-07-01 11:44:39] [config] ulr-query-vectors: ""
[2023-07-01 11:44:39] [config] ulr-softmax-temperature: 1
[2023-07-01 11:44:39] [config] ulr-trainable-transformation: false
[2023-07-01 11:44:39] [config] unlikelihood-loss: false
[2023-07-01 11:44:39] [config] valid-freq: 50000000
[2023-07-01 11:44:39] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:44:39] [config] valid-max-length: 1000
[2023-07-01 11:44:39] [config] valid-metrics:
[2023-07-01 11:44:39] [config]   - cross-entropy
[2023-07-01 11:44:39] [config]   - translation
[2023-07-01 11:44:39] [config] valid-mini-batch: 64
[2023-07-01 11:44:39] [config] valid-reset-stalled: false
[2023-07-01 11:44:39] [config] valid-script-args:
[2023-07-01 11:44:39] [config]   []
[2023-07-01 11:44:39] [config] valid-script-path: ""
[2023-07-01 11:44:39] [config] valid-sets:
[2023-07-01 11:44:39] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:44:39] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:44:39] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:44:39] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:44:39] [config] vocabs:
[2023-07-01 11:44:39] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:44:39] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:44:39] [config] word-penalty: 0
[2023-07-01 11:44:39] [config] word-scores: false
[2023-07-01 11:44:39] [config] workspace: 2048
[2023-07-01 11:44:39] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:44:39] Using synchronous SGD
[2023-07-01 11:44:39] Synced seed 1234
[2023-07-01 11:44:39] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:44:39] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:44:39] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:44:39] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:44:39] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:44:39] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:44:40] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:44:40] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:44:40] [comm] Using global sharding
[2023-07-01 11:44:40] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:44:40] [training] Using 1 GPUs
[2023-07-01 11:44:40] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:44:40] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:44:41] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:44:41] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:44:48] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:44:48] [valid] No post-processing script given for validating translator
[2023-07-01 11:44:48] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:44:48] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:44:48] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:44:48] [comm] Using global sharding
[2023-07-01 11:44:48] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:44:48] [training] Using 1 GPUs
[2023-07-01 11:44:48] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:44:49] Allocating memory for general optimizer shards
[2023-07-01 11:44:49] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:44:49] Loading Adam parameters
[2023-07-01 11:44:49] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:44:49] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:44:49] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:44:49] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:44:49] [data] Shuffling data
[2023-07-01 11:44:49] [data] Done reading 20,192 sentences
[2023-07-01 11:44:49] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:44:49] Training started
[2023-07-01 11:44:49] Training finished
[2023-07-01 11:44:52] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:44:52] [marian] Running on node20.datos.cluster.uy as process 20765 with command line:
[2023-07-01 11:44:52] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 159 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:44:52] [config] after: 0e
[2023-07-01 11:44:52] [config] after-batches: 0
[2023-07-01 11:44:52] [config] after-epochs: 159
[2023-07-01 11:44:52] [config] all-caps-every: 0
[2023-07-01 11:44:52] [config] allow-unk: false
[2023-07-01 11:44:52] [config] authors: false
[2023-07-01 11:44:52] [config] beam-size: 12
[2023-07-01 11:44:52] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:44:52] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:44:52] [config] bert-masking-fraction: 0.15
[2023-07-01 11:44:52] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:44:52] [config] bert-train-type-embeddings: true
[2023-07-01 11:44:52] [config] bert-type-vocab-size: 2
[2023-07-01 11:44:52] [config] build-info: ""
[2023-07-01 11:44:52] [config] check-gradient-nan: false
[2023-07-01 11:44:52] [config] check-nan: false
[2023-07-01 11:44:52] [config] cite: false
[2023-07-01 11:44:52] [config] clip-norm: 5
[2023-07-01 11:44:52] [config] cost-scaling:
[2023-07-01 11:44:52] [config]   []
[2023-07-01 11:44:52] [config] cost-type: ce-sum
[2023-07-01 11:44:52] [config] cpu-threads: 0
[2023-07-01 11:44:52] [config] data-threads: 8
[2023-07-01 11:44:52] [config] data-weighting: ""
[2023-07-01 11:44:52] [config] data-weighting-type: sentence
[2023-07-01 11:44:52] [config] dec-cell: gru
[2023-07-01 11:44:52] [config] dec-cell-base-depth: 2
[2023-07-01 11:44:52] [config] dec-cell-high-depth: 1
[2023-07-01 11:44:52] [config] dec-depth: 2
[2023-07-01 11:44:52] [config] devices:
[2023-07-01 11:44:52] [config]   - 0
[2023-07-01 11:44:52] [config] dim-emb: 512
[2023-07-01 11:44:52] [config] dim-rnn: 1024
[2023-07-01 11:44:52] [config] dim-vocabs:
[2023-07-01 11:44:52] [config]   - 16384
[2023-07-01 11:44:52] [config]   - 16384
[2023-07-01 11:44:52] [config] disp-first: 0
[2023-07-01 11:44:52] [config] disp-freq: 1000u
[2023-07-01 11:44:52] [config] disp-label-counts: true
[2023-07-01 11:44:52] [config] dropout-rnn: 0
[2023-07-01 11:44:52] [config] dropout-src: 0
[2023-07-01 11:44:52] [config] dropout-trg: 0
[2023-07-01 11:44:52] [config] dump-config: ""
[2023-07-01 11:44:52] [config] dynamic-gradient-scaling:
[2023-07-01 11:44:52] [config]   []
[2023-07-01 11:44:52] [config] early-stopping: 10
[2023-07-01 11:44:52] [config] early-stopping-on: first
[2023-07-01 11:44:52] [config] embedding-fix-src: false
[2023-07-01 11:44:52] [config] embedding-fix-trg: false
[2023-07-01 11:44:52] [config] embedding-normalization: false
[2023-07-01 11:44:52] [config] embedding-vectors:
[2023-07-01 11:44:52] [config]   []
[2023-07-01 11:44:52] [config] enc-cell: gru
[2023-07-01 11:44:52] [config] enc-cell-depth: 1
[2023-07-01 11:44:52] [config] enc-depth: 2
[2023-07-01 11:44:52] [config] enc-type: bidirectional
[2023-07-01 11:44:52] [config] english-title-case-every: 0
[2023-07-01 11:44:52] [config] exponential-smoothing: 0.0001
[2023-07-01 11:44:52] [config] factor-weight: 1
[2023-07-01 11:44:52] [config] factors-combine: sum
[2023-07-01 11:44:52] [config] factors-dim-emb: 0
[2023-07-01 11:44:52] [config] gradient-checkpointing: false
[2023-07-01 11:44:52] [config] gradient-norm-average-window: 100
[2023-07-01 11:44:52] [config] guided-alignment: none
[2023-07-01 11:44:52] [config] guided-alignment-cost: mse
[2023-07-01 11:44:52] [config] guided-alignment-weight: 0.1
[2023-07-01 11:44:52] [config] ignore-model-config: false
[2023-07-01 11:44:52] [config] input-types:
[2023-07-01 11:44:52] [config]   []
[2023-07-01 11:44:52] [config] interpolate-env-vars: false
[2023-07-01 11:44:52] [config] keep-best: false
[2023-07-01 11:44:52] [config] label-smoothing: 0.1
[2023-07-01 11:44:52] [config] layer-normalization: false
[2023-07-01 11:44:52] [config] learn-rate: 0.0003
[2023-07-01 11:44:52] [config] lemma-dependency: ""
[2023-07-01 11:44:52] [config] lemma-dim-emb: 0
[2023-07-01 11:44:52] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:44:52] [config] log-level: info
[2023-07-01 11:44:52] [config] log-time-zone: ""
[2023-07-01 11:44:52] [config] logical-epoch:
[2023-07-01 11:44:52] [config]   - 1e
[2023-07-01 11:44:52] [config]   - 0
[2023-07-01 11:44:52] [config] lr-decay: 0
[2023-07-01 11:44:52] [config] lr-decay-freq: 50000
[2023-07-01 11:44:52] [config] lr-decay-inv-sqrt:
[2023-07-01 11:44:52] [config]   - 16000
[2023-07-01 11:44:52] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:44:52] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:44:52] [config] lr-decay-start:
[2023-07-01 11:44:52] [config]   - 10
[2023-07-01 11:44:52] [config]   - 1
[2023-07-01 11:44:52] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:44:52] [config] lr-report: true
[2023-07-01 11:44:52] [config] lr-warmup: 16000
[2023-07-01 11:44:52] [config] lr-warmup-at-reload: false
[2023-07-01 11:44:52] [config] lr-warmup-cycle: false
[2023-07-01 11:44:52] [config] lr-warmup-start-rate: 0
[2023-07-01 11:44:52] [config] max-length: 100
[2023-07-01 11:44:52] [config] max-length-crop: false
[2023-07-01 11:44:52] [config] max-length-factor: 3
[2023-07-01 11:44:52] [config] maxi-batch: 100
[2023-07-01 11:44:52] [config] maxi-batch-sort: trg
[2023-07-01 11:44:52] [config] mini-batch: 1000
[2023-07-01 11:44:52] [config] mini-batch-fit: true
[2023-07-01 11:44:52] [config] mini-batch-fit-step: 10
[2023-07-01 11:44:52] [config] mini-batch-round-up: true
[2023-07-01 11:44:52] [config] mini-batch-track-lr: false
[2023-07-01 11:44:52] [config] mini-batch-warmup: 0
[2023-07-01 11:44:52] [config] mini-batch-words: 0
[2023-07-01 11:44:52] [config] mini-batch-words-ref: 0
[2023-07-01 11:44:52] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:44:52] [config] multi-loss-type: sum
[2023-07-01 11:44:52] [config] n-best: false
[2023-07-01 11:44:52] [config] no-nccl: false
[2023-07-01 11:44:52] [config] no-reload: false
[2023-07-01 11:44:52] [config] no-restore-corpus: false
[2023-07-01 11:44:52] [config] normalize: 1
[2023-07-01 11:44:52] [config] normalize-gradient: false
[2023-07-01 11:44:52] [config] num-devices: 0
[2023-07-01 11:44:52] [config] optimizer: adam
[2023-07-01 11:44:52] [config] optimizer-delay: 1
[2023-07-01 11:44:52] [config] optimizer-params:
[2023-07-01 11:44:52] [config]   - 0.9
[2023-07-01 11:44:52] [config]   - 0.98
[2023-07-01 11:44:52] [config]   - 1e-09
[2023-07-01 11:44:52] [config] output-omit-bias: false
[2023-07-01 11:44:52] [config] overwrite: true
[2023-07-01 11:44:52] [config] precision:
[2023-07-01 11:44:52] [config]   - float32
[2023-07-01 11:44:52] [config]   - float32
[2023-07-01 11:44:52] [config] pretrained-model: ""
[2023-07-01 11:44:52] [config] quantize-biases: false
[2023-07-01 11:44:52] [config] quantize-bits: 0
[2023-07-01 11:44:52] [config] quantize-log-based: false
[2023-07-01 11:44:52] [config] quantize-optimization-steps: 0
[2023-07-01 11:44:52] [config] quiet: false
[2023-07-01 11:44:52] [config] quiet-translation: true
[2023-07-01 11:44:52] [config] relative-paths: false
[2023-07-01 11:44:52] [config] right-left: false
[2023-07-01 11:44:52] [config] save-freq: 10000u
[2023-07-01 11:44:52] [config] seed: 1234
[2023-07-01 11:44:52] [config] sentencepiece-alphas:
[2023-07-01 11:44:52] [config]   []
[2023-07-01 11:44:52] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:44:52] [config] sentencepiece-options: ""
[2023-07-01 11:44:52] [config] sharding: global
[2023-07-01 11:44:52] [config] shuffle: data
[2023-07-01 11:44:52] [config] shuffle-in-ram: false
[2023-07-01 11:44:52] [config] sigterm: save-and-exit
[2023-07-01 11:44:52] [config] skip: false
[2023-07-01 11:44:52] [config] sqlite: ""
[2023-07-01 11:44:52] [config] sqlite-drop: false
[2023-07-01 11:44:52] [config] sync-freq: 200u
[2023-07-01 11:44:52] [config] sync-sgd: true
[2023-07-01 11:44:52] [config] tempdir: /tmp
[2023-07-01 11:44:52] [config] tied-embeddings: false
[2023-07-01 11:44:52] [config] tied-embeddings-all: true
[2023-07-01 11:44:52] [config] tied-embeddings-src: false
[2023-07-01 11:44:52] [config] train-embedder-rank:
[2023-07-01 11:44:52] [config]   []
[2023-07-01 11:44:52] [config] train-sets:
[2023-07-01 11:44:52] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:44:52] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:44:52] [config] transformer-aan-activation: swish
[2023-07-01 11:44:52] [config] transformer-aan-depth: 2
[2023-07-01 11:44:52] [config] transformer-aan-nogate: false
[2023-07-01 11:44:52] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:44:52] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:44:52] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:44:52] [config] transformer-depth-scaling: false
[2023-07-01 11:44:52] [config] transformer-dim-aan: 2048
[2023-07-01 11:44:52] [config] transformer-dim-ffn: 2048
[2023-07-01 11:44:52] [config] transformer-dropout: 0.1
[2023-07-01 11:44:52] [config] transformer-dropout-attention: 0
[2023-07-01 11:44:52] [config] transformer-dropout-ffn: 0
[2023-07-01 11:44:52] [config] transformer-ffn-activation: swish
[2023-07-01 11:44:52] [config] transformer-ffn-depth: 2
[2023-07-01 11:44:52] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:44:52] [config] transformer-heads: 8
[2023-07-01 11:44:52] [config] transformer-no-projection: false
[2023-07-01 11:44:52] [config] transformer-pool: false
[2023-07-01 11:44:52] [config] transformer-postprocess: dan
[2023-07-01 11:44:52] [config] transformer-postprocess-emb: d
[2023-07-01 11:44:52] [config] transformer-postprocess-top: ""
[2023-07-01 11:44:52] [config] transformer-preprocess: ""
[2023-07-01 11:44:52] [config] transformer-tied-layers:
[2023-07-01 11:44:52] [config]   []
[2023-07-01 11:44:52] [config] transformer-train-position-embeddings: false
[2023-07-01 11:44:52] [config] tsv: false
[2023-07-01 11:44:52] [config] tsv-fields: 0
[2023-07-01 11:44:52] [config] type: transformer
[2023-07-01 11:44:52] [config] ulr: false
[2023-07-01 11:44:52] [config] ulr-dim-emb: 0
[2023-07-01 11:44:52] [config] ulr-dropout: 0
[2023-07-01 11:44:52] [config] ulr-keys-vectors: ""
[2023-07-01 11:44:52] [config] ulr-query-vectors: ""
[2023-07-01 11:44:52] [config] ulr-softmax-temperature: 1
[2023-07-01 11:44:52] [config] ulr-trainable-transformation: false
[2023-07-01 11:44:52] [config] unlikelihood-loss: false
[2023-07-01 11:44:52] [config] valid-freq: 50000000
[2023-07-01 11:44:52] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:44:52] [config] valid-max-length: 1000
[2023-07-01 11:44:52] [config] valid-metrics:
[2023-07-01 11:44:52] [config]   - cross-entropy
[2023-07-01 11:44:52] [config]   - translation
[2023-07-01 11:44:52] [config] valid-mini-batch: 64
[2023-07-01 11:44:52] [config] valid-reset-stalled: false
[2023-07-01 11:44:52] [config] valid-script-args:
[2023-07-01 11:44:52] [config]   []
[2023-07-01 11:44:52] [config] valid-script-path: ""
[2023-07-01 11:44:52] [config] valid-sets:
[2023-07-01 11:44:52] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:44:52] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:44:52] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:44:52] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:44:52] [config] vocabs:
[2023-07-01 11:44:52] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:44:52] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:44:52] [config] word-penalty: 0
[2023-07-01 11:44:52] [config] word-scores: false
[2023-07-01 11:44:52] [config] workspace: 2048
[2023-07-01 11:44:52] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:44:52] Using synchronous SGD
[2023-07-01 11:44:52] Synced seed 1234
[2023-07-01 11:44:52] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:44:53] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:44:53] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:44:53] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:44:53] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:44:53] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:44:53] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:44:53] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:44:53] [comm] Using global sharding
[2023-07-01 11:44:53] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:44:53] [training] Using 1 GPUs
[2023-07-01 11:44:53] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:44:53] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:44:54] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:44:54] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:45:01] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:45:01] [valid] No post-processing script given for validating translator
[2023-07-01 11:45:01] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:45:01] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:45:01] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:45:01] [comm] Using global sharding
[2023-07-01 11:45:01] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:45:01] [training] Using 1 GPUs
[2023-07-01 11:45:01] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:45:02] Allocating memory for general optimizer shards
[2023-07-01 11:45:02] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:45:02] Loading Adam parameters
[2023-07-01 11:45:02] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:45:02] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:45:02] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:45:02] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:45:02] [data] Shuffling data
[2023-07-01 11:45:02] [data] Done reading 20,192 sentences
[2023-07-01 11:45:02] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:45:02] Training started
[2023-07-01 11:45:02] Training finished
[2023-07-01 11:45:06] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:45:06] [marian] Running on node20.datos.cluster.uy as process 20825 with command line:
[2023-07-01 11:45:06] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 160 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:45:06] [config] after: 0e
[2023-07-01 11:45:06] [config] after-batches: 0
[2023-07-01 11:45:06] [config] after-epochs: 160
[2023-07-01 11:45:06] [config] all-caps-every: 0
[2023-07-01 11:45:06] [config] allow-unk: false
[2023-07-01 11:45:06] [config] authors: false
[2023-07-01 11:45:06] [config] beam-size: 12
[2023-07-01 11:45:06] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:45:06] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:45:06] [config] bert-masking-fraction: 0.15
[2023-07-01 11:45:06] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:45:06] [config] bert-train-type-embeddings: true
[2023-07-01 11:45:06] [config] bert-type-vocab-size: 2
[2023-07-01 11:45:06] [config] build-info: ""
[2023-07-01 11:45:06] [config] check-gradient-nan: false
[2023-07-01 11:45:06] [config] check-nan: false
[2023-07-01 11:45:06] [config] cite: false
[2023-07-01 11:45:06] [config] clip-norm: 5
[2023-07-01 11:45:06] [config] cost-scaling:
[2023-07-01 11:45:06] [config]   []
[2023-07-01 11:45:06] [config] cost-type: ce-sum
[2023-07-01 11:45:06] [config] cpu-threads: 0
[2023-07-01 11:45:06] [config] data-threads: 8
[2023-07-01 11:45:06] [config] data-weighting: ""
[2023-07-01 11:45:06] [config] data-weighting-type: sentence
[2023-07-01 11:45:06] [config] dec-cell: gru
[2023-07-01 11:45:06] [config] dec-cell-base-depth: 2
[2023-07-01 11:45:06] [config] dec-cell-high-depth: 1
[2023-07-01 11:45:06] [config] dec-depth: 2
[2023-07-01 11:45:06] [config] devices:
[2023-07-01 11:45:06] [config]   - 0
[2023-07-01 11:45:06] [config] dim-emb: 512
[2023-07-01 11:45:06] [config] dim-rnn: 1024
[2023-07-01 11:45:06] [config] dim-vocabs:
[2023-07-01 11:45:06] [config]   - 16384
[2023-07-01 11:45:06] [config]   - 16384
[2023-07-01 11:45:06] [config] disp-first: 0
[2023-07-01 11:45:06] [config] disp-freq: 1000u
[2023-07-01 11:45:06] [config] disp-label-counts: true
[2023-07-01 11:45:06] [config] dropout-rnn: 0
[2023-07-01 11:45:06] [config] dropout-src: 0
[2023-07-01 11:45:06] [config] dropout-trg: 0
[2023-07-01 11:45:06] [config] dump-config: ""
[2023-07-01 11:45:06] [config] dynamic-gradient-scaling:
[2023-07-01 11:45:06] [config]   []
[2023-07-01 11:45:06] [config] early-stopping: 10
[2023-07-01 11:45:06] [config] early-stopping-on: first
[2023-07-01 11:45:06] [config] embedding-fix-src: false
[2023-07-01 11:45:06] [config] embedding-fix-trg: false
[2023-07-01 11:45:06] [config] embedding-normalization: false
[2023-07-01 11:45:06] [config] embedding-vectors:
[2023-07-01 11:45:06] [config]   []
[2023-07-01 11:45:06] [config] enc-cell: gru
[2023-07-01 11:45:06] [config] enc-cell-depth: 1
[2023-07-01 11:45:06] [config] enc-depth: 2
[2023-07-01 11:45:06] [config] enc-type: bidirectional
[2023-07-01 11:45:06] [config] english-title-case-every: 0
[2023-07-01 11:45:06] [config] exponential-smoothing: 0.0001
[2023-07-01 11:45:06] [config] factor-weight: 1
[2023-07-01 11:45:06] [config] factors-combine: sum
[2023-07-01 11:45:06] [config] factors-dim-emb: 0
[2023-07-01 11:45:06] [config] gradient-checkpointing: false
[2023-07-01 11:45:06] [config] gradient-norm-average-window: 100
[2023-07-01 11:45:06] [config] guided-alignment: none
[2023-07-01 11:45:06] [config] guided-alignment-cost: mse
[2023-07-01 11:45:06] [config] guided-alignment-weight: 0.1
[2023-07-01 11:45:06] [config] ignore-model-config: false
[2023-07-01 11:45:06] [config] input-types:
[2023-07-01 11:45:06] [config]   []
[2023-07-01 11:45:06] [config] interpolate-env-vars: false
[2023-07-01 11:45:06] [config] keep-best: false
[2023-07-01 11:45:06] [config] label-smoothing: 0.1
[2023-07-01 11:45:06] [config] layer-normalization: false
[2023-07-01 11:45:06] [config] learn-rate: 0.0003
[2023-07-01 11:45:06] [config] lemma-dependency: ""
[2023-07-01 11:45:06] [config] lemma-dim-emb: 0
[2023-07-01 11:45:06] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:45:06] [config] log-level: info
[2023-07-01 11:45:06] [config] log-time-zone: ""
[2023-07-01 11:45:06] [config] logical-epoch:
[2023-07-01 11:45:06] [config]   - 1e
[2023-07-01 11:45:06] [config]   - 0
[2023-07-01 11:45:06] [config] lr-decay: 0
[2023-07-01 11:45:06] [config] lr-decay-freq: 50000
[2023-07-01 11:45:06] [config] lr-decay-inv-sqrt:
[2023-07-01 11:45:06] [config]   - 16000
[2023-07-01 11:45:06] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:45:06] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:45:06] [config] lr-decay-start:
[2023-07-01 11:45:06] [config]   - 10
[2023-07-01 11:45:06] [config]   - 1
[2023-07-01 11:45:06] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:45:06] [config] lr-report: true
[2023-07-01 11:45:06] [config] lr-warmup: 16000
[2023-07-01 11:45:06] [config] lr-warmup-at-reload: false
[2023-07-01 11:45:06] [config] lr-warmup-cycle: false
[2023-07-01 11:45:06] [config] lr-warmup-start-rate: 0
[2023-07-01 11:45:06] [config] max-length: 100
[2023-07-01 11:45:06] [config] max-length-crop: false
[2023-07-01 11:45:06] [config] max-length-factor: 3
[2023-07-01 11:45:06] [config] maxi-batch: 100
[2023-07-01 11:45:06] [config] maxi-batch-sort: trg
[2023-07-01 11:45:06] [config] mini-batch: 1000
[2023-07-01 11:45:06] [config] mini-batch-fit: true
[2023-07-01 11:45:06] [config] mini-batch-fit-step: 10
[2023-07-01 11:45:06] [config] mini-batch-round-up: true
[2023-07-01 11:45:06] [config] mini-batch-track-lr: false
[2023-07-01 11:45:06] [config] mini-batch-warmup: 0
[2023-07-01 11:45:06] [config] mini-batch-words: 0
[2023-07-01 11:45:06] [config] mini-batch-words-ref: 0
[2023-07-01 11:45:06] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:45:06] [config] multi-loss-type: sum
[2023-07-01 11:45:06] [config] n-best: false
[2023-07-01 11:45:06] [config] no-nccl: false
[2023-07-01 11:45:06] [config] no-reload: false
[2023-07-01 11:45:06] [config] no-restore-corpus: false
[2023-07-01 11:45:06] [config] normalize: 1
[2023-07-01 11:45:06] [config] normalize-gradient: false
[2023-07-01 11:45:06] [config] num-devices: 0
[2023-07-01 11:45:06] [config] optimizer: adam
[2023-07-01 11:45:06] [config] optimizer-delay: 1
[2023-07-01 11:45:06] [config] optimizer-params:
[2023-07-01 11:45:06] [config]   - 0.9
[2023-07-01 11:45:06] [config]   - 0.98
[2023-07-01 11:45:06] [config]   - 1e-09
[2023-07-01 11:45:06] [config] output-omit-bias: false
[2023-07-01 11:45:06] [config] overwrite: true
[2023-07-01 11:45:06] [config] precision:
[2023-07-01 11:45:06] [config]   - float32
[2023-07-01 11:45:06] [config]   - float32
[2023-07-01 11:45:06] [config] pretrained-model: ""
[2023-07-01 11:45:06] [config] quantize-biases: false
[2023-07-01 11:45:06] [config] quantize-bits: 0
[2023-07-01 11:45:06] [config] quantize-log-based: false
[2023-07-01 11:45:06] [config] quantize-optimization-steps: 0
[2023-07-01 11:45:06] [config] quiet: false
[2023-07-01 11:45:06] [config] quiet-translation: true
[2023-07-01 11:45:06] [config] relative-paths: false
[2023-07-01 11:45:06] [config] right-left: false
[2023-07-01 11:45:06] [config] save-freq: 10000u
[2023-07-01 11:45:06] [config] seed: 1234
[2023-07-01 11:45:06] [config] sentencepiece-alphas:
[2023-07-01 11:45:06] [config]   []
[2023-07-01 11:45:06] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:45:06] [config] sentencepiece-options: ""
[2023-07-01 11:45:06] [config] sharding: global
[2023-07-01 11:45:06] [config] shuffle: data
[2023-07-01 11:45:06] [config] shuffle-in-ram: false
[2023-07-01 11:45:06] [config] sigterm: save-and-exit
[2023-07-01 11:45:06] [config] skip: false
[2023-07-01 11:45:06] [config] sqlite: ""
[2023-07-01 11:45:06] [config] sqlite-drop: false
[2023-07-01 11:45:06] [config] sync-freq: 200u
[2023-07-01 11:45:06] [config] sync-sgd: true
[2023-07-01 11:45:06] [config] tempdir: /tmp
[2023-07-01 11:45:06] [config] tied-embeddings: false
[2023-07-01 11:45:06] [config] tied-embeddings-all: true
[2023-07-01 11:45:06] [config] tied-embeddings-src: false
[2023-07-01 11:45:06] [config] train-embedder-rank:
[2023-07-01 11:45:06] [config]   []
[2023-07-01 11:45:06] [config] train-sets:
[2023-07-01 11:45:06] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:45:06] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:45:06] [config] transformer-aan-activation: swish
[2023-07-01 11:45:06] [config] transformer-aan-depth: 2
[2023-07-01 11:45:06] [config] transformer-aan-nogate: false
[2023-07-01 11:45:06] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:45:06] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:45:06] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:45:06] [config] transformer-depth-scaling: false
[2023-07-01 11:45:06] [config] transformer-dim-aan: 2048
[2023-07-01 11:45:06] [config] transformer-dim-ffn: 2048
[2023-07-01 11:45:06] [config] transformer-dropout: 0.1
[2023-07-01 11:45:06] [config] transformer-dropout-attention: 0
[2023-07-01 11:45:06] [config] transformer-dropout-ffn: 0
[2023-07-01 11:45:06] [config] transformer-ffn-activation: swish
[2023-07-01 11:45:06] [config] transformer-ffn-depth: 2
[2023-07-01 11:45:06] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:45:06] [config] transformer-heads: 8
[2023-07-01 11:45:06] [config] transformer-no-projection: false
[2023-07-01 11:45:06] [config] transformer-pool: false
[2023-07-01 11:45:06] [config] transformer-postprocess: dan
[2023-07-01 11:45:06] [config] transformer-postprocess-emb: d
[2023-07-01 11:45:06] [config] transformer-postprocess-top: ""
[2023-07-01 11:45:06] [config] transformer-preprocess: ""
[2023-07-01 11:45:06] [config] transformer-tied-layers:
[2023-07-01 11:45:06] [config]   []
[2023-07-01 11:45:06] [config] transformer-train-position-embeddings: false
[2023-07-01 11:45:06] [config] tsv: false
[2023-07-01 11:45:06] [config] tsv-fields: 0
[2023-07-01 11:45:06] [config] type: transformer
[2023-07-01 11:45:06] [config] ulr: false
[2023-07-01 11:45:06] [config] ulr-dim-emb: 0
[2023-07-01 11:45:06] [config] ulr-dropout: 0
[2023-07-01 11:45:06] [config] ulr-keys-vectors: ""
[2023-07-01 11:45:06] [config] ulr-query-vectors: ""
[2023-07-01 11:45:06] [config] ulr-softmax-temperature: 1
[2023-07-01 11:45:06] [config] ulr-trainable-transformation: false
[2023-07-01 11:45:06] [config] unlikelihood-loss: false
[2023-07-01 11:45:06] [config] valid-freq: 50000000
[2023-07-01 11:45:06] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:45:06] [config] valid-max-length: 1000
[2023-07-01 11:45:06] [config] valid-metrics:
[2023-07-01 11:45:06] [config]   - cross-entropy
[2023-07-01 11:45:06] [config]   - translation
[2023-07-01 11:45:06] [config] valid-mini-batch: 64
[2023-07-01 11:45:06] [config] valid-reset-stalled: false
[2023-07-01 11:45:06] [config] valid-script-args:
[2023-07-01 11:45:06] [config]   []
[2023-07-01 11:45:06] [config] valid-script-path: ""
[2023-07-01 11:45:06] [config] valid-sets:
[2023-07-01 11:45:06] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:45:06] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:45:06] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:45:06] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:45:06] [config] vocabs:
[2023-07-01 11:45:06] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:45:06] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:45:06] [config] word-penalty: 0
[2023-07-01 11:45:06] [config] word-scores: false
[2023-07-01 11:45:06] [config] workspace: 2048
[2023-07-01 11:45:06] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:45:06] Using synchronous SGD
[2023-07-01 11:45:06] Synced seed 1234
[2023-07-01 11:45:06] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:45:06] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:45:06] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:45:06] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:45:06] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:45:06] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:45:07] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:45:07] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:45:07] [comm] Using global sharding
[2023-07-01 11:45:07] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:45:07] [training] Using 1 GPUs
[2023-07-01 11:45:07] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:45:07] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:45:08] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:45:08] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:45:15] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:45:15] [valid] No post-processing script given for validating translator
[2023-07-01 11:45:15] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:45:15] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:45:15] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:45:15] [comm] Using global sharding
[2023-07-01 11:45:15] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:45:15] [training] Using 1 GPUs
[2023-07-01 11:45:15] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:45:16] Allocating memory for general optimizer shards
[2023-07-01 11:45:16] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:45:16] Loading Adam parameters
[2023-07-01 11:45:16] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:45:16] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:45:16] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:45:16] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:45:16] [data] Shuffling data
[2023-07-01 11:45:16] [data] Done reading 20,192 sentences
[2023-07-01 11:45:16] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:45:16] Training started
[2023-07-01 11:45:16] Training finished
[2023-07-01 11:45:20] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:45:20] [marian] Running on node20.datos.cluster.uy as process 20884 with command line:
[2023-07-01 11:45:20] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 161 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:45:20] [config] after: 0e
[2023-07-01 11:45:20] [config] after-batches: 0
[2023-07-01 11:45:20] [config] after-epochs: 161
[2023-07-01 11:45:20] [config] all-caps-every: 0
[2023-07-01 11:45:20] [config] allow-unk: false
[2023-07-01 11:45:20] [config] authors: false
[2023-07-01 11:45:20] [config] beam-size: 12
[2023-07-01 11:45:20] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:45:20] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:45:20] [config] bert-masking-fraction: 0.15
[2023-07-01 11:45:20] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:45:20] [config] bert-train-type-embeddings: true
[2023-07-01 11:45:20] [config] bert-type-vocab-size: 2
[2023-07-01 11:45:20] [config] build-info: ""
[2023-07-01 11:45:20] [config] check-gradient-nan: false
[2023-07-01 11:45:20] [config] check-nan: false
[2023-07-01 11:45:20] [config] cite: false
[2023-07-01 11:45:20] [config] clip-norm: 5
[2023-07-01 11:45:20] [config] cost-scaling:
[2023-07-01 11:45:20] [config]   []
[2023-07-01 11:45:20] [config] cost-type: ce-sum
[2023-07-01 11:45:20] [config] cpu-threads: 0
[2023-07-01 11:45:20] [config] data-threads: 8
[2023-07-01 11:45:20] [config] data-weighting: ""
[2023-07-01 11:45:20] [config] data-weighting-type: sentence
[2023-07-01 11:45:20] [config] dec-cell: gru
[2023-07-01 11:45:20] [config] dec-cell-base-depth: 2
[2023-07-01 11:45:20] [config] dec-cell-high-depth: 1
[2023-07-01 11:45:20] [config] dec-depth: 2
[2023-07-01 11:45:20] [config] devices:
[2023-07-01 11:45:20] [config]   - 0
[2023-07-01 11:45:20] [config] dim-emb: 512
[2023-07-01 11:45:20] [config] dim-rnn: 1024
[2023-07-01 11:45:20] [config] dim-vocabs:
[2023-07-01 11:45:20] [config]   - 16384
[2023-07-01 11:45:20] [config]   - 16384
[2023-07-01 11:45:20] [config] disp-first: 0
[2023-07-01 11:45:20] [config] disp-freq: 1000u
[2023-07-01 11:45:20] [config] disp-label-counts: true
[2023-07-01 11:45:20] [config] dropout-rnn: 0
[2023-07-01 11:45:20] [config] dropout-src: 0
[2023-07-01 11:45:20] [config] dropout-trg: 0
[2023-07-01 11:45:20] [config] dump-config: ""
[2023-07-01 11:45:20] [config] dynamic-gradient-scaling:
[2023-07-01 11:45:20] [config]   []
[2023-07-01 11:45:20] [config] early-stopping: 10
[2023-07-01 11:45:20] [config] early-stopping-on: first
[2023-07-01 11:45:20] [config] embedding-fix-src: false
[2023-07-01 11:45:20] [config] embedding-fix-trg: false
[2023-07-01 11:45:20] [config] embedding-normalization: false
[2023-07-01 11:45:20] [config] embedding-vectors:
[2023-07-01 11:45:20] [config]   []
[2023-07-01 11:45:20] [config] enc-cell: gru
[2023-07-01 11:45:20] [config] enc-cell-depth: 1
[2023-07-01 11:45:20] [config] enc-depth: 2
[2023-07-01 11:45:20] [config] enc-type: bidirectional
[2023-07-01 11:45:20] [config] english-title-case-every: 0
[2023-07-01 11:45:20] [config] exponential-smoothing: 0.0001
[2023-07-01 11:45:20] [config] factor-weight: 1
[2023-07-01 11:45:20] [config] factors-combine: sum
[2023-07-01 11:45:20] [config] factors-dim-emb: 0
[2023-07-01 11:45:20] [config] gradient-checkpointing: false
[2023-07-01 11:45:20] [config] gradient-norm-average-window: 100
[2023-07-01 11:45:20] [config] guided-alignment: none
[2023-07-01 11:45:20] [config] guided-alignment-cost: mse
[2023-07-01 11:45:20] [config] guided-alignment-weight: 0.1
[2023-07-01 11:45:20] [config] ignore-model-config: false
[2023-07-01 11:45:20] [config] input-types:
[2023-07-01 11:45:20] [config]   []
[2023-07-01 11:45:20] [config] interpolate-env-vars: false
[2023-07-01 11:45:20] [config] keep-best: false
[2023-07-01 11:45:20] [config] label-smoothing: 0.1
[2023-07-01 11:45:20] [config] layer-normalization: false
[2023-07-01 11:45:20] [config] learn-rate: 0.0003
[2023-07-01 11:45:20] [config] lemma-dependency: ""
[2023-07-01 11:45:20] [config] lemma-dim-emb: 0
[2023-07-01 11:45:20] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:45:20] [config] log-level: info
[2023-07-01 11:45:20] [config] log-time-zone: ""
[2023-07-01 11:45:20] [config] logical-epoch:
[2023-07-01 11:45:20] [config]   - 1e
[2023-07-01 11:45:20] [config]   - 0
[2023-07-01 11:45:20] [config] lr-decay: 0
[2023-07-01 11:45:20] [config] lr-decay-freq: 50000
[2023-07-01 11:45:20] [config] lr-decay-inv-sqrt:
[2023-07-01 11:45:20] [config]   - 16000
[2023-07-01 11:45:20] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:45:20] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:45:20] [config] lr-decay-start:
[2023-07-01 11:45:20] [config]   - 10
[2023-07-01 11:45:20] [config]   - 1
[2023-07-01 11:45:20] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:45:20] [config] lr-report: true
[2023-07-01 11:45:20] [config] lr-warmup: 16000
[2023-07-01 11:45:20] [config] lr-warmup-at-reload: false
[2023-07-01 11:45:20] [config] lr-warmup-cycle: false
[2023-07-01 11:45:20] [config] lr-warmup-start-rate: 0
[2023-07-01 11:45:20] [config] max-length: 100
[2023-07-01 11:45:20] [config] max-length-crop: false
[2023-07-01 11:45:20] [config] max-length-factor: 3
[2023-07-01 11:45:20] [config] maxi-batch: 100
[2023-07-01 11:45:20] [config] maxi-batch-sort: trg
[2023-07-01 11:45:20] [config] mini-batch: 1000
[2023-07-01 11:45:20] [config] mini-batch-fit: true
[2023-07-01 11:45:20] [config] mini-batch-fit-step: 10
[2023-07-01 11:45:20] [config] mini-batch-round-up: true
[2023-07-01 11:45:20] [config] mini-batch-track-lr: false
[2023-07-01 11:45:20] [config] mini-batch-warmup: 0
[2023-07-01 11:45:20] [config] mini-batch-words: 0
[2023-07-01 11:45:20] [config] mini-batch-words-ref: 0
[2023-07-01 11:45:20] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:45:20] [config] multi-loss-type: sum
[2023-07-01 11:45:20] [config] n-best: false
[2023-07-01 11:45:20] [config] no-nccl: false
[2023-07-01 11:45:20] [config] no-reload: false
[2023-07-01 11:45:20] [config] no-restore-corpus: false
[2023-07-01 11:45:20] [config] normalize: 1
[2023-07-01 11:45:20] [config] normalize-gradient: false
[2023-07-01 11:45:20] [config] num-devices: 0
[2023-07-01 11:45:20] [config] optimizer: adam
[2023-07-01 11:45:20] [config] optimizer-delay: 1
[2023-07-01 11:45:20] [config] optimizer-params:
[2023-07-01 11:45:20] [config]   - 0.9
[2023-07-01 11:45:20] [config]   - 0.98
[2023-07-01 11:45:20] [config]   - 1e-09
[2023-07-01 11:45:20] [config] output-omit-bias: false
[2023-07-01 11:45:20] [config] overwrite: true
[2023-07-01 11:45:20] [config] precision:
[2023-07-01 11:45:20] [config]   - float32
[2023-07-01 11:45:20] [config]   - float32
[2023-07-01 11:45:20] [config] pretrained-model: ""
[2023-07-01 11:45:20] [config] quantize-biases: false
[2023-07-01 11:45:20] [config] quantize-bits: 0
[2023-07-01 11:45:20] [config] quantize-log-based: false
[2023-07-01 11:45:20] [config] quantize-optimization-steps: 0
[2023-07-01 11:45:20] [config] quiet: false
[2023-07-01 11:45:20] [config] quiet-translation: true
[2023-07-01 11:45:20] [config] relative-paths: false
[2023-07-01 11:45:20] [config] right-left: false
[2023-07-01 11:45:20] [config] save-freq: 10000u
[2023-07-01 11:45:20] [config] seed: 1234
[2023-07-01 11:45:20] [config] sentencepiece-alphas:
[2023-07-01 11:45:20] [config]   []
[2023-07-01 11:45:20] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:45:20] [config] sentencepiece-options: ""
[2023-07-01 11:45:20] [config] sharding: global
[2023-07-01 11:45:20] [config] shuffle: data
[2023-07-01 11:45:20] [config] shuffle-in-ram: false
[2023-07-01 11:45:20] [config] sigterm: save-and-exit
[2023-07-01 11:45:20] [config] skip: false
[2023-07-01 11:45:20] [config] sqlite: ""
[2023-07-01 11:45:20] [config] sqlite-drop: false
[2023-07-01 11:45:20] [config] sync-freq: 200u
[2023-07-01 11:45:20] [config] sync-sgd: true
[2023-07-01 11:45:20] [config] tempdir: /tmp
[2023-07-01 11:45:20] [config] tied-embeddings: false
[2023-07-01 11:45:20] [config] tied-embeddings-all: true
[2023-07-01 11:45:20] [config] tied-embeddings-src: false
[2023-07-01 11:45:20] [config] train-embedder-rank:
[2023-07-01 11:45:20] [config]   []
[2023-07-01 11:45:20] [config] train-sets:
[2023-07-01 11:45:20] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:45:20] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:45:20] [config] transformer-aan-activation: swish
[2023-07-01 11:45:20] [config] transformer-aan-depth: 2
[2023-07-01 11:45:20] [config] transformer-aan-nogate: false
[2023-07-01 11:45:20] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:45:20] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:45:20] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:45:20] [config] transformer-depth-scaling: false
[2023-07-01 11:45:20] [config] transformer-dim-aan: 2048
[2023-07-01 11:45:20] [config] transformer-dim-ffn: 2048
[2023-07-01 11:45:20] [config] transformer-dropout: 0.1
[2023-07-01 11:45:20] [config] transformer-dropout-attention: 0
[2023-07-01 11:45:20] [config] transformer-dropout-ffn: 0
[2023-07-01 11:45:20] [config] transformer-ffn-activation: swish
[2023-07-01 11:45:20] [config] transformer-ffn-depth: 2
[2023-07-01 11:45:20] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:45:20] [config] transformer-heads: 8
[2023-07-01 11:45:20] [config] transformer-no-projection: false
[2023-07-01 11:45:20] [config] transformer-pool: false
[2023-07-01 11:45:20] [config] transformer-postprocess: dan
[2023-07-01 11:45:20] [config] transformer-postprocess-emb: d
[2023-07-01 11:45:20] [config] transformer-postprocess-top: ""
[2023-07-01 11:45:20] [config] transformer-preprocess: ""
[2023-07-01 11:45:20] [config] transformer-tied-layers:
[2023-07-01 11:45:20] [config]   []
[2023-07-01 11:45:20] [config] transformer-train-position-embeddings: false
[2023-07-01 11:45:20] [config] tsv: false
[2023-07-01 11:45:20] [config] tsv-fields: 0
[2023-07-01 11:45:20] [config] type: transformer
[2023-07-01 11:45:20] [config] ulr: false
[2023-07-01 11:45:20] [config] ulr-dim-emb: 0
[2023-07-01 11:45:20] [config] ulr-dropout: 0
[2023-07-01 11:45:20] [config] ulr-keys-vectors: ""
[2023-07-01 11:45:20] [config] ulr-query-vectors: ""
[2023-07-01 11:45:20] [config] ulr-softmax-temperature: 1
[2023-07-01 11:45:20] [config] ulr-trainable-transformation: false
[2023-07-01 11:45:20] [config] unlikelihood-loss: false
[2023-07-01 11:45:20] [config] valid-freq: 50000000
[2023-07-01 11:45:20] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:45:20] [config] valid-max-length: 1000
[2023-07-01 11:45:20] [config] valid-metrics:
[2023-07-01 11:45:20] [config]   - cross-entropy
[2023-07-01 11:45:20] [config]   - translation
[2023-07-01 11:45:20] [config] valid-mini-batch: 64
[2023-07-01 11:45:20] [config] valid-reset-stalled: false
[2023-07-01 11:45:20] [config] valid-script-args:
[2023-07-01 11:45:20] [config]   []
[2023-07-01 11:45:20] [config] valid-script-path: ""
[2023-07-01 11:45:20] [config] valid-sets:
[2023-07-01 11:45:20] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:45:20] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:45:20] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:45:20] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:45:20] [config] vocabs:
[2023-07-01 11:45:20] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:45:20] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:45:20] [config] word-penalty: 0
[2023-07-01 11:45:20] [config] word-scores: false
[2023-07-01 11:45:20] [config] workspace: 2048
[2023-07-01 11:45:20] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:45:20] Using synchronous SGD
[2023-07-01 11:45:20] Synced seed 1234
[2023-07-01 11:45:20] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:45:20] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:45:20] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:45:20] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:45:20] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:45:20] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:45:21] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:45:21] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:45:21] [comm] Using global sharding
[2023-07-01 11:45:21] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:45:21] [training] Using 1 GPUs
[2023-07-01 11:45:21] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:45:21] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:45:21] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:45:21] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:45:29] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:45:29] [valid] No post-processing script given for validating translator
[2023-07-01 11:45:29] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:45:29] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:45:29] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:45:29] [comm] Using global sharding
[2023-07-01 11:45:29] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:45:29] [training] Using 1 GPUs
[2023-07-01 11:45:29] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:45:29] Allocating memory for general optimizer shards
[2023-07-01 11:45:29] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:45:29] Loading Adam parameters
[2023-07-01 11:45:29] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:45:29] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:45:29] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:45:29] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:45:29] [data] Shuffling data
[2023-07-01 11:45:30] [data] Done reading 20,192 sentences
[2023-07-01 11:45:30] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:45:30] Training started
[2023-07-01 11:45:30] Training finished
[2023-07-01 11:45:33] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:45:33] [marian] Running on node20.datos.cluster.uy as process 20941 with command line:
[2023-07-01 11:45:33] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 162 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:45:33] [config] after: 0e
[2023-07-01 11:45:33] [config] after-batches: 0
[2023-07-01 11:45:33] [config] after-epochs: 162
[2023-07-01 11:45:33] [config] all-caps-every: 0
[2023-07-01 11:45:33] [config] allow-unk: false
[2023-07-01 11:45:33] [config] authors: false
[2023-07-01 11:45:33] [config] beam-size: 12
[2023-07-01 11:45:33] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:45:33] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:45:33] [config] bert-masking-fraction: 0.15
[2023-07-01 11:45:33] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:45:33] [config] bert-train-type-embeddings: true
[2023-07-01 11:45:33] [config] bert-type-vocab-size: 2
[2023-07-01 11:45:33] [config] build-info: ""
[2023-07-01 11:45:33] [config] check-gradient-nan: false
[2023-07-01 11:45:33] [config] check-nan: false
[2023-07-01 11:45:33] [config] cite: false
[2023-07-01 11:45:33] [config] clip-norm: 5
[2023-07-01 11:45:33] [config] cost-scaling:
[2023-07-01 11:45:33] [config]   []
[2023-07-01 11:45:33] [config] cost-type: ce-sum
[2023-07-01 11:45:33] [config] cpu-threads: 0
[2023-07-01 11:45:33] [config] data-threads: 8
[2023-07-01 11:45:33] [config] data-weighting: ""
[2023-07-01 11:45:33] [config] data-weighting-type: sentence
[2023-07-01 11:45:33] [config] dec-cell: gru
[2023-07-01 11:45:33] [config] dec-cell-base-depth: 2
[2023-07-01 11:45:33] [config] dec-cell-high-depth: 1
[2023-07-01 11:45:33] [config] dec-depth: 2
[2023-07-01 11:45:33] [config] devices:
[2023-07-01 11:45:33] [config]   - 0
[2023-07-01 11:45:33] [config] dim-emb: 512
[2023-07-01 11:45:33] [config] dim-rnn: 1024
[2023-07-01 11:45:33] [config] dim-vocabs:
[2023-07-01 11:45:33] [config]   - 16384
[2023-07-01 11:45:33] [config]   - 16384
[2023-07-01 11:45:33] [config] disp-first: 0
[2023-07-01 11:45:33] [config] disp-freq: 1000u
[2023-07-01 11:45:33] [config] disp-label-counts: true
[2023-07-01 11:45:33] [config] dropout-rnn: 0
[2023-07-01 11:45:33] [config] dropout-src: 0
[2023-07-01 11:45:33] [config] dropout-trg: 0
[2023-07-01 11:45:33] [config] dump-config: ""
[2023-07-01 11:45:33] [config] dynamic-gradient-scaling:
[2023-07-01 11:45:33] [config]   []
[2023-07-01 11:45:33] [config] early-stopping: 10
[2023-07-01 11:45:33] [config] early-stopping-on: first
[2023-07-01 11:45:33] [config] embedding-fix-src: false
[2023-07-01 11:45:33] [config] embedding-fix-trg: false
[2023-07-01 11:45:33] [config] embedding-normalization: false
[2023-07-01 11:45:33] [config] embedding-vectors:
[2023-07-01 11:45:33] [config]   []
[2023-07-01 11:45:33] [config] enc-cell: gru
[2023-07-01 11:45:33] [config] enc-cell-depth: 1
[2023-07-01 11:45:33] [config] enc-depth: 2
[2023-07-01 11:45:33] [config] enc-type: bidirectional
[2023-07-01 11:45:33] [config] english-title-case-every: 0
[2023-07-01 11:45:33] [config] exponential-smoothing: 0.0001
[2023-07-01 11:45:33] [config] factor-weight: 1
[2023-07-01 11:45:33] [config] factors-combine: sum
[2023-07-01 11:45:33] [config] factors-dim-emb: 0
[2023-07-01 11:45:33] [config] gradient-checkpointing: false
[2023-07-01 11:45:33] [config] gradient-norm-average-window: 100
[2023-07-01 11:45:33] [config] guided-alignment: none
[2023-07-01 11:45:33] [config] guided-alignment-cost: mse
[2023-07-01 11:45:33] [config] guided-alignment-weight: 0.1
[2023-07-01 11:45:33] [config] ignore-model-config: false
[2023-07-01 11:45:33] [config] input-types:
[2023-07-01 11:45:33] [config]   []
[2023-07-01 11:45:33] [config] interpolate-env-vars: false
[2023-07-01 11:45:33] [config] keep-best: false
[2023-07-01 11:45:33] [config] label-smoothing: 0.1
[2023-07-01 11:45:33] [config] layer-normalization: false
[2023-07-01 11:45:33] [config] learn-rate: 0.0003
[2023-07-01 11:45:33] [config] lemma-dependency: ""
[2023-07-01 11:45:33] [config] lemma-dim-emb: 0
[2023-07-01 11:45:33] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:45:33] [config] log-level: info
[2023-07-01 11:45:33] [config] log-time-zone: ""
[2023-07-01 11:45:33] [config] logical-epoch:
[2023-07-01 11:45:33] [config]   - 1e
[2023-07-01 11:45:33] [config]   - 0
[2023-07-01 11:45:33] [config] lr-decay: 0
[2023-07-01 11:45:33] [config] lr-decay-freq: 50000
[2023-07-01 11:45:33] [config] lr-decay-inv-sqrt:
[2023-07-01 11:45:33] [config]   - 16000
[2023-07-01 11:45:33] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:45:33] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:45:33] [config] lr-decay-start:
[2023-07-01 11:45:33] [config]   - 10
[2023-07-01 11:45:33] [config]   - 1
[2023-07-01 11:45:33] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:45:33] [config] lr-report: true
[2023-07-01 11:45:33] [config] lr-warmup: 16000
[2023-07-01 11:45:33] [config] lr-warmup-at-reload: false
[2023-07-01 11:45:33] [config] lr-warmup-cycle: false
[2023-07-01 11:45:33] [config] lr-warmup-start-rate: 0
[2023-07-01 11:45:33] [config] max-length: 100
[2023-07-01 11:45:33] [config] max-length-crop: false
[2023-07-01 11:45:33] [config] max-length-factor: 3
[2023-07-01 11:45:33] [config] maxi-batch: 100
[2023-07-01 11:45:33] [config] maxi-batch-sort: trg
[2023-07-01 11:45:33] [config] mini-batch: 1000
[2023-07-01 11:45:33] [config] mini-batch-fit: true
[2023-07-01 11:45:33] [config] mini-batch-fit-step: 10
[2023-07-01 11:45:33] [config] mini-batch-round-up: true
[2023-07-01 11:45:33] [config] mini-batch-track-lr: false
[2023-07-01 11:45:33] [config] mini-batch-warmup: 0
[2023-07-01 11:45:33] [config] mini-batch-words: 0
[2023-07-01 11:45:33] [config] mini-batch-words-ref: 0
[2023-07-01 11:45:33] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:45:33] [config] multi-loss-type: sum
[2023-07-01 11:45:33] [config] n-best: false
[2023-07-01 11:45:33] [config] no-nccl: false
[2023-07-01 11:45:33] [config] no-reload: false
[2023-07-01 11:45:33] [config] no-restore-corpus: false
[2023-07-01 11:45:33] [config] normalize: 1
[2023-07-01 11:45:33] [config] normalize-gradient: false
[2023-07-01 11:45:33] [config] num-devices: 0
[2023-07-01 11:45:33] [config] optimizer: adam
[2023-07-01 11:45:33] [config] optimizer-delay: 1
[2023-07-01 11:45:33] [config] optimizer-params:
[2023-07-01 11:45:33] [config]   - 0.9
[2023-07-01 11:45:33] [config]   - 0.98
[2023-07-01 11:45:33] [config]   - 1e-09
[2023-07-01 11:45:33] [config] output-omit-bias: false
[2023-07-01 11:45:33] [config] overwrite: true
[2023-07-01 11:45:33] [config] precision:
[2023-07-01 11:45:33] [config]   - float32
[2023-07-01 11:45:33] [config]   - float32
[2023-07-01 11:45:33] [config] pretrained-model: ""
[2023-07-01 11:45:33] [config] quantize-biases: false
[2023-07-01 11:45:33] [config] quantize-bits: 0
[2023-07-01 11:45:33] [config] quantize-log-based: false
[2023-07-01 11:45:33] [config] quantize-optimization-steps: 0
[2023-07-01 11:45:33] [config] quiet: false
[2023-07-01 11:45:33] [config] quiet-translation: true
[2023-07-01 11:45:33] [config] relative-paths: false
[2023-07-01 11:45:33] [config] right-left: false
[2023-07-01 11:45:33] [config] save-freq: 10000u
[2023-07-01 11:45:33] [config] seed: 1234
[2023-07-01 11:45:33] [config] sentencepiece-alphas:
[2023-07-01 11:45:33] [config]   []
[2023-07-01 11:45:33] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:45:33] [config] sentencepiece-options: ""
[2023-07-01 11:45:33] [config] sharding: global
[2023-07-01 11:45:33] [config] shuffle: data
[2023-07-01 11:45:33] [config] shuffle-in-ram: false
[2023-07-01 11:45:33] [config] sigterm: save-and-exit
[2023-07-01 11:45:33] [config] skip: false
[2023-07-01 11:45:33] [config] sqlite: ""
[2023-07-01 11:45:33] [config] sqlite-drop: false
[2023-07-01 11:45:33] [config] sync-freq: 200u
[2023-07-01 11:45:33] [config] sync-sgd: true
[2023-07-01 11:45:33] [config] tempdir: /tmp
[2023-07-01 11:45:33] [config] tied-embeddings: false
[2023-07-01 11:45:33] [config] tied-embeddings-all: true
[2023-07-01 11:45:33] [config] tied-embeddings-src: false
[2023-07-01 11:45:33] [config] train-embedder-rank:
[2023-07-01 11:45:33] [config]   []
[2023-07-01 11:45:33] [config] train-sets:
[2023-07-01 11:45:33] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:45:33] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:45:33] [config] transformer-aan-activation: swish
[2023-07-01 11:45:33] [config] transformer-aan-depth: 2
[2023-07-01 11:45:33] [config] transformer-aan-nogate: false
[2023-07-01 11:45:33] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:45:33] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:45:33] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:45:33] [config] transformer-depth-scaling: false
[2023-07-01 11:45:33] [config] transformer-dim-aan: 2048
[2023-07-01 11:45:33] [config] transformer-dim-ffn: 2048
[2023-07-01 11:45:33] [config] transformer-dropout: 0.1
[2023-07-01 11:45:33] [config] transformer-dropout-attention: 0
[2023-07-01 11:45:33] [config] transformer-dropout-ffn: 0
[2023-07-01 11:45:33] [config] transformer-ffn-activation: swish
[2023-07-01 11:45:33] [config] transformer-ffn-depth: 2
[2023-07-01 11:45:33] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:45:33] [config] transformer-heads: 8
[2023-07-01 11:45:33] [config] transformer-no-projection: false
[2023-07-01 11:45:33] [config] transformer-pool: false
[2023-07-01 11:45:33] [config] transformer-postprocess: dan
[2023-07-01 11:45:33] [config] transformer-postprocess-emb: d
[2023-07-01 11:45:33] [config] transformer-postprocess-top: ""
[2023-07-01 11:45:33] [config] transformer-preprocess: ""
[2023-07-01 11:45:33] [config] transformer-tied-layers:
[2023-07-01 11:45:33] [config]   []
[2023-07-01 11:45:33] [config] transformer-train-position-embeddings: false
[2023-07-01 11:45:33] [config] tsv: false
[2023-07-01 11:45:33] [config] tsv-fields: 0
[2023-07-01 11:45:33] [config] type: transformer
[2023-07-01 11:45:33] [config] ulr: false
[2023-07-01 11:45:33] [config] ulr-dim-emb: 0
[2023-07-01 11:45:33] [config] ulr-dropout: 0
[2023-07-01 11:45:33] [config] ulr-keys-vectors: ""
[2023-07-01 11:45:33] [config] ulr-query-vectors: ""
[2023-07-01 11:45:33] [config] ulr-softmax-temperature: 1
[2023-07-01 11:45:33] [config] ulr-trainable-transformation: false
[2023-07-01 11:45:33] [config] unlikelihood-loss: false
[2023-07-01 11:45:33] [config] valid-freq: 50000000
[2023-07-01 11:45:33] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:45:33] [config] valid-max-length: 1000
[2023-07-01 11:45:33] [config] valid-metrics:
[2023-07-01 11:45:33] [config]   - cross-entropy
[2023-07-01 11:45:33] [config]   - translation
[2023-07-01 11:45:33] [config] valid-mini-batch: 64
[2023-07-01 11:45:33] [config] valid-reset-stalled: false
[2023-07-01 11:45:33] [config] valid-script-args:
[2023-07-01 11:45:33] [config]   []
[2023-07-01 11:45:33] [config] valid-script-path: ""
[2023-07-01 11:45:33] [config] valid-sets:
[2023-07-01 11:45:33] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:45:33] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:45:33] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:45:33] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:45:33] [config] vocabs:
[2023-07-01 11:45:33] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:45:33] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:45:33] [config] word-penalty: 0
[2023-07-01 11:45:33] [config] word-scores: false
[2023-07-01 11:45:33] [config] workspace: 2048
[2023-07-01 11:45:33] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:45:33] Using synchronous SGD
[2023-07-01 11:45:33] Synced seed 1234
[2023-07-01 11:45:33] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:45:33] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:45:33] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:45:34] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:45:34] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:45:34] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:45:34] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:45:34] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:45:34] [comm] Using global sharding
[2023-07-01 11:45:34] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:45:34] [training] Using 1 GPUs
[2023-07-01 11:45:34] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:45:34] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:45:35] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:45:35] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:45:42] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:45:42] [valid] No post-processing script given for validating translator
[2023-07-01 11:45:42] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:45:42] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:45:42] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:45:42] [comm] Using global sharding
[2023-07-01 11:45:42] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:45:42] [training] Using 1 GPUs
[2023-07-01 11:45:42] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:45:43] Allocating memory for general optimizer shards
[2023-07-01 11:45:43] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:45:43] Loading Adam parameters
[2023-07-01 11:45:43] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:45:43] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:45:43] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:45:43] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:45:43] [data] Shuffling data
[2023-07-01 11:45:43] [data] Done reading 20,192 sentences
[2023-07-01 11:45:43] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:45:43] Training started
[2023-07-01 11:45:43] Training finished
[2023-07-01 11:45:47] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:45:47] [marian] Running on node20.datos.cluster.uy as process 21000 with command line:
[2023-07-01 11:45:47] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 163 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:45:47] [config] after: 0e
[2023-07-01 11:45:47] [config] after-batches: 0
[2023-07-01 11:45:47] [config] after-epochs: 163
[2023-07-01 11:45:47] [config] all-caps-every: 0
[2023-07-01 11:45:47] [config] allow-unk: false
[2023-07-01 11:45:47] [config] authors: false
[2023-07-01 11:45:47] [config] beam-size: 12
[2023-07-01 11:45:47] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:45:47] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:45:47] [config] bert-masking-fraction: 0.15
[2023-07-01 11:45:47] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:45:47] [config] bert-train-type-embeddings: true
[2023-07-01 11:45:47] [config] bert-type-vocab-size: 2
[2023-07-01 11:45:47] [config] build-info: ""
[2023-07-01 11:45:47] [config] check-gradient-nan: false
[2023-07-01 11:45:47] [config] check-nan: false
[2023-07-01 11:45:47] [config] cite: false
[2023-07-01 11:45:47] [config] clip-norm: 5
[2023-07-01 11:45:47] [config] cost-scaling:
[2023-07-01 11:45:47] [config]   []
[2023-07-01 11:45:47] [config] cost-type: ce-sum
[2023-07-01 11:45:47] [config] cpu-threads: 0
[2023-07-01 11:45:47] [config] data-threads: 8
[2023-07-01 11:45:47] [config] data-weighting: ""
[2023-07-01 11:45:47] [config] data-weighting-type: sentence
[2023-07-01 11:45:47] [config] dec-cell: gru
[2023-07-01 11:45:47] [config] dec-cell-base-depth: 2
[2023-07-01 11:45:47] [config] dec-cell-high-depth: 1
[2023-07-01 11:45:47] [config] dec-depth: 2
[2023-07-01 11:45:47] [config] devices:
[2023-07-01 11:45:47] [config]   - 0
[2023-07-01 11:45:47] [config] dim-emb: 512
[2023-07-01 11:45:47] [config] dim-rnn: 1024
[2023-07-01 11:45:47] [config] dim-vocabs:
[2023-07-01 11:45:47] [config]   - 16384
[2023-07-01 11:45:47] [config]   - 16384
[2023-07-01 11:45:47] [config] disp-first: 0
[2023-07-01 11:45:47] [config] disp-freq: 1000u
[2023-07-01 11:45:47] [config] disp-label-counts: true
[2023-07-01 11:45:47] [config] dropout-rnn: 0
[2023-07-01 11:45:47] [config] dropout-src: 0
[2023-07-01 11:45:47] [config] dropout-trg: 0
[2023-07-01 11:45:47] [config] dump-config: ""
[2023-07-01 11:45:47] [config] dynamic-gradient-scaling:
[2023-07-01 11:45:47] [config]   []
[2023-07-01 11:45:47] [config] early-stopping: 10
[2023-07-01 11:45:47] [config] early-stopping-on: first
[2023-07-01 11:45:47] [config] embedding-fix-src: false
[2023-07-01 11:45:47] [config] embedding-fix-trg: false
[2023-07-01 11:45:47] [config] embedding-normalization: false
[2023-07-01 11:45:47] [config] embedding-vectors:
[2023-07-01 11:45:47] [config]   []
[2023-07-01 11:45:47] [config] enc-cell: gru
[2023-07-01 11:45:47] [config] enc-cell-depth: 1
[2023-07-01 11:45:47] [config] enc-depth: 2
[2023-07-01 11:45:47] [config] enc-type: bidirectional
[2023-07-01 11:45:47] [config] english-title-case-every: 0
[2023-07-01 11:45:47] [config] exponential-smoothing: 0.0001
[2023-07-01 11:45:47] [config] factor-weight: 1
[2023-07-01 11:45:47] [config] factors-combine: sum
[2023-07-01 11:45:47] [config] factors-dim-emb: 0
[2023-07-01 11:45:47] [config] gradient-checkpointing: false
[2023-07-01 11:45:47] [config] gradient-norm-average-window: 100
[2023-07-01 11:45:47] [config] guided-alignment: none
[2023-07-01 11:45:47] [config] guided-alignment-cost: mse
[2023-07-01 11:45:47] [config] guided-alignment-weight: 0.1
[2023-07-01 11:45:47] [config] ignore-model-config: false
[2023-07-01 11:45:47] [config] input-types:
[2023-07-01 11:45:47] [config]   []
[2023-07-01 11:45:47] [config] interpolate-env-vars: false
[2023-07-01 11:45:47] [config] keep-best: false
[2023-07-01 11:45:47] [config] label-smoothing: 0.1
[2023-07-01 11:45:47] [config] layer-normalization: false
[2023-07-01 11:45:47] [config] learn-rate: 0.0003
[2023-07-01 11:45:47] [config] lemma-dependency: ""
[2023-07-01 11:45:47] [config] lemma-dim-emb: 0
[2023-07-01 11:45:47] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:45:47] [config] log-level: info
[2023-07-01 11:45:47] [config] log-time-zone: ""
[2023-07-01 11:45:47] [config] logical-epoch:
[2023-07-01 11:45:47] [config]   - 1e
[2023-07-01 11:45:47] [config]   - 0
[2023-07-01 11:45:47] [config] lr-decay: 0
[2023-07-01 11:45:47] [config] lr-decay-freq: 50000
[2023-07-01 11:45:47] [config] lr-decay-inv-sqrt:
[2023-07-01 11:45:47] [config]   - 16000
[2023-07-01 11:45:47] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:45:47] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:45:47] [config] lr-decay-start:
[2023-07-01 11:45:47] [config]   - 10
[2023-07-01 11:45:47] [config]   - 1
[2023-07-01 11:45:47] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:45:47] [config] lr-report: true
[2023-07-01 11:45:47] [config] lr-warmup: 16000
[2023-07-01 11:45:47] [config] lr-warmup-at-reload: false
[2023-07-01 11:45:47] [config] lr-warmup-cycle: false
[2023-07-01 11:45:47] [config] lr-warmup-start-rate: 0
[2023-07-01 11:45:47] [config] max-length: 100
[2023-07-01 11:45:47] [config] max-length-crop: false
[2023-07-01 11:45:47] [config] max-length-factor: 3
[2023-07-01 11:45:47] [config] maxi-batch: 100
[2023-07-01 11:45:47] [config] maxi-batch-sort: trg
[2023-07-01 11:45:47] [config] mini-batch: 1000
[2023-07-01 11:45:47] [config] mini-batch-fit: true
[2023-07-01 11:45:47] [config] mini-batch-fit-step: 10
[2023-07-01 11:45:47] [config] mini-batch-round-up: true
[2023-07-01 11:45:47] [config] mini-batch-track-lr: false
[2023-07-01 11:45:47] [config] mini-batch-warmup: 0
[2023-07-01 11:45:47] [config] mini-batch-words: 0
[2023-07-01 11:45:47] [config] mini-batch-words-ref: 0
[2023-07-01 11:45:47] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:45:47] [config] multi-loss-type: sum
[2023-07-01 11:45:47] [config] n-best: false
[2023-07-01 11:45:47] [config] no-nccl: false
[2023-07-01 11:45:47] [config] no-reload: false
[2023-07-01 11:45:47] [config] no-restore-corpus: false
[2023-07-01 11:45:47] [config] normalize: 1
[2023-07-01 11:45:47] [config] normalize-gradient: false
[2023-07-01 11:45:47] [config] num-devices: 0
[2023-07-01 11:45:47] [config] optimizer: adam
[2023-07-01 11:45:47] [config] optimizer-delay: 1
[2023-07-01 11:45:47] [config] optimizer-params:
[2023-07-01 11:45:47] [config]   - 0.9
[2023-07-01 11:45:47] [config]   - 0.98
[2023-07-01 11:45:47] [config]   - 1e-09
[2023-07-01 11:45:47] [config] output-omit-bias: false
[2023-07-01 11:45:47] [config] overwrite: true
[2023-07-01 11:45:47] [config] precision:
[2023-07-01 11:45:47] [config]   - float32
[2023-07-01 11:45:47] [config]   - float32
[2023-07-01 11:45:47] [config] pretrained-model: ""
[2023-07-01 11:45:47] [config] quantize-biases: false
[2023-07-01 11:45:47] [config] quantize-bits: 0
[2023-07-01 11:45:47] [config] quantize-log-based: false
[2023-07-01 11:45:47] [config] quantize-optimization-steps: 0
[2023-07-01 11:45:47] [config] quiet: false
[2023-07-01 11:45:47] [config] quiet-translation: true
[2023-07-01 11:45:47] [config] relative-paths: false
[2023-07-01 11:45:47] [config] right-left: false
[2023-07-01 11:45:47] [config] save-freq: 10000u
[2023-07-01 11:45:47] [config] seed: 1234
[2023-07-01 11:45:47] [config] sentencepiece-alphas:
[2023-07-01 11:45:47] [config]   []
[2023-07-01 11:45:47] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:45:47] [config] sentencepiece-options: ""
[2023-07-01 11:45:47] [config] sharding: global
[2023-07-01 11:45:47] [config] shuffle: data
[2023-07-01 11:45:47] [config] shuffle-in-ram: false
[2023-07-01 11:45:47] [config] sigterm: save-and-exit
[2023-07-01 11:45:47] [config] skip: false
[2023-07-01 11:45:47] [config] sqlite: ""
[2023-07-01 11:45:47] [config] sqlite-drop: false
[2023-07-01 11:45:47] [config] sync-freq: 200u
[2023-07-01 11:45:47] [config] sync-sgd: true
[2023-07-01 11:45:47] [config] tempdir: /tmp
[2023-07-01 11:45:47] [config] tied-embeddings: false
[2023-07-01 11:45:47] [config] tied-embeddings-all: true
[2023-07-01 11:45:47] [config] tied-embeddings-src: false
[2023-07-01 11:45:47] [config] train-embedder-rank:
[2023-07-01 11:45:47] [config]   []
[2023-07-01 11:45:47] [config] train-sets:
[2023-07-01 11:45:47] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:45:47] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:45:47] [config] transformer-aan-activation: swish
[2023-07-01 11:45:47] [config] transformer-aan-depth: 2
[2023-07-01 11:45:47] [config] transformer-aan-nogate: false
[2023-07-01 11:45:47] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:45:47] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:45:47] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:45:47] [config] transformer-depth-scaling: false
[2023-07-01 11:45:47] [config] transformer-dim-aan: 2048
[2023-07-01 11:45:47] [config] transformer-dim-ffn: 2048
[2023-07-01 11:45:47] [config] transformer-dropout: 0.1
[2023-07-01 11:45:47] [config] transformer-dropout-attention: 0
[2023-07-01 11:45:47] [config] transformer-dropout-ffn: 0
[2023-07-01 11:45:47] [config] transformer-ffn-activation: swish
[2023-07-01 11:45:47] [config] transformer-ffn-depth: 2
[2023-07-01 11:45:47] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:45:47] [config] transformer-heads: 8
[2023-07-01 11:45:47] [config] transformer-no-projection: false
[2023-07-01 11:45:47] [config] transformer-pool: false
[2023-07-01 11:45:47] [config] transformer-postprocess: dan
[2023-07-01 11:45:47] [config] transformer-postprocess-emb: d
[2023-07-01 11:45:47] [config] transformer-postprocess-top: ""
[2023-07-01 11:45:47] [config] transformer-preprocess: ""
[2023-07-01 11:45:47] [config] transformer-tied-layers:
[2023-07-01 11:45:47] [config]   []
[2023-07-01 11:45:47] [config] transformer-train-position-embeddings: false
[2023-07-01 11:45:47] [config] tsv: false
[2023-07-01 11:45:47] [config] tsv-fields: 0
[2023-07-01 11:45:47] [config] type: transformer
[2023-07-01 11:45:47] [config] ulr: false
[2023-07-01 11:45:47] [config] ulr-dim-emb: 0
[2023-07-01 11:45:47] [config] ulr-dropout: 0
[2023-07-01 11:45:47] [config] ulr-keys-vectors: ""
[2023-07-01 11:45:47] [config] ulr-query-vectors: ""
[2023-07-01 11:45:47] [config] ulr-softmax-temperature: 1
[2023-07-01 11:45:47] [config] ulr-trainable-transformation: false
[2023-07-01 11:45:47] [config] unlikelihood-loss: false
[2023-07-01 11:45:47] [config] valid-freq: 50000000
[2023-07-01 11:45:47] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:45:47] [config] valid-max-length: 1000
[2023-07-01 11:45:47] [config] valid-metrics:
[2023-07-01 11:45:47] [config]   - cross-entropy
[2023-07-01 11:45:47] [config]   - translation
[2023-07-01 11:45:47] [config] valid-mini-batch: 64
[2023-07-01 11:45:47] [config] valid-reset-stalled: false
[2023-07-01 11:45:47] [config] valid-script-args:
[2023-07-01 11:45:47] [config]   []
[2023-07-01 11:45:47] [config] valid-script-path: ""
[2023-07-01 11:45:47] [config] valid-sets:
[2023-07-01 11:45:47] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:45:47] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:45:47] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:45:47] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:45:47] [config] vocabs:
[2023-07-01 11:45:47] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:45:47] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:45:47] [config] word-penalty: 0
[2023-07-01 11:45:47] [config] word-scores: false
[2023-07-01 11:45:47] [config] workspace: 2048
[2023-07-01 11:45:47] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:45:47] Using synchronous SGD
[2023-07-01 11:45:47] Synced seed 1234
[2023-07-01 11:45:47] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:45:47] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:45:47] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:45:47] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:45:47] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:45:47] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:45:48] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:45:48] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:45:48] [comm] Using global sharding
[2023-07-01 11:45:48] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:45:48] [training] Using 1 GPUs
[2023-07-01 11:45:48] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:45:48] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:45:48] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:45:48] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:45:56] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:45:56] [valid] No post-processing script given for validating translator
[2023-07-01 11:45:56] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:45:56] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:45:56] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:45:56] [comm] Using global sharding
[2023-07-01 11:45:56] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:45:56] [training] Using 1 GPUs
[2023-07-01 11:45:56] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:45:56] Allocating memory for general optimizer shards
[2023-07-01 11:45:56] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:45:56] Loading Adam parameters
[2023-07-01 11:45:56] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:45:56] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:45:56] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:45:56] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:45:56] [data] Shuffling data
[2023-07-01 11:45:56] [data] Done reading 20,192 sentences
[2023-07-01 11:45:57] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:45:57] Training started
[2023-07-01 11:45:57] Training finished
[2023-07-01 11:46:00] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:46:00] [marian] Running on node20.datos.cluster.uy as process 21059 with command line:
[2023-07-01 11:46:00] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 164 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:46:00] [config] after: 0e
[2023-07-01 11:46:00] [config] after-batches: 0
[2023-07-01 11:46:00] [config] after-epochs: 164
[2023-07-01 11:46:00] [config] all-caps-every: 0
[2023-07-01 11:46:00] [config] allow-unk: false
[2023-07-01 11:46:00] [config] authors: false
[2023-07-01 11:46:00] [config] beam-size: 12
[2023-07-01 11:46:00] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:46:00] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:46:00] [config] bert-masking-fraction: 0.15
[2023-07-01 11:46:00] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:46:00] [config] bert-train-type-embeddings: true
[2023-07-01 11:46:00] [config] bert-type-vocab-size: 2
[2023-07-01 11:46:00] [config] build-info: ""
[2023-07-01 11:46:00] [config] check-gradient-nan: false
[2023-07-01 11:46:00] [config] check-nan: false
[2023-07-01 11:46:00] [config] cite: false
[2023-07-01 11:46:00] [config] clip-norm: 5
[2023-07-01 11:46:00] [config] cost-scaling:
[2023-07-01 11:46:00] [config]   []
[2023-07-01 11:46:00] [config] cost-type: ce-sum
[2023-07-01 11:46:00] [config] cpu-threads: 0
[2023-07-01 11:46:00] [config] data-threads: 8
[2023-07-01 11:46:00] [config] data-weighting: ""
[2023-07-01 11:46:00] [config] data-weighting-type: sentence
[2023-07-01 11:46:00] [config] dec-cell: gru
[2023-07-01 11:46:00] [config] dec-cell-base-depth: 2
[2023-07-01 11:46:00] [config] dec-cell-high-depth: 1
[2023-07-01 11:46:00] [config] dec-depth: 2
[2023-07-01 11:46:00] [config] devices:
[2023-07-01 11:46:00] [config]   - 0
[2023-07-01 11:46:00] [config] dim-emb: 512
[2023-07-01 11:46:00] [config] dim-rnn: 1024
[2023-07-01 11:46:00] [config] dim-vocabs:
[2023-07-01 11:46:00] [config]   - 16384
[2023-07-01 11:46:00] [config]   - 16384
[2023-07-01 11:46:00] [config] disp-first: 0
[2023-07-01 11:46:00] [config] disp-freq: 1000u
[2023-07-01 11:46:00] [config] disp-label-counts: true
[2023-07-01 11:46:00] [config] dropout-rnn: 0
[2023-07-01 11:46:00] [config] dropout-src: 0
[2023-07-01 11:46:00] [config] dropout-trg: 0
[2023-07-01 11:46:00] [config] dump-config: ""
[2023-07-01 11:46:00] [config] dynamic-gradient-scaling:
[2023-07-01 11:46:00] [config]   []
[2023-07-01 11:46:00] [config] early-stopping: 10
[2023-07-01 11:46:00] [config] early-stopping-on: first
[2023-07-01 11:46:00] [config] embedding-fix-src: false
[2023-07-01 11:46:00] [config] embedding-fix-trg: false
[2023-07-01 11:46:00] [config] embedding-normalization: false
[2023-07-01 11:46:00] [config] embedding-vectors:
[2023-07-01 11:46:00] [config]   []
[2023-07-01 11:46:00] [config] enc-cell: gru
[2023-07-01 11:46:00] [config] enc-cell-depth: 1
[2023-07-01 11:46:00] [config] enc-depth: 2
[2023-07-01 11:46:00] [config] enc-type: bidirectional
[2023-07-01 11:46:00] [config] english-title-case-every: 0
[2023-07-01 11:46:00] [config] exponential-smoothing: 0.0001
[2023-07-01 11:46:00] [config] factor-weight: 1
[2023-07-01 11:46:00] [config] factors-combine: sum
[2023-07-01 11:46:00] [config] factors-dim-emb: 0
[2023-07-01 11:46:00] [config] gradient-checkpointing: false
[2023-07-01 11:46:00] [config] gradient-norm-average-window: 100
[2023-07-01 11:46:00] [config] guided-alignment: none
[2023-07-01 11:46:00] [config] guided-alignment-cost: mse
[2023-07-01 11:46:00] [config] guided-alignment-weight: 0.1
[2023-07-01 11:46:00] [config] ignore-model-config: false
[2023-07-01 11:46:00] [config] input-types:
[2023-07-01 11:46:00] [config]   []
[2023-07-01 11:46:00] [config] interpolate-env-vars: false
[2023-07-01 11:46:00] [config] keep-best: false
[2023-07-01 11:46:00] [config] label-smoothing: 0.1
[2023-07-01 11:46:00] [config] layer-normalization: false
[2023-07-01 11:46:00] [config] learn-rate: 0.0003
[2023-07-01 11:46:00] [config] lemma-dependency: ""
[2023-07-01 11:46:00] [config] lemma-dim-emb: 0
[2023-07-01 11:46:00] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:46:00] [config] log-level: info
[2023-07-01 11:46:00] [config] log-time-zone: ""
[2023-07-01 11:46:00] [config] logical-epoch:
[2023-07-01 11:46:00] [config]   - 1e
[2023-07-01 11:46:00] [config]   - 0
[2023-07-01 11:46:00] [config] lr-decay: 0
[2023-07-01 11:46:00] [config] lr-decay-freq: 50000
[2023-07-01 11:46:00] [config] lr-decay-inv-sqrt:
[2023-07-01 11:46:00] [config]   - 16000
[2023-07-01 11:46:00] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:46:00] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:46:00] [config] lr-decay-start:
[2023-07-01 11:46:00] [config]   - 10
[2023-07-01 11:46:00] [config]   - 1
[2023-07-01 11:46:00] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:46:00] [config] lr-report: true
[2023-07-01 11:46:00] [config] lr-warmup: 16000
[2023-07-01 11:46:00] [config] lr-warmup-at-reload: false
[2023-07-01 11:46:00] [config] lr-warmup-cycle: false
[2023-07-01 11:46:00] [config] lr-warmup-start-rate: 0
[2023-07-01 11:46:00] [config] max-length: 100
[2023-07-01 11:46:00] [config] max-length-crop: false
[2023-07-01 11:46:00] [config] max-length-factor: 3
[2023-07-01 11:46:00] [config] maxi-batch: 100
[2023-07-01 11:46:00] [config] maxi-batch-sort: trg
[2023-07-01 11:46:00] [config] mini-batch: 1000
[2023-07-01 11:46:00] [config] mini-batch-fit: true
[2023-07-01 11:46:00] [config] mini-batch-fit-step: 10
[2023-07-01 11:46:00] [config] mini-batch-round-up: true
[2023-07-01 11:46:00] [config] mini-batch-track-lr: false
[2023-07-01 11:46:00] [config] mini-batch-warmup: 0
[2023-07-01 11:46:00] [config] mini-batch-words: 0
[2023-07-01 11:46:00] [config] mini-batch-words-ref: 0
[2023-07-01 11:46:00] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:46:00] [config] multi-loss-type: sum
[2023-07-01 11:46:00] [config] n-best: false
[2023-07-01 11:46:00] [config] no-nccl: false
[2023-07-01 11:46:00] [config] no-reload: false
[2023-07-01 11:46:00] [config] no-restore-corpus: false
[2023-07-01 11:46:00] [config] normalize: 1
[2023-07-01 11:46:00] [config] normalize-gradient: false
[2023-07-01 11:46:00] [config] num-devices: 0
[2023-07-01 11:46:00] [config] optimizer: adam
[2023-07-01 11:46:00] [config] optimizer-delay: 1
[2023-07-01 11:46:00] [config] optimizer-params:
[2023-07-01 11:46:00] [config]   - 0.9
[2023-07-01 11:46:00] [config]   - 0.98
[2023-07-01 11:46:00] [config]   - 1e-09
[2023-07-01 11:46:00] [config] output-omit-bias: false
[2023-07-01 11:46:00] [config] overwrite: true
[2023-07-01 11:46:00] [config] precision:
[2023-07-01 11:46:00] [config]   - float32
[2023-07-01 11:46:00] [config]   - float32
[2023-07-01 11:46:00] [config] pretrained-model: ""
[2023-07-01 11:46:00] [config] quantize-biases: false
[2023-07-01 11:46:00] [config] quantize-bits: 0
[2023-07-01 11:46:00] [config] quantize-log-based: false
[2023-07-01 11:46:00] [config] quantize-optimization-steps: 0
[2023-07-01 11:46:00] [config] quiet: false
[2023-07-01 11:46:00] [config] quiet-translation: true
[2023-07-01 11:46:00] [config] relative-paths: false
[2023-07-01 11:46:00] [config] right-left: false
[2023-07-01 11:46:00] [config] save-freq: 10000u
[2023-07-01 11:46:00] [config] seed: 1234
[2023-07-01 11:46:00] [config] sentencepiece-alphas:
[2023-07-01 11:46:00] [config]   []
[2023-07-01 11:46:00] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:46:00] [config] sentencepiece-options: ""
[2023-07-01 11:46:00] [config] sharding: global
[2023-07-01 11:46:00] [config] shuffle: data
[2023-07-01 11:46:00] [config] shuffle-in-ram: false
[2023-07-01 11:46:00] [config] sigterm: save-and-exit
[2023-07-01 11:46:00] [config] skip: false
[2023-07-01 11:46:00] [config] sqlite: ""
[2023-07-01 11:46:00] [config] sqlite-drop: false
[2023-07-01 11:46:00] [config] sync-freq: 200u
[2023-07-01 11:46:00] [config] sync-sgd: true
[2023-07-01 11:46:00] [config] tempdir: /tmp
[2023-07-01 11:46:00] [config] tied-embeddings: false
[2023-07-01 11:46:00] [config] tied-embeddings-all: true
[2023-07-01 11:46:00] [config] tied-embeddings-src: false
[2023-07-01 11:46:00] [config] train-embedder-rank:
[2023-07-01 11:46:00] [config]   []
[2023-07-01 11:46:00] [config] train-sets:
[2023-07-01 11:46:00] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:46:00] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:46:00] [config] transformer-aan-activation: swish
[2023-07-01 11:46:00] [config] transformer-aan-depth: 2
[2023-07-01 11:46:00] [config] transformer-aan-nogate: false
[2023-07-01 11:46:00] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:46:00] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:46:00] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:46:00] [config] transformer-depth-scaling: false
[2023-07-01 11:46:00] [config] transformer-dim-aan: 2048
[2023-07-01 11:46:00] [config] transformer-dim-ffn: 2048
[2023-07-01 11:46:00] [config] transformer-dropout: 0.1
[2023-07-01 11:46:00] [config] transformer-dropout-attention: 0
[2023-07-01 11:46:00] [config] transformer-dropout-ffn: 0
[2023-07-01 11:46:00] [config] transformer-ffn-activation: swish
[2023-07-01 11:46:00] [config] transformer-ffn-depth: 2
[2023-07-01 11:46:00] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:46:00] [config] transformer-heads: 8
[2023-07-01 11:46:00] [config] transformer-no-projection: false
[2023-07-01 11:46:00] [config] transformer-pool: false
[2023-07-01 11:46:00] [config] transformer-postprocess: dan
[2023-07-01 11:46:00] [config] transformer-postprocess-emb: d
[2023-07-01 11:46:00] [config] transformer-postprocess-top: ""
[2023-07-01 11:46:00] [config] transformer-preprocess: ""
[2023-07-01 11:46:00] [config] transformer-tied-layers:
[2023-07-01 11:46:00] [config]   []
[2023-07-01 11:46:00] [config] transformer-train-position-embeddings: false
[2023-07-01 11:46:00] [config] tsv: false
[2023-07-01 11:46:00] [config] tsv-fields: 0
[2023-07-01 11:46:00] [config] type: transformer
[2023-07-01 11:46:00] [config] ulr: false
[2023-07-01 11:46:00] [config] ulr-dim-emb: 0
[2023-07-01 11:46:00] [config] ulr-dropout: 0
[2023-07-01 11:46:00] [config] ulr-keys-vectors: ""
[2023-07-01 11:46:00] [config] ulr-query-vectors: ""
[2023-07-01 11:46:00] [config] ulr-softmax-temperature: 1
[2023-07-01 11:46:00] [config] ulr-trainable-transformation: false
[2023-07-01 11:46:00] [config] unlikelihood-loss: false
[2023-07-01 11:46:00] [config] valid-freq: 50000000
[2023-07-01 11:46:00] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:46:00] [config] valid-max-length: 1000
[2023-07-01 11:46:00] [config] valid-metrics:
[2023-07-01 11:46:00] [config]   - cross-entropy
[2023-07-01 11:46:00] [config]   - translation
[2023-07-01 11:46:00] [config] valid-mini-batch: 64
[2023-07-01 11:46:00] [config] valid-reset-stalled: false
[2023-07-01 11:46:00] [config] valid-script-args:
[2023-07-01 11:46:00] [config]   []
[2023-07-01 11:46:00] [config] valid-script-path: ""
[2023-07-01 11:46:00] [config] valid-sets:
[2023-07-01 11:46:00] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:46:00] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:46:00] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:46:00] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:46:00] [config] vocabs:
[2023-07-01 11:46:00] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:46:00] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:46:00] [config] word-penalty: 0
[2023-07-01 11:46:00] [config] word-scores: false
[2023-07-01 11:46:00] [config] workspace: 2048
[2023-07-01 11:46:00] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:46:00] Using synchronous SGD
[2023-07-01 11:46:00] Synced seed 1234
[2023-07-01 11:46:00] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:46:00] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:46:00] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:46:00] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:46:00] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:46:00] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:46:01] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:46:01] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:46:01] [comm] Using global sharding
[2023-07-01 11:46:01] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:46:01] [training] Using 1 GPUs
[2023-07-01 11:46:01] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:46:01] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:46:01] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:46:02] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:46:09] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:46:09] [valid] No post-processing script given for validating translator
[2023-07-01 11:46:09] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:46:09] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:46:09] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:46:09] [comm] Using global sharding
[2023-07-01 11:46:09] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:46:09] [training] Using 1 GPUs
[2023-07-01 11:46:09] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:46:10] Allocating memory for general optimizer shards
[2023-07-01 11:46:10] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:46:10] Loading Adam parameters
[2023-07-01 11:46:10] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:46:10] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:46:10] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:46:10] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:46:10] [data] Shuffling data
[2023-07-01 11:46:10] [data] Done reading 20,192 sentences
[2023-07-01 11:46:10] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:46:10] Training started
[2023-07-01 11:46:10] Training finished
[2023-07-01 11:46:13] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:46:13] [marian] Running on node20.datos.cluster.uy as process 21120 with command line:
[2023-07-01 11:46:13] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 165 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:46:13] [config] after: 0e
[2023-07-01 11:46:13] [config] after-batches: 0
[2023-07-01 11:46:13] [config] after-epochs: 165
[2023-07-01 11:46:13] [config] all-caps-every: 0
[2023-07-01 11:46:13] [config] allow-unk: false
[2023-07-01 11:46:13] [config] authors: false
[2023-07-01 11:46:13] [config] beam-size: 12
[2023-07-01 11:46:13] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:46:13] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:46:13] [config] bert-masking-fraction: 0.15
[2023-07-01 11:46:13] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:46:13] [config] bert-train-type-embeddings: true
[2023-07-01 11:46:13] [config] bert-type-vocab-size: 2
[2023-07-01 11:46:13] [config] build-info: ""
[2023-07-01 11:46:13] [config] check-gradient-nan: false
[2023-07-01 11:46:13] [config] check-nan: false
[2023-07-01 11:46:13] [config] cite: false
[2023-07-01 11:46:13] [config] clip-norm: 5
[2023-07-01 11:46:13] [config] cost-scaling:
[2023-07-01 11:46:13] [config]   []
[2023-07-01 11:46:13] [config] cost-type: ce-sum
[2023-07-01 11:46:13] [config] cpu-threads: 0
[2023-07-01 11:46:13] [config] data-threads: 8
[2023-07-01 11:46:13] [config] data-weighting: ""
[2023-07-01 11:46:13] [config] data-weighting-type: sentence
[2023-07-01 11:46:13] [config] dec-cell: gru
[2023-07-01 11:46:13] [config] dec-cell-base-depth: 2
[2023-07-01 11:46:13] [config] dec-cell-high-depth: 1
[2023-07-01 11:46:13] [config] dec-depth: 2
[2023-07-01 11:46:13] [config] devices:
[2023-07-01 11:46:13] [config]   - 0
[2023-07-01 11:46:13] [config] dim-emb: 512
[2023-07-01 11:46:13] [config] dim-rnn: 1024
[2023-07-01 11:46:13] [config] dim-vocabs:
[2023-07-01 11:46:13] [config]   - 16384
[2023-07-01 11:46:13] [config]   - 16384
[2023-07-01 11:46:13] [config] disp-first: 0
[2023-07-01 11:46:13] [config] disp-freq: 1000u
[2023-07-01 11:46:13] [config] disp-label-counts: true
[2023-07-01 11:46:13] [config] dropout-rnn: 0
[2023-07-01 11:46:13] [config] dropout-src: 0
[2023-07-01 11:46:13] [config] dropout-trg: 0
[2023-07-01 11:46:13] [config] dump-config: ""
[2023-07-01 11:46:13] [config] dynamic-gradient-scaling:
[2023-07-01 11:46:13] [config]   []
[2023-07-01 11:46:13] [config] early-stopping: 10
[2023-07-01 11:46:13] [config] early-stopping-on: first
[2023-07-01 11:46:13] [config] embedding-fix-src: false
[2023-07-01 11:46:13] [config] embedding-fix-trg: false
[2023-07-01 11:46:13] [config] embedding-normalization: false
[2023-07-01 11:46:13] [config] embedding-vectors:
[2023-07-01 11:46:13] [config]   []
[2023-07-01 11:46:13] [config] enc-cell: gru
[2023-07-01 11:46:13] [config] enc-cell-depth: 1
[2023-07-01 11:46:13] [config] enc-depth: 2
[2023-07-01 11:46:13] [config] enc-type: bidirectional
[2023-07-01 11:46:13] [config] english-title-case-every: 0
[2023-07-01 11:46:13] [config] exponential-smoothing: 0.0001
[2023-07-01 11:46:13] [config] factor-weight: 1
[2023-07-01 11:46:13] [config] factors-combine: sum
[2023-07-01 11:46:13] [config] factors-dim-emb: 0
[2023-07-01 11:46:13] [config] gradient-checkpointing: false
[2023-07-01 11:46:13] [config] gradient-norm-average-window: 100
[2023-07-01 11:46:13] [config] guided-alignment: none
[2023-07-01 11:46:13] [config] guided-alignment-cost: mse
[2023-07-01 11:46:13] [config] guided-alignment-weight: 0.1
[2023-07-01 11:46:13] [config] ignore-model-config: false
[2023-07-01 11:46:13] [config] input-types:
[2023-07-01 11:46:13] [config]   []
[2023-07-01 11:46:13] [config] interpolate-env-vars: false
[2023-07-01 11:46:13] [config] keep-best: false
[2023-07-01 11:46:13] [config] label-smoothing: 0.1
[2023-07-01 11:46:13] [config] layer-normalization: false
[2023-07-01 11:46:13] [config] learn-rate: 0.0003
[2023-07-01 11:46:13] [config] lemma-dependency: ""
[2023-07-01 11:46:13] [config] lemma-dim-emb: 0
[2023-07-01 11:46:13] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:46:13] [config] log-level: info
[2023-07-01 11:46:13] [config] log-time-zone: ""
[2023-07-01 11:46:13] [config] logical-epoch:
[2023-07-01 11:46:13] [config]   - 1e
[2023-07-01 11:46:13] [config]   - 0
[2023-07-01 11:46:13] [config] lr-decay: 0
[2023-07-01 11:46:13] [config] lr-decay-freq: 50000
[2023-07-01 11:46:13] [config] lr-decay-inv-sqrt:
[2023-07-01 11:46:13] [config]   - 16000
[2023-07-01 11:46:13] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:46:13] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:46:13] [config] lr-decay-start:
[2023-07-01 11:46:13] [config]   - 10
[2023-07-01 11:46:13] [config]   - 1
[2023-07-01 11:46:13] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:46:13] [config] lr-report: true
[2023-07-01 11:46:13] [config] lr-warmup: 16000
[2023-07-01 11:46:13] [config] lr-warmup-at-reload: false
[2023-07-01 11:46:13] [config] lr-warmup-cycle: false
[2023-07-01 11:46:13] [config] lr-warmup-start-rate: 0
[2023-07-01 11:46:13] [config] max-length: 100
[2023-07-01 11:46:13] [config] max-length-crop: false
[2023-07-01 11:46:13] [config] max-length-factor: 3
[2023-07-01 11:46:13] [config] maxi-batch: 100
[2023-07-01 11:46:13] [config] maxi-batch-sort: trg
[2023-07-01 11:46:13] [config] mini-batch: 1000
[2023-07-01 11:46:13] [config] mini-batch-fit: true
[2023-07-01 11:46:13] [config] mini-batch-fit-step: 10
[2023-07-01 11:46:13] [config] mini-batch-round-up: true
[2023-07-01 11:46:13] [config] mini-batch-track-lr: false
[2023-07-01 11:46:14] [config] mini-batch-warmup: 0
[2023-07-01 11:46:14] [config] mini-batch-words: 0
[2023-07-01 11:46:14] [config] mini-batch-words-ref: 0
[2023-07-01 11:46:14] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:46:14] [config] multi-loss-type: sum
[2023-07-01 11:46:14] [config] n-best: false
[2023-07-01 11:46:14] [config] no-nccl: false
[2023-07-01 11:46:14] [config] no-reload: false
[2023-07-01 11:46:14] [config] no-restore-corpus: false
[2023-07-01 11:46:14] [config] normalize: 1
[2023-07-01 11:46:14] [config] normalize-gradient: false
[2023-07-01 11:46:14] [config] num-devices: 0
[2023-07-01 11:46:14] [config] optimizer: adam
[2023-07-01 11:46:14] [config] optimizer-delay: 1
[2023-07-01 11:46:14] [config] optimizer-params:
[2023-07-01 11:46:14] [config]   - 0.9
[2023-07-01 11:46:14] [config]   - 0.98
[2023-07-01 11:46:14] [config]   - 1e-09
[2023-07-01 11:46:14] [config] output-omit-bias: false
[2023-07-01 11:46:14] [config] overwrite: true
[2023-07-01 11:46:14] [config] precision:
[2023-07-01 11:46:14] [config]   - float32
[2023-07-01 11:46:14] [config]   - float32
[2023-07-01 11:46:14] [config] pretrained-model: ""
[2023-07-01 11:46:14] [config] quantize-biases: false
[2023-07-01 11:46:14] [config] quantize-bits: 0
[2023-07-01 11:46:14] [config] quantize-log-based: false
[2023-07-01 11:46:14] [config] quantize-optimization-steps: 0
[2023-07-01 11:46:14] [config] quiet: false
[2023-07-01 11:46:14] [config] quiet-translation: true
[2023-07-01 11:46:14] [config] relative-paths: false
[2023-07-01 11:46:14] [config] right-left: false
[2023-07-01 11:46:14] [config] save-freq: 10000u
[2023-07-01 11:46:14] [config] seed: 1234
[2023-07-01 11:46:14] [config] sentencepiece-alphas:
[2023-07-01 11:46:14] [config]   []
[2023-07-01 11:46:14] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:46:14] [config] sentencepiece-options: ""
[2023-07-01 11:46:14] [config] sharding: global
[2023-07-01 11:46:14] [config] shuffle: data
[2023-07-01 11:46:14] [config] shuffle-in-ram: false
[2023-07-01 11:46:14] [config] sigterm: save-and-exit
[2023-07-01 11:46:14] [config] skip: false
[2023-07-01 11:46:14] [config] sqlite: ""
[2023-07-01 11:46:14] [config] sqlite-drop: false
[2023-07-01 11:46:14] [config] sync-freq: 200u
[2023-07-01 11:46:14] [config] sync-sgd: true
[2023-07-01 11:46:14] [config] tempdir: /tmp
[2023-07-01 11:46:14] [config] tied-embeddings: false
[2023-07-01 11:46:14] [config] tied-embeddings-all: true
[2023-07-01 11:46:14] [config] tied-embeddings-src: false
[2023-07-01 11:46:14] [config] train-embedder-rank:
[2023-07-01 11:46:14] [config]   []
[2023-07-01 11:46:14] [config] train-sets:
[2023-07-01 11:46:14] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:46:14] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:46:14] [config] transformer-aan-activation: swish
[2023-07-01 11:46:14] [config] transformer-aan-depth: 2
[2023-07-01 11:46:14] [config] transformer-aan-nogate: false
[2023-07-01 11:46:14] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:46:14] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:46:14] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:46:14] [config] transformer-depth-scaling: false
[2023-07-01 11:46:14] [config] transformer-dim-aan: 2048
[2023-07-01 11:46:14] [config] transformer-dim-ffn: 2048
[2023-07-01 11:46:14] [config] transformer-dropout: 0.1
[2023-07-01 11:46:14] [config] transformer-dropout-attention: 0
[2023-07-01 11:46:14] [config] transformer-dropout-ffn: 0
[2023-07-01 11:46:14] [config] transformer-ffn-activation: swish
[2023-07-01 11:46:14] [config] transformer-ffn-depth: 2
[2023-07-01 11:46:14] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:46:14] [config] transformer-heads: 8
[2023-07-01 11:46:14] [config] transformer-no-projection: false
[2023-07-01 11:46:14] [config] transformer-pool: false
[2023-07-01 11:46:14] [config] transformer-postprocess: dan
[2023-07-01 11:46:14] [config] transformer-postprocess-emb: d
[2023-07-01 11:46:14] [config] transformer-postprocess-top: ""
[2023-07-01 11:46:14] [config] transformer-preprocess: ""
[2023-07-01 11:46:14] [config] transformer-tied-layers:
[2023-07-01 11:46:14] [config]   []
[2023-07-01 11:46:14] [config] transformer-train-position-embeddings: false
[2023-07-01 11:46:14] [config] tsv: false
[2023-07-01 11:46:14] [config] tsv-fields: 0
[2023-07-01 11:46:14] [config] type: transformer
[2023-07-01 11:46:14] [config] ulr: false
[2023-07-01 11:46:14] [config] ulr-dim-emb: 0
[2023-07-01 11:46:14] [config] ulr-dropout: 0
[2023-07-01 11:46:14] [config] ulr-keys-vectors: ""
[2023-07-01 11:46:14] [config] ulr-query-vectors: ""
[2023-07-01 11:46:14] [config] ulr-softmax-temperature: 1
[2023-07-01 11:46:14] [config] ulr-trainable-transformation: false
[2023-07-01 11:46:14] [config] unlikelihood-loss: false
[2023-07-01 11:46:14] [config] valid-freq: 50000000
[2023-07-01 11:46:14] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:46:14] [config] valid-max-length: 1000
[2023-07-01 11:46:14] [config] valid-metrics:
[2023-07-01 11:46:14] [config]   - cross-entropy
[2023-07-01 11:46:14] [config]   - translation
[2023-07-01 11:46:14] [config] valid-mini-batch: 64
[2023-07-01 11:46:14] [config] valid-reset-stalled: false
[2023-07-01 11:46:14] [config] valid-script-args:
[2023-07-01 11:46:14] [config]   []
[2023-07-01 11:46:14] [config] valid-script-path: ""
[2023-07-01 11:46:14] [config] valid-sets:
[2023-07-01 11:46:14] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:46:14] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:46:14] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:46:14] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:46:14] [config] vocabs:
[2023-07-01 11:46:14] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:46:14] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:46:14] [config] word-penalty: 0
[2023-07-01 11:46:14] [config] word-scores: false
[2023-07-01 11:46:14] [config] workspace: 2048
[2023-07-01 11:46:14] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:46:14] Using synchronous SGD
[2023-07-01 11:46:14] Synced seed 1234
[2023-07-01 11:46:14] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:46:14] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:46:14] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:46:14] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:46:14] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:46:14] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:46:15] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:46:15] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:46:15] [comm] Using global sharding
[2023-07-01 11:46:15] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:46:15] [training] Using 1 GPUs
[2023-07-01 11:46:15] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:46:15] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:46:15] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:46:15] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:46:22] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:46:23] [valid] No post-processing script given for validating translator
[2023-07-01 11:46:23] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:46:23] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:46:23] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:46:23] [comm] Using global sharding
[2023-07-01 11:46:23] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:46:23] [training] Using 1 GPUs
[2023-07-01 11:46:23] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:46:23] Allocating memory for general optimizer shards
[2023-07-01 11:46:23] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:46:23] Loading Adam parameters
[2023-07-01 11:46:23] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:46:23] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:46:23] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:46:23] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:46:23] [data] Shuffling data
[2023-07-01 11:46:23] [data] Done reading 20,192 sentences
[2023-07-01 11:46:23] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:46:23] Training started
[2023-07-01 11:46:23] Training finished
[2023-07-01 11:46:27] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:46:27] [marian] Running on node20.datos.cluster.uy as process 21177 with command line:
[2023-07-01 11:46:27] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 166 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:46:27] [config] after: 0e
[2023-07-01 11:46:27] [config] after-batches: 0
[2023-07-01 11:46:27] [config] after-epochs: 166
[2023-07-01 11:46:27] [config] all-caps-every: 0
[2023-07-01 11:46:27] [config] allow-unk: false
[2023-07-01 11:46:27] [config] authors: false
[2023-07-01 11:46:27] [config] beam-size: 12
[2023-07-01 11:46:27] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:46:27] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:46:27] [config] bert-masking-fraction: 0.15
[2023-07-01 11:46:27] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:46:27] [config] bert-train-type-embeddings: true
[2023-07-01 11:46:27] [config] bert-type-vocab-size: 2
[2023-07-01 11:46:27] [config] build-info: ""
[2023-07-01 11:46:27] [config] check-gradient-nan: false
[2023-07-01 11:46:27] [config] check-nan: false
[2023-07-01 11:46:27] [config] cite: false
[2023-07-01 11:46:27] [config] clip-norm: 5
[2023-07-01 11:46:27] [config] cost-scaling:
[2023-07-01 11:46:27] [config]   []
[2023-07-01 11:46:27] [config] cost-type: ce-sum
[2023-07-01 11:46:27] [config] cpu-threads: 0
[2023-07-01 11:46:27] [config] data-threads: 8
[2023-07-01 11:46:27] [config] data-weighting: ""
[2023-07-01 11:46:27] [config] data-weighting-type: sentence
[2023-07-01 11:46:27] [config] dec-cell: gru
[2023-07-01 11:46:27] [config] dec-cell-base-depth: 2
[2023-07-01 11:46:27] [config] dec-cell-high-depth: 1
[2023-07-01 11:46:27] [config] dec-depth: 2
[2023-07-01 11:46:27] [config] devices:
[2023-07-01 11:46:27] [config]   - 0
[2023-07-01 11:46:27] [config] dim-emb: 512
[2023-07-01 11:46:27] [config] dim-rnn: 1024
[2023-07-01 11:46:27] [config] dim-vocabs:
[2023-07-01 11:46:27] [config]   - 16384
[2023-07-01 11:46:27] [config]   - 16384
[2023-07-01 11:46:27] [config] disp-first: 0
[2023-07-01 11:46:27] [config] disp-freq: 1000u
[2023-07-01 11:46:27] [config] disp-label-counts: true
[2023-07-01 11:46:27] [config] dropout-rnn: 0
[2023-07-01 11:46:27] [config] dropout-src: 0
[2023-07-01 11:46:27] [config] dropout-trg: 0
[2023-07-01 11:46:27] [config] dump-config: ""
[2023-07-01 11:46:27] [config] dynamic-gradient-scaling:
[2023-07-01 11:46:27] [config]   []
[2023-07-01 11:46:27] [config] early-stopping: 10
[2023-07-01 11:46:27] [config] early-stopping-on: first
[2023-07-01 11:46:27] [config] embedding-fix-src: false
[2023-07-01 11:46:27] [config] embedding-fix-trg: false
[2023-07-01 11:46:27] [config] embedding-normalization: false
[2023-07-01 11:46:27] [config] embedding-vectors:
[2023-07-01 11:46:27] [config]   []
[2023-07-01 11:46:27] [config] enc-cell: gru
[2023-07-01 11:46:27] [config] enc-cell-depth: 1
[2023-07-01 11:46:27] [config] enc-depth: 2
[2023-07-01 11:46:27] [config] enc-type: bidirectional
[2023-07-01 11:46:27] [config] english-title-case-every: 0
[2023-07-01 11:46:27] [config] exponential-smoothing: 0.0001
[2023-07-01 11:46:27] [config] factor-weight: 1
[2023-07-01 11:46:27] [config] factors-combine: sum
[2023-07-01 11:46:27] [config] factors-dim-emb: 0
[2023-07-01 11:46:27] [config] gradient-checkpointing: false
[2023-07-01 11:46:27] [config] gradient-norm-average-window: 100
[2023-07-01 11:46:27] [config] guided-alignment: none
[2023-07-01 11:46:27] [config] guided-alignment-cost: mse
[2023-07-01 11:46:27] [config] guided-alignment-weight: 0.1
[2023-07-01 11:46:27] [config] ignore-model-config: false
[2023-07-01 11:46:27] [config] input-types:
[2023-07-01 11:46:27] [config]   []
[2023-07-01 11:46:27] [config] interpolate-env-vars: false
[2023-07-01 11:46:27] [config] keep-best: false
[2023-07-01 11:46:27] [config] label-smoothing: 0.1
[2023-07-01 11:46:27] [config] layer-normalization: false
[2023-07-01 11:46:27] [config] learn-rate: 0.0003
[2023-07-01 11:46:27] [config] lemma-dependency: ""
[2023-07-01 11:46:27] [config] lemma-dim-emb: 0
[2023-07-01 11:46:27] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:46:27] [config] log-level: info
[2023-07-01 11:46:27] [config] log-time-zone: ""
[2023-07-01 11:46:27] [config] logical-epoch:
[2023-07-01 11:46:27] [config]   - 1e
[2023-07-01 11:46:27] [config]   - 0
[2023-07-01 11:46:27] [config] lr-decay: 0
[2023-07-01 11:46:27] [config] lr-decay-freq: 50000
[2023-07-01 11:46:27] [config] lr-decay-inv-sqrt:
[2023-07-01 11:46:27] [config]   - 16000
[2023-07-01 11:46:27] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:46:27] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:46:27] [config] lr-decay-start:
[2023-07-01 11:46:27] [config]   - 10
[2023-07-01 11:46:27] [config]   - 1
[2023-07-01 11:46:27] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:46:27] [config] lr-report: true
[2023-07-01 11:46:27] [config] lr-warmup: 16000
[2023-07-01 11:46:27] [config] lr-warmup-at-reload: false
[2023-07-01 11:46:27] [config] lr-warmup-cycle: false
[2023-07-01 11:46:27] [config] lr-warmup-start-rate: 0
[2023-07-01 11:46:27] [config] max-length: 100
[2023-07-01 11:46:27] [config] max-length-crop: false
[2023-07-01 11:46:27] [config] max-length-factor: 3
[2023-07-01 11:46:27] [config] maxi-batch: 100
[2023-07-01 11:46:27] [config] maxi-batch-sort: trg
[2023-07-01 11:46:27] [config] mini-batch: 1000
[2023-07-01 11:46:27] [config] mini-batch-fit: true
[2023-07-01 11:46:27] [config] mini-batch-fit-step: 10
[2023-07-01 11:46:27] [config] mini-batch-round-up: true
[2023-07-01 11:46:27] [config] mini-batch-track-lr: false
[2023-07-01 11:46:27] [config] mini-batch-warmup: 0
[2023-07-01 11:46:27] [config] mini-batch-words: 0
[2023-07-01 11:46:27] [config] mini-batch-words-ref: 0
[2023-07-01 11:46:27] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:46:27] [config] multi-loss-type: sum
[2023-07-01 11:46:27] [config] n-best: false
[2023-07-01 11:46:27] [config] no-nccl: false
[2023-07-01 11:46:27] [config] no-reload: false
[2023-07-01 11:46:27] [config] no-restore-corpus: false
[2023-07-01 11:46:27] [config] normalize: 1
[2023-07-01 11:46:27] [config] normalize-gradient: false
[2023-07-01 11:46:27] [config] num-devices: 0
[2023-07-01 11:46:27] [config] optimizer: adam
[2023-07-01 11:46:27] [config] optimizer-delay: 1
[2023-07-01 11:46:27] [config] optimizer-params:
[2023-07-01 11:46:27] [config]   - 0.9
[2023-07-01 11:46:27] [config]   - 0.98
[2023-07-01 11:46:27] [config]   - 1e-09
[2023-07-01 11:46:27] [config] output-omit-bias: false
[2023-07-01 11:46:27] [config] overwrite: true
[2023-07-01 11:46:27] [config] precision:
[2023-07-01 11:46:27] [config]   - float32
[2023-07-01 11:46:27] [config]   - float32
[2023-07-01 11:46:27] [config] pretrained-model: ""
[2023-07-01 11:46:27] [config] quantize-biases: false
[2023-07-01 11:46:27] [config] quantize-bits: 0
[2023-07-01 11:46:27] [config] quantize-log-based: false
[2023-07-01 11:46:27] [config] quantize-optimization-steps: 0
[2023-07-01 11:46:27] [config] quiet: false
[2023-07-01 11:46:27] [config] quiet-translation: true
[2023-07-01 11:46:27] [config] relative-paths: false
[2023-07-01 11:46:27] [config] right-left: false
[2023-07-01 11:46:27] [config] save-freq: 10000u
[2023-07-01 11:46:27] [config] seed: 1234
[2023-07-01 11:46:27] [config] sentencepiece-alphas:
[2023-07-01 11:46:27] [config]   []
[2023-07-01 11:46:27] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:46:27] [config] sentencepiece-options: ""
[2023-07-01 11:46:27] [config] sharding: global
[2023-07-01 11:46:27] [config] shuffle: data
[2023-07-01 11:46:27] [config] shuffle-in-ram: false
[2023-07-01 11:46:27] [config] sigterm: save-and-exit
[2023-07-01 11:46:27] [config] skip: false
[2023-07-01 11:46:27] [config] sqlite: ""
[2023-07-01 11:46:27] [config] sqlite-drop: false
[2023-07-01 11:46:27] [config] sync-freq: 200u
[2023-07-01 11:46:27] [config] sync-sgd: true
[2023-07-01 11:46:27] [config] tempdir: /tmp
[2023-07-01 11:46:27] [config] tied-embeddings: false
[2023-07-01 11:46:27] [config] tied-embeddings-all: true
[2023-07-01 11:46:27] [config] tied-embeddings-src: false
[2023-07-01 11:46:27] [config] train-embedder-rank:
[2023-07-01 11:46:27] [config]   []
[2023-07-01 11:46:27] [config] train-sets:
[2023-07-01 11:46:27] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:46:27] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:46:27] [config] transformer-aan-activation: swish
[2023-07-01 11:46:27] [config] transformer-aan-depth: 2
[2023-07-01 11:46:27] [config] transformer-aan-nogate: false
[2023-07-01 11:46:27] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:46:27] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:46:27] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:46:27] [config] transformer-depth-scaling: false
[2023-07-01 11:46:27] [config] transformer-dim-aan: 2048
[2023-07-01 11:46:27] [config] transformer-dim-ffn: 2048
[2023-07-01 11:46:27] [config] transformer-dropout: 0.1
[2023-07-01 11:46:27] [config] transformer-dropout-attention: 0
[2023-07-01 11:46:27] [config] transformer-dropout-ffn: 0
[2023-07-01 11:46:27] [config] transformer-ffn-activation: swish
[2023-07-01 11:46:27] [config] transformer-ffn-depth: 2
[2023-07-01 11:46:27] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:46:27] [config] transformer-heads: 8
[2023-07-01 11:46:27] [config] transformer-no-projection: false
[2023-07-01 11:46:27] [config] transformer-pool: false
[2023-07-01 11:46:27] [config] transformer-postprocess: dan
[2023-07-01 11:46:27] [config] transformer-postprocess-emb: d
[2023-07-01 11:46:27] [config] transformer-postprocess-top: ""
[2023-07-01 11:46:27] [config] transformer-preprocess: ""
[2023-07-01 11:46:27] [config] transformer-tied-layers:
[2023-07-01 11:46:27] [config]   []
[2023-07-01 11:46:27] [config] transformer-train-position-embeddings: false
[2023-07-01 11:46:27] [config] tsv: false
[2023-07-01 11:46:27] [config] tsv-fields: 0
[2023-07-01 11:46:27] [config] type: transformer
[2023-07-01 11:46:27] [config] ulr: false
[2023-07-01 11:46:27] [config] ulr-dim-emb: 0
[2023-07-01 11:46:27] [config] ulr-dropout: 0
[2023-07-01 11:46:27] [config] ulr-keys-vectors: ""
[2023-07-01 11:46:27] [config] ulr-query-vectors: ""
[2023-07-01 11:46:27] [config] ulr-softmax-temperature: 1
[2023-07-01 11:46:27] [config] ulr-trainable-transformation: false
[2023-07-01 11:46:27] [config] unlikelihood-loss: false
[2023-07-01 11:46:27] [config] valid-freq: 50000000
[2023-07-01 11:46:27] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:46:27] [config] valid-max-length: 1000
[2023-07-01 11:46:27] [config] valid-metrics:
[2023-07-01 11:46:27] [config]   - cross-entropy
[2023-07-01 11:46:27] [config]   - translation
[2023-07-01 11:46:27] [config] valid-mini-batch: 64
[2023-07-01 11:46:27] [config] valid-reset-stalled: false
[2023-07-01 11:46:27] [config] valid-script-args:
[2023-07-01 11:46:27] [config]   []
[2023-07-01 11:46:27] [config] valid-script-path: ""
[2023-07-01 11:46:27] [config] valid-sets:
[2023-07-01 11:46:27] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:46:27] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:46:27] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:46:27] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:46:27] [config] vocabs:
[2023-07-01 11:46:27] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:46:27] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:46:27] [config] word-penalty: 0
[2023-07-01 11:46:27] [config] word-scores: false
[2023-07-01 11:46:27] [config] workspace: 2048
[2023-07-01 11:46:27] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:46:27] Using synchronous SGD
[2023-07-01 11:46:27] Synced seed 1234
[2023-07-01 11:46:27] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:46:27] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:46:27] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:46:27] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:46:27] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:46:27] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:46:28] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:46:28] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:46:28] [comm] Using global sharding
[2023-07-01 11:46:28] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:46:28] [training] Using 1 GPUs
[2023-07-01 11:46:28] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:46:28] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:46:28] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:46:28] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:46:36] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:46:36] [valid] No post-processing script given for validating translator
[2023-07-01 11:46:36] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:46:36] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:46:36] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:46:36] [comm] Using global sharding
[2023-07-01 11:46:36] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:46:36] [training] Using 1 GPUs
[2023-07-01 11:46:36] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:46:36] Allocating memory for general optimizer shards
[2023-07-01 11:46:36] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:46:37] Loading Adam parameters
[2023-07-01 11:46:37] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:46:37] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:46:37] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:46:37] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:46:37] [data] Shuffling data
[2023-07-01 11:46:37] [data] Done reading 20,192 sentences
[2023-07-01 11:46:37] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:46:37] Training started
[2023-07-01 11:46:37] Training finished
[2023-07-01 11:46:40] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:46:40] [marian] Running on node20.datos.cluster.uy as process 21235 with command line:
[2023-07-01 11:46:40] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 167 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:46:40] [config] after: 0e
[2023-07-01 11:46:40] [config] after-batches: 0
[2023-07-01 11:46:40] [config] after-epochs: 167
[2023-07-01 11:46:40] [config] all-caps-every: 0
[2023-07-01 11:46:40] [config] allow-unk: false
[2023-07-01 11:46:40] [config] authors: false
[2023-07-01 11:46:40] [config] beam-size: 12
[2023-07-01 11:46:40] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:46:40] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:46:40] [config] bert-masking-fraction: 0.15
[2023-07-01 11:46:40] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:46:40] [config] bert-train-type-embeddings: true
[2023-07-01 11:46:40] [config] bert-type-vocab-size: 2
[2023-07-01 11:46:40] [config] build-info: ""
[2023-07-01 11:46:40] [config] check-gradient-nan: false
[2023-07-01 11:46:40] [config] check-nan: false
[2023-07-01 11:46:40] [config] cite: false
[2023-07-01 11:46:40] [config] clip-norm: 5
[2023-07-01 11:46:40] [config] cost-scaling:
[2023-07-01 11:46:40] [config]   []
[2023-07-01 11:46:40] [config] cost-type: ce-sum
[2023-07-01 11:46:40] [config] cpu-threads: 0
[2023-07-01 11:46:40] [config] data-threads: 8
[2023-07-01 11:46:40] [config] data-weighting: ""
[2023-07-01 11:46:40] [config] data-weighting-type: sentence
[2023-07-01 11:46:40] [config] dec-cell: gru
[2023-07-01 11:46:40] [config] dec-cell-base-depth: 2
[2023-07-01 11:46:40] [config] dec-cell-high-depth: 1
[2023-07-01 11:46:40] [config] dec-depth: 2
[2023-07-01 11:46:40] [config] devices:
[2023-07-01 11:46:40] [config]   - 0
[2023-07-01 11:46:40] [config] dim-emb: 512
[2023-07-01 11:46:40] [config] dim-rnn: 1024
[2023-07-01 11:46:40] [config] dim-vocabs:
[2023-07-01 11:46:40] [config]   - 16384
[2023-07-01 11:46:40] [config]   - 16384
[2023-07-01 11:46:40] [config] disp-first: 0
[2023-07-01 11:46:40] [config] disp-freq: 1000u
[2023-07-01 11:46:40] [config] disp-label-counts: true
[2023-07-01 11:46:40] [config] dropout-rnn: 0
[2023-07-01 11:46:40] [config] dropout-src: 0
[2023-07-01 11:46:40] [config] dropout-trg: 0
[2023-07-01 11:46:40] [config] dump-config: ""
[2023-07-01 11:46:40] [config] dynamic-gradient-scaling:
[2023-07-01 11:46:40] [config]   []
[2023-07-01 11:46:40] [config] early-stopping: 10
[2023-07-01 11:46:40] [config] early-stopping-on: first
[2023-07-01 11:46:40] [config] embedding-fix-src: false
[2023-07-01 11:46:40] [config] embedding-fix-trg: false
[2023-07-01 11:46:40] [config] embedding-normalization: false
[2023-07-01 11:46:40] [config] embedding-vectors:
[2023-07-01 11:46:40] [config]   []
[2023-07-01 11:46:40] [config] enc-cell: gru
[2023-07-01 11:46:40] [config] enc-cell-depth: 1
[2023-07-01 11:46:40] [config] enc-depth: 2
[2023-07-01 11:46:40] [config] enc-type: bidirectional
[2023-07-01 11:46:40] [config] english-title-case-every: 0
[2023-07-01 11:46:40] [config] exponential-smoothing: 0.0001
[2023-07-01 11:46:40] [config] factor-weight: 1
[2023-07-01 11:46:40] [config] factors-combine: sum
[2023-07-01 11:46:40] [config] factors-dim-emb: 0
[2023-07-01 11:46:40] [config] gradient-checkpointing: false
[2023-07-01 11:46:40] [config] gradient-norm-average-window: 100
[2023-07-01 11:46:40] [config] guided-alignment: none
[2023-07-01 11:46:40] [config] guided-alignment-cost: mse
[2023-07-01 11:46:40] [config] guided-alignment-weight: 0.1
[2023-07-01 11:46:40] [config] ignore-model-config: false
[2023-07-01 11:46:40] [config] input-types:
[2023-07-01 11:46:40] [config]   []
[2023-07-01 11:46:40] [config] interpolate-env-vars: false
[2023-07-01 11:46:40] [config] keep-best: false
[2023-07-01 11:46:40] [config] label-smoothing: 0.1
[2023-07-01 11:46:40] [config] layer-normalization: false
[2023-07-01 11:46:40] [config] learn-rate: 0.0003
[2023-07-01 11:46:40] [config] lemma-dependency: ""
[2023-07-01 11:46:40] [config] lemma-dim-emb: 0
[2023-07-01 11:46:40] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:46:40] [config] log-level: info
[2023-07-01 11:46:40] [config] log-time-zone: ""
[2023-07-01 11:46:40] [config] logical-epoch:
[2023-07-01 11:46:40] [config]   - 1e
[2023-07-01 11:46:40] [config]   - 0
[2023-07-01 11:46:40] [config] lr-decay: 0
[2023-07-01 11:46:40] [config] lr-decay-freq: 50000
[2023-07-01 11:46:40] [config] lr-decay-inv-sqrt:
[2023-07-01 11:46:40] [config]   - 16000
[2023-07-01 11:46:40] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:46:40] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:46:40] [config] lr-decay-start:
[2023-07-01 11:46:40] [config]   - 10
[2023-07-01 11:46:40] [config]   - 1
[2023-07-01 11:46:40] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:46:40] [config] lr-report: true
[2023-07-01 11:46:40] [config] lr-warmup: 16000
[2023-07-01 11:46:40] [config] lr-warmup-at-reload: false
[2023-07-01 11:46:40] [config] lr-warmup-cycle: false
[2023-07-01 11:46:40] [config] lr-warmup-start-rate: 0
[2023-07-01 11:46:40] [config] max-length: 100
[2023-07-01 11:46:40] [config] max-length-crop: false
[2023-07-01 11:46:40] [config] max-length-factor: 3
[2023-07-01 11:46:40] [config] maxi-batch: 100
[2023-07-01 11:46:40] [config] maxi-batch-sort: trg
[2023-07-01 11:46:40] [config] mini-batch: 1000
[2023-07-01 11:46:40] [config] mini-batch-fit: true
[2023-07-01 11:46:40] [config] mini-batch-fit-step: 10
[2023-07-01 11:46:40] [config] mini-batch-round-up: true
[2023-07-01 11:46:40] [config] mini-batch-track-lr: false
[2023-07-01 11:46:40] [config] mini-batch-warmup: 0
[2023-07-01 11:46:40] [config] mini-batch-words: 0
[2023-07-01 11:46:40] [config] mini-batch-words-ref: 0
[2023-07-01 11:46:40] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:46:40] [config] multi-loss-type: sum
[2023-07-01 11:46:40] [config] n-best: false
[2023-07-01 11:46:40] [config] no-nccl: false
[2023-07-01 11:46:40] [config] no-reload: false
[2023-07-01 11:46:40] [config] no-restore-corpus: false
[2023-07-01 11:46:40] [config] normalize: 1
[2023-07-01 11:46:40] [config] normalize-gradient: false
[2023-07-01 11:46:40] [config] num-devices: 0
[2023-07-01 11:46:40] [config] optimizer: adam
[2023-07-01 11:46:40] [config] optimizer-delay: 1
[2023-07-01 11:46:40] [config] optimizer-params:
[2023-07-01 11:46:40] [config]   - 0.9
[2023-07-01 11:46:40] [config]   - 0.98
[2023-07-01 11:46:40] [config]   - 1e-09
[2023-07-01 11:46:40] [config] output-omit-bias: false
[2023-07-01 11:46:40] [config] overwrite: true
[2023-07-01 11:46:40] [config] precision:
[2023-07-01 11:46:40] [config]   - float32
[2023-07-01 11:46:40] [config]   - float32
[2023-07-01 11:46:40] [config] pretrained-model: ""
[2023-07-01 11:46:40] [config] quantize-biases: false
[2023-07-01 11:46:40] [config] quantize-bits: 0
[2023-07-01 11:46:40] [config] quantize-log-based: false
[2023-07-01 11:46:40] [config] quantize-optimization-steps: 0
[2023-07-01 11:46:40] [config] quiet: false
[2023-07-01 11:46:40] [config] quiet-translation: true
[2023-07-01 11:46:40] [config] relative-paths: false
[2023-07-01 11:46:40] [config] right-left: false
[2023-07-01 11:46:40] [config] save-freq: 10000u
[2023-07-01 11:46:40] [config] seed: 1234
[2023-07-01 11:46:40] [config] sentencepiece-alphas:
[2023-07-01 11:46:40] [config]   []
[2023-07-01 11:46:40] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:46:40] [config] sentencepiece-options: ""
[2023-07-01 11:46:40] [config] sharding: global
[2023-07-01 11:46:40] [config] shuffle: data
[2023-07-01 11:46:40] [config] shuffle-in-ram: false
[2023-07-01 11:46:40] [config] sigterm: save-and-exit
[2023-07-01 11:46:40] [config] skip: false
[2023-07-01 11:46:40] [config] sqlite: ""
[2023-07-01 11:46:40] [config] sqlite-drop: false
[2023-07-01 11:46:40] [config] sync-freq: 200u
[2023-07-01 11:46:40] [config] sync-sgd: true
[2023-07-01 11:46:40] [config] tempdir: /tmp
[2023-07-01 11:46:40] [config] tied-embeddings: false
[2023-07-01 11:46:40] [config] tied-embeddings-all: true
[2023-07-01 11:46:40] [config] tied-embeddings-src: false
[2023-07-01 11:46:40] [config] train-embedder-rank:
[2023-07-01 11:46:40] [config]   []
[2023-07-01 11:46:40] [config] train-sets:
[2023-07-01 11:46:40] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:46:40] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:46:40] [config] transformer-aan-activation: swish
[2023-07-01 11:46:40] [config] transformer-aan-depth: 2
[2023-07-01 11:46:40] [config] transformer-aan-nogate: false
[2023-07-01 11:46:40] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:46:40] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:46:40] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:46:40] [config] transformer-depth-scaling: false
[2023-07-01 11:46:40] [config] transformer-dim-aan: 2048
[2023-07-01 11:46:40] [config] transformer-dim-ffn: 2048
[2023-07-01 11:46:40] [config] transformer-dropout: 0.1
[2023-07-01 11:46:40] [config] transformer-dropout-attention: 0
[2023-07-01 11:46:40] [config] transformer-dropout-ffn: 0
[2023-07-01 11:46:40] [config] transformer-ffn-activation: swish
[2023-07-01 11:46:40] [config] transformer-ffn-depth: 2
[2023-07-01 11:46:40] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:46:40] [config] transformer-heads: 8
[2023-07-01 11:46:40] [config] transformer-no-projection: false
[2023-07-01 11:46:40] [config] transformer-pool: false
[2023-07-01 11:46:40] [config] transformer-postprocess: dan
[2023-07-01 11:46:40] [config] transformer-postprocess-emb: d
[2023-07-01 11:46:40] [config] transformer-postprocess-top: ""
[2023-07-01 11:46:40] [config] transformer-preprocess: ""
[2023-07-01 11:46:40] [config] transformer-tied-layers:
[2023-07-01 11:46:40] [config]   []
[2023-07-01 11:46:40] [config] transformer-train-position-embeddings: false
[2023-07-01 11:46:40] [config] tsv: false
[2023-07-01 11:46:40] [config] tsv-fields: 0
[2023-07-01 11:46:40] [config] type: transformer
[2023-07-01 11:46:40] [config] ulr: false
[2023-07-01 11:46:40] [config] ulr-dim-emb: 0
[2023-07-01 11:46:40] [config] ulr-dropout: 0
[2023-07-01 11:46:40] [config] ulr-keys-vectors: ""
[2023-07-01 11:46:40] [config] ulr-query-vectors: ""
[2023-07-01 11:46:40] [config] ulr-softmax-temperature: 1
[2023-07-01 11:46:40] [config] ulr-trainable-transformation: false
[2023-07-01 11:46:40] [config] unlikelihood-loss: false
[2023-07-01 11:46:40] [config] valid-freq: 50000000
[2023-07-01 11:46:40] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:46:40] [config] valid-max-length: 1000
[2023-07-01 11:46:40] [config] valid-metrics:
[2023-07-01 11:46:40] [config]   - cross-entropy
[2023-07-01 11:46:40] [config]   - translation
[2023-07-01 11:46:40] [config] valid-mini-batch: 64
[2023-07-01 11:46:40] [config] valid-reset-stalled: false
[2023-07-01 11:46:40] [config] valid-script-args:
[2023-07-01 11:46:40] [config]   []
[2023-07-01 11:46:40] [config] valid-script-path: ""
[2023-07-01 11:46:40] [config] valid-sets:
[2023-07-01 11:46:40] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:46:40] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:46:40] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:46:40] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:46:40] [config] vocabs:
[2023-07-01 11:46:40] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:46:40] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:46:40] [config] word-penalty: 0
[2023-07-01 11:46:40] [config] word-scores: false
[2023-07-01 11:46:40] [config] workspace: 2048
[2023-07-01 11:46:40] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:46:40] Using synchronous SGD
[2023-07-01 11:46:40] Synced seed 1234
[2023-07-01 11:46:40] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:46:40] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:46:40] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:46:41] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:46:41] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:46:41] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:46:41] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:46:41] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:46:41] [comm] Using global sharding
[2023-07-01 11:46:41] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:46:41] [training] Using 1 GPUs
[2023-07-01 11:46:41] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:46:41] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:46:42] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:46:42] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:46:49] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:46:49] [valid] No post-processing script given for validating translator
[2023-07-01 11:46:49] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:46:49] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:46:49] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:46:49] [comm] Using global sharding
[2023-07-01 11:46:49] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:46:49] [training] Using 1 GPUs
[2023-07-01 11:46:49] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:46:50] Allocating memory for general optimizer shards
[2023-07-01 11:46:50] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:46:50] Loading Adam parameters
[2023-07-01 11:46:50] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:46:50] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:46:50] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:46:50] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:46:50] [data] Shuffling data
[2023-07-01 11:46:50] [data] Done reading 20,192 sentences
[2023-07-01 11:46:50] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:46:50] Training started
[2023-07-01 11:46:50] Training finished
[2023-07-01 11:46:54] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:46:54] [marian] Running on node20.datos.cluster.uy as process 21293 with command line:
[2023-07-01 11:46:54] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 168 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:46:54] [config] after: 0e
[2023-07-01 11:46:54] [config] after-batches: 0
[2023-07-01 11:46:54] [config] after-epochs: 168
[2023-07-01 11:46:54] [config] all-caps-every: 0
[2023-07-01 11:46:54] [config] allow-unk: false
[2023-07-01 11:46:54] [config] authors: false
[2023-07-01 11:46:54] [config] beam-size: 12
[2023-07-01 11:46:54] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:46:54] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:46:54] [config] bert-masking-fraction: 0.15
[2023-07-01 11:46:54] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:46:54] [config] bert-train-type-embeddings: true
[2023-07-01 11:46:54] [config] bert-type-vocab-size: 2
[2023-07-01 11:46:54] [config] build-info: ""
[2023-07-01 11:46:54] [config] check-gradient-nan: false
[2023-07-01 11:46:54] [config] check-nan: false
[2023-07-01 11:46:54] [config] cite: false
[2023-07-01 11:46:54] [config] clip-norm: 5
[2023-07-01 11:46:54] [config] cost-scaling:
[2023-07-01 11:46:54] [config]   []
[2023-07-01 11:46:54] [config] cost-type: ce-sum
[2023-07-01 11:46:54] [config] cpu-threads: 0
[2023-07-01 11:46:54] [config] data-threads: 8
[2023-07-01 11:46:54] [config] data-weighting: ""
[2023-07-01 11:46:54] [config] data-weighting-type: sentence
[2023-07-01 11:46:54] [config] dec-cell: gru
[2023-07-01 11:46:54] [config] dec-cell-base-depth: 2
[2023-07-01 11:46:54] [config] dec-cell-high-depth: 1
[2023-07-01 11:46:54] [config] dec-depth: 2
[2023-07-01 11:46:54] [config] devices:
[2023-07-01 11:46:54] [config]   - 0
[2023-07-01 11:46:54] [config] dim-emb: 512
[2023-07-01 11:46:54] [config] dim-rnn: 1024
[2023-07-01 11:46:54] [config] dim-vocabs:
[2023-07-01 11:46:54] [config]   - 16384
[2023-07-01 11:46:54] [config]   - 16384
[2023-07-01 11:46:54] [config] disp-first: 0
[2023-07-01 11:46:54] [config] disp-freq: 1000u
[2023-07-01 11:46:54] [config] disp-label-counts: true
[2023-07-01 11:46:54] [config] dropout-rnn: 0
[2023-07-01 11:46:54] [config] dropout-src: 0
[2023-07-01 11:46:54] [config] dropout-trg: 0
[2023-07-01 11:46:54] [config] dump-config: ""
[2023-07-01 11:46:54] [config] dynamic-gradient-scaling:
[2023-07-01 11:46:54] [config]   []
[2023-07-01 11:46:54] [config] early-stopping: 10
[2023-07-01 11:46:54] [config] early-stopping-on: first
[2023-07-01 11:46:54] [config] embedding-fix-src: false
[2023-07-01 11:46:54] [config] embedding-fix-trg: false
[2023-07-01 11:46:54] [config] embedding-normalization: false
[2023-07-01 11:46:54] [config] embedding-vectors:
[2023-07-01 11:46:54] [config]   []
[2023-07-01 11:46:54] [config] enc-cell: gru
[2023-07-01 11:46:54] [config] enc-cell-depth: 1
[2023-07-01 11:46:54] [config] enc-depth: 2
[2023-07-01 11:46:54] [config] enc-type: bidirectional
[2023-07-01 11:46:54] [config] english-title-case-every: 0
[2023-07-01 11:46:54] [config] exponential-smoothing: 0.0001
[2023-07-01 11:46:54] [config] factor-weight: 1
[2023-07-01 11:46:54] [config] factors-combine: sum
[2023-07-01 11:46:54] [config] factors-dim-emb: 0
[2023-07-01 11:46:54] [config] gradient-checkpointing: false
[2023-07-01 11:46:54] [config] gradient-norm-average-window: 100
[2023-07-01 11:46:54] [config] guided-alignment: none
[2023-07-01 11:46:54] [config] guided-alignment-cost: mse
[2023-07-01 11:46:54] [config] guided-alignment-weight: 0.1
[2023-07-01 11:46:54] [config] ignore-model-config: false
[2023-07-01 11:46:54] [config] input-types:
[2023-07-01 11:46:54] [config]   []
[2023-07-01 11:46:54] [config] interpolate-env-vars: false
[2023-07-01 11:46:54] [config] keep-best: false
[2023-07-01 11:46:54] [config] label-smoothing: 0.1
[2023-07-01 11:46:54] [config] layer-normalization: false
[2023-07-01 11:46:54] [config] learn-rate: 0.0003
[2023-07-01 11:46:54] [config] lemma-dependency: ""
[2023-07-01 11:46:54] [config] lemma-dim-emb: 0
[2023-07-01 11:46:54] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:46:54] [config] log-level: info
[2023-07-01 11:46:54] [config] log-time-zone: ""
[2023-07-01 11:46:54] [config] logical-epoch:
[2023-07-01 11:46:54] [config]   - 1e
[2023-07-01 11:46:54] [config]   - 0
[2023-07-01 11:46:54] [config] lr-decay: 0
[2023-07-01 11:46:54] [config] lr-decay-freq: 50000
[2023-07-01 11:46:54] [config] lr-decay-inv-sqrt:
[2023-07-01 11:46:54] [config]   - 16000
[2023-07-01 11:46:54] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:46:54] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:46:54] [config] lr-decay-start:
[2023-07-01 11:46:54] [config]   - 10
[2023-07-01 11:46:54] [config]   - 1
[2023-07-01 11:46:54] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:46:54] [config] lr-report: true
[2023-07-01 11:46:54] [config] lr-warmup: 16000
[2023-07-01 11:46:54] [config] lr-warmup-at-reload: false
[2023-07-01 11:46:54] [config] lr-warmup-cycle: false
[2023-07-01 11:46:54] [config] lr-warmup-start-rate: 0
[2023-07-01 11:46:54] [config] max-length: 100
[2023-07-01 11:46:54] [config] max-length-crop: false
[2023-07-01 11:46:54] [config] max-length-factor: 3
[2023-07-01 11:46:54] [config] maxi-batch: 100
[2023-07-01 11:46:54] [config] maxi-batch-sort: trg
[2023-07-01 11:46:54] [config] mini-batch: 1000
[2023-07-01 11:46:54] [config] mini-batch-fit: true
[2023-07-01 11:46:54] [config] mini-batch-fit-step: 10
[2023-07-01 11:46:54] [config] mini-batch-round-up: true
[2023-07-01 11:46:54] [config] mini-batch-track-lr: false
[2023-07-01 11:46:54] [config] mini-batch-warmup: 0
[2023-07-01 11:46:54] [config] mini-batch-words: 0
[2023-07-01 11:46:54] [config] mini-batch-words-ref: 0
[2023-07-01 11:46:54] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:46:54] [config] multi-loss-type: sum
[2023-07-01 11:46:54] [config] n-best: false
[2023-07-01 11:46:54] [config] no-nccl: false
[2023-07-01 11:46:54] [config] no-reload: false
[2023-07-01 11:46:54] [config] no-restore-corpus: false
[2023-07-01 11:46:54] [config] normalize: 1
[2023-07-01 11:46:54] [config] normalize-gradient: false
[2023-07-01 11:46:54] [config] num-devices: 0
[2023-07-01 11:46:54] [config] optimizer: adam
[2023-07-01 11:46:54] [config] optimizer-delay: 1
[2023-07-01 11:46:54] [config] optimizer-params:
[2023-07-01 11:46:54] [config]   - 0.9
[2023-07-01 11:46:54] [config]   - 0.98
[2023-07-01 11:46:54] [config]   - 1e-09
[2023-07-01 11:46:54] [config] output-omit-bias: false
[2023-07-01 11:46:54] [config] overwrite: true
[2023-07-01 11:46:54] [config] precision:
[2023-07-01 11:46:54] [config]   - float32
[2023-07-01 11:46:54] [config]   - float32
[2023-07-01 11:46:54] [config] pretrained-model: ""
[2023-07-01 11:46:54] [config] quantize-biases: false
[2023-07-01 11:46:54] [config] quantize-bits: 0
[2023-07-01 11:46:54] [config] quantize-log-based: false
[2023-07-01 11:46:54] [config] quantize-optimization-steps: 0
[2023-07-01 11:46:54] [config] quiet: false
[2023-07-01 11:46:54] [config] quiet-translation: true
[2023-07-01 11:46:54] [config] relative-paths: false
[2023-07-01 11:46:54] [config] right-left: false
[2023-07-01 11:46:54] [config] save-freq: 10000u
[2023-07-01 11:46:54] [config] seed: 1234
[2023-07-01 11:46:54] [config] sentencepiece-alphas:
[2023-07-01 11:46:54] [config]   []
[2023-07-01 11:46:54] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:46:54] [config] sentencepiece-options: ""
[2023-07-01 11:46:54] [config] sharding: global
[2023-07-01 11:46:54] [config] shuffle: data
[2023-07-01 11:46:54] [config] shuffle-in-ram: false
[2023-07-01 11:46:54] [config] sigterm: save-and-exit
[2023-07-01 11:46:54] [config] skip: false
[2023-07-01 11:46:54] [config] sqlite: ""
[2023-07-01 11:46:54] [config] sqlite-drop: false
[2023-07-01 11:46:54] [config] sync-freq: 200u
[2023-07-01 11:46:54] [config] sync-sgd: true
[2023-07-01 11:46:54] [config] tempdir: /tmp
[2023-07-01 11:46:54] [config] tied-embeddings: false
[2023-07-01 11:46:54] [config] tied-embeddings-all: true
[2023-07-01 11:46:54] [config] tied-embeddings-src: false
[2023-07-01 11:46:54] [config] train-embedder-rank:
[2023-07-01 11:46:54] [config]   []
[2023-07-01 11:46:54] [config] train-sets:
[2023-07-01 11:46:54] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:46:54] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:46:54] [config] transformer-aan-activation: swish
[2023-07-01 11:46:54] [config] transformer-aan-depth: 2
[2023-07-01 11:46:54] [config] transformer-aan-nogate: false
[2023-07-01 11:46:54] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:46:54] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:46:54] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:46:54] [config] transformer-depth-scaling: false
[2023-07-01 11:46:54] [config] transformer-dim-aan: 2048
[2023-07-01 11:46:54] [config] transformer-dim-ffn: 2048
[2023-07-01 11:46:54] [config] transformer-dropout: 0.1
[2023-07-01 11:46:54] [config] transformer-dropout-attention: 0
[2023-07-01 11:46:54] [config] transformer-dropout-ffn: 0
[2023-07-01 11:46:54] [config] transformer-ffn-activation: swish
[2023-07-01 11:46:54] [config] transformer-ffn-depth: 2
[2023-07-01 11:46:54] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:46:54] [config] transformer-heads: 8
[2023-07-01 11:46:54] [config] transformer-no-projection: false
[2023-07-01 11:46:54] [config] transformer-pool: false
[2023-07-01 11:46:54] [config] transformer-postprocess: dan
[2023-07-01 11:46:54] [config] transformer-postprocess-emb: d
[2023-07-01 11:46:54] [config] transformer-postprocess-top: ""
[2023-07-01 11:46:54] [config] transformer-preprocess: ""
[2023-07-01 11:46:54] [config] transformer-tied-layers:
[2023-07-01 11:46:54] [config]   []
[2023-07-01 11:46:54] [config] transformer-train-position-embeddings: false
[2023-07-01 11:46:54] [config] tsv: false
[2023-07-01 11:46:54] [config] tsv-fields: 0
[2023-07-01 11:46:54] [config] type: transformer
[2023-07-01 11:46:54] [config] ulr: false
[2023-07-01 11:46:54] [config] ulr-dim-emb: 0
[2023-07-01 11:46:54] [config] ulr-dropout: 0
[2023-07-01 11:46:54] [config] ulr-keys-vectors: ""
[2023-07-01 11:46:54] [config] ulr-query-vectors: ""
[2023-07-01 11:46:54] [config] ulr-softmax-temperature: 1
[2023-07-01 11:46:54] [config] ulr-trainable-transformation: false
[2023-07-01 11:46:54] [config] unlikelihood-loss: false
[2023-07-01 11:46:54] [config] valid-freq: 50000000
[2023-07-01 11:46:54] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:46:54] [config] valid-max-length: 1000
[2023-07-01 11:46:54] [config] valid-metrics:
[2023-07-01 11:46:54] [config]   - cross-entropy
[2023-07-01 11:46:54] [config]   - translation
[2023-07-01 11:46:54] [config] valid-mini-batch: 64
[2023-07-01 11:46:54] [config] valid-reset-stalled: false
[2023-07-01 11:46:54] [config] valid-script-args:
[2023-07-01 11:46:54] [config]   []
[2023-07-01 11:46:54] [config] valid-script-path: ""
[2023-07-01 11:46:54] [config] valid-sets:
[2023-07-01 11:46:54] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:46:54] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:46:54] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:46:54] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:46:54] [config] vocabs:
[2023-07-01 11:46:54] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:46:54] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:46:54] [config] word-penalty: 0
[2023-07-01 11:46:54] [config] word-scores: false
[2023-07-01 11:46:54] [config] workspace: 2048
[2023-07-01 11:46:54] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:46:54] Using synchronous SGD
[2023-07-01 11:46:54] Synced seed 1234
[2023-07-01 11:46:54] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:46:54] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:46:54] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:46:54] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:46:54] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:46:54] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:46:55] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:46:55] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:46:55] [comm] Using global sharding
[2023-07-01 11:46:55] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:46:55] [training] Using 1 GPUs
[2023-07-01 11:46:55] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:46:55] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:46:55] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:46:56] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:47:03] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:47:03] [valid] No post-processing script given for validating translator
[2023-07-01 11:47:03] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:47:03] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:47:03] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:47:03] [comm] Using global sharding
[2023-07-01 11:47:03] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:47:03] [training] Using 1 GPUs
[2023-07-01 11:47:03] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:47:04] Allocating memory for general optimizer shards
[2023-07-01 11:47:04] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:47:04] Loading Adam parameters
[2023-07-01 11:47:04] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:47:04] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:47:04] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:47:04] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:47:04] [data] Shuffling data
[2023-07-01 11:47:04] [data] Done reading 20,192 sentences
[2023-07-01 11:47:04] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:47:04] Training started
[2023-07-01 11:47:04] Training finished
[2023-07-01 11:47:07] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:47:07] [marian] Running on node20.datos.cluster.uy as process 21353 with command line:
[2023-07-01 11:47:07] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 169 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:47:07] [config] after: 0e
[2023-07-01 11:47:07] [config] after-batches: 0
[2023-07-01 11:47:07] [config] after-epochs: 169
[2023-07-01 11:47:07] [config] all-caps-every: 0
[2023-07-01 11:47:07] [config] allow-unk: false
[2023-07-01 11:47:07] [config] authors: false
[2023-07-01 11:47:07] [config] beam-size: 12
[2023-07-01 11:47:07] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:47:07] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:47:07] [config] bert-masking-fraction: 0.15
[2023-07-01 11:47:07] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:47:07] [config] bert-train-type-embeddings: true
[2023-07-01 11:47:07] [config] bert-type-vocab-size: 2
[2023-07-01 11:47:07] [config] build-info: ""
[2023-07-01 11:47:07] [config] check-gradient-nan: false
[2023-07-01 11:47:07] [config] check-nan: false
[2023-07-01 11:47:07] [config] cite: false
[2023-07-01 11:47:07] [config] clip-norm: 5
[2023-07-01 11:47:07] [config] cost-scaling:
[2023-07-01 11:47:07] [config]   []
[2023-07-01 11:47:07] [config] cost-type: ce-sum
[2023-07-01 11:47:07] [config] cpu-threads: 0
[2023-07-01 11:47:07] [config] data-threads: 8
[2023-07-01 11:47:07] [config] data-weighting: ""
[2023-07-01 11:47:07] [config] data-weighting-type: sentence
[2023-07-01 11:47:07] [config] dec-cell: gru
[2023-07-01 11:47:07] [config] dec-cell-base-depth: 2
[2023-07-01 11:47:07] [config] dec-cell-high-depth: 1
[2023-07-01 11:47:07] [config] dec-depth: 2
[2023-07-01 11:47:07] [config] devices:
[2023-07-01 11:47:07] [config]   - 0
[2023-07-01 11:47:07] [config] dim-emb: 512
[2023-07-01 11:47:07] [config] dim-rnn: 1024
[2023-07-01 11:47:07] [config] dim-vocabs:
[2023-07-01 11:47:07] [config]   - 16384
[2023-07-01 11:47:07] [config]   - 16384
[2023-07-01 11:47:07] [config] disp-first: 0
[2023-07-01 11:47:07] [config] disp-freq: 1000u
[2023-07-01 11:47:07] [config] disp-label-counts: true
[2023-07-01 11:47:07] [config] dropout-rnn: 0
[2023-07-01 11:47:07] [config] dropout-src: 0
[2023-07-01 11:47:07] [config] dropout-trg: 0
[2023-07-01 11:47:07] [config] dump-config: ""
[2023-07-01 11:47:07] [config] dynamic-gradient-scaling:
[2023-07-01 11:47:07] [config]   []
[2023-07-01 11:47:07] [config] early-stopping: 10
[2023-07-01 11:47:07] [config] early-stopping-on: first
[2023-07-01 11:47:07] [config] embedding-fix-src: false
[2023-07-01 11:47:07] [config] embedding-fix-trg: false
[2023-07-01 11:47:07] [config] embedding-normalization: false
[2023-07-01 11:47:07] [config] embedding-vectors:
[2023-07-01 11:47:07] [config]   []
[2023-07-01 11:47:07] [config] enc-cell: gru
[2023-07-01 11:47:07] [config] enc-cell-depth: 1
[2023-07-01 11:47:07] [config] enc-depth: 2
[2023-07-01 11:47:07] [config] enc-type: bidirectional
[2023-07-01 11:47:07] [config] english-title-case-every: 0
[2023-07-01 11:47:07] [config] exponential-smoothing: 0.0001
[2023-07-01 11:47:07] [config] factor-weight: 1
[2023-07-01 11:47:07] [config] factors-combine: sum
[2023-07-01 11:47:07] [config] factors-dim-emb: 0
[2023-07-01 11:47:07] [config] gradient-checkpointing: false
[2023-07-01 11:47:07] [config] gradient-norm-average-window: 100
[2023-07-01 11:47:07] [config] guided-alignment: none
[2023-07-01 11:47:07] [config] guided-alignment-cost: mse
[2023-07-01 11:47:07] [config] guided-alignment-weight: 0.1
[2023-07-01 11:47:07] [config] ignore-model-config: false
[2023-07-01 11:47:07] [config] input-types:
[2023-07-01 11:47:07] [config]   []
[2023-07-01 11:47:07] [config] interpolate-env-vars: false
[2023-07-01 11:47:07] [config] keep-best: false
[2023-07-01 11:47:07] [config] label-smoothing: 0.1
[2023-07-01 11:47:07] [config] layer-normalization: false
[2023-07-01 11:47:07] [config] learn-rate: 0.0003
[2023-07-01 11:47:07] [config] lemma-dependency: ""
[2023-07-01 11:47:07] [config] lemma-dim-emb: 0
[2023-07-01 11:47:07] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:47:07] [config] log-level: info
[2023-07-01 11:47:07] [config] log-time-zone: ""
[2023-07-01 11:47:07] [config] logical-epoch:
[2023-07-01 11:47:07] [config]   - 1e
[2023-07-01 11:47:07] [config]   - 0
[2023-07-01 11:47:07] [config] lr-decay: 0
[2023-07-01 11:47:07] [config] lr-decay-freq: 50000
[2023-07-01 11:47:07] [config] lr-decay-inv-sqrt:
[2023-07-01 11:47:07] [config]   - 16000
[2023-07-01 11:47:07] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:47:07] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:47:07] [config] lr-decay-start:
[2023-07-01 11:47:07] [config]   - 10
[2023-07-01 11:47:07] [config]   - 1
[2023-07-01 11:47:07] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:47:07] [config] lr-report: true
[2023-07-01 11:47:07] [config] lr-warmup: 16000
[2023-07-01 11:47:07] [config] lr-warmup-at-reload: false
[2023-07-01 11:47:07] [config] lr-warmup-cycle: false
[2023-07-01 11:47:07] [config] lr-warmup-start-rate: 0
[2023-07-01 11:47:07] [config] max-length: 100
[2023-07-01 11:47:07] [config] max-length-crop: false
[2023-07-01 11:47:07] [config] max-length-factor: 3
[2023-07-01 11:47:07] [config] maxi-batch: 100
[2023-07-01 11:47:07] [config] maxi-batch-sort: trg
[2023-07-01 11:47:07] [config] mini-batch: 1000
[2023-07-01 11:47:07] [config] mini-batch-fit: true
[2023-07-01 11:47:07] [config] mini-batch-fit-step: 10
[2023-07-01 11:47:07] [config] mini-batch-round-up: true
[2023-07-01 11:47:07] [config] mini-batch-track-lr: false
[2023-07-01 11:47:07] [config] mini-batch-warmup: 0
[2023-07-01 11:47:07] [config] mini-batch-words: 0
[2023-07-01 11:47:07] [config] mini-batch-words-ref: 0
[2023-07-01 11:47:07] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:47:07] [config] multi-loss-type: sum
[2023-07-01 11:47:07] [config] n-best: false
[2023-07-01 11:47:07] [config] no-nccl: false
[2023-07-01 11:47:07] [config] no-reload: false
[2023-07-01 11:47:07] [config] no-restore-corpus: false
[2023-07-01 11:47:07] [config] normalize: 1
[2023-07-01 11:47:07] [config] normalize-gradient: false
[2023-07-01 11:47:07] [config] num-devices: 0
[2023-07-01 11:47:07] [config] optimizer: adam
[2023-07-01 11:47:07] [config] optimizer-delay: 1
[2023-07-01 11:47:07] [config] optimizer-params:
[2023-07-01 11:47:07] [config]   - 0.9
[2023-07-01 11:47:07] [config]   - 0.98
[2023-07-01 11:47:07] [config]   - 1e-09
[2023-07-01 11:47:07] [config] output-omit-bias: false
[2023-07-01 11:47:07] [config] overwrite: true
[2023-07-01 11:47:07] [config] precision:
[2023-07-01 11:47:07] [config]   - float32
[2023-07-01 11:47:07] [config]   - float32
[2023-07-01 11:47:07] [config] pretrained-model: ""
[2023-07-01 11:47:07] [config] quantize-biases: false
[2023-07-01 11:47:07] [config] quantize-bits: 0
[2023-07-01 11:47:07] [config] quantize-log-based: false
[2023-07-01 11:47:07] [config] quantize-optimization-steps: 0
[2023-07-01 11:47:07] [config] quiet: false
[2023-07-01 11:47:07] [config] quiet-translation: true
[2023-07-01 11:47:07] [config] relative-paths: false
[2023-07-01 11:47:07] [config] right-left: false
[2023-07-01 11:47:07] [config] save-freq: 10000u
[2023-07-01 11:47:07] [config] seed: 1234
[2023-07-01 11:47:07] [config] sentencepiece-alphas:
[2023-07-01 11:47:07] [config]   []
[2023-07-01 11:47:07] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:47:07] [config] sentencepiece-options: ""
[2023-07-01 11:47:07] [config] sharding: global
[2023-07-01 11:47:07] [config] shuffle: data
[2023-07-01 11:47:07] [config] shuffle-in-ram: false
[2023-07-01 11:47:07] [config] sigterm: save-and-exit
[2023-07-01 11:47:07] [config] skip: false
[2023-07-01 11:47:07] [config] sqlite: ""
[2023-07-01 11:47:07] [config] sqlite-drop: false
[2023-07-01 11:47:07] [config] sync-freq: 200u
[2023-07-01 11:47:07] [config] sync-sgd: true
[2023-07-01 11:47:07] [config] tempdir: /tmp
[2023-07-01 11:47:07] [config] tied-embeddings: false
[2023-07-01 11:47:07] [config] tied-embeddings-all: true
[2023-07-01 11:47:07] [config] tied-embeddings-src: false
[2023-07-01 11:47:07] [config] train-embedder-rank:
[2023-07-01 11:47:07] [config]   []
[2023-07-01 11:47:07] [config] train-sets:
[2023-07-01 11:47:07] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:47:07] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:47:07] [config] transformer-aan-activation: swish
[2023-07-01 11:47:07] [config] transformer-aan-depth: 2
[2023-07-01 11:47:07] [config] transformer-aan-nogate: false
[2023-07-01 11:47:07] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:47:07] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:47:07] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:47:07] [config] transformer-depth-scaling: false
[2023-07-01 11:47:07] [config] transformer-dim-aan: 2048
[2023-07-01 11:47:07] [config] transformer-dim-ffn: 2048
[2023-07-01 11:47:07] [config] transformer-dropout: 0.1
[2023-07-01 11:47:07] [config] transformer-dropout-attention: 0
[2023-07-01 11:47:07] [config] transformer-dropout-ffn: 0
[2023-07-01 11:47:07] [config] transformer-ffn-activation: swish
[2023-07-01 11:47:07] [config] transformer-ffn-depth: 2
[2023-07-01 11:47:07] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:47:07] [config] transformer-heads: 8
[2023-07-01 11:47:07] [config] transformer-no-projection: false
[2023-07-01 11:47:07] [config] transformer-pool: false
[2023-07-01 11:47:07] [config] transformer-postprocess: dan
[2023-07-01 11:47:07] [config] transformer-postprocess-emb: d
[2023-07-01 11:47:07] [config] transformer-postprocess-top: ""
[2023-07-01 11:47:07] [config] transformer-preprocess: ""
[2023-07-01 11:47:07] [config] transformer-tied-layers:
[2023-07-01 11:47:07] [config]   []
[2023-07-01 11:47:07] [config] transformer-train-position-embeddings: false
[2023-07-01 11:47:07] [config] tsv: false
[2023-07-01 11:47:07] [config] tsv-fields: 0
[2023-07-01 11:47:07] [config] type: transformer
[2023-07-01 11:47:07] [config] ulr: false
[2023-07-01 11:47:07] [config] ulr-dim-emb: 0
[2023-07-01 11:47:07] [config] ulr-dropout: 0
[2023-07-01 11:47:07] [config] ulr-keys-vectors: ""
[2023-07-01 11:47:07] [config] ulr-query-vectors: ""
[2023-07-01 11:47:07] [config] ulr-softmax-temperature: 1
[2023-07-01 11:47:07] [config] ulr-trainable-transformation: false
[2023-07-01 11:47:07] [config] unlikelihood-loss: false
[2023-07-01 11:47:07] [config] valid-freq: 50000000
[2023-07-01 11:47:07] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:47:07] [config] valid-max-length: 1000
[2023-07-01 11:47:07] [config] valid-metrics:
[2023-07-01 11:47:07] [config]   - cross-entropy
[2023-07-01 11:47:07] [config]   - translation
[2023-07-01 11:47:07] [config] valid-mini-batch: 64
[2023-07-01 11:47:07] [config] valid-reset-stalled: false
[2023-07-01 11:47:07] [config] valid-script-args:
[2023-07-01 11:47:07] [config]   []
[2023-07-01 11:47:07] [config] valid-script-path: ""
[2023-07-01 11:47:07] [config] valid-sets:
[2023-07-01 11:47:07] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:47:07] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:47:07] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:47:07] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:47:07] [config] vocabs:
[2023-07-01 11:47:07] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:47:07] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:47:07] [config] word-penalty: 0
[2023-07-01 11:47:07] [config] word-scores: false
[2023-07-01 11:47:07] [config] workspace: 2048
[2023-07-01 11:47:07] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:47:07] Using synchronous SGD
[2023-07-01 11:47:08] Synced seed 1234
[2023-07-01 11:47:08] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:47:08] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:47:08] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:47:08] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:47:08] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:47:08] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:47:08] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:47:09] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:47:09] [comm] Using global sharding
[2023-07-01 11:47:09] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:47:09] [training] Using 1 GPUs
[2023-07-01 11:47:09] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:47:09] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:47:09] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:47:09] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:47:16] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:47:16] [valid] No post-processing script given for validating translator
[2023-07-01 11:47:16] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:47:16] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:47:16] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:47:16] [comm] Using global sharding
[2023-07-01 11:47:16] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:47:16] [training] Using 1 GPUs
[2023-07-01 11:47:16] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:47:17] Allocating memory for general optimizer shards
[2023-07-01 11:47:17] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:47:17] Loading Adam parameters
[2023-07-01 11:47:17] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:47:17] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:47:17] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:47:17] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:47:17] [data] Shuffling data
[2023-07-01 11:47:17] [data] Done reading 20,192 sentences
[2023-07-01 11:47:17] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:47:17] Training started
[2023-07-01 11:47:17] Training finished
[2023-07-01 11:47:20] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:47:20] [marian] Running on node20.datos.cluster.uy as process 21413 with command line:
[2023-07-01 11:47:20] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 170 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:47:20] [config] after: 0e
[2023-07-01 11:47:20] [config] after-batches: 0
[2023-07-01 11:47:20] [config] after-epochs: 170
[2023-07-01 11:47:20] [config] all-caps-every: 0
[2023-07-01 11:47:20] [config] allow-unk: false
[2023-07-01 11:47:20] [config] authors: false
[2023-07-01 11:47:20] [config] beam-size: 12
[2023-07-01 11:47:20] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:47:20] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:47:20] [config] bert-masking-fraction: 0.15
[2023-07-01 11:47:20] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:47:20] [config] bert-train-type-embeddings: true
[2023-07-01 11:47:20] [config] bert-type-vocab-size: 2
[2023-07-01 11:47:20] [config] build-info: ""
[2023-07-01 11:47:20] [config] check-gradient-nan: false
[2023-07-01 11:47:20] [config] check-nan: false
[2023-07-01 11:47:20] [config] cite: false
[2023-07-01 11:47:20] [config] clip-norm: 5
[2023-07-01 11:47:20] [config] cost-scaling:
[2023-07-01 11:47:20] [config]   []
[2023-07-01 11:47:20] [config] cost-type: ce-sum
[2023-07-01 11:47:20] [config] cpu-threads: 0
[2023-07-01 11:47:20] [config] data-threads: 8
[2023-07-01 11:47:20] [config] data-weighting: ""
[2023-07-01 11:47:20] [config] data-weighting-type: sentence
[2023-07-01 11:47:20] [config] dec-cell: gru
[2023-07-01 11:47:20] [config] dec-cell-base-depth: 2
[2023-07-01 11:47:20] [config] dec-cell-high-depth: 1
[2023-07-01 11:47:20] [config] dec-depth: 2
[2023-07-01 11:47:20] [config] devices:
[2023-07-01 11:47:20] [config]   - 0
[2023-07-01 11:47:20] [config] dim-emb: 512
[2023-07-01 11:47:20] [config] dim-rnn: 1024
[2023-07-01 11:47:20] [config] dim-vocabs:
[2023-07-01 11:47:20] [config]   - 16384
[2023-07-01 11:47:20] [config]   - 16384
[2023-07-01 11:47:20] [config] disp-first: 0
[2023-07-01 11:47:20] [config] disp-freq: 1000u
[2023-07-01 11:47:20] [config] disp-label-counts: true
[2023-07-01 11:47:20] [config] dropout-rnn: 0
[2023-07-01 11:47:20] [config] dropout-src: 0
[2023-07-01 11:47:20] [config] dropout-trg: 0
[2023-07-01 11:47:20] [config] dump-config: ""
[2023-07-01 11:47:20] [config] dynamic-gradient-scaling:
[2023-07-01 11:47:20] [config]   []
[2023-07-01 11:47:20] [config] early-stopping: 10
[2023-07-01 11:47:20] [config] early-stopping-on: first
[2023-07-01 11:47:20] [config] embedding-fix-src: false
[2023-07-01 11:47:20] [config] embedding-fix-trg: false
[2023-07-01 11:47:20] [config] embedding-normalization: false
[2023-07-01 11:47:20] [config] embedding-vectors:
[2023-07-01 11:47:20] [config]   []
[2023-07-01 11:47:20] [config] enc-cell: gru
[2023-07-01 11:47:20] [config] enc-cell-depth: 1
[2023-07-01 11:47:20] [config] enc-depth: 2
[2023-07-01 11:47:20] [config] enc-type: bidirectional
[2023-07-01 11:47:20] [config] english-title-case-every: 0
[2023-07-01 11:47:20] [config] exponential-smoothing: 0.0001
[2023-07-01 11:47:20] [config] factor-weight: 1
[2023-07-01 11:47:20] [config] factors-combine: sum
[2023-07-01 11:47:20] [config] factors-dim-emb: 0
[2023-07-01 11:47:20] [config] gradient-checkpointing: false
[2023-07-01 11:47:20] [config] gradient-norm-average-window: 100
[2023-07-01 11:47:20] [config] guided-alignment: none
[2023-07-01 11:47:20] [config] guided-alignment-cost: mse
[2023-07-01 11:47:20] [config] guided-alignment-weight: 0.1
[2023-07-01 11:47:20] [config] ignore-model-config: false
[2023-07-01 11:47:20] [config] input-types:
[2023-07-01 11:47:20] [config]   []
[2023-07-01 11:47:20] [config] interpolate-env-vars: false
[2023-07-01 11:47:20] [config] keep-best: false
[2023-07-01 11:47:20] [config] label-smoothing: 0.1
[2023-07-01 11:47:20] [config] layer-normalization: false
[2023-07-01 11:47:20] [config] learn-rate: 0.0003
[2023-07-01 11:47:20] [config] lemma-dependency: ""
[2023-07-01 11:47:20] [config] lemma-dim-emb: 0
[2023-07-01 11:47:20] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:47:20] [config] log-level: info
[2023-07-01 11:47:20] [config] log-time-zone: ""
[2023-07-01 11:47:20] [config] logical-epoch:
[2023-07-01 11:47:20] [config]   - 1e
[2023-07-01 11:47:20] [config]   - 0
[2023-07-01 11:47:20] [config] lr-decay: 0
[2023-07-01 11:47:20] [config] lr-decay-freq: 50000
[2023-07-01 11:47:20] [config] lr-decay-inv-sqrt:
[2023-07-01 11:47:20] [config]   - 16000
[2023-07-01 11:47:20] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:47:20] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:47:20] [config] lr-decay-start:
[2023-07-01 11:47:20] [config]   - 10
[2023-07-01 11:47:20] [config]   - 1
[2023-07-01 11:47:20] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:47:20] [config] lr-report: true
[2023-07-01 11:47:20] [config] lr-warmup: 16000
[2023-07-01 11:47:20] [config] lr-warmup-at-reload: false
[2023-07-01 11:47:20] [config] lr-warmup-cycle: false
[2023-07-01 11:47:20] [config] lr-warmup-start-rate: 0
[2023-07-01 11:47:20] [config] max-length: 100
[2023-07-01 11:47:20] [config] max-length-crop: false
[2023-07-01 11:47:20] [config] max-length-factor: 3
[2023-07-01 11:47:20] [config] maxi-batch: 100
[2023-07-01 11:47:20] [config] maxi-batch-sort: trg
[2023-07-01 11:47:20] [config] mini-batch: 1000
[2023-07-01 11:47:20] [config] mini-batch-fit: true
[2023-07-01 11:47:20] [config] mini-batch-fit-step: 10
[2023-07-01 11:47:20] [config] mini-batch-round-up: true
[2023-07-01 11:47:20] [config] mini-batch-track-lr: false
[2023-07-01 11:47:20] [config] mini-batch-warmup: 0
[2023-07-01 11:47:20] [config] mini-batch-words: 0
[2023-07-01 11:47:20] [config] mini-batch-words-ref: 0
[2023-07-01 11:47:20] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:47:20] [config] multi-loss-type: sum
[2023-07-01 11:47:20] [config] n-best: false
[2023-07-01 11:47:20] [config] no-nccl: false
[2023-07-01 11:47:20] [config] no-reload: false
[2023-07-01 11:47:20] [config] no-restore-corpus: false
[2023-07-01 11:47:20] [config] normalize: 1
[2023-07-01 11:47:20] [config] normalize-gradient: false
[2023-07-01 11:47:20] [config] num-devices: 0
[2023-07-01 11:47:20] [config] optimizer: adam
[2023-07-01 11:47:20] [config] optimizer-delay: 1
[2023-07-01 11:47:20] [config] optimizer-params:
[2023-07-01 11:47:20] [config]   - 0.9
[2023-07-01 11:47:20] [config]   - 0.98
[2023-07-01 11:47:20] [config]   - 1e-09
[2023-07-01 11:47:20] [config] output-omit-bias: false
[2023-07-01 11:47:20] [config] overwrite: true
[2023-07-01 11:47:20] [config] precision:
[2023-07-01 11:47:20] [config]   - float32
[2023-07-01 11:47:20] [config]   - float32
[2023-07-01 11:47:20] [config] pretrained-model: ""
[2023-07-01 11:47:20] [config] quantize-biases: false
[2023-07-01 11:47:20] [config] quantize-bits: 0
[2023-07-01 11:47:20] [config] quantize-log-based: false
[2023-07-01 11:47:20] [config] quantize-optimization-steps: 0
[2023-07-01 11:47:20] [config] quiet: false
[2023-07-01 11:47:20] [config] quiet-translation: true
[2023-07-01 11:47:20] [config] relative-paths: false
[2023-07-01 11:47:20] [config] right-left: false
[2023-07-01 11:47:20] [config] save-freq: 10000u
[2023-07-01 11:47:20] [config] seed: 1234
[2023-07-01 11:47:20] [config] sentencepiece-alphas:
[2023-07-01 11:47:20] [config]   []
[2023-07-01 11:47:20] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:47:20] [config] sentencepiece-options: ""
[2023-07-01 11:47:20] [config] sharding: global
[2023-07-01 11:47:20] [config] shuffle: data
[2023-07-01 11:47:20] [config] shuffle-in-ram: false
[2023-07-01 11:47:20] [config] sigterm: save-and-exit
[2023-07-01 11:47:20] [config] skip: false
[2023-07-01 11:47:20] [config] sqlite: ""
[2023-07-01 11:47:20] [config] sqlite-drop: false
[2023-07-01 11:47:20] [config] sync-freq: 200u
[2023-07-01 11:47:20] [config] sync-sgd: true
[2023-07-01 11:47:20] [config] tempdir: /tmp
[2023-07-01 11:47:20] [config] tied-embeddings: false
[2023-07-01 11:47:20] [config] tied-embeddings-all: true
[2023-07-01 11:47:20] [config] tied-embeddings-src: false
[2023-07-01 11:47:20] [config] train-embedder-rank:
[2023-07-01 11:47:20] [config]   []
[2023-07-01 11:47:20] [config] train-sets:
[2023-07-01 11:47:20] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:47:20] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:47:20] [config] transformer-aan-activation: swish
[2023-07-01 11:47:20] [config] transformer-aan-depth: 2
[2023-07-01 11:47:20] [config] transformer-aan-nogate: false
[2023-07-01 11:47:20] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:47:20] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:47:20] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:47:20] [config] transformer-depth-scaling: false
[2023-07-01 11:47:20] [config] transformer-dim-aan: 2048
[2023-07-01 11:47:20] [config] transformer-dim-ffn: 2048
[2023-07-01 11:47:20] [config] transformer-dropout: 0.1
[2023-07-01 11:47:20] [config] transformer-dropout-attention: 0
[2023-07-01 11:47:20] [config] transformer-dropout-ffn: 0
[2023-07-01 11:47:20] [config] transformer-ffn-activation: swish
[2023-07-01 11:47:20] [config] transformer-ffn-depth: 2
[2023-07-01 11:47:20] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:47:20] [config] transformer-heads: 8
[2023-07-01 11:47:20] [config] transformer-no-projection: false
[2023-07-01 11:47:20] [config] transformer-pool: false
[2023-07-01 11:47:20] [config] transformer-postprocess: dan
[2023-07-01 11:47:20] [config] transformer-postprocess-emb: d
[2023-07-01 11:47:20] [config] transformer-postprocess-top: ""
[2023-07-01 11:47:20] [config] transformer-preprocess: ""
[2023-07-01 11:47:20] [config] transformer-tied-layers:
[2023-07-01 11:47:20] [config]   []
[2023-07-01 11:47:20] [config] transformer-train-position-embeddings: false
[2023-07-01 11:47:20] [config] tsv: false
[2023-07-01 11:47:20] [config] tsv-fields: 0
[2023-07-01 11:47:20] [config] type: transformer
[2023-07-01 11:47:20] [config] ulr: false
[2023-07-01 11:47:20] [config] ulr-dim-emb: 0
[2023-07-01 11:47:20] [config] ulr-dropout: 0
[2023-07-01 11:47:20] [config] ulr-keys-vectors: ""
[2023-07-01 11:47:20] [config] ulr-query-vectors: ""
[2023-07-01 11:47:20] [config] ulr-softmax-temperature: 1
[2023-07-01 11:47:20] [config] ulr-trainable-transformation: false
[2023-07-01 11:47:20] [config] unlikelihood-loss: false
[2023-07-01 11:47:20] [config] valid-freq: 50000000
[2023-07-01 11:47:20] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:47:20] [config] valid-max-length: 1000
[2023-07-01 11:47:20] [config] valid-metrics:
[2023-07-01 11:47:20] [config]   - cross-entropy
[2023-07-01 11:47:20] [config]   - translation
[2023-07-01 11:47:20] [config] valid-mini-batch: 64
[2023-07-01 11:47:20] [config] valid-reset-stalled: false
[2023-07-01 11:47:20] [config] valid-script-args:
[2023-07-01 11:47:20] [config]   []
[2023-07-01 11:47:20] [config] valid-script-path: ""
[2023-07-01 11:47:20] [config] valid-sets:
[2023-07-01 11:47:20] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:47:20] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:47:20] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:47:20] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:47:20] [config] vocabs:
[2023-07-01 11:47:20] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:47:20] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:47:20] [config] word-penalty: 0
[2023-07-01 11:47:20] [config] word-scores: false
[2023-07-01 11:47:20] [config] workspace: 2048
[2023-07-01 11:47:20] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:47:20] Using synchronous SGD
[2023-07-01 11:47:21] Synced seed 1234
[2023-07-01 11:47:21] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:47:21] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:47:21] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:47:21] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:47:21] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:47:21] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:47:22] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:47:22] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:47:22] [comm] Using global sharding
[2023-07-01 11:47:22] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:47:22] [training] Using 1 GPUs
[2023-07-01 11:47:22] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:47:22] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:47:22] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:47:22] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:47:29] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:47:30] [valid] No post-processing script given for validating translator
[2023-07-01 11:47:30] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:47:30] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:47:30] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:47:30] [comm] Using global sharding
[2023-07-01 11:47:30] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:47:30] [training] Using 1 GPUs
[2023-07-01 11:47:30] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:47:30] Allocating memory for general optimizer shards
[2023-07-01 11:47:30] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:47:30] Loading Adam parameters
[2023-07-01 11:47:30] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:47:30] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:47:30] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:47:30] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:47:30] [data] Shuffling data
[2023-07-01 11:47:30] [data] Done reading 20,192 sentences
[2023-07-01 11:47:30] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:47:30] Training started
[2023-07-01 11:47:30] Training finished
[2023-07-01 11:47:34] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:47:34] [marian] Running on node20.datos.cluster.uy as process 21471 with command line:
[2023-07-01 11:47:34] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 171 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:47:34] [config] after: 0e
[2023-07-01 11:47:34] [config] after-batches: 0
[2023-07-01 11:47:34] [config] after-epochs: 171
[2023-07-01 11:47:34] [config] all-caps-every: 0
[2023-07-01 11:47:34] [config] allow-unk: false
[2023-07-01 11:47:34] [config] authors: false
[2023-07-01 11:47:34] [config] beam-size: 12
[2023-07-01 11:47:34] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:47:34] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:47:34] [config] bert-masking-fraction: 0.15
[2023-07-01 11:47:34] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:47:34] [config] bert-train-type-embeddings: true
[2023-07-01 11:47:34] [config] bert-type-vocab-size: 2
[2023-07-01 11:47:34] [config] build-info: ""
[2023-07-01 11:47:34] [config] check-gradient-nan: false
[2023-07-01 11:47:34] [config] check-nan: false
[2023-07-01 11:47:34] [config] cite: false
[2023-07-01 11:47:34] [config] clip-norm: 5
[2023-07-01 11:47:34] [config] cost-scaling:
[2023-07-01 11:47:34] [config]   []
[2023-07-01 11:47:34] [config] cost-type: ce-sum
[2023-07-01 11:47:34] [config] cpu-threads: 0
[2023-07-01 11:47:34] [config] data-threads: 8
[2023-07-01 11:47:34] [config] data-weighting: ""
[2023-07-01 11:47:34] [config] data-weighting-type: sentence
[2023-07-01 11:47:34] [config] dec-cell: gru
[2023-07-01 11:47:34] [config] dec-cell-base-depth: 2
[2023-07-01 11:47:34] [config] dec-cell-high-depth: 1
[2023-07-01 11:47:34] [config] dec-depth: 2
[2023-07-01 11:47:34] [config] devices:
[2023-07-01 11:47:34] [config]   - 0
[2023-07-01 11:47:34] [config] dim-emb: 512
[2023-07-01 11:47:34] [config] dim-rnn: 1024
[2023-07-01 11:47:34] [config] dim-vocabs:
[2023-07-01 11:47:34] [config]   - 16384
[2023-07-01 11:47:34] [config]   - 16384
[2023-07-01 11:47:34] [config] disp-first: 0
[2023-07-01 11:47:34] [config] disp-freq: 1000u
[2023-07-01 11:47:34] [config] disp-label-counts: true
[2023-07-01 11:47:34] [config] dropout-rnn: 0
[2023-07-01 11:47:34] [config] dropout-src: 0
[2023-07-01 11:47:34] [config] dropout-trg: 0
[2023-07-01 11:47:34] [config] dump-config: ""
[2023-07-01 11:47:34] [config] dynamic-gradient-scaling:
[2023-07-01 11:47:34] [config]   []
[2023-07-01 11:47:34] [config] early-stopping: 10
[2023-07-01 11:47:34] [config] early-stopping-on: first
[2023-07-01 11:47:34] [config] embedding-fix-src: false
[2023-07-01 11:47:34] [config] embedding-fix-trg: false
[2023-07-01 11:47:34] [config] embedding-normalization: false
[2023-07-01 11:47:34] [config] embedding-vectors:
[2023-07-01 11:47:34] [config]   []
[2023-07-01 11:47:34] [config] enc-cell: gru
[2023-07-01 11:47:34] [config] enc-cell-depth: 1
[2023-07-01 11:47:34] [config] enc-depth: 2
[2023-07-01 11:47:34] [config] enc-type: bidirectional
[2023-07-01 11:47:34] [config] english-title-case-every: 0
[2023-07-01 11:47:34] [config] exponential-smoothing: 0.0001
[2023-07-01 11:47:34] [config] factor-weight: 1
[2023-07-01 11:47:34] [config] factors-combine: sum
[2023-07-01 11:47:34] [config] factors-dim-emb: 0
[2023-07-01 11:47:34] [config] gradient-checkpointing: false
[2023-07-01 11:47:34] [config] gradient-norm-average-window: 100
[2023-07-01 11:47:34] [config] guided-alignment: none
[2023-07-01 11:47:34] [config] guided-alignment-cost: mse
[2023-07-01 11:47:34] [config] guided-alignment-weight: 0.1
[2023-07-01 11:47:34] [config] ignore-model-config: false
[2023-07-01 11:47:34] [config] input-types:
[2023-07-01 11:47:34] [config]   []
[2023-07-01 11:47:34] [config] interpolate-env-vars: false
[2023-07-01 11:47:34] [config] keep-best: false
[2023-07-01 11:47:34] [config] label-smoothing: 0.1
[2023-07-01 11:47:34] [config] layer-normalization: false
[2023-07-01 11:47:34] [config] learn-rate: 0.0003
[2023-07-01 11:47:34] [config] lemma-dependency: ""
[2023-07-01 11:47:34] [config] lemma-dim-emb: 0
[2023-07-01 11:47:34] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:47:34] [config] log-level: info
[2023-07-01 11:47:34] [config] log-time-zone: ""
[2023-07-01 11:47:34] [config] logical-epoch:
[2023-07-01 11:47:34] [config]   - 1e
[2023-07-01 11:47:34] [config]   - 0
[2023-07-01 11:47:34] [config] lr-decay: 0
[2023-07-01 11:47:34] [config] lr-decay-freq: 50000
[2023-07-01 11:47:34] [config] lr-decay-inv-sqrt:
[2023-07-01 11:47:34] [config]   - 16000
[2023-07-01 11:47:34] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:47:34] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:47:34] [config] lr-decay-start:
[2023-07-01 11:47:34] [config]   - 10
[2023-07-01 11:47:34] [config]   - 1
[2023-07-01 11:47:34] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:47:34] [config] lr-report: true
[2023-07-01 11:47:34] [config] lr-warmup: 16000
[2023-07-01 11:47:34] [config] lr-warmup-at-reload: false
[2023-07-01 11:47:34] [config] lr-warmup-cycle: false
[2023-07-01 11:47:34] [config] lr-warmup-start-rate: 0
[2023-07-01 11:47:34] [config] max-length: 100
[2023-07-01 11:47:34] [config] max-length-crop: false
[2023-07-01 11:47:34] [config] max-length-factor: 3
[2023-07-01 11:47:34] [config] maxi-batch: 100
[2023-07-01 11:47:34] [config] maxi-batch-sort: trg
[2023-07-01 11:47:34] [config] mini-batch: 1000
[2023-07-01 11:47:34] [config] mini-batch-fit: true
[2023-07-01 11:47:34] [config] mini-batch-fit-step: 10
[2023-07-01 11:47:34] [config] mini-batch-round-up: true
[2023-07-01 11:47:34] [config] mini-batch-track-lr: false
[2023-07-01 11:47:34] [config] mini-batch-warmup: 0
[2023-07-01 11:47:34] [config] mini-batch-words: 0
[2023-07-01 11:47:34] [config] mini-batch-words-ref: 0
[2023-07-01 11:47:34] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:47:34] [config] multi-loss-type: sum
[2023-07-01 11:47:34] [config] n-best: false
[2023-07-01 11:47:34] [config] no-nccl: false
[2023-07-01 11:47:34] [config] no-reload: false
[2023-07-01 11:47:34] [config] no-restore-corpus: false
[2023-07-01 11:47:34] [config] normalize: 1
[2023-07-01 11:47:34] [config] normalize-gradient: false
[2023-07-01 11:47:34] [config] num-devices: 0
[2023-07-01 11:47:34] [config] optimizer: adam
[2023-07-01 11:47:34] [config] optimizer-delay: 1
[2023-07-01 11:47:34] [config] optimizer-params:
[2023-07-01 11:47:34] [config]   - 0.9
[2023-07-01 11:47:34] [config]   - 0.98
[2023-07-01 11:47:34] [config]   - 1e-09
[2023-07-01 11:47:34] [config] output-omit-bias: false
[2023-07-01 11:47:34] [config] overwrite: true
[2023-07-01 11:47:34] [config] precision:
[2023-07-01 11:47:34] [config]   - float32
[2023-07-01 11:47:34] [config]   - float32
[2023-07-01 11:47:34] [config] pretrained-model: ""
[2023-07-01 11:47:34] [config] quantize-biases: false
[2023-07-01 11:47:34] [config] quantize-bits: 0
[2023-07-01 11:47:34] [config] quantize-log-based: false
[2023-07-01 11:47:34] [config] quantize-optimization-steps: 0
[2023-07-01 11:47:34] [config] quiet: false
[2023-07-01 11:47:34] [config] quiet-translation: true
[2023-07-01 11:47:34] [config] relative-paths: false
[2023-07-01 11:47:34] [config] right-left: false
[2023-07-01 11:47:34] [config] save-freq: 10000u
[2023-07-01 11:47:34] [config] seed: 1234
[2023-07-01 11:47:34] [config] sentencepiece-alphas:
[2023-07-01 11:47:34] [config]   []
[2023-07-01 11:47:34] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:47:34] [config] sentencepiece-options: ""
[2023-07-01 11:47:34] [config] sharding: global
[2023-07-01 11:47:34] [config] shuffle: data
[2023-07-01 11:47:34] [config] shuffle-in-ram: false
[2023-07-01 11:47:34] [config] sigterm: save-and-exit
[2023-07-01 11:47:34] [config] skip: false
[2023-07-01 11:47:34] [config] sqlite: ""
[2023-07-01 11:47:34] [config] sqlite-drop: false
[2023-07-01 11:47:34] [config] sync-freq: 200u
[2023-07-01 11:47:34] [config] sync-sgd: true
[2023-07-01 11:47:34] [config] tempdir: /tmp
[2023-07-01 11:47:34] [config] tied-embeddings: false
[2023-07-01 11:47:34] [config] tied-embeddings-all: true
[2023-07-01 11:47:34] [config] tied-embeddings-src: false
[2023-07-01 11:47:34] [config] train-embedder-rank:
[2023-07-01 11:47:34] [config]   []
[2023-07-01 11:47:34] [config] train-sets:
[2023-07-01 11:47:34] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:47:34] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:47:34] [config] transformer-aan-activation: swish
[2023-07-01 11:47:34] [config] transformer-aan-depth: 2
[2023-07-01 11:47:34] [config] transformer-aan-nogate: false
[2023-07-01 11:47:34] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:47:34] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:47:34] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:47:34] [config] transformer-depth-scaling: false
[2023-07-01 11:47:34] [config] transformer-dim-aan: 2048
[2023-07-01 11:47:34] [config] transformer-dim-ffn: 2048
[2023-07-01 11:47:34] [config] transformer-dropout: 0.1
[2023-07-01 11:47:34] [config] transformer-dropout-attention: 0
[2023-07-01 11:47:34] [config] transformer-dropout-ffn: 0
[2023-07-01 11:47:34] [config] transformer-ffn-activation: swish
[2023-07-01 11:47:34] [config] transformer-ffn-depth: 2
[2023-07-01 11:47:34] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:47:34] [config] transformer-heads: 8
[2023-07-01 11:47:34] [config] transformer-no-projection: false
[2023-07-01 11:47:34] [config] transformer-pool: false
[2023-07-01 11:47:34] [config] transformer-postprocess: dan
[2023-07-01 11:47:34] [config] transformer-postprocess-emb: d
[2023-07-01 11:47:34] [config] transformer-postprocess-top: ""
[2023-07-01 11:47:34] [config] transformer-preprocess: ""
[2023-07-01 11:47:34] [config] transformer-tied-layers:
[2023-07-01 11:47:34] [config]   []
[2023-07-01 11:47:34] [config] transformer-train-position-embeddings: false
[2023-07-01 11:47:34] [config] tsv: false
[2023-07-01 11:47:34] [config] tsv-fields: 0
[2023-07-01 11:47:34] [config] type: transformer
[2023-07-01 11:47:34] [config] ulr: false
[2023-07-01 11:47:34] [config] ulr-dim-emb: 0
[2023-07-01 11:47:34] [config] ulr-dropout: 0
[2023-07-01 11:47:34] [config] ulr-keys-vectors: ""
[2023-07-01 11:47:34] [config] ulr-query-vectors: ""
[2023-07-01 11:47:34] [config] ulr-softmax-temperature: 1
[2023-07-01 11:47:34] [config] ulr-trainable-transformation: false
[2023-07-01 11:47:34] [config] unlikelihood-loss: false
[2023-07-01 11:47:34] [config] valid-freq: 50000000
[2023-07-01 11:47:34] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:47:34] [config] valid-max-length: 1000
[2023-07-01 11:47:34] [config] valid-metrics:
[2023-07-01 11:47:34] [config]   - cross-entropy
[2023-07-01 11:47:34] [config]   - translation
[2023-07-01 11:47:34] [config] valid-mini-batch: 64
[2023-07-01 11:47:34] [config] valid-reset-stalled: false
[2023-07-01 11:47:34] [config] valid-script-args:
[2023-07-01 11:47:34] [config]   []
[2023-07-01 11:47:34] [config] valid-script-path: ""
[2023-07-01 11:47:34] [config] valid-sets:
[2023-07-01 11:47:34] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:47:34] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:47:34] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:47:34] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:47:34] [config] vocabs:
[2023-07-01 11:47:34] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:47:34] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:47:34] [config] word-penalty: 0
[2023-07-01 11:47:34] [config] word-scores: false
[2023-07-01 11:47:34] [config] workspace: 2048
[2023-07-01 11:47:34] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:47:34] Using synchronous SGD
[2023-07-01 11:47:34] Synced seed 1234
[2023-07-01 11:47:34] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:47:34] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:47:34] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:47:34] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:47:34] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:47:34] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:47:35] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:47:35] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:47:35] [comm] Using global sharding
[2023-07-01 11:47:35] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:47:35] [training] Using 1 GPUs
[2023-07-01 11:47:35] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:47:35] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:47:36] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:47:36] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:47:43] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:47:43] [valid] No post-processing script given for validating translator
[2023-07-01 11:47:43] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:47:43] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:47:43] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:47:43] [comm] Using global sharding
[2023-07-01 11:47:43] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:47:43] [training] Using 1 GPUs
[2023-07-01 11:47:43] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:47:44] Allocating memory for general optimizer shards
[2023-07-01 11:47:44] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:47:44] Loading Adam parameters
[2023-07-01 11:47:44] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:47:44] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:47:44] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:47:44] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:47:44] [data] Shuffling data
[2023-07-01 11:47:44] [data] Done reading 20,192 sentences
[2023-07-01 11:47:44] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:47:44] Training started
[2023-07-01 11:47:44] Training finished
[2023-07-01 11:47:48] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:47:48] [marian] Running on node20.datos.cluster.uy as process 21529 with command line:
[2023-07-01 11:47:48] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 172 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:47:48] [config] after: 0e
[2023-07-01 11:47:48] [config] after-batches: 0
[2023-07-01 11:47:48] [config] after-epochs: 172
[2023-07-01 11:47:48] [config] all-caps-every: 0
[2023-07-01 11:47:48] [config] allow-unk: false
[2023-07-01 11:47:48] [config] authors: false
[2023-07-01 11:47:48] [config] beam-size: 12
[2023-07-01 11:47:48] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:47:48] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:47:48] [config] bert-masking-fraction: 0.15
[2023-07-01 11:47:48] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:47:48] [config] bert-train-type-embeddings: true
[2023-07-01 11:47:48] [config] bert-type-vocab-size: 2
[2023-07-01 11:47:48] [config] build-info: ""
[2023-07-01 11:47:48] [config] check-gradient-nan: false
[2023-07-01 11:47:48] [config] check-nan: false
[2023-07-01 11:47:48] [config] cite: false
[2023-07-01 11:47:48] [config] clip-norm: 5
[2023-07-01 11:47:48] [config] cost-scaling:
[2023-07-01 11:47:48] [config]   []
[2023-07-01 11:47:48] [config] cost-type: ce-sum
[2023-07-01 11:47:48] [config] cpu-threads: 0
[2023-07-01 11:47:48] [config] data-threads: 8
[2023-07-01 11:47:48] [config] data-weighting: ""
[2023-07-01 11:47:48] [config] data-weighting-type: sentence
[2023-07-01 11:47:48] [config] dec-cell: gru
[2023-07-01 11:47:48] [config] dec-cell-base-depth: 2
[2023-07-01 11:47:48] [config] dec-cell-high-depth: 1
[2023-07-01 11:47:48] [config] dec-depth: 2
[2023-07-01 11:47:48] [config] devices:
[2023-07-01 11:47:48] [config]   - 0
[2023-07-01 11:47:48] [config] dim-emb: 512
[2023-07-01 11:47:48] [config] dim-rnn: 1024
[2023-07-01 11:47:48] [config] dim-vocabs:
[2023-07-01 11:47:48] [config]   - 16384
[2023-07-01 11:47:48] [config]   - 16384
[2023-07-01 11:47:48] [config] disp-first: 0
[2023-07-01 11:47:48] [config] disp-freq: 1000u
[2023-07-01 11:47:48] [config] disp-label-counts: true
[2023-07-01 11:47:48] [config] dropout-rnn: 0
[2023-07-01 11:47:48] [config] dropout-src: 0
[2023-07-01 11:47:48] [config] dropout-trg: 0
[2023-07-01 11:47:48] [config] dump-config: ""
[2023-07-01 11:47:48] [config] dynamic-gradient-scaling:
[2023-07-01 11:47:48] [config]   []
[2023-07-01 11:47:48] [config] early-stopping: 10
[2023-07-01 11:47:48] [config] early-stopping-on: first
[2023-07-01 11:47:48] [config] embedding-fix-src: false
[2023-07-01 11:47:48] [config] embedding-fix-trg: false
[2023-07-01 11:47:48] [config] embedding-normalization: false
[2023-07-01 11:47:48] [config] embedding-vectors:
[2023-07-01 11:47:48] [config]   []
[2023-07-01 11:47:48] [config] enc-cell: gru
[2023-07-01 11:47:48] [config] enc-cell-depth: 1
[2023-07-01 11:47:48] [config] enc-depth: 2
[2023-07-01 11:47:48] [config] enc-type: bidirectional
[2023-07-01 11:47:48] [config] english-title-case-every: 0
[2023-07-01 11:47:48] [config] exponential-smoothing: 0.0001
[2023-07-01 11:47:48] [config] factor-weight: 1
[2023-07-01 11:47:48] [config] factors-combine: sum
[2023-07-01 11:47:48] [config] factors-dim-emb: 0
[2023-07-01 11:47:48] [config] gradient-checkpointing: false
[2023-07-01 11:47:48] [config] gradient-norm-average-window: 100
[2023-07-01 11:47:48] [config] guided-alignment: none
[2023-07-01 11:47:48] [config] guided-alignment-cost: mse
[2023-07-01 11:47:48] [config] guided-alignment-weight: 0.1
[2023-07-01 11:47:48] [config] ignore-model-config: false
[2023-07-01 11:47:48] [config] input-types:
[2023-07-01 11:47:48] [config]   []
[2023-07-01 11:47:48] [config] interpolate-env-vars: false
[2023-07-01 11:47:48] [config] keep-best: false
[2023-07-01 11:47:48] [config] label-smoothing: 0.1
[2023-07-01 11:47:48] [config] layer-normalization: false
[2023-07-01 11:47:48] [config] learn-rate: 0.0003
[2023-07-01 11:47:48] [config] lemma-dependency: ""
[2023-07-01 11:47:48] [config] lemma-dim-emb: 0
[2023-07-01 11:47:48] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:47:48] [config] log-level: info
[2023-07-01 11:47:48] [config] log-time-zone: ""
[2023-07-01 11:47:48] [config] logical-epoch:
[2023-07-01 11:47:48] [config]   - 1e
[2023-07-01 11:47:48] [config]   - 0
[2023-07-01 11:47:48] [config] lr-decay: 0
[2023-07-01 11:47:48] [config] lr-decay-freq: 50000
[2023-07-01 11:47:48] [config] lr-decay-inv-sqrt:
[2023-07-01 11:47:48] [config]   - 16000
[2023-07-01 11:47:48] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:47:48] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:47:48] [config] lr-decay-start:
[2023-07-01 11:47:48] [config]   - 10
[2023-07-01 11:47:48] [config]   - 1
[2023-07-01 11:47:48] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:47:48] [config] lr-report: true
[2023-07-01 11:47:48] [config] lr-warmup: 16000
[2023-07-01 11:47:48] [config] lr-warmup-at-reload: false
[2023-07-01 11:47:48] [config] lr-warmup-cycle: false
[2023-07-01 11:47:48] [config] lr-warmup-start-rate: 0
[2023-07-01 11:47:48] [config] max-length: 100
[2023-07-01 11:47:48] [config] max-length-crop: false
[2023-07-01 11:47:48] [config] max-length-factor: 3
[2023-07-01 11:47:48] [config] maxi-batch: 100
[2023-07-01 11:47:48] [config] maxi-batch-sort: trg
[2023-07-01 11:47:48] [config] mini-batch: 1000
[2023-07-01 11:47:48] [config] mini-batch-fit: true
[2023-07-01 11:47:48] [config] mini-batch-fit-step: 10
[2023-07-01 11:47:48] [config] mini-batch-round-up: true
[2023-07-01 11:47:48] [config] mini-batch-track-lr: false
[2023-07-01 11:47:48] [config] mini-batch-warmup: 0
[2023-07-01 11:47:48] [config] mini-batch-words: 0
[2023-07-01 11:47:48] [config] mini-batch-words-ref: 0
[2023-07-01 11:47:48] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:47:48] [config] multi-loss-type: sum
[2023-07-01 11:47:48] [config] n-best: false
[2023-07-01 11:47:48] [config] no-nccl: false
[2023-07-01 11:47:48] [config] no-reload: false
[2023-07-01 11:47:48] [config] no-restore-corpus: false
[2023-07-01 11:47:48] [config] normalize: 1
[2023-07-01 11:47:48] [config] normalize-gradient: false
[2023-07-01 11:47:48] [config] num-devices: 0
[2023-07-01 11:47:48] [config] optimizer: adam
[2023-07-01 11:47:48] [config] optimizer-delay: 1
[2023-07-01 11:47:48] [config] optimizer-params:
[2023-07-01 11:47:48] [config]   - 0.9
[2023-07-01 11:47:48] [config]   - 0.98
[2023-07-01 11:47:48] [config]   - 1e-09
[2023-07-01 11:47:48] [config] output-omit-bias: false
[2023-07-01 11:47:48] [config] overwrite: true
[2023-07-01 11:47:48] [config] precision:
[2023-07-01 11:47:48] [config]   - float32
[2023-07-01 11:47:48] [config]   - float32
[2023-07-01 11:47:48] [config] pretrained-model: ""
[2023-07-01 11:47:48] [config] quantize-biases: false
[2023-07-01 11:47:48] [config] quantize-bits: 0
[2023-07-01 11:47:48] [config] quantize-log-based: false
[2023-07-01 11:47:48] [config] quantize-optimization-steps: 0
[2023-07-01 11:47:48] [config] quiet: false
[2023-07-01 11:47:48] [config] quiet-translation: true
[2023-07-01 11:47:48] [config] relative-paths: false
[2023-07-01 11:47:48] [config] right-left: false
[2023-07-01 11:47:48] [config] save-freq: 10000u
[2023-07-01 11:47:48] [config] seed: 1234
[2023-07-01 11:47:48] [config] sentencepiece-alphas:
[2023-07-01 11:47:48] [config]   []
[2023-07-01 11:47:48] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:47:48] [config] sentencepiece-options: ""
[2023-07-01 11:47:48] [config] sharding: global
[2023-07-01 11:47:48] [config] shuffle: data
[2023-07-01 11:47:48] [config] shuffle-in-ram: false
[2023-07-01 11:47:48] [config] sigterm: save-and-exit
[2023-07-01 11:47:48] [config] skip: false
[2023-07-01 11:47:48] [config] sqlite: ""
[2023-07-01 11:47:48] [config] sqlite-drop: false
[2023-07-01 11:47:48] [config] sync-freq: 200u
[2023-07-01 11:47:48] [config] sync-sgd: true
[2023-07-01 11:47:48] [config] tempdir: /tmp
[2023-07-01 11:47:48] [config] tied-embeddings: false
[2023-07-01 11:47:48] [config] tied-embeddings-all: true
[2023-07-01 11:47:48] [config] tied-embeddings-src: false
[2023-07-01 11:47:48] [config] train-embedder-rank:
[2023-07-01 11:47:48] [config]   []
[2023-07-01 11:47:48] [config] train-sets:
[2023-07-01 11:47:48] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:47:48] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:47:48] [config] transformer-aan-activation: swish
[2023-07-01 11:47:48] [config] transformer-aan-depth: 2
[2023-07-01 11:47:48] [config] transformer-aan-nogate: false
[2023-07-01 11:47:48] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:47:48] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:47:48] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:47:48] [config] transformer-depth-scaling: false
[2023-07-01 11:47:48] [config] transformer-dim-aan: 2048
[2023-07-01 11:47:48] [config] transformer-dim-ffn: 2048
[2023-07-01 11:47:48] [config] transformer-dropout: 0.1
[2023-07-01 11:47:48] [config] transformer-dropout-attention: 0
[2023-07-01 11:47:48] [config] transformer-dropout-ffn: 0
[2023-07-01 11:47:48] [config] transformer-ffn-activation: swish
[2023-07-01 11:47:48] [config] transformer-ffn-depth: 2
[2023-07-01 11:47:48] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:47:48] [config] transformer-heads: 8
[2023-07-01 11:47:48] [config] transformer-no-projection: false
[2023-07-01 11:47:48] [config] transformer-pool: false
[2023-07-01 11:47:48] [config] transformer-postprocess: dan
[2023-07-01 11:47:48] [config] transformer-postprocess-emb: d
[2023-07-01 11:47:48] [config] transformer-postprocess-top: ""
[2023-07-01 11:47:48] [config] transformer-preprocess: ""
[2023-07-01 11:47:48] [config] transformer-tied-layers:
[2023-07-01 11:47:48] [config]   []
[2023-07-01 11:47:48] [config] transformer-train-position-embeddings: false
[2023-07-01 11:47:48] [config] tsv: false
[2023-07-01 11:47:48] [config] tsv-fields: 0
[2023-07-01 11:47:48] [config] type: transformer
[2023-07-01 11:47:48] [config] ulr: false
[2023-07-01 11:47:48] [config] ulr-dim-emb: 0
[2023-07-01 11:47:48] [config] ulr-dropout: 0
[2023-07-01 11:47:48] [config] ulr-keys-vectors: ""
[2023-07-01 11:47:48] [config] ulr-query-vectors: ""
[2023-07-01 11:47:48] [config] ulr-softmax-temperature: 1
[2023-07-01 11:47:48] [config] ulr-trainable-transformation: false
[2023-07-01 11:47:48] [config] unlikelihood-loss: false
[2023-07-01 11:47:48] [config] valid-freq: 50000000
[2023-07-01 11:47:48] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:47:48] [config] valid-max-length: 1000
[2023-07-01 11:47:48] [config] valid-metrics:
[2023-07-01 11:47:48] [config]   - cross-entropy
[2023-07-01 11:47:48] [config]   - translation
[2023-07-01 11:47:48] [config] valid-mini-batch: 64
[2023-07-01 11:47:48] [config] valid-reset-stalled: false
[2023-07-01 11:47:48] [config] valid-script-args:
[2023-07-01 11:47:48] [config]   []
[2023-07-01 11:47:48] [config] valid-script-path: ""
[2023-07-01 11:47:48] [config] valid-sets:
[2023-07-01 11:47:48] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:47:48] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:47:48] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:47:48] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:47:48] [config] vocabs:
[2023-07-01 11:47:48] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:47:48] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:47:48] [config] word-penalty: 0
[2023-07-01 11:47:48] [config] word-scores: false
[2023-07-01 11:47:48] [config] workspace: 2048
[2023-07-01 11:47:48] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:47:48] Using synchronous SGD
[2023-07-01 11:47:48] Synced seed 1234
[2023-07-01 11:47:48] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:47:48] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:47:48] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:47:48] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:47:48] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:47:48] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:47:49] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:47:49] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:47:49] [comm] Using global sharding
[2023-07-01 11:47:49] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:47:49] [training] Using 1 GPUs
[2023-07-01 11:47:49] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:47:49] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:47:49] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:47:49] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:47:57] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:47:57] [valid] No post-processing script given for validating translator
[2023-07-01 11:47:57] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:47:57] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:47:57] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:47:57] [comm] Using global sharding
[2023-07-01 11:47:57] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:47:57] [training] Using 1 GPUs
[2023-07-01 11:47:57] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:47:57] Allocating memory for general optimizer shards
[2023-07-01 11:47:57] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:47:57] Loading Adam parameters
[2023-07-01 11:47:57] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:47:57] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:47:57] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:47:57] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:47:57] [data] Shuffling data
[2023-07-01 11:47:57] [data] Done reading 20,192 sentences
[2023-07-01 11:47:58] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:47:58] Training started
[2023-07-01 11:47:58] Training finished
[2023-07-01 11:48:01] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:48:01] [marian] Running on node20.datos.cluster.uy as process 21588 with command line:
[2023-07-01 11:48:01] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 173 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:48:01] [config] after: 0e
[2023-07-01 11:48:01] [config] after-batches: 0
[2023-07-01 11:48:01] [config] after-epochs: 173
[2023-07-01 11:48:01] [config] all-caps-every: 0
[2023-07-01 11:48:01] [config] allow-unk: false
[2023-07-01 11:48:01] [config] authors: false
[2023-07-01 11:48:01] [config] beam-size: 12
[2023-07-01 11:48:01] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:48:01] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:48:01] [config] bert-masking-fraction: 0.15
[2023-07-01 11:48:01] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:48:01] [config] bert-train-type-embeddings: true
[2023-07-01 11:48:01] [config] bert-type-vocab-size: 2
[2023-07-01 11:48:01] [config] build-info: ""
[2023-07-01 11:48:01] [config] check-gradient-nan: false
[2023-07-01 11:48:01] [config] check-nan: false
[2023-07-01 11:48:01] [config] cite: false
[2023-07-01 11:48:01] [config] clip-norm: 5
[2023-07-01 11:48:01] [config] cost-scaling:
[2023-07-01 11:48:01] [config]   []
[2023-07-01 11:48:01] [config] cost-type: ce-sum
[2023-07-01 11:48:01] [config] cpu-threads: 0
[2023-07-01 11:48:01] [config] data-threads: 8
[2023-07-01 11:48:01] [config] data-weighting: ""
[2023-07-01 11:48:01] [config] data-weighting-type: sentence
[2023-07-01 11:48:01] [config] dec-cell: gru
[2023-07-01 11:48:01] [config] dec-cell-base-depth: 2
[2023-07-01 11:48:01] [config] dec-cell-high-depth: 1
[2023-07-01 11:48:01] [config] dec-depth: 2
[2023-07-01 11:48:01] [config] devices:
[2023-07-01 11:48:01] [config]   - 0
[2023-07-01 11:48:01] [config] dim-emb: 512
[2023-07-01 11:48:01] [config] dim-rnn: 1024
[2023-07-01 11:48:01] [config] dim-vocabs:
[2023-07-01 11:48:01] [config]   - 16384
[2023-07-01 11:48:01] [config]   - 16384
[2023-07-01 11:48:01] [config] disp-first: 0
[2023-07-01 11:48:01] [config] disp-freq: 1000u
[2023-07-01 11:48:01] [config] disp-label-counts: true
[2023-07-01 11:48:01] [config] dropout-rnn: 0
[2023-07-01 11:48:01] [config] dropout-src: 0
[2023-07-01 11:48:01] [config] dropout-trg: 0
[2023-07-01 11:48:01] [config] dump-config: ""
[2023-07-01 11:48:01] [config] dynamic-gradient-scaling:
[2023-07-01 11:48:01] [config]   []
[2023-07-01 11:48:01] [config] early-stopping: 10
[2023-07-01 11:48:01] [config] early-stopping-on: first
[2023-07-01 11:48:01] [config] embedding-fix-src: false
[2023-07-01 11:48:01] [config] embedding-fix-trg: false
[2023-07-01 11:48:01] [config] embedding-normalization: false
[2023-07-01 11:48:01] [config] embedding-vectors:
[2023-07-01 11:48:01] [config]   []
[2023-07-01 11:48:01] [config] enc-cell: gru
[2023-07-01 11:48:01] [config] enc-cell-depth: 1
[2023-07-01 11:48:01] [config] enc-depth: 2
[2023-07-01 11:48:01] [config] enc-type: bidirectional
[2023-07-01 11:48:01] [config] english-title-case-every: 0
[2023-07-01 11:48:01] [config] exponential-smoothing: 0.0001
[2023-07-01 11:48:01] [config] factor-weight: 1
[2023-07-01 11:48:01] [config] factors-combine: sum
[2023-07-01 11:48:01] [config] factors-dim-emb: 0
[2023-07-01 11:48:01] [config] gradient-checkpointing: false
[2023-07-01 11:48:01] [config] gradient-norm-average-window: 100
[2023-07-01 11:48:01] [config] guided-alignment: none
[2023-07-01 11:48:01] [config] guided-alignment-cost: mse
[2023-07-01 11:48:01] [config] guided-alignment-weight: 0.1
[2023-07-01 11:48:01] [config] ignore-model-config: false
[2023-07-01 11:48:01] [config] input-types:
[2023-07-01 11:48:01] [config]   []
[2023-07-01 11:48:01] [config] interpolate-env-vars: false
[2023-07-01 11:48:01] [config] keep-best: false
[2023-07-01 11:48:01] [config] label-smoothing: 0.1
[2023-07-01 11:48:01] [config] layer-normalization: false
[2023-07-01 11:48:01] [config] learn-rate: 0.0003
[2023-07-01 11:48:01] [config] lemma-dependency: ""
[2023-07-01 11:48:01] [config] lemma-dim-emb: 0
[2023-07-01 11:48:01] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:48:01] [config] log-level: info
[2023-07-01 11:48:01] [config] log-time-zone: ""
[2023-07-01 11:48:01] [config] logical-epoch:
[2023-07-01 11:48:01] [config]   - 1e
[2023-07-01 11:48:01] [config]   - 0
[2023-07-01 11:48:01] [config] lr-decay: 0
[2023-07-01 11:48:01] [config] lr-decay-freq: 50000
[2023-07-01 11:48:01] [config] lr-decay-inv-sqrt:
[2023-07-01 11:48:01] [config]   - 16000
[2023-07-01 11:48:01] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:48:01] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:48:01] [config] lr-decay-start:
[2023-07-01 11:48:01] [config]   - 10
[2023-07-01 11:48:01] [config]   - 1
[2023-07-01 11:48:01] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:48:01] [config] lr-report: true
[2023-07-01 11:48:01] [config] lr-warmup: 16000
[2023-07-01 11:48:01] [config] lr-warmup-at-reload: false
[2023-07-01 11:48:01] [config] lr-warmup-cycle: false
[2023-07-01 11:48:01] [config] lr-warmup-start-rate: 0
[2023-07-01 11:48:01] [config] max-length: 100
[2023-07-01 11:48:01] [config] max-length-crop: false
[2023-07-01 11:48:01] [config] max-length-factor: 3
[2023-07-01 11:48:01] [config] maxi-batch: 100
[2023-07-01 11:48:01] [config] maxi-batch-sort: trg
[2023-07-01 11:48:01] [config] mini-batch: 1000
[2023-07-01 11:48:01] [config] mini-batch-fit: true
[2023-07-01 11:48:01] [config] mini-batch-fit-step: 10
[2023-07-01 11:48:01] [config] mini-batch-round-up: true
[2023-07-01 11:48:01] [config] mini-batch-track-lr: false
[2023-07-01 11:48:01] [config] mini-batch-warmup: 0
[2023-07-01 11:48:01] [config] mini-batch-words: 0
[2023-07-01 11:48:01] [config] mini-batch-words-ref: 0
[2023-07-01 11:48:01] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:48:01] [config] multi-loss-type: sum
[2023-07-01 11:48:01] [config] n-best: false
[2023-07-01 11:48:01] [config] no-nccl: false
[2023-07-01 11:48:01] [config] no-reload: false
[2023-07-01 11:48:01] [config] no-restore-corpus: false
[2023-07-01 11:48:01] [config] normalize: 1
[2023-07-01 11:48:01] [config] normalize-gradient: false
[2023-07-01 11:48:01] [config] num-devices: 0
[2023-07-01 11:48:01] [config] optimizer: adam
[2023-07-01 11:48:01] [config] optimizer-delay: 1
[2023-07-01 11:48:01] [config] optimizer-params:
[2023-07-01 11:48:01] [config]   - 0.9
[2023-07-01 11:48:01] [config]   - 0.98
[2023-07-01 11:48:01] [config]   - 1e-09
[2023-07-01 11:48:01] [config] output-omit-bias: false
[2023-07-01 11:48:01] [config] overwrite: true
[2023-07-01 11:48:01] [config] precision:
[2023-07-01 11:48:01] [config]   - float32
[2023-07-01 11:48:01] [config]   - float32
[2023-07-01 11:48:01] [config] pretrained-model: ""
[2023-07-01 11:48:01] [config] quantize-biases: false
[2023-07-01 11:48:01] [config] quantize-bits: 0
[2023-07-01 11:48:01] [config] quantize-log-based: false
[2023-07-01 11:48:01] [config] quantize-optimization-steps: 0
[2023-07-01 11:48:01] [config] quiet: false
[2023-07-01 11:48:01] [config] quiet-translation: true
[2023-07-01 11:48:01] [config] relative-paths: false
[2023-07-01 11:48:01] [config] right-left: false
[2023-07-01 11:48:01] [config] save-freq: 10000u
[2023-07-01 11:48:01] [config] seed: 1234
[2023-07-01 11:48:01] [config] sentencepiece-alphas:
[2023-07-01 11:48:01] [config]   []
[2023-07-01 11:48:01] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:48:01] [config] sentencepiece-options: ""
[2023-07-01 11:48:01] [config] sharding: global
[2023-07-01 11:48:01] [config] shuffle: data
[2023-07-01 11:48:01] [config] shuffle-in-ram: false
[2023-07-01 11:48:01] [config] sigterm: save-and-exit
[2023-07-01 11:48:01] [config] skip: false
[2023-07-01 11:48:01] [config] sqlite: ""
[2023-07-01 11:48:01] [config] sqlite-drop: false
[2023-07-01 11:48:01] [config] sync-freq: 200u
[2023-07-01 11:48:01] [config] sync-sgd: true
[2023-07-01 11:48:01] [config] tempdir: /tmp
[2023-07-01 11:48:01] [config] tied-embeddings: false
[2023-07-01 11:48:01] [config] tied-embeddings-all: true
[2023-07-01 11:48:01] [config] tied-embeddings-src: false
[2023-07-01 11:48:01] [config] train-embedder-rank:
[2023-07-01 11:48:01] [config]   []
[2023-07-01 11:48:01] [config] train-sets:
[2023-07-01 11:48:01] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:48:01] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:48:01] [config] transformer-aan-activation: swish
[2023-07-01 11:48:01] [config] transformer-aan-depth: 2
[2023-07-01 11:48:01] [config] transformer-aan-nogate: false
[2023-07-01 11:48:01] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:48:01] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:48:01] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:48:01] [config] transformer-depth-scaling: false
[2023-07-01 11:48:01] [config] transformer-dim-aan: 2048
[2023-07-01 11:48:01] [config] transformer-dim-ffn: 2048
[2023-07-01 11:48:01] [config] transformer-dropout: 0.1
[2023-07-01 11:48:01] [config] transformer-dropout-attention: 0
[2023-07-01 11:48:01] [config] transformer-dropout-ffn: 0
[2023-07-01 11:48:01] [config] transformer-ffn-activation: swish
[2023-07-01 11:48:01] [config] transformer-ffn-depth: 2
[2023-07-01 11:48:01] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:48:01] [config] transformer-heads: 8
[2023-07-01 11:48:01] [config] transformer-no-projection: false
[2023-07-01 11:48:01] [config] transformer-pool: false
[2023-07-01 11:48:01] [config] transformer-postprocess: dan
[2023-07-01 11:48:01] [config] transformer-postprocess-emb: d
[2023-07-01 11:48:01] [config] transformer-postprocess-top: ""
[2023-07-01 11:48:01] [config] transformer-preprocess: ""
[2023-07-01 11:48:01] [config] transformer-tied-layers:
[2023-07-01 11:48:01] [config]   []
[2023-07-01 11:48:01] [config] transformer-train-position-embeddings: false
[2023-07-01 11:48:01] [config] tsv: false
[2023-07-01 11:48:01] [config] tsv-fields: 0
[2023-07-01 11:48:01] [config] type: transformer
[2023-07-01 11:48:01] [config] ulr: false
[2023-07-01 11:48:01] [config] ulr-dim-emb: 0
[2023-07-01 11:48:01] [config] ulr-dropout: 0
[2023-07-01 11:48:01] [config] ulr-keys-vectors: ""
[2023-07-01 11:48:01] [config] ulr-query-vectors: ""
[2023-07-01 11:48:01] [config] ulr-softmax-temperature: 1
[2023-07-01 11:48:01] [config] ulr-trainable-transformation: false
[2023-07-01 11:48:01] [config] unlikelihood-loss: false
[2023-07-01 11:48:01] [config] valid-freq: 50000000
[2023-07-01 11:48:01] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:48:01] [config] valid-max-length: 1000
[2023-07-01 11:48:01] [config] valid-metrics:
[2023-07-01 11:48:01] [config]   - cross-entropy
[2023-07-01 11:48:01] [config]   - translation
[2023-07-01 11:48:01] [config] valid-mini-batch: 64
[2023-07-01 11:48:01] [config] valid-reset-stalled: false
[2023-07-01 11:48:01] [config] valid-script-args:
[2023-07-01 11:48:01] [config]   []
[2023-07-01 11:48:01] [config] valid-script-path: ""
[2023-07-01 11:48:01] [config] valid-sets:
[2023-07-01 11:48:01] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:48:01] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:48:01] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:48:01] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:48:01] [config] vocabs:
[2023-07-01 11:48:01] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:48:01] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:48:01] [config] word-penalty: 0
[2023-07-01 11:48:01] [config] word-scores: false
[2023-07-01 11:48:01] [config] workspace: 2048
[2023-07-01 11:48:01] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:48:01] Using synchronous SGD
[2023-07-01 11:48:01] Synced seed 1234
[2023-07-01 11:48:01] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:48:01] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:48:01] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:48:01] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:48:01] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:48:01] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:48:02] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:48:02] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:48:02] [comm] Using global sharding
[2023-07-01 11:48:02] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:48:02] [training] Using 1 GPUs
[2023-07-01 11:48:02] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:48:02] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:48:03] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:48:03] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:48:10] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:48:10] [valid] No post-processing script given for validating translator
[2023-07-01 11:48:10] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:48:10] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:48:10] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:48:10] [comm] Using global sharding
[2023-07-01 11:48:10] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:48:10] [training] Using 1 GPUs
[2023-07-01 11:48:10] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:48:11] Allocating memory for general optimizer shards
[2023-07-01 11:48:11] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:48:11] Loading Adam parameters
[2023-07-01 11:48:11] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:48:11] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:48:11] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:48:11] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:48:11] [data] Shuffling data
[2023-07-01 11:48:11] [data] Done reading 20,192 sentences
[2023-07-01 11:48:11] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:48:11] Training started
[2023-07-01 11:48:11] Training finished
[2023-07-01 11:48:15] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:48:15] [marian] Running on node20.datos.cluster.uy as process 21646 with command line:
[2023-07-01 11:48:15] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 174 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:48:15] [config] after: 0e
[2023-07-01 11:48:15] [config] after-batches: 0
[2023-07-01 11:48:15] [config] after-epochs: 174
[2023-07-01 11:48:15] [config] all-caps-every: 0
[2023-07-01 11:48:15] [config] allow-unk: false
[2023-07-01 11:48:15] [config] authors: false
[2023-07-01 11:48:15] [config] beam-size: 12
[2023-07-01 11:48:15] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:48:15] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:48:15] [config] bert-masking-fraction: 0.15
[2023-07-01 11:48:15] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:48:15] [config] bert-train-type-embeddings: true
[2023-07-01 11:48:15] [config] bert-type-vocab-size: 2
[2023-07-01 11:48:15] [config] build-info: ""
[2023-07-01 11:48:15] [config] check-gradient-nan: false
[2023-07-01 11:48:15] [config] check-nan: false
[2023-07-01 11:48:15] [config] cite: false
[2023-07-01 11:48:15] [config] clip-norm: 5
[2023-07-01 11:48:15] [config] cost-scaling:
[2023-07-01 11:48:15] [config]   []
[2023-07-01 11:48:15] [config] cost-type: ce-sum
[2023-07-01 11:48:15] [config] cpu-threads: 0
[2023-07-01 11:48:15] [config] data-threads: 8
[2023-07-01 11:48:15] [config] data-weighting: ""
[2023-07-01 11:48:15] [config] data-weighting-type: sentence
[2023-07-01 11:48:15] [config] dec-cell: gru
[2023-07-01 11:48:15] [config] dec-cell-base-depth: 2
[2023-07-01 11:48:15] [config] dec-cell-high-depth: 1
[2023-07-01 11:48:15] [config] dec-depth: 2
[2023-07-01 11:48:15] [config] devices:
[2023-07-01 11:48:15] [config]   - 0
[2023-07-01 11:48:15] [config] dim-emb: 512
[2023-07-01 11:48:15] [config] dim-rnn: 1024
[2023-07-01 11:48:15] [config] dim-vocabs:
[2023-07-01 11:48:15] [config]   - 16384
[2023-07-01 11:48:15] [config]   - 16384
[2023-07-01 11:48:15] [config] disp-first: 0
[2023-07-01 11:48:15] [config] disp-freq: 1000u
[2023-07-01 11:48:15] [config] disp-label-counts: true
[2023-07-01 11:48:15] [config] dropout-rnn: 0
[2023-07-01 11:48:15] [config] dropout-src: 0
[2023-07-01 11:48:15] [config] dropout-trg: 0
[2023-07-01 11:48:15] [config] dump-config: ""
[2023-07-01 11:48:15] [config] dynamic-gradient-scaling:
[2023-07-01 11:48:15] [config]   []
[2023-07-01 11:48:15] [config] early-stopping: 10
[2023-07-01 11:48:15] [config] early-stopping-on: first
[2023-07-01 11:48:15] [config] embedding-fix-src: false
[2023-07-01 11:48:15] [config] embedding-fix-trg: false
[2023-07-01 11:48:15] [config] embedding-normalization: false
[2023-07-01 11:48:15] [config] embedding-vectors:
[2023-07-01 11:48:15] [config]   []
[2023-07-01 11:48:15] [config] enc-cell: gru
[2023-07-01 11:48:15] [config] enc-cell-depth: 1
[2023-07-01 11:48:15] [config] enc-depth: 2
[2023-07-01 11:48:15] [config] enc-type: bidirectional
[2023-07-01 11:48:15] [config] english-title-case-every: 0
[2023-07-01 11:48:15] [config] exponential-smoothing: 0.0001
[2023-07-01 11:48:15] [config] factor-weight: 1
[2023-07-01 11:48:15] [config] factors-combine: sum
[2023-07-01 11:48:15] [config] factors-dim-emb: 0
[2023-07-01 11:48:15] [config] gradient-checkpointing: false
[2023-07-01 11:48:15] [config] gradient-norm-average-window: 100
[2023-07-01 11:48:15] [config] guided-alignment: none
[2023-07-01 11:48:15] [config] guided-alignment-cost: mse
[2023-07-01 11:48:15] [config] guided-alignment-weight: 0.1
[2023-07-01 11:48:15] [config] ignore-model-config: false
[2023-07-01 11:48:15] [config] input-types:
[2023-07-01 11:48:15] [config]   []
[2023-07-01 11:48:15] [config] interpolate-env-vars: false
[2023-07-01 11:48:15] [config] keep-best: false
[2023-07-01 11:48:15] [config] label-smoothing: 0.1
[2023-07-01 11:48:15] [config] layer-normalization: false
[2023-07-01 11:48:15] [config] learn-rate: 0.0003
[2023-07-01 11:48:15] [config] lemma-dependency: ""
[2023-07-01 11:48:15] [config] lemma-dim-emb: 0
[2023-07-01 11:48:15] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:48:15] [config] log-level: info
[2023-07-01 11:48:15] [config] log-time-zone: ""
[2023-07-01 11:48:15] [config] logical-epoch:
[2023-07-01 11:48:15] [config]   - 1e
[2023-07-01 11:48:15] [config]   - 0
[2023-07-01 11:48:15] [config] lr-decay: 0
[2023-07-01 11:48:15] [config] lr-decay-freq: 50000
[2023-07-01 11:48:15] [config] lr-decay-inv-sqrt:
[2023-07-01 11:48:15] [config]   - 16000
[2023-07-01 11:48:15] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:48:15] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:48:15] [config] lr-decay-start:
[2023-07-01 11:48:15] [config]   - 10
[2023-07-01 11:48:15] [config]   - 1
[2023-07-01 11:48:15] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:48:15] [config] lr-report: true
[2023-07-01 11:48:15] [config] lr-warmup: 16000
[2023-07-01 11:48:15] [config] lr-warmup-at-reload: false
[2023-07-01 11:48:15] [config] lr-warmup-cycle: false
[2023-07-01 11:48:15] [config] lr-warmup-start-rate: 0
[2023-07-01 11:48:15] [config] max-length: 100
[2023-07-01 11:48:15] [config] max-length-crop: false
[2023-07-01 11:48:15] [config] max-length-factor: 3
[2023-07-01 11:48:15] [config] maxi-batch: 100
[2023-07-01 11:48:15] [config] maxi-batch-sort: trg
[2023-07-01 11:48:15] [config] mini-batch: 1000
[2023-07-01 11:48:15] [config] mini-batch-fit: true
[2023-07-01 11:48:15] [config] mini-batch-fit-step: 10
[2023-07-01 11:48:15] [config] mini-batch-round-up: true
[2023-07-01 11:48:15] [config] mini-batch-track-lr: false
[2023-07-01 11:48:15] [config] mini-batch-warmup: 0
[2023-07-01 11:48:15] [config] mini-batch-words: 0
[2023-07-01 11:48:15] [config] mini-batch-words-ref: 0
[2023-07-01 11:48:15] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:48:15] [config] multi-loss-type: sum
[2023-07-01 11:48:15] [config] n-best: false
[2023-07-01 11:48:15] [config] no-nccl: false
[2023-07-01 11:48:15] [config] no-reload: false
[2023-07-01 11:48:15] [config] no-restore-corpus: false
[2023-07-01 11:48:15] [config] normalize: 1
[2023-07-01 11:48:15] [config] normalize-gradient: false
[2023-07-01 11:48:15] [config] num-devices: 0
[2023-07-01 11:48:15] [config] optimizer: adam
[2023-07-01 11:48:15] [config] optimizer-delay: 1
[2023-07-01 11:48:15] [config] optimizer-params:
[2023-07-01 11:48:15] [config]   - 0.9
[2023-07-01 11:48:15] [config]   - 0.98
[2023-07-01 11:48:15] [config]   - 1e-09
[2023-07-01 11:48:15] [config] output-omit-bias: false
[2023-07-01 11:48:15] [config] overwrite: true
[2023-07-01 11:48:15] [config] precision:
[2023-07-01 11:48:15] [config]   - float32
[2023-07-01 11:48:15] [config]   - float32
[2023-07-01 11:48:15] [config] pretrained-model: ""
[2023-07-01 11:48:15] [config] quantize-biases: false
[2023-07-01 11:48:15] [config] quantize-bits: 0
[2023-07-01 11:48:15] [config] quantize-log-based: false
[2023-07-01 11:48:15] [config] quantize-optimization-steps: 0
[2023-07-01 11:48:15] [config] quiet: false
[2023-07-01 11:48:15] [config] quiet-translation: true
[2023-07-01 11:48:15] [config] relative-paths: false
[2023-07-01 11:48:15] [config] right-left: false
[2023-07-01 11:48:15] [config] save-freq: 10000u
[2023-07-01 11:48:15] [config] seed: 1234
[2023-07-01 11:48:15] [config] sentencepiece-alphas:
[2023-07-01 11:48:15] [config]   []
[2023-07-01 11:48:15] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:48:15] [config] sentencepiece-options: ""
[2023-07-01 11:48:15] [config] sharding: global
[2023-07-01 11:48:15] [config] shuffle: data
[2023-07-01 11:48:15] [config] shuffle-in-ram: false
[2023-07-01 11:48:15] [config] sigterm: save-and-exit
[2023-07-01 11:48:15] [config] skip: false
[2023-07-01 11:48:15] [config] sqlite: ""
[2023-07-01 11:48:15] [config] sqlite-drop: false
[2023-07-01 11:48:15] [config] sync-freq: 200u
[2023-07-01 11:48:15] [config] sync-sgd: true
[2023-07-01 11:48:15] [config] tempdir: /tmp
[2023-07-01 11:48:15] [config] tied-embeddings: false
[2023-07-01 11:48:15] [config] tied-embeddings-all: true
[2023-07-01 11:48:15] [config] tied-embeddings-src: false
[2023-07-01 11:48:15] [config] train-embedder-rank:
[2023-07-01 11:48:15] [config]   []
[2023-07-01 11:48:15] [config] train-sets:
[2023-07-01 11:48:15] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:48:15] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:48:15] [config] transformer-aan-activation: swish
[2023-07-01 11:48:15] [config] transformer-aan-depth: 2
[2023-07-01 11:48:15] [config] transformer-aan-nogate: false
[2023-07-01 11:48:15] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:48:15] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:48:15] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:48:15] [config] transformer-depth-scaling: false
[2023-07-01 11:48:15] [config] transformer-dim-aan: 2048
[2023-07-01 11:48:15] [config] transformer-dim-ffn: 2048
[2023-07-01 11:48:15] [config] transformer-dropout: 0.1
[2023-07-01 11:48:15] [config] transformer-dropout-attention: 0
[2023-07-01 11:48:15] [config] transformer-dropout-ffn: 0
[2023-07-01 11:48:15] [config] transformer-ffn-activation: swish
[2023-07-01 11:48:15] [config] transformer-ffn-depth: 2
[2023-07-01 11:48:15] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:48:15] [config] transformer-heads: 8
[2023-07-01 11:48:15] [config] transformer-no-projection: false
[2023-07-01 11:48:15] [config] transformer-pool: false
[2023-07-01 11:48:15] [config] transformer-postprocess: dan
[2023-07-01 11:48:15] [config] transformer-postprocess-emb: d
[2023-07-01 11:48:15] [config] transformer-postprocess-top: ""
[2023-07-01 11:48:15] [config] transformer-preprocess: ""
[2023-07-01 11:48:15] [config] transformer-tied-layers:
[2023-07-01 11:48:15] [config]   []
[2023-07-01 11:48:15] [config] transformer-train-position-embeddings: false
[2023-07-01 11:48:15] [config] tsv: false
[2023-07-01 11:48:15] [config] tsv-fields: 0
[2023-07-01 11:48:15] [config] type: transformer
[2023-07-01 11:48:15] [config] ulr: false
[2023-07-01 11:48:15] [config] ulr-dim-emb: 0
[2023-07-01 11:48:15] [config] ulr-dropout: 0
[2023-07-01 11:48:15] [config] ulr-keys-vectors: ""
[2023-07-01 11:48:15] [config] ulr-query-vectors: ""
[2023-07-01 11:48:15] [config] ulr-softmax-temperature: 1
[2023-07-01 11:48:15] [config] ulr-trainable-transformation: false
[2023-07-01 11:48:15] [config] unlikelihood-loss: false
[2023-07-01 11:48:15] [config] valid-freq: 50000000
[2023-07-01 11:48:15] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:48:15] [config] valid-max-length: 1000
[2023-07-01 11:48:15] [config] valid-metrics:
[2023-07-01 11:48:15] [config]   - cross-entropy
[2023-07-01 11:48:15] [config]   - translation
[2023-07-01 11:48:15] [config] valid-mini-batch: 64
[2023-07-01 11:48:15] [config] valid-reset-stalled: false
[2023-07-01 11:48:15] [config] valid-script-args:
[2023-07-01 11:48:15] [config]   []
[2023-07-01 11:48:15] [config] valid-script-path: ""
[2023-07-01 11:48:15] [config] valid-sets:
[2023-07-01 11:48:15] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:48:15] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:48:15] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:48:15] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:48:15] [config] vocabs:
[2023-07-01 11:48:15] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:48:15] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:48:15] [config] word-penalty: 0
[2023-07-01 11:48:15] [config] word-scores: false
[2023-07-01 11:48:15] [config] workspace: 2048
[2023-07-01 11:48:15] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:48:15] Using synchronous SGD
[2023-07-01 11:48:15] Synced seed 1234
[2023-07-01 11:48:15] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:48:15] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:48:15] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:48:15] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:48:15] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:48:15] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:48:16] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:48:16] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:48:16] [comm] Using global sharding
[2023-07-01 11:48:16] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:48:16] [training] Using 1 GPUs
[2023-07-01 11:48:16] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:48:16] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:48:16] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:48:16] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:48:24] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:48:24] [valid] No post-processing script given for validating translator
[2023-07-01 11:48:24] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:48:24] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:48:24] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:48:24] [comm] Using global sharding
[2023-07-01 11:48:24] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:48:24] [training] Using 1 GPUs
[2023-07-01 11:48:24] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:48:24] Allocating memory for general optimizer shards
[2023-07-01 11:48:24] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:48:24] Loading Adam parameters
[2023-07-01 11:48:24] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:48:25] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:48:25] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:48:25] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:48:25] [data] Shuffling data
[2023-07-01 11:48:25] [data] Done reading 20,192 sentences
[2023-07-01 11:48:25] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:48:25] Training started
[2023-07-01 11:48:25] Training finished
[2023-07-01 11:48:28] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:48:28] [marian] Running on node20.datos.cluster.uy as process 21703 with command line:
[2023-07-01 11:48:28] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 175 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:48:28] [config] after: 0e
[2023-07-01 11:48:28] [config] after-batches: 0
[2023-07-01 11:48:28] [config] after-epochs: 175
[2023-07-01 11:48:28] [config] all-caps-every: 0
[2023-07-01 11:48:28] [config] allow-unk: false
[2023-07-01 11:48:28] [config] authors: false
[2023-07-01 11:48:28] [config] beam-size: 12
[2023-07-01 11:48:28] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:48:28] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:48:28] [config] bert-masking-fraction: 0.15
[2023-07-01 11:48:28] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:48:28] [config] bert-train-type-embeddings: true
[2023-07-01 11:48:28] [config] bert-type-vocab-size: 2
[2023-07-01 11:48:28] [config] build-info: ""
[2023-07-01 11:48:28] [config] check-gradient-nan: false
[2023-07-01 11:48:28] [config] check-nan: false
[2023-07-01 11:48:28] [config] cite: false
[2023-07-01 11:48:28] [config] clip-norm: 5
[2023-07-01 11:48:28] [config] cost-scaling:
[2023-07-01 11:48:28] [config]   []
[2023-07-01 11:48:28] [config] cost-type: ce-sum
[2023-07-01 11:48:28] [config] cpu-threads: 0
[2023-07-01 11:48:28] [config] data-threads: 8
[2023-07-01 11:48:28] [config] data-weighting: ""
[2023-07-01 11:48:28] [config] data-weighting-type: sentence
[2023-07-01 11:48:28] [config] dec-cell: gru
[2023-07-01 11:48:28] [config] dec-cell-base-depth: 2
[2023-07-01 11:48:28] [config] dec-cell-high-depth: 1
[2023-07-01 11:48:28] [config] dec-depth: 2
[2023-07-01 11:48:28] [config] devices:
[2023-07-01 11:48:28] [config]   - 0
[2023-07-01 11:48:28] [config] dim-emb: 512
[2023-07-01 11:48:28] [config] dim-rnn: 1024
[2023-07-01 11:48:28] [config] dim-vocabs:
[2023-07-01 11:48:28] [config]   - 16384
[2023-07-01 11:48:28] [config]   - 16384
[2023-07-01 11:48:28] [config] disp-first: 0
[2023-07-01 11:48:28] [config] disp-freq: 1000u
[2023-07-01 11:48:28] [config] disp-label-counts: true
[2023-07-01 11:48:28] [config] dropout-rnn: 0
[2023-07-01 11:48:28] [config] dropout-src: 0
[2023-07-01 11:48:28] [config] dropout-trg: 0
[2023-07-01 11:48:28] [config] dump-config: ""
[2023-07-01 11:48:28] [config] dynamic-gradient-scaling:
[2023-07-01 11:48:28] [config]   []
[2023-07-01 11:48:28] [config] early-stopping: 10
[2023-07-01 11:48:28] [config] early-stopping-on: first
[2023-07-01 11:48:28] [config] embedding-fix-src: false
[2023-07-01 11:48:28] [config] embedding-fix-trg: false
[2023-07-01 11:48:28] [config] embedding-normalization: false
[2023-07-01 11:48:28] [config] embedding-vectors:
[2023-07-01 11:48:28] [config]   []
[2023-07-01 11:48:28] [config] enc-cell: gru
[2023-07-01 11:48:28] [config] enc-cell-depth: 1
[2023-07-01 11:48:28] [config] enc-depth: 2
[2023-07-01 11:48:28] [config] enc-type: bidirectional
[2023-07-01 11:48:28] [config] english-title-case-every: 0
[2023-07-01 11:48:28] [config] exponential-smoothing: 0.0001
[2023-07-01 11:48:28] [config] factor-weight: 1
[2023-07-01 11:48:28] [config] factors-combine: sum
[2023-07-01 11:48:28] [config] factors-dim-emb: 0
[2023-07-01 11:48:28] [config] gradient-checkpointing: false
[2023-07-01 11:48:28] [config] gradient-norm-average-window: 100
[2023-07-01 11:48:28] [config] guided-alignment: none
[2023-07-01 11:48:28] [config] guided-alignment-cost: mse
[2023-07-01 11:48:28] [config] guided-alignment-weight: 0.1
[2023-07-01 11:48:28] [config] ignore-model-config: false
[2023-07-01 11:48:28] [config] input-types:
[2023-07-01 11:48:28] [config]   []
[2023-07-01 11:48:28] [config] interpolate-env-vars: false
[2023-07-01 11:48:28] [config] keep-best: false
[2023-07-01 11:48:28] [config] label-smoothing: 0.1
[2023-07-01 11:48:28] [config] layer-normalization: false
[2023-07-01 11:48:28] [config] learn-rate: 0.0003
[2023-07-01 11:48:28] [config] lemma-dependency: ""
[2023-07-01 11:48:28] [config] lemma-dim-emb: 0
[2023-07-01 11:48:28] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:48:28] [config] log-level: info
[2023-07-01 11:48:28] [config] log-time-zone: ""
[2023-07-01 11:48:28] [config] logical-epoch:
[2023-07-01 11:48:28] [config]   - 1e
[2023-07-01 11:48:28] [config]   - 0
[2023-07-01 11:48:28] [config] lr-decay: 0
[2023-07-01 11:48:28] [config] lr-decay-freq: 50000
[2023-07-01 11:48:28] [config] lr-decay-inv-sqrt:
[2023-07-01 11:48:28] [config]   - 16000
[2023-07-01 11:48:28] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:48:28] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:48:28] [config] lr-decay-start:
[2023-07-01 11:48:28] [config]   - 10
[2023-07-01 11:48:28] [config]   - 1
[2023-07-01 11:48:28] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:48:28] [config] lr-report: true
[2023-07-01 11:48:28] [config] lr-warmup: 16000
[2023-07-01 11:48:28] [config] lr-warmup-at-reload: false
[2023-07-01 11:48:28] [config] lr-warmup-cycle: false
[2023-07-01 11:48:28] [config] lr-warmup-start-rate: 0
[2023-07-01 11:48:28] [config] max-length: 100
[2023-07-01 11:48:28] [config] max-length-crop: false
[2023-07-01 11:48:28] [config] max-length-factor: 3
[2023-07-01 11:48:28] [config] maxi-batch: 100
[2023-07-01 11:48:28] [config] maxi-batch-sort: trg
[2023-07-01 11:48:28] [config] mini-batch: 1000
[2023-07-01 11:48:28] [config] mini-batch-fit: true
[2023-07-01 11:48:28] [config] mini-batch-fit-step: 10
[2023-07-01 11:48:28] [config] mini-batch-round-up: true
[2023-07-01 11:48:28] [config] mini-batch-track-lr: false
[2023-07-01 11:48:28] [config] mini-batch-warmup: 0
[2023-07-01 11:48:28] [config] mini-batch-words: 0
[2023-07-01 11:48:28] [config] mini-batch-words-ref: 0
[2023-07-01 11:48:28] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:48:28] [config] multi-loss-type: sum
[2023-07-01 11:48:28] [config] n-best: false
[2023-07-01 11:48:28] [config] no-nccl: false
[2023-07-01 11:48:28] [config] no-reload: false
[2023-07-01 11:48:28] [config] no-restore-corpus: false
[2023-07-01 11:48:28] [config] normalize: 1
[2023-07-01 11:48:28] [config] normalize-gradient: false
[2023-07-01 11:48:28] [config] num-devices: 0
[2023-07-01 11:48:28] [config] optimizer: adam
[2023-07-01 11:48:28] [config] optimizer-delay: 1
[2023-07-01 11:48:28] [config] optimizer-params:
[2023-07-01 11:48:28] [config]   - 0.9
[2023-07-01 11:48:28] [config]   - 0.98
[2023-07-01 11:48:28] [config]   - 1e-09
[2023-07-01 11:48:28] [config] output-omit-bias: false
[2023-07-01 11:48:28] [config] overwrite: true
[2023-07-01 11:48:28] [config] precision:
[2023-07-01 11:48:28] [config]   - float32
[2023-07-01 11:48:28] [config]   - float32
[2023-07-01 11:48:28] [config] pretrained-model: ""
[2023-07-01 11:48:28] [config] quantize-biases: false
[2023-07-01 11:48:28] [config] quantize-bits: 0
[2023-07-01 11:48:28] [config] quantize-log-based: false
[2023-07-01 11:48:28] [config] quantize-optimization-steps: 0
[2023-07-01 11:48:28] [config] quiet: false
[2023-07-01 11:48:28] [config] quiet-translation: true
[2023-07-01 11:48:28] [config] relative-paths: false
[2023-07-01 11:48:28] [config] right-left: false
[2023-07-01 11:48:28] [config] save-freq: 10000u
[2023-07-01 11:48:28] [config] seed: 1234
[2023-07-01 11:48:28] [config] sentencepiece-alphas:
[2023-07-01 11:48:28] [config]   []
[2023-07-01 11:48:28] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:48:28] [config] sentencepiece-options: ""
[2023-07-01 11:48:28] [config] sharding: global
[2023-07-01 11:48:28] [config] shuffle: data
[2023-07-01 11:48:28] [config] shuffle-in-ram: false
[2023-07-01 11:48:28] [config] sigterm: save-and-exit
[2023-07-01 11:48:28] [config] skip: false
[2023-07-01 11:48:28] [config] sqlite: ""
[2023-07-01 11:48:28] [config] sqlite-drop: false
[2023-07-01 11:48:28] [config] sync-freq: 200u
[2023-07-01 11:48:28] [config] sync-sgd: true
[2023-07-01 11:48:28] [config] tempdir: /tmp
[2023-07-01 11:48:28] [config] tied-embeddings: false
[2023-07-01 11:48:28] [config] tied-embeddings-all: true
[2023-07-01 11:48:28] [config] tied-embeddings-src: false
[2023-07-01 11:48:28] [config] train-embedder-rank:
[2023-07-01 11:48:28] [config]   []
[2023-07-01 11:48:28] [config] train-sets:
[2023-07-01 11:48:28] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:48:28] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:48:28] [config] transformer-aan-activation: swish
[2023-07-01 11:48:28] [config] transformer-aan-depth: 2
[2023-07-01 11:48:28] [config] transformer-aan-nogate: false
[2023-07-01 11:48:28] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:48:28] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:48:28] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:48:28] [config] transformer-depth-scaling: false
[2023-07-01 11:48:28] [config] transformer-dim-aan: 2048
[2023-07-01 11:48:28] [config] transformer-dim-ffn: 2048
[2023-07-01 11:48:28] [config] transformer-dropout: 0.1
[2023-07-01 11:48:28] [config] transformer-dropout-attention: 0
[2023-07-01 11:48:28] [config] transformer-dropout-ffn: 0
[2023-07-01 11:48:28] [config] transformer-ffn-activation: swish
[2023-07-01 11:48:28] [config] transformer-ffn-depth: 2
[2023-07-01 11:48:28] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:48:28] [config] transformer-heads: 8
[2023-07-01 11:48:28] [config] transformer-no-projection: false
[2023-07-01 11:48:28] [config] transformer-pool: false
[2023-07-01 11:48:28] [config] transformer-postprocess: dan
[2023-07-01 11:48:28] [config] transformer-postprocess-emb: d
[2023-07-01 11:48:28] [config] transformer-postprocess-top: ""
[2023-07-01 11:48:28] [config] transformer-preprocess: ""
[2023-07-01 11:48:28] [config] transformer-tied-layers:
[2023-07-01 11:48:28] [config]   []
[2023-07-01 11:48:28] [config] transformer-train-position-embeddings: false
[2023-07-01 11:48:28] [config] tsv: false
[2023-07-01 11:48:28] [config] tsv-fields: 0
[2023-07-01 11:48:28] [config] type: transformer
[2023-07-01 11:48:28] [config] ulr: false
[2023-07-01 11:48:28] [config] ulr-dim-emb: 0
[2023-07-01 11:48:28] [config] ulr-dropout: 0
[2023-07-01 11:48:28] [config] ulr-keys-vectors: ""
[2023-07-01 11:48:28] [config] ulr-query-vectors: ""
[2023-07-01 11:48:28] [config] ulr-softmax-temperature: 1
[2023-07-01 11:48:28] [config] ulr-trainable-transformation: false
[2023-07-01 11:48:28] [config] unlikelihood-loss: false
[2023-07-01 11:48:28] [config] valid-freq: 50000000
[2023-07-01 11:48:28] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:48:28] [config] valid-max-length: 1000
[2023-07-01 11:48:28] [config] valid-metrics:
[2023-07-01 11:48:28] [config]   - cross-entropy
[2023-07-01 11:48:28] [config]   - translation
[2023-07-01 11:48:28] [config] valid-mini-batch: 64
[2023-07-01 11:48:28] [config] valid-reset-stalled: false
[2023-07-01 11:48:28] [config] valid-script-args:
[2023-07-01 11:48:28] [config]   []
[2023-07-01 11:48:28] [config] valid-script-path: ""
[2023-07-01 11:48:28] [config] valid-sets:
[2023-07-01 11:48:28] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:48:28] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:48:28] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:48:28] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:48:28] [config] vocabs:
[2023-07-01 11:48:28] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:48:28] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:48:28] [config] word-penalty: 0
[2023-07-01 11:48:28] [config] word-scores: false
[2023-07-01 11:48:28] [config] workspace: 2048
[2023-07-01 11:48:28] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:48:28] Using synchronous SGD
[2023-07-01 11:48:28] Synced seed 1234
[2023-07-01 11:48:28] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:48:28] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:48:28] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:48:28] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:48:28] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:48:28] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:48:29] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:48:29] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:48:29] [comm] Using global sharding
[2023-07-01 11:48:29] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:48:29] [training] Using 1 GPUs
[2023-07-01 11:48:29] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:48:29] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:48:30] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:48:30] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:48:37] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:48:37] [valid] No post-processing script given for validating translator
[2023-07-01 11:48:37] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:48:37] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:48:37] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:48:37] [comm] Using global sharding
[2023-07-01 11:48:37] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:48:37] [training] Using 1 GPUs
[2023-07-01 11:48:37] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:48:38] Allocating memory for general optimizer shards
[2023-07-01 11:48:38] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:48:38] Loading Adam parameters
[2023-07-01 11:48:38] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:48:38] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:48:38] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:48:38] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:48:38] [data] Shuffling data
[2023-07-01 11:48:38] [data] Done reading 20,192 sentences
[2023-07-01 11:48:38] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:48:38] Training started
[2023-07-01 11:48:38] Training finished
[2023-07-01 11:48:42] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:48:42] [marian] Running on node20.datos.cluster.uy as process 21765 with command line:
[2023-07-01 11:48:42] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 176 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:48:42] [config] after: 0e
[2023-07-01 11:48:42] [config] after-batches: 0
[2023-07-01 11:48:42] [config] after-epochs: 176
[2023-07-01 11:48:42] [config] all-caps-every: 0
[2023-07-01 11:48:42] [config] allow-unk: false
[2023-07-01 11:48:42] [config] authors: false
[2023-07-01 11:48:42] [config] beam-size: 12
[2023-07-01 11:48:42] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:48:42] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:48:42] [config] bert-masking-fraction: 0.15
[2023-07-01 11:48:42] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:48:42] [config] bert-train-type-embeddings: true
[2023-07-01 11:48:42] [config] bert-type-vocab-size: 2
[2023-07-01 11:48:42] [config] build-info: ""
[2023-07-01 11:48:42] [config] check-gradient-nan: false
[2023-07-01 11:48:42] [config] check-nan: false
[2023-07-01 11:48:42] [config] cite: false
[2023-07-01 11:48:42] [config] clip-norm: 5
[2023-07-01 11:48:42] [config] cost-scaling:
[2023-07-01 11:48:42] [config]   []
[2023-07-01 11:48:42] [config] cost-type: ce-sum
[2023-07-01 11:48:42] [config] cpu-threads: 0
[2023-07-01 11:48:42] [config] data-threads: 8
[2023-07-01 11:48:42] [config] data-weighting: ""
[2023-07-01 11:48:42] [config] data-weighting-type: sentence
[2023-07-01 11:48:42] [config] dec-cell: gru
[2023-07-01 11:48:42] [config] dec-cell-base-depth: 2
[2023-07-01 11:48:42] [config] dec-cell-high-depth: 1
[2023-07-01 11:48:42] [config] dec-depth: 2
[2023-07-01 11:48:42] [config] devices:
[2023-07-01 11:48:42] [config]   - 0
[2023-07-01 11:48:42] [config] dim-emb: 512
[2023-07-01 11:48:42] [config] dim-rnn: 1024
[2023-07-01 11:48:42] [config] dim-vocabs:
[2023-07-01 11:48:42] [config]   - 16384
[2023-07-01 11:48:42] [config]   - 16384
[2023-07-01 11:48:42] [config] disp-first: 0
[2023-07-01 11:48:42] [config] disp-freq: 1000u
[2023-07-01 11:48:42] [config] disp-label-counts: true
[2023-07-01 11:48:42] [config] dropout-rnn: 0
[2023-07-01 11:48:42] [config] dropout-src: 0
[2023-07-01 11:48:42] [config] dropout-trg: 0
[2023-07-01 11:48:42] [config] dump-config: ""
[2023-07-01 11:48:42] [config] dynamic-gradient-scaling:
[2023-07-01 11:48:42] [config]   []
[2023-07-01 11:48:42] [config] early-stopping: 10
[2023-07-01 11:48:42] [config] early-stopping-on: first
[2023-07-01 11:48:42] [config] embedding-fix-src: false
[2023-07-01 11:48:42] [config] embedding-fix-trg: false
[2023-07-01 11:48:42] [config] embedding-normalization: false
[2023-07-01 11:48:42] [config] embedding-vectors:
[2023-07-01 11:48:42] [config]   []
[2023-07-01 11:48:42] [config] enc-cell: gru
[2023-07-01 11:48:42] [config] enc-cell-depth: 1
[2023-07-01 11:48:42] [config] enc-depth: 2
[2023-07-01 11:48:42] [config] enc-type: bidirectional
[2023-07-01 11:48:42] [config] english-title-case-every: 0
[2023-07-01 11:48:42] [config] exponential-smoothing: 0.0001
[2023-07-01 11:48:42] [config] factor-weight: 1
[2023-07-01 11:48:42] [config] factors-combine: sum
[2023-07-01 11:48:42] [config] factors-dim-emb: 0
[2023-07-01 11:48:42] [config] gradient-checkpointing: false
[2023-07-01 11:48:42] [config] gradient-norm-average-window: 100
[2023-07-01 11:48:42] [config] guided-alignment: none
[2023-07-01 11:48:42] [config] guided-alignment-cost: mse
[2023-07-01 11:48:42] [config] guided-alignment-weight: 0.1
[2023-07-01 11:48:42] [config] ignore-model-config: false
[2023-07-01 11:48:42] [config] input-types:
[2023-07-01 11:48:42] [config]   []
[2023-07-01 11:48:42] [config] interpolate-env-vars: false
[2023-07-01 11:48:42] [config] keep-best: false
[2023-07-01 11:48:42] [config] label-smoothing: 0.1
[2023-07-01 11:48:42] [config] layer-normalization: false
[2023-07-01 11:48:42] [config] learn-rate: 0.0003
[2023-07-01 11:48:42] [config] lemma-dependency: ""
[2023-07-01 11:48:42] [config] lemma-dim-emb: 0
[2023-07-01 11:48:42] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:48:42] [config] log-level: info
[2023-07-01 11:48:42] [config] log-time-zone: ""
[2023-07-01 11:48:42] [config] logical-epoch:
[2023-07-01 11:48:42] [config]   - 1e
[2023-07-01 11:48:42] [config]   - 0
[2023-07-01 11:48:42] [config] lr-decay: 0
[2023-07-01 11:48:42] [config] lr-decay-freq: 50000
[2023-07-01 11:48:42] [config] lr-decay-inv-sqrt:
[2023-07-01 11:48:42] [config]   - 16000
[2023-07-01 11:48:42] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:48:42] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:48:42] [config] lr-decay-start:
[2023-07-01 11:48:42] [config]   - 10
[2023-07-01 11:48:42] [config]   - 1
[2023-07-01 11:48:42] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:48:42] [config] lr-report: true
[2023-07-01 11:48:42] [config] lr-warmup: 16000
[2023-07-01 11:48:42] [config] lr-warmup-at-reload: false
[2023-07-01 11:48:42] [config] lr-warmup-cycle: false
[2023-07-01 11:48:42] [config] lr-warmup-start-rate: 0
[2023-07-01 11:48:42] [config] max-length: 100
[2023-07-01 11:48:42] [config] max-length-crop: false
[2023-07-01 11:48:42] [config] max-length-factor: 3
[2023-07-01 11:48:42] [config] maxi-batch: 100
[2023-07-01 11:48:42] [config] maxi-batch-sort: trg
[2023-07-01 11:48:42] [config] mini-batch: 1000
[2023-07-01 11:48:42] [config] mini-batch-fit: true
[2023-07-01 11:48:42] [config] mini-batch-fit-step: 10
[2023-07-01 11:48:42] [config] mini-batch-round-up: true
[2023-07-01 11:48:42] [config] mini-batch-track-lr: false
[2023-07-01 11:48:42] [config] mini-batch-warmup: 0
[2023-07-01 11:48:42] [config] mini-batch-words: 0
[2023-07-01 11:48:42] [config] mini-batch-words-ref: 0
[2023-07-01 11:48:42] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:48:42] [config] multi-loss-type: sum
[2023-07-01 11:48:42] [config] n-best: false
[2023-07-01 11:48:42] [config] no-nccl: false
[2023-07-01 11:48:42] [config] no-reload: false
[2023-07-01 11:48:42] [config] no-restore-corpus: false
[2023-07-01 11:48:42] [config] normalize: 1
[2023-07-01 11:48:42] [config] normalize-gradient: false
[2023-07-01 11:48:42] [config] num-devices: 0
[2023-07-01 11:48:42] [config] optimizer: adam
[2023-07-01 11:48:42] [config] optimizer-delay: 1
[2023-07-01 11:48:42] [config] optimizer-params:
[2023-07-01 11:48:42] [config]   - 0.9
[2023-07-01 11:48:42] [config]   - 0.98
[2023-07-01 11:48:42] [config]   - 1e-09
[2023-07-01 11:48:42] [config] output-omit-bias: false
[2023-07-01 11:48:42] [config] overwrite: true
[2023-07-01 11:48:42] [config] precision:
[2023-07-01 11:48:42] [config]   - float32
[2023-07-01 11:48:42] [config]   - float32
[2023-07-01 11:48:42] [config] pretrained-model: ""
[2023-07-01 11:48:42] [config] quantize-biases: false
[2023-07-01 11:48:42] [config] quantize-bits: 0
[2023-07-01 11:48:42] [config] quantize-log-based: false
[2023-07-01 11:48:42] [config] quantize-optimization-steps: 0
[2023-07-01 11:48:42] [config] quiet: false
[2023-07-01 11:48:42] [config] quiet-translation: true
[2023-07-01 11:48:42] [config] relative-paths: false
[2023-07-01 11:48:42] [config] right-left: false
[2023-07-01 11:48:42] [config] save-freq: 10000u
[2023-07-01 11:48:42] [config] seed: 1234
[2023-07-01 11:48:42] [config] sentencepiece-alphas:
[2023-07-01 11:48:42] [config]   []
[2023-07-01 11:48:42] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:48:42] [config] sentencepiece-options: ""
[2023-07-01 11:48:42] [config] sharding: global
[2023-07-01 11:48:42] [config] shuffle: data
[2023-07-01 11:48:42] [config] shuffle-in-ram: false
[2023-07-01 11:48:42] [config] sigterm: save-and-exit
[2023-07-01 11:48:42] [config] skip: false
[2023-07-01 11:48:42] [config] sqlite: ""
[2023-07-01 11:48:42] [config] sqlite-drop: false
[2023-07-01 11:48:42] [config] sync-freq: 200u
[2023-07-01 11:48:42] [config] sync-sgd: true
[2023-07-01 11:48:42] [config] tempdir: /tmp
[2023-07-01 11:48:42] [config] tied-embeddings: false
[2023-07-01 11:48:42] [config] tied-embeddings-all: true
[2023-07-01 11:48:42] [config] tied-embeddings-src: false
[2023-07-01 11:48:42] [config] train-embedder-rank:
[2023-07-01 11:48:42] [config]   []
[2023-07-01 11:48:42] [config] train-sets:
[2023-07-01 11:48:42] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:48:42] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:48:42] [config] transformer-aan-activation: swish
[2023-07-01 11:48:42] [config] transformer-aan-depth: 2
[2023-07-01 11:48:42] [config] transformer-aan-nogate: false
[2023-07-01 11:48:42] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:48:42] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:48:42] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:48:42] [config] transformer-depth-scaling: false
[2023-07-01 11:48:42] [config] transformer-dim-aan: 2048
[2023-07-01 11:48:42] [config] transformer-dim-ffn: 2048
[2023-07-01 11:48:42] [config] transformer-dropout: 0.1
[2023-07-01 11:48:42] [config] transformer-dropout-attention: 0
[2023-07-01 11:48:42] [config] transformer-dropout-ffn: 0
[2023-07-01 11:48:42] [config] transformer-ffn-activation: swish
[2023-07-01 11:48:42] [config] transformer-ffn-depth: 2
[2023-07-01 11:48:42] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:48:42] [config] transformer-heads: 8
[2023-07-01 11:48:42] [config] transformer-no-projection: false
[2023-07-01 11:48:42] [config] transformer-pool: false
[2023-07-01 11:48:42] [config] transformer-postprocess: dan
[2023-07-01 11:48:42] [config] transformer-postprocess-emb: d
[2023-07-01 11:48:42] [config] transformer-postprocess-top: ""
[2023-07-01 11:48:42] [config] transformer-preprocess: ""
[2023-07-01 11:48:42] [config] transformer-tied-layers:
[2023-07-01 11:48:42] [config]   []
[2023-07-01 11:48:42] [config] transformer-train-position-embeddings: false
[2023-07-01 11:48:42] [config] tsv: false
[2023-07-01 11:48:42] [config] tsv-fields: 0
[2023-07-01 11:48:42] [config] type: transformer
[2023-07-01 11:48:42] [config] ulr: false
[2023-07-01 11:48:42] [config] ulr-dim-emb: 0
[2023-07-01 11:48:42] [config] ulr-dropout: 0
[2023-07-01 11:48:42] [config] ulr-keys-vectors: ""
[2023-07-01 11:48:42] [config] ulr-query-vectors: ""
[2023-07-01 11:48:42] [config] ulr-softmax-temperature: 1
[2023-07-01 11:48:42] [config] ulr-trainable-transformation: false
[2023-07-01 11:48:42] [config] unlikelihood-loss: false
[2023-07-01 11:48:42] [config] valid-freq: 50000000
[2023-07-01 11:48:42] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:48:42] [config] valid-max-length: 1000
[2023-07-01 11:48:42] [config] valid-metrics:
[2023-07-01 11:48:42] [config]   - cross-entropy
[2023-07-01 11:48:42] [config]   - translation
[2023-07-01 11:48:42] [config] valid-mini-batch: 64
[2023-07-01 11:48:42] [config] valid-reset-stalled: false
[2023-07-01 11:48:42] [config] valid-script-args:
[2023-07-01 11:48:42] [config]   []
[2023-07-01 11:48:42] [config] valid-script-path: ""
[2023-07-01 11:48:42] [config] valid-sets:
[2023-07-01 11:48:42] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:48:42] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:48:42] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:48:42] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:48:42] [config] vocabs:
[2023-07-01 11:48:42] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:48:42] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:48:42] [config] word-penalty: 0
[2023-07-01 11:48:42] [config] word-scores: false
[2023-07-01 11:48:42] [config] workspace: 2048
[2023-07-01 11:48:42] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:48:42] Using synchronous SGD
[2023-07-01 11:48:42] Synced seed 1234
[2023-07-01 11:48:42] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:48:42] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:48:42] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:48:42] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:48:42] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:48:42] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:48:43] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:48:43] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:48:43] [comm] Using global sharding
[2023-07-01 11:48:43] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:48:43] [training] Using 1 GPUs
[2023-07-01 11:48:43] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:48:43] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:48:43] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:48:43] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:48:51] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:48:51] [valid] No post-processing script given for validating translator
[2023-07-01 11:48:51] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:48:51] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:48:51] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:48:51] [comm] Using global sharding
[2023-07-01 11:48:51] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:48:51] [training] Using 1 GPUs
[2023-07-01 11:48:51] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:48:51] Allocating memory for general optimizer shards
[2023-07-01 11:48:51] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:48:51] Loading Adam parameters
[2023-07-01 11:48:51] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:48:51] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:48:52] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:48:52] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:48:52] [data] Shuffling data
[2023-07-01 11:48:52] [data] Done reading 20,192 sentences
[2023-07-01 11:48:52] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:48:52] Training started
[2023-07-01 11:48:52] Training finished
[2023-07-01 11:48:55] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:48:55] [marian] Running on node20.datos.cluster.uy as process 21824 with command line:
[2023-07-01 11:48:55] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 177 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:48:55] [config] after: 0e
[2023-07-01 11:48:55] [config] after-batches: 0
[2023-07-01 11:48:55] [config] after-epochs: 177
[2023-07-01 11:48:55] [config] all-caps-every: 0
[2023-07-01 11:48:55] [config] allow-unk: false
[2023-07-01 11:48:55] [config] authors: false
[2023-07-01 11:48:55] [config] beam-size: 12
[2023-07-01 11:48:55] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:48:55] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:48:55] [config] bert-masking-fraction: 0.15
[2023-07-01 11:48:55] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:48:55] [config] bert-train-type-embeddings: true
[2023-07-01 11:48:55] [config] bert-type-vocab-size: 2
[2023-07-01 11:48:55] [config] build-info: ""
[2023-07-01 11:48:55] [config] check-gradient-nan: false
[2023-07-01 11:48:55] [config] check-nan: false
[2023-07-01 11:48:55] [config] cite: false
[2023-07-01 11:48:55] [config] clip-norm: 5
[2023-07-01 11:48:55] [config] cost-scaling:
[2023-07-01 11:48:55] [config]   []
[2023-07-01 11:48:55] [config] cost-type: ce-sum
[2023-07-01 11:48:55] [config] cpu-threads: 0
[2023-07-01 11:48:55] [config] data-threads: 8
[2023-07-01 11:48:55] [config] data-weighting: ""
[2023-07-01 11:48:55] [config] data-weighting-type: sentence
[2023-07-01 11:48:55] [config] dec-cell: gru
[2023-07-01 11:48:55] [config] dec-cell-base-depth: 2
[2023-07-01 11:48:55] [config] dec-cell-high-depth: 1
[2023-07-01 11:48:55] [config] dec-depth: 2
[2023-07-01 11:48:55] [config] devices:
[2023-07-01 11:48:55] [config]   - 0
[2023-07-01 11:48:55] [config] dim-emb: 512
[2023-07-01 11:48:55] [config] dim-rnn: 1024
[2023-07-01 11:48:55] [config] dim-vocabs:
[2023-07-01 11:48:55] [config]   - 16384
[2023-07-01 11:48:55] [config]   - 16384
[2023-07-01 11:48:55] [config] disp-first: 0
[2023-07-01 11:48:55] [config] disp-freq: 1000u
[2023-07-01 11:48:55] [config] disp-label-counts: true
[2023-07-01 11:48:55] [config] dropout-rnn: 0
[2023-07-01 11:48:55] [config] dropout-src: 0
[2023-07-01 11:48:55] [config] dropout-trg: 0
[2023-07-01 11:48:55] [config] dump-config: ""
[2023-07-01 11:48:55] [config] dynamic-gradient-scaling:
[2023-07-01 11:48:55] [config]   []
[2023-07-01 11:48:55] [config] early-stopping: 10
[2023-07-01 11:48:55] [config] early-stopping-on: first
[2023-07-01 11:48:55] [config] embedding-fix-src: false
[2023-07-01 11:48:55] [config] embedding-fix-trg: false
[2023-07-01 11:48:55] [config] embedding-normalization: false
[2023-07-01 11:48:55] [config] embedding-vectors:
[2023-07-01 11:48:55] [config]   []
[2023-07-01 11:48:55] [config] enc-cell: gru
[2023-07-01 11:48:55] [config] enc-cell-depth: 1
[2023-07-01 11:48:55] [config] enc-depth: 2
[2023-07-01 11:48:55] [config] enc-type: bidirectional
[2023-07-01 11:48:55] [config] english-title-case-every: 0
[2023-07-01 11:48:55] [config] exponential-smoothing: 0.0001
[2023-07-01 11:48:55] [config] factor-weight: 1
[2023-07-01 11:48:55] [config] factors-combine: sum
[2023-07-01 11:48:55] [config] factors-dim-emb: 0
[2023-07-01 11:48:55] [config] gradient-checkpointing: false
[2023-07-01 11:48:55] [config] gradient-norm-average-window: 100
[2023-07-01 11:48:55] [config] guided-alignment: none
[2023-07-01 11:48:55] [config] guided-alignment-cost: mse
[2023-07-01 11:48:55] [config] guided-alignment-weight: 0.1
[2023-07-01 11:48:55] [config] ignore-model-config: false
[2023-07-01 11:48:55] [config] input-types:
[2023-07-01 11:48:55] [config]   []
[2023-07-01 11:48:55] [config] interpolate-env-vars: false
[2023-07-01 11:48:55] [config] keep-best: false
[2023-07-01 11:48:55] [config] label-smoothing: 0.1
[2023-07-01 11:48:55] [config] layer-normalization: false
[2023-07-01 11:48:55] [config] learn-rate: 0.0003
[2023-07-01 11:48:55] [config] lemma-dependency: ""
[2023-07-01 11:48:55] [config] lemma-dim-emb: 0
[2023-07-01 11:48:55] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:48:55] [config] log-level: info
[2023-07-01 11:48:55] [config] log-time-zone: ""
[2023-07-01 11:48:55] [config] logical-epoch:
[2023-07-01 11:48:55] [config]   - 1e
[2023-07-01 11:48:55] [config]   - 0
[2023-07-01 11:48:55] [config] lr-decay: 0
[2023-07-01 11:48:55] [config] lr-decay-freq: 50000
[2023-07-01 11:48:55] [config] lr-decay-inv-sqrt:
[2023-07-01 11:48:55] [config]   - 16000
[2023-07-01 11:48:55] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:48:55] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:48:55] [config] lr-decay-start:
[2023-07-01 11:48:55] [config]   - 10
[2023-07-01 11:48:55] [config]   - 1
[2023-07-01 11:48:55] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:48:55] [config] lr-report: true
[2023-07-01 11:48:55] [config] lr-warmup: 16000
[2023-07-01 11:48:55] [config] lr-warmup-at-reload: false
[2023-07-01 11:48:55] [config] lr-warmup-cycle: false
[2023-07-01 11:48:55] [config] lr-warmup-start-rate: 0
[2023-07-01 11:48:55] [config] max-length: 100
[2023-07-01 11:48:55] [config] max-length-crop: false
[2023-07-01 11:48:55] [config] max-length-factor: 3
[2023-07-01 11:48:55] [config] maxi-batch: 100
[2023-07-01 11:48:55] [config] maxi-batch-sort: trg
[2023-07-01 11:48:55] [config] mini-batch: 1000
[2023-07-01 11:48:55] [config] mini-batch-fit: true
[2023-07-01 11:48:55] [config] mini-batch-fit-step: 10
[2023-07-01 11:48:55] [config] mini-batch-round-up: true
[2023-07-01 11:48:55] [config] mini-batch-track-lr: false
[2023-07-01 11:48:55] [config] mini-batch-warmup: 0
[2023-07-01 11:48:55] [config] mini-batch-words: 0
[2023-07-01 11:48:55] [config] mini-batch-words-ref: 0
[2023-07-01 11:48:55] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:48:55] [config] multi-loss-type: sum
[2023-07-01 11:48:55] [config] n-best: false
[2023-07-01 11:48:55] [config] no-nccl: false
[2023-07-01 11:48:55] [config] no-reload: false
[2023-07-01 11:48:55] [config] no-restore-corpus: false
[2023-07-01 11:48:55] [config] normalize: 1
[2023-07-01 11:48:55] [config] normalize-gradient: false
[2023-07-01 11:48:55] [config] num-devices: 0
[2023-07-01 11:48:55] [config] optimizer: adam
[2023-07-01 11:48:55] [config] optimizer-delay: 1
[2023-07-01 11:48:55] [config] optimizer-params:
[2023-07-01 11:48:55] [config]   - 0.9
[2023-07-01 11:48:55] [config]   - 0.98
[2023-07-01 11:48:55] [config]   - 1e-09
[2023-07-01 11:48:55] [config] output-omit-bias: false
[2023-07-01 11:48:55] [config] overwrite: true
[2023-07-01 11:48:55] [config] precision:
[2023-07-01 11:48:55] [config]   - float32
[2023-07-01 11:48:55] [config]   - float32
[2023-07-01 11:48:55] [config] pretrained-model: ""
[2023-07-01 11:48:55] [config] quantize-biases: false
[2023-07-01 11:48:55] [config] quantize-bits: 0
[2023-07-01 11:48:55] [config] quantize-log-based: false
[2023-07-01 11:48:55] [config] quantize-optimization-steps: 0
[2023-07-01 11:48:55] [config] quiet: false
[2023-07-01 11:48:55] [config] quiet-translation: true
[2023-07-01 11:48:55] [config] relative-paths: false
[2023-07-01 11:48:55] [config] right-left: false
[2023-07-01 11:48:55] [config] save-freq: 10000u
[2023-07-01 11:48:55] [config] seed: 1234
[2023-07-01 11:48:55] [config] sentencepiece-alphas:
[2023-07-01 11:48:55] [config]   []
[2023-07-01 11:48:55] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:48:55] [config] sentencepiece-options: ""
[2023-07-01 11:48:55] [config] sharding: global
[2023-07-01 11:48:55] [config] shuffle: data
[2023-07-01 11:48:55] [config] shuffle-in-ram: false
[2023-07-01 11:48:55] [config] sigterm: save-and-exit
[2023-07-01 11:48:55] [config] skip: false
[2023-07-01 11:48:55] [config] sqlite: ""
[2023-07-01 11:48:55] [config] sqlite-drop: false
[2023-07-01 11:48:55] [config] sync-freq: 200u
[2023-07-01 11:48:55] [config] sync-sgd: true
[2023-07-01 11:48:55] [config] tempdir: /tmp
[2023-07-01 11:48:55] [config] tied-embeddings: false
[2023-07-01 11:48:55] [config] tied-embeddings-all: true
[2023-07-01 11:48:55] [config] tied-embeddings-src: false
[2023-07-01 11:48:55] [config] train-embedder-rank:
[2023-07-01 11:48:55] [config]   []
[2023-07-01 11:48:55] [config] train-sets:
[2023-07-01 11:48:55] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:48:55] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:48:55] [config] transformer-aan-activation: swish
[2023-07-01 11:48:55] [config] transformer-aan-depth: 2
[2023-07-01 11:48:55] [config] transformer-aan-nogate: false
[2023-07-01 11:48:55] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:48:55] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:48:55] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:48:55] [config] transformer-depth-scaling: false
[2023-07-01 11:48:55] [config] transformer-dim-aan: 2048
[2023-07-01 11:48:55] [config] transformer-dim-ffn: 2048
[2023-07-01 11:48:55] [config] transformer-dropout: 0.1
[2023-07-01 11:48:55] [config] transformer-dropout-attention: 0
[2023-07-01 11:48:55] [config] transformer-dropout-ffn: 0
[2023-07-01 11:48:55] [config] transformer-ffn-activation: swish
[2023-07-01 11:48:55] [config] transformer-ffn-depth: 2
[2023-07-01 11:48:55] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:48:55] [config] transformer-heads: 8
[2023-07-01 11:48:55] [config] transformer-no-projection: false
[2023-07-01 11:48:55] [config] transformer-pool: false
[2023-07-01 11:48:55] [config] transformer-postprocess: dan
[2023-07-01 11:48:55] [config] transformer-postprocess-emb: d
[2023-07-01 11:48:55] [config] transformer-postprocess-top: ""
[2023-07-01 11:48:55] [config] transformer-preprocess: ""
[2023-07-01 11:48:55] [config] transformer-tied-layers:
[2023-07-01 11:48:55] [config]   []
[2023-07-01 11:48:55] [config] transformer-train-position-embeddings: false
[2023-07-01 11:48:55] [config] tsv: false
[2023-07-01 11:48:55] [config] tsv-fields: 0
[2023-07-01 11:48:55] [config] type: transformer
[2023-07-01 11:48:55] [config] ulr: false
[2023-07-01 11:48:55] [config] ulr-dim-emb: 0
[2023-07-01 11:48:55] [config] ulr-dropout: 0
[2023-07-01 11:48:55] [config] ulr-keys-vectors: ""
[2023-07-01 11:48:55] [config] ulr-query-vectors: ""
[2023-07-01 11:48:55] [config] ulr-softmax-temperature: 1
[2023-07-01 11:48:55] [config] ulr-trainable-transformation: false
[2023-07-01 11:48:55] [config] unlikelihood-loss: false
[2023-07-01 11:48:55] [config] valid-freq: 50000000
[2023-07-01 11:48:55] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:48:55] [config] valid-max-length: 1000
[2023-07-01 11:48:55] [config] valid-metrics:
[2023-07-01 11:48:55] [config]   - cross-entropy
[2023-07-01 11:48:55] [config]   - translation
[2023-07-01 11:48:55] [config] valid-mini-batch: 64
[2023-07-01 11:48:55] [config] valid-reset-stalled: false
[2023-07-01 11:48:55] [config] valid-script-args:
[2023-07-01 11:48:55] [config]   []
[2023-07-01 11:48:55] [config] valid-script-path: ""
[2023-07-01 11:48:55] [config] valid-sets:
[2023-07-01 11:48:55] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:48:55] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:48:55] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:48:55] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:48:55] [config] vocabs:
[2023-07-01 11:48:55] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:48:55] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:48:55] [config] word-penalty: 0
[2023-07-01 11:48:55] [config] word-scores: false
[2023-07-01 11:48:55] [config] workspace: 2048
[2023-07-01 11:48:55] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:48:55] Using synchronous SGD
[2023-07-01 11:48:55] Synced seed 1234
[2023-07-01 11:48:55] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:48:55] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:48:55] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:48:56] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:48:56] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:48:56] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:48:56] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:48:56] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:48:56] [comm] Using global sharding
[2023-07-01 11:48:56] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:48:56] [training] Using 1 GPUs
[2023-07-01 11:48:56] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:48:56] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:48:57] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:48:57] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:49:04] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:49:04] [valid] No post-processing script given for validating translator
[2023-07-01 11:49:04] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:49:04] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:49:04] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:49:04] [comm] Using global sharding
[2023-07-01 11:49:04] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:49:04] [training] Using 1 GPUs
[2023-07-01 11:49:04] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:49:05] Allocating memory for general optimizer shards
[2023-07-01 11:49:05] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:49:05] Loading Adam parameters
[2023-07-01 11:49:05] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:49:05] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:49:05] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:49:05] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:49:05] [data] Shuffling data
[2023-07-01 11:49:05] [data] Done reading 20,192 sentences
[2023-07-01 11:49:05] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:49:05] Training started
[2023-07-01 11:49:05] Training finished
[2023-07-01 11:49:08] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:49:08] [marian] Running on node20.datos.cluster.uy as process 21883 with command line:
[2023-07-01 11:49:08] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 178 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:49:08] [config] after: 0e
[2023-07-01 11:49:08] [config] after-batches: 0
[2023-07-01 11:49:08] [config] after-epochs: 178
[2023-07-01 11:49:08] [config] all-caps-every: 0
[2023-07-01 11:49:08] [config] allow-unk: false
[2023-07-01 11:49:08] [config] authors: false
[2023-07-01 11:49:08] [config] beam-size: 12
[2023-07-01 11:49:08] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:49:08] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:49:08] [config] bert-masking-fraction: 0.15
[2023-07-01 11:49:08] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:49:08] [config] bert-train-type-embeddings: true
[2023-07-01 11:49:08] [config] bert-type-vocab-size: 2
[2023-07-01 11:49:08] [config] build-info: ""
[2023-07-01 11:49:08] [config] check-gradient-nan: false
[2023-07-01 11:49:08] [config] check-nan: false
[2023-07-01 11:49:08] [config] cite: false
[2023-07-01 11:49:08] [config] clip-norm: 5
[2023-07-01 11:49:08] [config] cost-scaling:
[2023-07-01 11:49:08] [config]   []
[2023-07-01 11:49:08] [config] cost-type: ce-sum
[2023-07-01 11:49:08] [config] cpu-threads: 0
[2023-07-01 11:49:08] [config] data-threads: 8
[2023-07-01 11:49:08] [config] data-weighting: ""
[2023-07-01 11:49:08] [config] data-weighting-type: sentence
[2023-07-01 11:49:08] [config] dec-cell: gru
[2023-07-01 11:49:08] [config] dec-cell-base-depth: 2
[2023-07-01 11:49:08] [config] dec-cell-high-depth: 1
[2023-07-01 11:49:08] [config] dec-depth: 2
[2023-07-01 11:49:08] [config] devices:
[2023-07-01 11:49:08] [config]   - 0
[2023-07-01 11:49:08] [config] dim-emb: 512
[2023-07-01 11:49:08] [config] dim-rnn: 1024
[2023-07-01 11:49:08] [config] dim-vocabs:
[2023-07-01 11:49:08] [config]   - 16384
[2023-07-01 11:49:08] [config]   - 16384
[2023-07-01 11:49:08] [config] disp-first: 0
[2023-07-01 11:49:08] [config] disp-freq: 1000u
[2023-07-01 11:49:08] [config] disp-label-counts: true
[2023-07-01 11:49:08] [config] dropout-rnn: 0
[2023-07-01 11:49:08] [config] dropout-src: 0
[2023-07-01 11:49:08] [config] dropout-trg: 0
[2023-07-01 11:49:08] [config] dump-config: ""
[2023-07-01 11:49:08] [config] dynamic-gradient-scaling:
[2023-07-01 11:49:08] [config]   []
[2023-07-01 11:49:08] [config] early-stopping: 10
[2023-07-01 11:49:08] [config] early-stopping-on: first
[2023-07-01 11:49:08] [config] embedding-fix-src: false
[2023-07-01 11:49:08] [config] embedding-fix-trg: false
[2023-07-01 11:49:08] [config] embedding-normalization: false
[2023-07-01 11:49:08] [config] embedding-vectors:
[2023-07-01 11:49:08] [config]   []
[2023-07-01 11:49:08] [config] enc-cell: gru
[2023-07-01 11:49:08] [config] enc-cell-depth: 1
[2023-07-01 11:49:08] [config] enc-depth: 2
[2023-07-01 11:49:08] [config] enc-type: bidirectional
[2023-07-01 11:49:08] [config] english-title-case-every: 0
[2023-07-01 11:49:08] [config] exponential-smoothing: 0.0001
[2023-07-01 11:49:08] [config] factor-weight: 1
[2023-07-01 11:49:08] [config] factors-combine: sum
[2023-07-01 11:49:08] [config] factors-dim-emb: 0
[2023-07-01 11:49:08] [config] gradient-checkpointing: false
[2023-07-01 11:49:08] [config] gradient-norm-average-window: 100
[2023-07-01 11:49:08] [config] guided-alignment: none
[2023-07-01 11:49:08] [config] guided-alignment-cost: mse
[2023-07-01 11:49:08] [config] guided-alignment-weight: 0.1
[2023-07-01 11:49:08] [config] ignore-model-config: false
[2023-07-01 11:49:08] [config] input-types:
[2023-07-01 11:49:08] [config]   []
[2023-07-01 11:49:08] [config] interpolate-env-vars: false
[2023-07-01 11:49:08] [config] keep-best: false
[2023-07-01 11:49:08] [config] label-smoothing: 0.1
[2023-07-01 11:49:08] [config] layer-normalization: false
[2023-07-01 11:49:08] [config] learn-rate: 0.0003
[2023-07-01 11:49:08] [config] lemma-dependency: ""
[2023-07-01 11:49:08] [config] lemma-dim-emb: 0
[2023-07-01 11:49:08] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:49:08] [config] log-level: info
[2023-07-01 11:49:08] [config] log-time-zone: ""
[2023-07-01 11:49:08] [config] logical-epoch:
[2023-07-01 11:49:08] [config]   - 1e
[2023-07-01 11:49:08] [config]   - 0
[2023-07-01 11:49:08] [config] lr-decay: 0
[2023-07-01 11:49:08] [config] lr-decay-freq: 50000
[2023-07-01 11:49:08] [config] lr-decay-inv-sqrt:
[2023-07-01 11:49:08] [config]   - 16000
[2023-07-01 11:49:08] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:49:08] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:49:08] [config] lr-decay-start:
[2023-07-01 11:49:08] [config]   - 10
[2023-07-01 11:49:08] [config]   - 1
[2023-07-01 11:49:08] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:49:08] [config] lr-report: true
[2023-07-01 11:49:08] [config] lr-warmup: 16000
[2023-07-01 11:49:08] [config] lr-warmup-at-reload: false
[2023-07-01 11:49:08] [config] lr-warmup-cycle: false
[2023-07-01 11:49:08] [config] lr-warmup-start-rate: 0
[2023-07-01 11:49:08] [config] max-length: 100
[2023-07-01 11:49:08] [config] max-length-crop: false
[2023-07-01 11:49:08] [config] max-length-factor: 3
[2023-07-01 11:49:08] [config] maxi-batch: 100
[2023-07-01 11:49:08] [config] maxi-batch-sort: trg
[2023-07-01 11:49:08] [config] mini-batch: 1000
[2023-07-01 11:49:08] [config] mini-batch-fit: true
[2023-07-01 11:49:08] [config] mini-batch-fit-step: 10
[2023-07-01 11:49:08] [config] mini-batch-round-up: true
[2023-07-01 11:49:08] [config] mini-batch-track-lr: false
[2023-07-01 11:49:08] [config] mini-batch-warmup: 0
[2023-07-01 11:49:08] [config] mini-batch-words: 0
[2023-07-01 11:49:08] [config] mini-batch-words-ref: 0
[2023-07-01 11:49:08] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:49:08] [config] multi-loss-type: sum
[2023-07-01 11:49:08] [config] n-best: false
[2023-07-01 11:49:08] [config] no-nccl: false
[2023-07-01 11:49:08] [config] no-reload: false
[2023-07-01 11:49:08] [config] no-restore-corpus: false
[2023-07-01 11:49:08] [config] normalize: 1
[2023-07-01 11:49:08] [config] normalize-gradient: false
[2023-07-01 11:49:08] [config] num-devices: 0
[2023-07-01 11:49:08] [config] optimizer: adam
[2023-07-01 11:49:08] [config] optimizer-delay: 1
[2023-07-01 11:49:08] [config] optimizer-params:
[2023-07-01 11:49:08] [config]   - 0.9
[2023-07-01 11:49:08] [config]   - 0.98
[2023-07-01 11:49:08] [config]   - 1e-09
[2023-07-01 11:49:08] [config] output-omit-bias: false
[2023-07-01 11:49:08] [config] overwrite: true
[2023-07-01 11:49:08] [config] precision:
[2023-07-01 11:49:08] [config]   - float32
[2023-07-01 11:49:08] [config]   - float32
[2023-07-01 11:49:08] [config] pretrained-model: ""
[2023-07-01 11:49:08] [config] quantize-biases: false
[2023-07-01 11:49:08] [config] quantize-bits: 0
[2023-07-01 11:49:08] [config] quantize-log-based: false
[2023-07-01 11:49:08] [config] quantize-optimization-steps: 0
[2023-07-01 11:49:08] [config] quiet: false
[2023-07-01 11:49:08] [config] quiet-translation: true
[2023-07-01 11:49:08] [config] relative-paths: false
[2023-07-01 11:49:08] [config] right-left: false
[2023-07-01 11:49:08] [config] save-freq: 10000u
[2023-07-01 11:49:08] [config] seed: 1234
[2023-07-01 11:49:08] [config] sentencepiece-alphas:
[2023-07-01 11:49:08] [config]   []
[2023-07-01 11:49:08] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:49:08] [config] sentencepiece-options: ""
[2023-07-01 11:49:08] [config] sharding: global
[2023-07-01 11:49:08] [config] shuffle: data
[2023-07-01 11:49:08] [config] shuffle-in-ram: false
[2023-07-01 11:49:08] [config] sigterm: save-and-exit
[2023-07-01 11:49:08] [config] skip: false
[2023-07-01 11:49:08] [config] sqlite: ""
[2023-07-01 11:49:08] [config] sqlite-drop: false
[2023-07-01 11:49:08] [config] sync-freq: 200u
[2023-07-01 11:49:08] [config] sync-sgd: true
[2023-07-01 11:49:08] [config] tempdir: /tmp
[2023-07-01 11:49:08] [config] tied-embeddings: false
[2023-07-01 11:49:08] [config] tied-embeddings-all: true
[2023-07-01 11:49:08] [config] tied-embeddings-src: false
[2023-07-01 11:49:08] [config] train-embedder-rank:
[2023-07-01 11:49:08] [config]   []
[2023-07-01 11:49:08] [config] train-sets:
[2023-07-01 11:49:08] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:49:08] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:49:08] [config] transformer-aan-activation: swish
[2023-07-01 11:49:08] [config] transformer-aan-depth: 2
[2023-07-01 11:49:08] [config] transformer-aan-nogate: false
[2023-07-01 11:49:08] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:49:08] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:49:08] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:49:08] [config] transformer-depth-scaling: false
[2023-07-01 11:49:08] [config] transformer-dim-aan: 2048
[2023-07-01 11:49:08] [config] transformer-dim-ffn: 2048
[2023-07-01 11:49:08] [config] transformer-dropout: 0.1
[2023-07-01 11:49:08] [config] transformer-dropout-attention: 0
[2023-07-01 11:49:08] [config] transformer-dropout-ffn: 0
[2023-07-01 11:49:08] [config] transformer-ffn-activation: swish
[2023-07-01 11:49:08] [config] transformer-ffn-depth: 2
[2023-07-01 11:49:08] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:49:08] [config] transformer-heads: 8
[2023-07-01 11:49:08] [config] transformer-no-projection: false
[2023-07-01 11:49:08] [config] transformer-pool: false
[2023-07-01 11:49:08] [config] transformer-postprocess: dan
[2023-07-01 11:49:08] [config] transformer-postprocess-emb: d
[2023-07-01 11:49:08] [config] transformer-postprocess-top: ""
[2023-07-01 11:49:08] [config] transformer-preprocess: ""
[2023-07-01 11:49:08] [config] transformer-tied-layers:
[2023-07-01 11:49:08] [config]   []
[2023-07-01 11:49:08] [config] transformer-train-position-embeddings: false
[2023-07-01 11:49:08] [config] tsv: false
[2023-07-01 11:49:08] [config] tsv-fields: 0
[2023-07-01 11:49:08] [config] type: transformer
[2023-07-01 11:49:08] [config] ulr: false
[2023-07-01 11:49:08] [config] ulr-dim-emb: 0
[2023-07-01 11:49:08] [config] ulr-dropout: 0
[2023-07-01 11:49:08] [config] ulr-keys-vectors: ""
[2023-07-01 11:49:08] [config] ulr-query-vectors: ""
[2023-07-01 11:49:08] [config] ulr-softmax-temperature: 1
[2023-07-01 11:49:08] [config] ulr-trainable-transformation: false
[2023-07-01 11:49:08] [config] unlikelihood-loss: false
[2023-07-01 11:49:08] [config] valid-freq: 50000000
[2023-07-01 11:49:08] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:49:08] [config] valid-max-length: 1000
[2023-07-01 11:49:08] [config] valid-metrics:
[2023-07-01 11:49:08] [config]   - cross-entropy
[2023-07-01 11:49:08] [config]   - translation
[2023-07-01 11:49:08] [config] valid-mini-batch: 64
[2023-07-01 11:49:08] [config] valid-reset-stalled: false
[2023-07-01 11:49:08] [config] valid-script-args:
[2023-07-01 11:49:08] [config]   []
[2023-07-01 11:49:08] [config] valid-script-path: ""
[2023-07-01 11:49:08] [config] valid-sets:
[2023-07-01 11:49:08] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:49:08] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:49:08] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:49:08] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:49:08] [config] vocabs:
[2023-07-01 11:49:08] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:49:08] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:49:08] [config] word-penalty: 0
[2023-07-01 11:49:08] [config] word-scores: false
[2023-07-01 11:49:08] [config] workspace: 2048
[2023-07-01 11:49:08] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:49:08] Using synchronous SGD
[2023-07-01 11:49:09] Synced seed 1234
[2023-07-01 11:49:09] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:49:09] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:49:09] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:49:09] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:49:09] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:49:09] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:49:10] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:49:10] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:49:10] [comm] Using global sharding
[2023-07-01 11:49:10] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:49:10] [training] Using 1 GPUs
[2023-07-01 11:49:10] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:49:10] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:49:10] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:49:10] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:49:17] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:49:18] [valid] No post-processing script given for validating translator
[2023-07-01 11:49:18] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:49:18] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:49:18] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:49:18] [comm] Using global sharding
[2023-07-01 11:49:18] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:49:18] [training] Using 1 GPUs
[2023-07-01 11:49:18] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:49:18] Allocating memory for general optimizer shards
[2023-07-01 11:49:18] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:49:18] Loading Adam parameters
[2023-07-01 11:49:18] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:49:18] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:49:18] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:49:18] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:49:18] [data] Shuffling data
[2023-07-01 11:49:18] [data] Done reading 20,192 sentences
[2023-07-01 11:49:18] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:49:18] Training started
[2023-07-01 11:49:18] Training finished
[2023-07-01 11:49:22] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:49:22] [marian] Running on node20.datos.cluster.uy as process 21940 with command line:
[2023-07-01 11:49:22] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 179 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:49:22] [config] after: 0e
[2023-07-01 11:49:22] [config] after-batches: 0
[2023-07-01 11:49:22] [config] after-epochs: 179
[2023-07-01 11:49:22] [config] all-caps-every: 0
[2023-07-01 11:49:22] [config] allow-unk: false
[2023-07-01 11:49:22] [config] authors: false
[2023-07-01 11:49:22] [config] beam-size: 12
[2023-07-01 11:49:22] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:49:22] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:49:22] [config] bert-masking-fraction: 0.15
[2023-07-01 11:49:22] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:49:22] [config] bert-train-type-embeddings: true
[2023-07-01 11:49:22] [config] bert-type-vocab-size: 2
[2023-07-01 11:49:22] [config] build-info: ""
[2023-07-01 11:49:22] [config] check-gradient-nan: false
[2023-07-01 11:49:22] [config] check-nan: false
[2023-07-01 11:49:22] [config] cite: false
[2023-07-01 11:49:22] [config] clip-norm: 5
[2023-07-01 11:49:22] [config] cost-scaling:
[2023-07-01 11:49:22] [config]   []
[2023-07-01 11:49:22] [config] cost-type: ce-sum
[2023-07-01 11:49:22] [config] cpu-threads: 0
[2023-07-01 11:49:22] [config] data-threads: 8
[2023-07-01 11:49:22] [config] data-weighting: ""
[2023-07-01 11:49:22] [config] data-weighting-type: sentence
[2023-07-01 11:49:22] [config] dec-cell: gru
[2023-07-01 11:49:22] [config] dec-cell-base-depth: 2
[2023-07-01 11:49:22] [config] dec-cell-high-depth: 1
[2023-07-01 11:49:22] [config] dec-depth: 2
[2023-07-01 11:49:22] [config] devices:
[2023-07-01 11:49:22] [config]   - 0
[2023-07-01 11:49:22] [config] dim-emb: 512
[2023-07-01 11:49:22] [config] dim-rnn: 1024
[2023-07-01 11:49:22] [config] dim-vocabs:
[2023-07-01 11:49:22] [config]   - 16384
[2023-07-01 11:49:22] [config]   - 16384
[2023-07-01 11:49:22] [config] disp-first: 0
[2023-07-01 11:49:22] [config] disp-freq: 1000u
[2023-07-01 11:49:22] [config] disp-label-counts: true
[2023-07-01 11:49:22] [config] dropout-rnn: 0
[2023-07-01 11:49:22] [config] dropout-src: 0
[2023-07-01 11:49:22] [config] dropout-trg: 0
[2023-07-01 11:49:22] [config] dump-config: ""
[2023-07-01 11:49:22] [config] dynamic-gradient-scaling:
[2023-07-01 11:49:22] [config]   []
[2023-07-01 11:49:22] [config] early-stopping: 10
[2023-07-01 11:49:22] [config] early-stopping-on: first
[2023-07-01 11:49:22] [config] embedding-fix-src: false
[2023-07-01 11:49:22] [config] embedding-fix-trg: false
[2023-07-01 11:49:22] [config] embedding-normalization: false
[2023-07-01 11:49:22] [config] embedding-vectors:
[2023-07-01 11:49:22] [config]   []
[2023-07-01 11:49:22] [config] enc-cell: gru
[2023-07-01 11:49:22] [config] enc-cell-depth: 1
[2023-07-01 11:49:22] [config] enc-depth: 2
[2023-07-01 11:49:22] [config] enc-type: bidirectional
[2023-07-01 11:49:22] [config] english-title-case-every: 0
[2023-07-01 11:49:22] [config] exponential-smoothing: 0.0001
[2023-07-01 11:49:22] [config] factor-weight: 1
[2023-07-01 11:49:22] [config] factors-combine: sum
[2023-07-01 11:49:22] [config] factors-dim-emb: 0
[2023-07-01 11:49:22] [config] gradient-checkpointing: false
[2023-07-01 11:49:22] [config] gradient-norm-average-window: 100
[2023-07-01 11:49:22] [config] guided-alignment: none
[2023-07-01 11:49:22] [config] guided-alignment-cost: mse
[2023-07-01 11:49:22] [config] guided-alignment-weight: 0.1
[2023-07-01 11:49:22] [config] ignore-model-config: false
[2023-07-01 11:49:22] [config] input-types:
[2023-07-01 11:49:22] [config]   []
[2023-07-01 11:49:22] [config] interpolate-env-vars: false
[2023-07-01 11:49:22] [config] keep-best: false
[2023-07-01 11:49:22] [config] label-smoothing: 0.1
[2023-07-01 11:49:22] [config] layer-normalization: false
[2023-07-01 11:49:22] [config] learn-rate: 0.0003
[2023-07-01 11:49:22] [config] lemma-dependency: ""
[2023-07-01 11:49:22] [config] lemma-dim-emb: 0
[2023-07-01 11:49:22] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:49:22] [config] log-level: info
[2023-07-01 11:49:22] [config] log-time-zone: ""
[2023-07-01 11:49:22] [config] logical-epoch:
[2023-07-01 11:49:22] [config]   - 1e
[2023-07-01 11:49:22] [config]   - 0
[2023-07-01 11:49:22] [config] lr-decay: 0
[2023-07-01 11:49:22] [config] lr-decay-freq: 50000
[2023-07-01 11:49:22] [config] lr-decay-inv-sqrt:
[2023-07-01 11:49:22] [config]   - 16000
[2023-07-01 11:49:22] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:49:22] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:49:22] [config] lr-decay-start:
[2023-07-01 11:49:22] [config]   - 10
[2023-07-01 11:49:22] [config]   - 1
[2023-07-01 11:49:22] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:49:22] [config] lr-report: true
[2023-07-01 11:49:22] [config] lr-warmup: 16000
[2023-07-01 11:49:22] [config] lr-warmup-at-reload: false
[2023-07-01 11:49:22] [config] lr-warmup-cycle: false
[2023-07-01 11:49:22] [config] lr-warmup-start-rate: 0
[2023-07-01 11:49:22] [config] max-length: 100
[2023-07-01 11:49:22] [config] max-length-crop: false
[2023-07-01 11:49:22] [config] max-length-factor: 3
[2023-07-01 11:49:22] [config] maxi-batch: 100
[2023-07-01 11:49:22] [config] maxi-batch-sort: trg
[2023-07-01 11:49:22] [config] mini-batch: 1000
[2023-07-01 11:49:22] [config] mini-batch-fit: true
[2023-07-01 11:49:22] [config] mini-batch-fit-step: 10
[2023-07-01 11:49:22] [config] mini-batch-round-up: true
[2023-07-01 11:49:22] [config] mini-batch-track-lr: false
[2023-07-01 11:49:22] [config] mini-batch-warmup: 0
[2023-07-01 11:49:22] [config] mini-batch-words: 0
[2023-07-01 11:49:22] [config] mini-batch-words-ref: 0
[2023-07-01 11:49:22] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:49:22] [config] multi-loss-type: sum
[2023-07-01 11:49:22] [config] n-best: false
[2023-07-01 11:49:22] [config] no-nccl: false
[2023-07-01 11:49:22] [config] no-reload: false
[2023-07-01 11:49:22] [config] no-restore-corpus: false
[2023-07-01 11:49:22] [config] normalize: 1
[2023-07-01 11:49:22] [config] normalize-gradient: false
[2023-07-01 11:49:22] [config] num-devices: 0
[2023-07-01 11:49:22] [config] optimizer: adam
[2023-07-01 11:49:22] [config] optimizer-delay: 1
[2023-07-01 11:49:22] [config] optimizer-params:
[2023-07-01 11:49:22] [config]   - 0.9
[2023-07-01 11:49:22] [config]   - 0.98
[2023-07-01 11:49:22] [config]   - 1e-09
[2023-07-01 11:49:22] [config] output-omit-bias: false
[2023-07-01 11:49:22] [config] overwrite: true
[2023-07-01 11:49:22] [config] precision:
[2023-07-01 11:49:22] [config]   - float32
[2023-07-01 11:49:22] [config]   - float32
[2023-07-01 11:49:22] [config] pretrained-model: ""
[2023-07-01 11:49:22] [config] quantize-biases: false
[2023-07-01 11:49:22] [config] quantize-bits: 0
[2023-07-01 11:49:22] [config] quantize-log-based: false
[2023-07-01 11:49:22] [config] quantize-optimization-steps: 0
[2023-07-01 11:49:22] [config] quiet: false
[2023-07-01 11:49:22] [config] quiet-translation: true
[2023-07-01 11:49:22] [config] relative-paths: false
[2023-07-01 11:49:22] [config] right-left: false
[2023-07-01 11:49:22] [config] save-freq: 10000u
[2023-07-01 11:49:22] [config] seed: 1234
[2023-07-01 11:49:22] [config] sentencepiece-alphas:
[2023-07-01 11:49:22] [config]   []
[2023-07-01 11:49:22] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:49:22] [config] sentencepiece-options: ""
[2023-07-01 11:49:22] [config] sharding: global
[2023-07-01 11:49:22] [config] shuffle: data
[2023-07-01 11:49:22] [config] shuffle-in-ram: false
[2023-07-01 11:49:22] [config] sigterm: save-and-exit
[2023-07-01 11:49:22] [config] skip: false
[2023-07-01 11:49:22] [config] sqlite: ""
[2023-07-01 11:49:22] [config] sqlite-drop: false
[2023-07-01 11:49:22] [config] sync-freq: 200u
[2023-07-01 11:49:22] [config] sync-sgd: true
[2023-07-01 11:49:22] [config] tempdir: /tmp
[2023-07-01 11:49:22] [config] tied-embeddings: false
[2023-07-01 11:49:22] [config] tied-embeddings-all: true
[2023-07-01 11:49:22] [config] tied-embeddings-src: false
[2023-07-01 11:49:22] [config] train-embedder-rank:
[2023-07-01 11:49:22] [config]   []
[2023-07-01 11:49:22] [config] train-sets:
[2023-07-01 11:49:22] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:49:22] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:49:22] [config] transformer-aan-activation: swish
[2023-07-01 11:49:22] [config] transformer-aan-depth: 2
[2023-07-01 11:49:22] [config] transformer-aan-nogate: false
[2023-07-01 11:49:22] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:49:22] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:49:22] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:49:22] [config] transformer-depth-scaling: false
[2023-07-01 11:49:22] [config] transformer-dim-aan: 2048
[2023-07-01 11:49:22] [config] transformer-dim-ffn: 2048
[2023-07-01 11:49:22] [config] transformer-dropout: 0.1
[2023-07-01 11:49:22] [config] transformer-dropout-attention: 0
[2023-07-01 11:49:22] [config] transformer-dropout-ffn: 0
[2023-07-01 11:49:22] [config] transformer-ffn-activation: swish
[2023-07-01 11:49:22] [config] transformer-ffn-depth: 2
[2023-07-01 11:49:22] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:49:22] [config] transformer-heads: 8
[2023-07-01 11:49:22] [config] transformer-no-projection: false
[2023-07-01 11:49:22] [config] transformer-pool: false
[2023-07-01 11:49:22] [config] transformer-postprocess: dan
[2023-07-01 11:49:22] [config] transformer-postprocess-emb: d
[2023-07-01 11:49:22] [config] transformer-postprocess-top: ""
[2023-07-01 11:49:22] [config] transformer-preprocess: ""
[2023-07-01 11:49:22] [config] transformer-tied-layers:
[2023-07-01 11:49:22] [config]   []
[2023-07-01 11:49:22] [config] transformer-train-position-embeddings: false
[2023-07-01 11:49:22] [config] tsv: false
[2023-07-01 11:49:22] [config] tsv-fields: 0
[2023-07-01 11:49:22] [config] type: transformer
[2023-07-01 11:49:22] [config] ulr: false
[2023-07-01 11:49:22] [config] ulr-dim-emb: 0
[2023-07-01 11:49:22] [config] ulr-dropout: 0
[2023-07-01 11:49:22] [config] ulr-keys-vectors: ""
[2023-07-01 11:49:22] [config] ulr-query-vectors: ""
[2023-07-01 11:49:22] [config] ulr-softmax-temperature: 1
[2023-07-01 11:49:22] [config] ulr-trainable-transformation: false
[2023-07-01 11:49:22] [config] unlikelihood-loss: false
[2023-07-01 11:49:22] [config] valid-freq: 50000000
[2023-07-01 11:49:22] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:49:22] [config] valid-max-length: 1000
[2023-07-01 11:49:22] [config] valid-metrics:
[2023-07-01 11:49:22] [config]   - cross-entropy
[2023-07-01 11:49:22] [config]   - translation
[2023-07-01 11:49:22] [config] valid-mini-batch: 64
[2023-07-01 11:49:22] [config] valid-reset-stalled: false
[2023-07-01 11:49:22] [config] valid-script-args:
[2023-07-01 11:49:22] [config]   []
[2023-07-01 11:49:22] [config] valid-script-path: ""
[2023-07-01 11:49:22] [config] valid-sets:
[2023-07-01 11:49:22] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:49:22] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:49:22] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:49:22] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:49:22] [config] vocabs:
[2023-07-01 11:49:22] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:49:22] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:49:22] [config] word-penalty: 0
[2023-07-01 11:49:22] [config] word-scores: false
[2023-07-01 11:49:22] [config] workspace: 2048
[2023-07-01 11:49:22] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:49:22] Using synchronous SGD
[2023-07-01 11:49:22] Synced seed 1234
[2023-07-01 11:49:22] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:49:22] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:49:22] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:49:22] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:49:22] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:49:22] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:49:23] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:49:23] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:49:23] [comm] Using global sharding
[2023-07-01 11:49:23] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:49:23] [training] Using 1 GPUs
[2023-07-01 11:49:23] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:49:23] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:49:24] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:49:24] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:49:31] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:49:31] [valid] No post-processing script given for validating translator
[2023-07-01 11:49:31] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:49:31] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:49:31] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:49:31] [comm] Using global sharding
[2023-07-01 11:49:31] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:49:31] [training] Using 1 GPUs
[2023-07-01 11:49:31] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:49:32] Allocating memory for general optimizer shards
[2023-07-01 11:49:32] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:49:32] Loading Adam parameters
[2023-07-01 11:49:32] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:49:32] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:49:32] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:49:32] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:49:32] [data] Shuffling data
[2023-07-01 11:49:32] [data] Done reading 20,192 sentences
[2023-07-01 11:49:32] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:49:32] Training started
[2023-07-01 11:49:32] Training finished
[2023-07-01 11:49:36] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:49:36] [marian] Running on node20.datos.cluster.uy as process 21998 with command line:
[2023-07-01 11:49:36] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 180 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:49:36] [config] after: 0e
[2023-07-01 11:49:36] [config] after-batches: 0
[2023-07-01 11:49:36] [config] after-epochs: 180
[2023-07-01 11:49:36] [config] all-caps-every: 0
[2023-07-01 11:49:36] [config] allow-unk: false
[2023-07-01 11:49:36] [config] authors: false
[2023-07-01 11:49:36] [config] beam-size: 12
[2023-07-01 11:49:36] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:49:36] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:49:36] [config] bert-masking-fraction: 0.15
[2023-07-01 11:49:36] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:49:36] [config] bert-train-type-embeddings: true
[2023-07-01 11:49:36] [config] bert-type-vocab-size: 2
[2023-07-01 11:49:36] [config] build-info: ""
[2023-07-01 11:49:36] [config] check-gradient-nan: false
[2023-07-01 11:49:36] [config] check-nan: false
[2023-07-01 11:49:36] [config] cite: false
[2023-07-01 11:49:36] [config] clip-norm: 5
[2023-07-01 11:49:36] [config] cost-scaling:
[2023-07-01 11:49:36] [config]   []
[2023-07-01 11:49:36] [config] cost-type: ce-sum
[2023-07-01 11:49:36] [config] cpu-threads: 0
[2023-07-01 11:49:36] [config] data-threads: 8
[2023-07-01 11:49:36] [config] data-weighting: ""
[2023-07-01 11:49:36] [config] data-weighting-type: sentence
[2023-07-01 11:49:36] [config] dec-cell: gru
[2023-07-01 11:49:36] [config] dec-cell-base-depth: 2
[2023-07-01 11:49:36] [config] dec-cell-high-depth: 1
[2023-07-01 11:49:36] [config] dec-depth: 2
[2023-07-01 11:49:36] [config] devices:
[2023-07-01 11:49:36] [config]   - 0
[2023-07-01 11:49:36] [config] dim-emb: 512
[2023-07-01 11:49:36] [config] dim-rnn: 1024
[2023-07-01 11:49:36] [config] dim-vocabs:
[2023-07-01 11:49:36] [config]   - 16384
[2023-07-01 11:49:36] [config]   - 16384
[2023-07-01 11:49:36] [config] disp-first: 0
[2023-07-01 11:49:36] [config] disp-freq: 1000u
[2023-07-01 11:49:36] [config] disp-label-counts: true
[2023-07-01 11:49:36] [config] dropout-rnn: 0
[2023-07-01 11:49:36] [config] dropout-src: 0
[2023-07-01 11:49:36] [config] dropout-trg: 0
[2023-07-01 11:49:36] [config] dump-config: ""
[2023-07-01 11:49:36] [config] dynamic-gradient-scaling:
[2023-07-01 11:49:36] [config]   []
[2023-07-01 11:49:36] [config] early-stopping: 10
[2023-07-01 11:49:36] [config] early-stopping-on: first
[2023-07-01 11:49:36] [config] embedding-fix-src: false
[2023-07-01 11:49:36] [config] embedding-fix-trg: false
[2023-07-01 11:49:36] [config] embedding-normalization: false
[2023-07-01 11:49:36] [config] embedding-vectors:
[2023-07-01 11:49:36] [config]   []
[2023-07-01 11:49:36] [config] enc-cell: gru
[2023-07-01 11:49:36] [config] enc-cell-depth: 1
[2023-07-01 11:49:36] [config] enc-depth: 2
[2023-07-01 11:49:36] [config] enc-type: bidirectional
[2023-07-01 11:49:36] [config] english-title-case-every: 0
[2023-07-01 11:49:36] [config] exponential-smoothing: 0.0001
[2023-07-01 11:49:36] [config] factor-weight: 1
[2023-07-01 11:49:36] [config] factors-combine: sum
[2023-07-01 11:49:36] [config] factors-dim-emb: 0
[2023-07-01 11:49:36] [config] gradient-checkpointing: false
[2023-07-01 11:49:36] [config] gradient-norm-average-window: 100
[2023-07-01 11:49:36] [config] guided-alignment: none
[2023-07-01 11:49:36] [config] guided-alignment-cost: mse
[2023-07-01 11:49:36] [config] guided-alignment-weight: 0.1
[2023-07-01 11:49:36] [config] ignore-model-config: false
[2023-07-01 11:49:36] [config] input-types:
[2023-07-01 11:49:36] [config]   []
[2023-07-01 11:49:36] [config] interpolate-env-vars: false
[2023-07-01 11:49:36] [config] keep-best: false
[2023-07-01 11:49:36] [config] label-smoothing: 0.1
[2023-07-01 11:49:36] [config] layer-normalization: false
[2023-07-01 11:49:36] [config] learn-rate: 0.0003
[2023-07-01 11:49:36] [config] lemma-dependency: ""
[2023-07-01 11:49:36] [config] lemma-dim-emb: 0
[2023-07-01 11:49:36] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:49:36] [config] log-level: info
[2023-07-01 11:49:36] [config] log-time-zone: ""
[2023-07-01 11:49:36] [config] logical-epoch:
[2023-07-01 11:49:36] [config]   - 1e
[2023-07-01 11:49:36] [config]   - 0
[2023-07-01 11:49:36] [config] lr-decay: 0
[2023-07-01 11:49:36] [config] lr-decay-freq: 50000
[2023-07-01 11:49:36] [config] lr-decay-inv-sqrt:
[2023-07-01 11:49:36] [config]   - 16000
[2023-07-01 11:49:36] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:49:36] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:49:36] [config] lr-decay-start:
[2023-07-01 11:49:36] [config]   - 10
[2023-07-01 11:49:36] [config]   - 1
[2023-07-01 11:49:36] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:49:36] [config] lr-report: true
[2023-07-01 11:49:36] [config] lr-warmup: 16000
[2023-07-01 11:49:36] [config] lr-warmup-at-reload: false
[2023-07-01 11:49:36] [config] lr-warmup-cycle: false
[2023-07-01 11:49:36] [config] lr-warmup-start-rate: 0
[2023-07-01 11:49:36] [config] max-length: 100
[2023-07-01 11:49:36] [config] max-length-crop: false
[2023-07-01 11:49:36] [config] max-length-factor: 3
[2023-07-01 11:49:36] [config] maxi-batch: 100
[2023-07-01 11:49:36] [config] maxi-batch-sort: trg
[2023-07-01 11:49:36] [config] mini-batch: 1000
[2023-07-01 11:49:36] [config] mini-batch-fit: true
[2023-07-01 11:49:36] [config] mini-batch-fit-step: 10
[2023-07-01 11:49:36] [config] mini-batch-round-up: true
[2023-07-01 11:49:36] [config] mini-batch-track-lr: false
[2023-07-01 11:49:36] [config] mini-batch-warmup: 0
[2023-07-01 11:49:36] [config] mini-batch-words: 0
[2023-07-01 11:49:36] [config] mini-batch-words-ref: 0
[2023-07-01 11:49:36] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:49:36] [config] multi-loss-type: sum
[2023-07-01 11:49:36] [config] n-best: false
[2023-07-01 11:49:36] [config] no-nccl: false
[2023-07-01 11:49:36] [config] no-reload: false
[2023-07-01 11:49:36] [config] no-restore-corpus: false
[2023-07-01 11:49:36] [config] normalize: 1
[2023-07-01 11:49:36] [config] normalize-gradient: false
[2023-07-01 11:49:36] [config] num-devices: 0
[2023-07-01 11:49:36] [config] optimizer: adam
[2023-07-01 11:49:36] [config] optimizer-delay: 1
[2023-07-01 11:49:36] [config] optimizer-params:
[2023-07-01 11:49:36] [config]   - 0.9
[2023-07-01 11:49:36] [config]   - 0.98
[2023-07-01 11:49:36] [config]   - 1e-09
[2023-07-01 11:49:36] [config] output-omit-bias: false
[2023-07-01 11:49:36] [config] overwrite: true
[2023-07-01 11:49:36] [config] precision:
[2023-07-01 11:49:36] [config]   - float32
[2023-07-01 11:49:36] [config]   - float32
[2023-07-01 11:49:36] [config] pretrained-model: ""
[2023-07-01 11:49:36] [config] quantize-biases: false
[2023-07-01 11:49:36] [config] quantize-bits: 0
[2023-07-01 11:49:36] [config] quantize-log-based: false
[2023-07-01 11:49:36] [config] quantize-optimization-steps: 0
[2023-07-01 11:49:36] [config] quiet: false
[2023-07-01 11:49:36] [config] quiet-translation: true
[2023-07-01 11:49:36] [config] relative-paths: false
[2023-07-01 11:49:36] [config] right-left: false
[2023-07-01 11:49:36] [config] save-freq: 10000u
[2023-07-01 11:49:36] [config] seed: 1234
[2023-07-01 11:49:36] [config] sentencepiece-alphas:
[2023-07-01 11:49:36] [config]   []
[2023-07-01 11:49:36] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:49:36] [config] sentencepiece-options: ""
[2023-07-01 11:49:36] [config] sharding: global
[2023-07-01 11:49:36] [config] shuffle: data
[2023-07-01 11:49:36] [config] shuffle-in-ram: false
[2023-07-01 11:49:36] [config] sigterm: save-and-exit
[2023-07-01 11:49:36] [config] skip: false
[2023-07-01 11:49:36] [config] sqlite: ""
[2023-07-01 11:49:36] [config] sqlite-drop: false
[2023-07-01 11:49:36] [config] sync-freq: 200u
[2023-07-01 11:49:36] [config] sync-sgd: true
[2023-07-01 11:49:36] [config] tempdir: /tmp
[2023-07-01 11:49:36] [config] tied-embeddings: false
[2023-07-01 11:49:36] [config] tied-embeddings-all: true
[2023-07-01 11:49:36] [config] tied-embeddings-src: false
[2023-07-01 11:49:36] [config] train-embedder-rank:
[2023-07-01 11:49:36] [config]   []
[2023-07-01 11:49:36] [config] train-sets:
[2023-07-01 11:49:36] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:49:36] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:49:36] [config] transformer-aan-activation: swish
[2023-07-01 11:49:36] [config] transformer-aan-depth: 2
[2023-07-01 11:49:36] [config] transformer-aan-nogate: false
[2023-07-01 11:49:36] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:49:36] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:49:36] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:49:36] [config] transformer-depth-scaling: false
[2023-07-01 11:49:36] [config] transformer-dim-aan: 2048
[2023-07-01 11:49:36] [config] transformer-dim-ffn: 2048
[2023-07-01 11:49:36] [config] transformer-dropout: 0.1
[2023-07-01 11:49:36] [config] transformer-dropout-attention: 0
[2023-07-01 11:49:36] [config] transformer-dropout-ffn: 0
[2023-07-01 11:49:36] [config] transformer-ffn-activation: swish
[2023-07-01 11:49:36] [config] transformer-ffn-depth: 2
[2023-07-01 11:49:36] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:49:36] [config] transformer-heads: 8
[2023-07-01 11:49:36] [config] transformer-no-projection: false
[2023-07-01 11:49:36] [config] transformer-pool: false
[2023-07-01 11:49:36] [config] transformer-postprocess: dan
[2023-07-01 11:49:36] [config] transformer-postprocess-emb: d
[2023-07-01 11:49:36] [config] transformer-postprocess-top: ""
[2023-07-01 11:49:36] [config] transformer-preprocess: ""
[2023-07-01 11:49:36] [config] transformer-tied-layers:
[2023-07-01 11:49:36] [config]   []
[2023-07-01 11:49:36] [config] transformer-train-position-embeddings: false
[2023-07-01 11:49:36] [config] tsv: false
[2023-07-01 11:49:36] [config] tsv-fields: 0
[2023-07-01 11:49:36] [config] type: transformer
[2023-07-01 11:49:36] [config] ulr: false
[2023-07-01 11:49:36] [config] ulr-dim-emb: 0
[2023-07-01 11:49:36] [config] ulr-dropout: 0
[2023-07-01 11:49:36] [config] ulr-keys-vectors: ""
[2023-07-01 11:49:36] [config] ulr-query-vectors: ""
[2023-07-01 11:49:36] [config] ulr-softmax-temperature: 1
[2023-07-01 11:49:36] [config] ulr-trainable-transformation: false
[2023-07-01 11:49:36] [config] unlikelihood-loss: false
[2023-07-01 11:49:36] [config] valid-freq: 50000000
[2023-07-01 11:49:36] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:49:36] [config] valid-max-length: 1000
[2023-07-01 11:49:36] [config] valid-metrics:
[2023-07-01 11:49:36] [config]   - cross-entropy
[2023-07-01 11:49:36] [config]   - translation
[2023-07-01 11:49:36] [config] valid-mini-batch: 64
[2023-07-01 11:49:36] [config] valid-reset-stalled: false
[2023-07-01 11:49:36] [config] valid-script-args:
[2023-07-01 11:49:36] [config]   []
[2023-07-01 11:49:36] [config] valid-script-path: ""
[2023-07-01 11:49:36] [config] valid-sets:
[2023-07-01 11:49:36] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:49:36] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:49:36] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:49:36] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:49:36] [config] vocabs:
[2023-07-01 11:49:36] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:49:36] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:49:36] [config] word-penalty: 0
[2023-07-01 11:49:36] [config] word-scores: false
[2023-07-01 11:49:36] [config] workspace: 2048
[2023-07-01 11:49:36] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:49:36] Using synchronous SGD
[2023-07-01 11:49:36] Synced seed 1234
[2023-07-01 11:49:36] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:49:36] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:49:36] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:49:36] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:49:36] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:49:36] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:49:37] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:49:37] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:49:37] [comm] Using global sharding
[2023-07-01 11:49:37] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:49:37] [training] Using 1 GPUs
[2023-07-01 11:49:37] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:49:37] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:49:37] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:49:37] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:49:45] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:49:45] [valid] No post-processing script given for validating translator
[2023-07-01 11:49:45] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:49:45] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:49:45] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:49:45] [comm] Using global sharding
[2023-07-01 11:49:45] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:49:45] [training] Using 1 GPUs
[2023-07-01 11:49:45] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:49:45] Allocating memory for general optimizer shards
[2023-07-01 11:49:45] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:49:45] Loading Adam parameters
[2023-07-01 11:49:45] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:49:45] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:49:46] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:49:46] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:49:46] [data] Shuffling data
[2023-07-01 11:49:46] [data] Done reading 20,192 sentences
[2023-07-01 11:49:46] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:49:46] Training started
[2023-07-01 11:49:46] Training finished
[2023-07-01 11:49:49] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:49:49] [marian] Running on node20.datos.cluster.uy as process 22059 with command line:
[2023-07-01 11:49:49] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 181 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:49:49] [config] after: 0e
[2023-07-01 11:49:49] [config] after-batches: 0
[2023-07-01 11:49:49] [config] after-epochs: 181
[2023-07-01 11:49:49] [config] all-caps-every: 0
[2023-07-01 11:49:49] [config] allow-unk: false
[2023-07-01 11:49:49] [config] authors: false
[2023-07-01 11:49:49] [config] beam-size: 12
[2023-07-01 11:49:49] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:49:49] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:49:49] [config] bert-masking-fraction: 0.15
[2023-07-01 11:49:49] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:49:49] [config] bert-train-type-embeddings: true
[2023-07-01 11:49:49] [config] bert-type-vocab-size: 2
[2023-07-01 11:49:49] [config] build-info: ""
[2023-07-01 11:49:49] [config] check-gradient-nan: false
[2023-07-01 11:49:49] [config] check-nan: false
[2023-07-01 11:49:49] [config] cite: false
[2023-07-01 11:49:49] [config] clip-norm: 5
[2023-07-01 11:49:49] [config] cost-scaling:
[2023-07-01 11:49:49] [config]   []
[2023-07-01 11:49:49] [config] cost-type: ce-sum
[2023-07-01 11:49:49] [config] cpu-threads: 0
[2023-07-01 11:49:49] [config] data-threads: 8
[2023-07-01 11:49:49] [config] data-weighting: ""
[2023-07-01 11:49:49] [config] data-weighting-type: sentence
[2023-07-01 11:49:49] [config] dec-cell: gru
[2023-07-01 11:49:49] [config] dec-cell-base-depth: 2
[2023-07-01 11:49:49] [config] dec-cell-high-depth: 1
[2023-07-01 11:49:49] [config] dec-depth: 2
[2023-07-01 11:49:49] [config] devices:
[2023-07-01 11:49:49] [config]   - 0
[2023-07-01 11:49:49] [config] dim-emb: 512
[2023-07-01 11:49:49] [config] dim-rnn: 1024
[2023-07-01 11:49:49] [config] dim-vocabs:
[2023-07-01 11:49:49] [config]   - 16384
[2023-07-01 11:49:49] [config]   - 16384
[2023-07-01 11:49:49] [config] disp-first: 0
[2023-07-01 11:49:49] [config] disp-freq: 1000u
[2023-07-01 11:49:49] [config] disp-label-counts: true
[2023-07-01 11:49:49] [config] dropout-rnn: 0
[2023-07-01 11:49:49] [config] dropout-src: 0
[2023-07-01 11:49:49] [config] dropout-trg: 0
[2023-07-01 11:49:49] [config] dump-config: ""
[2023-07-01 11:49:49] [config] dynamic-gradient-scaling:
[2023-07-01 11:49:49] [config]   []
[2023-07-01 11:49:49] [config] early-stopping: 10
[2023-07-01 11:49:49] [config] early-stopping-on: first
[2023-07-01 11:49:49] [config] embedding-fix-src: false
[2023-07-01 11:49:49] [config] embedding-fix-trg: false
[2023-07-01 11:49:49] [config] embedding-normalization: false
[2023-07-01 11:49:49] [config] embedding-vectors:
[2023-07-01 11:49:49] [config]   []
[2023-07-01 11:49:49] [config] enc-cell: gru
[2023-07-01 11:49:49] [config] enc-cell-depth: 1
[2023-07-01 11:49:49] [config] enc-depth: 2
[2023-07-01 11:49:49] [config] enc-type: bidirectional
[2023-07-01 11:49:49] [config] english-title-case-every: 0
[2023-07-01 11:49:49] [config] exponential-smoothing: 0.0001
[2023-07-01 11:49:49] [config] factor-weight: 1
[2023-07-01 11:49:49] [config] factors-combine: sum
[2023-07-01 11:49:49] [config] factors-dim-emb: 0
[2023-07-01 11:49:49] [config] gradient-checkpointing: false
[2023-07-01 11:49:49] [config] gradient-norm-average-window: 100
[2023-07-01 11:49:49] [config] guided-alignment: none
[2023-07-01 11:49:49] [config] guided-alignment-cost: mse
[2023-07-01 11:49:49] [config] guided-alignment-weight: 0.1
[2023-07-01 11:49:49] [config] ignore-model-config: false
[2023-07-01 11:49:49] [config] input-types:
[2023-07-01 11:49:49] [config]   []
[2023-07-01 11:49:49] [config] interpolate-env-vars: false
[2023-07-01 11:49:49] [config] keep-best: false
[2023-07-01 11:49:49] [config] label-smoothing: 0.1
[2023-07-01 11:49:49] [config] layer-normalization: false
[2023-07-01 11:49:49] [config] learn-rate: 0.0003
[2023-07-01 11:49:49] [config] lemma-dependency: ""
[2023-07-01 11:49:49] [config] lemma-dim-emb: 0
[2023-07-01 11:49:49] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:49:49] [config] log-level: info
[2023-07-01 11:49:49] [config] log-time-zone: ""
[2023-07-01 11:49:49] [config] logical-epoch:
[2023-07-01 11:49:49] [config]   - 1e
[2023-07-01 11:49:49] [config]   - 0
[2023-07-01 11:49:49] [config] lr-decay: 0
[2023-07-01 11:49:49] [config] lr-decay-freq: 50000
[2023-07-01 11:49:49] [config] lr-decay-inv-sqrt:
[2023-07-01 11:49:49] [config]   - 16000
[2023-07-01 11:49:49] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:49:49] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:49:49] [config] lr-decay-start:
[2023-07-01 11:49:49] [config]   - 10
[2023-07-01 11:49:49] [config]   - 1
[2023-07-01 11:49:49] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:49:49] [config] lr-report: true
[2023-07-01 11:49:49] [config] lr-warmup: 16000
[2023-07-01 11:49:49] [config] lr-warmup-at-reload: false
[2023-07-01 11:49:49] [config] lr-warmup-cycle: false
[2023-07-01 11:49:49] [config] lr-warmup-start-rate: 0
[2023-07-01 11:49:49] [config] max-length: 100
[2023-07-01 11:49:49] [config] max-length-crop: false
[2023-07-01 11:49:49] [config] max-length-factor: 3
[2023-07-01 11:49:49] [config] maxi-batch: 100
[2023-07-01 11:49:49] [config] maxi-batch-sort: trg
[2023-07-01 11:49:49] [config] mini-batch: 1000
[2023-07-01 11:49:49] [config] mini-batch-fit: true
[2023-07-01 11:49:49] [config] mini-batch-fit-step: 10
[2023-07-01 11:49:49] [config] mini-batch-round-up: true
[2023-07-01 11:49:49] [config] mini-batch-track-lr: false
[2023-07-01 11:49:49] [config] mini-batch-warmup: 0
[2023-07-01 11:49:49] [config] mini-batch-words: 0
[2023-07-01 11:49:49] [config] mini-batch-words-ref: 0
[2023-07-01 11:49:49] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:49:49] [config] multi-loss-type: sum
[2023-07-01 11:49:49] [config] n-best: false
[2023-07-01 11:49:49] [config] no-nccl: false
[2023-07-01 11:49:49] [config] no-reload: false
[2023-07-01 11:49:49] [config] no-restore-corpus: false
[2023-07-01 11:49:49] [config] normalize: 1
[2023-07-01 11:49:49] [config] normalize-gradient: false
[2023-07-01 11:49:49] [config] num-devices: 0
[2023-07-01 11:49:49] [config] optimizer: adam
[2023-07-01 11:49:49] [config] optimizer-delay: 1
[2023-07-01 11:49:49] [config] optimizer-params:
[2023-07-01 11:49:49] [config]   - 0.9
[2023-07-01 11:49:49] [config]   - 0.98
[2023-07-01 11:49:49] [config]   - 1e-09
[2023-07-01 11:49:49] [config] output-omit-bias: false
[2023-07-01 11:49:49] [config] overwrite: true
[2023-07-01 11:49:49] [config] precision:
[2023-07-01 11:49:49] [config]   - float32
[2023-07-01 11:49:49] [config]   - float32
[2023-07-01 11:49:49] [config] pretrained-model: ""
[2023-07-01 11:49:49] [config] quantize-biases: false
[2023-07-01 11:49:49] [config] quantize-bits: 0
[2023-07-01 11:49:49] [config] quantize-log-based: false
[2023-07-01 11:49:49] [config] quantize-optimization-steps: 0
[2023-07-01 11:49:49] [config] quiet: false
[2023-07-01 11:49:49] [config] quiet-translation: true
[2023-07-01 11:49:49] [config] relative-paths: false
[2023-07-01 11:49:49] [config] right-left: false
[2023-07-01 11:49:49] [config] save-freq: 10000u
[2023-07-01 11:49:49] [config] seed: 1234
[2023-07-01 11:49:49] [config] sentencepiece-alphas:
[2023-07-01 11:49:49] [config]   []
[2023-07-01 11:49:49] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:49:49] [config] sentencepiece-options: ""
[2023-07-01 11:49:49] [config] sharding: global
[2023-07-01 11:49:49] [config] shuffle: data
[2023-07-01 11:49:49] [config] shuffle-in-ram: false
[2023-07-01 11:49:49] [config] sigterm: save-and-exit
[2023-07-01 11:49:49] [config] skip: false
[2023-07-01 11:49:49] [config] sqlite: ""
[2023-07-01 11:49:49] [config] sqlite-drop: false
[2023-07-01 11:49:49] [config] sync-freq: 200u
[2023-07-01 11:49:49] [config] sync-sgd: true
[2023-07-01 11:49:49] [config] tempdir: /tmp
[2023-07-01 11:49:49] [config] tied-embeddings: false
[2023-07-01 11:49:49] [config] tied-embeddings-all: true
[2023-07-01 11:49:49] [config] tied-embeddings-src: false
[2023-07-01 11:49:49] [config] train-embedder-rank:
[2023-07-01 11:49:49] [config]   []
[2023-07-01 11:49:49] [config] train-sets:
[2023-07-01 11:49:49] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:49:49] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:49:49] [config] transformer-aan-activation: swish
[2023-07-01 11:49:49] [config] transformer-aan-depth: 2
[2023-07-01 11:49:49] [config] transformer-aan-nogate: false
[2023-07-01 11:49:49] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:49:49] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:49:49] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:49:49] [config] transformer-depth-scaling: false
[2023-07-01 11:49:49] [config] transformer-dim-aan: 2048
[2023-07-01 11:49:49] [config] transformer-dim-ffn: 2048
[2023-07-01 11:49:49] [config] transformer-dropout: 0.1
[2023-07-01 11:49:49] [config] transformer-dropout-attention: 0
[2023-07-01 11:49:49] [config] transformer-dropout-ffn: 0
[2023-07-01 11:49:49] [config] transformer-ffn-activation: swish
[2023-07-01 11:49:49] [config] transformer-ffn-depth: 2
[2023-07-01 11:49:49] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:49:49] [config] transformer-heads: 8
[2023-07-01 11:49:49] [config] transformer-no-projection: false
[2023-07-01 11:49:49] [config] transformer-pool: false
[2023-07-01 11:49:49] [config] transformer-postprocess: dan
[2023-07-01 11:49:49] [config] transformer-postprocess-emb: d
[2023-07-01 11:49:49] [config] transformer-postprocess-top: ""
[2023-07-01 11:49:49] [config] transformer-preprocess: ""
[2023-07-01 11:49:49] [config] transformer-tied-layers:
[2023-07-01 11:49:49] [config]   []
[2023-07-01 11:49:49] [config] transformer-train-position-embeddings: false
[2023-07-01 11:49:49] [config] tsv: false
[2023-07-01 11:49:49] [config] tsv-fields: 0
[2023-07-01 11:49:49] [config] type: transformer
[2023-07-01 11:49:49] [config] ulr: false
[2023-07-01 11:49:49] [config] ulr-dim-emb: 0
[2023-07-01 11:49:49] [config] ulr-dropout: 0
[2023-07-01 11:49:49] [config] ulr-keys-vectors: ""
[2023-07-01 11:49:49] [config] ulr-query-vectors: ""
[2023-07-01 11:49:49] [config] ulr-softmax-temperature: 1
[2023-07-01 11:49:49] [config] ulr-trainable-transformation: false
[2023-07-01 11:49:49] [config] unlikelihood-loss: false
[2023-07-01 11:49:49] [config] valid-freq: 50000000
[2023-07-01 11:49:49] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:49:49] [config] valid-max-length: 1000
[2023-07-01 11:49:49] [config] valid-metrics:
[2023-07-01 11:49:49] [config]   - cross-entropy
[2023-07-01 11:49:49] [config]   - translation
[2023-07-01 11:49:49] [config] valid-mini-batch: 64
[2023-07-01 11:49:49] [config] valid-reset-stalled: false
[2023-07-01 11:49:49] [config] valid-script-args:
[2023-07-01 11:49:49] [config]   []
[2023-07-01 11:49:49] [config] valid-script-path: ""
[2023-07-01 11:49:49] [config] valid-sets:
[2023-07-01 11:49:49] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:49:49] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:49:49] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:49:49] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:49:49] [config] vocabs:
[2023-07-01 11:49:49] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:49:49] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:49:49] [config] word-penalty: 0
[2023-07-01 11:49:49] [config] word-scores: false
[2023-07-01 11:49:49] [config] workspace: 2048
[2023-07-01 11:49:49] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:49:49] Using synchronous SGD
[2023-07-01 11:49:49] Synced seed 1234
[2023-07-01 11:49:49] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:49:49] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:49:49] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:49:49] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:49:49] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:49:49] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:49:50] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:49:50] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:49:50] [comm] Using global sharding
[2023-07-01 11:49:50] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:49:50] [training] Using 1 GPUs
[2023-07-01 11:49:50] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:49:50] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:49:51] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:49:51] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:49:58] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:49:58] [valid] No post-processing script given for validating translator
[2023-07-01 11:49:58] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:49:58] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:49:58] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:49:58] [comm] Using global sharding
[2023-07-01 11:49:58] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:49:58] [training] Using 1 GPUs
[2023-07-01 11:49:58] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:49:59] Allocating memory for general optimizer shards
[2023-07-01 11:49:59] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:49:59] Loading Adam parameters
[2023-07-01 11:49:59] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:49:59] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:49:59] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:49:59] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:49:59] [data] Shuffling data
[2023-07-01 11:49:59] [data] Done reading 20,192 sentences
[2023-07-01 11:49:59] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:49:59] Training started
[2023-07-01 11:49:59] Training finished
[2023-07-01 11:50:03] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:50:03] [marian] Running on node20.datos.cluster.uy as process 22119 with command line:
[2023-07-01 11:50:03] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 182 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:50:03] [config] after: 0e
[2023-07-01 11:50:03] [config] after-batches: 0
[2023-07-01 11:50:03] [config] after-epochs: 182
[2023-07-01 11:50:03] [config] all-caps-every: 0
[2023-07-01 11:50:03] [config] allow-unk: false
[2023-07-01 11:50:03] [config] authors: false
[2023-07-01 11:50:03] [config] beam-size: 12
[2023-07-01 11:50:03] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:50:03] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:50:03] [config] bert-masking-fraction: 0.15
[2023-07-01 11:50:03] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:50:03] [config] bert-train-type-embeddings: true
[2023-07-01 11:50:03] [config] bert-type-vocab-size: 2
[2023-07-01 11:50:03] [config] build-info: ""
[2023-07-01 11:50:03] [config] check-gradient-nan: false
[2023-07-01 11:50:03] [config] check-nan: false
[2023-07-01 11:50:03] [config] cite: false
[2023-07-01 11:50:03] [config] clip-norm: 5
[2023-07-01 11:50:03] [config] cost-scaling:
[2023-07-01 11:50:03] [config]   []
[2023-07-01 11:50:03] [config] cost-type: ce-sum
[2023-07-01 11:50:03] [config] cpu-threads: 0
[2023-07-01 11:50:03] [config] data-threads: 8
[2023-07-01 11:50:03] [config] data-weighting: ""
[2023-07-01 11:50:03] [config] data-weighting-type: sentence
[2023-07-01 11:50:03] [config] dec-cell: gru
[2023-07-01 11:50:03] [config] dec-cell-base-depth: 2
[2023-07-01 11:50:03] [config] dec-cell-high-depth: 1
[2023-07-01 11:50:03] [config] dec-depth: 2
[2023-07-01 11:50:03] [config] devices:
[2023-07-01 11:50:03] [config]   - 0
[2023-07-01 11:50:03] [config] dim-emb: 512
[2023-07-01 11:50:03] [config] dim-rnn: 1024
[2023-07-01 11:50:03] [config] dim-vocabs:
[2023-07-01 11:50:03] [config]   - 16384
[2023-07-01 11:50:03] [config]   - 16384
[2023-07-01 11:50:03] [config] disp-first: 0
[2023-07-01 11:50:03] [config] disp-freq: 1000u
[2023-07-01 11:50:03] [config] disp-label-counts: true
[2023-07-01 11:50:03] [config] dropout-rnn: 0
[2023-07-01 11:50:03] [config] dropout-src: 0
[2023-07-01 11:50:03] [config] dropout-trg: 0
[2023-07-01 11:50:03] [config] dump-config: ""
[2023-07-01 11:50:03] [config] dynamic-gradient-scaling:
[2023-07-01 11:50:03] [config]   []
[2023-07-01 11:50:03] [config] early-stopping: 10
[2023-07-01 11:50:03] [config] early-stopping-on: first
[2023-07-01 11:50:03] [config] embedding-fix-src: false
[2023-07-01 11:50:03] [config] embedding-fix-trg: false
[2023-07-01 11:50:03] [config] embedding-normalization: false
[2023-07-01 11:50:03] [config] embedding-vectors:
[2023-07-01 11:50:03] [config]   []
[2023-07-01 11:50:03] [config] enc-cell: gru
[2023-07-01 11:50:03] [config] enc-cell-depth: 1
[2023-07-01 11:50:03] [config] enc-depth: 2
[2023-07-01 11:50:03] [config] enc-type: bidirectional
[2023-07-01 11:50:03] [config] english-title-case-every: 0
[2023-07-01 11:50:03] [config] exponential-smoothing: 0.0001
[2023-07-01 11:50:03] [config] factor-weight: 1
[2023-07-01 11:50:03] [config] factors-combine: sum
[2023-07-01 11:50:03] [config] factors-dim-emb: 0
[2023-07-01 11:50:03] [config] gradient-checkpointing: false
[2023-07-01 11:50:03] [config] gradient-norm-average-window: 100
[2023-07-01 11:50:03] [config] guided-alignment: none
[2023-07-01 11:50:03] [config] guided-alignment-cost: mse
[2023-07-01 11:50:03] [config] guided-alignment-weight: 0.1
[2023-07-01 11:50:03] [config] ignore-model-config: false
[2023-07-01 11:50:03] [config] input-types:
[2023-07-01 11:50:03] [config]   []
[2023-07-01 11:50:03] [config] interpolate-env-vars: false
[2023-07-01 11:50:03] [config] keep-best: false
[2023-07-01 11:50:03] [config] label-smoothing: 0.1
[2023-07-01 11:50:03] [config] layer-normalization: false
[2023-07-01 11:50:03] [config] learn-rate: 0.0003
[2023-07-01 11:50:03] [config] lemma-dependency: ""
[2023-07-01 11:50:03] [config] lemma-dim-emb: 0
[2023-07-01 11:50:03] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:50:03] [config] log-level: info
[2023-07-01 11:50:03] [config] log-time-zone: ""
[2023-07-01 11:50:03] [config] logical-epoch:
[2023-07-01 11:50:03] [config]   - 1e
[2023-07-01 11:50:03] [config]   - 0
[2023-07-01 11:50:03] [config] lr-decay: 0
[2023-07-01 11:50:03] [config] lr-decay-freq: 50000
[2023-07-01 11:50:03] [config] lr-decay-inv-sqrt:
[2023-07-01 11:50:03] [config]   - 16000
[2023-07-01 11:50:03] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:50:03] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:50:03] [config] lr-decay-start:
[2023-07-01 11:50:03] [config]   - 10
[2023-07-01 11:50:03] [config]   - 1
[2023-07-01 11:50:03] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:50:03] [config] lr-report: true
[2023-07-01 11:50:03] [config] lr-warmup: 16000
[2023-07-01 11:50:03] [config] lr-warmup-at-reload: false
[2023-07-01 11:50:03] [config] lr-warmup-cycle: false
[2023-07-01 11:50:03] [config] lr-warmup-start-rate: 0
[2023-07-01 11:50:03] [config] max-length: 100
[2023-07-01 11:50:03] [config] max-length-crop: false
[2023-07-01 11:50:03] [config] max-length-factor: 3
[2023-07-01 11:50:03] [config] maxi-batch: 100
[2023-07-01 11:50:03] [config] maxi-batch-sort: trg
[2023-07-01 11:50:03] [config] mini-batch: 1000
[2023-07-01 11:50:03] [config] mini-batch-fit: true
[2023-07-01 11:50:03] [config] mini-batch-fit-step: 10
[2023-07-01 11:50:03] [config] mini-batch-round-up: true
[2023-07-01 11:50:03] [config] mini-batch-track-lr: false
[2023-07-01 11:50:03] [config] mini-batch-warmup: 0
[2023-07-01 11:50:03] [config] mini-batch-words: 0
[2023-07-01 11:50:03] [config] mini-batch-words-ref: 0
[2023-07-01 11:50:03] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:50:03] [config] multi-loss-type: sum
[2023-07-01 11:50:03] [config] n-best: false
[2023-07-01 11:50:03] [config] no-nccl: false
[2023-07-01 11:50:03] [config] no-reload: false
[2023-07-01 11:50:03] [config] no-restore-corpus: false
[2023-07-01 11:50:03] [config] normalize: 1
[2023-07-01 11:50:03] [config] normalize-gradient: false
[2023-07-01 11:50:03] [config] num-devices: 0
[2023-07-01 11:50:03] [config] optimizer: adam
[2023-07-01 11:50:03] [config] optimizer-delay: 1
[2023-07-01 11:50:03] [config] optimizer-params:
[2023-07-01 11:50:03] [config]   - 0.9
[2023-07-01 11:50:03] [config]   - 0.98
[2023-07-01 11:50:03] [config]   - 1e-09
[2023-07-01 11:50:03] [config] output-omit-bias: false
[2023-07-01 11:50:03] [config] overwrite: true
[2023-07-01 11:50:03] [config] precision:
[2023-07-01 11:50:03] [config]   - float32
[2023-07-01 11:50:03] [config]   - float32
[2023-07-01 11:50:03] [config] pretrained-model: ""
[2023-07-01 11:50:03] [config] quantize-biases: false
[2023-07-01 11:50:03] [config] quantize-bits: 0
[2023-07-01 11:50:03] [config] quantize-log-based: false
[2023-07-01 11:50:03] [config] quantize-optimization-steps: 0
[2023-07-01 11:50:03] [config] quiet: false
[2023-07-01 11:50:03] [config] quiet-translation: true
[2023-07-01 11:50:03] [config] relative-paths: false
[2023-07-01 11:50:03] [config] right-left: false
[2023-07-01 11:50:03] [config] save-freq: 10000u
[2023-07-01 11:50:03] [config] seed: 1234
[2023-07-01 11:50:03] [config] sentencepiece-alphas:
[2023-07-01 11:50:03] [config]   []
[2023-07-01 11:50:03] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:50:03] [config] sentencepiece-options: ""
[2023-07-01 11:50:03] [config] sharding: global
[2023-07-01 11:50:03] [config] shuffle: data
[2023-07-01 11:50:03] [config] shuffle-in-ram: false
[2023-07-01 11:50:03] [config] sigterm: save-and-exit
[2023-07-01 11:50:03] [config] skip: false
[2023-07-01 11:50:03] [config] sqlite: ""
[2023-07-01 11:50:03] [config] sqlite-drop: false
[2023-07-01 11:50:03] [config] sync-freq: 200u
[2023-07-01 11:50:03] [config] sync-sgd: true
[2023-07-01 11:50:03] [config] tempdir: /tmp
[2023-07-01 11:50:03] [config] tied-embeddings: false
[2023-07-01 11:50:03] [config] tied-embeddings-all: true
[2023-07-01 11:50:03] [config] tied-embeddings-src: false
[2023-07-01 11:50:03] [config] train-embedder-rank:
[2023-07-01 11:50:03] [config]   []
[2023-07-01 11:50:03] [config] train-sets:
[2023-07-01 11:50:03] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:50:03] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:50:03] [config] transformer-aan-activation: swish
[2023-07-01 11:50:03] [config] transformer-aan-depth: 2
[2023-07-01 11:50:03] [config] transformer-aan-nogate: false
[2023-07-01 11:50:03] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:50:03] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:50:03] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:50:03] [config] transformer-depth-scaling: false
[2023-07-01 11:50:03] [config] transformer-dim-aan: 2048
[2023-07-01 11:50:03] [config] transformer-dim-ffn: 2048
[2023-07-01 11:50:03] [config] transformer-dropout: 0.1
[2023-07-01 11:50:03] [config] transformer-dropout-attention: 0
[2023-07-01 11:50:03] [config] transformer-dropout-ffn: 0
[2023-07-01 11:50:03] [config] transformer-ffn-activation: swish
[2023-07-01 11:50:03] [config] transformer-ffn-depth: 2
[2023-07-01 11:50:03] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:50:03] [config] transformer-heads: 8
[2023-07-01 11:50:03] [config] transformer-no-projection: false
[2023-07-01 11:50:03] [config] transformer-pool: false
[2023-07-01 11:50:03] [config] transformer-postprocess: dan
[2023-07-01 11:50:03] [config] transformer-postprocess-emb: d
[2023-07-01 11:50:03] [config] transformer-postprocess-top: ""
[2023-07-01 11:50:03] [config] transformer-preprocess: ""
[2023-07-01 11:50:03] [config] transformer-tied-layers:
[2023-07-01 11:50:03] [config]   []
[2023-07-01 11:50:03] [config] transformer-train-position-embeddings: false
[2023-07-01 11:50:03] [config] tsv: false
[2023-07-01 11:50:03] [config] tsv-fields: 0
[2023-07-01 11:50:03] [config] type: transformer
[2023-07-01 11:50:03] [config] ulr: false
[2023-07-01 11:50:03] [config] ulr-dim-emb: 0
[2023-07-01 11:50:03] [config] ulr-dropout: 0
[2023-07-01 11:50:03] [config] ulr-keys-vectors: ""
[2023-07-01 11:50:03] [config] ulr-query-vectors: ""
[2023-07-01 11:50:03] [config] ulr-softmax-temperature: 1
[2023-07-01 11:50:03] [config] ulr-trainable-transformation: false
[2023-07-01 11:50:03] [config] unlikelihood-loss: false
[2023-07-01 11:50:03] [config] valid-freq: 50000000
[2023-07-01 11:50:03] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:50:03] [config] valid-max-length: 1000
[2023-07-01 11:50:03] [config] valid-metrics:
[2023-07-01 11:50:03] [config]   - cross-entropy
[2023-07-01 11:50:03] [config]   - translation
[2023-07-01 11:50:03] [config] valid-mini-batch: 64
[2023-07-01 11:50:03] [config] valid-reset-stalled: false
[2023-07-01 11:50:03] [config] valid-script-args:
[2023-07-01 11:50:03] [config]   []
[2023-07-01 11:50:03] [config] valid-script-path: ""
[2023-07-01 11:50:03] [config] valid-sets:
[2023-07-01 11:50:03] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:50:03] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:50:03] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:50:03] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:50:03] [config] vocabs:
[2023-07-01 11:50:03] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:50:03] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:50:03] [config] word-penalty: 0
[2023-07-01 11:50:03] [config] word-scores: false
[2023-07-01 11:50:03] [config] workspace: 2048
[2023-07-01 11:50:03] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:50:03] Using synchronous SGD
[2023-07-01 11:50:03] Synced seed 1234
[2023-07-01 11:50:03] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:50:03] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:50:03] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:50:03] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:50:03] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:50:03] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:50:04] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:50:04] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:50:04] [comm] Using global sharding
[2023-07-01 11:50:04] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:50:04] [training] Using 1 GPUs
[2023-07-01 11:50:04] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:50:04] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:50:04] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:50:04] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:50:12] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:50:12] [valid] No post-processing script given for validating translator
[2023-07-01 11:50:12] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:50:12] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:50:12] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:50:12] [comm] Using global sharding
[2023-07-01 11:50:12] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:50:12] [training] Using 1 GPUs
[2023-07-01 11:50:12] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:50:12] Allocating memory for general optimizer shards
[2023-07-01 11:50:12] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:50:12] Loading Adam parameters
[2023-07-01 11:50:12] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:50:13] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:50:13] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:50:13] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:50:13] [data] Shuffling data
[2023-07-01 11:50:13] [data] Done reading 20,192 sentences
[2023-07-01 11:50:13] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:50:13] Training started
[2023-07-01 11:50:13] Training finished
[2023-07-01 11:50:16] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:50:16] [marian] Running on node20.datos.cluster.uy as process 22177 with command line:
[2023-07-01 11:50:16] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 183 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:50:16] [config] after: 0e
[2023-07-01 11:50:16] [config] after-batches: 0
[2023-07-01 11:50:16] [config] after-epochs: 183
[2023-07-01 11:50:16] [config] all-caps-every: 0
[2023-07-01 11:50:16] [config] allow-unk: false
[2023-07-01 11:50:16] [config] authors: false
[2023-07-01 11:50:16] [config] beam-size: 12
[2023-07-01 11:50:16] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:50:16] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:50:16] [config] bert-masking-fraction: 0.15
[2023-07-01 11:50:16] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:50:16] [config] bert-train-type-embeddings: true
[2023-07-01 11:50:16] [config] bert-type-vocab-size: 2
[2023-07-01 11:50:16] [config] build-info: ""
[2023-07-01 11:50:16] [config] check-gradient-nan: false
[2023-07-01 11:50:16] [config] check-nan: false
[2023-07-01 11:50:16] [config] cite: false
[2023-07-01 11:50:16] [config] clip-norm: 5
[2023-07-01 11:50:16] [config] cost-scaling:
[2023-07-01 11:50:16] [config]   []
[2023-07-01 11:50:16] [config] cost-type: ce-sum
[2023-07-01 11:50:16] [config] cpu-threads: 0
[2023-07-01 11:50:16] [config] data-threads: 8
[2023-07-01 11:50:16] [config] data-weighting: ""
[2023-07-01 11:50:16] [config] data-weighting-type: sentence
[2023-07-01 11:50:16] [config] dec-cell: gru
[2023-07-01 11:50:16] [config] dec-cell-base-depth: 2
[2023-07-01 11:50:16] [config] dec-cell-high-depth: 1
[2023-07-01 11:50:16] [config] dec-depth: 2
[2023-07-01 11:50:16] [config] devices:
[2023-07-01 11:50:16] [config]   - 0
[2023-07-01 11:50:16] [config] dim-emb: 512
[2023-07-01 11:50:16] [config] dim-rnn: 1024
[2023-07-01 11:50:16] [config] dim-vocabs:
[2023-07-01 11:50:16] [config]   - 16384
[2023-07-01 11:50:16] [config]   - 16384
[2023-07-01 11:50:16] [config] disp-first: 0
[2023-07-01 11:50:16] [config] disp-freq: 1000u
[2023-07-01 11:50:16] [config] disp-label-counts: true
[2023-07-01 11:50:16] [config] dropout-rnn: 0
[2023-07-01 11:50:16] [config] dropout-src: 0
[2023-07-01 11:50:16] [config] dropout-trg: 0
[2023-07-01 11:50:16] [config] dump-config: ""
[2023-07-01 11:50:16] [config] dynamic-gradient-scaling:
[2023-07-01 11:50:16] [config]   []
[2023-07-01 11:50:16] [config] early-stopping: 10
[2023-07-01 11:50:16] [config] early-stopping-on: first
[2023-07-01 11:50:16] [config] embedding-fix-src: false
[2023-07-01 11:50:16] [config] embedding-fix-trg: false
[2023-07-01 11:50:16] [config] embedding-normalization: false
[2023-07-01 11:50:16] [config] embedding-vectors:
[2023-07-01 11:50:16] [config]   []
[2023-07-01 11:50:16] [config] enc-cell: gru
[2023-07-01 11:50:16] [config] enc-cell-depth: 1
[2023-07-01 11:50:16] [config] enc-depth: 2
[2023-07-01 11:50:16] [config] enc-type: bidirectional
[2023-07-01 11:50:16] [config] english-title-case-every: 0
[2023-07-01 11:50:16] [config] exponential-smoothing: 0.0001
[2023-07-01 11:50:16] [config] factor-weight: 1
[2023-07-01 11:50:16] [config] factors-combine: sum
[2023-07-01 11:50:16] [config] factors-dim-emb: 0
[2023-07-01 11:50:16] [config] gradient-checkpointing: false
[2023-07-01 11:50:16] [config] gradient-norm-average-window: 100
[2023-07-01 11:50:16] [config] guided-alignment: none
[2023-07-01 11:50:16] [config] guided-alignment-cost: mse
[2023-07-01 11:50:16] [config] guided-alignment-weight: 0.1
[2023-07-01 11:50:16] [config] ignore-model-config: false
[2023-07-01 11:50:16] [config] input-types:
[2023-07-01 11:50:16] [config]   []
[2023-07-01 11:50:16] [config] interpolate-env-vars: false
[2023-07-01 11:50:16] [config] keep-best: false
[2023-07-01 11:50:16] [config] label-smoothing: 0.1
[2023-07-01 11:50:16] [config] layer-normalization: false
[2023-07-01 11:50:16] [config] learn-rate: 0.0003
[2023-07-01 11:50:16] [config] lemma-dependency: ""
[2023-07-01 11:50:16] [config] lemma-dim-emb: 0
[2023-07-01 11:50:16] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:50:16] [config] log-level: info
[2023-07-01 11:50:16] [config] log-time-zone: ""
[2023-07-01 11:50:16] [config] logical-epoch:
[2023-07-01 11:50:16] [config]   - 1e
[2023-07-01 11:50:16] [config]   - 0
[2023-07-01 11:50:16] [config] lr-decay: 0
[2023-07-01 11:50:16] [config] lr-decay-freq: 50000
[2023-07-01 11:50:16] [config] lr-decay-inv-sqrt:
[2023-07-01 11:50:16] [config]   - 16000
[2023-07-01 11:50:16] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:50:16] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:50:16] [config] lr-decay-start:
[2023-07-01 11:50:16] [config]   - 10
[2023-07-01 11:50:16] [config]   - 1
[2023-07-01 11:50:16] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:50:16] [config] lr-report: true
[2023-07-01 11:50:16] [config] lr-warmup: 16000
[2023-07-01 11:50:16] [config] lr-warmup-at-reload: false
[2023-07-01 11:50:16] [config] lr-warmup-cycle: false
[2023-07-01 11:50:16] [config] lr-warmup-start-rate: 0
[2023-07-01 11:50:16] [config] max-length: 100
[2023-07-01 11:50:16] [config] max-length-crop: false
[2023-07-01 11:50:16] [config] max-length-factor: 3
[2023-07-01 11:50:16] [config] maxi-batch: 100
[2023-07-01 11:50:16] [config] maxi-batch-sort: trg
[2023-07-01 11:50:16] [config] mini-batch: 1000
[2023-07-01 11:50:16] [config] mini-batch-fit: true
[2023-07-01 11:50:16] [config] mini-batch-fit-step: 10
[2023-07-01 11:50:16] [config] mini-batch-round-up: true
[2023-07-01 11:50:16] [config] mini-batch-track-lr: false
[2023-07-01 11:50:16] [config] mini-batch-warmup: 0
[2023-07-01 11:50:16] [config] mini-batch-words: 0
[2023-07-01 11:50:16] [config] mini-batch-words-ref: 0
[2023-07-01 11:50:16] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:50:16] [config] multi-loss-type: sum
[2023-07-01 11:50:16] [config] n-best: false
[2023-07-01 11:50:16] [config] no-nccl: false
[2023-07-01 11:50:16] [config] no-reload: false
[2023-07-01 11:50:16] [config] no-restore-corpus: false
[2023-07-01 11:50:16] [config] normalize: 1
[2023-07-01 11:50:16] [config] normalize-gradient: false
[2023-07-01 11:50:16] [config] num-devices: 0
[2023-07-01 11:50:16] [config] optimizer: adam
[2023-07-01 11:50:16] [config] optimizer-delay: 1
[2023-07-01 11:50:16] [config] optimizer-params:
[2023-07-01 11:50:16] [config]   - 0.9
[2023-07-01 11:50:16] [config]   - 0.98
[2023-07-01 11:50:16] [config]   - 1e-09
[2023-07-01 11:50:16] [config] output-omit-bias: false
[2023-07-01 11:50:16] [config] overwrite: true
[2023-07-01 11:50:16] [config] precision:
[2023-07-01 11:50:16] [config]   - float32
[2023-07-01 11:50:16] [config]   - float32
[2023-07-01 11:50:16] [config] pretrained-model: ""
[2023-07-01 11:50:16] [config] quantize-biases: false
[2023-07-01 11:50:16] [config] quantize-bits: 0
[2023-07-01 11:50:16] [config] quantize-log-based: false
[2023-07-01 11:50:16] [config] quantize-optimization-steps: 0
[2023-07-01 11:50:16] [config] quiet: false
[2023-07-01 11:50:16] [config] quiet-translation: true
[2023-07-01 11:50:16] [config] relative-paths: false
[2023-07-01 11:50:16] [config] right-left: false
[2023-07-01 11:50:16] [config] save-freq: 10000u
[2023-07-01 11:50:16] [config] seed: 1234
[2023-07-01 11:50:16] [config] sentencepiece-alphas:
[2023-07-01 11:50:16] [config]   []
[2023-07-01 11:50:16] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:50:16] [config] sentencepiece-options: ""
[2023-07-01 11:50:16] [config] sharding: global
[2023-07-01 11:50:16] [config] shuffle: data
[2023-07-01 11:50:16] [config] shuffle-in-ram: false
[2023-07-01 11:50:16] [config] sigterm: save-and-exit
[2023-07-01 11:50:16] [config] skip: false
[2023-07-01 11:50:16] [config] sqlite: ""
[2023-07-01 11:50:16] [config] sqlite-drop: false
[2023-07-01 11:50:16] [config] sync-freq: 200u
[2023-07-01 11:50:16] [config] sync-sgd: true
[2023-07-01 11:50:16] [config] tempdir: /tmp
[2023-07-01 11:50:16] [config] tied-embeddings: false
[2023-07-01 11:50:16] [config] tied-embeddings-all: true
[2023-07-01 11:50:16] [config] tied-embeddings-src: false
[2023-07-01 11:50:16] [config] train-embedder-rank:
[2023-07-01 11:50:16] [config]   []
[2023-07-01 11:50:16] [config] train-sets:
[2023-07-01 11:50:16] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:50:16] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:50:16] [config] transformer-aan-activation: swish
[2023-07-01 11:50:16] [config] transformer-aan-depth: 2
[2023-07-01 11:50:16] [config] transformer-aan-nogate: false
[2023-07-01 11:50:16] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:50:16] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:50:16] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:50:16] [config] transformer-depth-scaling: false
[2023-07-01 11:50:16] [config] transformer-dim-aan: 2048
[2023-07-01 11:50:16] [config] transformer-dim-ffn: 2048
[2023-07-01 11:50:16] [config] transformer-dropout: 0.1
[2023-07-01 11:50:16] [config] transformer-dropout-attention: 0
[2023-07-01 11:50:16] [config] transformer-dropout-ffn: 0
[2023-07-01 11:50:16] [config] transformer-ffn-activation: swish
[2023-07-01 11:50:16] [config] transformer-ffn-depth: 2
[2023-07-01 11:50:16] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:50:16] [config] transformer-heads: 8
[2023-07-01 11:50:16] [config] transformer-no-projection: false
[2023-07-01 11:50:16] [config] transformer-pool: false
[2023-07-01 11:50:16] [config] transformer-postprocess: dan
[2023-07-01 11:50:16] [config] transformer-postprocess-emb: d
[2023-07-01 11:50:16] [config] transformer-postprocess-top: ""
[2023-07-01 11:50:16] [config] transformer-preprocess: ""
[2023-07-01 11:50:16] [config] transformer-tied-layers:
[2023-07-01 11:50:16] [config]   []
[2023-07-01 11:50:16] [config] transformer-train-position-embeddings: false
[2023-07-01 11:50:16] [config] tsv: false
[2023-07-01 11:50:16] [config] tsv-fields: 0
[2023-07-01 11:50:16] [config] type: transformer
[2023-07-01 11:50:16] [config] ulr: false
[2023-07-01 11:50:16] [config] ulr-dim-emb: 0
[2023-07-01 11:50:16] [config] ulr-dropout: 0
[2023-07-01 11:50:16] [config] ulr-keys-vectors: ""
[2023-07-01 11:50:16] [config] ulr-query-vectors: ""
[2023-07-01 11:50:16] [config] ulr-softmax-temperature: 1
[2023-07-01 11:50:16] [config] ulr-trainable-transformation: false
[2023-07-01 11:50:16] [config] unlikelihood-loss: false
[2023-07-01 11:50:16] [config] valid-freq: 50000000
[2023-07-01 11:50:16] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:50:16] [config] valid-max-length: 1000
[2023-07-01 11:50:16] [config] valid-metrics:
[2023-07-01 11:50:16] [config]   - cross-entropy
[2023-07-01 11:50:16] [config]   - translation
[2023-07-01 11:50:16] [config] valid-mini-batch: 64
[2023-07-01 11:50:16] [config] valid-reset-stalled: false
[2023-07-01 11:50:16] [config] valid-script-args:
[2023-07-01 11:50:16] [config]   []
[2023-07-01 11:50:16] [config] valid-script-path: ""
[2023-07-01 11:50:16] [config] valid-sets:
[2023-07-01 11:50:16] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:50:16] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:50:16] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:50:16] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:50:16] [config] vocabs:
[2023-07-01 11:50:16] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:50:16] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:50:16] [config] word-penalty: 0
[2023-07-01 11:50:16] [config] word-scores: false
[2023-07-01 11:50:16] [config] workspace: 2048
[2023-07-01 11:50:16] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:50:16] Using synchronous SGD
[2023-07-01 11:50:16] Synced seed 1234
[2023-07-01 11:50:16] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:50:16] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:50:16] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:50:16] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:50:16] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:50:16] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:50:17] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:50:17] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:50:17] [comm] Using global sharding
[2023-07-01 11:50:17] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:50:17] [training] Using 1 GPUs
[2023-07-01 11:50:17] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:50:17] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:50:18] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:50:18] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:50:25] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:50:25] [valid] No post-processing script given for validating translator
[2023-07-01 11:50:25] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:50:25] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:50:25] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:50:25] [comm] Using global sharding
[2023-07-01 11:50:25] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:50:25] [training] Using 1 GPUs
[2023-07-01 11:50:25] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:50:26] Allocating memory for general optimizer shards
[2023-07-01 11:50:26] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:50:26] Loading Adam parameters
[2023-07-01 11:50:26] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:50:26] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:50:26] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:50:26] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:50:26] [data] Shuffling data
[2023-07-01 11:50:26] [data] Done reading 20,192 sentences
[2023-07-01 11:50:26] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:50:26] Training started
[2023-07-01 11:50:26] Training finished
[2023-07-01 11:50:30] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:50:30] [marian] Running on node20.datos.cluster.uy as process 22235 with command line:
[2023-07-01 11:50:30] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 184 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:50:30] [config] after: 0e
[2023-07-01 11:50:30] [config] after-batches: 0
[2023-07-01 11:50:30] [config] after-epochs: 184
[2023-07-01 11:50:30] [config] all-caps-every: 0
[2023-07-01 11:50:30] [config] allow-unk: false
[2023-07-01 11:50:30] [config] authors: false
[2023-07-01 11:50:30] [config] beam-size: 12
[2023-07-01 11:50:30] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:50:30] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:50:30] [config] bert-masking-fraction: 0.15
[2023-07-01 11:50:30] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:50:30] [config] bert-train-type-embeddings: true
[2023-07-01 11:50:30] [config] bert-type-vocab-size: 2
[2023-07-01 11:50:30] [config] build-info: ""
[2023-07-01 11:50:30] [config] check-gradient-nan: false
[2023-07-01 11:50:30] [config] check-nan: false
[2023-07-01 11:50:30] [config] cite: false
[2023-07-01 11:50:30] [config] clip-norm: 5
[2023-07-01 11:50:30] [config] cost-scaling:
[2023-07-01 11:50:30] [config]   []
[2023-07-01 11:50:30] [config] cost-type: ce-sum
[2023-07-01 11:50:30] [config] cpu-threads: 0
[2023-07-01 11:50:30] [config] data-threads: 8
[2023-07-01 11:50:30] [config] data-weighting: ""
[2023-07-01 11:50:30] [config] data-weighting-type: sentence
[2023-07-01 11:50:30] [config] dec-cell: gru
[2023-07-01 11:50:30] [config] dec-cell-base-depth: 2
[2023-07-01 11:50:30] [config] dec-cell-high-depth: 1
[2023-07-01 11:50:30] [config] dec-depth: 2
[2023-07-01 11:50:30] [config] devices:
[2023-07-01 11:50:30] [config]   - 0
[2023-07-01 11:50:30] [config] dim-emb: 512
[2023-07-01 11:50:30] [config] dim-rnn: 1024
[2023-07-01 11:50:30] [config] dim-vocabs:
[2023-07-01 11:50:30] [config]   - 16384
[2023-07-01 11:50:30] [config]   - 16384
[2023-07-01 11:50:30] [config] disp-first: 0
[2023-07-01 11:50:30] [config] disp-freq: 1000u
[2023-07-01 11:50:30] [config] disp-label-counts: true
[2023-07-01 11:50:30] [config] dropout-rnn: 0
[2023-07-01 11:50:30] [config] dropout-src: 0
[2023-07-01 11:50:30] [config] dropout-trg: 0
[2023-07-01 11:50:30] [config] dump-config: ""
[2023-07-01 11:50:30] [config] dynamic-gradient-scaling:
[2023-07-01 11:50:30] [config]   []
[2023-07-01 11:50:30] [config] early-stopping: 10
[2023-07-01 11:50:30] [config] early-stopping-on: first
[2023-07-01 11:50:30] [config] embedding-fix-src: false
[2023-07-01 11:50:30] [config] embedding-fix-trg: false
[2023-07-01 11:50:30] [config] embedding-normalization: false
[2023-07-01 11:50:30] [config] embedding-vectors:
[2023-07-01 11:50:30] [config]   []
[2023-07-01 11:50:30] [config] enc-cell: gru
[2023-07-01 11:50:30] [config] enc-cell-depth: 1
[2023-07-01 11:50:30] [config] enc-depth: 2
[2023-07-01 11:50:30] [config] enc-type: bidirectional
[2023-07-01 11:50:30] [config] english-title-case-every: 0
[2023-07-01 11:50:30] [config] exponential-smoothing: 0.0001
[2023-07-01 11:50:30] [config] factor-weight: 1
[2023-07-01 11:50:30] [config] factors-combine: sum
[2023-07-01 11:50:30] [config] factors-dim-emb: 0
[2023-07-01 11:50:30] [config] gradient-checkpointing: false
[2023-07-01 11:50:30] [config] gradient-norm-average-window: 100
[2023-07-01 11:50:30] [config] guided-alignment: none
[2023-07-01 11:50:30] [config] guided-alignment-cost: mse
[2023-07-01 11:50:30] [config] guided-alignment-weight: 0.1
[2023-07-01 11:50:30] [config] ignore-model-config: false
[2023-07-01 11:50:30] [config] input-types:
[2023-07-01 11:50:30] [config]   []
[2023-07-01 11:50:30] [config] interpolate-env-vars: false
[2023-07-01 11:50:30] [config] keep-best: false
[2023-07-01 11:50:30] [config] label-smoothing: 0.1
[2023-07-01 11:50:30] [config] layer-normalization: false
[2023-07-01 11:50:30] [config] learn-rate: 0.0003
[2023-07-01 11:50:30] [config] lemma-dependency: ""
[2023-07-01 11:50:30] [config] lemma-dim-emb: 0
[2023-07-01 11:50:30] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:50:30] [config] log-level: info
[2023-07-01 11:50:30] [config] log-time-zone: ""
[2023-07-01 11:50:30] [config] logical-epoch:
[2023-07-01 11:50:30] [config]   - 1e
[2023-07-01 11:50:30] [config]   - 0
[2023-07-01 11:50:30] [config] lr-decay: 0
[2023-07-01 11:50:30] [config] lr-decay-freq: 50000
[2023-07-01 11:50:30] [config] lr-decay-inv-sqrt:
[2023-07-01 11:50:30] [config]   - 16000
[2023-07-01 11:50:30] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:50:30] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:50:30] [config] lr-decay-start:
[2023-07-01 11:50:30] [config]   - 10
[2023-07-01 11:50:30] [config]   - 1
[2023-07-01 11:50:30] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:50:30] [config] lr-report: true
[2023-07-01 11:50:30] [config] lr-warmup: 16000
[2023-07-01 11:50:30] [config] lr-warmup-at-reload: false
[2023-07-01 11:50:30] [config] lr-warmup-cycle: false
[2023-07-01 11:50:30] [config] lr-warmup-start-rate: 0
[2023-07-01 11:50:30] [config] max-length: 100
[2023-07-01 11:50:30] [config] max-length-crop: false
[2023-07-01 11:50:30] [config] max-length-factor: 3
[2023-07-01 11:50:30] [config] maxi-batch: 100
[2023-07-01 11:50:30] [config] maxi-batch-sort: trg
[2023-07-01 11:50:30] [config] mini-batch: 1000
[2023-07-01 11:50:30] [config] mini-batch-fit: true
[2023-07-01 11:50:30] [config] mini-batch-fit-step: 10
[2023-07-01 11:50:30] [config] mini-batch-round-up: true
[2023-07-01 11:50:30] [config] mini-batch-track-lr: false
[2023-07-01 11:50:30] [config] mini-batch-warmup: 0
[2023-07-01 11:50:30] [config] mini-batch-words: 0
[2023-07-01 11:50:30] [config] mini-batch-words-ref: 0
[2023-07-01 11:50:30] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:50:30] [config] multi-loss-type: sum
[2023-07-01 11:50:30] [config] n-best: false
[2023-07-01 11:50:30] [config] no-nccl: false
[2023-07-01 11:50:30] [config] no-reload: false
[2023-07-01 11:50:30] [config] no-restore-corpus: false
[2023-07-01 11:50:30] [config] normalize: 1
[2023-07-01 11:50:30] [config] normalize-gradient: false
[2023-07-01 11:50:30] [config] num-devices: 0
[2023-07-01 11:50:30] [config] optimizer: adam
[2023-07-01 11:50:30] [config] optimizer-delay: 1
[2023-07-01 11:50:30] [config] optimizer-params:
[2023-07-01 11:50:30] [config]   - 0.9
[2023-07-01 11:50:30] [config]   - 0.98
[2023-07-01 11:50:30] [config]   - 1e-09
[2023-07-01 11:50:30] [config] output-omit-bias: false
[2023-07-01 11:50:30] [config] overwrite: true
[2023-07-01 11:50:30] [config] precision:
[2023-07-01 11:50:30] [config]   - float32
[2023-07-01 11:50:30] [config]   - float32
[2023-07-01 11:50:30] [config] pretrained-model: ""
[2023-07-01 11:50:30] [config] quantize-biases: false
[2023-07-01 11:50:30] [config] quantize-bits: 0
[2023-07-01 11:50:30] [config] quantize-log-based: false
[2023-07-01 11:50:30] [config] quantize-optimization-steps: 0
[2023-07-01 11:50:30] [config] quiet: false
[2023-07-01 11:50:30] [config] quiet-translation: true
[2023-07-01 11:50:30] [config] relative-paths: false
[2023-07-01 11:50:30] [config] right-left: false
[2023-07-01 11:50:30] [config] save-freq: 10000u
[2023-07-01 11:50:30] [config] seed: 1234
[2023-07-01 11:50:30] [config] sentencepiece-alphas:
[2023-07-01 11:50:30] [config]   []
[2023-07-01 11:50:30] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:50:30] [config] sentencepiece-options: ""
[2023-07-01 11:50:30] [config] sharding: global
[2023-07-01 11:50:30] [config] shuffle: data
[2023-07-01 11:50:30] [config] shuffle-in-ram: false
[2023-07-01 11:50:30] [config] sigterm: save-and-exit
[2023-07-01 11:50:30] [config] skip: false
[2023-07-01 11:50:30] [config] sqlite: ""
[2023-07-01 11:50:30] [config] sqlite-drop: false
[2023-07-01 11:50:30] [config] sync-freq: 200u
[2023-07-01 11:50:30] [config] sync-sgd: true
[2023-07-01 11:50:30] [config] tempdir: /tmp
[2023-07-01 11:50:30] [config] tied-embeddings: false
[2023-07-01 11:50:30] [config] tied-embeddings-all: true
[2023-07-01 11:50:30] [config] tied-embeddings-src: false
[2023-07-01 11:50:30] [config] train-embedder-rank:
[2023-07-01 11:50:30] [config]   []
[2023-07-01 11:50:30] [config] train-sets:
[2023-07-01 11:50:30] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:50:30] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:50:30] [config] transformer-aan-activation: swish
[2023-07-01 11:50:30] [config] transformer-aan-depth: 2
[2023-07-01 11:50:30] [config] transformer-aan-nogate: false
[2023-07-01 11:50:30] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:50:30] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:50:30] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:50:30] [config] transformer-depth-scaling: false
[2023-07-01 11:50:30] [config] transformer-dim-aan: 2048
[2023-07-01 11:50:30] [config] transformer-dim-ffn: 2048
[2023-07-01 11:50:30] [config] transformer-dropout: 0.1
[2023-07-01 11:50:30] [config] transformer-dropout-attention: 0
[2023-07-01 11:50:30] [config] transformer-dropout-ffn: 0
[2023-07-01 11:50:30] [config] transformer-ffn-activation: swish
[2023-07-01 11:50:30] [config] transformer-ffn-depth: 2
[2023-07-01 11:50:30] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:50:30] [config] transformer-heads: 8
[2023-07-01 11:50:30] [config] transformer-no-projection: false
[2023-07-01 11:50:30] [config] transformer-pool: false
[2023-07-01 11:50:30] [config] transformer-postprocess: dan
[2023-07-01 11:50:30] [config] transformer-postprocess-emb: d
[2023-07-01 11:50:30] [config] transformer-postprocess-top: ""
[2023-07-01 11:50:30] [config] transformer-preprocess: ""
[2023-07-01 11:50:30] [config] transformer-tied-layers:
[2023-07-01 11:50:30] [config]   []
[2023-07-01 11:50:30] [config] transformer-train-position-embeddings: false
[2023-07-01 11:50:30] [config] tsv: false
[2023-07-01 11:50:30] [config] tsv-fields: 0
[2023-07-01 11:50:30] [config] type: transformer
[2023-07-01 11:50:30] [config] ulr: false
[2023-07-01 11:50:30] [config] ulr-dim-emb: 0
[2023-07-01 11:50:30] [config] ulr-dropout: 0
[2023-07-01 11:50:30] [config] ulr-keys-vectors: ""
[2023-07-01 11:50:30] [config] ulr-query-vectors: ""
[2023-07-01 11:50:30] [config] ulr-softmax-temperature: 1
[2023-07-01 11:50:30] [config] ulr-trainable-transformation: false
[2023-07-01 11:50:30] [config] unlikelihood-loss: false
[2023-07-01 11:50:30] [config] valid-freq: 50000000
[2023-07-01 11:50:30] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:50:30] [config] valid-max-length: 1000
[2023-07-01 11:50:30] [config] valid-metrics:
[2023-07-01 11:50:30] [config]   - cross-entropy
[2023-07-01 11:50:30] [config]   - translation
[2023-07-01 11:50:30] [config] valid-mini-batch: 64
[2023-07-01 11:50:30] [config] valid-reset-stalled: false
[2023-07-01 11:50:30] [config] valid-script-args:
[2023-07-01 11:50:30] [config]   []
[2023-07-01 11:50:30] [config] valid-script-path: ""
[2023-07-01 11:50:30] [config] valid-sets:
[2023-07-01 11:50:30] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:50:30] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:50:30] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:50:30] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:50:30] [config] vocabs:
[2023-07-01 11:50:30] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:50:30] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:50:30] [config] word-penalty: 0
[2023-07-01 11:50:30] [config] word-scores: false
[2023-07-01 11:50:30] [config] workspace: 2048
[2023-07-01 11:50:30] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:50:30] Using synchronous SGD
[2023-07-01 11:50:30] Synced seed 1234
[2023-07-01 11:50:30] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:50:30] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:50:30] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:50:30] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:50:30] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:50:30] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:50:31] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:50:31] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:50:31] [comm] Using global sharding
[2023-07-01 11:50:31] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:50:31] [training] Using 1 GPUs
[2023-07-01 11:50:31] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:50:31] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:50:31] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:50:31] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:50:39] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:50:39] [valid] No post-processing script given for validating translator
[2023-07-01 11:50:39] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:50:39] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:50:39] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:50:39] [comm] Using global sharding
[2023-07-01 11:50:39] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:50:39] [training] Using 1 GPUs
[2023-07-01 11:50:39] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:50:39] Allocating memory for general optimizer shards
[2023-07-01 11:50:39] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:50:39] Loading Adam parameters
[2023-07-01 11:50:39] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:50:39] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:50:39] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:50:39] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:50:39] [data] Shuffling data
[2023-07-01 11:50:39] [data] Done reading 20,192 sentences
[2023-07-01 11:50:40] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:50:40] Training started
[2023-07-01 11:50:40] Training finished
[2023-07-01 11:50:43] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:50:43] [marian] Running on node20.datos.cluster.uy as process 22293 with command line:
[2023-07-01 11:50:43] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 185 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:50:43] [config] after: 0e
[2023-07-01 11:50:43] [config] after-batches: 0
[2023-07-01 11:50:43] [config] after-epochs: 185
[2023-07-01 11:50:43] [config] all-caps-every: 0
[2023-07-01 11:50:43] [config] allow-unk: false
[2023-07-01 11:50:43] [config] authors: false
[2023-07-01 11:50:43] [config] beam-size: 12
[2023-07-01 11:50:43] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:50:43] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:50:43] [config] bert-masking-fraction: 0.15
[2023-07-01 11:50:43] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:50:43] [config] bert-train-type-embeddings: true
[2023-07-01 11:50:43] [config] bert-type-vocab-size: 2
[2023-07-01 11:50:43] [config] build-info: ""
[2023-07-01 11:50:43] [config] check-gradient-nan: false
[2023-07-01 11:50:43] [config] check-nan: false
[2023-07-01 11:50:43] [config] cite: false
[2023-07-01 11:50:43] [config] clip-norm: 5
[2023-07-01 11:50:43] [config] cost-scaling:
[2023-07-01 11:50:43] [config]   []
[2023-07-01 11:50:43] [config] cost-type: ce-sum
[2023-07-01 11:50:43] [config] cpu-threads: 0
[2023-07-01 11:50:43] [config] data-threads: 8
[2023-07-01 11:50:43] [config] data-weighting: ""
[2023-07-01 11:50:43] [config] data-weighting-type: sentence
[2023-07-01 11:50:43] [config] dec-cell: gru
[2023-07-01 11:50:43] [config] dec-cell-base-depth: 2
[2023-07-01 11:50:43] [config] dec-cell-high-depth: 1
[2023-07-01 11:50:43] [config] dec-depth: 2
[2023-07-01 11:50:43] [config] devices:
[2023-07-01 11:50:43] [config]   - 0
[2023-07-01 11:50:43] [config] dim-emb: 512
[2023-07-01 11:50:43] [config] dim-rnn: 1024
[2023-07-01 11:50:43] [config] dim-vocabs:
[2023-07-01 11:50:43] [config]   - 16384
[2023-07-01 11:50:43] [config]   - 16384
[2023-07-01 11:50:43] [config] disp-first: 0
[2023-07-01 11:50:43] [config] disp-freq: 1000u
[2023-07-01 11:50:43] [config] disp-label-counts: true
[2023-07-01 11:50:43] [config] dropout-rnn: 0
[2023-07-01 11:50:43] [config] dropout-src: 0
[2023-07-01 11:50:43] [config] dropout-trg: 0
[2023-07-01 11:50:43] [config] dump-config: ""
[2023-07-01 11:50:43] [config] dynamic-gradient-scaling:
[2023-07-01 11:50:43] [config]   []
[2023-07-01 11:50:43] [config] early-stopping: 10
[2023-07-01 11:50:43] [config] early-stopping-on: first
[2023-07-01 11:50:43] [config] embedding-fix-src: false
[2023-07-01 11:50:43] [config] embedding-fix-trg: false
[2023-07-01 11:50:43] [config] embedding-normalization: false
[2023-07-01 11:50:43] [config] embedding-vectors:
[2023-07-01 11:50:43] [config]   []
[2023-07-01 11:50:43] [config] enc-cell: gru
[2023-07-01 11:50:43] [config] enc-cell-depth: 1
[2023-07-01 11:50:43] [config] enc-depth: 2
[2023-07-01 11:50:43] [config] enc-type: bidirectional
[2023-07-01 11:50:43] [config] english-title-case-every: 0
[2023-07-01 11:50:43] [config] exponential-smoothing: 0.0001
[2023-07-01 11:50:43] [config] factor-weight: 1
[2023-07-01 11:50:43] [config] factors-combine: sum
[2023-07-01 11:50:43] [config] factors-dim-emb: 0
[2023-07-01 11:50:43] [config] gradient-checkpointing: false
[2023-07-01 11:50:43] [config] gradient-norm-average-window: 100
[2023-07-01 11:50:43] [config] guided-alignment: none
[2023-07-01 11:50:43] [config] guided-alignment-cost: mse
[2023-07-01 11:50:43] [config] guided-alignment-weight: 0.1
[2023-07-01 11:50:43] [config] ignore-model-config: false
[2023-07-01 11:50:43] [config] input-types:
[2023-07-01 11:50:43] [config]   []
[2023-07-01 11:50:43] [config] interpolate-env-vars: false
[2023-07-01 11:50:43] [config] keep-best: false
[2023-07-01 11:50:43] [config] label-smoothing: 0.1
[2023-07-01 11:50:43] [config] layer-normalization: false
[2023-07-01 11:50:43] [config] learn-rate: 0.0003
[2023-07-01 11:50:43] [config] lemma-dependency: ""
[2023-07-01 11:50:43] [config] lemma-dim-emb: 0
[2023-07-01 11:50:43] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:50:43] [config] log-level: info
[2023-07-01 11:50:43] [config] log-time-zone: ""
[2023-07-01 11:50:43] [config] logical-epoch:
[2023-07-01 11:50:43] [config]   - 1e
[2023-07-01 11:50:43] [config]   - 0
[2023-07-01 11:50:43] [config] lr-decay: 0
[2023-07-01 11:50:43] [config] lr-decay-freq: 50000
[2023-07-01 11:50:43] [config] lr-decay-inv-sqrt:
[2023-07-01 11:50:43] [config]   - 16000
[2023-07-01 11:50:43] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:50:43] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:50:43] [config] lr-decay-start:
[2023-07-01 11:50:43] [config]   - 10
[2023-07-01 11:50:43] [config]   - 1
[2023-07-01 11:50:43] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:50:43] [config] lr-report: true
[2023-07-01 11:50:43] [config] lr-warmup: 16000
[2023-07-01 11:50:43] [config] lr-warmup-at-reload: false
[2023-07-01 11:50:43] [config] lr-warmup-cycle: false
[2023-07-01 11:50:43] [config] lr-warmup-start-rate: 0
[2023-07-01 11:50:43] [config] max-length: 100
[2023-07-01 11:50:43] [config] max-length-crop: false
[2023-07-01 11:50:43] [config] max-length-factor: 3
[2023-07-01 11:50:43] [config] maxi-batch: 100
[2023-07-01 11:50:43] [config] maxi-batch-sort: trg
[2023-07-01 11:50:43] [config] mini-batch: 1000
[2023-07-01 11:50:43] [config] mini-batch-fit: true
[2023-07-01 11:50:43] [config] mini-batch-fit-step: 10
[2023-07-01 11:50:43] [config] mini-batch-round-up: true
[2023-07-01 11:50:43] [config] mini-batch-track-lr: false
[2023-07-01 11:50:43] [config] mini-batch-warmup: 0
[2023-07-01 11:50:43] [config] mini-batch-words: 0
[2023-07-01 11:50:43] [config] mini-batch-words-ref: 0
[2023-07-01 11:50:43] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:50:43] [config] multi-loss-type: sum
[2023-07-01 11:50:43] [config] n-best: false
[2023-07-01 11:50:43] [config] no-nccl: false
[2023-07-01 11:50:43] [config] no-reload: false
[2023-07-01 11:50:43] [config] no-restore-corpus: false
[2023-07-01 11:50:43] [config] normalize: 1
[2023-07-01 11:50:43] [config] normalize-gradient: false
[2023-07-01 11:50:43] [config] num-devices: 0
[2023-07-01 11:50:43] [config] optimizer: adam
[2023-07-01 11:50:43] [config] optimizer-delay: 1
[2023-07-01 11:50:43] [config] optimizer-params:
[2023-07-01 11:50:43] [config]   - 0.9
[2023-07-01 11:50:43] [config]   - 0.98
[2023-07-01 11:50:43] [config]   - 1e-09
[2023-07-01 11:50:43] [config] output-omit-bias: false
[2023-07-01 11:50:43] [config] overwrite: true
[2023-07-01 11:50:43] [config] precision:
[2023-07-01 11:50:43] [config]   - float32
[2023-07-01 11:50:43] [config]   - float32
[2023-07-01 11:50:43] [config] pretrained-model: ""
[2023-07-01 11:50:43] [config] quantize-biases: false
[2023-07-01 11:50:43] [config] quantize-bits: 0
[2023-07-01 11:50:43] [config] quantize-log-based: false
[2023-07-01 11:50:43] [config] quantize-optimization-steps: 0
[2023-07-01 11:50:43] [config] quiet: false
[2023-07-01 11:50:43] [config] quiet-translation: true
[2023-07-01 11:50:43] [config] relative-paths: false
[2023-07-01 11:50:43] [config] right-left: false
[2023-07-01 11:50:43] [config] save-freq: 10000u
[2023-07-01 11:50:43] [config] seed: 1234
[2023-07-01 11:50:43] [config] sentencepiece-alphas:
[2023-07-01 11:50:43] [config]   []
[2023-07-01 11:50:43] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:50:43] [config] sentencepiece-options: ""
[2023-07-01 11:50:43] [config] sharding: global
[2023-07-01 11:50:43] [config] shuffle: data
[2023-07-01 11:50:43] [config] shuffle-in-ram: false
[2023-07-01 11:50:43] [config] sigterm: save-and-exit
[2023-07-01 11:50:43] [config] skip: false
[2023-07-01 11:50:43] [config] sqlite: ""
[2023-07-01 11:50:43] [config] sqlite-drop: false
[2023-07-01 11:50:43] [config] sync-freq: 200u
[2023-07-01 11:50:43] [config] sync-sgd: true
[2023-07-01 11:50:43] [config] tempdir: /tmp
[2023-07-01 11:50:43] [config] tied-embeddings: false
[2023-07-01 11:50:43] [config] tied-embeddings-all: true
[2023-07-01 11:50:43] [config] tied-embeddings-src: false
[2023-07-01 11:50:43] [config] train-embedder-rank:
[2023-07-01 11:50:43] [config]   []
[2023-07-01 11:50:43] [config] train-sets:
[2023-07-01 11:50:43] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:50:43] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:50:43] [config] transformer-aan-activation: swish
[2023-07-01 11:50:43] [config] transformer-aan-depth: 2
[2023-07-01 11:50:43] [config] transformer-aan-nogate: false
[2023-07-01 11:50:43] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:50:43] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:50:43] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:50:43] [config] transformer-depth-scaling: false
[2023-07-01 11:50:43] [config] transformer-dim-aan: 2048
[2023-07-01 11:50:43] [config] transformer-dim-ffn: 2048
[2023-07-01 11:50:43] [config] transformer-dropout: 0.1
[2023-07-01 11:50:43] [config] transformer-dropout-attention: 0
[2023-07-01 11:50:43] [config] transformer-dropout-ffn: 0
[2023-07-01 11:50:43] [config] transformer-ffn-activation: swish
[2023-07-01 11:50:43] [config] transformer-ffn-depth: 2
[2023-07-01 11:50:43] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:50:43] [config] transformer-heads: 8
[2023-07-01 11:50:43] [config] transformer-no-projection: false
[2023-07-01 11:50:43] [config] transformer-pool: false
[2023-07-01 11:50:43] [config] transformer-postprocess: dan
[2023-07-01 11:50:43] [config] transformer-postprocess-emb: d
[2023-07-01 11:50:43] [config] transformer-postprocess-top: ""
[2023-07-01 11:50:43] [config] transformer-preprocess: ""
[2023-07-01 11:50:43] [config] transformer-tied-layers:
[2023-07-01 11:50:43] [config]   []
[2023-07-01 11:50:43] [config] transformer-train-position-embeddings: false
[2023-07-01 11:50:43] [config] tsv: false
[2023-07-01 11:50:43] [config] tsv-fields: 0
[2023-07-01 11:50:43] [config] type: transformer
[2023-07-01 11:50:43] [config] ulr: false
[2023-07-01 11:50:43] [config] ulr-dim-emb: 0
[2023-07-01 11:50:43] [config] ulr-dropout: 0
[2023-07-01 11:50:43] [config] ulr-keys-vectors: ""
[2023-07-01 11:50:43] [config] ulr-query-vectors: ""
[2023-07-01 11:50:43] [config] ulr-softmax-temperature: 1
[2023-07-01 11:50:43] [config] ulr-trainable-transformation: false
[2023-07-01 11:50:43] [config] unlikelihood-loss: false
[2023-07-01 11:50:43] [config] valid-freq: 50000000
[2023-07-01 11:50:43] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:50:43] [config] valid-max-length: 1000
[2023-07-01 11:50:43] [config] valid-metrics:
[2023-07-01 11:50:43] [config]   - cross-entropy
[2023-07-01 11:50:43] [config]   - translation
[2023-07-01 11:50:43] [config] valid-mini-batch: 64
[2023-07-01 11:50:43] [config] valid-reset-stalled: false
[2023-07-01 11:50:43] [config] valid-script-args:
[2023-07-01 11:50:43] [config]   []
[2023-07-01 11:50:43] [config] valid-script-path: ""
[2023-07-01 11:50:43] [config] valid-sets:
[2023-07-01 11:50:43] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:50:43] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:50:43] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:50:43] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:50:43] [config] vocabs:
[2023-07-01 11:50:43] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:50:43] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:50:43] [config] word-penalty: 0
[2023-07-01 11:50:43] [config] word-scores: false
[2023-07-01 11:50:43] [config] workspace: 2048
[2023-07-01 11:50:43] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:50:43] Using synchronous SGD
[2023-07-01 11:50:44] Synced seed 1234
[2023-07-01 11:50:44] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:50:44] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:50:44] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:50:44] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:50:44] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:50:44] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:50:45] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:50:45] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:50:45] [comm] Using global sharding
[2023-07-01 11:50:45] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:50:45] [training] Using 1 GPUs
[2023-07-01 11:50:45] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:50:45] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:50:45] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:50:45] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:50:53] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:50:53] [valid] No post-processing script given for validating translator
[2023-07-01 11:50:53] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:50:53] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:50:53] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:50:53] [comm] Using global sharding
[2023-07-01 11:50:53] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:50:53] [training] Using 1 GPUs
[2023-07-01 11:50:53] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:50:53] Allocating memory for general optimizer shards
[2023-07-01 11:50:53] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:50:53] Loading Adam parameters
[2023-07-01 11:50:53] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:50:53] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:50:53] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:50:53] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:50:53] [data] Shuffling data
[2023-07-01 11:50:54] [data] Done reading 20,192 sentences
[2023-07-01 11:50:54] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:50:54] Training started
[2023-07-01 11:50:54] Training finished
[2023-07-01 11:50:57] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:50:57] [marian] Running on node20.datos.cluster.uy as process 22352 with command line:
[2023-07-01 11:50:57] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 186 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:50:57] [config] after: 0e
[2023-07-01 11:50:57] [config] after-batches: 0
[2023-07-01 11:50:57] [config] after-epochs: 186
[2023-07-01 11:50:57] [config] all-caps-every: 0
[2023-07-01 11:50:57] [config] allow-unk: false
[2023-07-01 11:50:57] [config] authors: false
[2023-07-01 11:50:57] [config] beam-size: 12
[2023-07-01 11:50:57] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:50:57] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:50:57] [config] bert-masking-fraction: 0.15
[2023-07-01 11:50:57] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:50:57] [config] bert-train-type-embeddings: true
[2023-07-01 11:50:57] [config] bert-type-vocab-size: 2
[2023-07-01 11:50:57] [config] build-info: ""
[2023-07-01 11:50:57] [config] check-gradient-nan: false
[2023-07-01 11:50:57] [config] check-nan: false
[2023-07-01 11:50:57] [config] cite: false
[2023-07-01 11:50:57] [config] clip-norm: 5
[2023-07-01 11:50:57] [config] cost-scaling:
[2023-07-01 11:50:57] [config]   []
[2023-07-01 11:50:57] [config] cost-type: ce-sum
[2023-07-01 11:50:57] [config] cpu-threads: 0
[2023-07-01 11:50:57] [config] data-threads: 8
[2023-07-01 11:50:57] [config] data-weighting: ""
[2023-07-01 11:50:57] [config] data-weighting-type: sentence
[2023-07-01 11:50:57] [config] dec-cell: gru
[2023-07-01 11:50:57] [config] dec-cell-base-depth: 2
[2023-07-01 11:50:57] [config] dec-cell-high-depth: 1
[2023-07-01 11:50:57] [config] dec-depth: 2
[2023-07-01 11:50:57] [config] devices:
[2023-07-01 11:50:57] [config]   - 0
[2023-07-01 11:50:57] [config] dim-emb: 512
[2023-07-01 11:50:57] [config] dim-rnn: 1024
[2023-07-01 11:50:57] [config] dim-vocabs:
[2023-07-01 11:50:57] [config]   - 16384
[2023-07-01 11:50:57] [config]   - 16384
[2023-07-01 11:50:57] [config] disp-first: 0
[2023-07-01 11:50:57] [config] disp-freq: 1000u
[2023-07-01 11:50:57] [config] disp-label-counts: true
[2023-07-01 11:50:57] [config] dropout-rnn: 0
[2023-07-01 11:50:57] [config] dropout-src: 0
[2023-07-01 11:50:57] [config] dropout-trg: 0
[2023-07-01 11:50:57] [config] dump-config: ""
[2023-07-01 11:50:57] [config] dynamic-gradient-scaling:
[2023-07-01 11:50:57] [config]   []
[2023-07-01 11:50:57] [config] early-stopping: 10
[2023-07-01 11:50:57] [config] early-stopping-on: first
[2023-07-01 11:50:57] [config] embedding-fix-src: false
[2023-07-01 11:50:57] [config] embedding-fix-trg: false
[2023-07-01 11:50:57] [config] embedding-normalization: false
[2023-07-01 11:50:57] [config] embedding-vectors:
[2023-07-01 11:50:57] [config]   []
[2023-07-01 11:50:57] [config] enc-cell: gru
[2023-07-01 11:50:57] [config] enc-cell-depth: 1
[2023-07-01 11:50:57] [config] enc-depth: 2
[2023-07-01 11:50:57] [config] enc-type: bidirectional
[2023-07-01 11:50:57] [config] english-title-case-every: 0
[2023-07-01 11:50:57] [config] exponential-smoothing: 0.0001
[2023-07-01 11:50:57] [config] factor-weight: 1
[2023-07-01 11:50:57] [config] factors-combine: sum
[2023-07-01 11:50:57] [config] factors-dim-emb: 0
[2023-07-01 11:50:57] [config] gradient-checkpointing: false
[2023-07-01 11:50:57] [config] gradient-norm-average-window: 100
[2023-07-01 11:50:57] [config] guided-alignment: none
[2023-07-01 11:50:57] [config] guided-alignment-cost: mse
[2023-07-01 11:50:57] [config] guided-alignment-weight: 0.1
[2023-07-01 11:50:57] [config] ignore-model-config: false
[2023-07-01 11:50:57] [config] input-types:
[2023-07-01 11:50:57] [config]   []
[2023-07-01 11:50:57] [config] interpolate-env-vars: false
[2023-07-01 11:50:57] [config] keep-best: false
[2023-07-01 11:50:57] [config] label-smoothing: 0.1
[2023-07-01 11:50:57] [config] layer-normalization: false
[2023-07-01 11:50:57] [config] learn-rate: 0.0003
[2023-07-01 11:50:57] [config] lemma-dependency: ""
[2023-07-01 11:50:57] [config] lemma-dim-emb: 0
[2023-07-01 11:50:57] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:50:57] [config] log-level: info
[2023-07-01 11:50:57] [config] log-time-zone: ""
[2023-07-01 11:50:57] [config] logical-epoch:
[2023-07-01 11:50:57] [config]   - 1e
[2023-07-01 11:50:57] [config]   - 0
[2023-07-01 11:50:57] [config] lr-decay: 0
[2023-07-01 11:50:57] [config] lr-decay-freq: 50000
[2023-07-01 11:50:57] [config] lr-decay-inv-sqrt:
[2023-07-01 11:50:57] [config]   - 16000
[2023-07-01 11:50:57] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:50:57] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:50:57] [config] lr-decay-start:
[2023-07-01 11:50:57] [config]   - 10
[2023-07-01 11:50:57] [config]   - 1
[2023-07-01 11:50:57] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:50:57] [config] lr-report: true
[2023-07-01 11:50:57] [config] lr-warmup: 16000
[2023-07-01 11:50:57] [config] lr-warmup-at-reload: false
[2023-07-01 11:50:57] [config] lr-warmup-cycle: false
[2023-07-01 11:50:57] [config] lr-warmup-start-rate: 0
[2023-07-01 11:50:57] [config] max-length: 100
[2023-07-01 11:50:57] [config] max-length-crop: false
[2023-07-01 11:50:57] [config] max-length-factor: 3
[2023-07-01 11:50:57] [config] maxi-batch: 100
[2023-07-01 11:50:57] [config] maxi-batch-sort: trg
[2023-07-01 11:50:57] [config] mini-batch: 1000
[2023-07-01 11:50:57] [config] mini-batch-fit: true
[2023-07-01 11:50:57] [config] mini-batch-fit-step: 10
[2023-07-01 11:50:57] [config] mini-batch-round-up: true
[2023-07-01 11:50:57] [config] mini-batch-track-lr: false
[2023-07-01 11:50:57] [config] mini-batch-warmup: 0
[2023-07-01 11:50:57] [config] mini-batch-words: 0
[2023-07-01 11:50:57] [config] mini-batch-words-ref: 0
[2023-07-01 11:50:57] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:50:57] [config] multi-loss-type: sum
[2023-07-01 11:50:57] [config] n-best: false
[2023-07-01 11:50:57] [config] no-nccl: false
[2023-07-01 11:50:57] [config] no-reload: false
[2023-07-01 11:50:57] [config] no-restore-corpus: false
[2023-07-01 11:50:57] [config] normalize: 1
[2023-07-01 11:50:57] [config] normalize-gradient: false
[2023-07-01 11:50:57] [config] num-devices: 0
[2023-07-01 11:50:57] [config] optimizer: adam
[2023-07-01 11:50:57] [config] optimizer-delay: 1
[2023-07-01 11:50:57] [config] optimizer-params:
[2023-07-01 11:50:57] [config]   - 0.9
[2023-07-01 11:50:57] [config]   - 0.98
[2023-07-01 11:50:57] [config]   - 1e-09
[2023-07-01 11:50:57] [config] output-omit-bias: false
[2023-07-01 11:50:57] [config] overwrite: true
[2023-07-01 11:50:57] [config] precision:
[2023-07-01 11:50:57] [config]   - float32
[2023-07-01 11:50:57] [config]   - float32
[2023-07-01 11:50:57] [config] pretrained-model: ""
[2023-07-01 11:50:57] [config] quantize-biases: false
[2023-07-01 11:50:57] [config] quantize-bits: 0
[2023-07-01 11:50:57] [config] quantize-log-based: false
[2023-07-01 11:50:57] [config] quantize-optimization-steps: 0
[2023-07-01 11:50:57] [config] quiet: false
[2023-07-01 11:50:57] [config] quiet-translation: true
[2023-07-01 11:50:57] [config] relative-paths: false
[2023-07-01 11:50:57] [config] right-left: false
[2023-07-01 11:50:57] [config] save-freq: 10000u
[2023-07-01 11:50:57] [config] seed: 1234
[2023-07-01 11:50:57] [config] sentencepiece-alphas:
[2023-07-01 11:50:57] [config]   []
[2023-07-01 11:50:57] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:50:57] [config] sentencepiece-options: ""
[2023-07-01 11:50:57] [config] sharding: global
[2023-07-01 11:50:57] [config] shuffle: data
[2023-07-01 11:50:57] [config] shuffle-in-ram: false
[2023-07-01 11:50:57] [config] sigterm: save-and-exit
[2023-07-01 11:50:57] [config] skip: false
[2023-07-01 11:50:57] [config] sqlite: ""
[2023-07-01 11:50:57] [config] sqlite-drop: false
[2023-07-01 11:50:57] [config] sync-freq: 200u
[2023-07-01 11:50:57] [config] sync-sgd: true
[2023-07-01 11:50:57] [config] tempdir: /tmp
[2023-07-01 11:50:57] [config] tied-embeddings: false
[2023-07-01 11:50:57] [config] tied-embeddings-all: true
[2023-07-01 11:50:57] [config] tied-embeddings-src: false
[2023-07-01 11:50:57] [config] train-embedder-rank:
[2023-07-01 11:50:57] [config]   []
[2023-07-01 11:50:57] [config] train-sets:
[2023-07-01 11:50:57] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:50:57] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:50:57] [config] transformer-aan-activation: swish
[2023-07-01 11:50:57] [config] transformer-aan-depth: 2
[2023-07-01 11:50:57] [config] transformer-aan-nogate: false
[2023-07-01 11:50:57] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:50:57] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:50:57] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:50:57] [config] transformer-depth-scaling: false
[2023-07-01 11:50:57] [config] transformer-dim-aan: 2048
[2023-07-01 11:50:57] [config] transformer-dim-ffn: 2048
[2023-07-01 11:50:57] [config] transformer-dropout: 0.1
[2023-07-01 11:50:57] [config] transformer-dropout-attention: 0
[2023-07-01 11:50:57] [config] transformer-dropout-ffn: 0
[2023-07-01 11:50:57] [config] transformer-ffn-activation: swish
[2023-07-01 11:50:57] [config] transformer-ffn-depth: 2
[2023-07-01 11:50:57] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:50:57] [config] transformer-heads: 8
[2023-07-01 11:50:57] [config] transformer-no-projection: false
[2023-07-01 11:50:57] [config] transformer-pool: false
[2023-07-01 11:50:57] [config] transformer-postprocess: dan
[2023-07-01 11:50:57] [config] transformer-postprocess-emb: d
[2023-07-01 11:50:57] [config] transformer-postprocess-top: ""
[2023-07-01 11:50:57] [config] transformer-preprocess: ""
[2023-07-01 11:50:57] [config] transformer-tied-layers:
[2023-07-01 11:50:57] [config]   []
[2023-07-01 11:50:57] [config] transformer-train-position-embeddings: false
[2023-07-01 11:50:57] [config] tsv: false
[2023-07-01 11:50:57] [config] tsv-fields: 0
[2023-07-01 11:50:57] [config] type: transformer
[2023-07-01 11:50:57] [config] ulr: false
[2023-07-01 11:50:57] [config] ulr-dim-emb: 0
[2023-07-01 11:50:57] [config] ulr-dropout: 0
[2023-07-01 11:50:57] [config] ulr-keys-vectors: ""
[2023-07-01 11:50:57] [config] ulr-query-vectors: ""
[2023-07-01 11:50:57] [config] ulr-softmax-temperature: 1
[2023-07-01 11:50:57] [config] ulr-trainable-transformation: false
[2023-07-01 11:50:57] [config] unlikelihood-loss: false
[2023-07-01 11:50:57] [config] valid-freq: 50000000
[2023-07-01 11:50:57] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:50:57] [config] valid-max-length: 1000
[2023-07-01 11:50:57] [config] valid-metrics:
[2023-07-01 11:50:57] [config]   - cross-entropy
[2023-07-01 11:50:57] [config]   - translation
[2023-07-01 11:50:57] [config] valid-mini-batch: 64
[2023-07-01 11:50:57] [config] valid-reset-stalled: false
[2023-07-01 11:50:57] [config] valid-script-args:
[2023-07-01 11:50:57] [config]   []
[2023-07-01 11:50:57] [config] valid-script-path: ""
[2023-07-01 11:50:57] [config] valid-sets:
[2023-07-01 11:50:57] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:50:57] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:50:57] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:50:57] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:50:57] [config] vocabs:
[2023-07-01 11:50:57] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:50:57] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:50:57] [config] word-penalty: 0
[2023-07-01 11:50:57] [config] word-scores: false
[2023-07-01 11:50:57] [config] workspace: 2048
[2023-07-01 11:50:57] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:50:57] Using synchronous SGD
[2023-07-01 11:50:58] Synced seed 1234
[2023-07-01 11:50:58] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:50:58] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:50:58] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:50:58] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:50:58] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:50:58] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:50:58] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:50:59] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:50:59] [comm] Using global sharding
[2023-07-01 11:50:59] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:50:59] [training] Using 1 GPUs
[2023-07-01 11:50:59] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:50:59] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:50:59] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:50:59] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:51:06] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:51:06] [valid] No post-processing script given for validating translator
[2023-07-01 11:51:06] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:51:06] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:51:06] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:51:06] [comm] Using global sharding
[2023-07-01 11:51:07] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:51:07] [training] Using 1 GPUs
[2023-07-01 11:51:07] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:51:07] Allocating memory for general optimizer shards
[2023-07-01 11:51:07] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:51:07] Loading Adam parameters
[2023-07-01 11:51:07] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:51:07] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:51:07] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:51:07] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:51:07] [data] Shuffling data
[2023-07-01 11:51:07] [data] Done reading 20,192 sentences
[2023-07-01 11:51:07] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:51:07] Training started
[2023-07-01 11:51:07] Training finished
[2023-07-01 11:51:11] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:51:11] [marian] Running on node20.datos.cluster.uy as process 22413 with command line:
[2023-07-01 11:51:11] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 187 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:51:11] [config] after: 0e
[2023-07-01 11:51:11] [config] after-batches: 0
[2023-07-01 11:51:11] [config] after-epochs: 187
[2023-07-01 11:51:11] [config] all-caps-every: 0
[2023-07-01 11:51:11] [config] allow-unk: false
[2023-07-01 11:51:11] [config] authors: false
[2023-07-01 11:51:11] [config] beam-size: 12
[2023-07-01 11:51:11] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:51:11] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:51:11] [config] bert-masking-fraction: 0.15
[2023-07-01 11:51:11] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:51:11] [config] bert-train-type-embeddings: true
[2023-07-01 11:51:11] [config] bert-type-vocab-size: 2
[2023-07-01 11:51:11] [config] build-info: ""
[2023-07-01 11:51:11] [config] check-gradient-nan: false
[2023-07-01 11:51:11] [config] check-nan: false
[2023-07-01 11:51:11] [config] cite: false
[2023-07-01 11:51:11] [config] clip-norm: 5
[2023-07-01 11:51:11] [config] cost-scaling:
[2023-07-01 11:51:11] [config]   []
[2023-07-01 11:51:11] [config] cost-type: ce-sum
[2023-07-01 11:51:11] [config] cpu-threads: 0
[2023-07-01 11:51:11] [config] data-threads: 8
[2023-07-01 11:51:11] [config] data-weighting: ""
[2023-07-01 11:51:11] [config] data-weighting-type: sentence
[2023-07-01 11:51:11] [config] dec-cell: gru
[2023-07-01 11:51:11] [config] dec-cell-base-depth: 2
[2023-07-01 11:51:11] [config] dec-cell-high-depth: 1
[2023-07-01 11:51:11] [config] dec-depth: 2
[2023-07-01 11:51:11] [config] devices:
[2023-07-01 11:51:11] [config]   - 0
[2023-07-01 11:51:11] [config] dim-emb: 512
[2023-07-01 11:51:11] [config] dim-rnn: 1024
[2023-07-01 11:51:11] [config] dim-vocabs:
[2023-07-01 11:51:11] [config]   - 16384
[2023-07-01 11:51:11] [config]   - 16384
[2023-07-01 11:51:11] [config] disp-first: 0
[2023-07-01 11:51:11] [config] disp-freq: 1000u
[2023-07-01 11:51:11] [config] disp-label-counts: true
[2023-07-01 11:51:11] [config] dropout-rnn: 0
[2023-07-01 11:51:11] [config] dropout-src: 0
[2023-07-01 11:51:11] [config] dropout-trg: 0
[2023-07-01 11:51:11] [config] dump-config: ""
[2023-07-01 11:51:11] [config] dynamic-gradient-scaling:
[2023-07-01 11:51:11] [config]   []
[2023-07-01 11:51:11] [config] early-stopping: 10
[2023-07-01 11:51:11] [config] early-stopping-on: first
[2023-07-01 11:51:11] [config] embedding-fix-src: false
[2023-07-01 11:51:11] [config] embedding-fix-trg: false
[2023-07-01 11:51:11] [config] embedding-normalization: false
[2023-07-01 11:51:11] [config] embedding-vectors:
[2023-07-01 11:51:11] [config]   []
[2023-07-01 11:51:11] [config] enc-cell: gru
[2023-07-01 11:51:11] [config] enc-cell-depth: 1
[2023-07-01 11:51:11] [config] enc-depth: 2
[2023-07-01 11:51:11] [config] enc-type: bidirectional
[2023-07-01 11:51:11] [config] english-title-case-every: 0
[2023-07-01 11:51:11] [config] exponential-smoothing: 0.0001
[2023-07-01 11:51:11] [config] factor-weight: 1
[2023-07-01 11:51:11] [config] factors-combine: sum
[2023-07-01 11:51:11] [config] factors-dim-emb: 0
[2023-07-01 11:51:11] [config] gradient-checkpointing: false
[2023-07-01 11:51:11] [config] gradient-norm-average-window: 100
[2023-07-01 11:51:11] [config] guided-alignment: none
[2023-07-01 11:51:11] [config] guided-alignment-cost: mse
[2023-07-01 11:51:11] [config] guided-alignment-weight: 0.1
[2023-07-01 11:51:11] [config] ignore-model-config: false
[2023-07-01 11:51:11] [config] input-types:
[2023-07-01 11:51:11] [config]   []
[2023-07-01 11:51:11] [config] interpolate-env-vars: false
[2023-07-01 11:51:11] [config] keep-best: false
[2023-07-01 11:51:11] [config] label-smoothing: 0.1
[2023-07-01 11:51:11] [config] layer-normalization: false
[2023-07-01 11:51:11] [config] learn-rate: 0.0003
[2023-07-01 11:51:11] [config] lemma-dependency: ""
[2023-07-01 11:51:11] [config] lemma-dim-emb: 0
[2023-07-01 11:51:11] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:51:11] [config] log-level: info
[2023-07-01 11:51:11] [config] log-time-zone: ""
[2023-07-01 11:51:11] [config] logical-epoch:
[2023-07-01 11:51:11] [config]   - 1e
[2023-07-01 11:51:11] [config]   - 0
[2023-07-01 11:51:11] [config] lr-decay: 0
[2023-07-01 11:51:11] [config] lr-decay-freq: 50000
[2023-07-01 11:51:11] [config] lr-decay-inv-sqrt:
[2023-07-01 11:51:11] [config]   - 16000
[2023-07-01 11:51:11] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:51:11] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:51:11] [config] lr-decay-start:
[2023-07-01 11:51:11] [config]   - 10
[2023-07-01 11:51:11] [config]   - 1
[2023-07-01 11:51:11] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:51:11] [config] lr-report: true
[2023-07-01 11:51:11] [config] lr-warmup: 16000
[2023-07-01 11:51:11] [config] lr-warmup-at-reload: false
[2023-07-01 11:51:11] [config] lr-warmup-cycle: false
[2023-07-01 11:51:11] [config] lr-warmup-start-rate: 0
[2023-07-01 11:51:11] [config] max-length: 100
[2023-07-01 11:51:11] [config] max-length-crop: false
[2023-07-01 11:51:11] [config] max-length-factor: 3
[2023-07-01 11:51:11] [config] maxi-batch: 100
[2023-07-01 11:51:11] [config] maxi-batch-sort: trg
[2023-07-01 11:51:11] [config] mini-batch: 1000
[2023-07-01 11:51:11] [config] mini-batch-fit: true
[2023-07-01 11:51:11] [config] mini-batch-fit-step: 10
[2023-07-01 11:51:11] [config] mini-batch-round-up: true
[2023-07-01 11:51:11] [config] mini-batch-track-lr: false
[2023-07-01 11:51:11] [config] mini-batch-warmup: 0
[2023-07-01 11:51:11] [config] mini-batch-words: 0
[2023-07-01 11:51:11] [config] mini-batch-words-ref: 0
[2023-07-01 11:51:11] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:51:11] [config] multi-loss-type: sum
[2023-07-01 11:51:11] [config] n-best: false
[2023-07-01 11:51:11] [config] no-nccl: false
[2023-07-01 11:51:11] [config] no-reload: false
[2023-07-01 11:51:11] [config] no-restore-corpus: false
[2023-07-01 11:51:11] [config] normalize: 1
[2023-07-01 11:51:11] [config] normalize-gradient: false
[2023-07-01 11:51:11] [config] num-devices: 0
[2023-07-01 11:51:11] [config] optimizer: adam
[2023-07-01 11:51:11] [config] optimizer-delay: 1
[2023-07-01 11:51:11] [config] optimizer-params:
[2023-07-01 11:51:11] [config]   - 0.9
[2023-07-01 11:51:11] [config]   - 0.98
[2023-07-01 11:51:11] [config]   - 1e-09
[2023-07-01 11:51:11] [config] output-omit-bias: false
[2023-07-01 11:51:11] [config] overwrite: true
[2023-07-01 11:51:11] [config] precision:
[2023-07-01 11:51:11] [config]   - float32
[2023-07-01 11:51:11] [config]   - float32
[2023-07-01 11:51:11] [config] pretrained-model: ""
[2023-07-01 11:51:11] [config] quantize-biases: false
[2023-07-01 11:51:11] [config] quantize-bits: 0
[2023-07-01 11:51:11] [config] quantize-log-based: false
[2023-07-01 11:51:11] [config] quantize-optimization-steps: 0
[2023-07-01 11:51:11] [config] quiet: false
[2023-07-01 11:51:11] [config] quiet-translation: true
[2023-07-01 11:51:11] [config] relative-paths: false
[2023-07-01 11:51:11] [config] right-left: false
[2023-07-01 11:51:11] [config] save-freq: 10000u
[2023-07-01 11:51:11] [config] seed: 1234
[2023-07-01 11:51:11] [config] sentencepiece-alphas:
[2023-07-01 11:51:11] [config]   []
[2023-07-01 11:51:11] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:51:11] [config] sentencepiece-options: ""
[2023-07-01 11:51:11] [config] sharding: global
[2023-07-01 11:51:11] [config] shuffle: data
[2023-07-01 11:51:11] [config] shuffle-in-ram: false
[2023-07-01 11:51:11] [config] sigterm: save-and-exit
[2023-07-01 11:51:11] [config] skip: false
[2023-07-01 11:51:11] [config] sqlite: ""
[2023-07-01 11:51:11] [config] sqlite-drop: false
[2023-07-01 11:51:11] [config] sync-freq: 200u
[2023-07-01 11:51:11] [config] sync-sgd: true
[2023-07-01 11:51:11] [config] tempdir: /tmp
[2023-07-01 11:51:11] [config] tied-embeddings: false
[2023-07-01 11:51:11] [config] tied-embeddings-all: true
[2023-07-01 11:51:11] [config] tied-embeddings-src: false
[2023-07-01 11:51:11] [config] train-embedder-rank:
[2023-07-01 11:51:11] [config]   []
[2023-07-01 11:51:11] [config] train-sets:
[2023-07-01 11:51:11] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:51:11] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:51:11] [config] transformer-aan-activation: swish
[2023-07-01 11:51:11] [config] transformer-aan-depth: 2
[2023-07-01 11:51:11] [config] transformer-aan-nogate: false
[2023-07-01 11:51:11] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:51:11] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:51:11] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:51:11] [config] transformer-depth-scaling: false
[2023-07-01 11:51:11] [config] transformer-dim-aan: 2048
[2023-07-01 11:51:11] [config] transformer-dim-ffn: 2048
[2023-07-01 11:51:11] [config] transformer-dropout: 0.1
[2023-07-01 11:51:11] [config] transformer-dropout-attention: 0
[2023-07-01 11:51:11] [config] transformer-dropout-ffn: 0
[2023-07-01 11:51:11] [config] transformer-ffn-activation: swish
[2023-07-01 11:51:11] [config] transformer-ffn-depth: 2
[2023-07-01 11:51:11] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:51:11] [config] transformer-heads: 8
[2023-07-01 11:51:11] [config] transformer-no-projection: false
[2023-07-01 11:51:11] [config] transformer-pool: false
[2023-07-01 11:51:11] [config] transformer-postprocess: dan
[2023-07-01 11:51:11] [config] transformer-postprocess-emb: d
[2023-07-01 11:51:11] [config] transformer-postprocess-top: ""
[2023-07-01 11:51:11] [config] transformer-preprocess: ""
[2023-07-01 11:51:11] [config] transformer-tied-layers:
[2023-07-01 11:51:11] [config]   []
[2023-07-01 11:51:11] [config] transformer-train-position-embeddings: false
[2023-07-01 11:51:11] [config] tsv: false
[2023-07-01 11:51:11] [config] tsv-fields: 0
[2023-07-01 11:51:11] [config] type: transformer
[2023-07-01 11:51:11] [config] ulr: false
[2023-07-01 11:51:11] [config] ulr-dim-emb: 0
[2023-07-01 11:51:11] [config] ulr-dropout: 0
[2023-07-01 11:51:11] [config] ulr-keys-vectors: ""
[2023-07-01 11:51:11] [config] ulr-query-vectors: ""
[2023-07-01 11:51:11] [config] ulr-softmax-temperature: 1
[2023-07-01 11:51:11] [config] ulr-trainable-transformation: false
[2023-07-01 11:51:11] [config] unlikelihood-loss: false
[2023-07-01 11:51:11] [config] valid-freq: 50000000
[2023-07-01 11:51:11] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:51:11] [config] valid-max-length: 1000
[2023-07-01 11:51:11] [config] valid-metrics:
[2023-07-01 11:51:11] [config]   - cross-entropy
[2023-07-01 11:51:11] [config]   - translation
[2023-07-01 11:51:11] [config] valid-mini-batch: 64
[2023-07-01 11:51:11] [config] valid-reset-stalled: false
[2023-07-01 11:51:11] [config] valid-script-args:
[2023-07-01 11:51:11] [config]   []
[2023-07-01 11:51:11] [config] valid-script-path: ""
[2023-07-01 11:51:11] [config] valid-sets:
[2023-07-01 11:51:11] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:51:11] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:51:11] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:51:11] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:51:11] [config] vocabs:
[2023-07-01 11:51:11] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:51:11] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:51:11] [config] word-penalty: 0
[2023-07-01 11:51:11] [config] word-scores: false
[2023-07-01 11:51:11] [config] workspace: 2048
[2023-07-01 11:51:11] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:51:11] Using synchronous SGD
[2023-07-01 11:51:11] Synced seed 1234
[2023-07-01 11:51:11] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:51:11] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:51:11] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:51:11] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:51:11] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:51:11] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:51:12] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:51:12] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:51:12] [comm] Using global sharding
[2023-07-01 11:51:12] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:51:12] [training] Using 1 GPUs
[2023-07-01 11:51:12] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:51:12] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:51:12] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:51:13] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:51:20] [batching] Done. Typical MB size is 4,592 target words
[2023-07-01 11:51:20] [valid] No post-processing script given for validating translator
[2023-07-01 11:51:20] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:51:20] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:51:20] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:51:20] [comm] Using global sharding
[2023-07-01 11:51:20] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:51:20] [training] Using 1 GPUs
[2023-07-01 11:51:20] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:51:21] Allocating memory for general optimizer shards
[2023-07-01 11:51:21] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:51:21] Loading Adam parameters
[2023-07-01 11:51:21] [memory] Reserving 176 MB, device gpu0
[2023-07-01 11:51:21] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:51:21] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz.optimizer.npz
[2023-07-01 11:51:21] [data] Restoring the corpus state to epoch 53, batch 9828
[2023-07-01 11:51:21] [data] Shuffling data
[2023-07-01 11:51:21] [data] Done reading 20,192 sentences
[2023-07-01 11:51:21] [data] Done shuffling 20,192 sentences to temp files
[2023-07-01 11:51:21] Training started
[2023-07-01 11:51:21] Training finished
[2023-07-01 11:51:24] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:51:24] [marian] Running on node20.datos.cluster.uy as process 22470 with command line:
[2023-07-01 11:51:24] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz --after-epochs 188 --valid-freq 50000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm --seed 1234 --type transformer --cpu-threads 0 --log /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log --valid-log /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt --quiet-translation --overwrite --max-length 100 --mini-batch-fit --mini-batch 1000 --beam-size 12 --normalize 1 --valid-mini-batch 64 --enc-depth 2 --dec-depth 2 --transformer-heads 8 --transformer-postprocess-emb d --transformer-postprocess dan --transformer-dropout 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --lr-report --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --tied-embeddings-all --exponential-smoothing --sync-sgd
[2023-07-01 11:51:24] [config] after: 0e
[2023-07-01 11:51:24] [config] after-batches: 0
[2023-07-01 11:51:24] [config] after-epochs: 188
[2023-07-01 11:51:24] [config] all-caps-every: 0
[2023-07-01 11:51:24] [config] allow-unk: false
[2023-07-01 11:51:24] [config] authors: false
[2023-07-01 11:51:24] [config] beam-size: 12
[2023-07-01 11:51:24] [config] bert-class-symbol: "[CLS]"
[2023-07-01 11:51:24] [config] bert-mask-symbol: "[MASK]"
[2023-07-01 11:51:24] [config] bert-masking-fraction: 0.15
[2023-07-01 11:51:24] [config] bert-sep-symbol: "[SEP]"
[2023-07-01 11:51:24] [config] bert-train-type-embeddings: true
[2023-07-01 11:51:24] [config] bert-type-vocab-size: 2
[2023-07-01 11:51:24] [config] build-info: ""
[2023-07-01 11:51:24] [config] check-gradient-nan: false
[2023-07-01 11:51:24] [config] check-nan: false
[2023-07-01 11:51:24] [config] cite: false
[2023-07-01 11:51:24] [config] clip-norm: 5
[2023-07-01 11:51:24] [config] cost-scaling:
[2023-07-01 11:51:24] [config]   []
[2023-07-01 11:51:24] [config] cost-type: ce-sum
[2023-07-01 11:51:24] [config] cpu-threads: 0
[2023-07-01 11:51:24] [config] data-threads: 8
[2023-07-01 11:51:24] [config] data-weighting: ""
[2023-07-01 11:51:24] [config] data-weighting-type: sentence
[2023-07-01 11:51:24] [config] dec-cell: gru
[2023-07-01 11:51:24] [config] dec-cell-base-depth: 2
[2023-07-01 11:51:24] [config] dec-cell-high-depth: 1
[2023-07-01 11:51:24] [config] dec-depth: 2
[2023-07-01 11:51:24] [config] devices:
[2023-07-01 11:51:24] [config]   - 0
[2023-07-01 11:51:24] [config] dim-emb: 512
[2023-07-01 11:51:24] [config] dim-rnn: 1024
[2023-07-01 11:51:24] [config] dim-vocabs:
[2023-07-01 11:51:24] [config]   - 16384
[2023-07-01 11:51:24] [config]   - 16384
[2023-07-01 11:51:24] [config] disp-first: 0
[2023-07-01 11:51:24] [config] disp-freq: 1000u
[2023-07-01 11:51:24] [config] disp-label-counts: true
[2023-07-01 11:51:24] [config] dropout-rnn: 0
[2023-07-01 11:51:24] [config] dropout-src: 0
[2023-07-01 11:51:24] [config] dropout-trg: 0
[2023-07-01 11:51:24] [config] dump-config: ""
[2023-07-01 11:51:24] [config] dynamic-gradient-scaling:
[2023-07-01 11:51:24] [config]   []
[2023-07-01 11:51:24] [config] early-stopping: 10
[2023-07-01 11:51:24] [config] early-stopping-on: first
[2023-07-01 11:51:24] [config] embedding-fix-src: false
[2023-07-01 11:51:24] [config] embedding-fix-trg: false
[2023-07-01 11:51:24] [config] embedding-normalization: false
[2023-07-01 11:51:24] [config] embedding-vectors:
[2023-07-01 11:51:24] [config]   []
[2023-07-01 11:51:24] [config] enc-cell: gru
[2023-07-01 11:51:24] [config] enc-cell-depth: 1
[2023-07-01 11:51:24] [config] enc-depth: 2
[2023-07-01 11:51:24] [config] enc-type: bidirectional
[2023-07-01 11:51:24] [config] english-title-case-every: 0
[2023-07-01 11:51:24] [config] exponential-smoothing: 0.0001
[2023-07-01 11:51:24] [config] factor-weight: 1
[2023-07-01 11:51:24] [config] factors-combine: sum
[2023-07-01 11:51:24] [config] factors-dim-emb: 0
[2023-07-01 11:51:24] [config] gradient-checkpointing: false
[2023-07-01 11:51:24] [config] gradient-norm-average-window: 100
[2023-07-01 11:51:24] [config] guided-alignment: none
[2023-07-01 11:51:24] [config] guided-alignment-cost: mse
[2023-07-01 11:51:24] [config] guided-alignment-weight: 0.1
[2023-07-01 11:51:24] [config] ignore-model-config: false
[2023-07-01 11:51:24] [config] input-types:
[2023-07-01 11:51:24] [config]   []
[2023-07-01 11:51:24] [config] interpolate-env-vars: false
[2023-07-01 11:51:24] [config] keep-best: false
[2023-07-01 11:51:24] [config] label-smoothing: 0.1
[2023-07-01 11:51:24] [config] layer-normalization: false
[2023-07-01 11:51:24] [config] learn-rate: 0.0003
[2023-07-01 11:51:24] [config] lemma-dependency: ""
[2023-07-01 11:51:24] [config] lemma-dim-emb: 0
[2023-07-01 11:51:24] [config] log: /docker/home/marianmt/logs/marian/log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:51:24] [config] log-level: info
[2023-07-01 11:51:24] [config] log-time-zone: ""
[2023-07-01 11:51:24] [config] logical-epoch:
[2023-07-01 11:51:24] [config]   - 1e
[2023-07-01 11:51:24] [config]   - 0
[2023-07-01 11:51:24] [config] lr-decay: 0
[2023-07-01 11:51:24] [config] lr-decay-freq: 50000
[2023-07-01 11:51:24] [config] lr-decay-inv-sqrt:
[2023-07-01 11:51:24] [config]   - 16000
[2023-07-01 11:51:24] [config] lr-decay-repeat-warmup: false
[2023-07-01 11:51:24] [config] lr-decay-reset-optimizer: false
[2023-07-01 11:51:24] [config] lr-decay-start:
[2023-07-01 11:51:24] [config]   - 10
[2023-07-01 11:51:24] [config]   - 1
[2023-07-01 11:51:24] [config] lr-decay-strategy: epoch+stalled
[2023-07-01 11:51:24] [config] lr-report: true
[2023-07-01 11:51:24] [config] lr-warmup: 16000
[2023-07-01 11:51:24] [config] lr-warmup-at-reload: false
[2023-07-01 11:51:24] [config] lr-warmup-cycle: false
[2023-07-01 11:51:24] [config] lr-warmup-start-rate: 0
[2023-07-01 11:51:24] [config] max-length: 100
[2023-07-01 11:51:24] [config] max-length-crop: false
[2023-07-01 11:51:24] [config] max-length-factor: 3
[2023-07-01 11:51:24] [config] maxi-batch: 100
[2023-07-01 11:51:24] [config] maxi-batch-sort: trg
[2023-07-01 11:51:24] [config] mini-batch: 1000
[2023-07-01 11:51:24] [config] mini-batch-fit: true
[2023-07-01 11:51:24] [config] mini-batch-fit-step: 10
[2023-07-01 11:51:24] [config] mini-batch-round-up: true
[2023-07-01 11:51:24] [config] mini-batch-track-lr: false
[2023-07-01 11:51:24] [config] mini-batch-warmup: 0
[2023-07-01 11:51:24] [config] mini-batch-words: 0
[2023-07-01 11:51:24] [config] mini-batch-words-ref: 0
[2023-07-01 11:51:24] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_scored_june_transformer_example_depth2/gn_es_scored_june_transformer_example_depth2.npz
[2023-07-01 11:51:24] [config] multi-loss-type: sum
[2023-07-01 11:51:24] [config] n-best: false
[2023-07-01 11:51:24] [config] no-nccl: false
[2023-07-01 11:51:24] [config] no-reload: false
[2023-07-01 11:51:24] [config] no-restore-corpus: false
[2023-07-01 11:51:24] [config] normalize: 1
[2023-07-01 11:51:24] [config] normalize-gradient: false
[2023-07-01 11:51:24] [config] num-devices: 0
[2023-07-01 11:51:24] [config] optimizer: adam
[2023-07-01 11:51:24] [config] optimizer-delay: 1
[2023-07-01 11:51:24] [config] optimizer-params:
[2023-07-01 11:51:24] [config]   - 0.9
[2023-07-01 11:51:24] [config]   - 0.98
[2023-07-01 11:51:24] [config]   - 1e-09
[2023-07-01 11:51:24] [config] output-omit-bias: false
[2023-07-01 11:51:24] [config] overwrite: true
[2023-07-01 11:51:24] [config] precision:
[2023-07-01 11:51:24] [config]   - float32
[2023-07-01 11:51:24] [config]   - float32
[2023-07-01 11:51:24] [config] pretrained-model: ""
[2023-07-01 11:51:24] [config] quantize-biases: false
[2023-07-01 11:51:24] [config] quantize-bits: 0
[2023-07-01 11:51:24] [config] quantize-log-based: false
[2023-07-01 11:51:24] [config] quantize-optimization-steps: 0
[2023-07-01 11:51:24] [config] quiet: false
[2023-07-01 11:51:24] [config] quiet-translation: true
[2023-07-01 11:51:24] [config] relative-paths: false
[2023-07-01 11:51:24] [config] right-left: false
[2023-07-01 11:51:24] [config] save-freq: 10000u
[2023-07-01 11:51:24] [config] seed: 1234
[2023-07-01 11:51:24] [config] sentencepiece-alphas:
[2023-07-01 11:51:24] [config]   []
[2023-07-01 11:51:24] [config] sentencepiece-max-lines: 2000000
[2023-07-01 11:51:24] [config] sentencepiece-options: ""
[2023-07-01 11:51:24] [config] sharding: global
[2023-07-01 11:51:24] [config] shuffle: data
[2023-07-01 11:51:24] [config] shuffle-in-ram: false
[2023-07-01 11:51:24] [config] sigterm: save-and-exit
[2023-07-01 11:51:24] [config] skip: false
[2023-07-01 11:51:24] [config] sqlite: ""
[2023-07-01 11:51:24] [config] sqlite-drop: false
[2023-07-01 11:51:24] [config] sync-freq: 200u
[2023-07-01 11:51:24] [config] sync-sgd: true
[2023-07-01 11:51:24] [config] tempdir: /tmp
[2023-07-01 11:51:24] [config] tied-embeddings: false
[2023-07-01 11:51:24] [config] tied-embeddings-all: true
[2023-07-01 11:51:24] [config] tied-embeddings-src: false
[2023-07-01 11:51:24] [config] train-embedder-rank:
[2023-07-01 11:51:24] [config]   []
[2023-07-01 11:51:24] [config] train-sets:
[2023-07-01 11:51:24] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-07-01 11:51:24] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-07-01 11:51:24] [config] transformer-aan-activation: swish
[2023-07-01 11:51:24] [config] transformer-aan-depth: 2
[2023-07-01 11:51:24] [config] transformer-aan-nogate: false
[2023-07-01 11:51:24] [config] transformer-decoder-autoreg: self-attention
[2023-07-01 11:51:24] [config] transformer-decoder-dim-ffn: 0
[2023-07-01 11:51:24] [config] transformer-decoder-ffn-depth: 0
[2023-07-01 11:51:24] [config] transformer-depth-scaling: false
[2023-07-01 11:51:24] [config] transformer-dim-aan: 2048
[2023-07-01 11:51:24] [config] transformer-dim-ffn: 2048
[2023-07-01 11:51:24] [config] transformer-dropout: 0.1
[2023-07-01 11:51:24] [config] transformer-dropout-attention: 0
[2023-07-01 11:51:24] [config] transformer-dropout-ffn: 0
[2023-07-01 11:51:24] [config] transformer-ffn-activation: swish
[2023-07-01 11:51:24] [config] transformer-ffn-depth: 2
[2023-07-01 11:51:24] [config] transformer-guided-alignment-layer: last
[2023-07-01 11:51:24] [config] transformer-heads: 8
[2023-07-01 11:51:24] [config] transformer-no-projection: false
[2023-07-01 11:51:24] [config] transformer-pool: false
[2023-07-01 11:51:24] [config] transformer-postprocess: dan
[2023-07-01 11:51:24] [config] transformer-postprocess-emb: d
[2023-07-01 11:51:24] [config] transformer-postprocess-top: ""
[2023-07-01 11:51:24] [config] transformer-preprocess: ""
[2023-07-01 11:51:24] [config] transformer-tied-layers:
[2023-07-01 11:51:24] [config]   []
[2023-07-01 11:51:24] [config] transformer-train-position-embeddings: false
[2023-07-01 11:51:24] [config] tsv: false
[2023-07-01 11:51:24] [config] tsv-fields: 0
[2023-07-01 11:51:24] [config] type: transformer
[2023-07-01 11:51:24] [config] ulr: false
[2023-07-01 11:51:24] [config] ulr-dim-emb: 0
[2023-07-01 11:51:24] [config] ulr-dropout: 0
[2023-07-01 11:51:24] [config] ulr-keys-vectors: ""
[2023-07-01 11:51:24] [config] ulr-query-vectors: ""
[2023-07-01 11:51:24] [config] ulr-softmax-temperature: 1
[2023-07-01 11:51:24] [config] ulr-trainable-transformation: false
[2023-07-01 11:51:24] [config] unlikelihood-loss: false
[2023-07-01 11:51:24] [config] valid-freq: 50000000
[2023-07-01 11:51:24] [config] valid-log: /docker/home/marianmt/logs/marian/valid_log_gn_es_scored_june_transformer_example_depth2.log
[2023-07-01 11:51:24] [config] valid-max-length: 1000
[2023-07-01 11:51:24] [config] valid-metrics:
[2023-07-01 11:51:24] [config]   - cross-entropy
[2023-07-01 11:51:24] [config]   - translation
[2023-07-01 11:51:24] [config] valid-mini-batch: 64
[2023-07-01 11:51:24] [config] valid-reset-stalled: false
[2023-07-01 11:51:24] [config] valid-script-args:
[2023-07-01 11:51:24] [config]   []
[2023-07-01 11:51:24] [config] valid-script-path: ""
[2023-07-01 11:51:24] [config] valid-sets:
[2023-07-01 11:51:24] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-07-01 11:51:24] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-07-01 11:51:24] [config] valid-translation-output: /docker/home/marianmt/evaluation/decoded-transformer-example-gn-es.txt
[2023-07-01 11:51:24] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:51:24] [config] vocabs:
[2023-07-01 11:51:24] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:51:24] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:51:24] [config] word-penalty: 0
[2023-07-01 11:51:24] [config] word-scores: false
[2023-07-01 11:51:24] [config] workspace: 2048
[2023-07-01 11:51:24] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-07-01 11:51:24] Using synchronous SGD
[2023-07-01 11:51:25] Synced seed 1234
[2023-07-01 11:51:25] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens16.txt.gn.spm
[2023-07-01 11:51:25] [data] Setting vocabulary size for input 0 to 16,384
[2023-07-01 11:51:25] [data] Loading SentencePiece vocabulary from file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens16.txt.es.spm
[2023-07-01 11:51:25] [data] Setting vocabulary size for input 1 to 16,384
[2023-07-01 11:51:25] [batching] Collecting statistics for batch fitting with step size 10
[2023-07-01 11:51:25] [MPI rank 0 out of 1]: GPU[0]
[2023-07-01 11:51:25] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-07-01 11:51:25] [comm] Using NCCL 2.8.3 for GPU communication
[2023-07-01 11:51:25] [comm] Using global sharding
[2023-07-01 11:51:26] [comm] NCCLCommunicators constructed successfully
[2023-07-01 11:51:26] [training] Using 1 GPUs
[2023-07-01 11:51:26] [logits] Applying loss function for 1 factor(s)
[2023-07-01 11:51:26] [memory] Reserving 88 MB, device gpu0
[2023-07-01 11:51:26] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-07-01 11:51:26] [memory] Reserving 88 MB, device gpu0
