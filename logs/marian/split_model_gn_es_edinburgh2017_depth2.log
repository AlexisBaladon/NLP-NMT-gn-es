[2023-06-25 08:13:09] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-06-25 08:13:09] [marian] Running on node07.datos.cluster.uy as process 12894 with command line:
[2023-06-25 08:13:09] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz --after-epochs 10 --valid-freq 5000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens.txt.gn /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens.txt.es --seed 1234 --type s2s --max-length 100 --mini-batch-fit --mini-batch 1000 --maxi-batch 1000 --beam-size 12 --normalize 1 --cost-type ce-mean-words --enc-type bidirectional --enc-depth 2 --enc-cell-depth 4 --dec-depth 2 --dec-cell-base-depth 8 --dec-cell-high-depth 1 --layer-normalization --dropout-rnn 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-decay-inv-sqrt 16000 --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --sync-sgd --exponential-smoothing --cpu-threads 0 --log /docker/home/marianmt/logs/marian/split_model_gn_es_edinburgh2017_depth2.log --valid-log /docker/home/marianmt/logs/marian/split_tok_150_gn_es_edinburgh2017_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/model-epochs.txt --quiet-translation
[2023-06-25 08:13:09] [config] after: 0e
[2023-06-25 08:13:09] [config] after-batches: 0
[2023-06-25 08:13:09] [config] after-epochs: 10
[2023-06-25 08:13:09] [config] all-caps-every: 0
[2023-06-25 08:13:09] [config] allow-unk: false
[2023-06-25 08:13:09] [config] authors: false
[2023-06-25 08:13:09] [config] beam-size: 12
[2023-06-25 08:13:09] [config] bert-class-symbol: "[CLS]"
[2023-06-25 08:13:09] [config] bert-mask-symbol: "[MASK]"
[2023-06-25 08:13:09] [config] bert-masking-fraction: 0.15
[2023-06-25 08:13:09] [config] bert-sep-symbol: "[SEP]"
[2023-06-25 08:13:09] [config] bert-train-type-embeddings: true
[2023-06-25 08:13:09] [config] bert-type-vocab-size: 2
[2023-06-25 08:13:09] [config] build-info: ""
[2023-06-25 08:13:09] [config] check-gradient-nan: false
[2023-06-25 08:13:09] [config] check-nan: false
[2023-06-25 08:13:09] [config] cite: false
[2023-06-25 08:13:09] [config] clip-norm: 5
[2023-06-25 08:13:09] [config] cost-scaling:
[2023-06-25 08:13:09] [config]   []
[2023-06-25 08:13:09] [config] cost-type: ce-mean-words
[2023-06-25 08:13:09] [config] cpu-threads: 0
[2023-06-25 08:13:09] [config] data-threads: 8
[2023-06-25 08:13:09] [config] data-weighting: ""
[2023-06-25 08:13:09] [config] data-weighting-type: sentence
[2023-06-25 08:13:09] [config] dec-cell: gru
[2023-06-25 08:13:09] [config] dec-cell-base-depth: 8
[2023-06-25 08:13:09] [config] dec-cell-high-depth: 1
[2023-06-25 08:13:09] [config] dec-depth: 2
[2023-06-25 08:13:09] [config] devices:
[2023-06-25 08:13:09] [config]   - 0
[2023-06-25 08:13:09] [config] dim-emb: 512
[2023-06-25 08:13:09] [config] dim-rnn: 1024
[2023-06-25 08:13:09] [config] dim-vocabs:
[2023-06-25 08:13:09] [config]   - 0
[2023-06-25 08:13:09] [config]   - 0
[2023-06-25 08:13:09] [config] disp-first: 0
[2023-06-25 08:13:09] [config] disp-freq: 1000u
[2023-06-25 08:13:09] [config] disp-label-counts: true
[2023-06-25 08:13:09] [config] dropout-rnn: 0.1
[2023-06-25 08:13:09] [config] dropout-src: 0
[2023-06-25 08:13:09] [config] dropout-trg: 0
[2023-06-25 08:13:09] [config] dump-config: ""
[2023-06-25 08:13:09] [config] dynamic-gradient-scaling:
[2023-06-25 08:13:09] [config]   []
[2023-06-25 08:13:09] [config] early-stopping: 10
[2023-06-25 08:13:09] [config] early-stopping-on: first
[2023-06-25 08:13:09] [config] embedding-fix-src: false
[2023-06-25 08:13:09] [config] embedding-fix-trg: false
[2023-06-25 08:13:09] [config] embedding-normalization: false
[2023-06-25 08:13:09] [config] embedding-vectors:
[2023-06-25 08:13:09] [config]   []
[2023-06-25 08:13:09] [config] enc-cell: gru
[2023-06-25 08:13:09] [config] enc-cell-depth: 4
[2023-06-25 08:13:09] [config] enc-depth: 2
[2023-06-25 08:13:09] [config] enc-type: bidirectional
[2023-06-25 08:13:09] [config] english-title-case-every: 0
[2023-06-25 08:13:09] [config] exponential-smoothing: 0.0001
[2023-06-25 08:13:09] [config] factor-weight: 1
[2023-06-25 08:13:09] [config] factors-combine: sum
[2023-06-25 08:13:09] [config] factors-dim-emb: 0
[2023-06-25 08:13:09] [config] gradient-checkpointing: false
[2023-06-25 08:13:09] [config] gradient-norm-average-window: 100
[2023-06-25 08:13:09] [config] guided-alignment: none
[2023-06-25 08:13:09] [config] guided-alignment-cost: mse
[2023-06-25 08:13:09] [config] guided-alignment-weight: 0.1
[2023-06-25 08:13:09] [config] ignore-model-config: false
[2023-06-25 08:13:09] [config] input-types:
[2023-06-25 08:13:09] [config]   []
[2023-06-25 08:13:09] [config] interpolate-env-vars: false
[2023-06-25 08:13:09] [config] keep-best: false
[2023-06-25 08:13:09] [config] label-smoothing: 0.1
[2023-06-25 08:13:09] [config] layer-normalization: true
[2023-06-25 08:13:09] [config] learn-rate: 0.0003
[2023-06-25 08:13:09] [config] lemma-dependency: ""
[2023-06-25 08:13:09] [config] lemma-dim-emb: 0
[2023-06-25 08:13:09] [config] log: /docker/home/marianmt/logs/marian/split_model_gn_es_edinburgh2017_depth2.log
[2023-06-25 08:13:09] [config] log-level: info
[2023-06-25 08:13:09] [config] log-time-zone: ""
[2023-06-25 08:13:09] [config] logical-epoch:
[2023-06-25 08:13:09] [config]   - 1e
[2023-06-25 08:13:09] [config]   - 0
[2023-06-25 08:13:09] [config] lr-decay: 0
[2023-06-25 08:13:09] [config] lr-decay-freq: 50000
[2023-06-25 08:13:09] [config] lr-decay-inv-sqrt:
[2023-06-25 08:13:09] [config]   - 16000
[2023-06-25 08:13:09] [config] lr-decay-repeat-warmup: false
[2023-06-25 08:13:09] [config] lr-decay-reset-optimizer: false
[2023-06-25 08:13:09] [config] lr-decay-start:
[2023-06-25 08:13:09] [config]   - 10
[2023-06-25 08:13:09] [config]   - 1
[2023-06-25 08:13:09] [config] lr-decay-strategy: epoch+stalled
[2023-06-25 08:13:09] [config] lr-report: false
[2023-06-25 08:13:09] [config] lr-warmup: 0
[2023-06-25 08:13:09] [config] lr-warmup-at-reload: false
[2023-06-25 08:13:09] [config] lr-warmup-cycle: false
[2023-06-25 08:13:09] [config] lr-warmup-start-rate: 0
[2023-06-25 08:13:09] [config] max-length: 100
[2023-06-25 08:13:09] [config] max-length-crop: false
[2023-06-25 08:13:09] [config] max-length-factor: 3
[2023-06-25 08:13:09] [config] maxi-batch: 1000
[2023-06-25 08:13:09] [config] maxi-batch-sort: trg
[2023-06-25 08:13:09] [config] mini-batch: 1000
[2023-06-25 08:13:09] [config] mini-batch-fit: true
[2023-06-25 08:13:09] [config] mini-batch-fit-step: 10
[2023-06-25 08:13:09] [config] mini-batch-round-up: true
[2023-06-25 08:13:09] [config] mini-batch-track-lr: false
[2023-06-25 08:13:09] [config] mini-batch-warmup: 0
[2023-06-25 08:13:09] [config] mini-batch-words: 0
[2023-06-25 08:13:09] [config] mini-batch-words-ref: 0
[2023-06-25 08:13:09] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz
[2023-06-25 08:13:09] [config] multi-loss-type: sum
[2023-06-25 08:13:09] [config] n-best: false
[2023-06-25 08:13:09] [config] no-nccl: false
[2023-06-25 08:13:09] [config] no-reload: false
[2023-06-25 08:13:09] [config] no-restore-corpus: false
[2023-06-25 08:13:09] [config] normalize: 1
[2023-06-25 08:13:09] [config] normalize-gradient: false
[2023-06-25 08:13:09] [config] num-devices: 0
[2023-06-25 08:13:09] [config] optimizer: adam
[2023-06-25 08:13:09] [config] optimizer-delay: 1
[2023-06-25 08:13:09] [config] optimizer-params:
[2023-06-25 08:13:09] [config]   - 0.9
[2023-06-25 08:13:09] [config]   - 0.98
[2023-06-25 08:13:09] [config]   - 1e-09
[2023-06-25 08:13:09] [config] output-omit-bias: false
[2023-06-25 08:13:09] [config] overwrite: false
[2023-06-25 08:13:09] [config] precision:
[2023-06-25 08:13:09] [config]   - float32
[2023-06-25 08:13:09] [config]   - float32
[2023-06-25 08:13:09] [config] pretrained-model: ""
[2023-06-25 08:13:09] [config] quantize-biases: false
[2023-06-25 08:13:09] [config] quantize-bits: 0
[2023-06-25 08:13:09] [config] quantize-log-based: false
[2023-06-25 08:13:09] [config] quantize-optimization-steps: 0
[2023-06-25 08:13:09] [config] quiet: false
[2023-06-25 08:13:09] [config] quiet-translation: true
[2023-06-25 08:13:09] [config] relative-paths: false
[2023-06-25 08:13:09] [config] right-left: false
[2023-06-25 08:13:09] [config] save-freq: 10000u
[2023-06-25 08:13:09] [config] seed: 1234
[2023-06-25 08:13:09] [config] sentencepiece-alphas:
[2023-06-25 08:13:09] [config]   []
[2023-06-25 08:13:09] [config] sentencepiece-max-lines: 2000000
[2023-06-25 08:13:09] [config] sentencepiece-options: ""
[2023-06-25 08:13:09] [config] sharding: global
[2023-06-25 08:13:09] [config] shuffle: data
[2023-06-25 08:13:09] [config] shuffle-in-ram: false
[2023-06-25 08:13:09] [config] sigterm: save-and-exit
[2023-06-25 08:13:09] [config] skip: false
[2023-06-25 08:13:09] [config] sqlite: ""
[2023-06-25 08:13:09] [config] sqlite-drop: false
[2023-06-25 08:13:09] [config] sync-freq: 200u
[2023-06-25 08:13:09] [config] sync-sgd: true
[2023-06-25 08:13:09] [config] tempdir: /tmp
[2023-06-25 08:13:09] [config] tied-embeddings: false
[2023-06-25 08:13:09] [config] tied-embeddings-all: false
[2023-06-25 08:13:09] [config] tied-embeddings-src: false
[2023-06-25 08:13:09] [config] train-embedder-rank:
[2023-06-25 08:13:09] [config]   []
[2023-06-25 08:13:09] [config] train-sets:
[2023-06-25 08:13:09] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-06-25 08:13:09] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-06-25 08:13:09] [config] transformer-aan-activation: swish
[2023-06-25 08:13:09] [config] transformer-aan-depth: 2
[2023-06-25 08:13:09] [config] transformer-aan-nogate: false
[2023-06-25 08:13:09] [config] transformer-decoder-autoreg: self-attention
[2023-06-25 08:13:09] [config] transformer-decoder-dim-ffn: 0
[2023-06-25 08:13:09] [config] transformer-decoder-ffn-depth: 0
[2023-06-25 08:13:09] [config] transformer-depth-scaling: false
[2023-06-25 08:13:09] [config] transformer-dim-aan: 2048
[2023-06-25 08:13:09] [config] transformer-dim-ffn: 2048
[2023-06-25 08:13:09] [config] transformer-dropout: 0
[2023-06-25 08:13:09] [config] transformer-dropout-attention: 0
[2023-06-25 08:13:09] [config] transformer-dropout-ffn: 0
[2023-06-25 08:13:09] [config] transformer-ffn-activation: swish
[2023-06-25 08:13:09] [config] transformer-ffn-depth: 2
[2023-06-25 08:13:09] [config] transformer-guided-alignment-layer: last
[2023-06-25 08:13:09] [config] transformer-heads: 8
[2023-06-25 08:13:09] [config] transformer-no-projection: false
[2023-06-25 08:13:09] [config] transformer-pool: false
[2023-06-25 08:13:09] [config] transformer-postprocess: dan
[2023-06-25 08:13:09] [config] transformer-postprocess-emb: d
[2023-06-25 08:13:09] [config] transformer-postprocess-top: ""
[2023-06-25 08:13:09] [config] transformer-preprocess: ""
[2023-06-25 08:13:09] [config] transformer-tied-layers:
[2023-06-25 08:13:09] [config]   []
[2023-06-25 08:13:09] [config] transformer-train-position-embeddings: false
[2023-06-25 08:13:09] [config] tsv: false
[2023-06-25 08:13:09] [config] tsv-fields: 0
[2023-06-25 08:13:09] [config] type: s2s
[2023-06-25 08:13:09] [config] ulr: false
[2023-06-25 08:13:09] [config] ulr-dim-emb: 0
[2023-06-25 08:13:09] [config] ulr-dropout: 0
[2023-06-25 08:13:09] [config] ulr-keys-vectors: ""
[2023-06-25 08:13:09] [config] ulr-query-vectors: ""
[2023-06-25 08:13:09] [config] ulr-softmax-temperature: 1
[2023-06-25 08:13:09] [config] ulr-trainable-transformation: false
[2023-06-25 08:13:09] [config] unlikelihood-loss: false
[2023-06-25 08:13:09] [config] valid-freq: 5000000
[2023-06-25 08:13:09] [config] valid-log: /docker/home/marianmt/logs/marian/split_tok_150_gn_es_edinburgh2017_depth2.log
[2023-06-25 08:13:09] [config] valid-max-length: 1000
[2023-06-25 08:13:09] [config] valid-metrics:
[2023-06-25 08:13:09] [config]   - cross-entropy
[2023-06-25 08:13:09] [config]   - translation
[2023-06-25 08:13:09] [config] valid-mini-batch: 32
[2023-06-25 08:13:09] [config] valid-reset-stalled: false
[2023-06-25 08:13:09] [config] valid-script-args:
[2023-06-25 08:13:09] [config]   []
[2023-06-25 08:13:09] [config] valid-script-path: ""
[2023-06-25 08:13:09] [config] valid-sets:
[2023-06-25 08:13:09] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-06-25 08:13:09] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-06-25 08:13:09] [config] valid-translation-output: /docker/home/marianmt/evaluation/model-epochs.txt
[2023-06-25 08:13:09] [config] vocabs:
[2023-06-25 08:13:09] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens.txt.gn
[2023-06-25 08:13:09] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens.txt.es
[2023-06-25 08:13:09] [config] word-penalty: 0
[2023-06-25 08:13:09] [config] word-scores: false
[2023-06-25 08:13:09] [config] workspace: 2048
[2023-06-25 08:13:09] [config] Model is being created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-06-25 08:13:09] Using synchronous SGD
[2023-06-25 08:13:10] Synced seed 1234
[2023-06-25 08:13:10] [data] Loading vocabulary from text file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens.txt.gn
[2023-06-25 08:13:10] [data] Setting vocabulary size for input 0 to 54,042
[2023-06-25 08:13:10] [data] Loading vocabulary from text file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens.txt.es
[2023-06-25 08:13:10] [data] Setting vocabulary size for input 1 to 36,507
[2023-06-25 08:13:10] [batching] Collecting statistics for batch fitting with step size 10
[2023-06-25 08:13:10] [MPI rank 0 out of 1]: GPU[0]
[2023-06-25 08:13:11] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-06-25 08:13:12] [comm] Using NCCL 2.8.3 for GPU communication
[2023-06-25 08:13:12] [comm] Using global sharding
[2023-06-25 08:13:12] [comm] NCCLCommunicators constructed successfully
[2023-06-25 08:13:12] [training] Using 1 GPUs
[2023-06-25 08:13:12] [logits] Applying loss function for 1 factor(s)
[2023-06-25 08:13:12] [memory] Reserving 666 MB, device gpu0
[2023-06-25 08:13:15] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-06-25 08:13:16] [memory] Reserving 666 MB, device gpu0
[2023-06-25 08:13:40] [batching] Done. Typical MB size is 1,196 target words
[2023-06-25 08:13:40] [valid] No post-processing script given for validating translator
[2023-06-25 08:13:40] [MPI rank 0 out of 1]: GPU[0]
[2023-06-25 08:13:40] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-06-25 08:13:40] [comm] Using NCCL 2.8.3 for GPU communication
[2023-06-25 08:13:40] [comm] Using global sharding
[2023-06-25 08:13:40] [comm] NCCLCommunicators constructed successfully
[2023-06-25 08:13:40] [training] Using 1 GPUs
[2023-06-25 08:13:40] Training started
[2023-06-25 08:13:40] [data] Shuffling data
[2023-06-25 08:13:40] [data] Done reading 20,192 sentences
[2023-06-25 08:13:40] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 08:13:40] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-06-25 08:13:40] [memory] Reserving 666 MB, device gpu0
[2023-06-25 08:13:40] [memory] Reserving 666 MB, device gpu0
[2023-06-25 08:13:41] Parameter type float32, optimization type float32, casting types false
[2023-06-25 08:13:41] Allocating memory for general optimizer shards
[2023-06-25 08:13:41] [memory] Reserving 666 MB, device gpu0
[2023-06-25 08:13:41] Allocating memory for Adam-specific shards
[2023-06-25 08:13:41] [memory] Reserving 1332 MB, device gpu0
[2023-06-25 08:17:01] Seen 20,177 samples
[2023-06-25 08:17:01] Starting data epoch 2 in logical epoch 2
[2023-06-25 08:17:01] [data] Shuffling data
[2023-06-25 08:17:01] [data] Done reading 20,192 sentences
[2023-06-25 08:17:01] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 08:20:31] Seen 20,177 samples
[2023-06-25 08:20:31] Starting data epoch 3 in logical epoch 3
[2023-06-25 08:20:31] [data] Shuffling data
[2023-06-25 08:20:31] [data] Done reading 20,192 sentences
[2023-06-25 08:20:31] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 08:20:41] Ep. 3 : Up. 1000 : Sen. 1,015 : Cost 6.10097933 : Time 420.95s : 2319.22 words/s : gNorm 0.8678
[2023-06-25 08:24:03] Seen 20,177 samples
[2023-06-25 08:24:03] Starting data epoch 4 in logical epoch 4
[2023-06-25 08:24:03] [data] Shuffling data
[2023-06-25 08:24:03] [data] Done reading 20,192 sentences
[2023-06-25 08:24:03] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 08:27:34] Seen 20,177 samples
[2023-06-25 08:27:34] Starting data epoch 5 in logical epoch 5
[2023-06-25 08:27:34] [data] Shuffling data
[2023-06-25 08:27:34] [data] Done reading 20,192 sentences
[2023-06-25 08:27:34] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 08:27:53] Ep. 5 : Up. 2000 : Sen. 1,782 : Cost 5.00191402 : Time 432.51s : 2259.06 words/s : gNorm 1.0072
[2023-06-25 08:31:05] Seen 20,177 samples
[2023-06-25 08:31:05] Starting data epoch 6 in logical epoch 6
[2023-06-25 08:31:05] [data] Shuffling data
[2023-06-25 08:31:05] [data] Done reading 20,192 sentences
[2023-06-25 08:31:05] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 08:34:37] Seen 20,177 samples
[2023-06-25 08:34:37] Starting data epoch 7 in logical epoch 7
[2023-06-25 08:34:37] [data] Shuffling data
[2023-06-25 08:34:37] [data] Done reading 20,192 sentences
[2023-06-25 08:34:37] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 08:35:07] Ep. 7 : Up. 3000 : Sen. 2,515 : Cost 4.24677277 : Time 433.91s : 2257.64 words/s : gNorm 1.0831
[2023-06-25 08:38:09] Seen 20,177 samples
[2023-06-25 08:38:09] Starting data epoch 8 in logical epoch 8
[2023-06-25 08:38:09] [data] Shuffling data
[2023-06-25 08:38:09] [data] Done reading 20,192 sentences
[2023-06-25 08:38:09] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 08:41:39] Seen 20,177 samples
[2023-06-25 08:41:39] Starting data epoch 9 in logical epoch 9
[2023-06-25 08:41:39] [data] Shuffling data
[2023-06-25 08:41:39] [data] Done reading 20,192 sentences
[2023-06-25 08:41:39] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 08:42:17] Ep. 9 : Up. 4000 : Sen. 3,548 : Cost 3.62699771 : Time 429.62s : 2277.19 words/s : gNorm 1.1409
[2023-06-25 08:45:10] Seen 20,177 samples
[2023-06-25 08:45:10] Starting data epoch 10 in logical epoch 10
[2023-06-25 08:45:10] [data] Shuffling data
[2023-06-25 08:45:10] [data] Done reading 20,192 sentences
[2023-06-25 08:45:10] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 08:48:41] Seen 20,177 samples
[2023-06-25 08:48:41] Starting data epoch 11 in logical epoch 11
[2023-06-25 08:48:41] Training finished
[2023-06-25 08:48:57] [valid] Ep. 11 : Up. 4890 : cross-entropy : 86.5722 : new best
[2023-06-25 08:52:15] [valid] Ep. 11 : Up. 4890 : translation : 0 : new best
[2023-06-25 08:52:15] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz
[2023-06-25 08:52:26] Saving Adam parameters
[2023-06-25 08:52:29] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz.optimizer.npz
[2023-06-25 09:01:30] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-06-25 09:01:30] [marian] Running on node07.datos.cluster.uy as process 19053 with command line:
[2023-06-25 09:01:30] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz --after-epochs 20 --valid-freq 5000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens.txt.gn /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens.txt.es --seed 1234 --type s2s --max-length 100 --mini-batch-fit --mini-batch 1000 --maxi-batch 1000 --beam-size 12 --normalize 1 --cost-type ce-mean-words --enc-type bidirectional --enc-depth 2 --enc-cell-depth 4 --dec-depth 2 --dec-cell-base-depth 8 --dec-cell-high-depth 1 --layer-normalization --dropout-rnn 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-decay-inv-sqrt 16000 --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --sync-sgd --exponential-smoothing --cpu-threads 0 --log /docker/home/marianmt/logs/marian/split_model_gn_es_edinburgh2017_depth2.log --valid-log /docker/home/marianmt/logs/marian/split_tok_150_gn_es_edinburgh2017_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/model-epochs.txt --quiet-translation
[2023-06-25 09:01:30] [config] after: 0e
[2023-06-25 09:01:30] [config] after-batches: 0
[2023-06-25 09:01:30] [config] after-epochs: 20
[2023-06-25 09:01:30] [config] all-caps-every: 0
[2023-06-25 09:01:30] [config] allow-unk: false
[2023-06-25 09:01:30] [config] authors: false
[2023-06-25 09:01:30] [config] beam-size: 12
[2023-06-25 09:01:30] [config] bert-class-symbol: "[CLS]"
[2023-06-25 09:01:30] [config] bert-mask-symbol: "[MASK]"
[2023-06-25 09:01:30] [config] bert-masking-fraction: 0.15
[2023-06-25 09:01:30] [config] bert-sep-symbol: "[SEP]"
[2023-06-25 09:01:30] [config] bert-train-type-embeddings: true
[2023-06-25 09:01:30] [config] bert-type-vocab-size: 2
[2023-06-25 09:01:30] [config] build-info: ""
[2023-06-25 09:01:30] [config] check-gradient-nan: false
[2023-06-25 09:01:30] [config] check-nan: false
[2023-06-25 09:01:30] [config] cite: false
[2023-06-25 09:01:30] [config] clip-norm: 5
[2023-06-25 09:01:30] [config] cost-scaling:
[2023-06-25 09:01:30] [config]   []
[2023-06-25 09:01:30] [config] cost-type: ce-mean-words
[2023-06-25 09:01:30] [config] cpu-threads: 0
[2023-06-25 09:01:30] [config] data-threads: 8
[2023-06-25 09:01:30] [config] data-weighting: ""
[2023-06-25 09:01:30] [config] data-weighting-type: sentence
[2023-06-25 09:01:30] [config] dec-cell: gru
[2023-06-25 09:01:30] [config] dec-cell-base-depth: 8
[2023-06-25 09:01:30] [config] dec-cell-high-depth: 1
[2023-06-25 09:01:30] [config] dec-depth: 2
[2023-06-25 09:01:30] [config] devices:
[2023-06-25 09:01:30] [config]   - 0
[2023-06-25 09:01:30] [config] dim-emb: 512
[2023-06-25 09:01:30] [config] dim-rnn: 1024
[2023-06-25 09:01:30] [config] dim-vocabs:
[2023-06-25 09:01:30] [config]   - 54042
[2023-06-25 09:01:30] [config]   - 36507
[2023-06-25 09:01:30] [config] disp-first: 0
[2023-06-25 09:01:30] [config] disp-freq: 1000u
[2023-06-25 09:01:30] [config] disp-label-counts: true
[2023-06-25 09:01:30] [config] dropout-rnn: 0.1
[2023-06-25 09:01:30] [config] dropout-src: 0
[2023-06-25 09:01:30] [config] dropout-trg: 0
[2023-06-25 09:01:30] [config] dump-config: ""
[2023-06-25 09:01:30] [config] dynamic-gradient-scaling:
[2023-06-25 09:01:30] [config]   []
[2023-06-25 09:01:30] [config] early-stopping: 10
[2023-06-25 09:01:30] [config] early-stopping-on: first
[2023-06-25 09:01:30] [config] embedding-fix-src: false
[2023-06-25 09:01:30] [config] embedding-fix-trg: false
[2023-06-25 09:01:30] [config] embedding-normalization: false
[2023-06-25 09:01:30] [config] embedding-vectors:
[2023-06-25 09:01:30] [config]   []
[2023-06-25 09:01:30] [config] enc-cell: gru
[2023-06-25 09:01:30] [config] enc-cell-depth: 4
[2023-06-25 09:01:30] [config] enc-depth: 2
[2023-06-25 09:01:30] [config] enc-type: bidirectional
[2023-06-25 09:01:30] [config] english-title-case-every: 0
[2023-06-25 09:01:30] [config] exponential-smoothing: 0.0001
[2023-06-25 09:01:30] [config] factor-weight: 1
[2023-06-25 09:01:30] [config] factors-combine: sum
[2023-06-25 09:01:30] [config] factors-dim-emb: 0
[2023-06-25 09:01:30] [config] gradient-checkpointing: false
[2023-06-25 09:01:30] [config] gradient-norm-average-window: 100
[2023-06-25 09:01:30] [config] guided-alignment: none
[2023-06-25 09:01:30] [config] guided-alignment-cost: mse
[2023-06-25 09:01:30] [config] guided-alignment-weight: 0.1
[2023-06-25 09:01:30] [config] ignore-model-config: false
[2023-06-25 09:01:30] [config] input-types:
[2023-06-25 09:01:30] [config]   []
[2023-06-25 09:01:30] [config] interpolate-env-vars: false
[2023-06-25 09:01:30] [config] keep-best: false
[2023-06-25 09:01:30] [config] label-smoothing: 0.1
[2023-06-25 09:01:30] [config] layer-normalization: true
[2023-06-25 09:01:30] [config] learn-rate: 0.0003
[2023-06-25 09:01:30] [config] lemma-dependency: ""
[2023-06-25 09:01:30] [config] lemma-dim-emb: 0
[2023-06-25 09:01:30] [config] log: /docker/home/marianmt/logs/marian/split_model_gn_es_edinburgh2017_depth2.log
[2023-06-25 09:01:30] [config] log-level: info
[2023-06-25 09:01:30] [config] log-time-zone: ""
[2023-06-25 09:01:30] [config] logical-epoch:
[2023-06-25 09:01:30] [config]   - 1e
[2023-06-25 09:01:30] [config]   - 0
[2023-06-25 09:01:30] [config] lr-decay: 0
[2023-06-25 09:01:30] [config] lr-decay-freq: 50000
[2023-06-25 09:01:30] [config] lr-decay-inv-sqrt:
[2023-06-25 09:01:30] [config]   - 16000
[2023-06-25 09:01:30] [config] lr-decay-repeat-warmup: false
[2023-06-25 09:01:30] [config] lr-decay-reset-optimizer: false
[2023-06-25 09:01:30] [config] lr-decay-start:
[2023-06-25 09:01:30] [config]   - 10
[2023-06-25 09:01:30] [config]   - 1
[2023-06-25 09:01:30] [config] lr-decay-strategy: epoch+stalled
[2023-06-25 09:01:30] [config] lr-report: false
[2023-06-25 09:01:30] [config] lr-warmup: 0
[2023-06-25 09:01:30] [config] lr-warmup-at-reload: false
[2023-06-25 09:01:30] [config] lr-warmup-cycle: false
[2023-06-25 09:01:30] [config] lr-warmup-start-rate: 0
[2023-06-25 09:01:30] [config] max-length: 100
[2023-06-25 09:01:30] [config] max-length-crop: false
[2023-06-25 09:01:30] [config] max-length-factor: 3
[2023-06-25 09:01:30] [config] maxi-batch: 1000
[2023-06-25 09:01:30] [config] maxi-batch-sort: trg
[2023-06-25 09:01:30] [config] mini-batch: 1000
[2023-06-25 09:01:30] [config] mini-batch-fit: true
[2023-06-25 09:01:30] [config] mini-batch-fit-step: 10
[2023-06-25 09:01:30] [config] mini-batch-round-up: true
[2023-06-25 09:01:30] [config] mini-batch-track-lr: false
[2023-06-25 09:01:30] [config] mini-batch-warmup: 0
[2023-06-25 09:01:30] [config] mini-batch-words: 0
[2023-06-25 09:01:30] [config] mini-batch-words-ref: 0
[2023-06-25 09:01:30] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz
[2023-06-25 09:01:30] [config] multi-loss-type: sum
[2023-06-25 09:01:30] [config] n-best: false
[2023-06-25 09:01:30] [config] no-nccl: false
[2023-06-25 09:01:30] [config] no-reload: false
[2023-06-25 09:01:30] [config] no-restore-corpus: false
[2023-06-25 09:01:30] [config] normalize: 1
[2023-06-25 09:01:30] [config] normalize-gradient: false
[2023-06-25 09:01:30] [config] num-devices: 0
[2023-06-25 09:01:30] [config] optimizer: adam
[2023-06-25 09:01:30] [config] optimizer-delay: 1
[2023-06-25 09:01:30] [config] optimizer-params:
[2023-06-25 09:01:30] [config]   - 0.9
[2023-06-25 09:01:30] [config]   - 0.98
[2023-06-25 09:01:30] [config]   - 1e-09
[2023-06-25 09:01:30] [config] output-omit-bias: false
[2023-06-25 09:01:30] [config] overwrite: false
[2023-06-25 09:01:30] [config] precision:
[2023-06-25 09:01:30] [config]   - float32
[2023-06-25 09:01:30] [config]   - float32
[2023-06-25 09:01:30] [config] pretrained-model: ""
[2023-06-25 09:01:30] [config] quantize-biases: false
[2023-06-25 09:01:30] [config] quantize-bits: 0
[2023-06-25 09:01:30] [config] quantize-log-based: false
[2023-06-25 09:01:30] [config] quantize-optimization-steps: 0
[2023-06-25 09:01:30] [config] quiet: false
[2023-06-25 09:01:30] [config] quiet-translation: true
[2023-06-25 09:01:30] [config] relative-paths: false
[2023-06-25 09:01:30] [config] right-left: false
[2023-06-25 09:01:30] [config] save-freq: 10000u
[2023-06-25 09:01:30] [config] seed: 1234
[2023-06-25 09:01:30] [config] sentencepiece-alphas:
[2023-06-25 09:01:30] [config]   []
[2023-06-25 09:01:30] [config] sentencepiece-max-lines: 2000000
[2023-06-25 09:01:30] [config] sentencepiece-options: ""
[2023-06-25 09:01:30] [config] sharding: global
[2023-06-25 09:01:30] [config] shuffle: data
[2023-06-25 09:01:30] [config] shuffle-in-ram: false
[2023-06-25 09:01:30] [config] sigterm: save-and-exit
[2023-06-25 09:01:30] [config] skip: false
[2023-06-25 09:01:30] [config] sqlite: ""
[2023-06-25 09:01:30] [config] sqlite-drop: false
[2023-06-25 09:01:30] [config] sync-freq: 200u
[2023-06-25 09:01:30] [config] sync-sgd: true
[2023-06-25 09:01:30] [config] tempdir: /tmp
[2023-06-25 09:01:30] [config] tied-embeddings: false
[2023-06-25 09:01:30] [config] tied-embeddings-all: false
[2023-06-25 09:01:30] [config] tied-embeddings-src: false
[2023-06-25 09:01:30] [config] train-embedder-rank:
[2023-06-25 09:01:30] [config]   []
[2023-06-25 09:01:30] [config] train-sets:
[2023-06-25 09:01:30] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-06-25 09:01:30] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-06-25 09:01:30] [config] transformer-aan-activation: swish
[2023-06-25 09:01:30] [config] transformer-aan-depth: 2
[2023-06-25 09:01:30] [config] transformer-aan-nogate: false
[2023-06-25 09:01:30] [config] transformer-decoder-autoreg: self-attention
[2023-06-25 09:01:30] [config] transformer-decoder-dim-ffn: 0
[2023-06-25 09:01:30] [config] transformer-decoder-ffn-depth: 0
[2023-06-25 09:01:30] [config] transformer-depth-scaling: false
[2023-06-25 09:01:30] [config] transformer-dim-aan: 2048
[2023-06-25 09:01:30] [config] transformer-dim-ffn: 2048
[2023-06-25 09:01:30] [config] transformer-dropout: 0
[2023-06-25 09:01:30] [config] transformer-dropout-attention: 0
[2023-06-25 09:01:30] [config] transformer-dropout-ffn: 0
[2023-06-25 09:01:30] [config] transformer-ffn-activation: swish
[2023-06-25 09:01:30] [config] transformer-ffn-depth: 2
[2023-06-25 09:01:30] [config] transformer-guided-alignment-layer: last
[2023-06-25 09:01:30] [config] transformer-heads: 8
[2023-06-25 09:01:30] [config] transformer-no-projection: false
[2023-06-25 09:01:30] [config] transformer-pool: false
[2023-06-25 09:01:30] [config] transformer-postprocess: dan
[2023-06-25 09:01:30] [config] transformer-postprocess-emb: d
[2023-06-25 09:01:30] [config] transformer-postprocess-top: ""
[2023-06-25 09:01:30] [config] transformer-preprocess: ""
[2023-06-25 09:01:30] [config] transformer-tied-layers:
[2023-06-25 09:01:30] [config]   []
[2023-06-25 09:01:30] [config] transformer-train-position-embeddings: false
[2023-06-25 09:01:30] [config] tsv: false
[2023-06-25 09:01:30] [config] tsv-fields: 0
[2023-06-25 09:01:30] [config] type: s2s
[2023-06-25 09:01:30] [config] ulr: false
[2023-06-25 09:01:30] [config] ulr-dim-emb: 0
[2023-06-25 09:01:30] [config] ulr-dropout: 0
[2023-06-25 09:01:30] [config] ulr-keys-vectors: ""
[2023-06-25 09:01:30] [config] ulr-query-vectors: ""
[2023-06-25 09:01:30] [config] ulr-softmax-temperature: 1
[2023-06-25 09:01:30] [config] ulr-trainable-transformation: false
[2023-06-25 09:01:30] [config] unlikelihood-loss: false
[2023-06-25 09:01:30] [config] valid-freq: 5000000
[2023-06-25 09:01:30] [config] valid-log: /docker/home/marianmt/logs/marian/split_tok_150_gn_es_edinburgh2017_depth2.log
[2023-06-25 09:01:30] [config] valid-max-length: 1000
[2023-06-25 09:01:30] [config] valid-metrics:
[2023-06-25 09:01:30] [config]   - cross-entropy
[2023-06-25 09:01:30] [config]   - translation
[2023-06-25 09:01:30] [config] valid-mini-batch: 32
[2023-06-25 09:01:30] [config] valid-reset-stalled: false
[2023-06-25 09:01:30] [config] valid-script-args:
[2023-06-25 09:01:30] [config]   []
[2023-06-25 09:01:30] [config] valid-script-path: ""
[2023-06-25 09:01:30] [config] valid-sets:
[2023-06-25 09:01:30] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-06-25 09:01:30] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-06-25 09:01:30] [config] valid-translation-output: /docker/home/marianmt/evaluation/model-epochs.txt
[2023-06-25 09:01:30] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-06-25 09:01:30] [config] vocabs:
[2023-06-25 09:01:30] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens.txt.gn
[2023-06-25 09:01:30] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens.txt.es
[2023-06-25 09:01:30] [config] word-penalty: 0
[2023-06-25 09:01:30] [config] word-scores: false
[2023-06-25 09:01:30] [config] workspace: 2048
[2023-06-25 09:01:30] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-06-25 09:01:30] Using synchronous SGD
[2023-06-25 09:01:33] Synced seed 1234
[2023-06-25 09:01:33] [data] Loading vocabulary from text file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens.txt.gn
[2023-06-25 09:01:33] [data] Setting vocabulary size for input 0 to 54,042
[2023-06-25 09:01:33] [data] Loading vocabulary from text file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens.txt.es
[2023-06-25 09:01:33] [data] Setting vocabulary size for input 1 to 36,507
[2023-06-25 09:01:33] [batching] Collecting statistics for batch fitting with step size 10
[2023-06-25 09:01:33] [MPI rank 0 out of 1]: GPU[0]
[2023-06-25 09:01:33] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-06-25 09:01:33] [comm] Using NCCL 2.8.3 for GPU communication
[2023-06-25 09:01:33] [comm] Using global sharding
[2023-06-25 09:01:33] [comm] NCCLCommunicators constructed successfully
[2023-06-25 09:01:33] [training] Using 1 GPUs
[2023-06-25 09:01:33] [logits] Applying loss function for 1 factor(s)
[2023-06-25 09:01:33] [memory] Reserving 666 MB, device gpu0
[2023-06-25 09:01:34] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-06-25 09:01:34] [memory] Reserving 666 MB, device gpu0
[2023-06-25 09:01:59] [batching] Done. Typical MB size is 1,196 target words
[2023-06-25 09:01:59] [valid] No post-processing script given for validating translator
[2023-06-25 09:01:59] [MPI rank 0 out of 1]: GPU[0]
[2023-06-25 09:01:59] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-06-25 09:01:59] [comm] Using NCCL 2.8.3 for GPU communication
[2023-06-25 09:01:59] [comm] Using global sharding
[2023-06-25 09:01:59] [comm] NCCLCommunicators constructed successfully
[2023-06-25 09:01:59] [training] Using 1 GPUs
[2023-06-25 09:01:59] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz
[2023-06-25 09:02:05] Allocating memory for general optimizer shards
[2023-06-25 09:02:05] [memory] Reserving 666 MB, device gpu0
[2023-06-25 09:02:05] Loading Adam parameters
[2023-06-25 09:02:05] [memory] Reserving 1332 MB, device gpu0
[2023-06-25 09:02:06] [memory] Reserving 666 MB, device gpu0
[2023-06-25 09:02:06] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz.optimizer.npz
[2023-06-25 09:02:06] [data] Restoring the corpus state to epoch 11, batch 4890
[2023-06-25 09:02:06] [data] Shuffling data
[2023-06-25 09:02:06] [data] Done reading 20,192 sentences
[2023-06-25 09:02:06] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 09:02:06] Training started
[2023-06-25 09:02:06] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-06-25 09:02:06] [memory] Reserving 666 MB, device gpu0
[2023-06-25 09:02:06] Parameter type float32, optimization type float32, casting types false
[2023-06-25 09:02:51] Ep. 11 : Up. 5000 : Sen. 4,765 : Cost 3.13750100 : Time 51.96s : 18787.43 words/s : gNorm 1.1073
[2023-06-25 09:05:37] Seen 20,177 samples
[2023-06-25 09:05:37] Starting data epoch 12 in logical epoch 12
[2023-06-25 09:05:37] [data] Shuffling data
[2023-06-25 09:05:37] [data] Done reading 20,192 sentences
[2023-06-25 09:05:37] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 09:09:09] Seen 20,177 samples
[2023-06-25 09:09:09] Starting data epoch 13 in logical epoch 13
[2023-06-25 09:09:09] [data] Shuffling data
[2023-06-25 09:09:09] [data] Done reading 20,192 sentences
[2023-06-25 09:09:09] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 09:10:08] Ep. 13 : Up. 6000 : Sen. 5,460 : Cost 2.75686598 : Time 437.04s : 2232.37 words/s : gNorm 1.0727
[2023-06-25 09:12:41] Seen 20,177 samples
[2023-06-25 09:12:41] Starting data epoch 14 in logical epoch 14
[2023-06-25 09:12:41] [data] Shuffling data
[2023-06-25 09:12:41] [data] Done reading 20,192 sentences
[2023-06-25 09:12:41] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 09:16:14] Seen 20,177 samples
[2023-06-25 09:16:14] Starting data epoch 15 in logical epoch 15
[2023-06-25 09:16:14] [data] Shuffling data
[2023-06-25 09:16:14] [data] Done reading 20,192 sentences
[2023-06-25 09:16:14] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 09:17:19] Ep. 15 : Up. 7000 : Sen. 6,538 : Cost 2.45815206 : Time 431.00s : 2263.86 words/s : gNorm 0.9820
[2023-06-25 09:19:45] Seen 20,177 samples
[2023-06-25 09:19:45] Starting data epoch 16 in logical epoch 16
[2023-06-25 09:19:45] [data] Shuffling data
[2023-06-25 09:19:45] [data] Done reading 20,192 sentences
[2023-06-25 09:19:45] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 09:23:17] Seen 20,177 samples
[2023-06-25 09:23:17] Starting data epoch 17 in logical epoch 17
[2023-06-25 09:23:17] [data] Shuffling data
[2023-06-25 09:23:17] [data] Done reading 20,192 sentences
[2023-06-25 09:23:18] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 09:24:33] Ep. 17 : Up. 8000 : Sen. 7,161 : Cost 2.24131823 : Time 434.36s : 2256.63 words/s : gNorm 0.8957
[2023-06-25 09:26:49] Seen 20,177 samples
[2023-06-25 09:26:49] Starting data epoch 18 in logical epoch 18
[2023-06-25 09:26:49] [data] Shuffling data
[2023-06-25 09:26:49] [data] Done reading 20,192 sentences
[2023-06-25 09:26:49] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 09:30:22] Seen 20,177 samples
[2023-06-25 09:30:22] Starting data epoch 19 in logical epoch 19
[2023-06-25 09:30:22] [data] Shuffling data
[2023-06-25 09:30:22] [data] Done reading 20,192 sentences
[2023-06-25 09:30:22] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 09:31:49] Ep. 19 : Up. 9000 : Sen. 7,758 : Cost 2.08475804 : Time 435.40s : 2249.28 words/s : gNorm 0.7893
[2023-06-25 09:33:54] Seen 20,177 samples
[2023-06-25 09:33:54] Starting data epoch 20 in logical epoch 20
[2023-06-25 09:33:54] [data] Shuffling data
[2023-06-25 09:33:54] [data] Done reading 20,192 sentences
[2023-06-25 09:33:54] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 09:37:24] Seen 20,177 samples
[2023-06-25 09:37:24] Starting data epoch 21 in logical epoch 21
[2023-06-25 09:37:24] Training finished
[2023-06-25 09:37:40] [valid] Ep. 21 : Up. 9780 : cross-entropy : 95.4048 : stalled 1 times (last best: 86.5722)
[2023-06-25 09:40:55] [valid] Ep. 21 : Up. 9780 : translation : 0 : new best
[2023-06-25 09:40:55] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz
[2023-06-25 09:41:03] Saving Adam parameters
[2023-06-25 09:41:06] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz.optimizer.npz
[2023-06-25 09:50:09] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-06-25 09:50:09] [marian] Running on node07.datos.cluster.uy as process 22345 with command line:
[2023-06-25 09:50:09] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz --after-epochs 30 --valid-freq 5000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens.txt.gn /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens.txt.es --seed 1234 --type s2s --max-length 100 --mini-batch-fit --mini-batch 1000 --maxi-batch 1000 --beam-size 12 --normalize 1 --cost-type ce-mean-words --enc-type bidirectional --enc-depth 2 --enc-cell-depth 4 --dec-depth 2 --dec-cell-base-depth 8 --dec-cell-high-depth 1 --layer-normalization --dropout-rnn 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-decay-inv-sqrt 16000 --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --sync-sgd --exponential-smoothing --cpu-threads 0 --log /docker/home/marianmt/logs/marian/split_model_gn_es_edinburgh2017_depth2.log --valid-log /docker/home/marianmt/logs/marian/split_tok_150_gn_es_edinburgh2017_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/model-epochs.txt --quiet-translation
[2023-06-25 09:50:10] [config] after: 0e
[2023-06-25 09:50:10] [config] after-batches: 0
[2023-06-25 09:50:10] [config] after-epochs: 30
[2023-06-25 09:50:10] [config] all-caps-every: 0
[2023-06-25 09:50:10] [config] allow-unk: false
[2023-06-25 09:50:10] [config] authors: false
[2023-06-25 09:50:10] [config] beam-size: 12
[2023-06-25 09:50:10] [config] bert-class-symbol: "[CLS]"
[2023-06-25 09:50:10] [config] bert-mask-symbol: "[MASK]"
[2023-06-25 09:50:10] [config] bert-masking-fraction: 0.15
[2023-06-25 09:50:10] [config] bert-sep-symbol: "[SEP]"
[2023-06-25 09:50:10] [config] bert-train-type-embeddings: true
[2023-06-25 09:50:10] [config] bert-type-vocab-size: 2
[2023-06-25 09:50:10] [config] build-info: ""
[2023-06-25 09:50:10] [config] check-gradient-nan: false
[2023-06-25 09:50:10] [config] check-nan: false
[2023-06-25 09:50:10] [config] cite: false
[2023-06-25 09:50:10] [config] clip-norm: 5
[2023-06-25 09:50:10] [config] cost-scaling:
[2023-06-25 09:50:10] [config]   []
[2023-06-25 09:50:10] [config] cost-type: ce-mean-words
[2023-06-25 09:50:10] [config] cpu-threads: 0
[2023-06-25 09:50:10] [config] data-threads: 8
[2023-06-25 09:50:10] [config] data-weighting: ""
[2023-06-25 09:50:10] [config] data-weighting-type: sentence
[2023-06-25 09:50:10] [config] dec-cell: gru
[2023-06-25 09:50:10] [config] dec-cell-base-depth: 8
[2023-06-25 09:50:10] [config] dec-cell-high-depth: 1
[2023-06-25 09:50:10] [config] dec-depth: 2
[2023-06-25 09:50:10] [config] devices:
[2023-06-25 09:50:10] [config]   - 0
[2023-06-25 09:50:10] [config] dim-emb: 512
[2023-06-25 09:50:10] [config] dim-rnn: 1024
[2023-06-25 09:50:10] [config] dim-vocabs:
[2023-06-25 09:50:10] [config]   - 54042
[2023-06-25 09:50:10] [config]   - 36507
[2023-06-25 09:50:10] [config] disp-first: 0
[2023-06-25 09:50:10] [config] disp-freq: 1000u
[2023-06-25 09:50:10] [config] disp-label-counts: true
[2023-06-25 09:50:10] [config] dropout-rnn: 0.1
[2023-06-25 09:50:10] [config] dropout-src: 0
[2023-06-25 09:50:10] [config] dropout-trg: 0
[2023-06-25 09:50:10] [config] dump-config: ""
[2023-06-25 09:50:10] [config] dynamic-gradient-scaling:
[2023-06-25 09:50:10] [config]   []
[2023-06-25 09:50:10] [config] early-stopping: 10
[2023-06-25 09:50:10] [config] early-stopping-on: first
[2023-06-25 09:50:10] [config] embedding-fix-src: false
[2023-06-25 09:50:10] [config] embedding-fix-trg: false
[2023-06-25 09:50:10] [config] embedding-normalization: false
[2023-06-25 09:50:10] [config] embedding-vectors:
[2023-06-25 09:50:10] [config]   []
[2023-06-25 09:50:10] [config] enc-cell: gru
[2023-06-25 09:50:10] [config] enc-cell-depth: 4
[2023-06-25 09:50:10] [config] enc-depth: 2
[2023-06-25 09:50:10] [config] enc-type: bidirectional
[2023-06-25 09:50:10] [config] english-title-case-every: 0
[2023-06-25 09:50:10] [config] exponential-smoothing: 0.0001
[2023-06-25 09:50:10] [config] factor-weight: 1
[2023-06-25 09:50:10] [config] factors-combine: sum
[2023-06-25 09:50:10] [config] factors-dim-emb: 0
[2023-06-25 09:50:10] [config] gradient-checkpointing: false
[2023-06-25 09:50:10] [config] gradient-norm-average-window: 100
[2023-06-25 09:50:10] [config] guided-alignment: none
[2023-06-25 09:50:10] [config] guided-alignment-cost: mse
[2023-06-25 09:50:10] [config] guided-alignment-weight: 0.1
[2023-06-25 09:50:10] [config] ignore-model-config: false
[2023-06-25 09:50:10] [config] input-types:
[2023-06-25 09:50:10] [config]   []
[2023-06-25 09:50:10] [config] interpolate-env-vars: false
[2023-06-25 09:50:10] [config] keep-best: false
[2023-06-25 09:50:10] [config] label-smoothing: 0.1
[2023-06-25 09:50:10] [config] layer-normalization: true
[2023-06-25 09:50:10] [config] learn-rate: 0.0003
[2023-06-25 09:50:10] [config] lemma-dependency: ""
[2023-06-25 09:50:10] [config] lemma-dim-emb: 0
[2023-06-25 09:50:10] [config] log: /docker/home/marianmt/logs/marian/split_model_gn_es_edinburgh2017_depth2.log
[2023-06-25 09:50:10] [config] log-level: info
[2023-06-25 09:50:10] [config] log-time-zone: ""
[2023-06-25 09:50:10] [config] logical-epoch:
[2023-06-25 09:50:10] [config]   - 1e
[2023-06-25 09:50:10] [config]   - 0
[2023-06-25 09:50:10] [config] lr-decay: 0
[2023-06-25 09:50:10] [config] lr-decay-freq: 50000
[2023-06-25 09:50:10] [config] lr-decay-inv-sqrt:
[2023-06-25 09:50:10] [config]   - 16000
[2023-06-25 09:50:10] [config] lr-decay-repeat-warmup: false
[2023-06-25 09:50:10] [config] lr-decay-reset-optimizer: false
[2023-06-25 09:50:10] [config] lr-decay-start:
[2023-06-25 09:50:10] [config]   - 10
[2023-06-25 09:50:10] [config]   - 1
[2023-06-25 09:50:10] [config] lr-decay-strategy: epoch+stalled
[2023-06-25 09:50:10] [config] lr-report: false
[2023-06-25 09:50:10] [config] lr-warmup: 0
[2023-06-25 09:50:10] [config] lr-warmup-at-reload: false
[2023-06-25 09:50:10] [config] lr-warmup-cycle: false
[2023-06-25 09:50:10] [config] lr-warmup-start-rate: 0
[2023-06-25 09:50:10] [config] max-length: 100
[2023-06-25 09:50:10] [config] max-length-crop: false
[2023-06-25 09:50:10] [config] max-length-factor: 3
[2023-06-25 09:50:10] [config] maxi-batch: 1000
[2023-06-25 09:50:10] [config] maxi-batch-sort: trg
[2023-06-25 09:50:10] [config] mini-batch: 1000
[2023-06-25 09:50:10] [config] mini-batch-fit: true
[2023-06-25 09:50:10] [config] mini-batch-fit-step: 10
[2023-06-25 09:50:10] [config] mini-batch-round-up: true
[2023-06-25 09:50:10] [config] mini-batch-track-lr: false
[2023-06-25 09:50:10] [config] mini-batch-warmup: 0
[2023-06-25 09:50:10] [config] mini-batch-words: 0
[2023-06-25 09:50:10] [config] mini-batch-words-ref: 0
[2023-06-25 09:50:10] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz
[2023-06-25 09:50:10] [config] multi-loss-type: sum
[2023-06-25 09:50:10] [config] n-best: false
[2023-06-25 09:50:10] [config] no-nccl: false
[2023-06-25 09:50:10] [config] no-reload: false
[2023-06-25 09:50:10] [config] no-restore-corpus: false
[2023-06-25 09:50:10] [config] normalize: 1
[2023-06-25 09:50:10] [config] normalize-gradient: false
[2023-06-25 09:50:10] [config] num-devices: 0
[2023-06-25 09:50:10] [config] optimizer: adam
[2023-06-25 09:50:10] [config] optimizer-delay: 1
[2023-06-25 09:50:10] [config] optimizer-params:
[2023-06-25 09:50:10] [config]   - 0.9
[2023-06-25 09:50:10] [config]   - 0.98
[2023-06-25 09:50:10] [config]   - 1e-09
[2023-06-25 09:50:10] [config] output-omit-bias: false
[2023-06-25 09:50:10] [config] overwrite: false
[2023-06-25 09:50:10] [config] precision:
[2023-06-25 09:50:10] [config]   - float32
[2023-06-25 09:50:10] [config]   - float32
[2023-06-25 09:50:10] [config] pretrained-model: ""
[2023-06-25 09:50:10] [config] quantize-biases: false
[2023-06-25 09:50:10] [config] quantize-bits: 0
[2023-06-25 09:50:10] [config] quantize-log-based: false
[2023-06-25 09:50:10] [config] quantize-optimization-steps: 0
[2023-06-25 09:50:10] [config] quiet: false
[2023-06-25 09:50:10] [config] quiet-translation: true
[2023-06-25 09:50:10] [config] relative-paths: false
[2023-06-25 09:50:10] [config] right-left: false
[2023-06-25 09:50:10] [config] save-freq: 10000u
[2023-06-25 09:50:10] [config] seed: 1234
[2023-06-25 09:50:10] [config] sentencepiece-alphas:
[2023-06-25 09:50:10] [config]   []
[2023-06-25 09:50:10] [config] sentencepiece-max-lines: 2000000
[2023-06-25 09:50:10] [config] sentencepiece-options: ""
[2023-06-25 09:50:10] [config] sharding: global
[2023-06-25 09:50:10] [config] shuffle: data
[2023-06-25 09:50:10] [config] shuffle-in-ram: false
[2023-06-25 09:50:10] [config] sigterm: save-and-exit
[2023-06-25 09:50:10] [config] skip: false
[2023-06-25 09:50:10] [config] sqlite: ""
[2023-06-25 09:50:10] [config] sqlite-drop: false
[2023-06-25 09:50:10] [config] sync-freq: 200u
[2023-06-25 09:50:10] [config] sync-sgd: true
[2023-06-25 09:50:10] [config] tempdir: /tmp
[2023-06-25 09:50:10] [config] tied-embeddings: false
[2023-06-25 09:50:10] [config] tied-embeddings-all: false
[2023-06-25 09:50:10] [config] tied-embeddings-src: false
[2023-06-25 09:50:10] [config] train-embedder-rank:
[2023-06-25 09:50:10] [config]   []
[2023-06-25 09:50:10] [config] train-sets:
[2023-06-25 09:50:10] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-06-25 09:50:10] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-06-25 09:50:10] [config] transformer-aan-activation: swish
[2023-06-25 09:50:10] [config] transformer-aan-depth: 2
[2023-06-25 09:50:10] [config] transformer-aan-nogate: false
[2023-06-25 09:50:10] [config] transformer-decoder-autoreg: self-attention
[2023-06-25 09:50:10] [config] transformer-decoder-dim-ffn: 0
[2023-06-25 09:50:10] [config] transformer-decoder-ffn-depth: 0
[2023-06-25 09:50:10] [config] transformer-depth-scaling: false
[2023-06-25 09:50:10] [config] transformer-dim-aan: 2048
[2023-06-25 09:50:10] [config] transformer-dim-ffn: 2048
[2023-06-25 09:50:10] [config] transformer-dropout: 0
[2023-06-25 09:50:10] [config] transformer-dropout-attention: 0
[2023-06-25 09:50:10] [config] transformer-dropout-ffn: 0
[2023-06-25 09:50:10] [config] transformer-ffn-activation: swish
[2023-06-25 09:50:10] [config] transformer-ffn-depth: 2
[2023-06-25 09:50:10] [config] transformer-guided-alignment-layer: last
[2023-06-25 09:50:10] [config] transformer-heads: 8
[2023-06-25 09:50:10] [config] transformer-no-projection: false
[2023-06-25 09:50:10] [config] transformer-pool: false
[2023-06-25 09:50:10] [config] transformer-postprocess: dan
[2023-06-25 09:50:10] [config] transformer-postprocess-emb: d
[2023-06-25 09:50:10] [config] transformer-postprocess-top: ""
[2023-06-25 09:50:10] [config] transformer-preprocess: ""
[2023-06-25 09:50:10] [config] transformer-tied-layers:
[2023-06-25 09:50:10] [config]   []
[2023-06-25 09:50:10] [config] transformer-train-position-embeddings: false
[2023-06-25 09:50:10] [config] tsv: false
[2023-06-25 09:50:10] [config] tsv-fields: 0
[2023-06-25 09:50:10] [config] type: s2s
[2023-06-25 09:50:10] [config] ulr: false
[2023-06-25 09:50:10] [config] ulr-dim-emb: 0
[2023-06-25 09:50:10] [config] ulr-dropout: 0
[2023-06-25 09:50:10] [config] ulr-keys-vectors: ""
[2023-06-25 09:50:10] [config] ulr-query-vectors: ""
[2023-06-25 09:50:10] [config] ulr-softmax-temperature: 1
[2023-06-25 09:50:10] [config] ulr-trainable-transformation: false
[2023-06-25 09:50:10] [config] unlikelihood-loss: false
[2023-06-25 09:50:10] [config] valid-freq: 5000000
[2023-06-25 09:50:10] [config] valid-log: /docker/home/marianmt/logs/marian/split_tok_150_gn_es_edinburgh2017_depth2.log
[2023-06-25 09:50:10] [config] valid-max-length: 1000
[2023-06-25 09:50:10] [config] valid-metrics:
[2023-06-25 09:50:10] [config]   - cross-entropy
[2023-06-25 09:50:10] [config]   - translation
[2023-06-25 09:50:10] [config] valid-mini-batch: 32
[2023-06-25 09:50:10] [config] valid-reset-stalled: false
[2023-06-25 09:50:10] [config] valid-script-args:
[2023-06-25 09:50:10] [config]   []
[2023-06-25 09:50:10] [config] valid-script-path: ""
[2023-06-25 09:50:10] [config] valid-sets:
[2023-06-25 09:50:10] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-06-25 09:50:10] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-06-25 09:50:10] [config] valid-translation-output: /docker/home/marianmt/evaluation/model-epochs.txt
[2023-06-25 09:50:10] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-06-25 09:50:10] [config] vocabs:
[2023-06-25 09:50:10] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens.txt.gn
[2023-06-25 09:50:10] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens.txt.es
[2023-06-25 09:50:10] [config] word-penalty: 0
[2023-06-25 09:50:10] [config] word-scores: false
[2023-06-25 09:50:10] [config] workspace: 2048
[2023-06-25 09:50:10] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-06-25 09:50:10] Using synchronous SGD
[2023-06-25 09:50:12] Synced seed 1234
[2023-06-25 09:50:12] [data] Loading vocabulary from text file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens.txt.gn
[2023-06-25 09:50:12] [data] Setting vocabulary size for input 0 to 54,042
[2023-06-25 09:50:12] [data] Loading vocabulary from text file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens.txt.es
[2023-06-25 09:50:12] [data] Setting vocabulary size for input 1 to 36,507
[2023-06-25 09:50:12] [batching] Collecting statistics for batch fitting with step size 10
[2023-06-25 09:50:12] [MPI rank 0 out of 1]: GPU[0]
[2023-06-25 09:50:12] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-06-25 09:50:13] [comm] Using NCCL 2.8.3 for GPU communication
[2023-06-25 09:50:13] [comm] Using global sharding
[2023-06-25 09:50:13] [comm] NCCLCommunicators constructed successfully
[2023-06-25 09:50:13] [training] Using 1 GPUs
[2023-06-25 09:50:13] [logits] Applying loss function for 1 factor(s)
[2023-06-25 09:50:13] [memory] Reserving 666 MB, device gpu0
[2023-06-25 09:50:13] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-06-25 09:50:14] [memory] Reserving 666 MB, device gpu0
[2023-06-25 09:50:38] [batching] Done. Typical MB size is 1,196 target words
[2023-06-25 09:50:38] [valid] No post-processing script given for validating translator
[2023-06-25 09:50:38] [MPI rank 0 out of 1]: GPU[0]
[2023-06-25 09:50:38] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-06-25 09:50:38] [comm] Using NCCL 2.8.3 for GPU communication
[2023-06-25 09:50:38] [comm] Using global sharding
[2023-06-25 09:50:38] [comm] NCCLCommunicators constructed successfully
[2023-06-25 09:50:38] [training] Using 1 GPUs
[2023-06-25 09:50:38] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz
[2023-06-25 09:50:57] Allocating memory for general optimizer shards
[2023-06-25 09:50:57] [memory] Reserving 666 MB, device gpu0
[2023-06-25 09:50:57] Loading Adam parameters
[2023-06-25 09:50:58] [memory] Reserving 1332 MB, device gpu0
[2023-06-25 09:50:58] [memory] Reserving 666 MB, device gpu0
[2023-06-25 09:50:58] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz.optimizer.npz
[2023-06-25 09:50:58] [data] Restoring the corpus state to epoch 21, batch 9780
[2023-06-25 09:50:58] [data] Shuffling data
[2023-06-25 09:50:58] [data] Done reading 20,192 sentences
[2023-06-25 09:50:58] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 09:50:58] Training started
[2023-06-25 09:50:59] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-06-25 09:50:59] [memory] Reserving 666 MB, device gpu0
[2023-06-25 09:50:59] Parameter type float32, optimization type float32, casting types false
[2023-06-25 09:52:31] Ep. 21 : Up. 10000 : Sen. 8,808 : Cost 1.98121428 : Time 112.93s : 8646.21 words/s : gNorm 0.7122
[2023-06-25 09:52:31] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.iter10000.npz
[2023-06-25 09:52:38] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz
[2023-06-25 09:52:45] Saving Adam parameters
[2023-06-25 09:52:48] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz.optimizer.npz
[2023-06-25 09:55:04] Seen 20,177 samples
[2023-06-25 09:55:04] Starting data epoch 22 in logical epoch 22
[2023-06-25 09:55:04] [data] Shuffling data
[2023-06-25 09:55:04] [data] Done reading 20,192 sentences
[2023-06-25 09:55:04] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 09:58:36] Seen 20,177 samples
[2023-06-25 09:58:36] Starting data epoch 23 in logical epoch 23
[2023-06-25 09:58:36] [data] Shuffling data
[2023-06-25 09:58:36] [data] Done reading 20,192 sentences
[2023-06-25 09:58:36] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 10:00:20] Ep. 23 : Up. 11000 : Sen. 10,264 : Cost 1.90673268 : Time 469.47s : 2080.79 words/s : gNorm 0.6362
[2023-06-25 10:02:08] Seen 20,177 samples
[2023-06-25 10:02:08] Starting data epoch 24 in logical epoch 24
[2023-06-25 10:02:08] [data] Shuffling data
[2023-06-25 10:02:08] [data] Done reading 20,192 sentences
[2023-06-25 10:02:08] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 10:05:41] Seen 20,177 samples
[2023-06-25 10:05:41] Starting data epoch 25 in logical epoch 25
[2023-06-25 10:05:41] [data] Shuffling data
[2023-06-25 10:05:41] [data] Done reading 20,192 sentences
[2023-06-25 10:05:41] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 10:07:39] Ep. 25 : Up. 12000 : Sen. 10,749 : Cost 1.85883975 : Time 438.43s : 2227.15 words/s : gNorm 0.5769
[2023-06-25 10:09:13] Seen 20,177 samples
[2023-06-25 10:09:13] Starting data epoch 26 in logical epoch 26
[2023-06-25 10:09:13] [data] Shuffling data
[2023-06-25 10:09:13] [data] Done reading 20,192 sentences
[2023-06-25 10:09:13] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 10:12:44] Seen 20,177 samples
[2023-06-25 10:12:44] Starting data epoch 27 in logical epoch 27
[2023-06-25 10:12:44] [data] Shuffling data
[2023-06-25 10:12:44] [data] Done reading 20,192 sentences
[2023-06-25 10:12:44] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 10:14:48] Ep. 27 : Up. 13000 : Sen. 12,078 : Cost 1.82115817 : Time 429.40s : 2273.01 words/s : gNorm 0.5405
[2023-06-25 10:16:17] Seen 20,177 samples
[2023-06-25 10:16:17] Starting data epoch 28 in logical epoch 28
[2023-06-25 10:16:17] [data] Shuffling data
[2023-06-25 10:16:17] [data] Done reading 20,192 sentences
[2023-06-25 10:16:17] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 10:19:48] Seen 20,177 samples
[2023-06-25 10:19:48] Starting data epoch 29 in logical epoch 29
[2023-06-25 10:19:48] [data] Shuffling data
[2023-06-25 10:19:48] [data] Done reading 20,192 sentences
[2023-06-25 10:19:48] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 10:22:01] Ep. 29 : Up. 14000 : Sen. 12,561 : Cost 1.79677641 : Time 433.29s : 2261.55 words/s : gNorm 0.5067
[2023-06-25 10:23:20] Seen 20,177 samples
[2023-06-25 10:23:20] Starting data epoch 30 in logical epoch 30
[2023-06-25 10:23:20] [data] Shuffling data
[2023-06-25 10:23:20] [data] Done reading 20,192 sentences
[2023-06-25 10:23:20] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 10:26:53] Seen 20,177 samples
[2023-06-25 10:26:53] Starting data epoch 31 in logical epoch 31
[2023-06-25 10:26:53] Training finished
[2023-06-25 10:27:09] [valid] Ep. 31 : Up. 14670 : cross-entropy : 98.1733 : stalled 2 times (last best: 86.5722)
[2023-06-25 10:30:27] [valid] Ep. 31 : Up. 14670 : translation : 0 : new best
[2023-06-25 10:30:27] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz
[2023-06-25 10:30:37] Saving Adam parameters
[2023-06-25 10:30:39] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz.optimizer.npz
[2023-06-25 10:39:42] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-06-25 10:39:42] [marian] Running on node07.datos.cluster.uy as process 34628 with command line:
[2023-06-25 10:39:42] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz --after-epochs 40 --valid-freq 5000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens.txt.gn /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens.txt.es --seed 1234 --type s2s --max-length 100 --mini-batch-fit --mini-batch 1000 --maxi-batch 1000 --beam-size 12 --normalize 1 --cost-type ce-mean-words --enc-type bidirectional --enc-depth 2 --enc-cell-depth 4 --dec-depth 2 --dec-cell-base-depth 8 --dec-cell-high-depth 1 --layer-normalization --dropout-rnn 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-decay-inv-sqrt 16000 --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --sync-sgd --exponential-smoothing --cpu-threads 0 --log /docker/home/marianmt/logs/marian/split_model_gn_es_edinburgh2017_depth2.log --valid-log /docker/home/marianmt/logs/marian/split_tok_150_gn_es_edinburgh2017_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/model-epochs.txt --quiet-translation
[2023-06-25 10:39:44] [config] after: 0e
[2023-06-25 10:39:44] [config] after-batches: 0
[2023-06-25 10:39:44] [config] after-epochs: 40
[2023-06-25 10:39:44] [config] all-caps-every: 0
[2023-06-25 10:39:44] [config] allow-unk: false
[2023-06-25 10:39:44] [config] authors: false
[2023-06-25 10:39:44] [config] beam-size: 12
[2023-06-25 10:39:44] [config] bert-class-symbol: "[CLS]"
[2023-06-25 10:39:44] [config] bert-mask-symbol: "[MASK]"
[2023-06-25 10:39:44] [config] bert-masking-fraction: 0.15
[2023-06-25 10:39:44] [config] bert-sep-symbol: "[SEP]"
[2023-06-25 10:39:44] [config] bert-train-type-embeddings: true
[2023-06-25 10:39:44] [config] bert-type-vocab-size: 2
[2023-06-25 10:39:44] [config] build-info: ""
[2023-06-25 10:39:44] [config] check-gradient-nan: false
[2023-06-25 10:39:44] [config] check-nan: false
[2023-06-25 10:39:44] [config] cite: false
[2023-06-25 10:39:44] [config] clip-norm: 5
[2023-06-25 10:39:44] [config] cost-scaling:
[2023-06-25 10:39:44] [config]   []
[2023-06-25 10:39:44] [config] cost-type: ce-mean-words
[2023-06-25 10:39:44] [config] cpu-threads: 0
[2023-06-25 10:39:44] [config] data-threads: 8
[2023-06-25 10:39:44] [config] data-weighting: ""
[2023-06-25 10:39:44] [config] data-weighting-type: sentence
[2023-06-25 10:39:44] [config] dec-cell: gru
[2023-06-25 10:39:44] [config] dec-cell-base-depth: 8
[2023-06-25 10:39:44] [config] dec-cell-high-depth: 1
[2023-06-25 10:39:44] [config] dec-depth: 2
[2023-06-25 10:39:44] [config] devices:
[2023-06-25 10:39:44] [config]   - 0
[2023-06-25 10:39:44] [config] dim-emb: 512
[2023-06-25 10:39:44] [config] dim-rnn: 1024
[2023-06-25 10:39:44] [config] dim-vocabs:
[2023-06-25 10:39:44] [config]   - 54042
[2023-06-25 10:39:44] [config]   - 36507
[2023-06-25 10:39:44] [config] disp-first: 0
[2023-06-25 10:39:44] [config] disp-freq: 1000u
[2023-06-25 10:39:44] [config] disp-label-counts: true
[2023-06-25 10:39:44] [config] dropout-rnn: 0.1
[2023-06-25 10:39:44] [config] dropout-src: 0
[2023-06-25 10:39:44] [config] dropout-trg: 0
[2023-06-25 10:39:44] [config] dump-config: ""
[2023-06-25 10:39:44] [config] dynamic-gradient-scaling:
[2023-06-25 10:39:44] [config]   []
[2023-06-25 10:39:44] [config] early-stopping: 10
[2023-06-25 10:39:44] [config] early-stopping-on: first
[2023-06-25 10:39:44] [config] embedding-fix-src: false
[2023-06-25 10:39:44] [config] embedding-fix-trg: false
[2023-06-25 10:39:44] [config] embedding-normalization: false
[2023-06-25 10:39:44] [config] embedding-vectors:
[2023-06-25 10:39:44] [config]   []
[2023-06-25 10:39:44] [config] enc-cell: gru
[2023-06-25 10:39:44] [config] enc-cell-depth: 4
[2023-06-25 10:39:44] [config] enc-depth: 2
[2023-06-25 10:39:44] [config] enc-type: bidirectional
[2023-06-25 10:39:44] [config] english-title-case-every: 0
[2023-06-25 10:39:44] [config] exponential-smoothing: 0.0001
[2023-06-25 10:39:44] [config] factor-weight: 1
[2023-06-25 10:39:44] [config] factors-combine: sum
[2023-06-25 10:39:44] [config] factors-dim-emb: 0
[2023-06-25 10:39:44] [config] gradient-checkpointing: false
[2023-06-25 10:39:44] [config] gradient-norm-average-window: 100
[2023-06-25 10:39:44] [config] guided-alignment: none
[2023-06-25 10:39:44] [config] guided-alignment-cost: mse
[2023-06-25 10:39:44] [config] guided-alignment-weight: 0.1
[2023-06-25 10:39:44] [config] ignore-model-config: false
[2023-06-25 10:39:44] [config] input-types:
[2023-06-25 10:39:44] [config]   []
[2023-06-25 10:39:44] [config] interpolate-env-vars: false
[2023-06-25 10:39:44] [config] keep-best: false
[2023-06-25 10:39:44] [config] label-smoothing: 0.1
[2023-06-25 10:39:44] [config] layer-normalization: true
[2023-06-25 10:39:44] [config] learn-rate: 0.0003
[2023-06-25 10:39:44] [config] lemma-dependency: ""
[2023-06-25 10:39:44] [config] lemma-dim-emb: 0
[2023-06-25 10:39:44] [config] log: /docker/home/marianmt/logs/marian/split_model_gn_es_edinburgh2017_depth2.log
[2023-06-25 10:39:44] [config] log-level: info
[2023-06-25 10:39:44] [config] log-time-zone: ""
[2023-06-25 10:39:44] [config] logical-epoch:
[2023-06-25 10:39:44] [config]   - 1e
[2023-06-25 10:39:44] [config]   - 0
[2023-06-25 10:39:44] [config] lr-decay: 0
[2023-06-25 10:39:44] [config] lr-decay-freq: 50000
[2023-06-25 10:39:44] [config] lr-decay-inv-sqrt:
[2023-06-25 10:39:44] [config]   - 16000
[2023-06-25 10:39:44] [config] lr-decay-repeat-warmup: false
[2023-06-25 10:39:44] [config] lr-decay-reset-optimizer: false
[2023-06-25 10:39:44] [config] lr-decay-start:
[2023-06-25 10:39:44] [config]   - 10
[2023-06-25 10:39:44] [config]   - 1
[2023-06-25 10:39:44] [config] lr-decay-strategy: epoch+stalled
[2023-06-25 10:39:44] [config] lr-report: false
[2023-06-25 10:39:44] [config] lr-warmup: 0
[2023-06-25 10:39:44] [config] lr-warmup-at-reload: false
[2023-06-25 10:39:44] [config] lr-warmup-cycle: false
[2023-06-25 10:39:44] [config] lr-warmup-start-rate: 0
[2023-06-25 10:39:44] [config] max-length: 100
[2023-06-25 10:39:44] [config] max-length-crop: false
[2023-06-25 10:39:44] [config] max-length-factor: 3
[2023-06-25 10:39:44] [config] maxi-batch: 1000
[2023-06-25 10:39:44] [config] maxi-batch-sort: trg
[2023-06-25 10:39:44] [config] mini-batch: 1000
[2023-06-25 10:39:44] [config] mini-batch-fit: true
[2023-06-25 10:39:44] [config] mini-batch-fit-step: 10
[2023-06-25 10:39:44] [config] mini-batch-round-up: true
[2023-06-25 10:39:44] [config] mini-batch-track-lr: false
[2023-06-25 10:39:44] [config] mini-batch-warmup: 0
[2023-06-25 10:39:44] [config] mini-batch-words: 0
[2023-06-25 10:39:44] [config] mini-batch-words-ref: 0
[2023-06-25 10:39:44] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz
[2023-06-25 10:39:44] [config] multi-loss-type: sum
[2023-06-25 10:39:44] [config] n-best: false
[2023-06-25 10:39:44] [config] no-nccl: false
[2023-06-25 10:39:44] [config] no-reload: false
[2023-06-25 10:39:44] [config] no-restore-corpus: false
[2023-06-25 10:39:44] [config] normalize: 1
[2023-06-25 10:39:44] [config] normalize-gradient: false
[2023-06-25 10:39:44] [config] num-devices: 0
[2023-06-25 10:39:44] [config] optimizer: adam
[2023-06-25 10:39:44] [config] optimizer-delay: 1
[2023-06-25 10:39:44] [config] optimizer-params:
[2023-06-25 10:39:44] [config]   - 0.9
[2023-06-25 10:39:44] [config]   - 0.98
[2023-06-25 10:39:44] [config]   - 1e-09
[2023-06-25 10:39:44] [config] output-omit-bias: false
[2023-06-25 10:39:44] [config] overwrite: false
[2023-06-25 10:39:44] [config] precision:
[2023-06-25 10:39:44] [config]   - float32
[2023-06-25 10:39:44] [config]   - float32
[2023-06-25 10:39:44] [config] pretrained-model: ""
[2023-06-25 10:39:44] [config] quantize-biases: false
[2023-06-25 10:39:44] [config] quantize-bits: 0
[2023-06-25 10:39:44] [config] quantize-log-based: false
[2023-06-25 10:39:44] [config] quantize-optimization-steps: 0
[2023-06-25 10:39:44] [config] quiet: false
[2023-06-25 10:39:44] [config] quiet-translation: true
[2023-06-25 10:39:44] [config] relative-paths: false
[2023-06-25 10:39:44] [config] right-left: false
[2023-06-25 10:39:44] [config] save-freq: 10000u
[2023-06-25 10:39:44] [config] seed: 1234
[2023-06-25 10:39:44] [config] sentencepiece-alphas:
[2023-06-25 10:39:44] [config]   []
[2023-06-25 10:39:44] [config] sentencepiece-max-lines: 2000000
[2023-06-25 10:39:44] [config] sentencepiece-options: ""
[2023-06-25 10:39:44] [config] sharding: global
[2023-06-25 10:39:44] [config] shuffle: data
[2023-06-25 10:39:44] [config] shuffle-in-ram: false
[2023-06-25 10:39:44] [config] sigterm: save-and-exit
[2023-06-25 10:39:44] [config] skip: false
[2023-06-25 10:39:44] [config] sqlite: ""
[2023-06-25 10:39:44] [config] sqlite-drop: false
[2023-06-25 10:39:44] [config] sync-freq: 200u
[2023-06-25 10:39:44] [config] sync-sgd: true
[2023-06-25 10:39:44] [config] tempdir: /tmp
[2023-06-25 10:39:44] [config] tied-embeddings: false
[2023-06-25 10:39:44] [config] tied-embeddings-all: false
[2023-06-25 10:39:44] [config] tied-embeddings-src: false
[2023-06-25 10:39:44] [config] train-embedder-rank:
[2023-06-25 10:39:44] [config]   []
[2023-06-25 10:39:44] [config] train-sets:
[2023-06-25 10:39:44] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-06-25 10:39:44] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-06-25 10:39:44] [config] transformer-aan-activation: swish
[2023-06-25 10:39:44] [config] transformer-aan-depth: 2
[2023-06-25 10:39:44] [config] transformer-aan-nogate: false
[2023-06-25 10:39:44] [config] transformer-decoder-autoreg: self-attention
[2023-06-25 10:39:44] [config] transformer-decoder-dim-ffn: 0
[2023-06-25 10:39:44] [config] transformer-decoder-ffn-depth: 0
[2023-06-25 10:39:44] [config] transformer-depth-scaling: false
[2023-06-25 10:39:44] [config] transformer-dim-aan: 2048
[2023-06-25 10:39:44] [config] transformer-dim-ffn: 2048
[2023-06-25 10:39:44] [config] transformer-dropout: 0
[2023-06-25 10:39:44] [config] transformer-dropout-attention: 0
[2023-06-25 10:39:44] [config] transformer-dropout-ffn: 0
[2023-06-25 10:39:44] [config] transformer-ffn-activation: swish
[2023-06-25 10:39:44] [config] transformer-ffn-depth: 2
[2023-06-25 10:39:44] [config] transformer-guided-alignment-layer: last
[2023-06-25 10:39:44] [config] transformer-heads: 8
[2023-06-25 10:39:44] [config] transformer-no-projection: false
[2023-06-25 10:39:44] [config] transformer-pool: false
[2023-06-25 10:39:44] [config] transformer-postprocess: dan
[2023-06-25 10:39:44] [config] transformer-postprocess-emb: d
[2023-06-25 10:39:44] [config] transformer-postprocess-top: ""
[2023-06-25 10:39:44] [config] transformer-preprocess: ""
[2023-06-25 10:39:44] [config] transformer-tied-layers:
[2023-06-25 10:39:44] [config]   []
[2023-06-25 10:39:44] [config] transformer-train-position-embeddings: false
[2023-06-25 10:39:44] [config] tsv: false
[2023-06-25 10:39:44] [config] tsv-fields: 0
[2023-06-25 10:39:44] [config] type: s2s
[2023-06-25 10:39:44] [config] ulr: false
[2023-06-25 10:39:44] [config] ulr-dim-emb: 0
[2023-06-25 10:39:44] [config] ulr-dropout: 0
[2023-06-25 10:39:44] [config] ulr-keys-vectors: ""
[2023-06-25 10:39:44] [config] ulr-query-vectors: ""
[2023-06-25 10:39:44] [config] ulr-softmax-temperature: 1
[2023-06-25 10:39:44] [config] ulr-trainable-transformation: false
[2023-06-25 10:39:44] [config] unlikelihood-loss: false
[2023-06-25 10:39:44] [config] valid-freq: 5000000
[2023-06-25 10:39:44] [config] valid-log: /docker/home/marianmt/logs/marian/split_tok_150_gn_es_edinburgh2017_depth2.log
[2023-06-25 10:39:44] [config] valid-max-length: 1000
[2023-06-25 10:39:44] [config] valid-metrics:
[2023-06-25 10:39:44] [config]   - cross-entropy
[2023-06-25 10:39:44] [config]   - translation
[2023-06-25 10:39:44] [config] valid-mini-batch: 32
[2023-06-25 10:39:44] [config] valid-reset-stalled: false
[2023-06-25 10:39:44] [config] valid-script-args:
[2023-06-25 10:39:44] [config]   []
[2023-06-25 10:39:44] [config] valid-script-path: ""
[2023-06-25 10:39:44] [config] valid-sets:
[2023-06-25 10:39:44] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-06-25 10:39:44] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-06-25 10:39:44] [config] valid-translation-output: /docker/home/marianmt/evaluation/model-epochs.txt
[2023-06-25 10:39:44] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-06-25 10:39:44] [config] vocabs:
[2023-06-25 10:39:44] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens.txt.gn
[2023-06-25 10:39:44] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens.txt.es
[2023-06-25 10:39:44] [config] word-penalty: 0
[2023-06-25 10:39:44] [config] word-scores: false
[2023-06-25 10:39:44] [config] workspace: 2048
[2023-06-25 10:39:44] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-06-25 10:39:44] Using synchronous SGD
[2023-06-25 10:39:49] Synced seed 1234
[2023-06-25 10:39:49] [data] Loading vocabulary from text file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens.txt.gn
[2023-06-25 10:39:49] [data] Setting vocabulary size for input 0 to 54,042
[2023-06-25 10:39:49] [data] Loading vocabulary from text file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens.txt.es
[2023-06-25 10:39:49] [data] Setting vocabulary size for input 1 to 36,507
[2023-06-25 10:39:49] [batching] Collecting statistics for batch fitting with step size 10
[2023-06-25 10:39:49] [MPI rank 0 out of 1]: GPU[0]
[2023-06-25 10:39:50] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-06-25 10:39:51] [comm] Using NCCL 2.8.3 for GPU communication
[2023-06-25 10:39:51] [comm] Using global sharding
[2023-06-25 10:39:51] [comm] NCCLCommunicators constructed successfully
[2023-06-25 10:39:51] [training] Using 1 GPUs
[2023-06-25 10:39:51] [logits] Applying loss function for 1 factor(s)
[2023-06-25 10:39:51] [memory] Reserving 666 MB, device gpu0
[2023-06-25 10:39:51] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-06-25 10:39:51] [memory] Reserving 666 MB, device gpu0
[2023-06-25 10:40:15] [batching] Done. Typical MB size is 1,196 target words
[2023-06-25 10:40:16] [valid] No post-processing script given for validating translator
[2023-06-25 10:40:16] [MPI rank 0 out of 1]: GPU[0]
[2023-06-25 10:40:16] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-06-25 10:40:16] [comm] Using NCCL 2.8.3 for GPU communication
[2023-06-25 10:40:16] [comm] Using global sharding
[2023-06-25 10:40:16] [comm] NCCLCommunicators constructed successfully
[2023-06-25 10:40:16] [training] Using 1 GPUs
[2023-06-25 10:40:16] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz
[2023-06-25 10:40:42] Allocating memory for general optimizer shards
[2023-06-25 10:40:42] [memory] Reserving 666 MB, device gpu0
[2023-06-25 10:40:42] Loading Adam parameters
[2023-06-25 10:40:43] [memory] Reserving 1332 MB, device gpu0
[2023-06-25 10:40:43] [memory] Reserving 666 MB, device gpu0
[2023-06-25 10:40:43] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz.optimizer.npz
[2023-06-25 10:40:43] [data] Restoring the corpus state to epoch 31, batch 14670
[2023-06-25 10:40:43] [data] Shuffling data
[2023-06-25 10:40:43] [data] Done reading 20,192 sentences
[2023-06-25 10:40:44] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 10:40:44] Training started
[2023-06-25 10:40:44] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-06-25 10:40:44] [memory] Reserving 666 MB, device gpu0
[2023-06-25 10:40:45] Parameter type float32, optimization type float32, casting types false
[2023-06-25 10:43:06] Ep. 31 : Up. 15000 : Sen. 13,171 : Cost 1.77616131 : Time 170.53s : 5733.63 words/s : gNorm 0.4888
[2023-06-25 10:44:11] Seen 20,177 samples
[2023-06-25 10:44:11] Starting data epoch 32 in logical epoch 32
[2023-06-25 10:44:11] [data] Shuffling data
[2023-06-25 10:44:11] [data] Done reading 20,192 sentences
[2023-06-25 10:44:11] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 10:47:43] Seen 20,177 samples
[2023-06-25 10:47:43] Starting data epoch 33 in logical epoch 33
[2023-06-25 10:47:43] [data] Shuffling data
[2023-06-25 10:47:43] [data] Done reading 20,192 sentences
[2023-06-25 10:47:43] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 10:50:17] Ep. 33 : Up. 16000 : Sen. 14,616 : Cost 1.76657867 : Time 430.97s : 2259.48 words/s : gNorm 0.4571
[2023-06-25 10:51:13] Seen 20,177 samples
[2023-06-25 10:51:13] Starting data epoch 34 in logical epoch 34
[2023-06-25 10:51:13] [data] Shuffling data
[2023-06-25 10:51:13] [data] Done reading 20,192 sentences
[2023-06-25 10:51:13] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 10:54:45] Seen 20,177 samples
[2023-06-25 10:54:45] Starting data epoch 35 in logical epoch 35
[2023-06-25 10:54:45] [data] Shuffling data
[2023-06-25 10:54:45] [data] Done reading 20,192 sentences
[2023-06-25 10:54:45] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 10:57:29] Ep. 35 : Up. 17000 : Sen. 15,381 : Cost 1.75067616 : Time 432.27s : 2262.37 words/s : gNorm 0.4246
[2023-06-25 10:58:18] Seen 20,177 samples
[2023-06-25 10:58:18] Starting data epoch 36 in logical epoch 36
[2023-06-25 10:58:18] [data] Shuffling data
[2023-06-25 10:58:18] [data] Done reading 20,192 sentences
[2023-06-25 10:58:18] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 11:01:51] Seen 20,177 samples
[2023-06-25 11:01:51] Starting data epoch 37 in logical epoch 37
[2023-06-25 11:01:51] [data] Shuffling data
[2023-06-25 11:01:51] [data] Done reading 20,192 sentences
[2023-06-25 11:01:51] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 11:04:43] Ep. 37 : Up. 18000 : Sen. 16,446 : Cost 1.73713899 : Time 433.53s : 2256.70 words/s : gNorm 0.4219
[2023-06-25 11:05:24] Seen 20,177 samples
[2023-06-25 11:05:24] Starting data epoch 38 in logical epoch 38
[2023-06-25 11:05:24] [data] Shuffling data
[2023-06-25 11:05:24] [data] Done reading 20,192 sentences
[2023-06-25 11:05:24] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 11:08:56] Seen 20,177 samples
[2023-06-25 11:08:56] Starting data epoch 39 in logical epoch 39
[2023-06-25 11:08:56] [data] Shuffling data
[2023-06-25 11:08:56] [data] Done reading 20,192 sentences
[2023-06-25 11:08:56] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 11:11:58] Ep. 39 : Up. 19000 : Sen. 17,184 : Cost 1.72420955 : Time 435.69s : 2237.76 words/s : gNorm 0.4034
[2023-06-25 11:12:28] Seen 20,177 samples
[2023-06-25 11:12:28] Starting data epoch 40 in logical epoch 40
[2023-06-25 11:12:28] [data] Shuffling data
[2023-06-25 11:12:28] [data] Done reading 20,192 sentences
[2023-06-25 11:12:28] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 11:16:01] Seen 20,177 samples
[2023-06-25 11:16:01] Starting data epoch 41 in logical epoch 41
[2023-06-25 11:16:01] Training finished
[2023-06-25 11:16:16] [valid] Ep. 41 : Up. 19560 : cross-entropy : 99.0377 : stalled 3 times (last best: 86.5722)
[2023-06-25 11:19:32] [valid] Ep. 41 : Up. 19560 : translation : 0 : new best
[2023-06-25 11:19:32] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz
[2023-06-25 11:19:40] Saving Adam parameters
[2023-06-25 11:19:42] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz.optimizer.npz
[2023-06-25 11:28:44] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-06-25 11:28:44] [marian] Running on node07.datos.cluster.uy as process 4426 with command line:
[2023-06-25 11:28:44] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz --after-epochs 50 --valid-freq 5000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens.txt.gn /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens.txt.es --seed 1234 --type s2s --max-length 100 --mini-batch-fit --mini-batch 1000 --maxi-batch 1000 --beam-size 12 --normalize 1 --cost-type ce-mean-words --enc-type bidirectional --enc-depth 2 --enc-cell-depth 4 --dec-depth 2 --dec-cell-base-depth 8 --dec-cell-high-depth 1 --layer-normalization --dropout-rnn 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-decay-inv-sqrt 16000 --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --sync-sgd --exponential-smoothing --cpu-threads 0 --log /docker/home/marianmt/logs/marian/split_model_gn_es_edinburgh2017_depth2.log --valid-log /docker/home/marianmt/logs/marian/split_tok_150_gn_es_edinburgh2017_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/model-epochs.txt --quiet-translation
[2023-06-25 11:28:45] [config] after: 0e
[2023-06-25 11:28:45] [config] after-batches: 0
[2023-06-25 11:28:45] [config] after-epochs: 50
[2023-06-25 11:28:45] [config] all-caps-every: 0
[2023-06-25 11:28:45] [config] allow-unk: false
[2023-06-25 11:28:45] [config] authors: false
[2023-06-25 11:28:45] [config] beam-size: 12
[2023-06-25 11:28:45] [config] bert-class-symbol: "[CLS]"
[2023-06-25 11:28:45] [config] bert-mask-symbol: "[MASK]"
[2023-06-25 11:28:45] [config] bert-masking-fraction: 0.15
[2023-06-25 11:28:45] [config] bert-sep-symbol: "[SEP]"
[2023-06-25 11:28:45] [config] bert-train-type-embeddings: true
[2023-06-25 11:28:45] [config] bert-type-vocab-size: 2
[2023-06-25 11:28:45] [config] build-info: ""
[2023-06-25 11:28:45] [config] check-gradient-nan: false
[2023-06-25 11:28:45] [config] check-nan: false
[2023-06-25 11:28:45] [config] cite: false
[2023-06-25 11:28:45] [config] clip-norm: 5
[2023-06-25 11:28:45] [config] cost-scaling:
[2023-06-25 11:28:45] [config]   []
[2023-06-25 11:28:45] [config] cost-type: ce-mean-words
[2023-06-25 11:28:45] [config] cpu-threads: 0
[2023-06-25 11:28:45] [config] data-threads: 8
[2023-06-25 11:28:45] [config] data-weighting: ""
[2023-06-25 11:28:45] [config] data-weighting-type: sentence
[2023-06-25 11:28:45] [config] dec-cell: gru
[2023-06-25 11:28:45] [config] dec-cell-base-depth: 8
[2023-06-25 11:28:45] [config] dec-cell-high-depth: 1
[2023-06-25 11:28:45] [config] dec-depth: 2
[2023-06-25 11:28:45] [config] devices:
[2023-06-25 11:28:45] [config]   - 0
[2023-06-25 11:28:45] [config] dim-emb: 512
[2023-06-25 11:28:45] [config] dim-rnn: 1024
[2023-06-25 11:28:45] [config] dim-vocabs:
[2023-06-25 11:28:45] [config]   - 54042
[2023-06-25 11:28:45] [config]   - 36507
[2023-06-25 11:28:45] [config] disp-first: 0
[2023-06-25 11:28:45] [config] disp-freq: 1000u
[2023-06-25 11:28:45] [config] disp-label-counts: true
[2023-06-25 11:28:45] [config] dropout-rnn: 0.1
[2023-06-25 11:28:45] [config] dropout-src: 0
[2023-06-25 11:28:45] [config] dropout-trg: 0
[2023-06-25 11:28:45] [config] dump-config: ""
[2023-06-25 11:28:45] [config] dynamic-gradient-scaling:
[2023-06-25 11:28:45] [config]   []
[2023-06-25 11:28:45] [config] early-stopping: 10
[2023-06-25 11:28:45] [config] early-stopping-on: first
[2023-06-25 11:28:45] [config] embedding-fix-src: false
[2023-06-25 11:28:45] [config] embedding-fix-trg: false
[2023-06-25 11:28:45] [config] embedding-normalization: false
[2023-06-25 11:28:45] [config] embedding-vectors:
[2023-06-25 11:28:45] [config]   []
[2023-06-25 11:28:45] [config] enc-cell: gru
[2023-06-25 11:28:45] [config] enc-cell-depth: 4
[2023-06-25 11:28:45] [config] enc-depth: 2
[2023-06-25 11:28:45] [config] enc-type: bidirectional
[2023-06-25 11:28:45] [config] english-title-case-every: 0
[2023-06-25 11:28:45] [config] exponential-smoothing: 0.0001
[2023-06-25 11:28:45] [config] factor-weight: 1
[2023-06-25 11:28:45] [config] factors-combine: sum
[2023-06-25 11:28:45] [config] factors-dim-emb: 0
[2023-06-25 11:28:45] [config] gradient-checkpointing: false
[2023-06-25 11:28:45] [config] gradient-norm-average-window: 100
[2023-06-25 11:28:45] [config] guided-alignment: none
[2023-06-25 11:28:45] [config] guided-alignment-cost: mse
[2023-06-25 11:28:45] [config] guided-alignment-weight: 0.1
[2023-06-25 11:28:45] [config] ignore-model-config: false
[2023-06-25 11:28:45] [config] input-types:
[2023-06-25 11:28:45] [config]   []
[2023-06-25 11:28:45] [config] interpolate-env-vars: false
[2023-06-25 11:28:45] [config] keep-best: false
[2023-06-25 11:28:45] [config] label-smoothing: 0.1
[2023-06-25 11:28:45] [config] layer-normalization: true
[2023-06-25 11:28:45] [config] learn-rate: 0.0003
[2023-06-25 11:28:45] [config] lemma-dependency: ""
[2023-06-25 11:28:45] [config] lemma-dim-emb: 0
[2023-06-25 11:28:45] [config] log: /docker/home/marianmt/logs/marian/split_model_gn_es_edinburgh2017_depth2.log
[2023-06-25 11:28:45] [config] log-level: info
[2023-06-25 11:28:45] [config] log-time-zone: ""
[2023-06-25 11:28:45] [config] logical-epoch:
[2023-06-25 11:28:45] [config]   - 1e
[2023-06-25 11:28:45] [config]   - 0
[2023-06-25 11:28:45] [config] lr-decay: 0
[2023-06-25 11:28:45] [config] lr-decay-freq: 50000
[2023-06-25 11:28:45] [config] lr-decay-inv-sqrt:
[2023-06-25 11:28:45] [config]   - 16000
[2023-06-25 11:28:45] [config] lr-decay-repeat-warmup: false
[2023-06-25 11:28:45] [config] lr-decay-reset-optimizer: false
[2023-06-25 11:28:45] [config] lr-decay-start:
[2023-06-25 11:28:45] [config]   - 10
[2023-06-25 11:28:45] [config]   - 1
[2023-06-25 11:28:45] [config] lr-decay-strategy: epoch+stalled
[2023-06-25 11:28:45] [config] lr-report: false
[2023-06-25 11:28:45] [config] lr-warmup: 0
[2023-06-25 11:28:45] [config] lr-warmup-at-reload: false
[2023-06-25 11:28:45] [config] lr-warmup-cycle: false
[2023-06-25 11:28:45] [config] lr-warmup-start-rate: 0
[2023-06-25 11:28:45] [config] max-length: 100
[2023-06-25 11:28:45] [config] max-length-crop: false
[2023-06-25 11:28:45] [config] max-length-factor: 3
[2023-06-25 11:28:45] [config] maxi-batch: 1000
[2023-06-25 11:28:45] [config] maxi-batch-sort: trg
[2023-06-25 11:28:45] [config] mini-batch: 1000
[2023-06-25 11:28:45] [config] mini-batch-fit: true
[2023-06-25 11:28:45] [config] mini-batch-fit-step: 10
[2023-06-25 11:28:45] [config] mini-batch-round-up: true
[2023-06-25 11:28:45] [config] mini-batch-track-lr: false
[2023-06-25 11:28:45] [config] mini-batch-warmup: 0
[2023-06-25 11:28:45] [config] mini-batch-words: 0
[2023-06-25 11:28:45] [config] mini-batch-words-ref: 0
[2023-06-25 11:28:45] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz
[2023-06-25 11:28:45] [config] multi-loss-type: sum
[2023-06-25 11:28:45] [config] n-best: false
[2023-06-25 11:28:45] [config] no-nccl: false
[2023-06-25 11:28:45] [config] no-reload: false
[2023-06-25 11:28:45] [config] no-restore-corpus: false
[2023-06-25 11:28:45] [config] normalize: 1
[2023-06-25 11:28:45] [config] normalize-gradient: false
[2023-06-25 11:28:45] [config] num-devices: 0
[2023-06-25 11:28:45] [config] optimizer: adam
[2023-06-25 11:28:45] [config] optimizer-delay: 1
[2023-06-25 11:28:45] [config] optimizer-params:
[2023-06-25 11:28:45] [config]   - 0.9
[2023-06-25 11:28:45] [config]   - 0.98
[2023-06-25 11:28:45] [config]   - 1e-09
[2023-06-25 11:28:45] [config] output-omit-bias: false
[2023-06-25 11:28:45] [config] overwrite: false
[2023-06-25 11:28:45] [config] precision:
[2023-06-25 11:28:45] [config]   - float32
[2023-06-25 11:28:45] [config]   - float32
[2023-06-25 11:28:45] [config] pretrained-model: ""
[2023-06-25 11:28:45] [config] quantize-biases: false
[2023-06-25 11:28:45] [config] quantize-bits: 0
[2023-06-25 11:28:45] [config] quantize-log-based: false
[2023-06-25 11:28:45] [config] quantize-optimization-steps: 0
[2023-06-25 11:28:45] [config] quiet: false
[2023-06-25 11:28:45] [config] quiet-translation: true
[2023-06-25 11:28:45] [config] relative-paths: false
[2023-06-25 11:28:45] [config] right-left: false
[2023-06-25 11:28:45] [config] save-freq: 10000u
[2023-06-25 11:28:45] [config] seed: 1234
[2023-06-25 11:28:45] [config] sentencepiece-alphas:
[2023-06-25 11:28:45] [config]   []
[2023-06-25 11:28:45] [config] sentencepiece-max-lines: 2000000
[2023-06-25 11:28:45] [config] sentencepiece-options: ""
[2023-06-25 11:28:45] [config] sharding: global
[2023-06-25 11:28:45] [config] shuffle: data
[2023-06-25 11:28:45] [config] shuffle-in-ram: false
[2023-06-25 11:28:45] [config] sigterm: save-and-exit
[2023-06-25 11:28:45] [config] skip: false
[2023-06-25 11:28:45] [config] sqlite: ""
[2023-06-25 11:28:45] [config] sqlite-drop: false
[2023-06-25 11:28:45] [config] sync-freq: 200u
[2023-06-25 11:28:45] [config] sync-sgd: true
[2023-06-25 11:28:45] [config] tempdir: /tmp
[2023-06-25 11:28:45] [config] tied-embeddings: false
[2023-06-25 11:28:45] [config] tied-embeddings-all: false
[2023-06-25 11:28:45] [config] tied-embeddings-src: false
[2023-06-25 11:28:45] [config] train-embedder-rank:
[2023-06-25 11:28:45] [config]   []
[2023-06-25 11:28:45] [config] train-sets:
[2023-06-25 11:28:45] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-06-25 11:28:45] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-06-25 11:28:45] [config] transformer-aan-activation: swish
[2023-06-25 11:28:45] [config] transformer-aan-depth: 2
[2023-06-25 11:28:45] [config] transformer-aan-nogate: false
[2023-06-25 11:28:45] [config] transformer-decoder-autoreg: self-attention
[2023-06-25 11:28:45] [config] transformer-decoder-dim-ffn: 0
[2023-06-25 11:28:45] [config] transformer-decoder-ffn-depth: 0
[2023-06-25 11:28:45] [config] transformer-depth-scaling: false
[2023-06-25 11:28:45] [config] transformer-dim-aan: 2048
[2023-06-25 11:28:45] [config] transformer-dim-ffn: 2048
[2023-06-25 11:28:45] [config] transformer-dropout: 0
[2023-06-25 11:28:45] [config] transformer-dropout-attention: 0
[2023-06-25 11:28:45] [config] transformer-dropout-ffn: 0
[2023-06-25 11:28:45] [config] transformer-ffn-activation: swish
[2023-06-25 11:28:45] [config] transformer-ffn-depth: 2
[2023-06-25 11:28:45] [config] transformer-guided-alignment-layer: last
[2023-06-25 11:28:45] [config] transformer-heads: 8
[2023-06-25 11:28:45] [config] transformer-no-projection: false
[2023-06-25 11:28:45] [config] transformer-pool: false
[2023-06-25 11:28:45] [config] transformer-postprocess: dan
[2023-06-25 11:28:45] [config] transformer-postprocess-emb: d
[2023-06-25 11:28:45] [config] transformer-postprocess-top: ""
[2023-06-25 11:28:45] [config] transformer-preprocess: ""
[2023-06-25 11:28:45] [config] transformer-tied-layers:
[2023-06-25 11:28:45] [config]   []
[2023-06-25 11:28:45] [config] transformer-train-position-embeddings: false
[2023-06-25 11:28:45] [config] tsv: false
[2023-06-25 11:28:45] [config] tsv-fields: 0
[2023-06-25 11:28:45] [config] type: s2s
[2023-06-25 11:28:45] [config] ulr: false
[2023-06-25 11:28:45] [config] ulr-dim-emb: 0
[2023-06-25 11:28:45] [config] ulr-dropout: 0
[2023-06-25 11:28:45] [config] ulr-keys-vectors: ""
[2023-06-25 11:28:45] [config] ulr-query-vectors: ""
[2023-06-25 11:28:45] [config] ulr-softmax-temperature: 1
[2023-06-25 11:28:45] [config] ulr-trainable-transformation: false
[2023-06-25 11:28:45] [config] unlikelihood-loss: false
[2023-06-25 11:28:45] [config] valid-freq: 5000000
[2023-06-25 11:28:45] [config] valid-log: /docker/home/marianmt/logs/marian/split_tok_150_gn_es_edinburgh2017_depth2.log
[2023-06-25 11:28:45] [config] valid-max-length: 1000
[2023-06-25 11:28:45] [config] valid-metrics:
[2023-06-25 11:28:45] [config]   - cross-entropy
[2023-06-25 11:28:45] [config]   - translation
[2023-06-25 11:28:45] [config] valid-mini-batch: 32
[2023-06-25 11:28:45] [config] valid-reset-stalled: false
[2023-06-25 11:28:45] [config] valid-script-args:
[2023-06-25 11:28:45] [config]   []
[2023-06-25 11:28:45] [config] valid-script-path: ""
[2023-06-25 11:28:45] [config] valid-sets:
[2023-06-25 11:28:45] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-06-25 11:28:45] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-06-25 11:28:45] [config] valid-translation-output: /docker/home/marianmt/evaluation/model-epochs.txt
[2023-06-25 11:28:45] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-06-25 11:28:45] [config] vocabs:
[2023-06-25 11:28:45] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens.txt.gn
[2023-06-25 11:28:45] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens.txt.es
[2023-06-25 11:28:45] [config] word-penalty: 0
[2023-06-25 11:28:45] [config] word-scores: false
[2023-06-25 11:28:45] [config] workspace: 2048
[2023-06-25 11:28:45] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-06-25 11:28:45] Using synchronous SGD
[2023-06-25 11:28:47] Synced seed 1234
[2023-06-25 11:28:47] [data] Loading vocabulary from text file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens.txt.gn
[2023-06-25 11:28:47] [data] Setting vocabulary size for input 0 to 54,042
[2023-06-25 11:28:47] [data] Loading vocabulary from text file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens.txt.es
[2023-06-25 11:28:47] [data] Setting vocabulary size for input 1 to 36,507
[2023-06-25 11:28:47] [batching] Collecting statistics for batch fitting with step size 10
[2023-06-25 11:28:47] [MPI rank 0 out of 1]: GPU[0]
[2023-06-25 11:28:47] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-06-25 11:28:48] [comm] Using NCCL 2.8.3 for GPU communication
[2023-06-25 11:28:48] [comm] Using global sharding
[2023-06-25 11:28:48] [comm] NCCLCommunicators constructed successfully
[2023-06-25 11:28:48] [training] Using 1 GPUs
[2023-06-25 11:28:48] [logits] Applying loss function for 1 factor(s)
[2023-06-25 11:28:48] [memory] Reserving 666 MB, device gpu0
[2023-06-25 11:28:48] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-06-25 11:28:48] [memory] Reserving 666 MB, device gpu0
[2023-06-25 11:29:13] [batching] Done. Typical MB size is 1,196 target words
[2023-06-25 11:29:13] [valid] No post-processing script given for validating translator
[2023-06-25 11:29:13] [MPI rank 0 out of 1]: GPU[0]
[2023-06-25 11:29:13] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-06-25 11:29:13] [comm] Using NCCL 2.8.3 for GPU communication
[2023-06-25 11:29:13] [comm] Using global sharding
[2023-06-25 11:29:13] [comm] NCCLCommunicators constructed successfully
[2023-06-25 11:29:13] [training] Using 1 GPUs
[2023-06-25 11:29:13] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz
[2023-06-25 11:29:32] Allocating memory for general optimizer shards
[2023-06-25 11:29:32] [memory] Reserving 666 MB, device gpu0
[2023-06-25 11:29:33] Loading Adam parameters
[2023-06-25 11:29:33] [memory] Reserving 1332 MB, device gpu0
[2023-06-25 11:29:33] [memory] Reserving 666 MB, device gpu0
[2023-06-25 11:29:34] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz.optimizer.npz
[2023-06-25 11:29:34] [data] Restoring the corpus state to epoch 41, batch 19560
[2023-06-25 11:29:34] [data] Shuffling data
[2023-06-25 11:29:34] [data] Done reading 20,192 sentences
[2023-06-25 11:29:34] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 11:29:34] Training started
[2023-06-25 11:29:34] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-06-25 11:29:34] [memory] Reserving 666 MB, device gpu0
[2023-06-25 11:29:34] Parameter type float32, optimization type float32, casting types false
[2023-06-25 11:32:42] Ep. 41 : Up. 20000 : Sen. 18,250 : Cost 1.71331632 : Time 209.38s : 4673.45 words/s : gNorm 0.3591
[2023-06-25 11:32:42] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.iter20000.npz
[2023-06-25 11:32:48] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz
[2023-06-25 11:32:56] Saving Adam parameters
[2023-06-25 11:32:59] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz.optimizer.npz
[2023-06-25 11:33:43] Seen 20,177 samples
[2023-06-25 11:33:43] Starting data epoch 42 in logical epoch 42
[2023-06-25 11:33:43] [data] Shuffling data
[2023-06-25 11:33:43] [data] Done reading 20,192 sentences
[2023-06-25 11:33:43] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 11:37:12] Seen 20,177 samples
[2023-06-25 11:37:12] Starting data epoch 43 in logical epoch 43
[2023-06-25 11:37:12] [data] Shuffling data
[2023-06-25 11:37:12] [data] Done reading 20,192 sentences
[2023-06-25 11:37:12] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 11:40:30] Ep. 43 : Up. 21000 : Sen. 19,111 : Cost 1.70551491 : Time 468.17s : 2086.67 words/s : gNorm 0.3457
[2023-06-25 11:40:43] Seen 20,177 samples
[2023-06-25 11:40:43] Starting data epoch 44 in logical epoch 44
[2023-06-25 11:40:43] [data] Shuffling data
[2023-06-25 11:40:43] [data] Done reading 20,192 sentences
[2023-06-25 11:40:44] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 11:44:16] Seen 20,177 samples
[2023-06-25 11:44:16] Starting data epoch 45 in logical epoch 45
[2023-06-25 11:44:16] [data] Shuffling data
[2023-06-25 11:44:16] [data] Done reading 20,192 sentences
[2023-06-25 11:44:16] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 11:47:46] Ep. 45 : Up. 22000 : Sen. 20,033 : Cost 1.70059478 : Time 436.02s : 2242.54 words/s : gNorm 0.3396
[2023-06-25 11:47:49] Seen 20,177 samples
[2023-06-25 11:47:49] Starting data epoch 46 in logical epoch 46
[2023-06-25 11:47:49] [data] Shuffling data
[2023-06-25 11:47:49] [data] Done reading 20,192 sentences
[2023-06-25 11:47:49] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 11:51:21] Seen 20,177 samples
[2023-06-25 11:51:21] Starting data epoch 47 in logical epoch 47
[2023-06-25 11:51:21] [data] Shuffling data
[2023-06-25 11:51:21] [data] Done reading 20,192 sentences
[2023-06-25 11:51:22] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 11:54:54] Seen 20,177 samples
[2023-06-25 11:54:54] Starting data epoch 48 in logical epoch 48
[2023-06-25 11:54:54] [data] Shuffling data
[2023-06-25 11:54:54] [data] Done reading 20,192 sentences
[2023-06-25 11:54:54] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 11:55:02] Ep. 48 : Up. 23000 : Sen. 589 : Cost 1.69100916 : Time 435.45s : 2247.32 words/s : gNorm 0.3068
[2023-06-25 11:58:27] Seen 20,177 samples
[2023-06-25 11:58:27] Starting data epoch 49 in logical epoch 49
[2023-06-25 11:58:27] [data] Shuffling data
[2023-06-25 11:58:27] [data] Done reading 20,192 sentences
[2023-06-25 11:58:27] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 12:01:59] Seen 20,177 samples
[2023-06-25 12:01:59] Starting data epoch 50 in logical epoch 50
[2023-06-25 12:01:59] [data] Shuffling data
[2023-06-25 12:01:59] [data] Done reading 20,192 sentences
[2023-06-25 12:01:59] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 12:02:16] Ep. 50 : Up. 24000 : Sen. 1,585 : Cost 1.68455184 : Time 434.43s : 2244.61 words/s : gNorm 0.2981
[2023-06-25 12:05:32] Seen 20,177 samples
[2023-06-25 12:05:32] Starting data epoch 51 in logical epoch 51
[2023-06-25 12:05:32] Training finished
[2023-06-25 12:05:47] [valid] Ep. 51 : Up. 24450 : cross-entropy : 99.8267 : stalled 4 times (last best: 86.5722)
[2023-06-25 12:08:58] [valid] Ep. 51 : Up. 24450 : translation : 0 : new best
[2023-06-25 12:08:58] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz
[2023-06-25 12:09:07] Saving Adam parameters
[2023-06-25 12:09:09] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz.optimizer.npz
[2023-06-25 12:18:02] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-06-25 12:18:02] [marian] Running on node07.datos.cluster.uy as process 7786 with command line:
[2023-06-25 12:18:02] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz --after-epochs 60 --valid-freq 5000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens.txt.gn /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens.txt.es --seed 1234 --type s2s --max-length 100 --mini-batch-fit --mini-batch 1000 --maxi-batch 1000 --beam-size 12 --normalize 1 --cost-type ce-mean-words --enc-type bidirectional --enc-depth 2 --enc-cell-depth 4 --dec-depth 2 --dec-cell-base-depth 8 --dec-cell-high-depth 1 --layer-normalization --dropout-rnn 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-decay-inv-sqrt 16000 --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --sync-sgd --exponential-smoothing --cpu-threads 0 --log /docker/home/marianmt/logs/marian/split_model_gn_es_edinburgh2017_depth2.log --valid-log /docker/home/marianmt/logs/marian/split_tok_150_gn_es_edinburgh2017_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/model-epochs.txt --quiet-translation
[2023-06-25 12:18:02] [config] after: 0e
[2023-06-25 12:18:02] [config] after-batches: 0
[2023-06-25 12:18:02] [config] after-epochs: 60
[2023-06-25 12:18:02] [config] all-caps-every: 0
[2023-06-25 12:18:02] [config] allow-unk: false
[2023-06-25 12:18:02] [config] authors: false
[2023-06-25 12:18:02] [config] beam-size: 12
[2023-06-25 12:18:02] [config] bert-class-symbol: "[CLS]"
[2023-06-25 12:18:02] [config] bert-mask-symbol: "[MASK]"
[2023-06-25 12:18:02] [config] bert-masking-fraction: 0.15
[2023-06-25 12:18:02] [config] bert-sep-symbol: "[SEP]"
[2023-06-25 12:18:02] [config] bert-train-type-embeddings: true
[2023-06-25 12:18:02] [config] bert-type-vocab-size: 2
[2023-06-25 12:18:02] [config] build-info: ""
[2023-06-25 12:18:02] [config] check-gradient-nan: false
[2023-06-25 12:18:02] [config] check-nan: false
[2023-06-25 12:18:02] [config] cite: false
[2023-06-25 12:18:02] [config] clip-norm: 5
[2023-06-25 12:18:02] [config] cost-scaling:
[2023-06-25 12:18:02] [config]   []
[2023-06-25 12:18:02] [config] cost-type: ce-mean-words
[2023-06-25 12:18:02] [config] cpu-threads: 0
[2023-06-25 12:18:02] [config] data-threads: 8
[2023-06-25 12:18:02] [config] data-weighting: ""
[2023-06-25 12:18:02] [config] data-weighting-type: sentence
[2023-06-25 12:18:02] [config] dec-cell: gru
[2023-06-25 12:18:02] [config] dec-cell-base-depth: 8
[2023-06-25 12:18:02] [config] dec-cell-high-depth: 1
[2023-06-25 12:18:02] [config] dec-depth: 2
[2023-06-25 12:18:02] [config] devices:
[2023-06-25 12:18:02] [config]   - 0
[2023-06-25 12:18:02] [config] dim-emb: 512
[2023-06-25 12:18:02] [config] dim-rnn: 1024
[2023-06-25 12:18:02] [config] dim-vocabs:
[2023-06-25 12:18:02] [config]   - 54042
[2023-06-25 12:18:02] [config]   - 36507
[2023-06-25 12:18:02] [config] disp-first: 0
[2023-06-25 12:18:02] [config] disp-freq: 1000u
[2023-06-25 12:18:02] [config] disp-label-counts: true
[2023-06-25 12:18:02] [config] dropout-rnn: 0.1
[2023-06-25 12:18:02] [config] dropout-src: 0
[2023-06-25 12:18:02] [config] dropout-trg: 0
[2023-06-25 12:18:02] [config] dump-config: ""
[2023-06-25 12:18:02] [config] dynamic-gradient-scaling:
[2023-06-25 12:18:02] [config]   []
[2023-06-25 12:18:02] [config] early-stopping: 10
[2023-06-25 12:18:02] [config] early-stopping-on: first
[2023-06-25 12:18:02] [config] embedding-fix-src: false
[2023-06-25 12:18:02] [config] embedding-fix-trg: false
[2023-06-25 12:18:02] [config] embedding-normalization: false
[2023-06-25 12:18:02] [config] embedding-vectors:
[2023-06-25 12:18:02] [config]   []
[2023-06-25 12:18:02] [config] enc-cell: gru
[2023-06-25 12:18:02] [config] enc-cell-depth: 4
[2023-06-25 12:18:02] [config] enc-depth: 2
[2023-06-25 12:18:02] [config] enc-type: bidirectional
[2023-06-25 12:18:02] [config] english-title-case-every: 0
[2023-06-25 12:18:02] [config] exponential-smoothing: 0.0001
[2023-06-25 12:18:02] [config] factor-weight: 1
[2023-06-25 12:18:02] [config] factors-combine: sum
[2023-06-25 12:18:02] [config] factors-dim-emb: 0
[2023-06-25 12:18:02] [config] gradient-checkpointing: false
[2023-06-25 12:18:02] [config] gradient-norm-average-window: 100
[2023-06-25 12:18:02] [config] guided-alignment: none
[2023-06-25 12:18:02] [config] guided-alignment-cost: mse
[2023-06-25 12:18:02] [config] guided-alignment-weight: 0.1
[2023-06-25 12:18:02] [config] ignore-model-config: false
[2023-06-25 12:18:02] [config] input-types:
[2023-06-25 12:18:02] [config]   []
[2023-06-25 12:18:02] [config] interpolate-env-vars: false
[2023-06-25 12:18:02] [config] keep-best: false
[2023-06-25 12:18:02] [config] label-smoothing: 0.1
[2023-06-25 12:18:02] [config] layer-normalization: true
[2023-06-25 12:18:02] [config] learn-rate: 0.0003
[2023-06-25 12:18:02] [config] lemma-dependency: ""
[2023-06-25 12:18:02] [config] lemma-dim-emb: 0
[2023-06-25 12:18:02] [config] log: /docker/home/marianmt/logs/marian/split_model_gn_es_edinburgh2017_depth2.log
[2023-06-25 12:18:02] [config] log-level: info
[2023-06-25 12:18:02] [config] log-time-zone: ""
[2023-06-25 12:18:02] [config] logical-epoch:
[2023-06-25 12:18:02] [config]   - 1e
[2023-06-25 12:18:02] [config]   - 0
[2023-06-25 12:18:02] [config] lr-decay: 0
[2023-06-25 12:18:02] [config] lr-decay-freq: 50000
[2023-06-25 12:18:02] [config] lr-decay-inv-sqrt:
[2023-06-25 12:18:02] [config]   - 16000
[2023-06-25 12:18:02] [config] lr-decay-repeat-warmup: false
[2023-06-25 12:18:02] [config] lr-decay-reset-optimizer: false
[2023-06-25 12:18:02] [config] lr-decay-start:
[2023-06-25 12:18:02] [config]   - 10
[2023-06-25 12:18:02] [config]   - 1
[2023-06-25 12:18:02] [config] lr-decay-strategy: epoch+stalled
[2023-06-25 12:18:02] [config] lr-report: false
[2023-06-25 12:18:02] [config] lr-warmup: 0
[2023-06-25 12:18:02] [config] lr-warmup-at-reload: false
[2023-06-25 12:18:02] [config] lr-warmup-cycle: false
[2023-06-25 12:18:02] [config] lr-warmup-start-rate: 0
[2023-06-25 12:18:02] [config] max-length: 100
[2023-06-25 12:18:02] [config] max-length-crop: false
[2023-06-25 12:18:02] [config] max-length-factor: 3
[2023-06-25 12:18:02] [config] maxi-batch: 1000
[2023-06-25 12:18:02] [config] maxi-batch-sort: trg
[2023-06-25 12:18:02] [config] mini-batch: 1000
[2023-06-25 12:18:02] [config] mini-batch-fit: true
[2023-06-25 12:18:02] [config] mini-batch-fit-step: 10
[2023-06-25 12:18:02] [config] mini-batch-round-up: true
[2023-06-25 12:18:02] [config] mini-batch-track-lr: false
[2023-06-25 12:18:02] [config] mini-batch-warmup: 0
[2023-06-25 12:18:02] [config] mini-batch-words: 0
[2023-06-25 12:18:02] [config] mini-batch-words-ref: 0
[2023-06-25 12:18:02] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz
[2023-06-25 12:18:02] [config] multi-loss-type: sum
[2023-06-25 12:18:02] [config] n-best: false
[2023-06-25 12:18:02] [config] no-nccl: false
[2023-06-25 12:18:02] [config] no-reload: false
[2023-06-25 12:18:02] [config] no-restore-corpus: false
[2023-06-25 12:18:02] [config] normalize: 1
[2023-06-25 12:18:02] [config] normalize-gradient: false
[2023-06-25 12:18:02] [config] num-devices: 0
[2023-06-25 12:18:02] [config] optimizer: adam
[2023-06-25 12:18:02] [config] optimizer-delay: 1
[2023-06-25 12:18:02] [config] optimizer-params:
[2023-06-25 12:18:02] [config]   - 0.9
[2023-06-25 12:18:02] [config]   - 0.98
[2023-06-25 12:18:02] [config]   - 1e-09
[2023-06-25 12:18:02] [config] output-omit-bias: false
[2023-06-25 12:18:02] [config] overwrite: false
[2023-06-25 12:18:02] [config] precision:
[2023-06-25 12:18:02] [config]   - float32
[2023-06-25 12:18:02] [config]   - float32
[2023-06-25 12:18:02] [config] pretrained-model: ""
[2023-06-25 12:18:02] [config] quantize-biases: false
[2023-06-25 12:18:02] [config] quantize-bits: 0
[2023-06-25 12:18:02] [config] quantize-log-based: false
[2023-06-25 12:18:02] [config] quantize-optimization-steps: 0
[2023-06-25 12:18:02] [config] quiet: false
[2023-06-25 12:18:02] [config] quiet-translation: true
[2023-06-25 12:18:02] [config] relative-paths: false
[2023-06-25 12:18:02] [config] right-left: false
[2023-06-25 12:18:02] [config] save-freq: 10000u
[2023-06-25 12:18:02] [config] seed: 1234
[2023-06-25 12:18:02] [config] sentencepiece-alphas:
[2023-06-25 12:18:02] [config]   []
[2023-06-25 12:18:02] [config] sentencepiece-max-lines: 2000000
[2023-06-25 12:18:02] [config] sentencepiece-options: ""
[2023-06-25 12:18:02] [config] sharding: global
[2023-06-25 12:18:02] [config] shuffle: data
[2023-06-25 12:18:02] [config] shuffle-in-ram: false
[2023-06-25 12:18:02] [config] sigterm: save-and-exit
[2023-06-25 12:18:02] [config] skip: false
[2023-06-25 12:18:02] [config] sqlite: ""
[2023-06-25 12:18:02] [config] sqlite-drop: false
[2023-06-25 12:18:02] [config] sync-freq: 200u
[2023-06-25 12:18:02] [config] sync-sgd: true
[2023-06-25 12:18:02] [config] tempdir: /tmp
[2023-06-25 12:18:02] [config] tied-embeddings: false
[2023-06-25 12:18:02] [config] tied-embeddings-all: false
[2023-06-25 12:18:02] [config] tied-embeddings-src: false
[2023-06-25 12:18:02] [config] train-embedder-rank:
[2023-06-25 12:18:02] [config]   []
[2023-06-25 12:18:02] [config] train-sets:
[2023-06-25 12:18:02] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-06-25 12:18:02] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-06-25 12:18:02] [config] transformer-aan-activation: swish
[2023-06-25 12:18:02] [config] transformer-aan-depth: 2
[2023-06-25 12:18:02] [config] transformer-aan-nogate: false
[2023-06-25 12:18:02] [config] transformer-decoder-autoreg: self-attention
[2023-06-25 12:18:02] [config] transformer-decoder-dim-ffn: 0
[2023-06-25 12:18:02] [config] transformer-decoder-ffn-depth: 0
[2023-06-25 12:18:02] [config] transformer-depth-scaling: false
[2023-06-25 12:18:02] [config] transformer-dim-aan: 2048
[2023-06-25 12:18:02] [config] transformer-dim-ffn: 2048
[2023-06-25 12:18:02] [config] transformer-dropout: 0
[2023-06-25 12:18:02] [config] transformer-dropout-attention: 0
[2023-06-25 12:18:02] [config] transformer-dropout-ffn: 0
[2023-06-25 12:18:02] [config] transformer-ffn-activation: swish
[2023-06-25 12:18:02] [config] transformer-ffn-depth: 2
[2023-06-25 12:18:02] [config] transformer-guided-alignment-layer: last
[2023-06-25 12:18:02] [config] transformer-heads: 8
[2023-06-25 12:18:02] [config] transformer-no-projection: false
[2023-06-25 12:18:02] [config] transformer-pool: false
[2023-06-25 12:18:02] [config] transformer-postprocess: dan
[2023-06-25 12:18:02] [config] transformer-postprocess-emb: d
[2023-06-25 12:18:02] [config] transformer-postprocess-top: ""
[2023-06-25 12:18:02] [config] transformer-preprocess: ""
[2023-06-25 12:18:02] [config] transformer-tied-layers:
[2023-06-25 12:18:02] [config]   []
[2023-06-25 12:18:02] [config] transformer-train-position-embeddings: false
[2023-06-25 12:18:02] [config] tsv: false
[2023-06-25 12:18:02] [config] tsv-fields: 0
[2023-06-25 12:18:02] [config] type: s2s
[2023-06-25 12:18:02] [config] ulr: false
[2023-06-25 12:18:02] [config] ulr-dim-emb: 0
[2023-06-25 12:18:02] [config] ulr-dropout: 0
[2023-06-25 12:18:02] [config] ulr-keys-vectors: ""
[2023-06-25 12:18:02] [config] ulr-query-vectors: ""
[2023-06-25 12:18:02] [config] ulr-softmax-temperature: 1
[2023-06-25 12:18:02] [config] ulr-trainable-transformation: false
[2023-06-25 12:18:02] [config] unlikelihood-loss: false
[2023-06-25 12:18:02] [config] valid-freq: 5000000
[2023-06-25 12:18:02] [config] valid-log: /docker/home/marianmt/logs/marian/split_tok_150_gn_es_edinburgh2017_depth2.log
[2023-06-25 12:18:02] [config] valid-max-length: 1000
[2023-06-25 12:18:02] [config] valid-metrics:
[2023-06-25 12:18:02] [config]   - cross-entropy
[2023-06-25 12:18:02] [config]   - translation
[2023-06-25 12:18:02] [config] valid-mini-batch: 32
[2023-06-25 12:18:02] [config] valid-reset-stalled: false
[2023-06-25 12:18:02] [config] valid-script-args:
[2023-06-25 12:18:02] [config]   []
[2023-06-25 12:18:02] [config] valid-script-path: ""
[2023-06-25 12:18:02] [config] valid-sets:
[2023-06-25 12:18:02] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-06-25 12:18:02] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-06-25 12:18:02] [config] valid-translation-output: /docker/home/marianmt/evaluation/model-epochs.txt
[2023-06-25 12:18:02] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-06-25 12:18:02] [config] vocabs:
[2023-06-25 12:18:02] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens.txt.gn
[2023-06-25 12:18:02] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens.txt.es
[2023-06-25 12:18:02] [config] word-penalty: 0
[2023-06-25 12:18:02] [config] word-scores: false
[2023-06-25 12:18:02] [config] workspace: 2048
[2023-06-25 12:18:02] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-06-25 12:18:02] Using synchronous SGD
[2023-06-25 12:18:02] Synced seed 1234
[2023-06-25 12:18:02] [data] Loading vocabulary from text file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens.txt.gn
[2023-06-25 12:18:02] [data] Setting vocabulary size for input 0 to 54,042
[2023-06-25 12:18:02] [data] Loading vocabulary from text file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens.txt.es
[2023-06-25 12:18:02] [data] Setting vocabulary size for input 1 to 36,507
[2023-06-25 12:18:02] [batching] Collecting statistics for batch fitting with step size 10
[2023-06-25 12:18:02] [MPI rank 0 out of 1]: GPU[0]
[2023-06-25 12:18:03] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-06-25 12:18:03] [comm] Using NCCL 2.8.3 for GPU communication
[2023-06-25 12:18:03] [comm] Using global sharding
[2023-06-25 12:18:03] [comm] NCCLCommunicators constructed successfully
[2023-06-25 12:18:03] [training] Using 1 GPUs
[2023-06-25 12:18:03] [logits] Applying loss function for 1 factor(s)
[2023-06-25 12:18:03] [memory] Reserving 666 MB, device gpu0
[2023-06-25 12:18:03] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-06-25 12:18:04] [memory] Reserving 666 MB, device gpu0
[2023-06-25 12:18:28] [batching] Done. Typical MB size is 1,196 target words
[2023-06-25 12:18:28] [valid] No post-processing script given for validating translator
[2023-06-25 12:18:28] [MPI rank 0 out of 1]: GPU[0]
[2023-06-25 12:18:28] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-06-25 12:18:29] [comm] Using NCCL 2.8.3 for GPU communication
[2023-06-25 12:18:29] [comm] Using global sharding
[2023-06-25 12:18:29] [comm] NCCLCommunicators constructed successfully
[2023-06-25 12:18:29] [training] Using 1 GPUs
[2023-06-25 12:18:29] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz
[2023-06-25 12:18:34] Allocating memory for general optimizer shards
[2023-06-25 12:18:34] [memory] Reserving 666 MB, device gpu0
[2023-06-25 12:18:34] Loading Adam parameters
[2023-06-25 12:18:35] [memory] Reserving 1332 MB, device gpu0
[2023-06-25 12:18:35] [memory] Reserving 666 MB, device gpu0
[2023-06-25 12:18:36] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz.optimizer.npz
[2023-06-25 12:18:36] [data] Restoring the corpus state to epoch 51, batch 24450
[2023-06-25 12:18:36] [data] Shuffling data
[2023-06-25 12:18:36] [data] Done reading 20,192 sentences
[2023-06-25 12:18:36] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 12:18:36] Training started
[2023-06-25 12:18:36] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-06-25 12:18:36] [memory] Reserving 666 MB, device gpu0
[2023-06-25 12:18:36] Parameter type float32, optimization type float32, casting types false
[2023-06-25 12:22:07] Seen 20,177 samples
[2023-06-25 12:22:07] Starting data epoch 52 in logical epoch 52
[2023-06-25 12:22:07] [data] Shuffling data
[2023-06-25 12:22:07] [data] Done reading 20,192 sentences
[2023-06-25 12:22:07] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 12:22:32] Ep. 52 : Up. 25000 : Sen. 2,466 : Cost 1.68141675 : Time 243.72s : 4009.47 words/s : gNorm 0.2834
[2023-06-25 12:25:40] Seen 20,177 samples
[2023-06-25 12:25:40] Starting data epoch 53 in logical epoch 53
[2023-06-25 12:25:40] [data] Shuffling data
[2023-06-25 12:25:40] [data] Done reading 20,192 sentences
[2023-06-25 12:25:40] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 12:29:12] Seen 20,177 samples
[2023-06-25 12:29:12] Starting data epoch 54 in logical epoch 54
[2023-06-25 12:29:12] [data] Shuffling data
[2023-06-25 12:29:12] [data] Done reading 20,192 sentences
[2023-06-25 12:29:12] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 12:29:48] Ep. 54 : Up. 26000 : Sen. 3,729 : Cost 1.67824042 : Time 436.21s : 2237.41 words/s : gNorm 0.2793
[2023-06-25 12:32:45] Seen 20,177 samples
[2023-06-25 12:32:45] Starting data epoch 55 in logical epoch 55
[2023-06-25 12:32:45] [data] Shuffling data
[2023-06-25 12:32:45] [data] Done reading 20,192 sentences
[2023-06-25 12:32:45] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 12:36:18] Seen 20,177 samples
[2023-06-25 12:36:18] Starting data epoch 56 in logical epoch 56
[2023-06-25 12:36:18] [data] Shuffling data
[2023-06-25 12:36:18] [data] Done reading 20,192 sentences
[2023-06-25 12:36:18] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 12:37:04] Ep. 56 : Up. 27000 : Sen. 4,249 : Cost 1.67283833 : Time 435.95s : 2246.19 words/s : gNorm 0.2690
[2023-06-25 12:39:50] Seen 20,177 samples
[2023-06-25 12:39:50] Starting data epoch 57 in logical epoch 57
[2023-06-25 12:39:50] [data] Shuffling data
[2023-06-25 12:39:50] [data] Done reading 20,192 sentences
[2023-06-25 12:39:50] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 12:43:22] Seen 20,177 samples
[2023-06-25 12:43:22] Starting data epoch 58 in logical epoch 58
[2023-06-25 12:43:22] [data] Shuffling data
[2023-06-25 12:43:22] [data] Done reading 20,192 sentences
[2023-06-25 12:43:23] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 12:44:19] Ep. 58 : Up. 28000 : Sen. 5,179 : Cost 1.67073548 : Time 434.77s : 2257.08 words/s : gNorm 0.2586
[2023-06-25 12:46:55] Seen 20,177 samples
[2023-06-25 12:46:55] Starting data epoch 59 in logical epoch 59
[2023-06-25 12:46:55] [data] Shuffling data
[2023-06-25 12:46:55] [data] Done reading 20,192 sentences
[2023-06-25 12:46:55] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 12:50:27] Seen 20,177 samples
[2023-06-25 12:50:27] Starting data epoch 60 in logical epoch 60
[2023-06-25 12:50:27] [data] Shuffling data
[2023-06-25 12:50:27] [data] Done reading 20,192 sentences
[2023-06-25 12:50:27] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 12:51:34] Ep. 60 : Up. 29000 : Sen. 6,024 : Cost 1.66620708 : Time 435.02s : 2233.03 words/s : gNorm 0.2601
[2023-06-25 12:54:00] Seen 20,177 samples
[2023-06-25 12:54:00] Starting data epoch 61 in logical epoch 61
[2023-06-25 12:54:00] Training finished
[2023-06-25 12:54:15] [valid] Ep. 61 : Up. 29340 : cross-entropy : 100.484 : stalled 5 times (last best: 86.5722)
[2023-06-25 12:57:27] [valid] Ep. 61 : Up. 29340 : translation : 0 : new best
[2023-06-25 12:57:27] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz
[2023-06-25 12:57:34] Saving Adam parameters
[2023-06-25 12:57:37] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz.optimizer.npz
[2023-06-25 13:06:26] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-06-25 13:06:26] [marian] Running on node07.datos.cluster.uy as process 10744 with command line:
[2023-06-25 13:06:26] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz --after-epochs 70 --valid-freq 5000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens.txt.gn /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens.txt.es --seed 1234 --type s2s --max-length 100 --mini-batch-fit --mini-batch 1000 --maxi-batch 1000 --beam-size 12 --normalize 1 --cost-type ce-mean-words --enc-type bidirectional --enc-depth 2 --enc-cell-depth 4 --dec-depth 2 --dec-cell-base-depth 8 --dec-cell-high-depth 1 --layer-normalization --dropout-rnn 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-decay-inv-sqrt 16000 --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --sync-sgd --exponential-smoothing --cpu-threads 0 --log /docker/home/marianmt/logs/marian/split_model_gn_es_edinburgh2017_depth2.log --valid-log /docker/home/marianmt/logs/marian/split_tok_150_gn_es_edinburgh2017_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/model-epochs.txt --quiet-translation
[2023-06-25 13:06:26] [config] after: 0e
[2023-06-25 13:06:26] [config] after-batches: 0
[2023-06-25 13:06:26] [config] after-epochs: 70
[2023-06-25 13:06:26] [config] all-caps-every: 0
[2023-06-25 13:06:26] [config] allow-unk: false
[2023-06-25 13:06:26] [config] authors: false
[2023-06-25 13:06:26] [config] beam-size: 12
[2023-06-25 13:06:26] [config] bert-class-symbol: "[CLS]"
[2023-06-25 13:06:26] [config] bert-mask-symbol: "[MASK]"
[2023-06-25 13:06:26] [config] bert-masking-fraction: 0.15
[2023-06-25 13:06:26] [config] bert-sep-symbol: "[SEP]"
[2023-06-25 13:06:26] [config] bert-train-type-embeddings: true
[2023-06-25 13:06:26] [config] bert-type-vocab-size: 2
[2023-06-25 13:06:26] [config] build-info: ""
[2023-06-25 13:06:26] [config] check-gradient-nan: false
[2023-06-25 13:06:26] [config] check-nan: false
[2023-06-25 13:06:26] [config] cite: false
[2023-06-25 13:06:26] [config] clip-norm: 5
[2023-06-25 13:06:26] [config] cost-scaling:
[2023-06-25 13:06:26] [config]   []
[2023-06-25 13:06:26] [config] cost-type: ce-mean-words
[2023-06-25 13:06:26] [config] cpu-threads: 0
[2023-06-25 13:06:26] [config] data-threads: 8
[2023-06-25 13:06:26] [config] data-weighting: ""
[2023-06-25 13:06:26] [config] data-weighting-type: sentence
[2023-06-25 13:06:26] [config] dec-cell: gru
[2023-06-25 13:06:26] [config] dec-cell-base-depth: 8
[2023-06-25 13:06:26] [config] dec-cell-high-depth: 1
[2023-06-25 13:06:26] [config] dec-depth: 2
[2023-06-25 13:06:26] [config] devices:
[2023-06-25 13:06:26] [config]   - 0
[2023-06-25 13:06:26] [config] dim-emb: 512
[2023-06-25 13:06:26] [config] dim-rnn: 1024
[2023-06-25 13:06:26] [config] dim-vocabs:
[2023-06-25 13:06:26] [config]   - 54042
[2023-06-25 13:06:26] [config]   - 36507
[2023-06-25 13:06:26] [config] disp-first: 0
[2023-06-25 13:06:26] [config] disp-freq: 1000u
[2023-06-25 13:06:26] [config] disp-label-counts: true
[2023-06-25 13:06:26] [config] dropout-rnn: 0.1
[2023-06-25 13:06:26] [config] dropout-src: 0
[2023-06-25 13:06:26] [config] dropout-trg: 0
[2023-06-25 13:06:26] [config] dump-config: ""
[2023-06-25 13:06:26] [config] dynamic-gradient-scaling:
[2023-06-25 13:06:26] [config]   []
[2023-06-25 13:06:26] [config] early-stopping: 10
[2023-06-25 13:06:26] [config] early-stopping-on: first
[2023-06-25 13:06:26] [config] embedding-fix-src: false
[2023-06-25 13:06:26] [config] embedding-fix-trg: false
[2023-06-25 13:06:26] [config] embedding-normalization: false
[2023-06-25 13:06:26] [config] embedding-vectors:
[2023-06-25 13:06:26] [config]   []
[2023-06-25 13:06:26] [config] enc-cell: gru
[2023-06-25 13:06:26] [config] enc-cell-depth: 4
[2023-06-25 13:06:26] [config] enc-depth: 2
[2023-06-25 13:06:26] [config] enc-type: bidirectional
[2023-06-25 13:06:26] [config] english-title-case-every: 0
[2023-06-25 13:06:26] [config] exponential-smoothing: 0.0001
[2023-06-25 13:06:26] [config] factor-weight: 1
[2023-06-25 13:06:26] [config] factors-combine: sum
[2023-06-25 13:06:26] [config] factors-dim-emb: 0
[2023-06-25 13:06:26] [config] gradient-checkpointing: false
[2023-06-25 13:06:26] [config] gradient-norm-average-window: 100
[2023-06-25 13:06:26] [config] guided-alignment: none
[2023-06-25 13:06:26] [config] guided-alignment-cost: mse
[2023-06-25 13:06:26] [config] guided-alignment-weight: 0.1
[2023-06-25 13:06:26] [config] ignore-model-config: false
[2023-06-25 13:06:26] [config] input-types:
[2023-06-25 13:06:26] [config]   []
[2023-06-25 13:06:26] [config] interpolate-env-vars: false
[2023-06-25 13:06:26] [config] keep-best: false
[2023-06-25 13:06:26] [config] label-smoothing: 0.1
[2023-06-25 13:06:26] [config] layer-normalization: true
[2023-06-25 13:06:26] [config] learn-rate: 0.0003
[2023-06-25 13:06:26] [config] lemma-dependency: ""
[2023-06-25 13:06:26] [config] lemma-dim-emb: 0
[2023-06-25 13:06:26] [config] log: /docker/home/marianmt/logs/marian/split_model_gn_es_edinburgh2017_depth2.log
[2023-06-25 13:06:26] [config] log-level: info
[2023-06-25 13:06:26] [config] log-time-zone: ""
[2023-06-25 13:06:26] [config] logical-epoch:
[2023-06-25 13:06:26] [config]   - 1e
[2023-06-25 13:06:26] [config]   - 0
[2023-06-25 13:06:26] [config] lr-decay: 0
[2023-06-25 13:06:26] [config] lr-decay-freq: 50000
[2023-06-25 13:06:26] [config] lr-decay-inv-sqrt:
[2023-06-25 13:06:26] [config]   - 16000
[2023-06-25 13:06:26] [config] lr-decay-repeat-warmup: false
[2023-06-25 13:06:26] [config] lr-decay-reset-optimizer: false
[2023-06-25 13:06:26] [config] lr-decay-start:
[2023-06-25 13:06:26] [config]   - 10
[2023-06-25 13:06:26] [config]   - 1
[2023-06-25 13:06:26] [config] lr-decay-strategy: epoch+stalled
[2023-06-25 13:06:26] [config] lr-report: false
[2023-06-25 13:06:26] [config] lr-warmup: 0
[2023-06-25 13:06:26] [config] lr-warmup-at-reload: false
[2023-06-25 13:06:26] [config] lr-warmup-cycle: false
[2023-06-25 13:06:26] [config] lr-warmup-start-rate: 0
[2023-06-25 13:06:26] [config] max-length: 100
[2023-06-25 13:06:26] [config] max-length-crop: false
[2023-06-25 13:06:26] [config] max-length-factor: 3
[2023-06-25 13:06:26] [config] maxi-batch: 1000
[2023-06-25 13:06:26] [config] maxi-batch-sort: trg
[2023-06-25 13:06:26] [config] mini-batch: 1000
[2023-06-25 13:06:26] [config] mini-batch-fit: true
[2023-06-25 13:06:26] [config] mini-batch-fit-step: 10
[2023-06-25 13:06:26] [config] mini-batch-round-up: true
[2023-06-25 13:06:26] [config] mini-batch-track-lr: false
[2023-06-25 13:06:26] [config] mini-batch-warmup: 0
[2023-06-25 13:06:26] [config] mini-batch-words: 0
[2023-06-25 13:06:26] [config] mini-batch-words-ref: 0
[2023-06-25 13:06:26] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz
[2023-06-25 13:06:26] [config] multi-loss-type: sum
[2023-06-25 13:06:26] [config] n-best: false
[2023-06-25 13:06:26] [config] no-nccl: false
[2023-06-25 13:06:26] [config] no-reload: false
[2023-06-25 13:06:26] [config] no-restore-corpus: false
[2023-06-25 13:06:26] [config] normalize: 1
[2023-06-25 13:06:26] [config] normalize-gradient: false
[2023-06-25 13:06:26] [config] num-devices: 0
[2023-06-25 13:06:26] [config] optimizer: adam
[2023-06-25 13:06:26] [config] optimizer-delay: 1
[2023-06-25 13:06:26] [config] optimizer-params:
[2023-06-25 13:06:26] [config]   - 0.9
[2023-06-25 13:06:26] [config]   - 0.98
[2023-06-25 13:06:26] [config]   - 1e-09
[2023-06-25 13:06:26] [config] output-omit-bias: false
[2023-06-25 13:06:26] [config] overwrite: false
[2023-06-25 13:06:26] [config] precision:
[2023-06-25 13:06:26] [config]   - float32
[2023-06-25 13:06:26] [config]   - float32
[2023-06-25 13:06:26] [config] pretrained-model: ""
[2023-06-25 13:06:26] [config] quantize-biases: false
[2023-06-25 13:06:26] [config] quantize-bits: 0
[2023-06-25 13:06:26] [config] quantize-log-based: false
[2023-06-25 13:06:26] [config] quantize-optimization-steps: 0
[2023-06-25 13:06:26] [config] quiet: false
[2023-06-25 13:06:26] [config] quiet-translation: true
[2023-06-25 13:06:26] [config] relative-paths: false
[2023-06-25 13:06:26] [config] right-left: false
[2023-06-25 13:06:26] [config] save-freq: 10000u
[2023-06-25 13:06:26] [config] seed: 1234
[2023-06-25 13:06:26] [config] sentencepiece-alphas:
[2023-06-25 13:06:26] [config]   []
[2023-06-25 13:06:26] [config] sentencepiece-max-lines: 2000000
[2023-06-25 13:06:26] [config] sentencepiece-options: ""
[2023-06-25 13:06:26] [config] sharding: global
[2023-06-25 13:06:26] [config] shuffle: data
[2023-06-25 13:06:26] [config] shuffle-in-ram: false
[2023-06-25 13:06:26] [config] sigterm: save-and-exit
[2023-06-25 13:06:26] [config] skip: false
[2023-06-25 13:06:26] [config] sqlite: ""
[2023-06-25 13:06:26] [config] sqlite-drop: false
[2023-06-25 13:06:26] [config] sync-freq: 200u
[2023-06-25 13:06:26] [config] sync-sgd: true
[2023-06-25 13:06:26] [config] tempdir: /tmp
[2023-06-25 13:06:26] [config] tied-embeddings: false
[2023-06-25 13:06:26] [config] tied-embeddings-all: false
[2023-06-25 13:06:26] [config] tied-embeddings-src: false
[2023-06-25 13:06:26] [config] train-embedder-rank:
[2023-06-25 13:06:26] [config]   []
[2023-06-25 13:06:26] [config] train-sets:
[2023-06-25 13:06:26] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-06-25 13:06:26] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-06-25 13:06:26] [config] transformer-aan-activation: swish
[2023-06-25 13:06:26] [config] transformer-aan-depth: 2
[2023-06-25 13:06:26] [config] transformer-aan-nogate: false
[2023-06-25 13:06:26] [config] transformer-decoder-autoreg: self-attention
[2023-06-25 13:06:26] [config] transformer-decoder-dim-ffn: 0
[2023-06-25 13:06:26] [config] transformer-decoder-ffn-depth: 0
[2023-06-25 13:06:26] [config] transformer-depth-scaling: false
[2023-06-25 13:06:26] [config] transformer-dim-aan: 2048
[2023-06-25 13:06:26] [config] transformer-dim-ffn: 2048
[2023-06-25 13:06:26] [config] transformer-dropout: 0
[2023-06-25 13:06:26] [config] transformer-dropout-attention: 0
[2023-06-25 13:06:26] [config] transformer-dropout-ffn: 0
[2023-06-25 13:06:26] [config] transformer-ffn-activation: swish
[2023-06-25 13:06:26] [config] transformer-ffn-depth: 2
[2023-06-25 13:06:26] [config] transformer-guided-alignment-layer: last
[2023-06-25 13:06:26] [config] transformer-heads: 8
[2023-06-25 13:06:26] [config] transformer-no-projection: false
[2023-06-25 13:06:26] [config] transformer-pool: false
[2023-06-25 13:06:26] [config] transformer-postprocess: dan
[2023-06-25 13:06:26] [config] transformer-postprocess-emb: d
[2023-06-25 13:06:26] [config] transformer-postprocess-top: ""
[2023-06-25 13:06:26] [config] transformer-preprocess: ""
[2023-06-25 13:06:26] [config] transformer-tied-layers:
[2023-06-25 13:06:26] [config]   []
[2023-06-25 13:06:26] [config] transformer-train-position-embeddings: false
[2023-06-25 13:06:26] [config] tsv: false
[2023-06-25 13:06:26] [config] tsv-fields: 0
[2023-06-25 13:06:26] [config] type: s2s
[2023-06-25 13:06:26] [config] ulr: false
[2023-06-25 13:06:26] [config] ulr-dim-emb: 0
[2023-06-25 13:06:26] [config] ulr-dropout: 0
[2023-06-25 13:06:26] [config] ulr-keys-vectors: ""
[2023-06-25 13:06:26] [config] ulr-query-vectors: ""
[2023-06-25 13:06:26] [config] ulr-softmax-temperature: 1
[2023-06-25 13:06:26] [config] ulr-trainable-transformation: false
[2023-06-25 13:06:26] [config] unlikelihood-loss: false
[2023-06-25 13:06:26] [config] valid-freq: 5000000
[2023-06-25 13:06:26] [config] valid-log: /docker/home/marianmt/logs/marian/split_tok_150_gn_es_edinburgh2017_depth2.log
[2023-06-25 13:06:26] [config] valid-max-length: 1000
[2023-06-25 13:06:26] [config] valid-metrics:
[2023-06-25 13:06:26] [config]   - cross-entropy
[2023-06-25 13:06:26] [config]   - translation
[2023-06-25 13:06:26] [config] valid-mini-batch: 32
[2023-06-25 13:06:26] [config] valid-reset-stalled: false
[2023-06-25 13:06:26] [config] valid-script-args:
[2023-06-25 13:06:26] [config]   []
[2023-06-25 13:06:26] [config] valid-script-path: ""
[2023-06-25 13:06:26] [config] valid-sets:
[2023-06-25 13:06:26] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-06-25 13:06:26] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-06-25 13:06:26] [config] valid-translation-output: /docker/home/marianmt/evaluation/model-epochs.txt
[2023-06-25 13:06:26] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-06-25 13:06:26] [config] vocabs:
[2023-06-25 13:06:26] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens.txt.gn
[2023-06-25 13:06:26] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens.txt.es
[2023-06-25 13:06:26] [config] word-penalty: 0
[2023-06-25 13:06:26] [config] word-scores: false
[2023-06-25 13:06:26] [config] workspace: 2048
[2023-06-25 13:06:26] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-06-25 13:06:26] Using synchronous SGD
[2023-06-25 13:06:26] Synced seed 1234
[2023-06-25 13:06:26] [data] Loading vocabulary from text file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens.txt.gn
[2023-06-25 13:06:26] [data] Setting vocabulary size for input 0 to 54,042
[2023-06-25 13:06:26] [data] Loading vocabulary from text file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens.txt.es
[2023-06-25 13:06:27] [data] Setting vocabulary size for input 1 to 36,507
[2023-06-25 13:06:27] [batching] Collecting statistics for batch fitting with step size 10
[2023-06-25 13:06:27] [MPI rank 0 out of 1]: GPU[0]
[2023-06-25 13:06:27] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-06-25 13:06:27] [comm] Using NCCL 2.8.3 for GPU communication
[2023-06-25 13:06:27] [comm] Using global sharding
[2023-06-25 13:06:27] [comm] NCCLCommunicators constructed successfully
[2023-06-25 13:06:27] [training] Using 1 GPUs
[2023-06-25 13:06:27] [logits] Applying loss function for 1 factor(s)
[2023-06-25 13:06:27] [memory] Reserving 666 MB, device gpu0
[2023-06-25 13:06:28] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-06-25 13:06:28] [memory] Reserving 666 MB, device gpu0
[2023-06-25 13:06:53] [batching] Done. Typical MB size is 1,196 target words
[2023-06-25 13:06:53] [valid] No post-processing script given for validating translator
[2023-06-25 13:06:53] [MPI rank 0 out of 1]: GPU[0]
[2023-06-25 13:06:53] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-06-25 13:06:53] [comm] Using NCCL 2.8.3 for GPU communication
[2023-06-25 13:06:53] [comm] Using global sharding
[2023-06-25 13:06:53] [comm] NCCLCommunicators constructed successfully
[2023-06-25 13:06:53] [training] Using 1 GPUs
[2023-06-25 13:06:53] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz
[2023-06-25 13:06:58] Allocating memory for general optimizer shards
[2023-06-25 13:06:58] [memory] Reserving 666 MB, device gpu0
[2023-06-25 13:06:59] Loading Adam parameters
[2023-06-25 13:06:59] [memory] Reserving 1332 MB, device gpu0
[2023-06-25 13:06:59] [memory] Reserving 666 MB, device gpu0
[2023-06-25 13:07:00] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz.optimizer.npz
[2023-06-25 13:07:00] [data] Restoring the corpus state to epoch 61, batch 29340
[2023-06-25 13:07:00] [data] Shuffling data
[2023-06-25 13:07:00] [data] Done reading 20,192 sentences
[2023-06-25 13:07:00] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 13:07:00] Training started
[2023-06-25 13:07:00] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-06-25 13:07:00] [memory] Reserving 666 MB, device gpu0
[2023-06-25 13:07:00] Parameter type float32, optimization type float32, casting types false
[2023-06-25 13:10:32] Seen 20,177 samples
[2023-06-25 13:10:32] Starting data epoch 62 in logical epoch 62
[2023-06-25 13:10:32] [data] Shuffling data
[2023-06-25 13:10:32] [data] Done reading 20,192 sentences
[2023-06-25 13:10:32] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 13:11:47] Ep. 62 : Up. 30000 : Sen. 7,403 : Cost 1.66310704 : Time 293.93s : 3328.84 words/s : gNorm 0.2501
[2023-06-25 13:11:47] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.iter30000.npz
[2023-06-25 13:11:53] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz
[2023-06-25 13:12:00] Saving Adam parameters
[2023-06-25 13:12:03] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz.optimizer.npz
[2023-06-25 13:14:40] Seen 20,177 samples
[2023-06-25 13:14:40] Starting data epoch 63 in logical epoch 63
[2023-06-25 13:14:40] [data] Shuffling data
[2023-06-25 13:14:41] [data] Done reading 20,192 sentences
[2023-06-25 13:14:41] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 13:18:15] Seen 20,177 samples
[2023-06-25 13:18:15] Starting data epoch 64 in logical epoch 64
[2023-06-25 13:18:15] [data] Shuffling data
[2023-06-25 13:18:15] [data] Done reading 20,192 sentences
[2023-06-25 13:18:15] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 13:19:40] Ep. 64 : Up. 31000 : Sen. 8,218 : Cost 1.66116500 : Time 473.52s : 2062.25 words/s : gNorm 0.2498
[2023-06-25 13:21:49] Seen 20,177 samples
[2023-06-25 13:21:49] Starting data epoch 65 in logical epoch 65
[2023-06-25 13:21:49] [data] Shuffling data
[2023-06-25 13:21:49] [data] Done reading 20,192 sentences
[2023-06-25 13:21:49] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 13:25:22] Seen 20,177 samples
[2023-06-25 13:25:22] Starting data epoch 66 in logical epoch 66
[2023-06-25 13:25:22] [data] Shuffling data
[2023-06-25 13:25:22] [data] Done reading 20,192 sentences
[2023-06-25 13:25:23] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 13:26:54] Ep. 66 : Up. 32000 : Sen. 9,225 : Cost 1.65792620 : Time 433.87s : 2252.12 words/s : gNorm 0.2441
[2023-06-25 13:28:57] Seen 20,177 samples
[2023-06-25 13:28:57] Starting data epoch 67 in logical epoch 67
[2023-06-25 13:28:57] [data] Shuffling data
[2023-06-25 13:28:57] [data] Done reading 20,192 sentences
[2023-06-25 13:28:57] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 13:32:31] Seen 20,177 samples
[2023-06-25 13:32:31] Starting data epoch 68 in logical epoch 68
[2023-06-25 13:32:31] [data] Shuffling data
[2023-06-25 13:32:31] [data] Done reading 20,192 sentences
[2023-06-25 13:32:31] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 13:34:12] Ep. 68 : Up. 33000 : Sen. 9,983 : Cost 1.66016388 : Time 438.23s : 2231.44 words/s : gNorm 0.2370
[2023-06-25 13:36:06] Seen 20,177 samples
[2023-06-25 13:36:06] Starting data epoch 69 in logical epoch 69
[2023-06-25 13:36:06] [data] Shuffling data
[2023-06-25 13:36:06] [data] Done reading 20,192 sentences
[2023-06-25 13:36:06] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 13:39:43] Seen 20,177 samples
[2023-06-25 13:39:43] Starting data epoch 70 in logical epoch 70
[2023-06-25 13:39:43] [data] Shuffling data
[2023-06-25 13:39:44] [data] Done reading 20,192 sentences
[2023-06-25 13:39:44] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 13:41:40] Ep. 70 : Up. 34000 : Sen. 11,031 : Cost 1.65561414 : Time 448.24s : 2184.37 words/s : gNorm 0.2514
[2023-06-25 13:43:22] Seen 20,177 samples
[2023-06-25 13:43:22] Starting data epoch 71 in logical epoch 71
[2023-06-25 13:43:22] Training finished
[2023-06-25 13:43:38] [valid] Ep. 71 : Up. 34230 : cross-entropy : 101.049 : stalled 6 times (last best: 86.5722)
[2023-06-25 13:47:21] [valid] Ep. 71 : Up. 34230 : translation : 0 : new best
[2023-06-25 13:47:21] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz
[2023-06-25 13:47:27] Saving Adam parameters
[2023-06-25 13:47:30] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz.optimizer.npz
[2023-06-25 13:56:25] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-06-25 13:56:25] [marian] Running on node07.datos.cluster.uy as process 14203 with command line:
[2023-06-25 13:56:25] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz --after-epochs 80 --valid-freq 5000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens.txt.gn /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens.txt.es --seed 1234 --type s2s --max-length 100 --mini-batch-fit --mini-batch 1000 --maxi-batch 1000 --beam-size 12 --normalize 1 --cost-type ce-mean-words --enc-type bidirectional --enc-depth 2 --enc-cell-depth 4 --dec-depth 2 --dec-cell-base-depth 8 --dec-cell-high-depth 1 --layer-normalization --dropout-rnn 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-decay-inv-sqrt 16000 --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --sync-sgd --exponential-smoothing --cpu-threads 0 --log /docker/home/marianmt/logs/marian/split_model_gn_es_edinburgh2017_depth2.log --valid-log /docker/home/marianmt/logs/marian/split_tok_150_gn_es_edinburgh2017_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/model-epochs.txt --quiet-translation
[2023-06-25 13:56:25] [config] after: 0e
[2023-06-25 13:56:25] [config] after-batches: 0
[2023-06-25 13:56:25] [config] after-epochs: 80
[2023-06-25 13:56:25] [config] all-caps-every: 0
[2023-06-25 13:56:25] [config] allow-unk: false
[2023-06-25 13:56:25] [config] authors: false
[2023-06-25 13:56:25] [config] beam-size: 12
[2023-06-25 13:56:25] [config] bert-class-symbol: "[CLS]"
[2023-06-25 13:56:25] [config] bert-mask-symbol: "[MASK]"
[2023-06-25 13:56:25] [config] bert-masking-fraction: 0.15
[2023-06-25 13:56:25] [config] bert-sep-symbol: "[SEP]"
[2023-06-25 13:56:25] [config] bert-train-type-embeddings: true
[2023-06-25 13:56:25] [config] bert-type-vocab-size: 2
[2023-06-25 13:56:25] [config] build-info: ""
[2023-06-25 13:56:25] [config] check-gradient-nan: false
[2023-06-25 13:56:25] [config] check-nan: false
[2023-06-25 13:56:25] [config] cite: false
[2023-06-25 13:56:25] [config] clip-norm: 5
[2023-06-25 13:56:25] [config] cost-scaling:
[2023-06-25 13:56:25] [config]   []
[2023-06-25 13:56:25] [config] cost-type: ce-mean-words
[2023-06-25 13:56:25] [config] cpu-threads: 0
[2023-06-25 13:56:25] [config] data-threads: 8
[2023-06-25 13:56:25] [config] data-weighting: ""
[2023-06-25 13:56:25] [config] data-weighting-type: sentence
[2023-06-25 13:56:25] [config] dec-cell: gru
[2023-06-25 13:56:25] [config] dec-cell-base-depth: 8
[2023-06-25 13:56:25] [config] dec-cell-high-depth: 1
[2023-06-25 13:56:25] [config] dec-depth: 2
[2023-06-25 13:56:25] [config] devices:
[2023-06-25 13:56:25] [config]   - 0
[2023-06-25 13:56:25] [config] dim-emb: 512
[2023-06-25 13:56:25] [config] dim-rnn: 1024
[2023-06-25 13:56:25] [config] dim-vocabs:
[2023-06-25 13:56:25] [config]   - 54042
[2023-06-25 13:56:25] [config]   - 36507
[2023-06-25 13:56:25] [config] disp-first: 0
[2023-06-25 13:56:25] [config] disp-freq: 1000u
[2023-06-25 13:56:25] [config] disp-label-counts: true
[2023-06-25 13:56:25] [config] dropout-rnn: 0.1
[2023-06-25 13:56:25] [config] dropout-src: 0
[2023-06-25 13:56:25] [config] dropout-trg: 0
[2023-06-25 13:56:25] [config] dump-config: ""
[2023-06-25 13:56:25] [config] dynamic-gradient-scaling:
[2023-06-25 13:56:25] [config]   []
[2023-06-25 13:56:25] [config] early-stopping: 10
[2023-06-25 13:56:25] [config] early-stopping-on: first
[2023-06-25 13:56:25] [config] embedding-fix-src: false
[2023-06-25 13:56:25] [config] embedding-fix-trg: false
[2023-06-25 13:56:25] [config] embedding-normalization: false
[2023-06-25 13:56:25] [config] embedding-vectors:
[2023-06-25 13:56:25] [config]   []
[2023-06-25 13:56:25] [config] enc-cell: gru
[2023-06-25 13:56:25] [config] enc-cell-depth: 4
[2023-06-25 13:56:25] [config] enc-depth: 2
[2023-06-25 13:56:25] [config] enc-type: bidirectional
[2023-06-25 13:56:25] [config] english-title-case-every: 0
[2023-06-25 13:56:25] [config] exponential-smoothing: 0.0001
[2023-06-25 13:56:25] [config] factor-weight: 1
[2023-06-25 13:56:25] [config] factors-combine: sum
[2023-06-25 13:56:25] [config] factors-dim-emb: 0
[2023-06-25 13:56:25] [config] gradient-checkpointing: false
[2023-06-25 13:56:25] [config] gradient-norm-average-window: 100
[2023-06-25 13:56:25] [config] guided-alignment: none
[2023-06-25 13:56:25] [config] guided-alignment-cost: mse
[2023-06-25 13:56:25] [config] guided-alignment-weight: 0.1
[2023-06-25 13:56:25] [config] ignore-model-config: false
[2023-06-25 13:56:25] [config] input-types:
[2023-06-25 13:56:25] [config]   []
[2023-06-25 13:56:25] [config] interpolate-env-vars: false
[2023-06-25 13:56:25] [config] keep-best: false
[2023-06-25 13:56:25] [config] label-smoothing: 0.1
[2023-06-25 13:56:25] [config] layer-normalization: true
[2023-06-25 13:56:25] [config] learn-rate: 0.0003
[2023-06-25 13:56:25] [config] lemma-dependency: ""
[2023-06-25 13:56:25] [config] lemma-dim-emb: 0
[2023-06-25 13:56:25] [config] log: /docker/home/marianmt/logs/marian/split_model_gn_es_edinburgh2017_depth2.log
[2023-06-25 13:56:25] [config] log-level: info
[2023-06-25 13:56:25] [config] log-time-zone: ""
[2023-06-25 13:56:25] [config] logical-epoch:
[2023-06-25 13:56:25] [config]   - 1e
[2023-06-25 13:56:25] [config]   - 0
[2023-06-25 13:56:25] [config] lr-decay: 0
[2023-06-25 13:56:25] [config] lr-decay-freq: 50000
[2023-06-25 13:56:25] [config] lr-decay-inv-sqrt:
[2023-06-25 13:56:25] [config]   - 16000
[2023-06-25 13:56:25] [config] lr-decay-repeat-warmup: false
[2023-06-25 13:56:25] [config] lr-decay-reset-optimizer: false
[2023-06-25 13:56:25] [config] lr-decay-start:
[2023-06-25 13:56:25] [config]   - 10
[2023-06-25 13:56:25] [config]   - 1
[2023-06-25 13:56:25] [config] lr-decay-strategy: epoch+stalled
[2023-06-25 13:56:25] [config] lr-report: false
[2023-06-25 13:56:25] [config] lr-warmup: 0
[2023-06-25 13:56:25] [config] lr-warmup-at-reload: false
[2023-06-25 13:56:25] [config] lr-warmup-cycle: false
[2023-06-25 13:56:25] [config] lr-warmup-start-rate: 0
[2023-06-25 13:56:25] [config] max-length: 100
[2023-06-25 13:56:25] [config] max-length-crop: false
[2023-06-25 13:56:25] [config] max-length-factor: 3
[2023-06-25 13:56:25] [config] maxi-batch: 1000
[2023-06-25 13:56:25] [config] maxi-batch-sort: trg
[2023-06-25 13:56:25] [config] mini-batch: 1000
[2023-06-25 13:56:25] [config] mini-batch-fit: true
[2023-06-25 13:56:25] [config] mini-batch-fit-step: 10
[2023-06-25 13:56:25] [config] mini-batch-round-up: true
[2023-06-25 13:56:25] [config] mini-batch-track-lr: false
[2023-06-25 13:56:25] [config] mini-batch-warmup: 0
[2023-06-25 13:56:25] [config] mini-batch-words: 0
[2023-06-25 13:56:25] [config] mini-batch-words-ref: 0
[2023-06-25 13:56:25] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz
[2023-06-25 13:56:25] [config] multi-loss-type: sum
[2023-06-25 13:56:25] [config] n-best: false
[2023-06-25 13:56:25] [config] no-nccl: false
[2023-06-25 13:56:25] [config] no-reload: false
[2023-06-25 13:56:25] [config] no-restore-corpus: false
[2023-06-25 13:56:25] [config] normalize: 1
[2023-06-25 13:56:25] [config] normalize-gradient: false
[2023-06-25 13:56:25] [config] num-devices: 0
[2023-06-25 13:56:25] [config] optimizer: adam
[2023-06-25 13:56:25] [config] optimizer-delay: 1
[2023-06-25 13:56:25] [config] optimizer-params:
[2023-06-25 13:56:25] [config]   - 0.9
[2023-06-25 13:56:25] [config]   - 0.98
[2023-06-25 13:56:25] [config]   - 1e-09
[2023-06-25 13:56:25] [config] output-omit-bias: false
[2023-06-25 13:56:25] [config] overwrite: false
[2023-06-25 13:56:25] [config] precision:
[2023-06-25 13:56:25] [config]   - float32
[2023-06-25 13:56:25] [config]   - float32
[2023-06-25 13:56:25] [config] pretrained-model: ""
[2023-06-25 13:56:25] [config] quantize-biases: false
[2023-06-25 13:56:25] [config] quantize-bits: 0
[2023-06-25 13:56:25] [config] quantize-log-based: false
[2023-06-25 13:56:25] [config] quantize-optimization-steps: 0
[2023-06-25 13:56:25] [config] quiet: false
[2023-06-25 13:56:25] [config] quiet-translation: true
[2023-06-25 13:56:25] [config] relative-paths: false
[2023-06-25 13:56:25] [config] right-left: false
[2023-06-25 13:56:25] [config] save-freq: 10000u
[2023-06-25 13:56:25] [config] seed: 1234
[2023-06-25 13:56:25] [config] sentencepiece-alphas:
[2023-06-25 13:56:25] [config]   []
[2023-06-25 13:56:25] [config] sentencepiece-max-lines: 2000000
[2023-06-25 13:56:25] [config] sentencepiece-options: ""
[2023-06-25 13:56:25] [config] sharding: global
[2023-06-25 13:56:25] [config] shuffle: data
[2023-06-25 13:56:25] [config] shuffle-in-ram: false
[2023-06-25 13:56:25] [config] sigterm: save-and-exit
[2023-06-25 13:56:25] [config] skip: false
[2023-06-25 13:56:25] [config] sqlite: ""
[2023-06-25 13:56:25] [config] sqlite-drop: false
[2023-06-25 13:56:25] [config] sync-freq: 200u
[2023-06-25 13:56:25] [config] sync-sgd: true
[2023-06-25 13:56:25] [config] tempdir: /tmp
[2023-06-25 13:56:25] [config] tied-embeddings: false
[2023-06-25 13:56:25] [config] tied-embeddings-all: false
[2023-06-25 13:56:25] [config] tied-embeddings-src: false
[2023-06-25 13:56:25] [config] train-embedder-rank:
[2023-06-25 13:56:25] [config]   []
[2023-06-25 13:56:25] [config] train-sets:
[2023-06-25 13:56:25] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-06-25 13:56:25] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-06-25 13:56:25] [config] transformer-aan-activation: swish
[2023-06-25 13:56:25] [config] transformer-aan-depth: 2
[2023-06-25 13:56:25] [config] transformer-aan-nogate: false
[2023-06-25 13:56:25] [config] transformer-decoder-autoreg: self-attention
[2023-06-25 13:56:25] [config] transformer-decoder-dim-ffn: 0
[2023-06-25 13:56:25] [config] transformer-decoder-ffn-depth: 0
[2023-06-25 13:56:25] [config] transformer-depth-scaling: false
[2023-06-25 13:56:25] [config] transformer-dim-aan: 2048
[2023-06-25 13:56:25] [config] transformer-dim-ffn: 2048
[2023-06-25 13:56:25] [config] transformer-dropout: 0
[2023-06-25 13:56:25] [config] transformer-dropout-attention: 0
[2023-06-25 13:56:25] [config] transformer-dropout-ffn: 0
[2023-06-25 13:56:25] [config] transformer-ffn-activation: swish
[2023-06-25 13:56:25] [config] transformer-ffn-depth: 2
[2023-06-25 13:56:25] [config] transformer-guided-alignment-layer: last
[2023-06-25 13:56:25] [config] transformer-heads: 8
[2023-06-25 13:56:25] [config] transformer-no-projection: false
[2023-06-25 13:56:25] [config] transformer-pool: false
[2023-06-25 13:56:25] [config] transformer-postprocess: dan
[2023-06-25 13:56:25] [config] transformer-postprocess-emb: d
[2023-06-25 13:56:25] [config] transformer-postprocess-top: ""
[2023-06-25 13:56:25] [config] transformer-preprocess: ""
[2023-06-25 13:56:25] [config] transformer-tied-layers:
[2023-06-25 13:56:25] [config]   []
[2023-06-25 13:56:25] [config] transformer-train-position-embeddings: false
[2023-06-25 13:56:25] [config] tsv: false
[2023-06-25 13:56:25] [config] tsv-fields: 0
[2023-06-25 13:56:25] [config] type: s2s
[2023-06-25 13:56:25] [config] ulr: false
[2023-06-25 13:56:25] [config] ulr-dim-emb: 0
[2023-06-25 13:56:25] [config] ulr-dropout: 0
[2023-06-25 13:56:25] [config] ulr-keys-vectors: ""
[2023-06-25 13:56:25] [config] ulr-query-vectors: ""
[2023-06-25 13:56:25] [config] ulr-softmax-temperature: 1
[2023-06-25 13:56:25] [config] ulr-trainable-transformation: false
[2023-06-25 13:56:25] [config] unlikelihood-loss: false
[2023-06-25 13:56:25] [config] valid-freq: 5000000
[2023-06-25 13:56:25] [config] valid-log: /docker/home/marianmt/logs/marian/split_tok_150_gn_es_edinburgh2017_depth2.log
[2023-06-25 13:56:25] [config] valid-max-length: 1000
[2023-06-25 13:56:25] [config] valid-metrics:
[2023-06-25 13:56:25] [config]   - cross-entropy
[2023-06-25 13:56:25] [config]   - translation
[2023-06-25 13:56:25] [config] valid-mini-batch: 32
[2023-06-25 13:56:25] [config] valid-reset-stalled: false
[2023-06-25 13:56:25] [config] valid-script-args:
[2023-06-25 13:56:25] [config]   []
[2023-06-25 13:56:25] [config] valid-script-path: ""
[2023-06-25 13:56:25] [config] valid-sets:
[2023-06-25 13:56:25] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-06-25 13:56:25] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-06-25 13:56:25] [config] valid-translation-output: /docker/home/marianmt/evaluation/model-epochs.txt
[2023-06-25 13:56:25] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-06-25 13:56:25] [config] vocabs:
[2023-06-25 13:56:25] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens.txt.gn
[2023-06-25 13:56:25] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens.txt.es
[2023-06-25 13:56:25] [config] word-penalty: 0
[2023-06-25 13:56:25] [config] word-scores: false
[2023-06-25 13:56:25] [config] workspace: 2048
[2023-06-25 13:56:25] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-06-25 13:56:25] Using synchronous SGD
[2023-06-25 13:56:26] Synced seed 1234
[2023-06-25 13:56:26] [data] Loading vocabulary from text file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens.txt.gn
[2023-06-25 13:56:26] [data] Setting vocabulary size for input 0 to 54,042
[2023-06-25 13:56:26] [data] Loading vocabulary from text file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens.txt.es
[2023-06-25 13:56:26] [data] Setting vocabulary size for input 1 to 36,507
[2023-06-25 13:56:26] [batching] Collecting statistics for batch fitting with step size 10
[2023-06-25 13:56:26] [MPI rank 0 out of 1]: GPU[0]
[2023-06-25 13:56:27] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-06-25 13:56:27] [comm] Using NCCL 2.8.3 for GPU communication
[2023-06-25 13:56:27] [comm] Using global sharding
[2023-06-25 13:56:27] [comm] NCCLCommunicators constructed successfully
[2023-06-25 13:56:27] [training] Using 1 GPUs
[2023-06-25 13:56:27] [logits] Applying loss function for 1 factor(s)
[2023-06-25 13:56:27] [memory] Reserving 666 MB, device gpu0
[2023-06-25 13:56:27] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-06-25 13:56:28] [memory] Reserving 666 MB, device gpu0
[2023-06-25 13:56:52] [batching] Done. Typical MB size is 1,196 target words
[2023-06-25 13:56:52] [valid] No post-processing script given for validating translator
[2023-06-25 13:56:52] [MPI rank 0 out of 1]: GPU[0]
[2023-06-25 13:56:52] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-06-25 13:56:52] [comm] Using NCCL 2.8.3 for GPU communication
[2023-06-25 13:56:52] [comm] Using global sharding
[2023-06-25 13:56:52] [comm] NCCLCommunicators constructed successfully
[2023-06-25 13:56:52] [training] Using 1 GPUs
[2023-06-25 13:56:52] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz
[2023-06-25 13:56:58] Allocating memory for general optimizer shards
[2023-06-25 13:56:58] [memory] Reserving 666 MB, device gpu0
[2023-06-25 13:56:58] Loading Adam parameters
[2023-06-25 13:56:59] [memory] Reserving 1332 MB, device gpu0
[2023-06-25 13:56:59] [memory] Reserving 666 MB, device gpu0
[2023-06-25 13:56:59] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz.optimizer.npz
[2023-06-25 13:56:59] [data] Restoring the corpus state to epoch 71, batch 34230
[2023-06-25 13:56:59] [data] Shuffling data
[2023-06-25 13:56:59] [data] Done reading 20,192 sentences
[2023-06-25 13:56:59] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 13:56:59] Training started
[2023-06-25 13:56:59] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-06-25 13:57:00] [memory] Reserving 666 MB, device gpu0
[2023-06-25 13:57:00] Parameter type float32, optimization type float32, casting types false
[2023-06-25 14:00:36] Seen 20,177 samples
[2023-06-25 14:00:36] Starting data epoch 72 in logical epoch 72
[2023-06-25 14:00:36] [data] Shuffling data
[2023-06-25 14:00:36] [data] Done reading 20,192 sentences
[2023-06-25 14:00:36] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 14:02:43] Ep. 72 : Up. 35000 : Sen. 11,515 : Cost 1.65272093 : Time 350.75s : 2793.70 words/s : gNorm 0.2265
[2023-06-25 14:04:15] Seen 20,177 samples
[2023-06-25 14:04:15] Starting data epoch 73 in logical epoch 73
[2023-06-25 14:04:15] [data] Shuffling data
[2023-06-25 14:04:15] [data] Done reading 20,192 sentences
[2023-06-25 14:04:15] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 14:07:55] Seen 20,177 samples
[2023-06-25 14:07:55] Starting data epoch 74 in logical epoch 74
[2023-06-25 14:07:55] [data] Shuffling data
[2023-06-25 14:07:55] [data] Done reading 20,192 sentences
[2023-06-25 14:07:55] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 14:10:10] Ep. 74 : Up. 36000 : Sen. 12,763 : Cost 1.65033054 : Time 446.69s : 2178.89 words/s : gNorm 0.2499
[2023-06-25 14:11:33] Seen 20,177 samples
[2023-06-25 14:11:33] Starting data epoch 75 in logical epoch 75
[2023-06-25 14:11:33] [data] Shuffling data
[2023-06-25 14:11:33] [data] Done reading 20,192 sentences
[2023-06-25 14:11:33] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 14:15:12] Seen 20,177 samples
[2023-06-25 14:15:12] Starting data epoch 76 in logical epoch 76
[2023-06-25 14:15:12] [data] Shuffling data
[2023-06-25 14:15:12] [data] Done reading 20,192 sentences
[2023-06-25 14:15:12] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 14:17:38] Ep. 76 : Up. 37000 : Sen. 13,420 : Cost 1.64694202 : Time 448.34s : 2181.41 words/s : gNorm 0.2239
[2023-06-25 14:18:50] Seen 20,177 samples
[2023-06-25 14:18:50] Starting data epoch 77 in logical epoch 77
[2023-06-25 14:18:50] [data] Shuffling data
[2023-06-25 14:18:50] [data] Done reading 20,192 sentences
[2023-06-25 14:18:50] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 14:22:29] Seen 20,177 samples
[2023-06-25 14:22:29] Starting data epoch 78 in logical epoch 78
[2023-06-25 14:22:29] [data] Shuffling data
[2023-06-25 14:22:29] [data] Done reading 20,192 sentences
[2023-06-25 14:22:29] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 14:25:07] Ep. 78 : Up. 38000 : Sen. 14,238 : Cost 1.64657533 : Time 449.03s : 2178.75 words/s : gNorm 0.2360
[2023-06-25 14:26:08] Seen 20,177 samples
[2023-06-25 14:26:08] Starting data epoch 79 in logical epoch 79
[2023-06-25 14:26:08] [data] Shuffling data
[2023-06-25 14:26:09] [data] Done reading 20,192 sentences
[2023-06-25 14:26:09] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 14:29:51] Seen 20,177 samples
[2023-06-25 14:29:51] Starting data epoch 80 in logical epoch 80
[2023-06-25 14:29:51] [data] Shuffling data
[2023-06-25 14:29:51] [data] Done reading 20,192 sentences
[2023-06-25 14:29:51] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 14:32:37] Ep. 80 : Up. 39000 : Sen. 15,486 : Cost 1.64295208 : Time 449.95s : 2170.25 words/s : gNorm 0.2221
[2023-06-25 14:33:33] Seen 20,177 samples
[2023-06-25 14:33:33] Starting data epoch 81 in logical epoch 81
[2023-06-25 14:33:33] Training finished
[2023-06-25 14:33:49] [valid] Ep. 81 : Up. 39120 : cross-entropy : 101.581 : stalled 7 times (last best: 86.5722)
[2023-06-25 14:37:45] [valid] Ep. 81 : Up. 39120 : translation : 0 : new best
[2023-06-25 14:37:45] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz
[2023-06-25 14:37:52] Saving Adam parameters
[2023-06-25 14:37:55] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz.optimizer.npz
[2023-06-25 14:46:57] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-06-25 14:46:57] [marian] Running on node07.datos.cluster.uy as process 17661 with command line:
[2023-06-25 14:46:57] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz --after-epochs 90 --valid-freq 5000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens.txt.gn /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens.txt.es --seed 1234 --type s2s --max-length 100 --mini-batch-fit --mini-batch 1000 --maxi-batch 1000 --beam-size 12 --normalize 1 --cost-type ce-mean-words --enc-type bidirectional --enc-depth 2 --enc-cell-depth 4 --dec-depth 2 --dec-cell-base-depth 8 --dec-cell-high-depth 1 --layer-normalization --dropout-rnn 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-decay-inv-sqrt 16000 --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --sync-sgd --exponential-smoothing --cpu-threads 0 --log /docker/home/marianmt/logs/marian/split_model_gn_es_edinburgh2017_depth2.log --valid-log /docker/home/marianmt/logs/marian/split_tok_150_gn_es_edinburgh2017_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/model-epochs.txt --quiet-translation
[2023-06-25 14:46:57] [config] after: 0e
[2023-06-25 14:46:57] [config] after-batches: 0
[2023-06-25 14:46:57] [config] after-epochs: 90
[2023-06-25 14:46:57] [config] all-caps-every: 0
[2023-06-25 14:46:57] [config] allow-unk: false
[2023-06-25 14:46:57] [config] authors: false
[2023-06-25 14:46:57] [config] beam-size: 12
[2023-06-25 14:46:57] [config] bert-class-symbol: "[CLS]"
[2023-06-25 14:46:57] [config] bert-mask-symbol: "[MASK]"
[2023-06-25 14:46:57] [config] bert-masking-fraction: 0.15
[2023-06-25 14:46:57] [config] bert-sep-symbol: "[SEP]"
[2023-06-25 14:46:57] [config] bert-train-type-embeddings: true
[2023-06-25 14:46:57] [config] bert-type-vocab-size: 2
[2023-06-25 14:46:57] [config] build-info: ""
[2023-06-25 14:46:57] [config] check-gradient-nan: false
[2023-06-25 14:46:57] [config] check-nan: false
[2023-06-25 14:46:57] [config] cite: false
[2023-06-25 14:46:57] [config] clip-norm: 5
[2023-06-25 14:46:57] [config] cost-scaling:
[2023-06-25 14:46:57] [config]   []
[2023-06-25 14:46:57] [config] cost-type: ce-mean-words
[2023-06-25 14:46:57] [config] cpu-threads: 0
[2023-06-25 14:46:57] [config] data-threads: 8
[2023-06-25 14:46:57] [config] data-weighting: ""
[2023-06-25 14:46:57] [config] data-weighting-type: sentence
[2023-06-25 14:46:57] [config] dec-cell: gru
[2023-06-25 14:46:57] [config] dec-cell-base-depth: 8
[2023-06-25 14:46:57] [config] dec-cell-high-depth: 1
[2023-06-25 14:46:57] [config] dec-depth: 2
[2023-06-25 14:46:57] [config] devices:
[2023-06-25 14:46:57] [config]   - 0
[2023-06-25 14:46:57] [config] dim-emb: 512
[2023-06-25 14:46:57] [config] dim-rnn: 1024
[2023-06-25 14:46:57] [config] dim-vocabs:
[2023-06-25 14:46:57] [config]   - 54042
[2023-06-25 14:46:57] [config]   - 36507
[2023-06-25 14:46:57] [config] disp-first: 0
[2023-06-25 14:46:57] [config] disp-freq: 1000u
[2023-06-25 14:46:57] [config] disp-label-counts: true
[2023-06-25 14:46:57] [config] dropout-rnn: 0.1
[2023-06-25 14:46:57] [config] dropout-src: 0
[2023-06-25 14:46:57] [config] dropout-trg: 0
[2023-06-25 14:46:57] [config] dump-config: ""
[2023-06-25 14:46:57] [config] dynamic-gradient-scaling:
[2023-06-25 14:46:57] [config]   []
[2023-06-25 14:46:57] [config] early-stopping: 10
[2023-06-25 14:46:57] [config] early-stopping-on: first
[2023-06-25 14:46:57] [config] embedding-fix-src: false
[2023-06-25 14:46:57] [config] embedding-fix-trg: false
[2023-06-25 14:46:57] [config] embedding-normalization: false
[2023-06-25 14:46:57] [config] embedding-vectors:
[2023-06-25 14:46:57] [config]   []
[2023-06-25 14:46:57] [config] enc-cell: gru
[2023-06-25 14:46:57] [config] enc-cell-depth: 4
[2023-06-25 14:46:57] [config] enc-depth: 2
[2023-06-25 14:46:57] [config] enc-type: bidirectional
[2023-06-25 14:46:57] [config] english-title-case-every: 0
[2023-06-25 14:46:57] [config] exponential-smoothing: 0.0001
[2023-06-25 14:46:57] [config] factor-weight: 1
[2023-06-25 14:46:57] [config] factors-combine: sum
[2023-06-25 14:46:57] [config] factors-dim-emb: 0
[2023-06-25 14:46:57] [config] gradient-checkpointing: false
[2023-06-25 14:46:57] [config] gradient-norm-average-window: 100
[2023-06-25 14:46:57] [config] guided-alignment: none
[2023-06-25 14:46:57] [config] guided-alignment-cost: mse
[2023-06-25 14:46:57] [config] guided-alignment-weight: 0.1
[2023-06-25 14:46:57] [config] ignore-model-config: false
[2023-06-25 14:46:57] [config] input-types:
[2023-06-25 14:46:57] [config]   []
[2023-06-25 14:46:57] [config] interpolate-env-vars: false
[2023-06-25 14:46:57] [config] keep-best: false
[2023-06-25 14:46:57] [config] label-smoothing: 0.1
[2023-06-25 14:46:57] [config] layer-normalization: true
[2023-06-25 14:46:57] [config] learn-rate: 0.0003
[2023-06-25 14:46:57] [config] lemma-dependency: ""
[2023-06-25 14:46:57] [config] lemma-dim-emb: 0
[2023-06-25 14:46:57] [config] log: /docker/home/marianmt/logs/marian/split_model_gn_es_edinburgh2017_depth2.log
[2023-06-25 14:46:57] [config] log-level: info
[2023-06-25 14:46:57] [config] log-time-zone: ""
[2023-06-25 14:46:57] [config] logical-epoch:
[2023-06-25 14:46:57] [config]   - 1e
[2023-06-25 14:46:57] [config]   - 0
[2023-06-25 14:46:57] [config] lr-decay: 0
[2023-06-25 14:46:57] [config] lr-decay-freq: 50000
[2023-06-25 14:46:57] [config] lr-decay-inv-sqrt:
[2023-06-25 14:46:57] [config]   - 16000
[2023-06-25 14:46:57] [config] lr-decay-repeat-warmup: false
[2023-06-25 14:46:57] [config] lr-decay-reset-optimizer: false
[2023-06-25 14:46:57] [config] lr-decay-start:
[2023-06-25 14:46:57] [config]   - 10
[2023-06-25 14:46:57] [config]   - 1
[2023-06-25 14:46:57] [config] lr-decay-strategy: epoch+stalled
[2023-06-25 14:46:57] [config] lr-report: false
[2023-06-25 14:46:57] [config] lr-warmup: 0
[2023-06-25 14:46:57] [config] lr-warmup-at-reload: false
[2023-06-25 14:46:57] [config] lr-warmup-cycle: false
[2023-06-25 14:46:57] [config] lr-warmup-start-rate: 0
[2023-06-25 14:46:57] [config] max-length: 100
[2023-06-25 14:46:57] [config] max-length-crop: false
[2023-06-25 14:46:57] [config] max-length-factor: 3
[2023-06-25 14:46:57] [config] maxi-batch: 1000
[2023-06-25 14:46:57] [config] maxi-batch-sort: trg
[2023-06-25 14:46:57] [config] mini-batch: 1000
[2023-06-25 14:46:57] [config] mini-batch-fit: true
[2023-06-25 14:46:57] [config] mini-batch-fit-step: 10
[2023-06-25 14:46:57] [config] mini-batch-round-up: true
[2023-06-25 14:46:57] [config] mini-batch-track-lr: false
[2023-06-25 14:46:57] [config] mini-batch-warmup: 0
[2023-06-25 14:46:57] [config] mini-batch-words: 0
[2023-06-25 14:46:57] [config] mini-batch-words-ref: 0
[2023-06-25 14:46:57] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz
[2023-06-25 14:46:57] [config] multi-loss-type: sum
[2023-06-25 14:46:57] [config] n-best: false
[2023-06-25 14:46:57] [config] no-nccl: false
[2023-06-25 14:46:57] [config] no-reload: false
[2023-06-25 14:46:57] [config] no-restore-corpus: false
[2023-06-25 14:46:57] [config] normalize: 1
[2023-06-25 14:46:57] [config] normalize-gradient: false
[2023-06-25 14:46:57] [config] num-devices: 0
[2023-06-25 14:46:57] [config] optimizer: adam
[2023-06-25 14:46:57] [config] optimizer-delay: 1
[2023-06-25 14:46:57] [config] optimizer-params:
[2023-06-25 14:46:57] [config]   - 0.9
[2023-06-25 14:46:57] [config]   - 0.98
[2023-06-25 14:46:57] [config]   - 1e-09
[2023-06-25 14:46:57] [config] output-omit-bias: false
[2023-06-25 14:46:57] [config] overwrite: false
[2023-06-25 14:46:57] [config] precision:
[2023-06-25 14:46:57] [config]   - float32
[2023-06-25 14:46:57] [config]   - float32
[2023-06-25 14:46:57] [config] pretrained-model: ""
[2023-06-25 14:46:57] [config] quantize-biases: false
[2023-06-25 14:46:57] [config] quantize-bits: 0
[2023-06-25 14:46:57] [config] quantize-log-based: false
[2023-06-25 14:46:57] [config] quantize-optimization-steps: 0
[2023-06-25 14:46:57] [config] quiet: false
[2023-06-25 14:46:57] [config] quiet-translation: true
[2023-06-25 14:46:57] [config] relative-paths: false
[2023-06-25 14:46:57] [config] right-left: false
[2023-06-25 14:46:57] [config] save-freq: 10000u
[2023-06-25 14:46:57] [config] seed: 1234
[2023-06-25 14:46:57] [config] sentencepiece-alphas:
[2023-06-25 14:46:57] [config]   []
[2023-06-25 14:46:57] [config] sentencepiece-max-lines: 2000000
[2023-06-25 14:46:57] [config] sentencepiece-options: ""
[2023-06-25 14:46:57] [config] sharding: global
[2023-06-25 14:46:57] [config] shuffle: data
[2023-06-25 14:46:57] [config] shuffle-in-ram: false
[2023-06-25 14:46:57] [config] sigterm: save-and-exit
[2023-06-25 14:46:57] [config] skip: false
[2023-06-25 14:46:57] [config] sqlite: ""
[2023-06-25 14:46:57] [config] sqlite-drop: false
[2023-06-25 14:46:57] [config] sync-freq: 200u
[2023-06-25 14:46:57] [config] sync-sgd: true
[2023-06-25 14:46:57] [config] tempdir: /tmp
[2023-06-25 14:46:57] [config] tied-embeddings: false
[2023-06-25 14:46:57] [config] tied-embeddings-all: false
[2023-06-25 14:46:57] [config] tied-embeddings-src: false
[2023-06-25 14:46:57] [config] train-embedder-rank:
[2023-06-25 14:46:57] [config]   []
[2023-06-25 14:46:57] [config] train-sets:
[2023-06-25 14:46:57] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-06-25 14:46:57] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-06-25 14:46:57] [config] transformer-aan-activation: swish
[2023-06-25 14:46:57] [config] transformer-aan-depth: 2
[2023-06-25 14:46:57] [config] transformer-aan-nogate: false
[2023-06-25 14:46:57] [config] transformer-decoder-autoreg: self-attention
[2023-06-25 14:46:57] [config] transformer-decoder-dim-ffn: 0
[2023-06-25 14:46:57] [config] transformer-decoder-ffn-depth: 0
[2023-06-25 14:46:57] [config] transformer-depth-scaling: false
[2023-06-25 14:46:57] [config] transformer-dim-aan: 2048
[2023-06-25 14:46:57] [config] transformer-dim-ffn: 2048
[2023-06-25 14:46:57] [config] transformer-dropout: 0
[2023-06-25 14:46:57] [config] transformer-dropout-attention: 0
[2023-06-25 14:46:57] [config] transformer-dropout-ffn: 0
[2023-06-25 14:46:57] [config] transformer-ffn-activation: swish
[2023-06-25 14:46:57] [config] transformer-ffn-depth: 2
[2023-06-25 14:46:57] [config] transformer-guided-alignment-layer: last
[2023-06-25 14:46:57] [config] transformer-heads: 8
[2023-06-25 14:46:57] [config] transformer-no-projection: false
[2023-06-25 14:46:57] [config] transformer-pool: false
[2023-06-25 14:46:57] [config] transformer-postprocess: dan
[2023-06-25 14:46:57] [config] transformer-postprocess-emb: d
[2023-06-25 14:46:57] [config] transformer-postprocess-top: ""
[2023-06-25 14:46:57] [config] transformer-preprocess: ""
[2023-06-25 14:46:57] [config] transformer-tied-layers:
[2023-06-25 14:46:57] [config]   []
[2023-06-25 14:46:57] [config] transformer-train-position-embeddings: false
[2023-06-25 14:46:57] [config] tsv: false
[2023-06-25 14:46:57] [config] tsv-fields: 0
[2023-06-25 14:46:57] [config] type: s2s
[2023-06-25 14:46:57] [config] ulr: false
[2023-06-25 14:46:57] [config] ulr-dim-emb: 0
[2023-06-25 14:46:57] [config] ulr-dropout: 0
[2023-06-25 14:46:57] [config] ulr-keys-vectors: ""
[2023-06-25 14:46:57] [config] ulr-query-vectors: ""
[2023-06-25 14:46:57] [config] ulr-softmax-temperature: 1
[2023-06-25 14:46:57] [config] ulr-trainable-transformation: false
[2023-06-25 14:46:57] [config] unlikelihood-loss: false
[2023-06-25 14:46:57] [config] valid-freq: 5000000
[2023-06-25 14:46:57] [config] valid-log: /docker/home/marianmt/logs/marian/split_tok_150_gn_es_edinburgh2017_depth2.log
[2023-06-25 14:46:57] [config] valid-max-length: 1000
[2023-06-25 14:46:57] [config] valid-metrics:
[2023-06-25 14:46:57] [config]   - cross-entropy
[2023-06-25 14:46:57] [config]   - translation
[2023-06-25 14:46:57] [config] valid-mini-batch: 32
[2023-06-25 14:46:57] [config] valid-reset-stalled: false
[2023-06-25 14:46:57] [config] valid-script-args:
[2023-06-25 14:46:57] [config]   []
[2023-06-25 14:46:57] [config] valid-script-path: ""
[2023-06-25 14:46:57] [config] valid-sets:
[2023-06-25 14:46:57] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-06-25 14:46:57] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-06-25 14:46:57] [config] valid-translation-output: /docker/home/marianmt/evaluation/model-epochs.txt
[2023-06-25 14:46:57] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-06-25 14:46:57] [config] vocabs:
[2023-06-25 14:46:57] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens.txt.gn
[2023-06-25 14:46:57] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens.txt.es
[2023-06-25 14:46:57] [config] word-penalty: 0
[2023-06-25 14:46:57] [config] word-scores: false
[2023-06-25 14:46:57] [config] workspace: 2048
[2023-06-25 14:46:57] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-06-25 14:46:57] Using synchronous SGD
[2023-06-25 14:46:58] Synced seed 1234
[2023-06-25 14:46:58] [data] Loading vocabulary from text file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens.txt.gn
[2023-06-25 14:46:58] [data] Setting vocabulary size for input 0 to 54,042
[2023-06-25 14:46:58] [data] Loading vocabulary from text file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens.txt.es
[2023-06-25 14:46:58] [data] Setting vocabulary size for input 1 to 36,507
[2023-06-25 14:46:58] [batching] Collecting statistics for batch fitting with step size 10
[2023-06-25 14:46:58] [MPI rank 0 out of 1]: GPU[0]
[2023-06-25 14:46:58] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-06-25 14:46:59] [comm] Using NCCL 2.8.3 for GPU communication
[2023-06-25 14:46:59] [comm] Using global sharding
[2023-06-25 14:46:59] [comm] NCCLCommunicators constructed successfully
[2023-06-25 14:46:59] [training] Using 1 GPUs
[2023-06-25 14:46:59] [logits] Applying loss function for 1 factor(s)
[2023-06-25 14:46:59] [memory] Reserving 666 MB, device gpu0
[2023-06-25 14:46:59] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-06-25 14:47:00] [memory] Reserving 666 MB, device gpu0
[2023-06-25 14:47:24] [batching] Done. Typical MB size is 1,196 target words
[2023-06-25 14:47:24] [valid] No post-processing script given for validating translator
[2023-06-25 14:47:24] [MPI rank 0 out of 1]: GPU[0]
[2023-06-25 14:47:24] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-06-25 14:47:24] [comm] Using NCCL 2.8.3 for GPU communication
[2023-06-25 14:47:24] [comm] Using global sharding
[2023-06-25 14:47:24] [comm] NCCLCommunicators constructed successfully
[2023-06-25 14:47:24] [training] Using 1 GPUs
[2023-06-25 14:47:24] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz
[2023-06-25 14:47:30] Allocating memory for general optimizer shards
[2023-06-25 14:47:30] [memory] Reserving 666 MB, device gpu0
[2023-06-25 14:47:30] Loading Adam parameters
[2023-06-25 14:47:31] [memory] Reserving 1332 MB, device gpu0
[2023-06-25 14:47:31] [memory] Reserving 666 MB, device gpu0
[2023-06-25 14:47:32] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz.optimizer.npz
[2023-06-25 14:47:32] [data] Restoring the corpus state to epoch 81, batch 39120
[2023-06-25 14:47:32] [data] Shuffling data
[2023-06-25 14:47:32] [data] Done reading 20,192 sentences
[2023-06-25 14:47:32] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 14:47:32] Training started
[2023-06-25 14:47:32] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-06-25 14:47:32] [memory] Reserving 666 MB, device gpu0
[2023-06-25 14:47:33] Parameter type float32, optimization type float32, casting types false
[2023-06-25 14:51:14] Seen 20,177 samples
[2023-06-25 14:51:14] Starting data epoch 82 in logical epoch 82
[2023-06-25 14:51:14] [data] Shuffling data
[2023-06-25 14:51:14] [data] Done reading 20,192 sentences
[2023-06-25 14:51:14] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 14:54:19] Ep. 82 : Up. 40000 : Sen. 15,834 : Cost 1.64182889 : Time 414.33s : 2363.35 words/s : gNorm 0.2451
[2023-06-25 14:54:19] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.iter40000.npz
[2023-06-25 14:54:24] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz
[2023-06-25 14:54:31] Saving Adam parameters
[2023-06-25 14:54:34] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz.optimizer.npz
[2023-06-25 14:55:34] Seen 20,177 samples
[2023-06-25 14:55:34] Starting data epoch 83 in logical epoch 83
[2023-06-25 14:55:34] [data] Shuffling data
[2023-06-25 14:55:34] [data] Done reading 20,192 sentences
[2023-06-25 14:55:34] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 14:59:17] Seen 20,177 samples
[2023-06-25 14:59:17] Starting data epoch 84 in logical epoch 84
[2023-06-25 14:59:17] [data] Shuffling data
[2023-06-25 14:59:17] [data] Done reading 20,192 sentences
[2023-06-25 14:59:17] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 15:02:29] Ep. 84 : Up. 41000 : Sen. 17,211 : Cost 1.64137554 : Time 490.41s : 1986.42 words/s : gNorm 0.2354
[2023-06-25 15:03:05] Seen 20,177 samples
[2023-06-25 15:03:05] Starting data epoch 85 in logical epoch 85
[2023-06-25 15:03:05] [data] Shuffling data
[2023-06-25 15:03:05] [data] Done reading 20,192 sentences
[2023-06-25 15:03:05] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 15:06:51] Seen 20,177 samples
[2023-06-25 15:06:51] Starting data epoch 86 in logical epoch 86
[2023-06-25 15:06:51] [data] Shuffling data
[2023-06-25 15:06:51] [data] Done reading 20,192 sentences
[2023-06-25 15:06:52] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 15:10:13] Ep. 86 : Up. 42000 : Sen. 18,030 : Cost 1.64089000 : Time 463.75s : 2110.35 words/s : gNorm 0.2220
[2023-06-25 15:10:38] Seen 20,177 samples
[2023-06-25 15:10:38] Starting data epoch 87 in logical epoch 87
[2023-06-25 15:10:38] [data] Shuffling data
[2023-06-25 15:10:38] [data] Done reading 20,192 sentences
[2023-06-25 15:10:38] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 15:14:25] Seen 20,177 samples
[2023-06-25 15:14:25] Starting data epoch 88 in logical epoch 88
[2023-06-25 15:14:25] [data] Shuffling data
[2023-06-25 15:14:25] [data] Done reading 20,192 sentences
[2023-06-25 15:14:25] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 15:17:57] Ep. 88 : Up. 43000 : Sen. 18,859 : Cost 1.63795912 : Time 464.67s : 2104.50 words/s : gNorm 0.2220
[2023-06-25 15:18:12] Seen 20,177 samples
[2023-06-25 15:18:12] Starting data epoch 89 in logical epoch 89
[2023-06-25 15:18:12] [data] Shuffling data
[2023-06-25 15:18:12] [data] Done reading 20,192 sentences
[2023-06-25 15:18:12] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 15:21:59] Seen 20,177 samples
[2023-06-25 15:21:59] Starting data epoch 90 in logical epoch 90
[2023-06-25 15:21:59] [data] Shuffling data
[2023-06-25 15:21:59] [data] Done reading 20,192 sentences
[2023-06-25 15:21:59] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 15:25:41] Ep. 90 : Up. 44000 : Sen. 19,663 : Cost 1.63811910 : Time 463.56s : 2106.74 words/s : gNorm 0.2189
[2023-06-25 15:25:45] Seen 20,177 samples
[2023-06-25 15:25:45] Starting data epoch 91 in logical epoch 91
[2023-06-25 15:25:45] Training finished
[2023-06-25 15:26:02] [valid] Ep. 91 : Up. 44010 : cross-entropy : 102.079 : stalled 8 times (last best: 86.5722)
[2023-06-25 15:29:59] [valid] Ep. 91 : Up. 44010 : translation : 0 : new best
[2023-06-25 15:29:59] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz
[2023-06-25 15:30:07] Saving Adam parameters
[2023-06-25 15:30:10] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz.optimizer.npz
[2023-06-25 15:39:17] [marian] Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-06-25 15:39:17] [marian] Running on node07.datos.cluster.uy as process 20822 with command line:
[2023-06-25 15:39:17] [marian] /marian/build/marian --train-sets /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn /docker/home/marianmt/artifacts/data/train/train_es.txt.es --model /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz --after-epochs 100 --valid-freq 5000000 --vocabs /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens.txt.gn /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens.txt.es --seed 1234 --type s2s --max-length 100 --mini-batch-fit --mini-batch 1000 --maxi-batch 1000 --beam-size 12 --normalize 1 --cost-type ce-mean-words --enc-type bidirectional --enc-depth 2 --enc-cell-depth 4 --dec-depth 2 --dec-cell-base-depth 8 --dec-cell-high-depth 1 --layer-normalization --dropout-rnn 0.1 --label-smoothing 0.1 --learn-rate 0.0003 --lr-decay-inv-sqrt 16000 --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --sync-sgd --exponential-smoothing --cpu-threads 0 --log /docker/home/marianmt/logs/marian/split_model_gn_es_edinburgh2017_depth2.log --valid-log /docker/home/marianmt/logs/marian/split_tok_150_gn_es_edinburgh2017_depth2.log --valid-sets /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es --valid-metrics cross-entropy translation --valid-translation-output /docker/home/marianmt/evaluation/model-epochs.txt --quiet-translation
[2023-06-25 15:39:17] [config] after: 0e
[2023-06-25 15:39:17] [config] after-batches: 0
[2023-06-25 15:39:17] [config] after-epochs: 100
[2023-06-25 15:39:17] [config] all-caps-every: 0
[2023-06-25 15:39:17] [config] allow-unk: false
[2023-06-25 15:39:17] [config] authors: false
[2023-06-25 15:39:17] [config] beam-size: 12
[2023-06-25 15:39:17] [config] bert-class-symbol: "[CLS]"
[2023-06-25 15:39:17] [config] bert-mask-symbol: "[MASK]"
[2023-06-25 15:39:17] [config] bert-masking-fraction: 0.15
[2023-06-25 15:39:17] [config] bert-sep-symbol: "[SEP]"
[2023-06-25 15:39:17] [config] bert-train-type-embeddings: true
[2023-06-25 15:39:17] [config] bert-type-vocab-size: 2
[2023-06-25 15:39:17] [config] build-info: ""
[2023-06-25 15:39:17] [config] check-gradient-nan: false
[2023-06-25 15:39:17] [config] check-nan: false
[2023-06-25 15:39:17] [config] cite: false
[2023-06-25 15:39:17] [config] clip-norm: 5
[2023-06-25 15:39:17] [config] cost-scaling:
[2023-06-25 15:39:17] [config]   []
[2023-06-25 15:39:17] [config] cost-type: ce-mean-words
[2023-06-25 15:39:17] [config] cpu-threads: 0
[2023-06-25 15:39:17] [config] data-threads: 8
[2023-06-25 15:39:17] [config] data-weighting: ""
[2023-06-25 15:39:17] [config] data-weighting-type: sentence
[2023-06-25 15:39:17] [config] dec-cell: gru
[2023-06-25 15:39:17] [config] dec-cell-base-depth: 8
[2023-06-25 15:39:17] [config] dec-cell-high-depth: 1
[2023-06-25 15:39:17] [config] dec-depth: 2
[2023-06-25 15:39:17] [config] devices:
[2023-06-25 15:39:17] [config]   - 0
[2023-06-25 15:39:17] [config] dim-emb: 512
[2023-06-25 15:39:17] [config] dim-rnn: 1024
[2023-06-25 15:39:17] [config] dim-vocabs:
[2023-06-25 15:39:17] [config]   - 54042
[2023-06-25 15:39:17] [config]   - 36507
[2023-06-25 15:39:17] [config] disp-first: 0
[2023-06-25 15:39:17] [config] disp-freq: 1000u
[2023-06-25 15:39:17] [config] disp-label-counts: true
[2023-06-25 15:39:17] [config] dropout-rnn: 0.1
[2023-06-25 15:39:17] [config] dropout-src: 0
[2023-06-25 15:39:17] [config] dropout-trg: 0
[2023-06-25 15:39:17] [config] dump-config: ""
[2023-06-25 15:39:17] [config] dynamic-gradient-scaling:
[2023-06-25 15:39:17] [config]   []
[2023-06-25 15:39:17] [config] early-stopping: 10
[2023-06-25 15:39:17] [config] early-stopping-on: first
[2023-06-25 15:39:17] [config] embedding-fix-src: false
[2023-06-25 15:39:17] [config] embedding-fix-trg: false
[2023-06-25 15:39:17] [config] embedding-normalization: false
[2023-06-25 15:39:17] [config] embedding-vectors:
[2023-06-25 15:39:17] [config]   []
[2023-06-25 15:39:17] [config] enc-cell: gru
[2023-06-25 15:39:17] [config] enc-cell-depth: 4
[2023-06-25 15:39:17] [config] enc-depth: 2
[2023-06-25 15:39:17] [config] enc-type: bidirectional
[2023-06-25 15:39:17] [config] english-title-case-every: 0
[2023-06-25 15:39:17] [config] exponential-smoothing: 0.0001
[2023-06-25 15:39:17] [config] factor-weight: 1
[2023-06-25 15:39:17] [config] factors-combine: sum
[2023-06-25 15:39:17] [config] factors-dim-emb: 0
[2023-06-25 15:39:17] [config] gradient-checkpointing: false
[2023-06-25 15:39:17] [config] gradient-norm-average-window: 100
[2023-06-25 15:39:17] [config] guided-alignment: none
[2023-06-25 15:39:17] [config] guided-alignment-cost: mse
[2023-06-25 15:39:17] [config] guided-alignment-weight: 0.1
[2023-06-25 15:39:17] [config] ignore-model-config: false
[2023-06-25 15:39:17] [config] input-types:
[2023-06-25 15:39:17] [config]   []
[2023-06-25 15:39:17] [config] interpolate-env-vars: false
[2023-06-25 15:39:17] [config] keep-best: false
[2023-06-25 15:39:17] [config] label-smoothing: 0.1
[2023-06-25 15:39:17] [config] layer-normalization: true
[2023-06-25 15:39:17] [config] learn-rate: 0.0003
[2023-06-25 15:39:17] [config] lemma-dependency: ""
[2023-06-25 15:39:17] [config] lemma-dim-emb: 0
[2023-06-25 15:39:17] [config] log: /docker/home/marianmt/logs/marian/split_model_gn_es_edinburgh2017_depth2.log
[2023-06-25 15:39:17] [config] log-level: info
[2023-06-25 15:39:17] [config] log-time-zone: ""
[2023-06-25 15:39:17] [config] logical-epoch:
[2023-06-25 15:39:17] [config]   - 1e
[2023-06-25 15:39:17] [config]   - 0
[2023-06-25 15:39:17] [config] lr-decay: 0
[2023-06-25 15:39:17] [config] lr-decay-freq: 50000
[2023-06-25 15:39:17] [config] lr-decay-inv-sqrt:
[2023-06-25 15:39:17] [config]   - 16000
[2023-06-25 15:39:17] [config] lr-decay-repeat-warmup: false
[2023-06-25 15:39:17] [config] lr-decay-reset-optimizer: false
[2023-06-25 15:39:17] [config] lr-decay-start:
[2023-06-25 15:39:17] [config]   - 10
[2023-06-25 15:39:17] [config]   - 1
[2023-06-25 15:39:17] [config] lr-decay-strategy: epoch+stalled
[2023-06-25 15:39:17] [config] lr-report: false
[2023-06-25 15:39:17] [config] lr-warmup: 0
[2023-06-25 15:39:17] [config] lr-warmup-at-reload: false
[2023-06-25 15:39:17] [config] lr-warmup-cycle: false
[2023-06-25 15:39:17] [config] lr-warmup-start-rate: 0
[2023-06-25 15:39:17] [config] max-length: 100
[2023-06-25 15:39:17] [config] max-length-crop: false
[2023-06-25 15:39:17] [config] max-length-factor: 3
[2023-06-25 15:39:17] [config] maxi-batch: 1000
[2023-06-25 15:39:17] [config] maxi-batch-sort: trg
[2023-06-25 15:39:17] [config] mini-batch: 1000
[2023-06-25 15:39:17] [config] mini-batch-fit: true
[2023-06-25 15:39:17] [config] mini-batch-fit-step: 10
[2023-06-25 15:39:17] [config] mini-batch-round-up: true
[2023-06-25 15:39:17] [config] mini-batch-track-lr: false
[2023-06-25 15:39:17] [config] mini-batch-warmup: 0
[2023-06-25 15:39:17] [config] mini-batch-words: 0
[2023-06-25 15:39:17] [config] mini-batch-words-ref: 0
[2023-06-25 15:39:17] [config] model: /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz
[2023-06-25 15:39:17] [config] multi-loss-type: sum
[2023-06-25 15:39:17] [config] n-best: false
[2023-06-25 15:39:17] [config] no-nccl: false
[2023-06-25 15:39:17] [config] no-reload: false
[2023-06-25 15:39:17] [config] no-restore-corpus: false
[2023-06-25 15:39:17] [config] normalize: 1
[2023-06-25 15:39:17] [config] normalize-gradient: false
[2023-06-25 15:39:17] [config] num-devices: 0
[2023-06-25 15:39:17] [config] optimizer: adam
[2023-06-25 15:39:17] [config] optimizer-delay: 1
[2023-06-25 15:39:17] [config] optimizer-params:
[2023-06-25 15:39:17] [config]   - 0.9
[2023-06-25 15:39:17] [config]   - 0.98
[2023-06-25 15:39:17] [config]   - 1e-09
[2023-06-25 15:39:17] [config] output-omit-bias: false
[2023-06-25 15:39:17] [config] overwrite: false
[2023-06-25 15:39:17] [config] precision:
[2023-06-25 15:39:17] [config]   - float32
[2023-06-25 15:39:17] [config]   - float32
[2023-06-25 15:39:17] [config] pretrained-model: ""
[2023-06-25 15:39:17] [config] quantize-biases: false
[2023-06-25 15:39:17] [config] quantize-bits: 0
[2023-06-25 15:39:17] [config] quantize-log-based: false
[2023-06-25 15:39:17] [config] quantize-optimization-steps: 0
[2023-06-25 15:39:17] [config] quiet: false
[2023-06-25 15:39:17] [config] quiet-translation: true
[2023-06-25 15:39:17] [config] relative-paths: false
[2023-06-25 15:39:17] [config] right-left: false
[2023-06-25 15:39:17] [config] save-freq: 10000u
[2023-06-25 15:39:17] [config] seed: 1234
[2023-06-25 15:39:17] [config] sentencepiece-alphas:
[2023-06-25 15:39:17] [config]   []
[2023-06-25 15:39:17] [config] sentencepiece-max-lines: 2000000
[2023-06-25 15:39:17] [config] sentencepiece-options: ""
[2023-06-25 15:39:17] [config] sharding: global
[2023-06-25 15:39:17] [config] shuffle: data
[2023-06-25 15:39:17] [config] shuffle-in-ram: false
[2023-06-25 15:39:17] [config] sigterm: save-and-exit
[2023-06-25 15:39:17] [config] skip: false
[2023-06-25 15:39:17] [config] sqlite: ""
[2023-06-25 15:39:17] [config] sqlite-drop: false
[2023-06-25 15:39:17] [config] sync-freq: 200u
[2023-06-25 15:39:17] [config] sync-sgd: true
[2023-06-25 15:39:17] [config] tempdir: /tmp
[2023-06-25 15:39:17] [config] tied-embeddings: false
[2023-06-25 15:39:17] [config] tied-embeddings-all: false
[2023-06-25 15:39:17] [config] tied-embeddings-src: false
[2023-06-25 15:39:17] [config] train-embedder-rank:
[2023-06-25 15:39:17] [config]   []
[2023-06-25 15:39:17] [config] train-sets:
[2023-06-25 15:39:17] [config]   - /docker/home/marianmt/artifacts/data/train/train_gn.txt.gn
[2023-06-25 15:39:17] [config]   - /docker/home/marianmt/artifacts/data/train/train_es.txt.es
[2023-06-25 15:39:17] [config] transformer-aan-activation: swish
[2023-06-25 15:39:17] [config] transformer-aan-depth: 2
[2023-06-25 15:39:17] [config] transformer-aan-nogate: false
[2023-06-25 15:39:17] [config] transformer-decoder-autoreg: self-attention
[2023-06-25 15:39:17] [config] transformer-decoder-dim-ffn: 0
[2023-06-25 15:39:17] [config] transformer-decoder-ffn-depth: 0
[2023-06-25 15:39:17] [config] transformer-depth-scaling: false
[2023-06-25 15:39:17] [config] transformer-dim-aan: 2048
[2023-06-25 15:39:17] [config] transformer-dim-ffn: 2048
[2023-06-25 15:39:17] [config] transformer-dropout: 0
[2023-06-25 15:39:17] [config] transformer-dropout-attention: 0
[2023-06-25 15:39:17] [config] transformer-dropout-ffn: 0
[2023-06-25 15:39:17] [config] transformer-ffn-activation: swish
[2023-06-25 15:39:17] [config] transformer-ffn-depth: 2
[2023-06-25 15:39:17] [config] transformer-guided-alignment-layer: last
[2023-06-25 15:39:17] [config] transformer-heads: 8
[2023-06-25 15:39:17] [config] transformer-no-projection: false
[2023-06-25 15:39:17] [config] transformer-pool: false
[2023-06-25 15:39:17] [config] transformer-postprocess: dan
[2023-06-25 15:39:17] [config] transformer-postprocess-emb: d
[2023-06-25 15:39:17] [config] transformer-postprocess-top: ""
[2023-06-25 15:39:17] [config] transformer-preprocess: ""
[2023-06-25 15:39:17] [config] transformer-tied-layers:
[2023-06-25 15:39:17] [config]   []
[2023-06-25 15:39:17] [config] transformer-train-position-embeddings: false
[2023-06-25 15:39:17] [config] tsv: false
[2023-06-25 15:39:17] [config] tsv-fields: 0
[2023-06-25 15:39:17] [config] type: s2s
[2023-06-25 15:39:17] [config] ulr: false
[2023-06-25 15:39:17] [config] ulr-dim-emb: 0
[2023-06-25 15:39:17] [config] ulr-dropout: 0
[2023-06-25 15:39:17] [config] ulr-keys-vectors: ""
[2023-06-25 15:39:17] [config] ulr-query-vectors: ""
[2023-06-25 15:39:17] [config] ulr-softmax-temperature: 1
[2023-06-25 15:39:17] [config] ulr-trainable-transformation: false
[2023-06-25 15:39:17] [config] unlikelihood-loss: false
[2023-06-25 15:39:17] [config] valid-freq: 5000000
[2023-06-25 15:39:17] [config] valid-log: /docker/home/marianmt/logs/marian/split_tok_150_gn_es_edinburgh2017_depth2.log
[2023-06-25 15:39:17] [config] valid-max-length: 1000
[2023-06-25 15:39:17] [config] valid-metrics:
[2023-06-25 15:39:17] [config]   - cross-entropy
[2023-06-25 15:39:17] [config]   - translation
[2023-06-25 15:39:17] [config] valid-mini-batch: 32
[2023-06-25 15:39:17] [config] valid-reset-stalled: false
[2023-06-25 15:39:17] [config] valid-script-args:
[2023-06-25 15:39:17] [config]   []
[2023-06-25 15:39:17] [config] valid-script-path: ""
[2023-06-25 15:39:17] [config] valid-sets:
[2023-06-25 15:39:17] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_gn.txt.gn
[2023-06-25 15:39:17] [config]   - /docker/home/marianmt/artifacts/data/validation/valid_es.txt.es
[2023-06-25 15:39:17] [config] valid-translation-output: /docker/home/marianmt/evaluation/model-epochs.txt
[2023-06-25 15:39:17] [config] version: v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-06-25 15:39:17] [config] vocabs:
[2023-06-25 15:39:17] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens.txt.gn
[2023-06-25 15:39:17] [config]   - /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens.txt.es
[2023-06-25 15:39:17] [config] word-penalty: 0
[2023-06-25 15:39:17] [config] word-scores: false
[2023-06-25 15:39:17] [config] workspace: 2048
[2023-06-25 15:39:17] [config] Loaded model has been created with Marian v1.11.0 f00d062 2022-02-08 08:39:24 -0800
[2023-06-25 15:39:17] Using synchronous SGD
[2023-06-25 15:39:19] Synced seed 1234
[2023-06-25 15:39:19] [data] Loading vocabulary from text file /docker/home/marianmt/artifacts/data/vocabulary/gn_unique_tokens.txt.gn
[2023-06-25 15:39:19] [data] Setting vocabulary size for input 0 to 54,042
[2023-06-25 15:39:19] [data] Loading vocabulary from text file /docker/home/marianmt/artifacts/data/vocabulary/es_unique_tokens.txt.es
[2023-06-25 15:39:19] [data] Setting vocabulary size for input 1 to 36,507
[2023-06-25 15:39:19] [batching] Collecting statistics for batch fitting with step size 10
[2023-06-25 15:39:19] [MPI rank 0 out of 1]: GPU[0]
[2023-06-25 15:39:20] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-06-25 15:39:20] [comm] Using NCCL 2.8.3 for GPU communication
[2023-06-25 15:39:20] [comm] Using global sharding
[2023-06-25 15:39:20] [comm] NCCLCommunicators constructed successfully
[2023-06-25 15:39:20] [training] Using 1 GPUs
[2023-06-25 15:39:20] [logits] Applying loss function for 1 factor(s)
[2023-06-25 15:39:20] [memory] Reserving 666 MB, device gpu0
[2023-06-25 15:39:20] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-06-25 15:39:21] [memory] Reserving 666 MB, device gpu0
[2023-06-25 15:39:45] [batching] Done. Typical MB size is 1,196 target words
[2023-06-25 15:39:45] [valid] No post-processing script given for validating translator
[2023-06-25 15:39:45] [MPI rank 0 out of 1]: GPU[0]
[2023-06-25 15:39:45] [memory] Extending reserved space to 2048 MB (device gpu0)
[2023-06-25 15:39:45] [comm] Using NCCL 2.8.3 for GPU communication
[2023-06-25 15:39:45] [comm] Using global sharding
[2023-06-25 15:39:45] [comm] NCCLCommunicators constructed successfully
[2023-06-25 15:39:45] [training] Using 1 GPUs
[2023-06-25 15:39:45] Loading model from /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz
[2023-06-25 15:39:51] Allocating memory for general optimizer shards
[2023-06-25 15:39:51] [memory] Reserving 666 MB, device gpu0
[2023-06-25 15:39:51] Loading Adam parameters
[2023-06-25 15:39:52] [memory] Reserving 1332 MB, device gpu0
[2023-06-25 15:39:52] [memory] Reserving 666 MB, device gpu0
[2023-06-25 15:39:52] [training] Master parameters and optimizers restored from training checkpoint /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz.optimizer.npz
[2023-06-25 15:39:52] [data] Restoring the corpus state to epoch 91, batch 44010
[2023-06-25 15:39:52] [data] Shuffling data
[2023-06-25 15:39:52] [data] Done reading 20,192 sentences
[2023-06-25 15:39:52] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 15:39:52] Training started
[2023-06-25 15:39:52] [training] Batches are processed as 1 process(es) x 1 devices/process
[2023-06-25 15:39:53] [memory] Reserving 666 MB, device gpu0
[2023-06-25 15:39:53] Parameter type float32, optimization type float32, casting types false
[2023-06-25 15:43:36] Seen 20,177 samples
[2023-06-25 15:43:36] Starting data epoch 92 in logical epoch 92
[2023-06-25 15:43:36] [data] Shuffling data
[2023-06-25 15:43:36] [data] Done reading 20,192 sentences
[2023-06-25 15:43:37] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 15:47:23] Seen 20,177 samples
[2023-06-25 15:47:23] Starting data epoch 93 in logical epoch 93
[2023-06-25 15:47:23] [data] Shuffling data
[2023-06-25 15:47:23] [data] Done reading 20,192 sentences
[2023-06-25 15:47:23] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 15:47:29] Ep. 93 : Up. 45000 : Sen. 553 : Cost 1.63629663 : Time 464.53s : 2102.53 words/s : gNorm 0.2200
[2023-06-25 15:51:11] Seen 20,177 samples
[2023-06-25 15:51:11] Starting data epoch 94 in logical epoch 94
[2023-06-25 15:51:11] [data] Shuffling data
[2023-06-25 15:51:11] [data] Done reading 20,192 sentences
[2023-06-25 15:51:11] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 15:54:58] Seen 20,177 samples
[2023-06-25 15:54:58] Starting data epoch 95 in logical epoch 95
[2023-06-25 15:54:58] [data] Shuffling data
[2023-06-25 15:54:58] [data] Done reading 20,192 sentences
[2023-06-25 15:54:58] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 15:55:13] Ep. 95 : Up. 46000 : Sen. 1,504 : Cost 1.63253713 : Time 463.51s : 2106.31 words/s : gNorm 0.2085
[2023-06-25 15:58:43] Seen 20,177 samples
[2023-06-25 15:58:43] Starting data epoch 96 in logical epoch 96
[2023-06-25 15:58:43] [data] Shuffling data
[2023-06-25 15:58:43] [data] Done reading 20,192 sentences
[2023-06-25 15:58:43] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 16:02:30] Seen 20,177 samples
[2023-06-25 16:02:30] Starting data epoch 97 in logical epoch 97
[2023-06-25 16:02:30] [data] Shuffling data
[2023-06-25 16:02:30] [data] Done reading 20,192 sentences
[2023-06-25 16:02:30] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 16:02:57] Ep. 97 : Up. 47000 : Sen. 2,332 : Cost 1.63143718 : Time 463.78s : 2108.25 words/s : gNorm 0.2025
[2023-06-25 16:06:17] Seen 20,177 samples
[2023-06-25 16:06:17] Starting data epoch 98 in logical epoch 98
[2023-06-25 16:06:17] [data] Shuffling data
[2023-06-25 16:06:17] [data] Done reading 20,192 sentences
[2023-06-25 16:06:17] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 16:10:06] Seen 20,177 samples
[2023-06-25 16:10:06] Starting data epoch 99 in logical epoch 99
[2023-06-25 16:10:06] [data] Shuffling data
[2023-06-25 16:10:06] [data] Done reading 20,192 sentences
[2023-06-25 16:10:06] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 16:10:41] Ep. 99 : Up. 48000 : Sen. 3,176 : Cost 1.63090086 : Time 464.57s : 2105.65 words/s : gNorm 0.2012
[2023-06-25 16:13:49] Seen 20,177 samples
[2023-06-25 16:13:49] Starting data epoch 100 in logical epoch 100
[2023-06-25 16:13:49] [data] Shuffling data
[2023-06-25 16:13:49] [data] Done reading 20,192 sentences
[2023-06-25 16:13:49] [data] Done shuffling 20,192 sentences to temp files
[2023-06-25 16:17:31] Seen 20,177 samples
[2023-06-25 16:17:31] Starting data epoch 101 in logical epoch 101
[2023-06-25 16:17:31] Training finished
[2023-06-25 16:17:47] [valid] Ep. 101 : Up. 48900 : cross-entropy : 102.577 : stalled 9 times (last best: 86.5722)
[2023-06-25 16:21:28] [valid] Ep. 101 : Up. 48900 : translation : 0 : new best
[2023-06-25 16:21:28] Saving model weights and runtime parameters to /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz
[2023-06-25 16:21:36] Saving Adam parameters
[2023-06-25 16:21:39] [training] Saving training checkpoint to /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz and /docker/home/marianmt/artifacts/models/model_gn_es_edinburgh2017_depth2/gn_es_edinburgh2017_depth2.npz.optimizer.npz
